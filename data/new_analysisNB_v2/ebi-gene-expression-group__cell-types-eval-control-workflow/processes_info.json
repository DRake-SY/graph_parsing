{
    "fetch_training_datasets": {
        "name_process": "fetch_training_datasets",
        "string_process": "\nprocess fetch_training_datasets {\n    conda \"${baseDir}/envs/load_data.yaml\"\n\n    input:\n        tuple val(dataset_id), val(seq_method), val(num_clust), val(barcode_col), val(cell_type_col), val(matrix_type) from IMPORT_PARAMS\n\n    output:\n        tuple file(dataset_id), val(dataset_id), val(barcode_col), val(cell_type_col), val(matrix_type) into TRAINING_DATA\n        val(num_clust) into N_CLUST\n\n    \"\"\"\n    if [ ${seq_method} ==  \"droplet\" ]; then \n        MATRIX_TYPE_UPD=\"CPM\"\n    else\n        MATRIX_TYPE_UPD=${matrix_type}\n    fi\n    get_experiment_data.R\\\n                --accesssion-code ${dataset_id}\\\n                --config-file ${params.data_import.scxa_import_config_file}\\\n                --matrix-type \\$MATRIX_TYPE_UPD\\\n                --output-dir-name ${dataset_id}\\\n                --get-sdrf ${params.data_import.get_sdrf}\\\n                --get-condensed-sdrf ${params.data_import.get_cond_sdrf}\\\n                --get-idf ${params.data_import.get_idf}\\\n                --get-marker-genes ${params.data_import.get_marker_genes}\\\n                --number-of-clusters ${num_clust}\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "\"\"\"\n    if [ ${seq_method} ==  \"droplet\" ]; then \n        MATRIX_TYPE_UPD=\"CPM\"\n    else\n        MATRIX_TYPE_UPD=${matrix_type}\n    fi\n    get_experiment_data.R\\\n                --accesssion-code ${dataset_id}\\\n                --config-file ${params.data_import.scxa_import_config_file}\\\n                --matrix-type \\$MATRIX_TYPE_UPD\\\n                --output-dir-name ${dataset_id}\\\n                --get-sdrf ${params.data_import.get_sdrf}\\\n                --get-condensed-sdrf ${params.data_import.get_cond_sdrf}\\\n                --get-idf ${params.data_import.get_idf}\\\n                --get-marker-genes ${params.data_import.get_marker_genes}\\\n                --number-of-clusters ${num_clust}\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "IMPORT_PARAMS"
        ],
        "nb_inputs": 1,
        "outputs": [
            "TRAINING_DATA",
            "N_CLUST"
        ],
        "nb_outputs": 2,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [
            "conda \"${baseDir}/envs/load_data.yaml\""
        ],
        "when": "",
        "stub": ""
    },
    "unmelt_condensed_sdrf": {
        "name_process": "unmelt_condensed_sdrf",
        "string_process": " process unmelt_condensed_sdrf {\n        conda \"${baseDir}/envs/exp_metadata.yaml\"\n\n        input:\n            tuple file(data), val(dataset_id), val(barcode_col), val(cell_type_col), val(matrix_type) from TRAINING_DATA\n\n        output:\n            tuple file(\"${data}.query\"), file(\"${data}.ref\"), val(dataset_id), val(barcode_col), val(cell_type_col), val(matrix_type) into TRAINING_DATA_UNMELT\n\t    file(\"${data}/unmelted_sdrf.tsv\") into UNMELTED_SDRF_QUERY\n        \"\"\"\n        unmelt_condensed.R\\\n                -i ${data}/condensed-sdrf.tsv\\\n                -o ${data}/unmelted_sdrf.tsv\\\n                --has-ontology\\\n                --retain-types ${params.data_import.unmelt_sdrf.retain_types}\n\t# rename data dir name to avoid downstream file name collision\n\tparallel cp -R ${data} ::: ${data}.query ${data}.ref \n        \"\"\"\n    }",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n        unmelt_condensed.R\\\n                -i ${data}/condensed-sdrf.tsv\\\n                -o ${data}/unmelted_sdrf.tsv\\\n                --has-ontology\\\n                --retain-types ${params.data_import.unmelt_sdrf.retain_types}\n\t# rename data dir name to avoid downstream file name collision\n\tparallel cp -R ${data} ::: ${data}.query ${data}.ref \n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "parallelGWAS"
        ],
        "tools_url": [
            "https://bio.tools/parallelgwas"
        ],
        "tools_dico": [
            {
                "name": "parallelGWAS",
                "uri": "https://bio.tools/parallelgwas",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Developing parallel computing tools for genome-wide association studies.",
                "homepage": "https://en.osdn.jp/projects/parallelgwas/"
            }
        ],
        "inputs": [
            "TRAINING_DATA"
        ],
        "nb_inputs": 1,
        "outputs": [
            "TRAINING_DATA_UNMELT",
            "UNMELTED_SDRF_QUERY"
        ],
        "nb_outputs": 2,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [
            "conda \"${baseDir}/envs/exp_metadata.yaml\""
        ],
        "when": "",
        "stub": ""
    },
    "unzip_data": {
        "name_process": "unzip_data",
        "string_process": "\tprocess unzip_data {\n\t\n\tinput: \n\ttuple file(test_zip), file(train_zip), val(dataset_id), val(matrix_type) from GROUPED_DATA\n\tval(barcode_col) from BARCODE_COL\n\tval(cell_label_col) from CELL_LABEL_COL\t\n\t\n\toutput: \n\ttuple file(\"*.test.*\"), file(\"*.train.*\"), val(dataset_id), val(barcode_col), val(cell_label_col), val(matrix_type) into DATA\n\tfile(\"*.test.*/marker_genes_*\") into MARKERS\n\tfile(\"*.test.*/unmelted_sdrf.tsv\") into UNMELTED_SDRF_QUERY\n\t\"\"\"\n\t# unzip test \n\tunzip $test_zip\n\t# unzip train \n\tunzip $train_zip\n\t\"\"\"\n\t}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n\t# unzip test \n\tunzip $test_zip\n\t# unzip train \n\tunzip $train_zip\n\t\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "GROUPED_DATA",
            "BARCODE_COL",
            "CELL_LABEL_COL"
        ],
        "nb_inputs": 3,
        "outputs": [
            "DATA",
            "MARKERS",
            "UNMELTED_SDRF_QUERY"
        ],
        "nb_outputs": 3,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "run_garnett_workflow": {
        "name_process": "run_garnett_workflow",
        "string_process": " process run_garnett_workflow {\n        publishDir \"${params.tool_outputs_dir}\", mode: 'copy'\n        conda \"${baseDir}/envs/nextflow.yaml\"\n\n        errorStrategy { task.exitStatus == 130 || task.exitStatus == 137  ? 'retry' : 'finish' }   \n        maxRetries 5\n        memory { 16.GB * task.attempt }\n        \n        input:\n            tuple file(test_data), file(training_data), val(dataset_id), val(barcode_col), val(cell_label_col), val(matrix_type), val(num_clust) from GARNETT_FILTERED_DATA\n        output:\n             file(\"garnett_output.txt\") into GARNETT_OUTPUT\n\n        \"\"\"\n        RESULTS_DIR=\\$PWD\n        nextflow run $EVAL_WORKFLOWS/garnett-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --ref_10x_dir \"${training_data}/10x_data\"\\\n                            --query_10x_dir \"${test_data}/10x_data\"\\\n                            --marker_genes ${training_data}/marker_genes_${num_clust}.tsv\\\n                            --pval-col ${params.garnett.pval_col}\\\n                            --groups-col ${params.garnett.groups_col}\\\n                            --gene-names ${params.garnett.gene_names}\\\n                            --ref_cds_gene_id_type ${params.garnett.ref_cds_gene_id_type}\\\n                            --query_cds_gene_id_type ${params.garnett.query_cds_gene_id_type}\\\n                            --database ${params.garnett.database}\\\n                            --marker_gene_id_type ${params.garnett.marker_gene_id_type}\\\n                            --classifier_gene_type ${params.garnett.classifier_gene_type}\\\n                            --n_outgroups ${params.garnett.n_outgroups}\\\n                            --cell_id_field ${params.garnett.cell_id_field}\\\n                            --predicted_cell_type_field ${params.garnett.predicted_cell_type_field}\n        \"\"\"\n    }",
        "nb_lignes_process": 32,
        "string_script": "\"\"\"\n        RESULTS_DIR=\\$PWD\n        nextflow run $EVAL_WORKFLOWS/garnett-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --ref_10x_dir \"${training_data}/10x_data\"\\\n                            --query_10x_dir \"${test_data}/10x_data\"\\\n                            --marker_genes ${training_data}/marker_genes_${num_clust}.tsv\\\n                            --pval-col ${params.garnett.pval_col}\\\n                            --groups-col ${params.garnett.groups_col}\\\n                            --gene-names ${params.garnett.gene_names}\\\n                            --ref_cds_gene_id_type ${params.garnett.ref_cds_gene_id_type}\\\n                            --query_cds_gene_id_type ${params.garnett.query_cds_gene_id_type}\\\n                            --database ${params.garnett.database}\\\n                            --marker_gene_id_type ${params.garnett.marker_gene_id_type}\\\n                            --classifier_gene_type ${params.garnett.classifier_gene_type}\\\n                            --n_outgroups ${params.garnett.n_outgroups}\\\n                            --cell_id_field ${params.garnett.cell_id_field}\\\n                            --predicted_cell_type_field ${params.garnett.predicted_cell_type_field}\n        \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "Nextflow"
        ],
        "tools_url": [
            "https://bio.tools/nextflow"
        ],
        "tools_dico": [
            {
                "name": "Nextflow",
                "uri": "https://bio.tools/nextflow",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3762",
                                    "term": "Service composition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Nextflow enables scalable and reproducible scientific workflows using software containers. It allows the adaptation of pipelines written in the most common scripting languages.",
                "homepage": "https://www.nextflow.io/"
            }
        ],
        "inputs": [
            "GARNETT_FILTERED_DATA"
        ],
        "nb_inputs": 1,
        "outputs": [
            "GARNETT_OUTPUT"
        ],
        "nb_outputs": 1,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [
            "publishDir \"${params.tool_outputs_dir}\", mode: 'copy'",
            "conda \"${baseDir}/envs/nextflow.yaml\"",
            "errorStrategy { task.exitStatus == 130 || task.exitStatus == 137 ? 'retry' : 'finish' }",
            "maxRetries 5",
            "memory { 16.GB * task.attempt }"
        ],
        "when": "",
        "stub": ""
    },
    "run_scmap_cell_workflow": {
        "name_process": "run_scmap_cell_workflow",
        "string_process": " process run_scmap_cell_workflow {\n        publishDir \"${params.tool_outputs_dir}\", mode: 'copy'\n        conda \"${baseDir}/envs/nextflow.yaml\"\n\n        errorStrategy { task.exitStatus == 130 || task.exitStatus == 137  ? 'retry' : 'finish' }   \n        maxRetries 5\n        memory { 16.GB * task.attempt }\n\n        input:\n\t\ttuple file(test_data), file(training_data), val(dataset_id), val(barcode_col), val(cell_label_col), val(matrix_type) from SCMAP_CELL_FILTERED_DATA\n        output: \n            file(\"scmap-cell_output.txt\") into SCMAP_CELL_OUTPUT\n\n        \"\"\"\n        RESULTS_DIR=\\$PWD    \n        nextflow run $EVAL_WORKFLOWS/scmap-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --projection_method ${params.scmap_cell.projection_method}\\\n                            --query_10x_dir \"${test_data}/10x_data\"\\\n                            --reference_10x_dir \"${training_data}/10x_data\"\\\n                            --reference_metadata ${training_data}/unmelted_sdrf.tsv\\\n                            --output_dir_cell ${params.scmap_cell.output_dir_cell}\\\n                            --col_names ${params.scmap_cell.col_names}\\\n                            --cell_id_col ${params.metadata.ref_barcode_col_name}\\\n                            --cluster_col ${params.metadata.ref_label_col_name}\\\n                            --plot_file ${params.scmap_cell.plot_file}\\\n                            --threshold ${params.scmap_cell.threshold}\n        \"\"\"\n    }",
        "nb_lignes_process": 28,
        "string_script": "\"\"\"\n        RESULTS_DIR=\\$PWD    \n        nextflow run $EVAL_WORKFLOWS/scmap-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --projection_method ${params.scmap_cell.projection_method}\\\n                            --query_10x_dir \"${test_data}/10x_data\"\\\n                            --reference_10x_dir \"${training_data}/10x_data\"\\\n                            --reference_metadata ${training_data}/unmelted_sdrf.tsv\\\n                            --output_dir_cell ${params.scmap_cell.output_dir_cell}\\\n                            --col_names ${params.scmap_cell.col_names}\\\n                            --cell_id_col ${params.metadata.ref_barcode_col_name}\\\n                            --cluster_col ${params.metadata.ref_label_col_name}\\\n                            --plot_file ${params.scmap_cell.plot_file}\\\n                            --threshold ${params.scmap_cell.threshold}\n        \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "Nextflow"
        ],
        "tools_url": [
            "https://bio.tools/nextflow"
        ],
        "tools_dico": [
            {
                "name": "Nextflow",
                "uri": "https://bio.tools/nextflow",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3762",
                                    "term": "Service composition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Nextflow enables scalable and reproducible scientific workflows using software containers. It allows the adaptation of pipelines written in the most common scripting languages.",
                "homepage": "https://www.nextflow.io/"
            }
        ],
        "inputs": [
            "SCMAP_CELL_FILTERED_DATA"
        ],
        "nb_inputs": 1,
        "outputs": [
            "SCMAP_CELL_OUTPUT"
        ],
        "nb_outputs": 1,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [
            "publishDir \"${params.tool_outputs_dir}\", mode: 'copy'",
            "conda \"${baseDir}/envs/nextflow.yaml\"",
            "errorStrategy { task.exitStatus == 130 || task.exitStatus == 137 ? 'retry' : 'finish' }",
            "maxRetries 5",
            "memory { 16.GB * task.attempt }"
        ],
        "when": "",
        "stub": ""
    },
    "run_scmap_cluster_workflow": {
        "name_process": "run_scmap_cluster_workflow",
        "string_process": " process run_scmap_cluster_workflow {\n        publishDir \"${params.tool_outputs_dir}\", mode: 'copy'\n        conda \"${baseDir}/envs/nextflow.yaml\"\n\n        errorStrategy { task.exitStatus == 130 || task.exitStatus == 137  ? 'retry' : 'finish' }   \n        maxRetries 5\n        memory { 16.GB * task.attempt }\n\n        input:\n\t\ttuple file(test_data), file(training_data), val(dataset_id), val(barcode_col), val(cell_label_col), val(matrix_type) from SCMAP_CLUSTER_FILTERED_DATA\n\n        output:\n            file(\"scmap-cluster_output.txt\") into SCMAP_CLUST_OUTPUT\n\n        \"\"\"\n        RESULTS_DIR=\\$PWD\n        nextflow run $EVAL_WORKFLOWS/scmap-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --projection_method ${params.scmap_cluster.projection_method}\\\n                            --query_10x_dir \"${test_data}/10x_data\"\\\n                            --reference_10x_dir \"${training_data}/10x_data\"\\\n                            --reference_metadata  ${training_data}/unmelted_sdrf.tsv\\\n                            --output_dir_cluster ${params.scmap_cluster.output_dir_cluster}\\\n                            --col_names ${params.scmap_cluster.col_names}\\\n                            --cell_id_col ${params.metadata.ref_barcode_col_name}\\\n                            --cluster_col ${params.metadata.ref_label_col_name}\\\n                            --plot_file ${params.scmap_cluster.plot_file}\\\n                            --threshold ${params.scmap_cluster.threshold}\n        \"\"\"\n    }",
        "nb_lignes_process": 29,
        "string_script": "\"\"\"\n        RESULTS_DIR=\\$PWD\n        nextflow run $EVAL_WORKFLOWS/scmap-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --projection_method ${params.scmap_cluster.projection_method}\\\n                            --query_10x_dir \"${test_data}/10x_data\"\\\n                            --reference_10x_dir \"${training_data}/10x_data\"\\\n                            --reference_metadata  ${training_data}/unmelted_sdrf.tsv\\\n                            --output_dir_cluster ${params.scmap_cluster.output_dir_cluster}\\\n                            --col_names ${params.scmap_cluster.col_names}\\\n                            --cell_id_col ${params.metadata.ref_barcode_col_name}\\\n                            --cluster_col ${params.metadata.ref_label_col_name}\\\n                            --plot_file ${params.scmap_cluster.plot_file}\\\n                            --threshold ${params.scmap_cluster.threshold}\n        \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "Nextflow"
        ],
        "tools_url": [
            "https://bio.tools/nextflow"
        ],
        "tools_dico": [
            {
                "name": "Nextflow",
                "uri": "https://bio.tools/nextflow",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3762",
                                    "term": "Service composition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Nextflow enables scalable and reproducible scientific workflows using software containers. It allows the adaptation of pipelines written in the most common scripting languages.",
                "homepage": "https://www.nextflow.io/"
            }
        ],
        "inputs": [
            "SCMAP_CLUSTER_FILTERED_DATA"
        ],
        "nb_inputs": 1,
        "outputs": [
            "SCMAP_CLUST_OUTPUT"
        ],
        "nb_outputs": 1,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [
            "publishDir \"${params.tool_outputs_dir}\", mode: 'copy'",
            "conda \"${baseDir}/envs/nextflow.yaml\"",
            "errorStrategy { task.exitStatus == 130 || task.exitStatus == 137 ? 'retry' : 'finish' }",
            "maxRetries 5",
            "memory { 16.GB * task.attempt }"
        ],
        "when": "",
        "stub": ""
    },
    "run_scpred_workflow": {
        "name_process": "run_scpred_workflow",
        "string_process": " process run_scpred_workflow {\n        publishDir \"${params.tool_outputs_dir}\", mode: 'copy'\n        conda \"${baseDir}/envs/nextflow.yaml\"\n\n        errorStrategy { task.exitStatus == 130 || task.exitStatus == 137  ? 'retry' : 'finish' }   \n        maxRetries 5\n        memory { 16.GB * task.attempt }\n        \n        input:\n\t\ttuple file(test_data), file(training_data), val(dataset_id), val(barcode_col), val(cell_label_col), val(matrix_type) from SCPRED_FILTERED_DATA\n\n        output:\n            file(\"scpred_output.txt\") into SCPRED_OUTPUT\n\n        \"\"\"\n        RESULTS_DIR=\\$PWD\n        nextflow run $EVAL_WORKFLOWS/scpred-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --method ${params.scpred.method}\\\n                            -latest\\\n                            --training_10x_dir \"${training_data}/10x_data\"\\\n                            --prediction_10x_dir \"${test_data}/10x_data\"\\\n                            --metadata_file ${training_data}/unmelted_sdrf.tsv\\\n                            --eigenvalue_plot_path ${params.scpred.eigenvalue_plot_path}\\\n                            --train_probs_plot_path ${params.scpred.train_probs_plot_path}\\\n                            --prediction_probs_path ${params.scpred.prediction_probs_path}\\\n                            --model_predictions_path ${params.scpred.model_predictions_path}\\\n                            --confusion_table_path ${params.scpred.confusion_table_path}\\\n                            --normalised_counts_slot ${params.scpred.normalised_counts_slot}\\\n                            --cell_id_col_name ${params.metadata.ref_barcode_col_name}\\\n                            --cell_types_col_name ${params.metadata.ref_label_col_name}\\\n                            --col_names ${params.scpred.col_names}\\\n                            --log_transform ${params.scpred.log_transform}\\\n                            --model ${params.scpred.model}\n        \"\"\"\n    }",
        "nb_lignes_process": 35,
        "string_script": "\"\"\"\n        RESULTS_DIR=\\$PWD\n        nextflow run $EVAL_WORKFLOWS/scpred-eval-workflow/main.nf\\\n                            -profile ${params.profile}\\\n                            --results_dir \\$RESULTS_DIR\\\n                            --method ${params.scpred.method}\\\n                            -latest\\\n                            --training_10x_dir \"${training_data}/10x_data\"\\\n                            --prediction_10x_dir \"${test_data}/10x_data\"\\\n                            --metadata_file ${training_data}/unmelted_sdrf.tsv\\\n                            --eigenvalue_plot_path ${params.scpred.eigenvalue_plot_path}\\\n                            --train_probs_plot_path ${params.scpred.train_probs_plot_path}\\\n                            --prediction_probs_path ${params.scpred.prediction_probs_path}\\\n                            --model_predictions_path ${params.scpred.model_predictions_path}\\\n                            --confusion_table_path ${params.scpred.confusion_table_path}\\\n                            --normalised_counts_slot ${params.scpred.normalised_counts_slot}\\\n                            --cell_id_col_name ${params.metadata.ref_barcode_col_name}\\\n                            --cell_types_col_name ${params.metadata.ref_label_col_name}\\\n                            --col_names ${params.scpred.col_names}\\\n                            --log_transform ${params.scpred.log_transform}\\\n                            --model ${params.scpred.model}\n        \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "Nextflow"
        ],
        "tools_url": [
            "https://bio.tools/nextflow"
        ],
        "tools_dico": [
            {
                "name": "Nextflow",
                "uri": "https://bio.tools/nextflow",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3762",
                                    "term": "Service composition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Nextflow enables scalable and reproducible scientific workflows using software containers. It allows the adaptation of pipelines written in the most common scripting languages.",
                "homepage": "https://www.nextflow.io/"
            }
        ],
        "inputs": [
            "SCPRED_FILTERED_DATA"
        ],
        "nb_inputs": 1,
        "outputs": [
            "SCPRED_OUTPUT"
        ],
        "nb_outputs": 1,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [
            "publishDir \"${params.tool_outputs_dir}\", mode: 'copy'",
            "conda \"${baseDir}/envs/nextflow.yaml\"",
            "errorStrategy { task.exitStatus == 130 || task.exitStatus == 137 ? 'retry' : 'finish' }",
            "maxRetries 5",
            "memory { 16.GB * task.attempt }"
        ],
        "when": "",
        "stub": ""
    },
    "combine_results": {
        "name_process": "combine_results",
        "string_process": "\nprocess combine_results{\n    input:\n        file(method_outputs) from ALL_RESULTS.collect()\n\n    output:\n        file('results_dir') into COMBINED_RESULTS_DIR\n\n    \"\"\"\n    mkdir -p results_dir/\n    for file in ${method_outputs}\n    do\n        mv \\$file results_dir\n    done\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\n    mkdir -p results_dir/\n    for file in ${method_outputs}\n    do\n        mv \\$file results_dir\n    done\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ALL_RESULTS"
        ],
        "nb_inputs": 1,
        "outputs": [
            "COMBINED_RESULTS_DIR"
        ],
        "nb_outputs": 1,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "run_label_analysis": {
        "name_process": "run_label_analysis",
        "string_process": " process run_label_analysis {\n        conda \"${baseDir}/envs/nextflow.yaml\"\n        publishDir \"${params.label_analysis_outdir}\", mode: 'copy'\n        errorStrategy { task.exitStatus == 130 || task.exitStatus == 137  ? 'retry' : 'finish' }   \n        maxRetries 5\n        memory { 16.GB * task.attempt }\n\n        input:\n            file(tool_outputs_dir) from COMBINED_RESULTS_DIR\n                                                                                             \n            file(query_lab_file) from UNMELTED_SDRF_QUERY.first()\n\n        output:\n            file(\"${params.label_analysis.tool_perf_table}\") into TOOL_PERF_TABLE\n            file(\"${params.label_analysis.tool_table_pvals}\") into TOOL_TABLE_PVALS\n\n        \"\"\"\n        RESULTS_DIR=\\$PWD \n        nextflow run $EVAL_WORKFLOWS/label-analysis-eval-workflow/main.nf\\\n                            -profile cluster\\\n\t\t\t    --results_dir \\$RESULTS_DIR\\\n                            --input_dir ${tool_outputs_dir}\\\n                            --condensed_sdrf ${params.label_analysis.condensed_sdrf}\\\n\t\t   \t    --parallel ${params.label_analysis.parallel}\\\n                            --ontology_dict ${params.label_analysis.ontology_dict}\\\n                            --ontology_graph ${params.label_analysis.ontology_graph}\\\n\t\t\t    --tool_perf_table ${params.label_analysis.tool_perf_table}\\\n                            --cell_anno_table ${params.label_analysis.cell_anno_table}\\\n                            --tool_table_pvals ${params.label_analysis.tool_table_pvals}\\\n                            --ref_labels_file ${query_lab_file}\\\n                            --empirical_dist ${params.label_analysis.empirical_dist}\\\n                            --num_iter ${params.label_analysis.num_iter}\\\n                            --num_cores ${params.label_analysis.num_cores}\\\n                            --cell_ontology_col ${params.metadata.ref_CL_col_name}\\\n                            --barcode_col_ref ${params.label_analysis.barcode_col_ref}\\\n                            --barcode_col_pred ${params.label_analysis.barcode_col_pred}\\\n                            --label_column_ref ${params.metadata.ref_label_col_name}\\\n                            --label_column_pred ${params.label_analysis.label_column_pred}\\\n                            --semantic_sim_metric ${params.label_analysis.semantic_sim_metric}\n        \"\"\"\n    }",
        "nb_lignes_process": 39,
        "string_script": "\"\"\"\n        RESULTS_DIR=\\$PWD \n        nextflow run $EVAL_WORKFLOWS/label-analysis-eval-workflow/main.nf\\\n                            -profile cluster\\\n\t\t\t    --results_dir \\$RESULTS_DIR\\\n                            --input_dir ${tool_outputs_dir}\\\n                            --condensed_sdrf ${params.label_analysis.condensed_sdrf}\\\n\t\t   \t    --parallel ${params.label_analysis.parallel}\\\n                            --ontology_dict ${params.label_analysis.ontology_dict}\\\n                            --ontology_graph ${params.label_analysis.ontology_graph}\\\n\t\t\t    --tool_perf_table ${params.label_analysis.tool_perf_table}\\\n                            --cell_anno_table ${params.label_analysis.cell_anno_table}\\\n                            --tool_table_pvals ${params.label_analysis.tool_table_pvals}\\\n                            --ref_labels_file ${query_lab_file}\\\n                            --empirical_dist ${params.label_analysis.empirical_dist}\\\n                            --num_iter ${params.label_analysis.num_iter}\\\n                            --num_cores ${params.label_analysis.num_cores}\\\n                            --cell_ontology_col ${params.metadata.ref_CL_col_name}\\\n                            --barcode_col_ref ${params.label_analysis.barcode_col_ref}\\\n                            --barcode_col_pred ${params.label_analysis.barcode_col_pred}\\\n                            --label_column_ref ${params.metadata.ref_label_col_name}\\\n                            --label_column_pred ${params.label_analysis.label_column_pred}\\\n                            --semantic_sim_metric ${params.label_analysis.semantic_sim_metric}\n        \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "Nextflow"
        ],
        "tools_url": [
            "https://bio.tools/nextflow"
        ],
        "tools_dico": [
            {
                "name": "Nextflow",
                "uri": "https://bio.tools/nextflow",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3762",
                                    "term": "Service composition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Nextflow enables scalable and reproducible scientific workflows using software containers. It allows the adaptation of pipelines written in the most common scripting languages.",
                "homepage": "https://www.nextflow.io/"
            }
        ],
        "inputs": [
            "COMBINED_RESULTS_DIR",
            "UNMELTED_SDRF_QUERY"
        ],
        "nb_inputs": 2,
        "outputs": [
            "TOOL_PERF_TABLE",
            "TOOL_TABLE_PVALS"
        ],
        "nb_outputs": 2,
        "name_workflow": "ebi-gene-expression-group__cell-types-eval-control-workflow",
        "directive": [
            "conda \"${baseDir}/envs/nextflow.yaml\"",
            "publishDir \"${params.label_analysis_outdir}\", mode: 'copy'",
            "errorStrategy { task.exitStatus == 130 || task.exitStatus == 137 ? 'retry' : 'finish' }",
            "maxRetries 5",
            "memory { 16.GB * task.attempt }"
        ],
        "when": "",
        "stub": ""
    }
}