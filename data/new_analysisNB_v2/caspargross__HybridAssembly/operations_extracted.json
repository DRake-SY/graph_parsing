{
    "OPERATION_1": {
        "string": "files = Channel.create()",
        "origin": [],
        "gives": [
            [
                "files",
                "P"
            ]
        ]
    },
    "OPERATION_2": {
        "string": "files_to_seqpurge = Channel.create()",
        "origin": [],
        "gives": [
            [
                "files_to_seqpurge",
                "P"
            ]
        ]
    },
    "OPERATION_3": {
        "string": "files_preprocessed = Channel.create()",
        "origin": [],
        "gives": [
            [
                "files_preprocessed",
                "P"
            ]
        ]
    },
    "OPERATION_4": {
        "string": "files_filtered = Channel.create()",
        "origin": [],
        "gives": [
            [
                "files_filtered",
                "P"
            ]
        ]
    },
    "OPERATION_5": {
        "string": "files_pilon = Channel.create()",
        "origin": [],
        "gives": [
            [
                "files_pilon",
                "P"
            ]
        ]
    },
    "OPERATION_6": {
        "string": "assembly_nopilon = Channel.create()",
        "origin": [],
        "gives": [
            [
                "assembly_nopilon",
                "P"
            ]
        ]
    },
    "OPERATION_7": {
        "string": "assembly_pilon = Channel.create()",
        "origin": [],
        "gives": [
            [
                "assembly_pilon",
                "P"
            ]
        ]
    },
    "OPERATION_8": {
        "string": "assembly_merged = Channel.create()",
        "origin": [],
        "gives": [
            [
                "assembly_merged",
                "P"
            ]
        ]
    },
    "OPERATION_9": {
        "string": "read_stats = Channel.create()",
        "origin": [],
        "gives": [
            [
                "read_stats",
                "P"
            ]
        ]
    },
    "OPERATION_10": {
        "string": "to_sample_stats = Channel.create()",
        "origin": [],
        "gives": [
            [
                "to_sample_stats",
                "P"
            ]
        ]
    },
    "OPERATION_11": {
        "string": "files.into{files_init; files_preprocessing}",
        "origin": [
            [
                "files",
                "P"
            ]
        ],
        "gives": [
            [
                "files_init",
                "P"
            ],
            [
                "files_preprocessing",
                "P"
            ]
        ]
    },
    "OPERATION_12": {
        "string": "files_lr_filtered\n    .choice(files_preprocessed, files_to_seqpurge){\n        longReadOnly ? 0 : 1 \n        }",
        "origin": [
            [
                "files_lr_filtered",
                "P"
            ]
        ],
        "gives": [
            [
                "files_preprocessed",
                "P"
            ],
            [
                "files_to_seqpurge",
                "P"
            ]
        ]
    },
    "OPERATION_13": {
        "string": "files_preprocessed\n    .mix(files_filtered)\n    .into{\n        files_pre_unicycler;\n        files_pre_spades;\n        files_pre_canu;\n        files_pre_miniasm;\n        files_pre_flye\n        }",
        "origin": [
            [
                "files_preprocessed",
                "P"
            ],
            [
                "files_filtered",
                "P"
            ]
        ],
        "gives": [
            [
                "files_pre_unicycler",
                "P"
            ],
            [
                "files_pre_spades",
                "P"
            ],
            [
                "files_pre_canu",
                "P"
            ],
            [
                "files_pre_miniasm",
                "P"
            ],
            [
                "files_pre_flye",
                "P"
            ]
        ]
    },
    "OPERATION_14": {
        "string": "files_unpolished_canu.mix(\n    files_unpolished_racon, \n    files_unpolished_flye)\n    .choice(files_pilon, assembly_nopilon){\n        longReadOnly ? 1 : 0}",
        "origin": [
            [
                "files_unpolished_canu",
                "P"
            ],
            [
                "files_unpolished_racon",
                "P"
            ],
            [
                "files_unpolished_flye",
                "P"
            ]
        ],
        "gives": [
            [
                "files_pilon",
                "P"
            ],
            [
                "assembly_nopilon",
                "P"
            ]
        ]
    },
    "OPERATION_15": {
        "string": "assembly_merged = assembly_nopilon\n    .map{it -> [it[0], it[4], it[5]]}\n    .mix(\n        assembly_spades_simple,\n        assembly_gapfiller,\n        assembly_unicycler,\n        assembly_pilon \n        )",
        "origin": [
            [
                "assembly_nopilon",
                "P"
            ],
            [
                "assembly_spades_simple",
                "P"
            ],
            [
                "assembly_gapfiller",
                "P"
            ],
            [
                "assembly_unicycler",
                "P"
            ],
            [
                "assembly_pilon",
                "P"
            ]
        ],
        "gives": [
            [
                "assembly_merged",
                "P"
            ]
        ]
    },
    "OPERATION_16": {
        "string": "stats_lr\n    .mix(stats_sr)\n    .groupTuple()\n    .set{read_stats}",
        "origin": [
            [
                "stats_lr",
                "P"
            ],
            [
                "stats_sr",
                "P"
            ]
        ],
        "gives": [
            [
                "read_stats",
                "P"
            ]
        ]
    },
    "OPERATION_17": {
        "string": "final_files\n    .groupTuple()\n    .join(read_stats)\n    .set{to_sample_stats}",
        "origin": [
            [
                "final_files",
                "P"
            ],
            [
                "read_stats",
                "P"
            ]
        ],
        "gives": [
            [
                "to_sample_stats",
                "P"
            ]
        ]
    },
    "OPERATION_18": {
        "string": "files_init\n    .combine(final_files_plasmident)\n           \n    .collectFile(newLine: true, \n\t\tstoreDir : workflow.launchDir) {\n        it -> \n            ['file_paths_plasmident.tsv', \n\t\tit[0] + '\\t' + it[6].toString() + '\\t' + it[1].toString()]\n    }",
        "origin": [
            [
                "files_init",
                "P"
            ],
            [
                "final_files_plasmident",
                "P"
            ]
        ],
        "gives": []
    }
}