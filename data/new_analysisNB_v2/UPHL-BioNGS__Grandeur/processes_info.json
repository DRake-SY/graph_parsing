{
    "seqyclean": {
        "name_process": "seqyclean",
        "string_process": "\nprocess seqyclean {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus 1\n  container 'staphb/seqyclean:latest'\n\n  when:\n  sample != null\n\n  input:\n  tuple val(sample), file(reads) from reads_seqyclean\n\n  output:\n  tuple sample, file(\"seqyclean/${sample}_clean_PE{1,2}.fastq.gz\") into clean_reads_mash, clean_reads_cg, clean_reads_seqsero2, clean_reads_bwa, clean_reads_shigatyper, clean_reads_kraken2, clean_reads_spades\n  file(\"seqyclean/${sample}_clean_SE.fastq.gz\")\n  file(\"seqyclean/${sample}_clean_SummaryStatistics.tsv\") into seqyclean_files, seqyclean_files_combine\n  file(\"seqyclean/${sample}_clean_SummaryStatistics.txt\")\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n  tuple sample, env(perc_kept) into seqyclean_perc_kept_results\n  tuple sample, env(kept) into seqyclean_pairskept_results\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"seqyclean version: $(seqyclean -h | grep Version | head -n 1)\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    seqyclean !{params.seqyclean_options} \\\n      -c !{params.seqyclean_contaminant_file} \\\n      -1 !{reads[0]} \\\n      -2 !{reads[1]} \\\n      -o seqyclean/!{sample}_clean \\\n      -gz \\\n      2>> $err_file >> $log_file\n\n    kept=$(cut -f 58 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)\n    perc_kept=$(cut -f 59 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)\n    if [ -z \"$kept\" ] ; then kept=\"0\" ; fi\n    if [ -z \"$perc_kept\" ] ; then perc_kept=\"0\" ; fi\n  '''\n}",
        "nb_lignes_process": 47,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"seqyclean version: $(seqyclean -h | grep Version | head -n 1)\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    seqyclean !{params.seqyclean_options} \\\n      -c !{params.seqyclean_contaminant_file} \\\n      -1 !{reads[0]} \\\n      -2 !{reads[1]} \\\n      -o seqyclean/!{sample}_clean \\\n      -gz \\\n      2>> $err_file >> $log_file\n\n    kept=$(cut -f 58 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)\n    perc_kept=$(cut -f 59 seqyclean/!{sample}_clean_SummaryStatistics.tsv | grep -v \"Kept\" | head -n 1)\n    if [ -z \"$kept\" ] ; then kept=\"0\" ; fi\n    if [ -z \"$perc_kept\" ] ; then perc_kept=\"0\" ; fi\n  '''",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "reads_seqyclean"
        ],
        "nb_inputs": 1,
        "outputs": [
            "clean_reads_mash",
            "clean_reads_cg",
            "clean_reads_seqsero2",
            "clean_reads_bwa",
            "clean_reads_shigatyper",
            "clean_reads_kraken2",
            "clean_reads_spades",
            "seqyclean_files",
            "seqyclean_files_combine",
            "seqyclean_perc_kept_results",
            "seqyclean_pairskept_results"
        ],
        "nb_outputs": 11,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'staphb/seqyclean:latest'"
        ],
        "when": "sample != null",
        "stub": ""
    },
    "spades": {
        "name_process": "spades",
        "string_process": "\nprocess spades {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.maxcpus\n  container 'staphb/spades:latest'\n\n  when:\n  params.spades\n\n  input:\n  tuple val(sample), file(reads) from clean_reads_spades\n\n  output:\n  path(\"${task.process}/${sample}\")\n  tuple sample, file(\"contigs/${sample}_contigs.fa\") into contigs_prokka, contigs_quast, contigs_blastn, contigs_mlst, contigs_bwa, contigs_create, contigs_kleborate, contigs_amrfinder, contigs_serotypefinder\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} contigs logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    spades.py --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    spades.py !{params.spades_options} \\\n      -1 !{reads[0]} \\\n      -2 !{reads[1]} \\\n      --threads !{task.cpus} \\\n      -o !{task.process}/!{sample} \\\n      2>> $err_file >> $log_file\n\n    cp !{task.process}/!{sample}/contigs.fasta contigs/!{sample}_contigs.fa\n  '''\n}",
        "nb_lignes_process": 39,
        "string_script": "  '''\n    mkdir -p !{task.process} contigs logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    spades.py --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    spades.py !{params.spades_options} \\\n      -1 !{reads[0]} \\\n      -2 !{reads[1]} \\\n      --threads !{task.cpus} \\\n      -o !{task.process}/!{sample} \\\n      2>> $err_file >> $log_file\n\n    cp !{task.process}/!{sample}/contigs.fasta contigs/!{sample}_contigs.fa\n  '''",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "clean_reads_spades"
        ],
        "nb_inputs": 1,
        "outputs": [
            "contigs_prokka",
            "contigs_quast",
            "contigs_blastn",
            "contigs_mlst",
            "contigs_bwa",
            "contigs_create",
            "contigs_kleborate",
            "contigs_amrfinder",
            "contigs_serotypefinder"
        ],
        "nb_outputs": 9,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.maxcpus",
            "container 'staphb/spades:latest'"
        ],
        "when": "params.spades",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus 1\n  container 'staphb/fastqc:latest'\n\n  when:\n  params.fastqc && sample != null\n\n  input:\n  tuple val(sample), file(raw) from reads_fastqc\n\n  output:\n  file(\"${task.process}/*.html\")\n  file(\"${task.process}/*_fastqc.zip\") into fastqc_files\n  tuple sample, env(raw_1) into fastqc_1_results\n  tuple sample, env(raw_2) into fastqc_2_results\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    fastqc --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    fastqc !{params.fastqc_options} \\\n      --outdir fastqc \\\n      --threads !{task.cpus} \\\n      !{raw} \\\n      2>> $err_file >> $log_file\n\n    zipped_fastq=($(ls fastqc/*fastqc.zip) \"\")\n\n    raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' )\n    raw_2=$(unzip -p fastqc/*fastqc.zip */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' )\n\n    if [ -z \"$raw_1\" ] ; then raw_1=\"0\" ; fi\n    if [ -z \"$raw_2\" ] ; then raw_2=\"0\" ; fi\n  '''\n}",
        "nb_lignes_process": 46,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    fastqc --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    fastqc !{params.fastqc_options} \\\n      --outdir fastqc \\\n      --threads !{task.cpus} \\\n      !{raw} \\\n      2>> $err_file >> $log_file\n\n    zipped_fastq=($(ls fastqc/*fastqc.zip) \"\")\n\n    raw_1=$(unzip -p ${zipped_fastq[0]} */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' )\n    raw_2=$(unzip -p fastqc/*fastqc.zip */fastqc_data.txt | grep \"Total Sequences\" | awk '{ print $3 }' )\n\n    if [ -z \"$raw_1\" ] ; then raw_1=\"0\" ; fi\n    if [ -z \"$raw_2\" ] ; then raw_2=\"0\" ; fi\n  '''",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "reads_fastqc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_files",
            "fastqc_1_results",
            "fastqc_2_results"
        ],
        "nb_outputs": 3,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'staphb/fastqc:latest'"
        ],
        "when": "params.fastqc && sample != null",
        "stub": ""
    },
    "mash_sketch": {
        "name_process": "mash_sketch",
        "string_process": "\nprocess mash_sketch {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus 1\n  container 'staphb/mash:latest'\n\n  when:\n  params.mash\n\n  input:\n  tuple val(sample), file(reads) from clean_reads_mash\n\n  output:\n  tuple sample, file(\"mash/${sample}.msh\") into mash_sketch_files optional true\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n  tuple sample, env(genome_size) into mash_genome_size_results, mash_genome_size_gc\n  tuple sample, env(coverage) into mash_coverage_results\n\n  shell:\n  '''\n    mkdir -p mash logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"mash version: $(mash --version | head -n 1 )\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    cat !{reads} | mash sketch -m 2 -o mash/!{sample} - 2>> $err_file | tee $log_file\n\n    genome_size=$(grep \"Estimated genome size\" $err_file | awk '{print $4}' )\n    coverage=$(grep \"Estimated coverage\" $err_file | awk '{print $3}' )\n  '''\n}",
        "nb_lignes_process": 36,
        "string_script": "  '''\n    mkdir -p mash logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"mash version: $(mash --version | head -n 1 )\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    cat !{reads} | mash sketch -m 2 -o mash/!{sample} - 2>> $err_file | tee $log_file\n\n    genome_size=$(grep \"Estimated genome size\" $err_file | awk '{print $4}' )\n    coverage=$(grep \"Estimated coverage\" $err_file | awk '{print $3}' )\n  '''",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "Mash"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/mash"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "Mash",
                "uri": "https://bio.tools/mash",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2533",
                            "term": "DNA mutation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance matrix generation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Phylogenetic distance matrix generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance matrix construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Fast genome and metagenome distance estimation using MinHash.",
                "homepage": "https://github.com/marbl/mash"
            }
        ],
        "inputs": [
            "clean_reads_mash"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mash_sketch_files",
            "mash_genome_size_results",
            "mash_genome_size_gc",
            "mash_coverage_results"
        ],
        "nb_outputs": 4,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'staphb/mash:latest'"
        ],
        "when": "params.mash",
        "stub": ""
    },
    "mash_dist": {
        "name_process": "mash_dist",
        "string_process": "\nprocess mash_dist {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.medcpus\n  container 'staphb/mash:latest'\n\n  when:\n  params.mash\n\n  input:\n  tuple val(sample), file(msh) from mash_sketch_files.concat(fastas_mash)\n\n  output:\n  tuple sample, file(\"mash/${sample}_mashdist.txt\") optional true\n  tuple sample, env(genus) into mash_genus_results, mash_genus_prokka, mash_genus_gc, mash_genus_amrfinder\n  tuple sample, env(species) into mash_species_results, mash_species_prokka, mash_species_gc, mash_species_amrfinder\n  tuple sample, env(full_mash) into mash_full_results\n  tuple sample, env(pvalue) into mash_pvalue_results\n  tuple sample, env(distance) into mash_distance_results\n  tuple sample, env(salmonella_flag) into salmonella_flag\n  tuple sample, env(ecoli_flag) into ecoli_flag, shigella_flag\n  tuple sample, env(klebsiella_flag) into klebsiella_flag\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p mash logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"mash version: $(mash --version | head -n 1 )\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    mash dist -p !{task.cpus} !{params.mash_options} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file\n\n    if [ ! -s \"mash/!{sample}_mashdist.txt\" ]\n    then\n      echo \"!{sample} had no mash results with '!{params.mash_options}'. Trying again without those parameters.\" 2>> $log_file\n      mash dist -p !{task.cpus} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file\n    fi\n\n    mash_result=($(head -n 1 mash/!{sample}_mashdist.txt | head -n 1 | cut -f 1 | cut -f 8 -d \"-\" | cut -f 1,2 -d \"_\" | cut -f 1 -d \".\" | tr \"_\" \" \" ) 'missing' 'missing')\n    genus=${mash_result[0]}\n    species=${mash_result[1]}\n    full_mash=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 1 )\n    pvalue=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 4 )\n    distance=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 3 )\n    if [ -z \"$full_mash\" ] ; then full_mash='missing' ; fi\n    if [ -z \"$pvalue\" ] ; then pvalue='NA' ; fi\n    if [ -z \"$distance\" ] ; then distance='NA' ; fi\n\n    salmonella_flag=''\n    find_salmonella=$(head mash/!{sample}_mashdist.txt | grep \"Salmonella\" | head -n 1 )\n    if [ -n \"$find_salmonella\" ] ; then salmonella_flag=\"found\" ; else salmonella_flag=\"not\" ; fi\n\n    ecoli_flag=''\n    find_ecoli=$(head mash/!{sample}_mashdist.txt | grep -e \"Escherichia\" -e \"Shigella\" | head -n 1 )\n    if [ -n \"$find_ecoli\" ] ; then ecoli_flag=\"found\" ; else ecoli_flag=\"not\" ; fi\n\n    klebsiella_flag=''\n    find_klebsiella=$(head mash/!{sample}_mashdist.txt | grep -e \"Klebsiella\" -e \"Enterobacter\" -e \"Serratia\" | head -n 1 )\n    if [ -n \"$find_klebsiella\" ] ; then klebsiella_flag=\"found\" ; else klebsiella_flag=\"not\" ; fi\n  '''\n}",
        "nb_lignes_process": 67,
        "string_script": "  '''\n    mkdir -p mash logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"mash version: $(mash --version | head -n 1 )\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    mash dist -p !{task.cpus} !{params.mash_options} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file\n\n    if [ ! -s \"mash/!{sample}_mashdist.txt\" ]\n    then\n      echo \"!{sample} had no mash results with '!{params.mash_options}'. Trying again without those parameters.\" 2>> $log_file\n      mash dist -p !{task.cpus} !{params.mash_reference} !{msh} | sort -gk3 > mash/!{sample}_mashdist.txt 2>> $err_file\n    fi\n\n    mash_result=($(head -n 1 mash/!{sample}_mashdist.txt | head -n 1 | cut -f 1 | cut -f 8 -d \"-\" | cut -f 1,2 -d \"_\" | cut -f 1 -d \".\" | tr \"_\" \" \" ) 'missing' 'missing')\n    genus=${mash_result[0]}\n    species=${mash_result[1]}\n    full_mash=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 1 )\n    pvalue=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 4 )\n    distance=$(head -n 1 mash/!{sample}_mashdist.txt | cut -f 3 )\n    if [ -z \"$full_mash\" ] ; then full_mash='missing' ; fi\n    if [ -z \"$pvalue\" ] ; then pvalue='NA' ; fi\n    if [ -z \"$distance\" ] ; then distance='NA' ; fi\n\n    salmonella_flag=''\n    find_salmonella=$(head mash/!{sample}_mashdist.txt | grep \"Salmonella\" | head -n 1 )\n    if [ -n \"$find_salmonella\" ] ; then salmonella_flag=\"found\" ; else salmonella_flag=\"not\" ; fi\n\n    ecoli_flag=''\n    find_ecoli=$(head mash/!{sample}_mashdist.txt | grep -e \"Escherichia\" -e \"Shigella\" | head -n 1 )\n    if [ -n \"$find_ecoli\" ] ; then ecoli_flag=\"found\" ; else ecoli_flag=\"not\" ; fi\n\n    klebsiella_flag=''\n    find_klebsiella=$(head mash/!{sample}_mashdist.txt | grep -e \"Klebsiella\" -e \"Enterobacter\" -e \"Serratia\" | head -n 1 )\n    if [ -n \"$find_klebsiella\" ] ; then klebsiella_flag=\"found\" ; else klebsiella_flag=\"not\" ; fi\n  '''",
        "nb_lignes_script": 41,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "Mash"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/mash"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "Mash",
                "uri": "https://bio.tools/mash",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2533",
                            "term": "DNA mutation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance matrix generation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Phylogenetic distance matrix generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance matrix construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Fast genome and metagenome distance estimation using MinHash.",
                "homepage": "https://github.com/marbl/mash"
            }
        ],
        "inputs": [
            "mash_sketch_files",
            "fastas_mash"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample",
            "mash_genus_results",
            "mash_genus_prokka",
            "mash_genus_gc",
            "mash_genus_amrfinder",
            "mash_species_results",
            "mash_species_prokka",
            "mash_species_gc",
            "mash_species_amrfinder",
            "mash_full_results",
            "mash_pvalue_results",
            "mash_distance_results",
            "salmonella_flag",
            "ecoli_flag",
            "shigella_flag",
            "klebsiella_flag"
        ],
        "nb_outputs": 16,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/mash:latest'"
        ],
        "when": "params.mash",
        "stub": ""
    },
    "prokka": {
        "name_process": "prokka",
        "string_process": " process prokka {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"${sample}\"\n    cpus params.maxcpus\n    container 'staphb/prokka:latest'\n\n    when:\n    params.prokka\n\n    input:\n    tuple val(sample), file(contigs), val(genus), val(species) from contigs_prokka.concat(fastas_prokka).join(mash_genus_prokka, remainder: true, by:0).join(mash_species_prokka, remainder: true, by:0)\n\n    output:\n    file(\"prokka/${sample}/${sample}.{err,faa,ffn,fna,fsa,gbk,gff,log,sqn,tbl,tsv}\")\n    file(\"prokka/${sample}/${sample}.txt\") into prokka_files\n    file(\"gff/${sample}.gff\") into gffs\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p prokka gff logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      prokka -v >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      prokka !{params.prokka_options} \\\n        --cpu !{task.cpus} \\\n        --centre !{params.center} \\\n        --outdir prokka/!{sample} \\\n        --prefix !{sample} \\\n        --genus !{genus} \\\n        --species !{species} \\\n        --force !{contigs} 2>> $err_file | tee -a $log_file\n\n      cp prokka/!{sample}/!{sample}.gff gff/!{sample}.gff\n    '''\n  }",
        "nb_lignes_process": 41,
        "string_script": "    '''\n      mkdir -p prokka gff logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      prokka -v >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      prokka !{params.prokka_options} \\\n        --cpu !{task.cpus} \\\n        --centre !{params.center} \\\n        --outdir prokka/!{sample} \\\n        --prefix !{sample} \\\n        --genus !{genus} \\\n        --species !{species} \\\n        --force !{contigs} 2>> $err_file | tee -a $log_file\n\n      cp prokka/!{sample}/!{sample}.gff gff/!{sample}.gff\n    '''",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "Prokka"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/prokka"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "Prokka",
                "uri": "https://bio.tools/prokka",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0781",
                            "term": "Virology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.",
                "homepage": "https://github.com/tseemann/prokka"
            }
        ],
        "inputs": [
            "contigs_prokka",
            "fastas_prokka"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prokka_files",
            "gffs"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.maxcpus",
            "container 'staphb/prokka:latest'"
        ],
        "when": "params.prokka",
        "stub": ""
    },
    "quast": {
        "name_process": "quast",
        "string_process": "\nprocess quast {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus 1\n  container 'staphb/quast:latest'\n\n  when:\n  params.quast\n\n  input:\n  tuple val(sample), file(contigs) from contigs_quast.concat(fastas_quast)\n\n  output:\n  path(\"quast/${sample}\")\n  file(\"quast/${sample}_quast_report.tsv\") into quast_files optional true\n  file(\"quast/${sample}/transposed_report.tsv\") into quast_files_combine optional true\n  tuple sample, env(gc) into quast_gc_results\n  tuple sample, env(num_contigs) into quast_contigs_results\n  tuple sample, env(n50) into quast_N50_contigs_results\n  tuple sample, env(length) into quast_length_results\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    quast.py --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    quast.py !{params.quast_options} \\\n      !{contigs} \\\n      --output-dir quast/!{sample} \\\n      --threads !{task.cpus} \\\n      2>> $err_file | tee -a $log_file\n\n    gc=$(grep \"GC (\" quast/!{sample}/report.txt | awk '{print $3}' )\n    num_contigs=$(grep \"contigs\" quast/!{sample}/report.txt | grep -v \"(\" | awk '{print $3}' )\n    n50=$(grep \"N50\" quast/!{sample}/report.txt | awk '{print $2}' )\n    length=$(grep \"Total length\" quast/!{sample}/report.txt | grep -v \"(\" | awk '{print $3}' )\n    if [ -z \"$gc\" ] ; then gc='NA' ; fi\n    if [ -z \"$num_contigs\" ] ; then num_contigs='NA' ; fi\n    if [ -z \"$n50\" ] ; then n50='NA' ; fi\n    if [ -z \"$length\" ] ; then length='NA' ; fi\n\n    cp quast/!{sample}/report.tsv quast/!{sample}_quast_report.tsv\n  '''\n}",
        "nb_lignes_process": 52,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    quast.py --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    quast.py !{params.quast_options} \\\n      !{contigs} \\\n      --output-dir quast/!{sample} \\\n      --threads !{task.cpus} \\\n      2>> $err_file | tee -a $log_file\n\n    gc=$(grep \"GC (\" quast/!{sample}/report.txt | awk '{print $3}' )\n    num_contigs=$(grep \"contigs\" quast/!{sample}/report.txt | grep -v \"(\" | awk '{print $3}' )\n    n50=$(grep \"N50\" quast/!{sample}/report.txt | awk '{print $2}' )\n    length=$(grep \"Total length\" quast/!{sample}/report.txt | grep -v \"(\" | awk '{print $3}' )\n    if [ -z \"$gc\" ] ; then gc='NA' ; fi\n    if [ -z \"$num_contigs\" ] ; then num_contigs='NA' ; fi\n    if [ -z \"$n50\" ] ; then n50='NA' ; fi\n    if [ -z \"$length\" ] ; then length='NA' ; fi\n\n    cp quast/!{sample}/report.tsv quast/!{sample}_quast_report.tsv\n  '''",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "contigs_quast",
            "fastas_quast"
        ],
        "nb_inputs": 2,
        "outputs": [
            "quast_files",
            "quast_files_combine",
            "quast_gc_results",
            "quast_contigs_results",
            "quast_N50_contigs_results",
            "quast_length_results"
        ],
        "nb_outputs": 6,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'staphb/quast:latest'"
        ],
        "when": "params.quast",
        "stub": ""
    },
    "shuffle": {
        "name_process": "shuffle",
        "string_process": "\nprocess shuffle {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus 1\n  container 'staphb/lyveset:latest'\n\n  when:\n  params.cg_pipeline\n\n  input:\n  tuple val(sample), file(reads) from clean_reads_cg\n\n  output:\n  tuple sample, file(\"shuffled/${sample}_shuffled.fastq.gz\") into shuffled_files\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p shuffled logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    run_assembly_shuffleReads.pl -gz !{reads} 2>> $err_file > shuffled/!{sample}_shuffled.fastq.gz\n  '''\n}",
        "nb_lignes_process": 30,
        "string_script": "  '''\n    mkdir -p shuffled logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    run_assembly_shuffleReads.pl -gz !{reads} 2>> $err_file > shuffled/!{sample}_shuffled.fastq.gz\n  '''",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "clean_reads_cg"
        ],
        "nb_inputs": 1,
        "outputs": [
            "shuffled_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'staphb/lyveset:latest'"
        ],
        "when": "params.cg_pipeline",
        "stub": ""
    },
    "cg_pipeline": {
        "name_process": "cg_pipeline",
        "string_process": "\nprocess cg_pipeline {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.medcpus\n  container 'staphb/lyveset:latest'\n\n  when:\n  params.cg_pipeline\n\n  input:\n  tuple val(sample), file(fastq), val(mash), val(genus), val(species), file(genome_file) from for_gc\n\n  output:\n  file(\"cg_pipeline/${sample}_cg_pipeline_report.txt\") optional true into cg_pipeline_files\n  tuple sample, env(read_length) into cg_avrl_results\n  tuple sample, env(quality) into cg_quality_results\n  tuple sample, env(coverage) into cg_cov_results\n  tuple sample, env(reference_genome_length) into ref_genome_length\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    genome_length=''\n    if [ \"!{genus}\" != \"null\" ] && [ \"!{species}\" != \"null\" ] ; then genome_length=$(grep !{genus} !{genome_file} | grep !{species} | grep -v \"#\" | head -n 1 | cut -f 2 -d \":\" | cut -f 1 -d \",\" | awk '{ print $0 \"e+06\" }') ; fi\n    if [ -z \"$genome_length\" ] && [ \"!{mash}\" != \"null\" ] ; then genome_length=$(echo !{mash} | xargs printf \"%.0f\" ) ; fi\n\n    if [ -n \"$genome_length\" ]\n    then\n      run_assembly_readMetrics.pl !{fastq} \\\n        !{params.cg_pipeline_options} \\\n        --fast \\\n        --numcpus !{task.cpus} \\\n        -e $genome_length \\\n        2>> $err_file > cg_pipeline/!{sample}_cg_pipeline_report.txt\n\n        read_length=$(cut -f 2 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )\n        quality=$(cut -f 6 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )\n        coverage=$(cut -f 9 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )\n    else\n      genome_length='0'\n      read_length='NA'\n      quality='NA'\n      coverage='NA'\n      echo \"Could not determine genome length of isolate, so could not run GC pipeline\" | tee $log_file\n    fi\n\n    if [ -z \"$read_length\" ] ; then read_length='NA' ; fi\n    if [ -z \"$quality\" ] ; then quality='NA' ; fi\n    if [ -z \"$coverage\" ] ; then coverage='NA' ; fi\n    reference_genome_length=$genome_length\n  '''\n}",
        "nb_lignes_process": 61,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    genome_length=''\n    if [ \"!{genus}\" != \"null\" ] && [ \"!{species}\" != \"null\" ] ; then genome_length=$(grep !{genus} !{genome_file} | grep !{species} | grep -v \"#\" | head -n 1 | cut -f 2 -d \":\" | cut -f 1 -d \",\" | awk '{ print $0 \"e+06\" }') ; fi\n    if [ -z \"$genome_length\" ] && [ \"!{mash}\" != \"null\" ] ; then genome_length=$(echo !{mash} | xargs printf \"%.0f\" ) ; fi\n\n    if [ -n \"$genome_length\" ]\n    then\n      run_assembly_readMetrics.pl !{fastq} \\\n        !{params.cg_pipeline_options} \\\n        --fast \\\n        --numcpus !{task.cpus} \\\n        -e $genome_length \\\n        2>> $err_file > cg_pipeline/!{sample}_cg_pipeline_report.txt\n\n        read_length=$(cut -f 2 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )\n        quality=$(cut -f 6 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )\n        coverage=$(cut -f 9 cg_pipeline/!{sample}_cg_pipeline_report.txt | tail -n 1 )\n    else\n      genome_length='0'\n      read_length='NA'\n      quality='NA'\n      coverage='NA'\n      echo \"Could not determine genome length of isolate, so could not run GC pipeline\" | tee $log_file\n    fi\n\n    if [ -z \"$read_length\" ] ; then read_length='NA' ; fi\n    if [ -z \"$quality\" ] ; then quality='NA' ; fi\n    if [ -z \"$coverage\" ] ; then coverage='NA' ; fi\n    reference_genome_length=$genome_length\n  '''",
        "nb_lignes_script": 39,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "for_gc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cg_pipeline_files",
            "cg_avrl_results",
            "cg_quality_results",
            "cg_cov_results",
            "ref_genome_length"
        ],
        "nb_outputs": 5,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/lyveset:latest'"
        ],
        "when": "params.cg_pipeline",
        "stub": ""
    },
    "seqsero2": {
        "name_process": "seqsero2",
        "string_process": "\nprocess seqsero2 {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.medcpus\n  container 'staphb/seqsero2:latest'\n\n  when:\n  params.seqsero2 && flag =~ 'found'\n\n  input:\n  tuple val(sample), file(fastq_or_fasta), val(flag) from clean_reads_seqsero2.concat(fastas_seqsero2).join(salmonella_flag, by:0)\n\n  output:\n  tuple sample, env(antigenic_profile) into seqsero2_profile_results\n  tuple sample, env(serotype) into seqsero2_serotype_results\n  tuple sample, env(contamination) into seqsero2_contamination_results\n  file(\"seqsero2/${sample}/*\")\n  file(\"seqsero2/${sample}/SeqSero_result.tsv\") into seqsero2_files\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    SeqSero2_package.py --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    fastq_check=$(echo \"!{fastq_or_fasta}\" | grep \"fastq\" | head -n 1 )\n    if [ -n \"$fastq_check\" ] ; then seqsero_options=\"!{params.seqsero2_options_fastq}\" ; else seqsero_options=\"!{params.seqsero2_options_fasta}\" ; fi\n\n    SeqSero2_package.py $seqsero_options \\\n      -i !{fastq_or_fasta} \\\n      -p !{task.cpus} \\\n      -d seqsero2/!{sample} \\\n      -n !{sample} \\\n      2>> $err_file >> $log_file\n\n    serotype=$(cut -f 9 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)\n    contamination=$(cut -f 10 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)\n    antigenic_profile=$(cut -f 8 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)\n    enteritidis_check=$(grep \"Enteritidis\" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )\n    sdf_check=$(grep \"Detected Sdf\" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )\n\n    if [ -n \"$sdf_check\" ] && [ -n \"$enteritidis_check\" ]\n    then\n      serotype=\"$serotype (Sdf+)\"\n    elif [ -z \"$sdf_check\" ] && [ -n \"$enteritidis_check\" ]\n    then\n      serotype=\"$serotype (Sdf-)\"\n    fi\n\n    if [ -z \"$serotype\" ] ; then serotype='NA' ; fi\n    if [ -z \"$contamination\" ] ; then contamination='NA' ; fi\n    if [ -z \"$antigenic_profile\" ] ; then antigenic_profile='NA' ; fi\n  '''\n}",
        "nb_lignes_process": 61,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    SeqSero2_package.py --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    fastq_check=$(echo \"!{fastq_or_fasta}\" | grep \"fastq\" | head -n 1 )\n    if [ -n \"$fastq_check\" ] ; then seqsero_options=\"!{params.seqsero2_options_fastq}\" ; else seqsero_options=\"!{params.seqsero2_options_fasta}\" ; fi\n\n    SeqSero2_package.py $seqsero_options \\\n      -i !{fastq_or_fasta} \\\n      -p !{task.cpus} \\\n      -d seqsero2/!{sample} \\\n      -n !{sample} \\\n      2>> $err_file >> $log_file\n\n    serotype=$(cut -f 9 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)\n    contamination=$(cut -f 10 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)\n    antigenic_profile=$(cut -f 8 seqsero2/!{sample}/SeqSero_result.tsv | tail -n 1)\n    enteritidis_check=$(grep \"Enteritidis\" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )\n    sdf_check=$(grep \"Detected Sdf\" seqsero2/!{sample}/SeqSero_result.tsv | head -n 1 )\n\n    if [ -n \"$sdf_check\" ] && [ -n \"$enteritidis_check\" ]\n    then\n      serotype=\"$serotype (Sdf+)\"\n    elif [ -z \"$sdf_check\" ] && [ -n \"$enteritidis_check\" ]\n    then\n      serotype=\"$serotype (Sdf-)\"\n    fi\n\n    if [ -z \"$serotype\" ] ; then serotype='NA' ; fi\n    if [ -z \"$contamination\" ] ; then contamination='NA' ; fi\n    if [ -z \"$antigenic_profile\" ] ; then antigenic_profile='NA' ; fi\n  '''",
        "nb_lignes_script": 39,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "clean_reads_seqsero2",
            "fastas_seqsero2"
        ],
        "nb_inputs": 2,
        "outputs": [
            "seqsero2_profile_results",
            "seqsero2_serotype_results",
            "seqsero2_contamination_results",
            "seqsero2_files"
        ],
        "nb_outputs": 4,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/seqsero2:latest'"
        ],
        "when": "params.seqsero2 && flag =~ 'found'",
        "stub": ""
    },
    "shigatyper": {
        "name_process": "shigatyper",
        "string_process": "\nprocess shigatyper {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.medcpus\n  container 'andrewlangvt/shigatyper:1'\n\n  when:\n  params.shigatyper && flag =~ 'found'\n\n  input:\n  tuple val(sample), file(fastq), val(flag) from clean_reads_shigatyper.join(shigella_flag, by:0)\n\n  output:\n  file(\"${task.process}/${sample}_shigatyper.tsv\")\n  tuple sample, env(predictions) into shigatyper_predictions\n  tuple sample, env(lacy_cada) into shigatyper_cadA\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    shigatyper --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    shigatyper !{params.shigatyper_options} \\\n      --name !{sample} \\\n      !{fastq} \\\n      2>> $err_file \\\n      > !{task.process}/!{sample}_shigatyper.tsv\n\n    predictions=$(grep -v \"prediction\" !{task.process}/!{sample}_shigatyper.tsv | cut -f 2 | tr '\\\\n' ',' | sed 's/,$//g' )\n    lacy_cada=\"$(grep -ie \"lac\" -ie \"cad\" $err_file | head -n 1)\"\n    if [ -z \"$predictions\" ] ; then predictions='none' ; fi\n    if [ -z \"$lacy_cada\" ] ; then lacy_cada='none' ; fi\n  '''\n}",
        "nb_lignes_process": 42,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    shigatyper --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    shigatyper !{params.shigatyper_options} \\\n      --name !{sample} \\\n      !{fastq} \\\n      2>> $err_file \\\n      > !{task.process}/!{sample}_shigatyper.tsv\n\n    predictions=$(grep -v \"prediction\" !{task.process}/!{sample}_shigatyper.tsv | cut -f 2 | tr '\\\\n' ',' | sed 's/,$//g' )\n    lacy_cada=\"$(grep -ie \"lac\" -ie \"cad\" $err_file | head -n 1)\"\n    if [ -z \"$predictions\" ] ; then predictions='none' ; fi\n    if [ -z \"$lacy_cada\" ] ; then lacy_cada='none' ; fi\n  '''",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "clean_reads_shigatyper"
        ],
        "nb_inputs": 1,
        "outputs": [
            "shigatyper_predictions",
            "shigatyper_cadA"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'andrewlangvt/shigatyper:1'"
        ],
        "when": "params.shigatyper && flag =~ 'found'",
        "stub": ""
    },
    "kleborate": {
        "name_process": "kleborate",
        "string_process": "\nprocess kleborate {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.medcpus\n  container 'staphb/kleborate:latest'\n\n  when:\n  params.kleborate && flag =~ 'found'\n\n  input:\n  tuple val(sample), file(contig), val(flag) from contigs_kleborate.concat(fastas_kleborate).join(klebsiella_flag, by:0)\n\n  output:\n  tuple sample, env(kleborate_score) into kleborate_score\n  tuple sample, env(kleborate_mlst) into kleborate_mlst\n  file(\"${task.process}/${sample}_results.txt\") into kleborate_files\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    kleborate --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    kleborate !{params.kleborate_options} \\\n      -o !{task.process}/!{sample}_results.txt \\\n      -a !{contig} \\\n      2>> $err_file >> $log_file\n\n    virulence_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\\\t' '\\\\n' | grep -n virulence_score | cut -f 1 -d \":\" )\n    mlst_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\\\t' '\\\\n' | grep -n ST | cut -f 1 -d \":\" )\n    if [ -n \"$virulence_column\" ] ; then kleborate_score=$(cut -f $virulence_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi\n    if [ -n \"$mlst_column\" ] ; then kleborate_mlst=$(cut -f $mlst_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi\n    if [ -z \"$kleborate_score\" ] ; then kleborate_score='NA' ; fi\n    if [ -z \"$kleborate_mlst\" ] ; then kleborate_mlst='NA' ; fi\n  '''\n}",
        "nb_lignes_process": 43,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    kleborate --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    kleborate !{params.kleborate_options} \\\n      -o !{task.process}/!{sample}_results.txt \\\n      -a !{contig} \\\n      2>> $err_file >> $log_file\n\n    virulence_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\\\t' '\\\\n' | grep -n virulence_score | cut -f 1 -d \":\" )\n    mlst_column=$(head -n 1 !{task.process}/!{sample}_results.txt | tr '\\\\t' '\\\\n' | grep -n ST | cut -f 1 -d \":\" )\n    if [ -n \"$virulence_column\" ] ; then kleborate_score=$(cut -f $virulence_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi\n    if [ -n \"$mlst_column\" ] ; then kleborate_mlst=$(cut -f $mlst_column !{task.process}/!{sample}_results.txt | tail -n 1 ) ; fi\n    if [ -z \"$kleborate_score\" ] ; then kleborate_score='NA' ; fi\n    if [ -z \"$kleborate_mlst\" ] ; then kleborate_mlst='NA' ; fi\n  '''",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "contigs_kleborate",
            "fastas_kleborate"
        ],
        "nb_inputs": 2,
        "outputs": [
            "kleborate_score",
            "kleborate_mlst",
            "kleborate_files"
        ],
        "nb_outputs": 3,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/kleborate:latest'"
        ],
        "when": "params.kleborate && flag =~ 'found'",
        "stub": ""
    },
    "serotypefinder": {
        "name_process": "serotypefinder",
        "string_process": "\nprocess serotypefinder {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.medcpus\n  container 'staphb/serotypefinder:latest'\n\n  when:\n  params.serotypefinder && flag =~ 'found'\n\n  input:\n  tuple val(sample), file(fasta), val(flag) from contigs_serotypefinder.concat(fastas_serotypefinder).join(ecoli_flag, by:0)\n\n  output:\n  file(\"${task.process}/${sample}/*\")\n  tuple sample, env(o_type) into serotypefinder_results_o\n  tuple sample, env(h_type) into serotypefinder_results_h\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process}/!{sample} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    serotypefinder.py !{params.serotypefinder_options} \\\n      -i !{fasta} \\\n      -o !{task.process}/!{sample} \\\n      -x \\\n      2>> $err_file >> $log_file\n\n    h_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^H | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    o_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^O | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    if [ -z \"$h_type\" ] ; then h_type=\"none\" ; fi\n    if [ -z \"$o_type\" ] ; then o_type=\"none\" ; fi\n  '''\n}",
        "nb_lignes_process": 41,
        "string_script": "  '''\n    mkdir -p !{task.process}/!{sample} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    serotypefinder.py !{params.serotypefinder_options} \\\n      -i !{fasta} \\\n      -o !{task.process}/!{sample} \\\n      -x \\\n      2>> $err_file >> $log_file\n\n    h_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^H | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    o_type=$(cut -f 3 !{task.process}/!{sample}/results_tab.tsv | grep ^O | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    if [ -z \"$h_type\" ] ; then h_type=\"none\" ; fi\n    if [ -z \"$o_type\" ] ; then o_type=\"none\" ; fi\n  '''",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "contigs_serotypefinder",
            "fastas_serotypefinder"
        ],
        "nb_inputs": 2,
        "outputs": [
            "serotypefinder_results_o",
            "serotypefinder_results_h"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/serotypefinder:latest'"
        ],
        "when": "params.serotypefinder && flag =~ 'found'",
        "stub": ""
    },
    "amrfinderplus": {
        "name_process": "amrfinderplus",
        "string_process": "\nprocess amrfinderplus {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus params.medcpus\n  container 'staphb/ncbi-amrfinderplus:latest'\n\n  when:\n  params.amrfinderplus\n\n  input:\n  tuple val(sample), file(contigs), val(genus), val(species) from contigs_amrfinder.concat(fastas_amrfinder).join(mash_genus_amrfinder, by: 0).join(mash_species_amrfinder, by: 0)\n\n  output:\n  file(\"ncbi-AMRFinderplus/${sample}_amrfinder_plus.txt\") into amrfinder_files\n  tuple sample, env(amr_genes) into amr_genes\n  tuple sample, env(virulence_genes) into virulence_genes\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p ncbi-AMRFinderplus logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    organism_options=(Acinetobacter_baumannii\n    Campylobacter\n    Enterococcus_faecalis\n    Enterococcus_faecium\n    Escherichia:Shigella\n    Klebsiella\n    Salmonella\n    Staphylococcus_aureus\n    Staphylococcus_pseudintermedius\n    Streptococcus_agalactiae\n    Streptococcus_pneumoniae\n    Streptococcus_pyogenes\n    Vibrio_cholerae)\n\n    organism=$(history -p ${organism_options[@]} | grep -i !{genus} | grep -i !{species} | head -n 1 )\n    if [ -z \"$organism\" ] ; then organism=$(history -p ${organism_options[@]} | grep -i !{genus} | head -n 1 | cut -f 1 -d \":\" ) ; fi\n    if [ -n \"$organism\" ]\n    then\n      organism_check=\"--organism $organism\"\n      echo \"Mash result of !{genus} !{species} matched with $organism\" >> $log_file\n    else\n      organism_check=''\n      echo \"Mash result of !{genus} !{species} did not match any of the organisms\" >> $log_file\n    fi\n\n    amrfinder !{params.amrfinderplus_options} \\\n      --nucleotide !{contigs} \\\n      --threads !{task.cpus} \\\n      --name !{sample} \\\n      --output ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt \\\n      $organism_check \\\n      --plus \\\n      2>> $err_file >> $log_file\n\n    amr_genes=$(cut -f 7 ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | tail +2 | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    virulence_genes=$(grep \"VIRULENCE\" ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | cut -f 7 | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    if [ -z \"$amr_genes\" ] ; then amr_genes=\"none\" ; fi\n    if [ -z \"$virulence_genes\" ] ; then virulence_genes=\"none\" ; fi\n  '''\n}",
        "nb_lignes_process": 69,
        "string_script": "  '''\n    mkdir -p ncbi-AMRFinderplus logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    organism_options=(Acinetobacter_baumannii\n    Campylobacter\n    Enterococcus_faecalis\n    Enterococcus_faecium\n    Escherichia:Shigella\n    Klebsiella\n    Salmonella\n    Staphylococcus_aureus\n    Staphylococcus_pseudintermedius\n    Streptococcus_agalactiae\n    Streptococcus_pneumoniae\n    Streptococcus_pyogenes\n    Vibrio_cholerae)\n\n    organism=$(history -p ${organism_options[@]} | grep -i !{genus} | grep -i !{species} | head -n 1 )\n    if [ -z \"$organism\" ] ; then organism=$(history -p ${organism_options[@]} | grep -i !{genus} | head -n 1 | cut -f 1 -d \":\" ) ; fi\n    if [ -n \"$organism\" ]\n    then\n      organism_check=\"--organism $organism\"\n      echo \"Mash result of !{genus} !{species} matched with $organism\" >> $log_file\n    else\n      organism_check=''\n      echo \"Mash result of !{genus} !{species} did not match any of the organisms\" >> $log_file\n    fi\n\n    amrfinder !{params.amrfinderplus_options} \\\n      --nucleotide !{contigs} \\\n      --threads !{task.cpus} \\\n      --name !{sample} \\\n      --output ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt \\\n      $organism_check \\\n      --plus \\\n      2>> $err_file >> $log_file\n\n    amr_genes=$(cut -f 7 ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | tail +2 | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    virulence_genes=$(grep \"VIRULENCE\" ncbi-AMRFinderplus/!{sample}_amrfinder_plus.txt | cut -f 7 | sort | uniq | tr '\\\\n' ',' | sed 's/,$//g' )\n    if [ -z \"$amr_genes\" ] ; then amr_genes=\"none\" ; fi\n    if [ -z \"$virulence_genes\" ] ; then virulence_genes=\"none\" ; fi\n  '''",
        "nb_lignes_script": 49,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "contigs_amrfinder",
            "fastas_amrfinder"
        ],
        "nb_inputs": 2,
        "outputs": [
            "amrfinder_files",
            "amr_genes",
            "virulence_genes"
        ],
        "nb_outputs": 3,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/ncbi-amrfinderplus:latest'"
        ],
        "when": "params.amrfinderplus",
        "stub": ""
    },
    "kraken2": {
        "name_process": "kraken2",
        "string_process": " process kraken2 {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"${sample}\"\n    cpus params.maxcpus\n    container 'staphb/kraken2:latest'\n\n    input:\n    tuple val(sample), file(clean), path(kraken2_db) from clean_reads_kraken2.concat(fastas_kraken2).combine(local_kraken2)\n\n    output:\n    file(\"${task.process}/${sample}_kraken2_report.txt\") into kraken2_files\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n    tuple sample, env(top_hit) into kraken2_top_hit\n    tuple sample, env(top_perc) into kraken2_top_perc\n    tuple sample, env(top_reads) into kraken2_top_reads\n\n    shell:\n    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      kraken2 --version >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      fastq_check=$(echo \"!{clean}\" | grep \"fastq\" | head -n 1 )\n      if [ -n \"$fastq_check\" ] ; then kraken2_parameter=\"--paired --classified-out cseqs#.fq\" ; else kraken2_parameter=\"\" ; fi\n\n      kraken2 !{params.kraken2_options} \\\n        $kraken2_parameter \\\n        --threads !{task.cpus} \\\n        --db !{kraken2_db} \\\n        !{clean} \\\n        --report !{task.process}/!{sample}_kraken2_report.txt \\\n        2>> $err_file >> $log_file\n\n      top_hit=$(cat !{task.process}/!{sample}_kraken2_report.txt   | grep -w S | sort | tail -n 1 | awk '{print $6 \" \" $7}')\n      top_perc=$(cat !{task.process}/!{sample}_kraken2_report.txt  | grep -w S | sort | tail -n 1 | awk '{print $1}')\n      top_reads=$(cat !{task.process}/!{sample}_kraken2_report.txt | grep -w S | sort | tail -n 1 | awk '{print $3}')\n      if [ -z \"$top_hit\" ] ; then top_hit=\"NA\" ; fi\n      if [ -z \"$top_perc\" ] ; then top_perc=\"0\" ; fi\n      if [ -z \"$top_reads\" ] ; then top_reads=\"0\" ; fi\n    '''\n  }",
        "nb_lignes_process": 45,
        "string_script": "    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      kraken2 --version >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      fastq_check=$(echo \"!{clean}\" | grep \"fastq\" | head -n 1 )\n      if [ -n \"$fastq_check\" ] ; then kraken2_parameter=\"--paired --classified-out cseqs#.fq\" ; else kraken2_parameter=\"\" ; fi\n\n      kraken2 !{params.kraken2_options} \\\n        $kraken2_parameter \\\n        --threads !{task.cpus} \\\n        --db !{kraken2_db} \\\n        !{clean} \\\n        --report !{task.process}/!{sample}_kraken2_report.txt \\\n        2>> $err_file >> $log_file\n\n      top_hit=$(cat !{task.process}/!{sample}_kraken2_report.txt   | grep -w S | sort | tail -n 1 | awk '{print $6 \" \" $7}')\n      top_perc=$(cat !{task.process}/!{sample}_kraken2_report.txt  | grep -w S | sort | tail -n 1 | awk '{print $1}')\n      top_reads=$(cat !{task.process}/!{sample}_kraken2_report.txt | grep -w S | sort | tail -n 1 | awk '{print $3}')\n      if [ -z \"$top_hit\" ] ; then top_hit=\"NA\" ; fi\n      if [ -z \"$top_perc\" ] ; then top_perc=\"0\" ; fi\n      if [ -z \"$top_reads\" ] ; then top_reads=\"0\" ; fi\n    '''",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "kraken2"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/kraken2"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            }
        ],
        "inputs": [
            "clean_reads_kraken2",
            "local_kraken2",
            "fastas_kraken2"
        ],
        "nb_inputs": 3,
        "outputs": [
            "kraken2_files",
            "kraken2_top_hit",
            "kraken2_top_perc",
            "kraken2_top_reads"
        ],
        "nb_outputs": 4,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.maxcpus",
            "container 'staphb/kraken2:latest'"
        ],
        "when": "",
        "stub": ""
    },
    "blastn": {
        "name_process": "blastn",
        "string_process": " process blastn {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"${sample}\"\n    cpus params.medcpus\n    container 'ncbi/blast:latest'\n\n    input:\n    tuple val(sample), file(contig), path(blastdb) from contigs_blastn.combine(local_blastdb)\n\n    output:\n    tuple sample, file(\"blastn/${sample}.tsv\") into blastn_files\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      blastn -version >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blastn -query !{contig} \\\n        -out blastn/!{sample}.tsv \\\n        -num_threads !{task.cpus} \\\n        -db !{blastdb}/!{params.local_db_type} \\\n        -outfmt '6 qseqid staxids bitscore std' \\\n        -max_target_seqs 10 \\\n        -max_hsps 1 \\\n        -evalue 1e-25 \\\n        2>> $err_file >> $log_file\n    '''\n  }",
        "nb_lignes_process": 35,
        "string_script": "    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      blastn -version >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blastn -query !{contig} \\\n        -out blastn/!{sample}.tsv \\\n        -num_threads !{task.cpus} \\\n        -db !{blastdb}/!{params.local_db_type} \\\n        -outfmt '6 qseqid staxids bitscore std' \\\n        -max_target_seqs 10 \\\n        -max_hsps 1 \\\n        -evalue 1e-25 \\\n        2>> $err_file >> $log_file\n    '''",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "G-BLASTN"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/g-blastn"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "G-BLASTN",
                "uri": "https://bio.tools/g-blastn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0346",
                                    "term": "Sequence similarity search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2976",
                                "term": "Protein sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0857",
                                "term": "Sequence search results"
                            }
                        ]
                    }
                ],
                "description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "homepage": "http://www.comp.hkbu.edu.hk/~chxw/software/G-BLASTN.html"
            }
        ],
        "inputs": [
            "contigs_blastn",
            "local_blastdb"
        ],
        "nb_inputs": 2,
        "outputs": [
            "blastn_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'ncbi/blast:latest'"
        ],
        "when": "",
        "stub": ""
    },
    "bwa": {
        "name_process": "bwa",
        "string_process": " process bwa {\n    publishDir \"${params.outdir}\", mode: 'copy', pattern: \"logs/${task.process}/*.{log,err}\"\n    tag \"${sample}\"\n    cpus params.medcpus\n    container 'staphb/bwa:latest'\n\n    input:\n    tuple val(sample), file(reads), file(contig) from clean_reads_bwa.join(contigs_bwa, by:0)\n\n    output:\n    tuple sample, file(\"${task.process}/${sample}.sam\") into sam_files\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"bwa $(bwa 2>&1 | grep Version )\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      bwa index !{contig} 2>> $err_file >> $log_file\n\n      bwa mem !{params.bwa_options} \\\n        -t !{task.cpus} \\\n        !{contig} \\\n        !{reads} \\\n        2>> $err_file \\\n        > !{task.process}/!{sample}.sam\n    '''\n  }",
        "nb_lignes_process": 34,
        "string_script": "    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"bwa $(bwa 2>&1 | grep Version )\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      bwa index !{contig} 2>> $err_file >> $log_file\n\n      bwa mem !{params.bwa_options} \\\n        -t !{task.cpus} \\\n        !{contig} \\\n        !{reads} \\\n        2>> $err_file \\\n        > !{task.process}/!{sample}.sam\n    '''",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "BWA"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/bwa"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            }
        ],
        "inputs": [
            "clean_reads_bwa"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sam_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy', pattern: \"logs/${task.process}/*.{log,err}\"",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/bwa:latest'"
        ],
        "when": "",
        "stub": ""
    },
    "sort": {
        "name_process": "sort",
        "string_process": " process sort {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"${sample}\"\n    cpus params.medcpus\n    container 'staphb/samtools:latest'\n\n    input:\n    tuple val(sample), file(sam) from sam_files\n\n    output:\n    tuple sample, file(\"aligned/${sample}.sorted.bam*\") into bam_files\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p aligned logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      samtools --version >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      samtools sort !{params.samtools_sort_options} \\\n        --threads !{task.cpus} \\\n        !{sam} \\\n        -o aligned/!{sample}.sorted.bam \\\n        --write-index \\\n        2>> $err_file >> $log_file\n    '''\n  }",
        "nb_lignes_process": 32,
        "string_script": "    '''\n      mkdir -p aligned logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      samtools --version >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      samtools sort !{params.samtools_sort_options} \\\n        --threads !{task.cpus} \\\n        !{sam} \\\n        -o aligned/!{sample}.sorted.bam \\\n        --write-index \\\n        2>> $err_file >> $log_file\n    '''",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sam_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "bam_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus params.medcpus",
            "container 'staphb/samtools:latest'"
        ],
        "when": "",
        "stub": ""
    },
    "create": {
        "name_process": "create",
        "string_process": " process create {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"${sample}\"\n    cpus 1\n    container 'chrishah/blobtools:v1.1.1'\n\n    input:\n    tuple val(sample), file(contig), file(blastn), file(bam) from contigs_create.join(blastn_files, by:0).join(bam_files, by:0)\n\n    output:\n    tuple sample, file(\"blobtools/${sample}.blobDB.json\") into create_files_view, create_files_plot\n    file(\"blobtools/${sample}.${sample}.sorted.bam.cov\")\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p blobtools logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"blobtools version $(blobtools -v)\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blobtools create !{params.blobtools_create_options} \\\n        -o blobtools/!{sample} \\\n        -i !{contig} \\\n        -b !{sample}.sorted.bam \\\n        -t !{blastn} \\\n        2>> $err_file >> $log_file\n    '''\n  }",
        "nb_lignes_process": 33,
        "string_script": "    '''\n      mkdir -p blobtools logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"blobtools version $(blobtools -v)\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blobtools create !{params.blobtools_create_options} \\\n        -o blobtools/!{sample} \\\n        -i !{contig} \\\n        -b !{sample}.sorted.bam \\\n        -t !{blastn} \\\n        2>> $err_file >> $log_file\n    '''",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "BlobTools"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/blobtools"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "BlobTools",
                "uri": "https://bio.tools/blobtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly validation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly QC"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Visualisation, quality control and taxonomic partitioning of genome datasets.",
                "homepage": "https://github.com/DRL/blobtools"
            }
        ],
        "inputs": [
            "contigs_create"
        ],
        "nb_inputs": 1,
        "outputs": [
            "create_files_view",
            "create_files_plot"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'chrishah/blobtools:v1.1.1'"
        ],
        "when": "",
        "stub": ""
    },
    "view": {
        "name_process": "view",
        "string_process": " process view {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"${sample}\"\n    cpus 1\n    container 'chrishah/blobtools:v1.1.1'\n\n    input:\n    tuple val(sample), file(json) from create_files_view\n\n    output:\n    tuple sample, file(\"blobtools/${sample}.blobDB.table.txt\") into view_files\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p blobtools logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"blobtools version $(blobtools -v)\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blobtools view !{params.blobtools_view_options} \\\n        -i !{json} \\\n        -o blobtools/ \\\n        2>> $err_file >> $log_file\n    '''\n  }",
        "nb_lignes_process": 30,
        "string_script": "    '''\n      mkdir -p blobtools logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"blobtools version $(blobtools -v)\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blobtools view !{params.blobtools_view_options} \\\n        -i !{json} \\\n        -o blobtools/ \\\n        2>> $err_file >> $log_file\n    '''",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "BlobTools"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/blobtools"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "BlobTools",
                "uri": "https://bio.tools/blobtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly validation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly QC"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Visualisation, quality control and taxonomic partitioning of genome datasets.",
                "homepage": "https://github.com/DRL/blobtools"
            }
        ],
        "inputs": [
            "create_files_view"
        ],
        "nb_inputs": 1,
        "outputs": [
            "view_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'chrishah/blobtools:v1.1.1'"
        ],
        "when": "",
        "stub": ""
    },
    "blobtools": {
        "name_process": "blobtools",
        "string_process": " process blobtools {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"${sample}\"\n    cpus 1\n    container 'chrishah/blobtools:v1.1.1'\n\n    input:\n    tuple val(sample), file(json) from create_files_plot\n\n    output:\n    file(\"blobtools/${sample}.*\")\n    tuple sample, env(blobtools_species) into blobtools_species_results\n    tuple sample, env(blobtools_perc) into blobtools_perc_results\n    file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p blobtools logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"blobtools version $(blobtools -v)\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blobtools plot !{params.blobtools_plot_options} \\\n        -i !{json} \\\n        -o blobtools/ \\\n        2>> $err_file 2>> $log_file\n\n      perc='0.0'\n      blobtools_species='missing'\n      while read line\n      do\n        new_perc=$(echo $line | cut -f 13 -d \" \" | sed 's/%//g')\n        min=$(echo $perc $new_perc | awk '{if ($1 > $2) print $1; else print $2}')\n        if [ \"$min\" != \"$perc\" ]\n        then\n          perc=$new_perc\n          blobtools_species=$(echo $line | cut -f 1 -d \" \" )\n          blobtools_perc=$(echo $line | cut -f 13 -d \" \" )\n        fi\n      done < <(grep -vw all blobtools/!{sample}*.stats.txt | grep -v \"# name\" | tr ' ' '_' | grep '%')\n    '''\n  }",
        "nb_lignes_process": 46,
        "string_script": "    '''\n      mkdir -p blobtools logs/!{task.process}\n      log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      echo \"container : !{task.container}\" >> $log_file\n      echo \"blobtools version $(blobtools -v)\" >> $log_file\n      echo \"Nextflow command : \" >> $log_file\n      cat .command.sh >> $log_file\n\n      blobtools plot !{params.blobtools_plot_options} \\\n        -i !{json} \\\n        -o blobtools/ \\\n        2>> $err_file 2>> $log_file\n\n      perc='0.0'\n      blobtools_species='missing'\n      while read line\n      do\n        new_perc=$(echo $line | cut -f 13 -d \" \" | sed 's/%//g')\n        min=$(echo $perc $new_perc | awk '{if ($1 > $2) print $1; else print $2}')\n        if [ \"$min\" != \"$perc\" ]\n        then\n          perc=$new_perc\n          blobtools_species=$(echo $line | cut -f 1 -d \" \" )\n          blobtools_perc=$(echo $line | cut -f 13 -d \" \" )\n        fi\n      done < <(grep -vw all blobtools/!{sample}*.stats.txt | grep -v \"# name\" | tr ' ' '_' | grep '%')\n    '''",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "BlobTools"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/blobtools"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "BlobTools",
                "uri": "https://bio.tools/blobtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly validation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly QC"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Visualisation, quality control and taxonomic partitioning of genome datasets.",
                "homepage": "https://github.com/DRL/blobtools"
            }
        ],
        "inputs": [
            "create_files_plot"
        ],
        "nb_inputs": 1,
        "outputs": [
            "blobtools_species_results",
            "blobtools_perc_results"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'chrishah/blobtools:v1.1.1'"
        ],
        "when": "",
        "stub": ""
    },
    "mlst": {
        "name_process": "mlst",
        "string_process": "\nprocess mlst {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"${sample}\"\n  cpus 1\n  container 'staphb/mlst:latest'\n\n  when:\n  params.mlst\n\n  input:\n  tuple val(sample), file(contig) from contigs_mlst.concat(fastas_mlst)\n\n  output:\n  file(\"${task.process}/${sample}_mlst.txt\") into mlst_files\n  tuple sample, env(mlst) into mlst_results\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    mlst --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    mlst !{contig} 2>> $err_file > mlst/!{sample}_mlst.txt\n\n    mlst=$(awk '{ print $2 \":\" $3 }' mlst/!{sample}_mlst.txt)\n  '''\n}",
        "nb_lignes_process": 34,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    mlst --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    mlst !{contig} 2>> $err_file > mlst/!{sample}_mlst.txt\n\n    mlst=$(awk '{ print $2 \":\" $3 }' mlst/!{sample}_mlst.txt)\n  '''",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "MLST"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/mlst"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "MLST",
                "uri": "https://bio.tools/mlst",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2830",
                            "term": "Immunoproteins and antigens"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "Multi Locus Sequence Typing from an assembled genome or from a set of reads.",
                "homepage": "http://cge.cbs.dtu.dk/services/MLST/"
            }
        ],
        "inputs": [
            "contigs_mlst",
            "fastas_mlst"
        ],
        "nb_inputs": 2,
        "outputs": [
            "mlst_files",
            "mlst_results"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'staphb/mlst:latest'"
        ],
        "when": "params.mlst",
        "stub": ""
    },
    "summary": {
        "name_process": "summary",
        "string_process": "\nprocess summary {\n  publishDir \"${params.outdir}\", mode: 'copy', overwrite: true\n  tag \"${sample}\"\n  cpus 1\n  container 'staphb/parallel-perl:latest'\n\n  when:\n  params.summary\n\n  input:\n  set val(sample), file(file),\n    val(seqyclean_perc_kept_results),\n    val(seqyclean_pairskept_results),\n    val(fastqc_1_results),\n    val(fastqc_2_results),\n    val(mash_genome_size_results),\n    val(mash_coverage_results),\n    val(mash_genus_results),\n    val(mash_species_results),\n    val(mash_full_results),\n    val(mash_pvalue_results),\n    val(mash_distance_results),\n    val(quast_gc_results),\n    val(quast_contigs_results),\n    val(quast_N50_contigs_results),\n    val(quast_length_results),\n    val(cg_avrl_results),\n    val(cg_quality_results),\n    val(cg_cov_results),\n    val(ref_genome_length),\n    val(seqsero2_profile_results),\n    val(seqsero2_serotype_results),\n    val(seqsero2_contamination_results),\n    val(serotypefinder_results_o),\n    val(serotypefinder_results_h),\n    val(shigatyper_predictions),\n    val(shigatyper_cadA),\n    val(kleborate_score),\n    val(kleborate_mlst),\n    val(blobtools_species_results),\n    val(blobtools_perc_results),\n    val(kraken2_top_hit),\n    val(kraken2_top_perc),\n    val(kraken2_top_reads),\n    val(amr_genes),\n    val(virulence_genes),\n    val(mlst_results) from results\n\n  output:\n  file(\"summary/${sample}.summary.txt\") into summary_files_txt\n  file(\"summary/${sample}.summary.tsv\") into summary_files_tsv\n  file(\"logs/${task.process}/${sample}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    sample_id_split=($(echo !{sample} | sed 's/-/ /g' | sed 's/_/ /g' ))\n    if [ \"${#sample_id_split[@]}\" -ge \"5\" ]\n    then\n      sample_id=\"${sample_id_split[0]}-${sample_id_split[1]}\"\n    elif [ \"${#sample_id_split[@]}\" -eq \"4\" ]\n    then\n      sample_id=${sample_id_split[0]}\n    else\n      sample_id=!{sample}\n    fi\n\n    header=\"sample_id;sample\"\n    result=\"$sample_id;!{sample}\"\n\n    header=$header\";seqyclean_pairs_kept;seqyclean_percent_kept\"\n    result=$result\";!{seqyclean_pairskept_results};!{seqyclean_perc_kept_results}\"\n\n    if [ \"!{params.fastqc}\" != \"false\" ]\n    then\n      header=$header\";fastqc_1_reads;fastqc_2_reads\"\n      result=$result\";!{fastqc_1_results};!{fastqc_2_results}\"\n    fi\n\n    if [ \"!{params.mash}\" != \"false\" ]\n    then\n      header=$header\";mash_genome_size;mash_coverage;mash_genus;mash_species;mash_full;mash_pvalue;mash_distance\"\n      result=$result\";!{mash_genome_size_results};!{mash_coverage_results};!{mash_genus_results};!{mash_species_results};!{mash_full_results};!{mash_pvalue_results};!{mash_distance_results}\"\n    fi\n\n    if [ \"!{params.quast}\" != \"false\" ]\n    then\n      header=$header\";quast_gc_%;quast_contigs;quast_N50;quast_length\"\n      result=$result\";!{quast_gc_results};!{quast_contigs_results};!{quast_N50_contigs_results};!{quast_length_results}\"\n    fi\n\n    if [ \"!{params.cg_pipeline}\" != \"false\" ]\n    then\n      header=$header\";cg_average_read_length;cg_average_quality;cg_coverage;ref_genome_length\"\n      result=$result\";!{cg_avrl_results};!{cg_quality_results};!{cg_cov_results};!{ref_genome_length}\"\n    fi\n\n    if [ \"!{params.seqsero2}\" != \"false\" ]\n    then\n      header=$header\";seqsero2_profile;seqsero2_serotype;seqsero2_contamination\"\n      result=$result\";!{seqsero2_profile_results};!{seqsero2_serotype_results};!{seqsero2_contamination_results}\"\n    fi\n\n    if [ \"!{params.serotypefinder}\" != \"false\" ]\n    then\n      header=$header\";serotypefinder_o_group;serotypefinder_h_group\"\n      result=$result\";!{serotypefinder_results_o};!{serotypefinder_results_h}\"\n    fi\n\n    if [ \"!{params.kleborate}\" != \"false\" ]\n    then\n      header=$header\";kleborate_score;kleborate_mlst\"\n      result=$result\";!{kleborate_score};!{kleborate_mlst}\"\n    fi\n\n    if [ \"!{params.amrfinderplus}\" != \"false\" ]\n    then\n      header=$header\";amr_genes;virulence_genes\"\n      result=$result\";!{amr_genes};!{virulence_genes}\"\n    fi\n\n    if [ \"!{params.blobtools}\" != \"false\" ]\n    then\n      header=$header\";blobtools_top_species;blobtools_percentage\"\n      result=$result\";!{blobtools_species_results};!{blobtools_perc_results}\"\n    fi\n\n    if [ \"!{params.kraken2}\" != \"false\" ]\n    then\n      header=$header\";kraken2_top_species;kraken2_num_reads;kraken2_percentage\"\n      result=$result\";!{kraken2_top_hit};!{kraken2_top_reads};!{kraken2_top_perc}\"\n    fi\n\n    if [ \"!{params.mlst}\" != \"false\" ]\n    then\n      header=$header\";mlst\"\n      result=$result\";!{mlst_results}\"\n    fi\n\n    if [ \"!{params.shigatyper}\" != \"false\" ]\n    then\n      header=$header\";shigatyper_predictions;shigatyper_cadA\"\n      result=$result\";!{shigatyper_predictions};!{shigatyper_cadA}\"\n    fi\n\n    echo $header > summary/!{sample}.summary.txt\n    echo $result >> summary/!{sample}.summary.txt\n\n    cat summary/!{sample}.summary.txt | tr ';' '\\t' > summary/!{sample}.summary.tsv\n  '''\n}",
        "nb_lignes_process": 158,
        "string_script": "  '''\n    mkdir -p !{task.process} logs/!{task.process}\n    log_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{sample}.!{workflow.sessionId}.err\n\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    sample_id_split=($(echo !{sample} | sed 's/-/ /g' | sed 's/_/ /g' ))\n    if [ \"${#sample_id_split[@]}\" -ge \"5\" ]\n    then\n      sample_id=\"${sample_id_split[0]}-${sample_id_split[1]}\"\n    elif [ \"${#sample_id_split[@]}\" -eq \"4\" ]\n    then\n      sample_id=${sample_id_split[0]}\n    else\n      sample_id=!{sample}\n    fi\n\n    header=\"sample_id;sample\"\n    result=\"$sample_id;!{sample}\"\n\n    header=$header\";seqyclean_pairs_kept;seqyclean_percent_kept\"\n    result=$result\";!{seqyclean_pairskept_results};!{seqyclean_perc_kept_results}\"\n\n    if [ \"!{params.fastqc}\" != \"false\" ]\n    then\n      header=$header\";fastqc_1_reads;fastqc_2_reads\"\n      result=$result\";!{fastqc_1_results};!{fastqc_2_results}\"\n    fi\n\n    if [ \"!{params.mash}\" != \"false\" ]\n    then\n      header=$header\";mash_genome_size;mash_coverage;mash_genus;mash_species;mash_full;mash_pvalue;mash_distance\"\n      result=$result\";!{mash_genome_size_results};!{mash_coverage_results};!{mash_genus_results};!{mash_species_results};!{mash_full_results};!{mash_pvalue_results};!{mash_distance_results}\"\n    fi\n\n    if [ \"!{params.quast}\" != \"false\" ]\n    then\n      header=$header\";quast_gc_%;quast_contigs;quast_N50;quast_length\"\n      result=$result\";!{quast_gc_results};!{quast_contigs_results};!{quast_N50_contigs_results};!{quast_length_results}\"\n    fi\n\n    if [ \"!{params.cg_pipeline}\" != \"false\" ]\n    then\n      header=$header\";cg_average_read_length;cg_average_quality;cg_coverage;ref_genome_length\"\n      result=$result\";!{cg_avrl_results};!{cg_quality_results};!{cg_cov_results};!{ref_genome_length}\"\n    fi\n\n    if [ \"!{params.seqsero2}\" != \"false\" ]\n    then\n      header=$header\";seqsero2_profile;seqsero2_serotype;seqsero2_contamination\"\n      result=$result\";!{seqsero2_profile_results};!{seqsero2_serotype_results};!{seqsero2_contamination_results}\"\n    fi\n\n    if [ \"!{params.serotypefinder}\" != \"false\" ]\n    then\n      header=$header\";serotypefinder_o_group;serotypefinder_h_group\"\n      result=$result\";!{serotypefinder_results_o};!{serotypefinder_results_h}\"\n    fi\n\n    if [ \"!{params.kleborate}\" != \"false\" ]\n    then\n      header=$header\";kleborate_score;kleborate_mlst\"\n      result=$result\";!{kleborate_score};!{kleborate_mlst}\"\n    fi\n\n    if [ \"!{params.amrfinderplus}\" != \"false\" ]\n    then\n      header=$header\";amr_genes;virulence_genes\"\n      result=$result\";!{amr_genes};!{virulence_genes}\"\n    fi\n\n    if [ \"!{params.blobtools}\" != \"false\" ]\n    then\n      header=$header\";blobtools_top_species;blobtools_percentage\"\n      result=$result\";!{blobtools_species_results};!{blobtools_perc_results}\"\n    fi\n\n    if [ \"!{params.kraken2}\" != \"false\" ]\n    then\n      header=$header\";kraken2_top_species;kraken2_num_reads;kraken2_percentage\"\n      result=$result\";!{kraken2_top_hit};!{kraken2_top_reads};!{kraken2_top_perc}\"\n    fi\n\n    if [ \"!{params.mlst}\" != \"false\" ]\n    then\n      header=$header\";mlst\"\n      result=$result\";!{mlst_results}\"\n    fi\n\n    if [ \"!{params.shigatyper}\" != \"false\" ]\n    then\n      header=$header\";shigatyper_predictions;shigatyper_cadA\"\n      result=$result\";!{shigatyper_predictions};!{shigatyper_cadA}\"\n    fi\n\n    echo $header > summary/!{sample}.summary.txt\n    echo $result >> summary/!{sample}.summary.txt\n\n    cat summary/!{sample}.summary.txt | tr ';' '\\t' > summary/!{sample}.summary.tsv\n  '''",
        "nb_lignes_script": 103,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "SAMPLE",
            "MLST"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/sample",
            "https://bio.tools/mlst"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "SAMPLE",
                "uri": "https://bio.tools/sample",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Linkage mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Functional mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic cartography"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map generation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The tool is designed to identify regions that are linked to a recessive disease by analysing genotype data from the parents and unaffected sibs of affected individuals. Since this analysis does not use data from affected patients, it is suited to the identification of lethal recessive genes, when the patients may have died before DNA samples could be obtained.",
                "homepage": "http://dna.leeds.ac.uk/sample/"
            },
            {
                "name": "MLST",
                "uri": "https://bio.tools/mlst",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2830",
                            "term": "Immunoproteins and antigens"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "Multi Locus Sequence Typing from an assembled genome or from a set of reads.",
                "homepage": "http://cge.cbs.dtu.dk/services/MLST/"
            }
        ],
        "inputs": [
            "results"
        ],
        "nb_inputs": 1,
        "outputs": [
            "summary_files_txt",
            "summary_files_tsv"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy', overwrite: true",
            "tag \"${sample}\"",
            "cpus 1",
            "container 'staphb/parallel-perl:latest'"
        ],
        "when": "params.summary",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc {\n  publishDir \"${params.outdir}\", mode: 'copy'\n  tag \"multiqc\"\n  cpus 1\n  container 'ewels/multiqc:latest'\n\n  when:\n  params.multiqc\n\n  input:\n  file(fastqc) from fastqc_files.collect().ifEmpty([])\n  file(quast) from quast_files.collect().ifEmpty([])\n  file(seqyclean) from seqyclean_files.collect().ifEmpty([])\n  file(kraken2) from kraken2_files.collect().ifEmpty([])\n  file(prokka) from prokka_files.collect().ifEmpty([])\n\n  output:\n  file(\"${task.process}/multiqc_report.html\") optional true\n  file(\"${task.process}/multiqc_data/*\") optional true\n  file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")\n\n  shell:\n  '''\n    mkdir -p !{task.process} quast fastqc kraken2 prokka seqyclean logs/!{task.process}\n    log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    multiqc --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    for quast_file in !{quast}\n    do\n      if [ -f \"$quast_file\" ]\n      then\n        sample=$(echo $quast_file | sed 's/_quast_report.tsv//g' | head -n 1 )\n        mkdir -p quast/$sample\n        mv $quast_file quast/$sample/report.tsv\n      fi\n    done\n\n    multiqc !{params.multiqc_options} \\\n      --outdir !{task.process} \\\n      --cl_config \"prokka_fn_snames: True\"  \\\n      . \\\n      2>> $err_file >> $log_file\n  '''\n}",
        "nb_lignes_process": 50,
        "string_script": "  '''\n    mkdir -p !{task.process} quast fastqc kraken2 prokka seqyclean logs/!{task.process}\n    log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n    err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n    # time stamp + capturing tool versions\n    date | tee -a $log_file $err_file > /dev/null\n    echo \"container : !{task.container}\" >> $log_file\n    multiqc --version >> $log_file\n    echo \"Nextflow command : \" >> $log_file\n    cat .command.sh >> $log_file\n\n    for quast_file in !{quast}\n    do\n      if [ -f \"$quast_file\" ]\n      then\n        sample=$(echo $quast_file | sed 's/_quast_report.tsv//g' | head -n 1 )\n        mkdir -p quast/$sample\n        mv $quast_file quast/$sample/report.tsv\n      fi\n    done\n\n    multiqc !{params.multiqc_options} \\\n      --outdir !{task.process} \\\n      --cl_config \"prokka_fn_snames: True\"  \\\n      . \\\n      2>> $err_file >> $log_file\n  '''",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastqc_files",
            "quast_files",
            "seqyclean_files",
            "kraken2_files",
            "prokka_files"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"multiqc\"",
            "cpus 1",
            "container 'ewels/multiqc:latest'"
        ],
        "when": "params.multiqc",
        "stub": ""
    },
    "roary": {
        "name_process": "roary",
        "string_process": " process roary {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"Core Genome Alignment\"\n    cpus params.maxcpus\n    container 'staphb/roary:latest'\n\n    input:\n    file(contigs) from gffs.concat(local_gffs).collect()\n\n    output:\n    file(\"roary/*\")\n    file(\"roary/fixed_input_files/*\")\n    file(\"roary/core_gene_alignment.aln\") into roary_core_genome_iqtree, roary_core_genome_snp_dists\n    file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p logs/!{task.process}\n      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      roary -a >> $log_file\n\n      echo \"There are $(ls *gff | wc -l) files for alignment\" >> $log_file\n\n      roary !{params.roary_options} \\\n        -p !{task.cpus} \\\n        -f roary \\\n        -e -n \\\n        *.gff \\\n        2>> $err_file >> $log_file\n    '''\n  }",
        "nb_lignes_process": 33,
        "string_script": "    '''\n      mkdir -p logs/!{task.process}\n      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      roary -a >> $log_file\n\n      echo \"There are $(ls *gff | wc -l) files for alignment\" >> $log_file\n\n      roary !{params.roary_options} \\\n        -p !{task.cpus} \\\n        -f roary \\\n        -e -n \\\n        *.gff \\\n        2>> $err_file >> $log_file\n    '''",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq",
            "Roary"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq",
            "https://bio.tools/roary"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "Roary",
                "uri": "https://bio.tools/roary",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A high speed stand alone pan genome pipeline, which takes annotated assemblies in GFF3 format (produced by Prokka (Seemann, 2014)) and calculates the pan genome.",
                "homepage": "http://sanger-pathogens.github.io/Roary/"
            }
        ],
        "inputs": [
            "gffs",
            "local_gffs"
        ],
        "nb_inputs": 2,
        "outputs": [
            "roary_core_genome_iqtree",
            "roary_core_genome_snp_dists"
        ],
        "nb_outputs": 2,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"Core Genome Alignment\"",
            "cpus params.maxcpus",
            "container 'staphb/roary:latest'"
        ],
        "when": "",
        "stub": ""
    },
    "iqtree2": {
        "name_process": "iqtree2",
        "string_process": " process iqtree2 {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"Pylogenetic Tree\"\n    cpus params.maxcpus\n    container 'staphb/iqtree2:latest'\n\n    when:\n    params.iqtree2\n\n    input:\n    file(msa) from roary_core_genome_iqtree\n\n    output:\n    file(\"${task.process}/iqtree{.ckp.gz,.treefile,.iqtree,.log,.splits.nex}\")\n    file(\"${task.process}/iqtree.contree\") into treefile\n    file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      iqtree2 -v >> $log_file\n\n      outgroup=''\n      if [ -n \"!{params.outgroup}\" ] ; then outgroup=\"-o !{params.outgroup}\" ; fi\n\n      iqtree2 !{params.iqtree2_options} \\\n        -s !{msa} \\\n        -pre !{task.process}/iqtree \\\n        -nt AUTO \\\n        -ntmax !{task.cpus} \\\n        $outgroup \\\n        2>> $err_file >> $log_file\n    '''\n  }",
        "nb_lignes_process": 37,
        "string_script": "    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      iqtree2 -v >> $log_file\n\n      outgroup=''\n      if [ -n \"!{params.outgroup}\" ] ; then outgroup=\"-o !{params.outgroup}\" ; fi\n\n      iqtree2 !{params.iqtree2_options} \\\n        -s !{msa} \\\n        -pre !{task.process}/iqtree \\\n        -nt AUTO \\\n        -ntmax !{task.cpus} \\\n        $outgroup \\\n        2>> $err_file >> $log_file\n    '''",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "roary_core_genome_iqtree"
        ],
        "nb_inputs": 1,
        "outputs": [
            "treefile"
        ],
        "nb_outputs": 1,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"Pylogenetic Tree\"",
            "cpus params.maxcpus",
            "container 'staphb/iqtree2:latest'"
        ],
        "when": "params.iqtree2",
        "stub": ""
    },
    "snp_dists": {
        "name_process": "snp_dists",
        "string_process": " process snp_dists {\n    publishDir \"${params.outdir}\", mode: 'copy'\n    tag \"SNP matrix\"\n    cpus 1\n    container 'staphb/snp-dists:latest'\n\n    when:\n    params.snp_dists\n\n    input:\n    file(contigs) from roary_core_genome_snp_dists\n\n    output:\n    file(\"${task.process}/snp_matrix.txt\")\n    file(\"logs/${task.process}/${task.process}.${workflow.sessionId}.{log,err}\")\n\n    shell:\n    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      snp-dists -v >> $log_file\n\n      snp-dists !{params.snp_dists_options} \\\n        !{contigs} \\\n        2>> $err_file \\\n        > !{task.process}/snp_matrix.txt\n    '''\n  }",
        "nb_lignes_process": 30,
        "string_script": "    '''\n      mkdir -p !{task.process} logs/!{task.process}\n      log_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.log\n      err_file=logs/!{task.process}/!{task.process}.!{workflow.sessionId}.err\n\n      # time stamp + capturing tool versions\n      date | tee -a $log_file $err_file > /dev/null\n      snp-dists -v >> $log_file\n\n      snp-dists !{params.snp_dists_options} \\\n        !{contigs} \\\n        2>> $err_file \\\n        > !{task.process}/snp_matrix.txt\n    '''",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "datelife",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "roary_core_genome_snp_dists"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "UPHL-BioNGS__Grandeur",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'",
            "tag \"SNP matrix\"",
            "cpus 1",
            "container 'staphb/snp-dists:latest'"
        ],
        "when": "params.snp_dists",
        "stub": ""
    }
}