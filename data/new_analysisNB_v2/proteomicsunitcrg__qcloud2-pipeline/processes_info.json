{
    "makeblastdb": {
        "name_process": "makeblastdb",
        "string_process": "\nprocess makeblastdb {\n    storeDir blastdb_folder\n    afterScript(\"chmod 777 ${blastdb_folder}\")\n    tag { genome_id }\n\n    input:\n    set genome_id, fasta_file, internal_dbfile, file(fasta_path) from fasta_desc\n\n    output:\n    set genome_id, internal_dbfile, file (\"*\") into blastdbs, blastdbs_d\n    \n    script:\n    \"\"\"\n     if [ `echo ${fasta_file} | grep 'gz'` ]; then zcat ${fasta_file} > ${internal_dbfile}; else ln -s ${fasta_file} ${internal_dbfile}; fi\n     makeblastdb -dbtype prot -in ${internal_dbfile} -out ${internal_dbfile}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n     if [ `echo ${fasta_file} | grep 'gz'` ]; then zcat ${fasta_file} > ${internal_dbfile}; else ln -s ${fasta_file} ${internal_dbfile}; fi\n     makeblastdb -dbtype prot -in ${internal_dbfile} -out ${internal_dbfile}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_desc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "blastdbs",
            "blastdbs_d"
        ],
        "nb_outputs": 2,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "storeDir blastdb_folder",
            "afterScript(\"chmod 777 ${blastdb_folder}\")",
            "tag { genome_id }"
        ],
        "when": "",
        "stub": ""
    },
    "thermofilerawparser": {
        "name_process": "thermofilerawparser",
        "string_process": "\nprocess thermofilerawparser {\n    label 'thermoconvert'  \n    tag { \"${labsys}_${qcode}_${checksum}\" }\n\n    input:\n    set orifile, labsys, qcode, checksum, file(zipfile) from zipfiles\n\n    output:\n    set val(\"${labsys}_${qcode}_${checksum}\"), qcode, checksum, file(\"${labsys}_${qcode}_${checksum}.mzML\") into mzmlfiles_for_correction\n    \n    script:\n    def filename = zipfile.getBaseName()\n\tdef extens = filename.split('.')\n    if (extens.length == 0) {\n\t\tfilename = filename + \".raw\"\n\t} else if (extens[-1] != \"raw\" ) {\n\t\tfilename = filename + \".raw\"\n\t}\n    \"\"\"\n    unzip ${zipfile}\n    ThermoRawFileParser -i=${filename} -f=1 -m=0 -o ./\n    mv *.mzML ${labsys}_${qcode}_${checksum}.mzML\n    rm *.raw\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    def filename = zipfile.getBaseName()\n\tdef extens = filename.split('.')\n    if (extens.length == 0) {\n\t\tfilename = filename + \".raw\"\n\t} else if (extens[-1] != \"raw\" ) {\n\t\tfilename = filename + \".raw\"\n\t}\n    \"\"\"\n    unzip ${zipfile}\n    ThermoRawFileParser -i=${filename} -f=1 -m=0 -o ./\n    mv *.mzML ${labsys}_${qcode}_${checksum}.mzML\n    rm *.raw\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "ThermoRawFileParser"
        ],
        "tools_url": [
            "https://bio.tools/ThermoRawFileParser"
        ],
        "tools_dico": [
            {
                "name": "ThermoRawFileParser",
                "uri": "https://bio.tools/ThermoRawFileParser",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3695",
                                    "term": "Filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3434",
                                    "term": "Conversion"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak assignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak finding"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0943",
                                "term": "Mass spectrum"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0943",
                                "term": "Mass spectrum"
                            }
                        ]
                    }
                ],
                "description": "Open-source, crossplatform tool that converts Thermo RAW files into open file formats such as MGF and to the HUPO-PSI standard file format mzML",
                "homepage": "https://github.com/compomics/ThermoRawFileParser"
            }
        ],
        "inputs": [
            "zipfiles"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mzmlfiles_for_correction"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "label 'thermoconvert'",
            "tag { \"${labsys}_${qcode}_${checksum}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "correctMzml": {
        "name_process": "correctMzml",
        "string_process": "\nprocess correctMzml {\n   tag { sample_id }\n   \n    input:\n    set sample_id, qcode, checksum, file(mzML_file) from (mzmlfiles_for_correction)\n \n    output:\n    set qcode, sample_id, checksum, file(\"${sample_id}.ok.mzML\") into corrected_mzmlfiles_for_second_step\n\n   \"\"\"  \n    if [ `echo ${mzML_file} | grep 'gz'` ]; then zcat ${mzML_file} > ${sample_id}.mzML; \\\n    sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${sample_id}.mzML > ${sample_id}.ok.mzML; \\\n    else sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${mzML_file} > ${sample_id}.ok.mzML; fi\n   \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"  \n    if [ `echo ${mzML_file} | grep 'gz'` ]; then zcat ${mzML_file} > ${sample_id}.mzML; \\\n    sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${sample_id}.mzML > ${sample_id}.ok.mzML; \\\n    else sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${mzML_file} > ${sample_id}.ok.mzML; fi\n   \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mzmlfiles_for_correction"
        ],
        "nb_inputs": 1,
        "outputs": [
            "corrected_mzmlfiles_for_second_step"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }"
        ],
        "when": "",
        "stub": ""
    },
    "run_shotgun": {
        "name_process": "run_shotgun",
        "string_process": "\nprocess run_shotgun {\n\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun\n    file(workflowfile) from shotgunWF\n    \n    when:\n    analysis_type == 'shotgun'\n\n    output:\n    set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.featureXML\") into shot_featureXMLfiles_for_calc_peptide_area, shot_featureXMLfiles_for_calc_mass_accuracy, shot_featureXMLfiles_for_calc_median_fwhm\n    set sample_id, internal_code, analysis_type, checksum, file(mzML_file) into shot_mzML_file_for_MedianITMS1, shot_mzML_file_for_MedianITMS2, shot_mzML_file_for_check, shot_mzML_file_for_tic \n    set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.qcml\") into qcmlfiles_for_MS2_spectral_count, qcmlfiles_for_tot_num_uniq_peptides, qcmlfiles_for_tot_num_uniq_proteins, qcmlfiles_for_tot_num_psm\n    set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.featureXML\"), file(\"${sample_id}.idXML\") into shot_featureXMLfiles_for_ret_time\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 25,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun",
            "shotgunWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_featureXMLfiles_for_calc_peptide_area",
            "shot_featureXMLfiles_for_calc_mass_accuracy",
            "shot_featureXMLfiles_for_calc_median_fwhm",
            "shot_mzML_file_for_MedianITMS1",
            "shot_mzML_file_for_MedianITMS2",
            "shot_mzML_file_for_check",
            "shot_mzML_file_for_tic",
            "qcmlfiles_for_MS2_spectral_count",
            "qcmlfiles_for_tot_num_uniq_peptides",
            "qcmlfiles_for_tot_num_uniq_proteins",
            "qcmlfiles_for_tot_num_psm",
            "shot_featureXMLfiles_for_ret_time"
        ],
        "nb_outputs": 12,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun'",
        "stub": ""
    },
    "run_srm": {
        "name_process": "run_srm",
        "string_process": "\nprocess run_srm {\n      tag { sample_id }\n\n       label 'big_mem'\n        input:\n        set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_srm\n        file(workflowfile) from srmWF\n        file(srmCSV)\n        \n        when:\n        analysis_type == 'srm'\n\n        output:\n        set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.featureXML\") into srm_featureXMLfiles_for_calc_peptide_area, srm_featureXMLfiles_for_calc_mass_accuracy, srm_featureXMLfiles_for_calc_median_fwhm\n        set sample_id, internal_code, analysis_type, checksum, file(mzML_file) into srm_mzML_file_for_MedianITMS1, srm_mzML_file_for_MedianITMS2, srm_mzML_file_for_check \n        set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.featureXML\"), file(\"${sample_id}.idXML\") into srm_featureXMLfiles_for_ret_time\n   \n        script:\n        def outfile = \"${sample_id}.featureXML\"\n        def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, ofeatxml:\"${sample_id}.featureXML\", srmCSV:srmCSV)\n        knime.launch()\n}",
        "nb_lignes_process": 21,
        "string_script": "        def outfile = \"${sample_id}.featureXML\"\n        def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, ofeatxml:\"${sample_id}.featureXML\", srmCSV:srmCSV)\n        knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_srm",
            "srmWF",
            "srmCSV"
        ],
        "nb_inputs": 3,
        "outputs": [
            "srm_featureXMLfiles_for_calc_peptide_area",
            "srm_featureXMLfiles_for_calc_mass_accuracy",
            "srm_featureXMLfiles_for_calc_median_fwhm",
            "srm_mzML_file_for_MedianITMS1",
            "srm_mzML_file_for_MedianITMS2",
            "srm_mzML_file_for_check",
            "srm_featureXMLfiles_for_ret_time"
        ],
        "nb_outputs": 7,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'"
        ],
        "when": "analysis_type == 'srm'",
        "stub": ""
    },
    "shotgun_qc4l_cid": {
        "name_process": "shotgun_qc4l_cid",
        "string_process": "\nprocess shotgun_qc4l_cid {\n    tag { sample_id }\n    label 'big_mem'\n    \n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_cid\n    file(workflowfile) from shotgun_qc4l_cidWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum , file(\"${sample_id}.featureXML\") into shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area  \n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum, file(mzML_file) into shot_qc4l_cid_mzML_file_for_MedianITMS1, shot_qc4l_cid_mzML_file_for_MedianITMS2, shot_qc4l_cid_mzML_file_for_check, shot_qc4l_cid_mzML_file_for_tic\n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_cid_qcmlfiles_for_tot_num_psm\n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum, file(\"${sample_id}.featureXML\"), file(\"${sample_id}.idXML\") into shot_qc4l_cid_featureXMLfiles_for_ret_time\n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 25,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_cid",
            "shotgun_qc4l_cidWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_cid_mzML_file_for_MedianITMS1",
            "shot_qc4l_cid_mzML_file_for_MedianITMS2",
            "shot_qc4l_cid_mzML_file_for_check",
            "shot_qc4l_cid_mzML_file_for_tic",
            "shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_cid_featureXMLfiles_for_ret_time",
            "shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy"
        ],
        "nb_outputs": 12,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "shotgun_qc4l_hcd": {
        "name_process": "shotgun_qc4l_hcd",
        "string_process": "\nprocess shotgun_qc4l_hcd {\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_hcd\n    file(workflowfile) from shotgun_qc4l_hcdWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_hcd\"), internal_code, val(\"shotgun_qc4l_hcd\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_hcd_featureXMLfiles_for_calc_peptide_area, shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm\n    set val(\"${sample_id}_hcd\"), internal_code, val(\"shotgun_qc4l_hcd\"), checksum, file(mzML_file) into shot_qc4l_hcd_mzML_file_for_MedianITMS1, shot_qc4l_hcd_mzML_file_for_MedianITMS2, shot_qc4l_hcd_mzML_file_for_check, shot_qc4l_hcd_mzML_file_for_tic\n    set val(\"${sample_id}_hcd\"), internal_code, val(\"shotgun_qc4l_hcd\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_hcd_qcmlfiles_for_tot_num_psm\n    set val(\"${sample_id}_hcd\"), internal_code, val(\"shotgun_qc4l_hcd\"), checksum, file(\"${sample_id}.featureXML\"), file(\"${sample_id}.idXML\") into shot_qc4l_hcd_featureXMLfiles_for_ret_time\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 24,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_hcd",
            "shotgun_qc4l_hcdWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_hcd_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS1",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS2",
            "shot_qc4l_hcd_mzML_file_for_check",
            "shot_qc4l_hcd_mzML_file_for_tic",
            "shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_hcd_featureXMLfiles_for_ret_time"
        ],
        "nb_outputs": 12,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "shotgun_qc4l_etcid": {
        "name_process": "shotgun_qc4l_etcid",
        "string_process": "\nprocess shotgun_qc4l_etcid {\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_etcid\n    file(workflowfile) from shotgun_qc4l_etcidWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_etcid\"), internal_code, val(\"shotgun_qc4l_etcid\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area, shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm\n    set val(\"${sample_id}_etcid\"), internal_code, val(\"shotgun_qc4l_etcid\"), checksum, file(mzML_file) into shot_qc4l_etcid_mzML_file_for_MedianITMS1, shot_qc4l_etcid_mzML_file_for_MedianITMS2, shot_qc4l_etcid_mzML_file_for_check, shot_qc4l_etcid_mzML_file_for_tic \n    set val(\"${sample_id}_etcid\"), internal_code, val(\"shotgun_qc4l_etcid\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_etcid_qcmlfiles_for_tot_num_psm\n    set val(\"${sample_id}_etcid\"), internal_code, val(\"shotgun_qc4l_etcid\"), checksum, file(\"${sample_id}.featureXML\"), file(\"${sample_id}.idXML\") into shot_qc4l_etcid_featureXMLfiles_for_ret_time\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 24,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_etcid",
            "shotgun_qc4l_etcidWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS1",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS2",
            "shot_qc4l_etcid_mzML_file_for_check",
            "shot_qc4l_etcid_mzML_file_for_tic",
            "shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_etcid_featureXMLfiles_for_ret_time"
        ],
        "nb_outputs": 12,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "shotgun_qc4l_ethcd": {
        "name_process": "shotgun_qc4l_ethcd",
        "string_process": "\nprocess shotgun_qc4l_ethcd  {\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_ethcd\n    file(workflowfile) from shotgun_qc4l_ethcdWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_ethcd\"), internal_code, val(\"shotgun_qc4l_ethcd\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area, shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm\n    set val(\"${sample_id}_ethcd\"), internal_code, val(\"shotgun_qc4l_ethcd\"), checksum, file(mzML_file) into shot_qc4l_ethcd_mzML_file_for_MedianITMS1, shot_qc4l_ethcd_mzML_file_for_MedianITMS2, shot_qc4l_ethcd_mzML_file_for_check, shot_qc4l_ethcd_mzML_file_for_tic \n    set val(\"${sample_id}_ethcd\"), internal_code, val(\"shotgun_qc4l_ethcd\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm\n    set val(\"${sample_id}_ethcd\"), internal_code, val(\"shotgun_qc4l_ethcd\"), checksum, file(\"${sample_id}.featureXML\"), file(\"${sample_id}.idXML\") into shot_qc4l_ethcid_featureXMLfiles_for_ret_time\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 24,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_ethcd",
            "shotgun_qc4l_ethcdWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS1",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS2",
            "shot_qc4l_ethcd_mzML_file_for_check",
            "shot_qc4l_ethcd_mzML_file_for_tic",
            "shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_ethcid_featureXMLfiles_for_ret_time"
        ],
        "nb_outputs": 12,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "calc_MS2_spectral_count": {
        "name_process": "calc_MS2_spectral_count",
        "string_process": "\nprocess calc_MS2_spectral_count {\n    tag { \"${sample_id}-${analysis_type}\" }\n    \n    input:\n    set sample_id, internal_code, val(analysis_type), checksum, file(qcmlfile) from qcmlfiles_for_MS2_spectral_count.mix(shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count, shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count)\n    file(workflowfile) from getWFFile(baseQCPath, \"MS2specCount\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['MS2specCount'][analysis_type]}.json\") into ms2_spectral_for_delivery\n\n    script:\n    def analysis_id = Correspondence['MS2specCount'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['MS2specCount'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n}",
        "nb_lignes_process": 16,
        "string_script": "    def analysis_id = Correspondence['MS2specCount'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['MS2specCount'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count",
            "baseQCPath",
            "\"MS2specCount\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "ms2_spectral_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_tot_num_uniq_peptides": {
        "name_process": "calc_tot_num_uniq_peptides",
        "string_process": "\nprocess calc_tot_num_uniq_peptides {\n    tag { \"${sample_id}-${analysis_type}\" }\n   \n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(qcmlfile) from qcmlfiles_for_tot_num_uniq_peptides.mix(shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides)\n    file(workflowfile) from getWFFile(baseQCPath, \"totNumOfUniPep\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['totNumOfUniPep'][analysis_type]}.json\") into uni_peptides_for_delivery\n\n    script:\n    def analysis_id = Correspondence['totNumOfUniPep'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniPep'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n}",
        "nb_lignes_process": 16,
        "string_script": "    def analysis_id = Correspondence['totNumOfUniPep'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniPep'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides",
            "baseQCPath",
            "\"totNumOfUniPep\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "uni_peptides_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_tot_num_uniq_proteins": {
        "name_process": "calc_tot_num_uniq_proteins",
        "string_process": "\nprocess calc_tot_num_uniq_proteins {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(qcmlfile) from qcmlfiles_for_tot_num_uniq_proteins.mix(shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins)\n    file(workflowfile) from getWFFile(baseQCPath, \"totNumOfUniProt\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['totNumOfUniProt'][analysis_type]}.json\") into uni_prots_for_delivery\n\n    script:\n    def analysis_id = Correspondence['totNumOfUniProt'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniProt'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['totNumOfUniProt'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniProt'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins",
            "baseQCPath",
            "\"totNumOfUniProt\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "uni_prots_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_tot_num_psm": {
        "name_process": "calc_tot_num_psm",
        "string_process": "\nprocess calc_tot_num_psm {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(qcmlfile) from qcmlfiles_for_tot_num_psm.mix(shot_qc4l_cid_qcmlfiles_for_tot_num_psm, shot_qc4l_hcd_qcmlfiles_for_tot_num_psm, shot_qc4l_etcid_qcmlfiles_for_tot_num_psm, shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm)\n    file(workflowfile) from getWFFile(baseQCPath, \"totNumOfPsm\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['totNumOfPsm'][analysis_type]}.json\") into tot_psm_for_delivery\n\n    script:\n    def analysis_id = Correspondence['totNumOfPsm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfPsm'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['totNumOfPsm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfPsm'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_tot_num_psm",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm",
            "baseQCPath",
            "\"totNumOfPsm\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "tot_psm_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_median_IT_MS1": {
        "name_process": "calc_median_IT_MS1",
        "string_process": "\nprocess calc_median_IT_MS1 {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(mzml_file) from shot_mzML_file_for_MedianITMS1.mix(srm_mzML_file_for_MedianITMS1, shot_qc4l_cid_mzML_file_for_MedianITMS1, shot_qc4l_hcd_mzML_file_for_MedianITMS1, shot_qc4l_etcid_mzML_file_for_MedianITMS1, shot_qc4l_ethcd_mzML_file_for_MedianITMS1)\n    file(workflowfile) from getWFFile(baseQCPath, \"medianITMS1\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['medianITMS1'][analysis_type]}.json\") into median_itms1_for_delivery\n\n    script:\n    def analysis_id = Correspondence['medianITMS1'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS1'][analysis_type]}.json\" \n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['medianITMS1'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS1'][analysis_type]}.json\" \n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_mzML_file_for_MedianITMS1",
            "srm_mzML_file_for_MedianITMS1",
            "shot_qc4l_cid_mzML_file_for_MedianITMS1",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS1",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS1",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS1",
            "baseQCPath",
            "\"medianITMS1\""
        ],
        "nb_inputs": 8,
        "outputs": [
            "median_itms1_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_median_IT_MS2": {
        "name_process": "calc_median_IT_MS2",
        "string_process": "\nprocess calc_median_IT_MS2 {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(mzml_file) from shot_mzML_file_for_MedianITMS2.mix(srm_mzML_file_for_MedianITMS2, shot_qc4l_cid_mzML_file_for_MedianITMS2, shot_qc4l_hcd_mzML_file_for_MedianITMS2, shot_qc4l_etcid_mzML_file_for_MedianITMS2, shot_qc4l_ethcd_mzML_file_for_MedianITMS2)\n    file(workflowfile) from getWFFile(baseQCPath, \"medianITMS2\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['medianITMS2'][analysis_type]}.json\") into median_itms2_for_delivery\n\n    script:\n    def analysis_id = Correspondence['medianITMS2'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS2'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile,  empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['medianITMS2'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS2'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile,  empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_mzML_file_for_MedianITMS2",
            "srm_mzML_file_for_MedianITMS2",
            "shot_qc4l_cid_mzML_file_for_MedianITMS2",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS2",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS2",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS2",
            "baseQCPath",
            "\"medianITMS2\""
        ],
        "nb_inputs": 8,
        "outputs": [
            "median_itms2_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_peptide_area": {
        "name_process": "calc_peptide_area",
        "string_process": "\nprocess calc_peptide_area {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, val(internal_code), analysis_type, checksum, file(featxml_file) from shot_featureXMLfiles_for_calc_peptide_area.mix(srm_featureXMLfiles_for_calc_peptide_area)\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from getWFFile(baseQCPath, \"pepArea\")\n\n    output:\n    set sample_id, internal_code, checksum, val(\"${Correspondence['pepArea'][analysis_type]}\"), file(\"${sample_id}_QC_${Correspondence['pepArea'][analysis_type]}.json\") into pep_area_for_check\n\n    script:\n    def analysis_id = Correspondence['pepArea'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n\tdef outfile = \"${sample_id}_QC_${Correspondence['pepArea'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 20,
        "string_script": "    def analysis_id = Correspondence['pepArea'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n\tdef outfile = \"${sample_id}_QC_${Correspondence['pepArea'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_featureXMLfiles_for_calc_peptide_area",
            "srm_featureXMLfiles_for_calc_peptide_area",
            "peptideCSV",
            "peptideCSV_C4L",
            "baseQCPath",
            "\"pepArea\""
        ],
        "nb_inputs": 6,
        "outputs": [
            "pep_area_for_check"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_peptide_area_c4l": {
        "name_process": "calc_peptide_area_c4l",
        "string_process": "\nprocess calc_peptide_area_c4l {\n    tag { \"${labsys}_${qcode}_${checksum}\" }\n    label 'thermoconvert'  \n\n\twhen:\n    qcode == 'QC03'\n\n    input:\n    set orifile, labsys, qcode, checksum, file(zipfile) from zip_for_calc_peptide_area_c4l\n\n                                                                                                                                  \n                                                                                                                                                                                                                                                                                       \n\n\t                                             \n\t                                                     \n    file(workflowfile) from getWFFile(baseQCPath, \"pepArea_qc4l\", \"sh\")\n    file(masses_C4L)\n    file(mass_isotop)\n    file(fgcz_exe)\n    file(temp_qcloud_out)\n    \n    output:\n    set val(\"${labsys}_${qcode}_${checksum}\"), file(\"${labsys}_${qcode}_${checksum}_QC_${Correspondence['pepArea_qc4l']['shotgun_qc4l_hcd']}.json\") into pep_c4l_for_delivery\n\n    script:\n    def analysis_id = Correspondence['pepArea_qc4l']['shotgun_qc4l_hcd']\n    def ontology_id = \"QC_${ontology[analysis_id]}\"\n    def heavy_conc = 100\n    def tolppm = 10\n    def rt_window = 2\n                                              \n    def outfile = \"${labsys}_${qcode}_${checksum}_QC_${Correspondence['pepArea_qc4l']['shotgun_qc4l_hcd']}.json\"\n    \"\"\"\n    zcat ${zipfile} > temp.raw\n    touch ${outfile}\n    ./${workflowfile} temp.raw ${checksum} ${masses_C4L} ${mass_isotop} \\\n    ${temp_qcloud_out} ${outfile} ${heavy_conc} ${tolppm} ${rt_window} \n    rm temp.raw\n    \"\"\"\n\n}",
        "nb_lignes_process": 40,
        "string_script": "    def analysis_id = Correspondence['pepArea_qc4l']['shotgun_qc4l_hcd']\n    def ontology_id = \"QC_${ontology[analysis_id]}\"\n    def heavy_conc = 100\n    def tolppm = 10\n    def rt_window = 2\n                                              \n    def outfile = \"${labsys}_${qcode}_${checksum}_QC_${Correspondence['pepArea_qc4l']['shotgun_qc4l_hcd']}.json\"\n    \"\"\"\n    zcat ${zipfile} > temp.raw\n    touch ${outfile}\n    ./${workflowfile} temp.raw ${checksum} ${masses_C4L} ${mass_isotop} \\\n    ${temp_qcloud_out} ${outfile} ${heavy_conc} ${tolppm} ${rt_window} \n    rm temp.raw\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "zip_for_calc_peptide_area_c4l",
            "baseQCPath",
            "\"pepArea_qc4l\"",
            "\"sh\"",
            "masses_C4L",
            "mass_isotop",
            "fgcz_exe",
            "temp_qcloud_out"
        ],
        "nb_inputs": 8,
        "outputs": [
            "pep_c4l_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${labsys}_${qcode}_${checksum}\" }",
            "label 'thermoconvert'"
        ],
        "when": "qcode == 'QC03'",
        "stub": ""
    },
    "calc_tic": {
        "name_process": "calc_tic",
        "string_process": "\nprocess calc_tic {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, val(analysis_type), checksum, file(mzmlfile) from shot_mzML_file_for_tic.mix(shot_qc4l_cid_mzML_file_for_tic, shot_qc4l_hcd_mzML_file_for_tic, shot_qc4l_etcid_mzML_file_for_tic, shot_qc4l_ethcd_mzML_file_for_tic)\n    file(workflowfile) from getWFFile(baseQCPath, \"tic\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['tic'][analysis_type]}.json\") into tic_for_delivery\n\n    script:\n    def analysis_id = Correspondence['tic'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['tic'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mzml:mzmlfile, stype:internal_code, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()   \n}",
        "nb_lignes_process": 16,
        "string_script": "    def analysis_id = Correspondence['tic'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['tic'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mzml:mzmlfile, stype:internal_code, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_mzML_file_for_tic",
            "shot_qc4l_cid_mzML_file_for_tic",
            "shot_qc4l_hcd_mzML_file_for_tic",
            "shot_qc4l_etcid_mzML_file_for_tic",
            "shot_qc4l_ethcd_mzML_file_for_tic",
            "baseQCPath",
            "\"tic\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "tic_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_retTime": {
        "name_process": "calc_retTime",
        "string_process": "\nprocess calc_retTime {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file), file(idxml_file) from shot_featureXMLfiles_for_ret_time.mix(srm_featureXMLfiles_for_ret_time)\n \tfile (\"peptide.csv\") from file (peptideCSV)\n    file(workflowfile) from getWFFile(baseQCPath, \"retTime\")\n\n    output:\n                                                                                                                                                                                                   \n    set sample_id, file(\"${sample_id}_QC_${Correspondence['retTime'][analysis_type]}.json\") into retTime_for_delivery\n\n    script:\n    def analysis_id = Correspondence['retTime'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['retTime'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, idxml:idxml_file, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()   \n}",
        "nb_lignes_process": 19,
        "string_script": "    def analysis_id = Correspondence['retTime'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['retTime'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, idxml:idxml_file, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_featureXMLfiles_for_ret_time",
            "srm_featureXMLfiles_for_ret_time",
            "peptideCSV",
            "baseQCPath",
            "\"retTime\""
        ],
        "nb_inputs": 5,
        "outputs": [
            "retTime_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_retTime_c4l": {
        "name_process": "calc_retTime_c4l",
        "string_process": "\nprocess calc_retTime_c4l {\n    tag { \"${labsys}_${qcode}_${checksum}\" }\n    label 'thermoconvert'\n\n    when:\n    qcode == 'QC03'\n\n    input:\n    set orifile, labsys, qcode, checksum, file(zipfile) from zip_for_calc_retime_area_c4l\n    file(workflowfile) from getWFFile(baseQCPath, \"retTime_qc4l\", \"sh\")\n    file(masses_C4L)\n    file(mass_isotop)\n    file(fgcz_exe)\n    file(temp_qcloud_out)\n\n    output:\n    set val(\"${labsys}_${qcode}_${checksum}\"), file(\"${labsys}_${qcode}_${checksum}_QC_${Correspondence['retTime_qc4l']['shotgun_qc4l_hcd']}.json\") into retTime_qc4l_for_delivery\n\n    script:\n    def heavy_conc = 100\n    def tolppm = 10\n    def rt_window = 2\n    def outfile = \"${labsys}_${qcode}_${checksum}_QC_${Correspondence['pepArea_qc4l']['shotgun_qc4l_hcd']}.json\"\n    def outfile_rt = \"${labsys}_${qcode}_${checksum}_QC_${Correspondence['retTime_qc4l']['shotgun_qc4l_hcd']}.json\"\n    \"\"\"\n    zcat ${zipfile} > temp.raw\n    touch ${outfile_rt}\n    ./${workflowfile} temp.raw ${checksum} ${masses_C4L} ${mass_isotop} \\\n    ${temp_qcloud_out} ${outfile} ${heavy_conc} ${tolppm} ${rt_window} ${outfile_rt}\n    rm temp.raw\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    def heavy_conc = 100\n    def tolppm = 10\n    def rt_window = 2\n    def outfile = \"${labsys}_${qcode}_${checksum}_QC_${Correspondence['pepArea_qc4l']['shotgun_qc4l_hcd']}.json\"\n    def outfile_rt = \"${labsys}_${qcode}_${checksum}_QC_${Correspondence['retTime_qc4l']['shotgun_qc4l_hcd']}.json\"\n    \"\"\"\n    zcat ${zipfile} > temp.raw\n    touch ${outfile_rt}\n    ./${workflowfile} temp.raw ${checksum} ${masses_C4L} ${mass_isotop} \\\n    ${temp_qcloud_out} ${outfile} ${heavy_conc} ${tolppm} ${rt_window} ${outfile_rt}\n    rm temp.raw\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "zip_for_calc_retime_area_c4l",
            "baseQCPath",
            "\"retTime_qc4l\"",
            "\"sh\"",
            "masses_C4L",
            "mass_isotop",
            "fgcz_exe",
            "temp_qcloud_out"
        ],
        "nb_inputs": 8,
        "outputs": [
            "retTime_qc4l_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${labsys}_${qcode}_${checksum}\" }",
            "label 'thermoconvert'"
        ],
        "when": "qcode == 'QC03'",
        "stub": ""
    },
    "calc_retTime_c4l_fake": {
        "name_process": "calc_retTime_c4l_fake",
        "string_process": "\nprocess calc_retTime_c4l_fake {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area.mix(shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area, shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area)\n\n    output:\n    set sample_id, val(null) into pep_c4l_for_delivery_fake\n\n    script:\n        \"\"\"\n        echo \"this is a workaround because of a nextflow problem with joining\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 14,
        "string_script": "        \"\"\"\n        echo \"this is a workaround because of a nextflow problem with joining\"\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area"
        ],
        "nb_inputs": 3,
        "outputs": [
            "pep_c4l_for_delivery_fake"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_mass_accuracy": {
        "name_process": "calc_mass_accuracy",
        "string_process": " process calc_mass_accuracy {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_featureXMLfiles_for_calc_mass_accuracy.mix(srm_featureXMLfiles_for_calc_mass_accuracy)\n\tfile(\"peptide.csv\") from file (peptideCSV)\n    file(workflowfile) from getWFFile(baseQCPath, \"massAccuracy\") \n\n    output:\n    set sample_id, internal_code, checksum, val(\"${Correspondence['massAccuracy'][analysis_type]}\"),  file(\"${sample_id}_QC_${Correspondence['massAccuracy'][analysis_type]}.json\") into mass_json_for_check\n\n    script:\n    def analysis_id = Correspondence['massAccuracy'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['massAccuracy'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['massAccuracy'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['massAccuracy'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_featureXMLfiles_for_calc_mass_accuracy",
            "srm_featureXMLfiles_for_calc_mass_accuracy",
            "peptideCSV",
            "baseQCPath",
            "\"massAccuracy\""
        ],
        "nb_inputs": 5,
        "outputs": [
            "mass_json_for_check"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_mass_accuracy_c4l": {
        "name_process": "calc_mass_accuracy_c4l",
        "string_process": " process calc_mass_accuracy_c4l {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from getWFFile(baseQCPath, \"massAccuracy_qc4l\") \n\n    output:\n                                                                                                                                                                                                                               \n    set sample_id, file(\"${sample_id}_QC_${Correspondence['massAccuracy_qc4l'][analysis_type]}.json\") into mass_c4l_json_for_delivery\n\n    script:\n    def analysis_id = Correspondence['massAccuracy_qc4l'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['massAccuracy_qc4l'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n}",
        "nb_lignes_process": 18,
        "string_script": "    def analysis_id = Correspondence['massAccuracy_qc4l'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['massAccuracy_qc4l'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy",
            "peptideCSV_C4L",
            "baseQCPath",
            "\"massAccuracy_qc4l\""
        ],
        "nb_inputs": 4,
        "outputs": [
            "mass_c4l_json_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_mass_accuracy_c4l_fake": {
        "name_process": "calc_mass_accuracy_c4l_fake",
        "string_process": "\nprocess calc_mass_accuracy_c4l_fake {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy.mix(shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy)\n\n    output:\n    set sample_id, val(null) into mass_c4l_json_for_delivery_fake\n\n    script:\n\t\"\"\"\n\techo \"this is a workaround because of a nextflow problem with joining :))\"\n\t\"\"\"\n    \n}",
        "nb_lignes_process": 14,
        "string_script": "\t\"\"\"\n\techo \"this is a workaround because of a nextflow problem with joining :))\"\n\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy"
        ],
        "nb_inputs": 3,
        "outputs": [
            "mass_c4l_json_for_delivery_fake"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_median_fwhm": {
        "name_process": "calc_median_fwhm",
        "string_process": " process calc_median_fwhm {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_featureXMLfiles_for_calc_median_fwhm.mix(srm_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm)\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from getWFFile(baseQCPath, \"medianFwhm\") \n\n    output:\n    set sample_id, internal_code, checksum, val(\"${Correspondence['medianFwhm'][analysis_type]}\"),  file(\"${sample_id}_QC_${Correspondence['medianFwhm'][analysis_type]}.json\") into median_fwhm_for_check\n\n    script:\n    def analysis_id = Correspondence['medianFwhm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianFwhm'][analysis_type]}.json\"\n    \"\"\"\n    touch ${outfile}\n    \"\"\"\n                                                                                                                                                                                                                                                           \n                    \n    \n}",
        "nb_lignes_process": 22,
        "string_script": "    def analysis_id = Correspondence['medianFwhm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianFwhm'][analysis_type]}.json\"\n    \"\"\"\n    touch ${outfile}\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_featureXMLfiles_for_calc_median_fwhm",
            "srm_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm",
            "peptideCSV",
            "peptideCSV_C4L",
            "baseQCPath",
            "\"medianFwhm\""
        ],
        "nb_inputs": 10,
        "outputs": [
            "median_fwhm_for_check"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "check_peptides": {
        "name_process": "check_peptides",
        "string_process": " process check_peptides {\n    tag { \"${sample_id}-${process_id}-json_file\" }\n    beforeScript(\"mkdir out\")\n\n    input:\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n\tset sample_id, internal_code, checksum, process_id, file(json_file) from pep_area_for_check\n    file(workflowfile) from chekPeptidesWF\n\n    output:\n    set sample_id, file(\"out/${json_file}\") into pep_checked_for_delivery\n\n    script:\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum, csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()\n}",
        "nb_lignes_process": 17,
        "string_script": "    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum, csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "peptideCSV",
            "peptideCSV_C4L",
            "pep_area_for_check",
            "chekPeptidesWF"
        ],
        "nb_inputs": 4,
        "outputs": [
            "pep_checked_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { \"${sample_id}-${process_id}-json_file\" }",
            "beforeScript(\"mkdir out\")"
        ],
        "when": "",
        "stub": ""
    },
    "check_mass": {
        "name_process": "check_mass",
        "string_process": " process check_mass {\n    tag { sample_id }\n    beforeScript(\"mkdir out\")\n\n    input:\n    set sample_id, internal_code, checksum, process_id, file(json_file) from mass_json_for_check\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n\tfile(workflowfile) from chekPeptidesWF\n\n    output:\n    set sample_id, file(\"out/${json_file}\") into mass_checked_for_joining\n\n    script:\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()\n}",
        "nb_lignes_process": 17,
        "string_script": "    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mass_json_for_check",
            "peptideCSV",
            "peptideCSV_C4L",
            "chekPeptidesWF"
        ],
        "nb_inputs": 4,
        "outputs": [
            "mass_checked_for_joining"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "beforeScript(\"mkdir out\")"
        ],
        "when": "",
        "stub": ""
    },
    "check_fwhm": {
        "name_process": "check_fwhm",
        "string_process": " process check_fwhm {\n    tag { sample_id }\n    beforeScript(\"mkdir out\")\n\t\n    input:\n    set sample_id, internal_code, checksum, process_id, file(json_file) from median_fwhm_for_check\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from chekPeptidesWF\n\n    output:\n    set sample_id, file(\"out/${json_file}\") into median_checked_for_delivery\n\n    script:\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()\n}",
        "nb_lignes_process": 17,
        "string_script": "    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "median_fwhm_for_check",
            "peptideCSV",
            "peptideCSV_C4L",
            "chekPeptidesWF"
        ],
        "nb_inputs": 4,
        "outputs": [
            "median_checked_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }",
            "beforeScript(\"mkdir out\")"
        ],
        "when": "",
        "stub": ""
    },
    "check_mzML": {
        "name_process": "check_mzML",
        "string_process": "\nprocess check_mzML {\n    tag { sample_id }\n\t   \n    input:\n    set sample_id, internal_id, analysis_type, checksum, file(mzML_file) from shot_mzML_file_for_check.mix(srm_mzML_file_for_check, shot_qc4l_cid_mzML_file_for_check, shot_qc4l_hcd_mzML_file_for_check, shot_qc4l_etcid_mzML_file_for_check, shot_qc4l_ethcd_mzML_file_for_check)\n\n    output:\n    set sample_id, internal_id, analysis_type, checksum, file(\"${mzML_file}.timestamp\"), file(\"${mzML_file}.filename\") into mZML_params_for_mapping\n\n    script:\n    \"\"\"\n    xmllint --xpath 'string(/mzML/@id)' ${mzML_file} > ${mzML_file}.filename\n    xmllint --xpath 'string(/mzML/run/@startTimeStamp)' ${mzML_file} > raw_time    \n    cat raw_time | xargs -I{} date -d {} +\"%Y-%m-%dT%TZ\"  | tr -d '\\n' > ${mzML_file}.timestamp\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    xmllint --xpath 'string(/mzML/@id)' ${mzML_file} > ${mzML_file}.filename\n    xmllint --xpath 'string(/mzML/run/@startTimeStamp)' ${mzML_file} > raw_time    \n    cat raw_time | xargs -I{} date -d {} +\"%Y-%m-%dT%TZ\"  | tr -d '\\n' > ${mzML_file}.timestamp\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_mzML_file_for_check",
            "srm_mzML_file_for_check",
            "shot_qc4l_cid_mzML_file_for_check",
            "shot_qc4l_hcd_mzML_file_for_check",
            "shot_qc4l_etcid_mzML_file_for_check",
            "shot_qc4l_ethcd_mzML_file_for_check"
        ],
        "nb_inputs": 6,
        "outputs": [
            "mZML_params_for_mapping"
        ],
        "nb_outputs": 1,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }"
        ],
        "when": "",
        "stub": ""
    },
    "sendToDB": {
        "name_process": "sendToDB",
        "string_process": " process sendToDB {\n    tag { sample_id }\n\n    input:\n    file(workflowfile) from api_connectionWF\n\n    set sample_id, internal_code, checksum, timestamp, filename, file(pepfile), file(\"*\") from mZML_params_for_delivery.join(pep_c4l_all).join(jsonToBeSent)\n    val db_host from params.db_host\n\n    script:\n    def pieces = sample_id.tokenize( '_' )\n    def instrument_id = pieces[0] \n    def parent_id = ontology[internal_code]\n    def filepieces = filename.tokenize( '_' )\n    def orifile = filepieces[0..-4].join( '_' )\n    def knime = new Knime(wf:workflowfile, rdate:timestamp, oriname:orifile, chksum:checksum, stype:internal_code, ifolder:\".\", labs:instrument_id, utoken:\"${db_host}/api/auth\", uifile:\"${db_host}/api/file/QC:${parent_id}\", uidata:\"${db_host}/api/data/pipeline\", mem:\"${task.memory.mega-5000}m\")\n    knime.launch()\n\n}",
        "nb_lignes_process": 17,
        "string_script": "    def pieces = sample_id.tokenize( '_' )\n    def instrument_id = pieces[0] \n    def parent_id = ontology[internal_code]\n    def filepieces = filename.tokenize( '_' )\n    def orifile = filepieces[0..-4].join( '_' )\n    def knime = new Knime(wf:workflowfile, rdate:timestamp, oriname:orifile, chksum:checksum, stype:internal_code, ifolder:\".\", labs:instrument_id, utoken:\"${db_host}/api/auth\", uifile:\"${db_host}/api/file/QC:${parent_id}\", uidata:\"${db_host}/api/data/pipeline\", mem:\"${task.memory.mega-5000}m\")\n    knime.launch()",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "api_connectionWF",
            "mZML_params_for_delivery",
            "pep_c4l_all",
            "jsonToBeSent",
            "params"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "proteomicsunitcrg__qcloud2-pipeline",
        "directive": [
            "tag { sample_id }"
        ],
        "when": "",
        "stub": ""
    }
}