{
    "filter_contig_size": {
        "name_process": "filter_contig_size",
        "string_process": "\nprocess filter_contig_size{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}\", mode:'link'\n\n  input:\n  set sample_id, seq from contig_files\n  \n  output:\n  set sample_id, \"${sample_id}_contigs_filt.fasta\"  into filter_contigs_out\n  \n  script:\n\"\"\" \nseqtk seq -L 2 ${seq[0]} > ${sample_id}_contigs_filt.fasta\n\"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\" \nseqtk seq -L 2 ${seq[0]} > ${sample_id}_contigs_filt.fasta\n\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "contig_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "filter_contigs_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "number_of_sequences": {
        "name_process": "number_of_sequences",
        "string_process": "\nprocess number_of_sequences{\n tag {\"${sample_id}\"}\n \n publishDir \"${params.publish_base_dir}/${sample_id}\", mode:'link'\n  input:\n\n  set sample_id, seq from filt_contig_size_count_in\n\n  output:\n  set sample_id, \"${sample_id}_nrOfSeq.txt\"  into nr_of_seq_out\n\n  script:\n\"\"\"\ncat ${seq} | grep \">\" | awk '!seen[\\$0]++' | wc -l > \"${sample_id}_nrOfSeq.txt\"\n\n\"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\ncat ${seq} | grep \">\" | awk '!seen[\\$0]++' | wc -l > \"${sample_id}_nrOfSeq.txt\"\n\n\"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filt_contig_size_count_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "nr_of_seq_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_nr_of_seq": {
        "name_process": "collect_nr_of_seq",
        "string_process": "\nprocess collect_nr_of_seq{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All\", mode:'link'\n\ninput:\nfile nrOfSeq from nr_of_seq_out.map{it[1]}.collect()\n\noutput:\n\nfile \"all_samples_collected_nrOfSeq.txt\" into collected_nrOfSeq_out\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${nrOfSeq})\ntotal=0\nfor i in \"\\${arr[@]}\"\ndo\n\ttotal=\\$(expr \\$total + \\$(cat \\$i | bc))\ndone\n\necho \\$total > \"all_samples_collected_nrOfSeq.txt\"\n\n\"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${nrOfSeq})\ntotal=0\nfor i in \"\\${arr[@]}\"\ndo\n\ttotal=\\$(expr \\$total + \\$(cat \\$i | bc))\ndone\n\necho \\$total > \"all_samples_collected_nrOfSeq.txt\"\n\n\"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nr_of_seq_out"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_nrOfSeq_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "grep_misMatch0": {
        "name_process": "grep_misMatch0",
        "string_process": "\nprocess grep_misMatch0{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/misMatch0\", mode:'link'\n\n  input:\n  set sample_id, seq from misMatch0_in \n  \n  output:\n  set sample_id, \"${sample_id}_list_all_headers_M0.txt\", \"${sample_id}_AMTS_UTR_M0.fasta\", \"${sample_id}_AMTAS_UTR_M0.fasta\", \"${sample_id}_AMTPTU_UTR_M0.fasta\" into misMatch0_out\n\n  script:\n\"\"\" \n#!/bin/bash\n#Universal TM-PCR\n#AMTS\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGAAGGTGAGTTTA\" ${seq} > AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGTAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGGAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGCAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\ncat AMTS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nsleep 2\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTS_UTR_M0.fasta\nsleep 2\nrm tmp_list.txt AMTS_UTR.fasta\n#AMTAS\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"AGCCCGGCCAGTCC\" ${seq} > AMTAS_UTR.fasta\nsleep 2\ncat AMTAS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nsleep 2\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTAS_UTR_M0.fasta\nsleep 2\nrm tmp_list.txt AMTAS_UTR.fasta\n#AMTPTU\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"TCAAGGGGCAATTCGGGCT\" ${seq} > AMTPTU_UTR.fasta\nsleep 2\ncat AMTPTU_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTPTU_UTR_M0.fasta\nsleep 2\nrm tmp_list.txt AMTPTU_UTR.fasta\n\ncat *M0.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > ${sample_id}_list_all_headers_M0.txt\n\"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "\"\"\" \n#!/bin/bash\n#Universal TM-PCR\n#AMTS\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGAAGGTGAGTTTA\" ${seq} > AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGTAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGGAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"GTGCCGCAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\ncat AMTS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nsleep 2\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTS_UTR_M0.fasta\nsleep 2\nrm tmp_list.txt AMTS_UTR.fasta\n#AMTAS\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"AGCCCGGCCAGTCC\" ${seq} > AMTAS_UTR.fasta\nsleep 2\ncat AMTAS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nsleep 2\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTAS_UTR_M0.fasta\nsleep 2\nrm tmp_list.txt AMTAS_UTR.fasta\n#AMTPTU\nseqkit grep --by-seq --max-mismatch 0 --threads ${task.cpus} --pattern \"TCAAGGGGCAATTCGGGCT\" ${seq} > AMTPTU_UTR.fasta\nsleep 2\ncat AMTPTU_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTPTU_UTR_M0.fasta\nsleep 2\nrm tmp_list.txt AMTPTU_UTR.fasta\n\ncat *M0.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > ${sample_id}_list_all_headers_M0.txt\n\"\"\"",
        "nb_lignes_script": 34,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "misMatch0_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "misMatch0_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/misMatch0\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "grep_misMatch1": {
        "name_process": "grep_misMatch1",
        "string_process": "\nprocess grep_misMatch1{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/misMatch1\", mode:'link'\n\n  input:\n  set sample_id, seq from misMatch1_in \n  \n  output:\n  set sample_id, \"${sample_id}_list_all_headers_M1.txt\", \"${sample_id}_AMTS_UTR_M1.fasta\", \"${sample_id}_AMTAS_UTR_M1.fasta\", \"${sample_id}_AMTPTU_UTR_M1.fasta\" into misMatch1_out\n\n  script:\n\"\"\" \n#!/bin/bash\n#Universal TM-PCR\n#AMTS\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGAAGGTGAGTTTA\" ${seq} > AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGTAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGGAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGCAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\ncat AMTS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTS_UTR_M1.fasta\nsleep 2\nrm tmp_list.txt AMTS_UTR.fasta\n#AMTAS\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"AGCCCGGCCAGTCC\" ${seq} > AMTAS_UTR.fasta\nsleep 2\ncat AMTAS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTAS_UTR_M1.fasta\nsleep 2\nrm tmp_list.txt AMTAS_UTR.fasta\n#AMTPTU\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"TCAAGGGGCAATTCGGGCT\" ${seq} > AMTPTU_UTR.fasta\nsleep 2\ncat AMTPTU_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTPTU_UTR_M1.fasta\nsleep 2\nrm tmp_list.txt AMTPTU_UTR.fasta\ncat *M1.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > ${sample_id}_list_all_headers_M1.txt\n\"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "\"\"\" \n#!/bin/bash\n#Universal TM-PCR\n#AMTS\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGAAGGTGAGTTTA\" ${seq} > AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGTAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGGAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"GTGCCGCAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\ncat AMTS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTS_UTR_M1.fasta\nsleep 2\nrm tmp_list.txt AMTS_UTR.fasta\n#AMTAS\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"AGCCCGGCCAGTCC\" ${seq} > AMTAS_UTR.fasta\nsleep 2\ncat AMTAS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTAS_UTR_M1.fasta\nsleep 2\nrm tmp_list.txt AMTAS_UTR.fasta\n#AMTPTU\nseqkit grep --by-seq --max-mismatch 1 --threads ${task.cpus} --pattern \"TCAAGGGGCAATTCGGGCT\" ${seq} > AMTPTU_UTR.fasta\nsleep 2\ncat AMTPTU_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTPTU_UTR_M1.fasta\nsleep 2\nrm tmp_list.txt AMTPTU_UTR.fasta\ncat *M1.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > ${sample_id}_list_all_headers_M1.txt\n\"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "misMatch1_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "misMatch1_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/misMatch1\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "grep_misMatch2": {
        "name_process": "grep_misMatch2",
        "string_process": "\nprocess grep_misMatch2{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/misMatch2\", mode:'link'\n\n  input:\n  set sample_id, seq from misMatch2_in \n  \n  output:\n  set sample_id, \"${sample_id}_list_all_headers_M2.txt\", \"${sample_id}_AMTS_UTR_M2.fasta\", \"${sample_id}_AMTAS_UTR_M2.fasta\", \"${sample_id}_AMTPTU_UTR_M2.fasta\" into misMatch2_out\n\n  script:\n\"\"\" \n#!/bin/bash\n#Universal TM-PCR\n#AMTS\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGAAGGTGAGTTTA\" ${seq} > AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGTAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGGAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGCAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\ncat AMTS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTS_UTR_M2.fasta\nsleep 2\nrm tmp_list.txt AMTS_UTR.fasta\n#AMTAS\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"AGCCCGGCCAGTCC\" ${seq} > AMTAS_UTR.fasta\nsleep 2\ncat AMTAS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTAS_UTR_M2.fasta\nsleep 2\nrm tmp_list.txt AMTAS_UTR.fasta\n#AMTPTU\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"TCAAGGGGCAATTCGGGCT\" ${seq} > AMTPTU_UTR.fasta\nsleep 2\ncat AMTPTU_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTPTU_UTR_M2.fasta\nsleep 2\nrm tmp_list.txt AMTPTU_UTR.fasta\ncat *M2.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > ${sample_id}_list_all_headers_M2.txt\n\"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "\"\"\" \n#!/bin/bash\n#Universal TM-PCR\n#AMTS\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGAAGGTGAGTTTA\" ${seq} > AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGTAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGGAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"GTGCCGCAGGTGAGTTTA\" ${seq} >> AMTS_UTR.fasta\nsleep 2\ncat AMTS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTS_UTR_M2.fasta\nsleep 2\nrm tmp_list.txt AMTS_UTR.fasta\n#AMTAS\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"AGCCCGGCCAGTCC\" ${seq} > AMTAS_UTR.fasta\nsleep 2\ncat AMTAS_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTAS_UTR_M2.fasta\nsleep 2\nrm tmp_list.txt AMTAS_UTR.fasta\n#AMTPTU\nseqkit grep --by-seq --max-mismatch 2 --threads ${task.cpus} --pattern \"TCAAGGGGCAATTCGGGCT\" ${seq} > AMTPTU_UTR.fasta\nsleep 2\ncat AMTPTU_UTR.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > tmp_list.txt\nseqtk subseq ${seq} tmp_list.txt > ${sample_id}_AMTPTU_UTR_M2.fasta\nsleep 2\nrm tmp_list.txt AMTPTU_UTR.fasta\ncat *M2.fasta | grep \">\" | cut -d \">\" -f 2 | awk '!seen[\\$0]++' > ${sample_id}_list_all_headers_M2.txt\n\"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "misMatch2_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "misMatch2_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/misMatch2\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "create_table_misMatch0": {
        "name_process": "create_table_misMatch0",
        "string_process": "\nprocess create_table_misMatch0{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'\n\n  input:\n    set sample_id, list, AMTS_UTR, AMTAS_UTR, AMTPTU_UTR from misMatch0_out\n  \n  output:\n  set sample_id, \"${sample_id}_table_misMatch0.tsv\", list into misMatch0_table_out\n\n  script:\n\"\"\" \n#!/bin/python3\n\nfw = open(\"${sample_id}_table_misMatch0.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nsampleid = \"${sample_id}\"\nf = open(\"${list}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${AMTS_UTR}\", \"r\")\nAMTS = f.readlines()\nf.close()\nf = open(\"${AMTAS_UTR}\", \"r\")\nAMTAS = f.readlines()\nf.close()\nf = open(\"${AMTPTU_UTR}\", \"r\")\nAMTPTU = f.readlines()\nf.close()\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = 0\n    AMTAS_prime = 0\n    AMTPTU_prime = 0\n    for prim_seq in AMTS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTS_prime = 1\n    for prim_seq in AMTAS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTAS_prime = 1\n    for prim_seq in AMTPTU:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTPTU_prime = 1\n\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\nfw.close()\n\"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "\"\"\" \n#!/bin/python3\n\nfw = open(\"${sample_id}_table_misMatch0.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nsampleid = \"${sample_id}\"\nf = open(\"${list}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${AMTS_UTR}\", \"r\")\nAMTS = f.readlines()\nf.close()\nf = open(\"${AMTAS_UTR}\", \"r\")\nAMTAS = f.readlines()\nf.close()\nf = open(\"${AMTPTU_UTR}\", \"r\")\nAMTPTU = f.readlines()\nf.close()\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = 0\n    AMTAS_prime = 0\n    AMTPTU_prime = 0\n    for prim_seq in AMTS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTS_prime = 1\n    for prim_seq in AMTAS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTAS_prime = 1\n    for prim_seq in AMTPTU:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTPTU_prime = 1\n\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\nfw.close()\n\"\"\"",
        "nb_lignes_script": 37,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "misMatch0_out"
        ],
        "nb_inputs": 1,
        "outputs": [
            "misMatch0_table_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "create_table_misMatch1": {
        "name_process": "create_table_misMatch1",
        "string_process": "\nprocess create_table_misMatch1{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'\n\n  input:\n    set sample_id, list, AMTS_UTR, AMTAS_UTR, AMTPTU_UTR from misMatch1_out\n  \n  output:\n  set sample_id, \"${sample_id}_table_misMatch1.tsv\", list into misMatch1_table_out\n\n  script:\n\"\"\" \n#!/bin/python3\n\nfw = open(\"${sample_id}_table_misMatch1.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nsampleid = \"${sample_id}\"\nf = open(\"${list}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${AMTS_UTR}\", \"r\")\nAMTS = f.readlines()\nf.close()\nf = open(\"${AMTAS_UTR}\", \"r\")\nAMTAS = f.readlines()\nf.close()\nf = open(\"${AMTPTU_UTR}\", \"r\")\nAMTPTU = f.readlines()\nf.close()\n\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = 0\n    AMTAS_prime = 0\n    AMTPTU_prime = 0\n    for prim_seq in AMTS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTS_prime = 1\n    for prim_seq in AMTAS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTAS_prime = 1\n    for prim_seq in AMTPTU:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTPTU_prime = 1\n\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\nfw.close()\n\"\"\"\n}",
        "nb_lignes_process": 51,
        "string_script": "\"\"\" \n#!/bin/python3\n\nfw = open(\"${sample_id}_table_misMatch1.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nsampleid = \"${sample_id}\"\nf = open(\"${list}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${AMTS_UTR}\", \"r\")\nAMTS = f.readlines()\nf.close()\nf = open(\"${AMTAS_UTR}\", \"r\")\nAMTAS = f.readlines()\nf.close()\nf = open(\"${AMTPTU_UTR}\", \"r\")\nAMTPTU = f.readlines()\nf.close()\n\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = 0\n    AMTAS_prime = 0\n    AMTPTU_prime = 0\n    for prim_seq in AMTS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTS_prime = 1\n    for prim_seq in AMTAS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTAS_prime = 1\n    for prim_seq in AMTPTU:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTPTU_prime = 1\n\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\nfw.close()\n\"\"\"",
        "nb_lignes_script": 38,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "misMatch1_out"
        ],
        "nb_inputs": 1,
        "outputs": [
            "misMatch1_table_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "create_table_misMatch2": {
        "name_process": "create_table_misMatch2",
        "string_process": "\nprocess create_table_misMatch2{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'\n\n  input:\n    set sample_id, list, AMTS_UTR, AMTAS_UTR, AMTPTU_UTR from misMatch2_out\n  \n  output:\n  set sample_id, \"${sample_id}_table_misMatch2.tsv\", list into misMatch2_table_out\n\n  script:\n\"\"\" \n#!/bin/python3\n\nfw = open(\"${sample_id}_table_misMatch2.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nsampleid = \"${sample_id}\"\nf = open(\"${list}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${AMTS_UTR}\", \"r\")\nAMTS = f.readlines()\nf.close()\nf = open(\"${AMTAS_UTR}\", \"r\")\nAMTAS = f.readlines()\nf.close()\nf = open(\"${AMTPTU_UTR}\", \"r\")\nAMTPTU = f.readlines()\nf.close()\n\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = 0\n    AMTAS_prime = 0\n    AMTPTU_prime = 0\n    for prim_seq in AMTS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTS_prime = 1\n    for prim_seq in AMTAS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTAS_prime = 1\n    for prim_seq in AMTPTU:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTPTU_prime = 1\n\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\nfw.close()\n\"\"\"\n}",
        "nb_lignes_process": 51,
        "string_script": "\"\"\" \n#!/bin/python3\n\nfw = open(\"${sample_id}_table_misMatch2.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nsampleid = \"${sample_id}\"\nf = open(\"${list}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${AMTS_UTR}\", \"r\")\nAMTS = f.readlines()\nf.close()\nf = open(\"${AMTAS_UTR}\", \"r\")\nAMTAS = f.readlines()\nf.close()\nf = open(\"${AMTPTU_UTR}\", \"r\")\nAMTPTU = f.readlines()\nf.close()\n\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = 0\n    AMTAS_prime = 0\n    AMTPTU_prime = 0\n    for prim_seq in AMTS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTS_prime = 1\n    for prim_seq in AMTAS:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTAS_prime = 1\n    for prim_seq in AMTPTU:\n        if seq_id.replace('\\\\n', '') == prim_seq.replace('\\\\n', '').replace('>', ''):\n            AMTPTU_prime = 1\n\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\nfw.close()\n\"\"\"",
        "nb_lignes_script": 38,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "misMatch2_out"
        ],
        "nb_inputs": 1,
        "outputs": [
            "misMatch2_table_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "create_table_all_misMatches": {
        "name_process": "create_table_all_misMatches",
        "string_process": "\nprocess create_table_all_misMatches{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'\n\n  input:\n  set sample_id, table_M0, list_M0, table_M1, list_M1, table_M2, list_M2 from all_misMatches_in\n  \n  output:\n  set sample_id, \"${sample_id}_table_misMatches_combined.tsv\", list_M2 into all_misMatches_table\n  set sample_id, list_M0, list_M1, list_M2 into nr_of_matched_seq\n\n  script:\n\"\"\" \n#!/bin/python3\n\ndef isEmpty(myString):\n    if myString and myString.strip():\n        #Is not empty\n        return False\n    #Is empty\n    return True\n\nfw = open(\"${sample_id}_table_misMatches_combined.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nf = open(\"${list_M2}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${table_M0}\", \"r\")\ntable0 = f.readlines()\nf.close()\nf = open(\"${table_M1}\", \"r\")\ntable1 = f.readlines()\nf.close()\nf = open(\"${table_M2}\", \"r\")\ntable2 = f.readlines()\nf.close()\n\nsampleid = \"${sample_id}\"\n\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = \"-\"\n    AMTAS_prime = \"-\"\n    AMTPTU_prime = \"-\"\n    for t0 in table0:\n        if isEmpty(t0) != True:\n            if str(seq_id) == str(t0.split()[1]):\n                if int(t0.split()[2]) != 0:\n                    AMTS_prime = \"M0\"\n                if int(t0.split()[3]) != 0:\n                    AMTAS_prime = \"M0\"\n                if int(t0.split()[4]) != 0:\n                    AMTPTU_prime = \"M0\"\n    for t0 in table1:\n        if isEmpty(t0) != True:\n            if str(seq_id) == str(t0.split()[1]):\n                if int(t0.split()[2]) != 0 and AMTS_prime != \"M0\":\n                    AMTS_prime = \"M1\"\n                if int(t0.split()[3]) != 0 and AMTAS_prime != \"M0\":\n                    AMTAS_prime = \"M1\"\n                if int(t0.split()[4]) != 0 and AMTPTU_prime != \"M0\":\n                    AMTPTU_prime = \"M1\"\n    for t0 in table2:\n        if isEmpty(t0) != True:\n            if str(seq_id) == str(t0.split()[1]):\n                if int(t0.split()[2]) != 0 and AMTS_prime != \"M0\" and AMTS_prime != \"M1\":\n                    AMTS_prime = \"M2\"\n                if int(t0.split()[3]) != 0 and AMTAS_prime != \"M0\" and AMTAS_prime != \"M1\":\n                    AMTAS_prime = \"M2\"\n                if int(t0.split()[4]) != 0 and AMTPTU_prime != \"M0\" and AMTPTU_prime != \"M1\":\n                    AMTPTU_prime = \"M2\"\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\n\nfw.close()\n\"\"\"\n}",
        "nb_lignes_process": 78,
        "string_script": "\"\"\" \n#!/bin/python3\n\ndef isEmpty(myString):\n    if myString and myString.strip():\n        #Is not empty\n        return False\n    #Is empty\n    return True\n\nfw = open(\"${sample_id}_table_misMatches_combined.tsv\", \"a\")\nheader = \"sample_id\" + \"\\\\t\" + \"seq_id\" + \"\\\\t\" + \"AMTS_UTR\" + \"\\\\t\" + \"AMTAS_UTR\" + \"\\\\t\" + \"AMTPTU_UTR\" + \"\\\\n\"\nfw.write(header)\nf = open(\"${list_M2}\", \"r\")\nf_list = f.readlines()\nf.close()\nf = open(\"${table_M0}\", \"r\")\ntable0 = f.readlines()\nf.close()\nf = open(\"${table_M1}\", \"r\")\ntable1 = f.readlines()\nf.close()\nf = open(\"${table_M2}\", \"r\")\ntable2 = f.readlines()\nf.close()\n\nsampleid = \"${sample_id}\"\n\nfor seq in f_list:\n    seq_id = seq.split()[0].replace('\\\\n', '')\n    AMTS_prime = \"-\"\n    AMTAS_prime = \"-\"\n    AMTPTU_prime = \"-\"\n    for t0 in table0:\n        if isEmpty(t0) != True:\n            if str(seq_id) == str(t0.split()[1]):\n                if int(t0.split()[2]) != 0:\n                    AMTS_prime = \"M0\"\n                if int(t0.split()[3]) != 0:\n                    AMTAS_prime = \"M0\"\n                if int(t0.split()[4]) != 0:\n                    AMTPTU_prime = \"M0\"\n    for t0 in table1:\n        if isEmpty(t0) != True:\n            if str(seq_id) == str(t0.split()[1]):\n                if int(t0.split()[2]) != 0 and AMTS_prime != \"M0\":\n                    AMTS_prime = \"M1\"\n                if int(t0.split()[3]) != 0 and AMTAS_prime != \"M0\":\n                    AMTAS_prime = \"M1\"\n                if int(t0.split()[4]) != 0 and AMTPTU_prime != \"M0\":\n                    AMTPTU_prime = \"M1\"\n    for t0 in table2:\n        if isEmpty(t0) != True:\n            if str(seq_id) == str(t0.split()[1]):\n                if int(t0.split()[2]) != 0 and AMTS_prime != \"M0\" and AMTS_prime != \"M1\":\n                    AMTS_prime = \"M2\"\n                if int(t0.split()[3]) != 0 and AMTAS_prime != \"M0\" and AMTAS_prime != \"M1\":\n                    AMTAS_prime = \"M2\"\n                if int(t0.split()[4]) != 0 and AMTPTU_prime != \"M0\" and AMTPTU_prime != \"M1\":\n                    AMTPTU_prime = \"M2\"\n    str_line = str(sampleid) + \"\\\\t\" + str(seq_id) + \"\\\\t\" + str(AMTS_prime) + \"\\\\t\" + str(AMTAS_prime) + \"\\\\t\" + str(AMTPTU_prime) + \"\\\\n\"\n    fw.write(str_line)\n\nfw.close()\n\"\"\"",
        "nb_lignes_script": 64,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_misMatches_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "all_misMatches_table",
            "nr_of_matched_seq"
        ],
        "nb_outputs": 2,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_misMatch_tables_M0": {
        "name_process": "collect_misMatch_tables_M0",
        "string_process": "\nprocess collect_misMatch_tables_M0{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'\n\ninput:\nfile tables from misMatch0_combine_all_in.map{it[1]}.collect()\n\noutput:\n\nfile \"all_samples_collected_table_misMatches_M0.tsv\" into collected_misMatch_table_M0\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_M0.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_M0.tsv\"\n\tfi\n   \ndone\n\"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_M0.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_M0.tsv\"\n\tfi\n   \ndone\n\"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "misMatch0_combine_all_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_misMatch_table_M0"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_misMatch_tables_M1": {
        "name_process": "collect_misMatch_tables_M1",
        "string_process": "\nprocess collect_misMatch_tables_M1{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'\n\ninput:\nfile tables from misMatch1_combine_all_in.map{it[1]}.collect()\n\noutput:\n\nfile \"all_samples_collected_table_misMatches_M1.tsv\" into collected_misMatch_table_M1\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_M1.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_M1.tsv\"\n\tfi\n   \ndone\n\"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_M1.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_M1.tsv\"\n\tfi\n   \ndone\n\"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "misMatch1_combine_all_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_misMatch_table_M1"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_misMatch_tables_M2": {
        "name_process": "collect_misMatch_tables_M2",
        "string_process": "\nprocess collect_misMatch_tables_M2{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'\n\ninput:\nfile tables from misMatch2_combine_all_in.map{it[1]}.collect()\n\noutput:\n\nfile \"all_samples_collected_table_misMatches_M2.tsv\" into collected_misMatch_table_M2\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_M2.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_M2.tsv\"\n\tfi\n   \ndone\n\"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_M2.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_M2.tsv\"\n\tfi\n   \ndone\n\"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "misMatch2_combine_all_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_misMatch_table_M2"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_misMatch_tables_comb": {
        "name_process": "collect_misMatch_tables_comb",
        "string_process": "\nprocess collect_misMatch_tables_comb{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'\n\ninput:\nfile tables from all_misMatches_table.map{it[1]}.collect()\n\noutput:\n\nfile \"all_samples_collected_table_misMatches_combined.tsv\" into collected_misMatch_table_comb\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_combined.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_combined.tsv\"\n\tfi\n   \ndone\n\"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${tables})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tif [ \"\\$first_elem\" = true ] ; then\n\t\tcat \\$i >> \"all_samples_collected_table_misMatches_combined.tsv\"\n\t\tfirst_elem=false\n\telse\n\t\tcat \\$i | tail -n +2 >> \"all_samples_collected_table_misMatches_combined.tsv\"\n\tfi\n   \ndone\n\"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_misMatches_table"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_misMatch_table_comb"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/tables\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_nr_matched_seq_M0": {
        "name_process": "collect_nr_matched_seq_M0",
        "string_process": "\nprocess collect_nr_matched_seq_M0{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/lists\", mode:'link'\n\ninput:\nfile lists from nr_of_matched_seq_M0.map{it[1]}.collect()\n\noutput:\n\nset \"all_samples_collected_listsM0.txt\", \"nr_of_matched_seq_M0.txt\" into collected_lists_and_nr_of_matched0\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${lists})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tcat \\$i >> \"all_samples_collected_listsM0.txt\"\n   \ndone\n\ncat \"all_samples_collected_listsM0.txt\" | awk '!seen[\\$0]++' | wc -l > \"nr_of_matched_seq_M0.txt\"\n\"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${lists})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfirst_elem=true\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tcat \\$i >> \"all_samples_collected_listsM0.txt\"\n   \ndone\n\ncat \"all_samples_collected_listsM0.txt\" | awk '!seen[\\$0]++' | wc -l > \"nr_of_matched_seq_M0.txt\"\n\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nr_of_matched_seq_M0"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_lists_and_nr_of_matched0"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/lists\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_nr_matched_seq_M1": {
        "name_process": "collect_nr_matched_seq_M1",
        "string_process": "\nprocess collect_nr_matched_seq_M1{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/lists\", mode:'link'\n\ninput:\nfile lists from nr_of_matched_seq_M1.map{it[2]}.collect()\n\noutput:\n\nset \"all_samples_collected_listsM1.txt\", \"nr_of_matched_seq_M1.txt\" into collected_lists_and_nr_of_matched1\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${lists})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tcat \\$i >> \"all_samples_collected_listsM1.txt\"\n   \ndone\n\ncat \"all_samples_collected_listsM1.txt\" | awk '!seen[\\$0]++' | wc -l > \"nr_of_matched_seq_M1.txt\"\n\"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${lists})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tcat \\$i >> \"all_samples_collected_listsM1.txt\"\n   \ndone\n\ncat \"all_samples_collected_listsM1.txt\" | awk '!seen[\\$0]++' | wc -l > \"nr_of_matched_seq_M1.txt\"\n\"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nr_of_matched_seq_M1"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_lists_and_nr_of_matched1"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/lists\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_nr_matched_seq_M2": {
        "name_process": "collect_nr_matched_seq_M2",
        "string_process": "\nprocess collect_nr_matched_seq_M2{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/lists\", mode:'link'\n\ninput:\nfile lists from nr_of_matched_seq_M2.map{it[3]}.collect()\n\noutput:\n\nset \"all_samples_collected_listsM2.txt\", \"nr_of_matched_seq_M2.txt\" into collected_lists_and_nr_of_matched2\n\nscript:\n\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${lists})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tcat \\$i >> \"all_samples_collected_listsM2.txt\"\n   \ndone\n\ncat \"all_samples_collected_listsM2.txt\" | awk '!seen[\\$0]++' | wc -l > \"nr_of_matched_seq_M2.txt\"\n\"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "\"\"\"\nIFS=' ' read -r -a arr <<< \\$(echo ${lists})\nreadarray -t sortedArr < <(for i in \"\\${arr[@]}\"; do echo \"\\$i\"; done | sort)\nfor i in \"\\${sortedArr[@]}\"\ndo\n\tcat \\$i >> \"all_samples_collected_listsM2.txt\"\n   \ndone\n\ncat \"all_samples_collected_listsM2.txt\" | awk '!seen[\\$0]++' | wc -l > \"nr_of_matched_seq_M2.txt\"\n\"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nr_of_matched_seq_M2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_lists_and_nr_of_matched2"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/lists\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_comb": {
        "name_process": "plot_comb",
        "string_process": "\nprocess plot_comb{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'\n\ninput:\nset table, nrOfSeq, list0, nrOfUniqueSeq0, list1, nrOfUniqueSeq1, list2, nrOfUniqueSeq2 from plot_comb_in\n\noutput:\n\nset \"plot_comb.png\", \"plot_comb_with_total_seq.png\" into plot_comb_out\n\nscript:\n\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq0}\", \"r\")\nuniqueSeq0 = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${nrOfUniqueSeq1}\", \"r\")\nuniqueSeq1 = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${nrOfUniqueSeq2}\", \"r\")\nuniqueSeq2 = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\n\nuniqueSeq2 = uniqueSeq2 - uniqueSeq1\nuniqueSeq1 = uniqueSeq1 - uniqueSeq0\n\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nprimer_count_arr0 = [0]*len(header)\nprimer_count_arr1 = [0]*len(header)\nprimer_count_arr2 = [0]*len(header)\n\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if \"M0\" in tmp[i]:\n            primer_count_arr0[i] = primer_count_arr0[i] + 1\n            primer_count_arr[i] = primer_count_arr[i] + 1\n        if \"M1\" in tmp[i]:\n            primer_count_arr1[i] = primer_count_arr1[i] + 1\n            primer_count_arr[i] = primer_count_arr[i] + 1\n        if \"M2\" in tmp[i]:\n            primer_count_arr2[i] = primer_count_arr2[i] + 1\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j]\n            primer_count_arr0[j], primer_count_arr0[j+1] = primer_count_arr0[j+1], primer_count_arr0[j]\n            primer_count_arr1[j], primer_count_arr1[j+1] = primer_count_arr1[j+1], primer_count_arr1[j]  \n            primer_count_arr2[j], primer_count_arr2[j+1] = primer_count_arr2[j+1], primer_count_arr2[j]  \n            header[j], header[j+1] = header[j+1], header[j] \n\ndataset = np.array(primer_count_arr)\ndataset0 = np.array(primer_count_arr0)\ndataset1 = np.array(primer_count_arr1)\ndataset2 = np.array(primer_count_arr2)\n\nfig, ax = plt.subplots(figsize=(20,10))\nwidth = 0.35 \nax.bar(header, dataset0, width, label='M0')\nax.bar(header, dataset1, width, bottom=dataset0, label='M1')\nax.bar(header, dataset2, width, bottom=dataset0+dataset1, label='M2')\nax.set_xticklabels(header,rotation='vertical')\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.legend()\nplt.subplots_adjust(bottom=0.24)\nplt.savefig(\"plot_comb.png\")\n\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nprimer_count_arr0.append(total_seq)\nprimer_count_arr1.append(0)\nprimer_count_arr2.append(0)\nheader.append(\"total_nr_unique_seq\")\nall_unique = uniqueSeq0 + uniqueSeq1 + uniqueSeq2\nprimer_count_arr.append(all_unique)\nprimer_count_arr0.append(uniqueSeq0)\nprimer_count_arr1.append(uniqueSeq1)\nprimer_count_arr2.append(uniqueSeq2)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j]\n            primer_count_arr0[j], primer_count_arr0[j+1] = primer_count_arr0[j+1], primer_count_arr0[j]\n            primer_count_arr1[j], primer_count_arr1[j+1] = primer_count_arr1[j+1], primer_count_arr1[j]  \n            primer_count_arr2[j], primer_count_arr2[j+1] = primer_count_arr2[j+1], primer_count_arr2[j]  \n            header[j], header[j+1] = header[j+1], header[j] \n\n_dataset = np.array(primer_count_arr)\n_dataset0 = np.array(primer_count_arr0)\n_dataset1 = np.array(primer_count_arr1)\n_dataset2 = np.array(primer_count_arr2)\n\nfig, ax = plt.subplots(figsize=(20,10))\nwidth = 0.35 \nax.bar(header, _dataset0, width, label='M0')\nax.bar(header, _dataset1, width, bottom=_dataset0, label='M1')\nax.bar(header, _dataset2, width, bottom=_dataset0+_dataset1, label='M2')\nax.set_xticklabels(header,rotation='vertical')\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.legend()\nplt.subplots_adjust(bottom=0.24)\nplt.savefig(\"plot_comb_with_total_seq.png\")\n\"\"\"\n}",
        "nb_lignes_process": 123,
        "string_script": "\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq0}\", \"r\")\nuniqueSeq0 = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${nrOfUniqueSeq1}\", \"r\")\nuniqueSeq1 = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${nrOfUniqueSeq2}\", \"r\")\nuniqueSeq2 = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\n\nuniqueSeq2 = uniqueSeq2 - uniqueSeq1\nuniqueSeq1 = uniqueSeq1 - uniqueSeq0\n\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nprimer_count_arr0 = [0]*len(header)\nprimer_count_arr1 = [0]*len(header)\nprimer_count_arr2 = [0]*len(header)\n\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if \"M0\" in tmp[i]:\n            primer_count_arr0[i] = primer_count_arr0[i] + 1\n            primer_count_arr[i] = primer_count_arr[i] + 1\n        if \"M1\" in tmp[i]:\n            primer_count_arr1[i] = primer_count_arr1[i] + 1\n            primer_count_arr[i] = primer_count_arr[i] + 1\n        if \"M2\" in tmp[i]:\n            primer_count_arr2[i] = primer_count_arr2[i] + 1\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j]\n            primer_count_arr0[j], primer_count_arr0[j+1] = primer_count_arr0[j+1], primer_count_arr0[j]\n            primer_count_arr1[j], primer_count_arr1[j+1] = primer_count_arr1[j+1], primer_count_arr1[j]  \n            primer_count_arr2[j], primer_count_arr2[j+1] = primer_count_arr2[j+1], primer_count_arr2[j]  \n            header[j], header[j+1] = header[j+1], header[j] \n\ndataset = np.array(primer_count_arr)\ndataset0 = np.array(primer_count_arr0)\ndataset1 = np.array(primer_count_arr1)\ndataset2 = np.array(primer_count_arr2)\n\nfig, ax = plt.subplots(figsize=(20,10))\nwidth = 0.35 \nax.bar(header, dataset0, width, label='M0')\nax.bar(header, dataset1, width, bottom=dataset0, label='M1')\nax.bar(header, dataset2, width, bottom=dataset0+dataset1, label='M2')\nax.set_xticklabels(header,rotation='vertical')\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.legend()\nplt.subplots_adjust(bottom=0.24)\nplt.savefig(\"plot_comb.png\")\n\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nprimer_count_arr0.append(total_seq)\nprimer_count_arr1.append(0)\nprimer_count_arr2.append(0)\nheader.append(\"total_nr_unique_seq\")\nall_unique = uniqueSeq0 + uniqueSeq1 + uniqueSeq2\nprimer_count_arr.append(all_unique)\nprimer_count_arr0.append(uniqueSeq0)\nprimer_count_arr1.append(uniqueSeq1)\nprimer_count_arr2.append(uniqueSeq2)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j]\n            primer_count_arr0[j], primer_count_arr0[j+1] = primer_count_arr0[j+1], primer_count_arr0[j]\n            primer_count_arr1[j], primer_count_arr1[j+1] = primer_count_arr1[j+1], primer_count_arr1[j]  \n            primer_count_arr2[j], primer_count_arr2[j+1] = primer_count_arr2[j+1], primer_count_arr2[j]  \n            header[j], header[j+1] = header[j+1], header[j] \n\n_dataset = np.array(primer_count_arr)\n_dataset0 = np.array(primer_count_arr0)\n_dataset1 = np.array(primer_count_arr1)\n_dataset2 = np.array(primer_count_arr2)\n\nfig, ax = plt.subplots(figsize=(20,10))\nwidth = 0.35 \nax.bar(header, _dataset0, width, label='M0')\nax.bar(header, _dataset1, width, bottom=_dataset0, label='M1')\nax.bar(header, _dataset2, width, bottom=_dataset0+_dataset1, label='M2')\nax.set_xticklabels(header,rotation='vertical')\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.legend()\nplt.subplots_adjust(bottom=0.24)\nplt.savefig(\"plot_comb_with_total_seq.png\")\n\"\"\"",
        "nb_lignes_script": 109,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_comb_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "plot_comb_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_M0": {
        "name_process": "plot_M0",
        "string_process": "\nprocess plot_M0{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'\n\ninput:\nset table, nrOfSeq, list, nrOfUniqueSeq from plot_M0_in\n\noutput:\n\nset \"plot_M0.png\", \"plot_M0_with_total_seq.png\" into plot_M0_out\n\nscript:\n\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq}\", \"r\")\nuniqueSeq = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if int(tmp[i]) != 0:\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M0.png\")\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nheader.append(\"total_nr_unique_seq\")\nprimer_count_arr.append(uniqueSeq)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M0_with_total_seq.png\")\n\"\"\"\n}",
        "nb_lignes_process": 106,
        "string_script": "\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq}\", \"r\")\nuniqueSeq = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if int(tmp[i]) != 0:\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M0.png\")\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nheader.append(\"total_nr_unique_seq\")\nprimer_count_arr.append(uniqueSeq)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M0_with_total_seq.png\")\n\"\"\"",
        "nb_lignes_script": 92,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_M0_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "plot_M0_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_M1": {
        "name_process": "plot_M1",
        "string_process": "\nprocess plot_M1{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'\n\ninput:\nset table, nrOfSeq, list, nrOfUniqueSeq from plot_M1_in\n\noutput:\n\nset \"plot_M1.png\", \"plot_M1_with_total_seq.png\" into plot_M1_out\n\nscript:\n\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq}\", \"r\")\nuniqueSeq = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nprint(f_table)\nprint(header)\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if int(tmp[i]) != 0:\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M1.png\")\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nheader.append(\"total_nr_unique_seq\")\nprimer_count_arr.append(uniqueSeq)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M1_with_total_seq.png\")\n\"\"\"\n}",
        "nb_lignes_process": 108,
        "string_script": "\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq}\", \"r\")\nuniqueSeq = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nprint(f_table)\nprint(header)\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if int(tmp[i]) != 0:\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M1.png\")\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nheader.append(\"total_nr_unique_seq\")\nprimer_count_arr.append(uniqueSeq)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M1_with_total_seq.png\")\n\"\"\"",
        "nb_lignes_script": 94,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_M1_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "plot_M1_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_M2": {
        "name_process": "plot_M2",
        "string_process": "\nprocess plot_M2{\n  tag {\"All\"}\n\n  publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'\n\ninput:\nset table, nrOfSeq, list, nrOfUniqueSeq from plot_M2_in\n\noutput:\n\nset \"plot_M2.png\", \"plot_M2_with_total_seq.png\" into plot_M2_out\n\nscript:\n\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq}\", \"r\")\nuniqueSeq = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nprint(f_table)\nprint(header)\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if int(tmp[i]) != 0:\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M2.png\")\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nheader.append(\"total_nr_unique_seq\")\nprimer_count_arr.append(uniqueSeq)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M2_with_total_seq.png\")\n\"\"\"\n}",
        "nb_lignes_process": 108,
        "string_script": "\"\"\"\n#!/bin/python3\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nf = open(\"${nrOfUniqueSeq}\", \"r\")\nuniqueSeq = int(f.readline().replace(\"\\\\n\", \"\"))\nf.close()\nf = open(\"${table}\", \"r\")\nheader = f.readline().replace(\"\\\\n\", \"\").split('\\t')[2:]\nf_table = f.readlines()\nprint(f_table)\nprint(header)\nf.close()\nf = open(\"${nrOfSeq}\", \"r\")\ntotal_seq = int(f.readline())\nf.close()\nprimer_count_arr = [0]*len(header)\nfor line in f_table:\n    tmp = line.replace(\"\\\\n\", \"\").split('\\t')[2:]\n    for i in range(len(tmp)):\n        if int(tmp[i]) != 0:\n            primer_count_arr[i] = primer_count_arr[i] + 1\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M2.png\")\n\nheader.append(\"total_seq\")\nprimer_count_arr.append(total_seq)\nheader.append(\"total_nr_unique_seq\")\nprimer_count_arr.append(uniqueSeq)\n\nfor i in range(len(primer_count_arr)): \n    for j in range(0, len(primer_count_arr)-i-1): \n        if primer_count_arr[j] < primer_count_arr[j+1]: \n            primer_count_arr[j], primer_count_arr[j+1] = primer_count_arr[j+1], primer_count_arr[j] \n            header[j], header[j+1] = header[j+1], header[j] \n\nx = np.arange(len(header))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(20,10))\nrects1 = ax.bar(x, primer_count_arr, width)\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Number of occurrences')\nax.set_title('Number of occurrences of the most common primer sequences')\nax.set_xticks(x)\nax.set_xticklabels(header,rotation='vertical')\nax.legend().remove()\n\ndef autolabel(rects):\n    #Attach a text label above each bar in *rects*, displaying its height.\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\nautolabel(rects1)\nfig.tight_layout()\nplt.savefig(\"plot_M2_with_total_seq.png\")\n\"\"\"",
        "nb_lignes_script": 94,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_M2_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "plot_M2_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTV-primer-analysis",
        "directive": [
            "tag {\"All\"}",
            "publishDir \"${params.publish_base_dir}/All/plots\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    }
}