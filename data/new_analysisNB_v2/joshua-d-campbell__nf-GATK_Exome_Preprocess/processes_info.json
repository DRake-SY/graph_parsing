{
    "runFastqToSam": {
        "name_process": "runFastqToSam",
        "string_process": "\nprocess runFastqToSam {\n    tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"\n    publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/FastqToSam/\"\n    \n    input:\n    set indivID, sampleID, libraryID, rgID, platform_unit, platform, platform_model, run_date, center, fastqR1, fastqR2 from readPairsFastqToSam\n    \n    output:\n    set indivID, sampleID, libraryID, rgID, file(outfile) into runFastqToSamOutput\n\n    script:\n    outfile = sampleID + \"_\" + libraryID + \"_\" + rgID + \".unaligned.bam\"\n    \n    \"\"\"\n\tjava -Xmx5G -XX:ParallelGCThreads=1 -jar ${PICARD} FastqToSam \\\n\t\tFASTQ=${fastqR1} \\\n\t\tFASTQ2=${fastqR2} \\\n\t\tOUTPUT=${outfile} \\\n\t\tREAD_GROUP_NAME=${rgID} \\\n\t\tSAMPLE_NAME=${sampleID} \\\n\t\tLIBRARY_NAME=${libraryID} \\\n\t\tPLATFORM_UNIT=${platform_unit} \\\n\t\tPLATFORM=${platform} \\\n\t\tPLATFORM_MODEL=${platform_model} \\\n\t\tSEQUENCING_CENTER=${center} \\\n\t\tRUN_DATE=${run_date} \\\n\t\tTMP_DIR=tmp\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    outfile = sampleID + \"_\" + libraryID + \"_\" + rgID + \".unaligned.bam\"\n    \n    \"\"\"\n\tjava -Xmx5G -XX:ParallelGCThreads=1 -jar ${PICARD} FastqToSam \\\n\t\tFASTQ=${fastqR1} \\\n\t\tFASTQ2=${fastqR2} \\\n\t\tOUTPUT=${outfile} \\\n\t\tREAD_GROUP_NAME=${rgID} \\\n\t\tSAMPLE_NAME=${sampleID} \\\n\t\tLIBRARY_NAME=${libraryID} \\\n\t\tPLATFORM_UNIT=${platform_unit} \\\n\t\tPLATFORM=${platform} \\\n\t\tPLATFORM_MODEL=${platform_model} \\\n\t\tSEQUENCING_CENTER=${center} \\\n\t\tRUN_DATE=${run_date} \\\n\t\tTMP_DIR=tmp\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "readPairsFastqToSam"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runFastqToSamOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/FastqToSam/\""
        ],
        "when": "",
        "stub": ""
    },
    "runMarkIlluminaAdapters": {
        "name_process": "runMarkIlluminaAdapters",
        "string_process": "\nprocess runMarkIlluminaAdapters {\n    tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"\n    publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/MarkIlluminaAdapters/\"\n    \n    input:\n    set indivID, sampleID, libraryID, rgID, ubam from runFastqToSamOutput\n    \n    output:\n    set indivID, sampleID, libraryID, rgID, ubam, file(outfile_bam), file(outfile_metrics) into runMarkIlluminaAdaptersOutput\n\t\n    script:\n    outfile_bam = sampleID + \"_\" + libraryID + \"_\" + rgID + \".adapters_marked.bam\"\n    outfile_metrics = sampleID + \"_\" + libraryID + \"_\" + rgID + \"_adapters_metrics.txt\"\n            \n    \"\"\"\n\tjava -Xmx5G -XX:ParallelGCThreads=1 -jar ${PICARD} MarkIlluminaAdapters \\\n\t\tI=${ubam} \\\n\t\tO=${outfile_bam} \\\n\t\tM=${outfile_metrics} \\\n\t\tTMP_DIR=tmp\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    outfile_bam = sampleID + \"_\" + libraryID + \"_\" + rgID + \".adapters_marked.bam\"\n    outfile_metrics = sampleID + \"_\" + libraryID + \"_\" + rgID + \"_adapters_metrics.txt\"\n            \n    \"\"\"\n\tjava -Xmx5G -XX:ParallelGCThreads=1 -jar ${PICARD} MarkIlluminaAdapters \\\n\t\tI=${ubam} \\\n\t\tO=${outfile_bam} \\\n\t\tM=${outfile_metrics} \\\n\t\tTMP_DIR=tmp\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runFastqToSamOutput"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runMarkIlluminaAdaptersOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/MarkIlluminaAdapters/\""
        ],
        "when": "",
        "stub": ""
    },
    "runBWA": {
        "name_process": "runBWA",
        "string_process": "\nprocess runBWA {\n    tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/BWA/\"\n\t\n    input:\n    set indivID, sampleID, libraryID, rgID, ubam, ubamxt, metrics from runMarkIlluminaAdaptersOutput\n    \n    output:\n    set indivID, sampleID, file(outfile_bam) into runBWAOutput\n    \n    script:\n    outfile_bam = sampleID + \"_\" + libraryID + \"_\" + rgID + \".aligned.bam\"\n\t\n    \"\"\"\n\tset -o pipefail\n\tjava -Dsamjdk.buffer_size=131072 -Dsamjdk.compression_level=1 -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:ParallelGCThreads=1 -Xmx5G -jar ${PICARD} SamToFastq \\\n\t\tI=${ubamxt} \\\n\t\tFASTQ=/dev/stdout \\\n\t\tCLIPPING_ATTRIBUTE=XT CLIPPING_ACTION=2 INTERLEAVE=true NON_PF=true \\\n\t\tTMP_DIR=tmp | \\\n\tbwa mem -M -t 14 -p ${REF} /dev/stdin | \\\n\tjava -XX:ParallelGCThreads=1 -Xmx5G -jar ${PICARD} MergeBamAlignment \\\n\t\tALIGNED_BAM=/dev/stdin \\\n\t\tUNMAPPED_BAM=${ubamxt} \\\n\t\tOUTPUT=${outfile_bam} \\\n\t\tR=${REF} CREATE_INDEX=true ADD_MATE_CIGAR=true \\\n\t\tCLIP_ADAPTERS=false \\\n\t\tCLIP_OVERLAPPING_READS=true \\\n\t\tINCLUDE_SECONDARY_ALIGNMENTS=true \\\n\t\tMAX_INSERTIONS_OR_DELETIONS=-1 \\\n\t\tPRIMARY_ALIGNMENT_STRATEGY=MostDistant \\\n\t\tATTRIBUTES_TO_RETAIN=XS \\\n\t\tTMP_DIR=tmp\n\t\t\n\trm -rf tmp\t\n\t\"\"\"\t\n}",
        "nb_lignes_process": 36,
        "string_script": "    outfile_bam = sampleID + \"_\" + libraryID + \"_\" + rgID + \".aligned.bam\"\n\t\n    \"\"\"\n\tset -o pipefail\n\tjava -Dsamjdk.buffer_size=131072 -Dsamjdk.compression_level=1 -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -XX:ParallelGCThreads=1 -Xmx5G -jar ${PICARD} SamToFastq \\\n\t\tI=${ubamxt} \\\n\t\tFASTQ=/dev/stdout \\\n\t\tCLIPPING_ATTRIBUTE=XT CLIPPING_ACTION=2 INTERLEAVE=true NON_PF=true \\\n\t\tTMP_DIR=tmp | \\\n\tbwa mem -M -t 14 -p ${REF} /dev/stdin | \\\n\tjava -XX:ParallelGCThreads=1 -Xmx5G -jar ${PICARD} MergeBamAlignment \\\n\t\tALIGNED_BAM=/dev/stdin \\\n\t\tUNMAPPED_BAM=${ubamxt} \\\n\t\tOUTPUT=${outfile_bam} \\\n\t\tR=${REF} CREATE_INDEX=true ADD_MATE_CIGAR=true \\\n\t\tCLIP_ADAPTERS=false \\\n\t\tCLIP_OVERLAPPING_READS=true \\\n\t\tINCLUDE_SECONDARY_ALIGNMENTS=true \\\n\t\tMAX_INSERTIONS_OR_DELETIONS=-1 \\\n\t\tPRIMARY_ALIGNMENT_STRATEGY=MostDistant \\\n\t\tATTRIBUTES_TO_RETAIN=XS \\\n\t\tTMP_DIR=tmp\n\t\t\n\trm -rf tmp\t\n\t\"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "BWA"
        ],
        "tools_url": [
            "https://bio.tools/bwa"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            }
        ],
        "inputs": [
            "runMarkIlluminaAdaptersOutput"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runBWAOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/BWA/\""
        ],
        "when": "",
        "stub": ""
    },
    "runMarkDuplicates": {
        "name_process": "runMarkDuplicates",
        "string_process": "\nprocess runMarkDuplicates {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/MarkDuplicates\"\n\t\n    input:\n    set indivID, sampleID, aligned_bam_list from runBWAOutput_grouped_by_sample\n    \n    output:\n    set indivID, sampleID, file(outfile_bam), file(outfile_bai) into runMarkDuplicatesOutput\n    set indivID, file(outfile_metrics) into runMarkDuplicatesOutput_QC\n    \n    script:\n    outfile_bam = sampleID + \".dedup.bam\"\n    outfile_bai = sampleID + \".dedup.bai\"\n    outfile_metrics = sampleID + \"_duplicate_metrics.txt\"\t\n\t        \n    \"\"\"\n\tjava -Xmx30g -XX:ParallelGCThreads=5 -Djava.io.tmpdir=tmp/ -jar ${PICARD} MarkDuplicates \\\n\t\tINPUT=${aligned_bam_list.join(\" INPUT=\")} \\\n\t\tOUTPUT=${outfile_bam} \\\n\t\tMETRICS_FILE=${outfile_metrics} \\\n\t\tCREATE_INDEX=true \\\n\t\tTMP_DIR=tmp\n\t\"\"\"  \n}",
        "nb_lignes_process": 24,
        "string_script": "    outfile_bam = sampleID + \".dedup.bam\"\n    outfile_bai = sampleID + \".dedup.bai\"\n    outfile_metrics = sampleID + \"_duplicate_metrics.txt\"\t\n\t        \n    \"\"\"\n\tjava -Xmx30g -XX:ParallelGCThreads=5 -Djava.io.tmpdir=tmp/ -jar ${PICARD} MarkDuplicates \\\n\t\tINPUT=${aligned_bam_list.join(\" INPUT=\")} \\\n\t\tOUTPUT=${outfile_bam} \\\n\t\tMETRICS_FILE=${outfile_metrics} \\\n\t\tCREATE_INDEX=true \\\n\t\tTMP_DIR=tmp\n\t\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runBWAOutput_grouped_by_sample"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runMarkDuplicatesOutput",
            "runMarkDuplicatesOutput_QC"
        ],
        "nb_outputs": 2,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/MarkDuplicates\""
        ],
        "when": "",
        "stub": ""
    },
    "runRealignerTargetCreator": {
        "name_process": "runRealignerTargetCreator",
        "string_process": "\nprocess runRealignerTargetCreator {\n    tag \"${indivID}\"\n    publishDir \"${OUTDIR}/${indivID}/Processing/RealignerTargetCreator/\"\n    \n    input:\n    set indivID, sampleID, dedup_bam_list from runMarkDuplicatesOutput_grouped_by_sample\n    \n    output:\n    set indivID, dedup_bam_list, file(target_file) into runRealignerTargetCreatorOutput\n \t\n    script:\n    target_file = indivID + \"_target_intervals.list\"\n\t        \n    \"\"\"\n\tjava -Xmx25G -XX:ParallelGCThreads=2 -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T RealignerTargetCreator \\\n\t\t-R ${REF} \\\n\t\t-I ${dedup_bam_list.join(\" -I \")} \\\n\t\t-known ${GOLD1} \\\n\t\t-known ${GOLD2} \\\n\t\t-o ${target_file}\n\t\"\"\"  \n}",
        "nb_lignes_process": 22,
        "string_script": "    target_file = indivID + \"_target_intervals.list\"\n\t        \n    \"\"\"\n\tjava -Xmx25G -XX:ParallelGCThreads=2 -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T RealignerTargetCreator \\\n\t\t-R ${REF} \\\n\t\t-I ${dedup_bam_list.join(\" -I \")} \\\n\t\t-known ${GOLD1} \\\n\t\t-known ${GOLD2} \\\n\t\t-o ${target_file}\n\t\"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runMarkDuplicatesOutput_grouped_by_sample"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRealignerTargetCreatorOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}\"",
            "publishDir \"${OUTDIR}/${indivID}/Processing/RealignerTargetCreator/\""
        ],
        "when": "",
        "stub": ""
    },
    "runIndelRealigner": {
        "name_process": "runIndelRealigner",
        "string_process": "\nprocess runIndelRealigner {\n    tag \"${indivID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/Processing/IndelRealigner/\"\n\t    \n    input:\n    set indivID, dedup_bam_list, target_file from runRealignerTargetCreatorOutput\n \t    \n    output:\n    set indivID, file('*.realign.bam') into runIndelRealignerOutput mode flatten\n    set indivID, file('*.realign.bai') into runIndelRealignerBAIOutput \n    \n    script:\n            \n    \"\"\"\n\tjava -Xmx25G -XX:ParallelGCThreads=2 -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T IndelRealigner \\\n\t\t-R ${REF} \\\n\t\t-I ${dedup_bam_list.join(\" -I \")} \\\n\t\t-targetIntervals ${target_file} \\\n\t\t-known ${GOLD1} \\\n\t\t-known ${GOLD2} \\\n                -maxReads 500000 \\\n                --maxReadsInMemory 500000 \\\n\t\t-nWayOut \".realign.bam\"\t\t\n\t\"\"\"  \n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n\tjava -Xmx25G -XX:ParallelGCThreads=2 -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T IndelRealigner \\\n\t\t-R ${REF} \\\n\t\t-I ${dedup_bam_list.join(\" -I \")} \\\n\t\t-targetIntervals ${target_file} \\\n\t\t-known ${GOLD1} \\\n\t\t-known ${GOLD2} \\\n                -maxReads 500000 \\\n                --maxReadsInMemory 500000 \\\n\t\t-nWayOut \".realign.bam\"\t\t\n\t\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runRealignerTargetCreatorOutput"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runIndelRealignerOutput",
            "runIndelRealignerBAIOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}\"",
            "publishDir \"${OUTDIR}/${indivID}/Processing/IndelRealigner/\""
        ],
        "when": "",
        "stub": ""
    },
    "runBaseRecalibrator": {
        "name_process": "runBaseRecalibrator",
        "string_process": "\nprocess runBaseRecalibrator {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/BaseRecalibrator/\"\n\t    \n    input:\n    set indivID, sampleID, realign_bam from runIndelRealignerOutput_split\n    \n    output:\n    set indivID, sampleID, realign_bam, file(recal_table) into runBaseRecalibratorOutput\n    \n    script:\n    recal_table = sampleID + \"_recal_table.txt\" \n       \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx30g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T BaseRecalibrator \\\n\t\t-R ${REF} \\\n\t\t-I ${realign_bam} \\\n\t\t-knownSites ${GOLD1} \\\n\t\t-knownSites ${GOLD2} \\\n\t\t-knownSites ${DBSNP} \\\n\t\t-o ${recal_table}\n\t\"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    recal_table = sampleID + \"_recal_table.txt\" \n       \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx30g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T BaseRecalibrator \\\n\t\t-R ${REF} \\\n\t\t-I ${realign_bam} \\\n\t\t-knownSites ${GOLD1} \\\n\t\t-knownSites ${GOLD2} \\\n\t\t-knownSites ${DBSNP} \\\n\t\t-o ${recal_table}\n\t\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runIndelRealignerOutput_split"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runBaseRecalibratorOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/BaseRecalibrator/\""
        ],
        "when": "",
        "stub": ""
    },
    "runPrintReads": {
        "name_process": "runPrintReads",
        "string_process": "\nprocess runPrintReads {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/\"\n\t    \n    input:\n    set indivID, sampleID, realign_bam, recal_table from runBaseRecalibratorOutput \n\n    output:\n    set indivID, sampleID, file(outfile_bam), file(outfile_bai), file(outfile_bai2) into runPrintReadsOutput_for_DepthOfCoverage, runPrintReadsOutput_for_HC_Metrics, runPrintReadsOutput_for_Multiple_Metrics, runPrintReadsOutput_for_OxoG_Metrics\n    set indivID, sampleID, realign_bam, recal_table into runPrintReadsOutput_for_PostRecal\n            \n    script:\n    outfile_bam = sampleID + \".clean.bam\"\n    outfile_bai = sampleID + \".clean.bai\"\n    outfile_bai2 = sampleID + \".clean.bam.bai\"           \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx25g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T PrintReads \\\n\t\t-R ${REF} \\\n\t\t-I ${realign_bam} \\\n\t\t-BQSR ${recal_table} \\\n\t\t-o ${outfile_bam}\n    samtools index ${outfile_bam}\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    outfile_bam = sampleID + \".clean.bam\"\n    outfile_bai = sampleID + \".clean.bai\"\n    outfile_bai2 = sampleID + \".clean.bam.bai\"           \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx25g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T PrintReads \\\n\t\t-R ${REF} \\\n\t\t-I ${realign_bam} \\\n\t\t-BQSR ${recal_table} \\\n\t\t-o ${outfile_bam}\n    samtools index ${outfile_bam}\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "runBaseRecalibratorOutput"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runPrintReadsOutput_for_DepthOfCoverage",
            "runPrintReadsOutput_for_HC_Metrics",
            "runPrintReadsOutput_for_Multiple_Metrics",
            "runPrintReadsOutput_for_OxoG_Metrics",
            "runPrintReadsOutput_for_PostRecal"
        ],
        "nb_outputs": 5,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/\""
        ],
        "when": "",
        "stub": ""
    },
    "runBaseRecalibratorPostRecal": {
        "name_process": "runBaseRecalibratorPostRecal",
        "string_process": "\nprocess runBaseRecalibratorPostRecal {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/BaseRecalibratorPostRecal/\"\n\t    \n    input:\n    set indivID, sampleID, realign_bam, recal_table from runPrintReadsOutput_for_PostRecal\n    \n    output:\n    set indivID, sampleID, recal_table, file(post_recal_table) into runBaseRecalibratorPostRecalOutput_Analyze\n        \n    script:\n    post_recal_table = sampleID + \"_post_recal_table.txt\" \n       \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T BaseRecalibrator \\\n\t\t-R ${REF} \\\n\t\t-I ${realign_bam} \\\n\t\t-knownSites ${GOLD1} \\\n\t\t-knownSites ${GOLD2} \\\n\t\t-knownSites ${DBSNP} \\\n\t\t-BQSR ${recal_table} \\\n\t\t-o ${post_recal_table}\n\t\"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    post_recal_table = sampleID + \"_post_recal_table.txt\" \n       \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T BaseRecalibrator \\\n\t\t-R ${REF} \\\n\t\t-I ${realign_bam} \\\n\t\t-knownSites ${GOLD1} \\\n\t\t-knownSites ${GOLD2} \\\n\t\t-knownSites ${DBSNP} \\\n\t\t-BQSR ${recal_table} \\\n\t\t-o ${post_recal_table}\n\t\"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runPrintReadsOutput_for_PostRecal"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runBaseRecalibratorPostRecalOutput_Analyze"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/BaseRecalibratorPostRecal/\""
        ],
        "when": "",
        "stub": ""
    },
    "runAnalyzeCovariates": {
        "name_process": "runAnalyzeCovariates",
        "string_process": "\nprocess runAnalyzeCovariates {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/AnalyzeCovariates/\"\n\t    \n    input:\n    set indivID, sampleID, recal_table, post_recal_table from runBaseRecalibratorPostRecalOutput_Analyze\n\n\toutput:\n\tset indivID, sampleID, recal_plots into runAnalyzeCovariatesOutput\n\t    \n    script:\n    recal_plots = sampleID + \"_recal_plots.pdf\" \n\n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T AnalyzeCovariates \\\n\t\t-R ${REF} \\\n\t\t-before ${recal_table} \\\n\t\t-after ${post_recal_table} \\\n\t\t-plots ${recal_plots}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    recal_plots = sampleID + \"_recal_plots.pdf\" \n\n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar ${GATK} \\\n\t\t-T AnalyzeCovariates \\\n\t\t-R ${REF} \\\n\t\t-before ${recal_table} \\\n\t\t-after ${post_recal_table} \\\n\t\t-plots ${recal_plots}\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runBaseRecalibratorPostRecalOutput_Analyze"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runAnalyzeCovariatesOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/AnalyzeCovariates/\""
        ],
        "when": "",
        "stub": ""
    },
    "runDepthOfCoverage": {
        "name_process": "runDepthOfCoverage",
        "string_process": "\nprocess runDepthOfCoverage {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/DepthOfCoverage\"\n\t    \n    input:\n    set indivID, sampleID, bam, bai, bai2 from runPrintReadsOutput_for_DepthOfCoverage\n\n    output:\n    file(\"${prefix}*\") into DepthOfCoverageOutput\n    \n    script:\n    prefix = sampleID + \".\"\n         \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Djava.io.tmpdir=tmp/ -Xmx5g -jar ${GATK} \\\n\t\t-R ${REF} \\\n\t\t-T DepthOfCoverage \\\n\t\t-I ${bam} \\\n\t\t--omitDepthOutputAtEachBase \\\n\t\t-L ${TARGETS} \\\n\t\t-ct 10 -ct 20 -ct 50 -ct 100 \\\n\t\t-o ${sampleID}\n\n\t\"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    prefix = sampleID + \".\"\n         \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Djava.io.tmpdir=tmp/ -Xmx5g -jar ${GATK} \\\n\t\t-R ${REF} \\\n\t\t-T DepthOfCoverage \\\n\t\t-I ${bam} \\\n\t\t--omitDepthOutputAtEachBase \\\n\t\t-L ${TARGETS} \\\n\t\t-ct 10 -ct 20 -ct 50 -ct 100 \\\n\t\t-o ${sampleID}\n\n\t\"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runPrintReadsOutput_for_DepthOfCoverage"
        ],
        "nb_inputs": 1,
        "outputs": [
            "DepthOfCoverageOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/DepthOfCoverage\""
        ],
        "when": "",
        "stub": ""
    },
    "runCollectMultipleMetrics": {
        "name_process": "runCollectMultipleMetrics",
        "string_process": "\nprocess runCollectMultipleMetrics {\n    tag \"${indivID}|${sampleID}\"\n \tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Picard_Metrics\"\n \t    \n    input:\n    set indivID, sampleID, bam, bai, bai2 from runPrintReadsOutput_for_Multiple_Metrics\n\n    output:\n    set indivID, file(\"${prefix}*\") into CollectMultipleMetricsOutput mode flatten\n\n    script:       \n    prefix = sampleID + \".\"\n\n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar $PICARD CollectMultipleMetrics \\\n\t\tPROGRAM=MeanQualityByCycle \\\n\t\tPROGRAM=QualityScoreDistribution \\\n\t\tPROGRAM=CollectAlignmentSummaryMetrics \\\n\t\tPROGRAM=CollectInsertSizeMetrics\\\n\t\tPROGRAM=CollectGcBiasMetrics \\\n\t\tPROGRAM=CollectSequencingArtifactMetrics \\\n\t\tPROGRAM=CollectBaseDistributionByCycle \\\n\t\tPROGRAM=CollectQualityYieldMetrics \\\n\t\tINPUT=${bam} \\\n\t\tREFERENCE_SEQUENCE=${REF} \\\n\t\tDB_SNP=${DBSNP} \\\n\t\tINTERVALS=${BAITS} \\\n\t\tASSUME_SORTED=true \\\n\t\tOUTPUT=${prefix} \\\n\t\tTMP_DIR=tmp\n\t\"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    prefix = sampleID + \".\"\n\n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar $PICARD CollectMultipleMetrics \\\n\t\tPROGRAM=MeanQualityByCycle \\\n\t\tPROGRAM=QualityScoreDistribution \\\n\t\tPROGRAM=CollectAlignmentSummaryMetrics \\\n\t\tPROGRAM=CollectInsertSizeMetrics\\\n\t\tPROGRAM=CollectGcBiasMetrics \\\n\t\tPROGRAM=CollectSequencingArtifactMetrics \\\n\t\tPROGRAM=CollectBaseDistributionByCycle \\\n\t\tPROGRAM=CollectQualityYieldMetrics \\\n\t\tINPUT=${bam} \\\n\t\tREFERENCE_SEQUENCE=${REF} \\\n\t\tDB_SNP=${DBSNP} \\\n\t\tINTERVALS=${BAITS} \\\n\t\tASSUME_SORTED=true \\\n\t\tOUTPUT=${prefix} \\\n\t\tTMP_DIR=tmp\n\t\"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runPrintReadsOutput_for_Multiple_Metrics"
        ],
        "nb_inputs": 1,
        "outputs": [
            "CollectMultipleMetricsOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Picard_Metrics\""
        ],
        "when": "",
        "stub": ""
    },
    "runHybridCaptureMetrics": {
        "name_process": "runHybridCaptureMetrics",
        "string_process": "\nprocess runHybridCaptureMetrics {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Picard_Metrics\"\n\t    \n    input:\n    set indivID, sampleID, bam, bai, bai2 from runPrintReadsOutput_for_HC_Metrics\n\n\toutput:\n\tset indivID, file(outfile) into HybridCaptureMetricsOutput mode flatten\n\n    script:       \n    outfile = sampleID + \".hybrid_selection_metrics.txt\"\n    target_coverage = sampleID + \".target_coverage.txt\"    \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar $PICARD CollectHsMetrics \\\n\t\tINPUT=${bam} \\\n\t\tOUTPUT=${outfile} \\\n\t\tTARGET_INTERVALS=${TARGETS} \\\n\t\tBAIT_INTERVALS=${BAITS} \\\n\t\tREFERENCE_SEQUENCE=${REF} \\\n\t\tPER_TARGET_COVERAGE=${target_coverage} \\\n\t\tTMP_DIR=tmp\n\t\"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    outfile = sampleID + \".hybrid_selection_metrics.txt\"\n    target_coverage = sampleID + \".target_coverage.txt\"    \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar $PICARD CollectHsMetrics \\\n\t\tINPUT=${bam} \\\n\t\tOUTPUT=${outfile} \\\n\t\tTARGET_INTERVALS=${TARGETS} \\\n\t\tBAIT_INTERVALS=${BAITS} \\\n\t\tREFERENCE_SEQUENCE=${REF} \\\n\t\tPER_TARGET_COVERAGE=${target_coverage} \\\n\t\tTMP_DIR=tmp\n\t\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runPrintReadsOutput_for_HC_Metrics"
        ],
        "nb_inputs": 1,
        "outputs": [
            "HybridCaptureMetricsOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Picard_Metrics\""
        ],
        "when": "",
        "stub": ""
    },
    "runOxoGMetrics": {
        "name_process": "runOxoGMetrics",
        "string_process": "\nprocess runOxoGMetrics {\n    tag \"${indivID}|${sampleID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Picard_Metrics\"\n\t    \n    input:\n    set indivID, sampleID, bam, bai, bai2 from runPrintReadsOutput_for_OxoG_Metrics\n\n\toutput:\n\tset indivID, file(outfile) into runOxoGMetricsOutput mode flatten\n\n    script:       \n    outfile = sampleID + \".OxoG_metrics.txt\"\n    \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar $PICARD CollectOxoGMetrics \\\n\t\tINPUT=${bam} \\\n\t\tOUTPUT=${outfile} \\\n\t\tDB_SNP=${DBSNP} \\\n\t\tINTERVALS=${BAITS} \\\n\t\tREFERENCE_SEQUENCE=${REF} \\\n\t\tTMP_DIR=tmp\n\t\"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    outfile = sampleID + \".OxoG_metrics.txt\"\n    \n    \"\"\"\n\tjava -XX:ParallelGCThreads=2 -Xmx5g -Djava.io.tmpdir=tmp/ -jar $PICARD CollectOxoGMetrics \\\n\t\tINPUT=${bam} \\\n\t\tOUTPUT=${outfile} \\\n\t\tDB_SNP=${DBSNP} \\\n\t\tINTERVALS=${BAITS} \\\n\t\tREFERENCE_SEQUENCE=${REF} \\\n\t\tTMP_DIR=tmp\n\t\"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runPrintReadsOutput_for_OxoG_Metrics"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runOxoGMetricsOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Picard_Metrics\""
        ],
        "when": "",
        "stub": ""
    },
    "runFastQC": {
        "name_process": "runFastQC",
        "string_process": "\nprocess runFastQC {\n    tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/FastQC/\"\n\t    \n    input:\n    set indivID, sampleID, libraryID, rgID, platform_unit, platform, platform_model, run_date, center, fastqR1, fastqR2 from readPairsFastQC\n\n    output:\n    set indivID, file(\"*.zip\") into FastQCOutput mode flatten\n   \tfile(\"*.html\") into FastQCOutput2\n   \t\n    script:\n\n    \"\"\"\n    fastqc -t 1 -o . ${fastqR1} ${fastqR2}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    fastqc -t 1 -o . ${fastqR1} ${fastqR2}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "readPairsFastQC"
        ],
        "nb_inputs": 1,
        "outputs": [
            "FastQCOutput",
            "FastQCOutput2"
        ],
        "nb_outputs": 2,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}|${sampleID}|${libraryID}|${rgID}\"",
            "publishDir \"${OUTDIR}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/FastQC/\""
        ],
        "when": "",
        "stub": ""
    },
    "runMultiQCFastq": {
        "name_process": "runMultiQCFastq",
        "string_process": "\nprocess runMultiQCFastq {\n    tag \"${indivID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/QC/Fastq\"\n\t    \n    input:\n    set indivID, zip_files from FastQCOutput_grouped_by_indiv\n    \n    output:\n    set file(\"multiqc_fastq_file_list.txt\"), file(\"fastq_multiqc*\") into runMultiQCFastqOutput\n    \t\n    script:\n     \n    \"\"\"\n    echo -e \"${zip_files.flatten().join('\\n')}\" > multiqc_fastq_file_list.txt\n    multiqc -n fastq_multiqc --file-list multiqc_fastq_file_list.txt\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    echo -e \"${zip_files.flatten().join('\\n')}\" > multiqc_fastq_file_list.txt\n    multiqc -n fastq_multiqc --file-list multiqc_fastq_file_list.txt\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "FastQCOutput_grouped_by_indiv"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runMultiQCFastqOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}\"",
            "publishDir \"${OUTDIR}/${indivID}/QC/Fastq\""
        ],
        "when": "",
        "stub": ""
    },
    "runMultiQCLibrary": {
        "name_process": "runMultiQCLibrary",
        "string_process": "\nprocess runMultiQCLibrary {\n    tag \"${indivID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/QC/Library\"\n\t    \n    input:\n    set indivID, files from runMarkDuplicatesOutput_QC_grouped_by_indiv\n\n    output:\n    set file(\"multiqc_library_file_list.txt\"), file(\"library_multiqc*\") into runMultiQCLibraryOutput\n    \t\n    script:\n    \"\"\"\n    echo -e \"${files.flatten().join('\\n')}\" > multiqc_library_file_list.txt\n    multiqc -n library_multiqc --file-list multiqc_library_file_list.txt\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    echo -e \"${files.flatten().join('\\n')}\" > multiqc_library_file_list.txt\n    multiqc -n library_multiqc --file-list multiqc_library_file_list.txt\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "runMarkDuplicatesOutput_QC_grouped_by_indiv"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runMultiQCLibraryOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}\"",
            "publishDir \"${OUTDIR}/${indivID}/QC/Library\""
        ],
        "when": "",
        "stub": ""
    },
    "runMultiQCSample": {
        "name_process": "runMultiQCSample",
        "string_process": "\nprocess runMultiQCSample {\n    tag \"${indivID}\"\n\tpublishDir \"${OUTDIR}/${indivID}/QC/Sample\"\n\t    \n    input:\n\tset indivID, metrics_files from CollectMultipleMetricsOutput_grouped_by_indiv\n    set indivID, hybrid_files from HybridCaptureMetricsOutput_grouped_by_indiv\n    set indivID, oxog_files from runOxoGMetricsOutput_grouped_by_indiv\n        \n    output:\n    set file(\"sample_multiqc*\"), file(\"multiqc_sample_file_list.txt\") into runMultiQCSampleOutput\n    \t\n    script:\n    \"\"\"\n    echo -e \"${metrics_files.flatten().join('\\n')}\" > multiqc_sample_file_list.txt\n    echo -e \"${hybrid_files.flatten().join('\\n')}\" >> multiqc_sample_file_list.txt\n    echo -e \"${oxog_files.flatten().join('\\n')}\" >> multiqc_sample_file_list.txt\n            \n    multiqc -n sample_multiqc --file-list multiqc_sample_file_list.txt\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    echo -e \"${metrics_files.flatten().join('\\n')}\" > multiqc_sample_file_list.txt\n    echo -e \"${hybrid_files.flatten().join('\\n')}\" >> multiqc_sample_file_list.txt\n    echo -e \"${oxog_files.flatten().join('\\n')}\" >> multiqc_sample_file_list.txt\n            \n    multiqc -n sample_multiqc --file-list multiqc_sample_file_list.txt\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "CollectMultipleMetricsOutput_grouped_by_indiv",
            "HybridCaptureMetricsOutput_grouped_by_indiv",
            "runOxoGMetricsOutput_grouped_by_indiv"
        ],
        "nb_inputs": 3,
        "outputs": [
            "runMultiQCSampleOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "joshua-d-campbell__nf-GATK_Exome_Preprocess",
        "directive": [
            "tag \"${indivID}\"",
            "publishDir \"${OUTDIR}/${indivID}/QC/Sample\""
        ],
        "when": "",
        "stub": ""
    }
}