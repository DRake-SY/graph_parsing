{
    "demultiplex": {
        "name_process": "demultiplex",
        "string_process": " process demultiplex {\n     publishDir \"${params.outdir}/demultiplexed_samples\", mode: 'copy'\n\n     input:\n     file(reads) from multiplexed_reads\n\n     output:\n     file(\"barcode*.fastq\") into reads mode flatten\n\n     script:\n     kit = params.kit\n     \"\"\"\n     qcat -f $reads -k $kit --trim -t ${task.cpus} -b .\n     \"\"\"\n }",
        "nb_lignes_process": 13,
        "string_script": "     kit = params.kit\n     \"\"\"\n     qcat -f $reads -k $kit --trim -t ${task.cpus} -b .\n     \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "KiT",
            "seqCAT"
        ],
        "tools_url": [
            "https://bio.tools/kit",
            "https://bio.tools/seqcat"
        ],
        "tools_dico": [
            {
                "name": "KiT",
                "uri": "https://bio.tools/kit",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3383",
                            "term": "Bioimaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3383",
                            "term": "Biological imaging"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3443",
                                    "term": "Image analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Kinetochore Tracking (KiT) is an open-source software package for tracking kinetochores from live-cell fluorescent movies.",
                "homepage": "https://bitbucket.org/jarmond/kit/overview"
            },
            {
                "name": "seqCAT",
                "uri": "https://bio.tools/seqcat",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package uses variant calling data (in the form of VCF files) from high throughput sequencing technologies to authenticate and validate the source, function and characteristics of biological samples used in scientific endeavours.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/seqCAT.html"
            }
        ],
        "inputs": [
            "multiplexed_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/demultiplexed_samples\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "demultiplex_porechop": {
        "name_process": "demultiplex_porechop",
        "string_process": " process demultiplex_porechop {\n        input:\n        file(reads) from multiplexed_reads_porechop\n\n        output:\n        file(\"BC*.fastq\") into reads mode flatten\n\n        script:\n            \"\"\"\n            porechop -i \"${reads}\" -t 4 -b .\n            \"\"\"\n    }",
        "nb_lignes_process": 10,
        "string_script": "            \"\"\"\n            porechop -i \"${reads}\" -t 4 -b .\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "multiplexed_reads_porechop"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "QC": {
        "name_process": "QC",
        "string_process": "\nprocess QC {\n    input:\n    file(reads) from reads\n\n    output:\n    tuple env(barcode), file(\"*qced_reads_set.fastq\") into reads_fastqc, qc_results \n\n    script:\n    \"\"\"\n    barcode=${reads.baseName}\n    fastp -i $reads -q 8 -l ${params.min_read_length} --length_limit ${params.max_read_length} -o \\$barcode\\\\_qced_reads.fastq\n    #perl prinseq-lite.pl -fastq $reads -out_good qced_reads -min_len 1400 -max_len 1700 -log qc_log -min_qual_mean 8\n    head -n\\$(( ${params.umap_set_size}*4 )) \\$barcode\\\\_qced_reads.fastq > \\$barcode\\\\_qced_reads_set.fastq\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    barcode=${reads.baseName}\n    fastp -i $reads -q 8 -l ${params.min_read_length} --length_limit ${params.max_read_length} -o \\$barcode\\\\_qced_reads.fastq\n    #perl prinseq-lite.pl -fastq $reads -out_good qced_reads -min_len 1400 -max_len 1700 -log qc_log -min_qual_mean 8\n    head -n\\$(( ${params.umap_set_size}*4 )) \\$barcode\\\\_qced_reads.fastq > \\$barcode\\\\_qced_reads_set.fastq\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reads_fastqc",
            "qc_results"
        ],
        "nb_outputs": 2,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n    publishDir \"${params.outdir}/fastqc_rawdata\", mode: 'copy',\n    saveAs: {filename -> filename.indexOf(\".zip\") > 0 ? \"zips/$filename\" : \"$filename\"}\n\n    input:\n    set val(name), file(reads) from reads_fastqc\n\n    output:\n    file \"*_fastqc.{zip,html}\" into fastqc_results\n\n    script:\n    \"\"\"\n    fastqc -q $reads\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    fastqc -q $reads\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "reads_fastqc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/fastqc_rawdata\", mode: 'copy' , saveAs: {filename -> filename.indexOf(\".zip\") > 0 ? \"zips/$filename\" : \"$filename\"}"
        ],
        "when": "",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": " process multiqc {\n        publishDir \"${params.outdir}/MultiQC\", mode: 'copy'\n\n        input:\n        file ('fastqc/*') from fastqc_results.collect().ifEmpty([])\n        \n        output:\n        file \"*multiqc_report.html\"\n        file \"*_data\"\n\n        script:\n        \"\"\"\n        multiqc . \n        \"\"\"\n    }",
        "nb_lignes_process": 13,
        "string_script": "        \"\"\"\n        multiqc . \n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastqc_results"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/MultiQC\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "kmer_freqs": {
        "name_process": "kmer_freqs",
        "string_process": " process kmer_freqs {\n     memory { 7.GB * task.attempt }\n     time { 1.hour * task.attempt }\n     errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n     maxRetries 3\n\n     input:\n     tuple val(barcode), file(qced_reads) from qc_results\n\n     output:\n     file \"freqs.txt\" into freqs\n     tuple val(barcode), file(qced_reads) into freqs_qc_results\n\n     script:   \n     \"\"\"\n     kmer_freq.py -r $qced_reads > freqs.txt\n     \"\"\"\n\n }",
        "nb_lignes_process": 17,
        "string_script": "     \"\"\"\n     kmer_freq.py -r $qced_reads > freqs.txt\n     \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qc_results"
        ],
        "nb_inputs": 1,
        "outputs": [
            "freqs",
            "freqs_qc_results"
        ],
        "nb_outputs": 2,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "memory { 7.GB * task.attempt }",
            "time { 1.hour * task.attempt }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "read_clustering": {
        "name_process": "read_clustering",
        "string_process": " process read_clustering {\n     time { 1.hour * task.attempt }\n     errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n     maxRetries 3\n\n     publishDir \"${params.outdir}/${barcode}/\", mode: 'copy', pattern: 'hdbscan.output.*'\n\n     input:\n     file(kmer_freqs) from freqs\n     tuple val(barcode), file(qced_reads) from freqs_qc_results\n\n     output:\n     tuple val(barcode), file('hdbscan.output.tsv'), file(qced_reads) into clustering_out\n     file('*.png')\n\n     script:\n     template \"umap_hdbscan.py\"\n }",
        "nb_lignes_process": 16,
        "string_script": "     template \"umap_hdbscan.py\"",
        "nb_lignes_script": 0,
        "language_script": "bash",
        "tools": [
            "docxtemplate"
        ],
        "tools_url": [
            "https://bio.tools/docxtemplate"
        ],
        "tools_dico": [
            {
                "name": "docxtemplate",
                "uri": "https://bio.tools/docxtemplate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3314",
                            "term": "Chemistry"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0322",
                                    "term": "Molecular model refinement"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Phenix', 'restraints', 'Amber', 'refinement' | Improved chemistry restraints for crystallographic refinement by integrating the Amber force field into Phenix | Word templates and tools for Windows | The IUCr Word templates utilize the content management features and document styles of Word to format your manuscript and to store essential details for submission of your manuscript",
                "homepage": "http://journals.iucr.org/services/docxtemplate/"
            }
        ],
        "inputs": [
            "freqs",
            "freqs_qc_results"
        ],
        "nb_inputs": 2,
        "outputs": [
            "clustering_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "time { 1.hour * task.attempt }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries 3",
            "publishDir \"${params.outdir}/${barcode}/\", mode: 'copy', pattern: 'hdbscan.output.*'"
        ],
        "when": "",
        "stub": ""
    },
    "split_by_cluster": {
        "name_process": "split_by_cluster",
        "string_process": " process split_by_cluster {\n     input:\n     tuple val(barcode), file(clusters), file(qced_reads) from clustering_out\n\n     output:\n     tuple val(barcode), file('*[0-9]*.log'), file('*[0-9]*.fastq') into cluster_reads mode flatten\n\n     script:\n     \"\"\"\n     sed 's/\\\\srunid.*//g' $qced_reads > only_id_header_readfile.fastq\n     CLUSTERS_CNT=\\$(awk '(\\$5 ~ /[0-9]/) {print \\$5}' $clusters | sort -nr | uniq | head -n1)\n\n     for ((i = 0 ; i <= \\$CLUSTERS_CNT ; i++));\n     do\n        cluster_id=\\$i\n        awk -v cluster=\"\\$cluster_id\" '(\\$5 == cluster) {print \\$1}' $clusters > \\$cluster_id\\\\_ids.txt\n        seqtk subseq only_id_header_readfile.fastq \\$cluster_id\\\\_ids.txt > \\$cluster_id.fastq\n        READ_COUNT=\\$(( \\$(awk '{print \\$1/4}' <(wc -l \\$cluster_id.fastq)) ))\n        echo -n \"\\$cluster_id;\\$READ_COUNT\" > \\$cluster_id.log\n     done\n     \"\"\"\n }",
        "nb_lignes_process": 20,
        "string_script": "     \"\"\"\n     sed 's/\\\\srunid.*//g' $qced_reads > only_id_header_readfile.fastq\n     CLUSTERS_CNT=\\$(awk '(\\$5 ~ /[0-9]/) {print \\$5}' $clusters | sort -nr | uniq | head -n1)\n\n     for ((i = 0 ; i <= \\$CLUSTERS_CNT ; i++));\n     do\n        cluster_id=\\$i\n        awk -v cluster=\"\\$cluster_id\" '(\\$5 == cluster) {print \\$1}' $clusters > \\$cluster_id\\\\_ids.txt\n        seqtk subseq only_id_header_readfile.fastq \\$cluster_id\\\\_ids.txt > \\$cluster_id.fastq\n        READ_COUNT=\\$(( \\$(awk '{print \\$1/4}' <(wc -l \\$cluster_id.fastq)) ))\n        echo -n \"\\$cluster_id;\\$READ_COUNT\" > \\$cluster_id.log\n     done\n     \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "clustering_out"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cluster_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "read_correction": {
        "name_process": "read_correction",
        "string_process": " process read_correction {\n     memory { 7.GB * task.attempt }\n     time { 1.hour * task.attempt }\n     errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n     maxRetries 3\n\n     input:\n     tuple val(barcode), file(cluster_log), file(reads) from cluster_reads\n\n     output:\n      tuple val(barcode), val(cluster_id), file('*_racon_.log'), file('corrected_reads.correctedReads.fasta') into corrected_reads\n\n     script:\n     count=params.polishing_reads\n     cluster_id=cluster_log.baseName\n     \"\"\"\n     head -n\\$(( $count*4 )) $reads > subset.fastq\n     canu -correct -p corrected_reads -nanopore-raw subset.fastq genomeSize=${params.avg_amplicon_size} stopOnLowCoverage=1 minInputCoverage=2 minReadLength=500 minOverlapLength=200\n     gunzip corrected_reads.correctedReads.fasta.gz\n     READ_COUNT=\\$(( \\$(awk '{print \\$1/2}' <(wc -l corrected_reads.correctedReads.fasta)) ))\n     cat $cluster_log > ${cluster_id}_racon.log\n     echo -n \";$count;\\$READ_COUNT;\" >> ${cluster_id}_racon.log && cp ${cluster_id}_racon.log ${cluster_id}_racon_.log\n     \"\"\"\n }",
        "nb_lignes_process": 22,
        "string_script": "     count=params.polishing_reads\n     cluster_id=cluster_log.baseName\n     \"\"\"\n     head -n\\$(( $count*4 )) $reads > subset.fastq\n     canu -correct -p corrected_reads -nanopore-raw subset.fastq genomeSize=${params.avg_amplicon_size} stopOnLowCoverage=1 minInputCoverage=2 minReadLength=500 minOverlapLength=200\n     gunzip corrected_reads.correctedReads.fasta.gz\n     READ_COUNT=\\$(( \\$(awk '{print \\$1/2}' <(wc -l corrected_reads.correctedReads.fasta)) ))\n     cat $cluster_log > ${cluster_id}_racon.log\n     echo -n \";$count;\\$READ_COUNT;\" >> ${cluster_id}_racon.log && cp ${cluster_id}_racon.log ${cluster_id}_racon_.log\n     \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "CANU"
        ],
        "tools_url": [
            "https://bio.tools/canu"
        ],
        "tools_dico": [
            {
                "name": "CANU",
                "uri": "https://bio.tools/canu",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De-novo assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De Bruijn graph"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "Sequence assembly (de-novo assembly)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "De-novo assembly tool for long read chemistry like Nanopore data and PacBio data.",
                "homepage": "https://github.com/marbl/canu"
            }
        ],
        "inputs": [
            "cluster_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "corrected_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "memory { 7.GB * task.attempt }",
            "time { 1.hour * task.attempt }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "draft_selection": {
        "name_process": "draft_selection",
        "string_process": " process draft_selection {\n     publishDir \"${params.outdir}/${barcode}/cluster${cluster_id}\", mode: 'copy', pattern: 'draft_read.fasta'\n     errorStrategy 'retry'\n\n     input:\n     tuple val(barcode), val(cluster_id), file(cluster_log), file(reads) from corrected_reads\n\n     output:\n     tuple val(barcode), val(cluster_id), file('*_draft.log'), file('draft_read.fasta'), file(reads) into draft\n\n     script:\n     \"\"\"\n     split -l 2 $reads split_reads\n     find split_reads* > read_list.txt\n\n     fastANI --ql read_list.txt --rl read_list.txt -o fastani_output.ani -t 48 -k 16 --fragLen 160\n\n     DRAFT=\\$(awk 'NR>1{name[\\$1] = \\$1; arr[\\$1] += \\$3; count[\\$1] += 1}  END{for (a in arr) {print arr[a] / count[a], name[a] }}' fastani_output.ani | sort -rg | cut -d \" \" -f2 | head -n1)\n     cat \\$DRAFT > draft_read.fasta\n     ID=\\$(head -n1 draft_read.fasta | sed 's/>//g')\n     cat $cluster_log > ${cluster_id}_draft.log\n     echo -n \\$ID >> ${cluster_id}_draft.log\n    \"\"\"\n }",
        "nb_lignes_process": 22,
        "string_script": "     \"\"\"\n     split -l 2 $reads split_reads\n     find split_reads* > read_list.txt\n\n     fastANI --ql read_list.txt --rl read_list.txt -o fastani_output.ani -t 48 -k 16 --fragLen 160\n\n     DRAFT=\\$(awk 'NR>1{name[\\$1] = \\$1; arr[\\$1] += \\$3; count[\\$1] += 1}  END{for (a in arr) {print arr[a] / count[a], name[a] }}' fastani_output.ani | sort -rg | cut -d \" \" -f2 | head -n1)\n     cat \\$DRAFT > draft_read.fasta\n     ID=\\$(head -n1 draft_read.fasta | sed 's/>//g')\n     cat $cluster_log > ${cluster_id}_draft.log\n     echo -n \\$ID >> ${cluster_id}_draft.log\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "corrected_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "draft"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/${barcode}/cluster${cluster_id}\", mode: 'copy', pattern: 'draft_read.fasta'",
            "errorStrategy 'retry'"
        ],
        "when": "",
        "stub": ""
    },
    "racon_pass": {
        "name_process": "racon_pass",
        "string_process": " process racon_pass {\n     memory { 7.GB * task.attempt }\n     time { 1.hour * task.attempt }\n     errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n     maxRetries 3\n\n     input:\n     tuple val(barcode), val(cluster_id), file(cluster_log), file(draft_read), file(corrected_reads) from draft\n\n     output:\n     tuple val(barcode), val(cluster_id), file(cluster_log), file('racon_consensus.fasta'), file(corrected_reads), env(success) into racon_output\n\n     script:\n     \"\"\"\n     success=1\n     minimap2 -ax map-ont --no-long-join -r100 -a $draft_read $corrected_reads -o aligned.sam\n     if racon --quality-threshold=9 -w 250 $corrected_reads aligned.sam $draft_read > racon_consensus.fasta ; then\n        success=1\n     else\n        success=0\n        cat $draft_read > racon_consensus.fasta\n     fi\n\n     \"\"\"\n }",
        "nb_lignes_process": 23,
        "string_script": "     \"\"\"\n     success=1\n     minimap2 -ax map-ont --no-long-join -r100 -a $draft_read $corrected_reads -o aligned.sam\n     if racon --quality-threshold=9 -w 250 $corrected_reads aligned.sam $draft_read > racon_consensus.fasta ; then\n        success=1\n     else\n        success=0\n        cat $draft_read > racon_consensus.fasta\n     fi\n\n     \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "Minimap2"
        ],
        "tools_url": [
            "https://bio.tools/minimap2"
        ],
        "tools_dico": [
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            }
        ],
        "inputs": [
            "draft"
        ],
        "nb_inputs": 1,
        "outputs": [
            "racon_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "memory { 7.GB * task.attempt }",
            "time { 1.hour * task.attempt }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "medaka_pass": {
        "name_process": "medaka_pass",
        "string_process": " process medaka_pass {\n     memory { 7.GB * task.attempt }\n     time { 1.hour * task.attempt }\n     errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n     maxRetries 3\n\n     publishDir \"${params.outdir}/${barcode}/cluster${cluster_id}\", mode: 'copy', pattern: 'consensus_medaka.fasta/consensus.fasta' \n\n     input:\n     tuple val(barcode), val(cluster_id), file(cluster_log), file(draft), file(corrected_reads), val(success) from racon_output\n\n     output:\n     tuple val(barcode), val(cluster_id), file(cluster_log), file('consensus_medaka.fasta/consensus.fasta') into final_consensus\n\n     script:\n     if(success == \"0\"){\n        log.warn \"\"\"Sample $barcode : Racon correction for cluster $cluster_id failed due to not enough overlaps. Taking draft read as consensus\"\"\"\n        racon_warnings.add(\"\"\"Sample $barcode : Racon correction for cluster $cluster_id failed due to not enough overlaps. Taking draft read as consensus\"\"\")\n     }\n     \"\"\"\n     if medaka_consensus -i $corrected_reads -d $draft -o consensus_medaka.fasta -t 4 -m r941_min_high_g303 ; then\n        echo \"Command succeeded\"\n     else\n        cat $draft > consensus_medaka.fasta\n     fi\n     \"\"\"\n\n }",
        "nb_lignes_process": 26,
        "string_script": "     if(success == \"0\"){\n        log.warn \"\"\"Sample $barcode : Racon correction for cluster $cluster_id failed due to not enough overlaps. Taking draft read as consensus\"\"\"\n        racon_warnings.add(\"\"\"Sample $barcode : Racon correction for cluster $cluster_id failed due to not enough overlaps. Taking draft read as consensus\"\"\")\n     }\n     \"\"\"\n     if medaka_consensus -i $corrected_reads -d $draft -o consensus_medaka.fasta -t 4 -m r941_min_high_g303 ; then\n        echo \"Command succeeded\"\n     else\n        cat $draft > consensus_medaka.fasta\n     fi\n     \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "racon_output"
        ],
        "nb_inputs": 1,
        "outputs": [
            "final_consensus"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "memory { 7.GB * task.attempt }",
            "time { 1.hour * task.attempt }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries 3",
            "publishDir \"${params.outdir}/${barcode}/cluster${cluster_id}\", mode: 'copy', pattern: 'consensus_medaka.fasta/consensus.fasta'"
        ],
        "when": "",
        "stub": ""
    },
    "consensus_classification": {
        "name_process": "consensus_classification",
        "string_process": " process consensus_classification {\n     publishDir \"${params.outdir}/${barcode}/cluster${cluster_id}\", mode: 'copy', pattern: 'consensus_classification.csv'\n     time '3m'\n     errorStrategy { sleep(1000); return 'retry' }\n     maxRetries 5\n\n     input:\n     tuple val(barcode), val(cluster_id), file(cluster_log), file(consensus) from final_consensus\n\n     output:\n     file('consensus_classification.csv')\n     tuple val(barcode), file('*_blast.log') into classifications_ch\n\n     script:\n     db = resolve_blast_db_path(params.db)\n     taxdb = resolve_blast_db_path(params.tax)\n\n     if(!params.db)\n        \"\"\"\n        blastn -query $consensus -db nr -remote -entrez_query \"Bacteria [Organism]\" -task blastn -dust no -outfmt \"10 staxids sscinames evalue length score pident\" -evalue 11 -max_hsps 50 -max_target_seqs 5 > consensus_classification.csv\n        cat $cluster_log > ${cluster_id}_blast.log\n        echo -n \";\" >> ${cluster_id}_blast.log\n        BLAST_OUT=\\$(cut -d\";\" -f1,2,4,5 consensus_classification.csv | head -n1)\n        echo \\$BLAST_OUT >> ${cluster_id}_blast.log\n        \"\"\"\n\n    else\n        \"\"\"\n        export BLASTDB=\n        export BLASTDB=\\$BLASTDB:$taxdb\n        blastn -query $consensus -db $db -task blastn -dust no -outfmt \"10 sscinames staxids evalue length pident\" -evalue 11 -max_hsps 50 -max_target_seqs 5 | sed 's/,/;/g' > consensus_classification.csv\n        #DECIDE FINAL CLASSIFFICATION\n        cat $cluster_log > ${cluster_id}_blast.log\n        echo -n \";\" >> ${cluster_id}_blast.log\n        BLAST_OUT=\\$(cut -d\";\" -f1,2,4,5 consensus_classification.csv | head -n1)\n        echo \\$BLAST_OUT >> ${cluster_id}_blast.log\n        \"\"\"\n }",
        "nb_lignes_process": 36,
        "string_script": "     db = resolve_blast_db_path(params.db)\n     taxdb = resolve_blast_db_path(params.tax)\n\n     if(!params.db)\n        \"\"\"\n        blastn -query $consensus -db nr -remote -entrez_query \"Bacteria [Organism]\" -task blastn -dust no -outfmt \"10 staxids sscinames evalue length score pident\" -evalue 11 -max_hsps 50 -max_target_seqs 5 > consensus_classification.csv\n        cat $cluster_log > ${cluster_id}_blast.log\n        echo -n \";\" >> ${cluster_id}_blast.log\n        BLAST_OUT=\\$(cut -d\";\" -f1,2,4,5 consensus_classification.csv | head -n1)\n        echo \\$BLAST_OUT >> ${cluster_id}_blast.log\n        \"\"\"\n\n    else\n        \"\"\"\n        export BLASTDB=\n        export BLASTDB=\\$BLASTDB:$taxdb\n        blastn -query $consensus -db $db -task blastn -dust no -outfmt \"10 sscinames staxids evalue length pident\" -evalue 11 -max_hsps 50 -max_target_seqs 5 | sed 's/,/;/g' > consensus_classification.csv\n        #DECIDE FINAL CLASSIFFICATION\n        cat $cluster_log > ${cluster_id}_blast.log\n        echo -n \";\" >> ${cluster_id}_blast.log\n        BLAST_OUT=\\$(cut -d\";\" -f1,2,4,5 consensus_classification.csv | head -n1)\n        echo \\$BLAST_OUT >> ${cluster_id}_blast.log\n        \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "ODB",
            "G-BLASTN"
        ],
        "tools_url": [
            "https://bio.tools/odb",
            "https://bio.tools/g-blastn"
        ],
        "tools_dico": [
            {
                "name": "ODB",
                "uri": "https://bio.tools/odb",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0114",
                            "term": "Gene structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0114",
                            "term": "Gene features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0435",
                                    "term": "Operon prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0579",
                                    "term": "Operon drawing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0308",
                                    "term": "PCR primer design"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Over-representation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0579",
                                    "term": "Operon rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0308",
                                    "term": "PCR primer prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0308",
                                    "term": "Primer design"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Contains all known and conserved operons in completely sequenced genomes.",
                "homepage": "http://operondb.jp/"
            },
            {
                "name": "G-BLASTN",
                "uri": "https://bio.tools/g-blastn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0346",
                                    "term": "Sequence similarity search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2976",
                                "term": "Protein sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0857",
                                "term": "Sequence search results"
                            }
                        ]
                    }
                ],
                "description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "homepage": "http://www.comp.hkbu.edu.hk/~chxw/software/G-BLASTN.html"
            }
        ],
        "inputs": [
            "final_consensus"
        ],
        "nb_inputs": 1,
        "outputs": [
            "classifications_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/${barcode}/cluster${cluster_id}\", mode: 'copy', pattern: 'consensus_classification.csv'",
            "time '3m'",
            "errorStrategy { sleep(1000); return 'retry' }",
            "maxRetries 5"
        ],
        "when": "",
        "stub": ""
    },
    "join_results": {
        "name_process": "join_results",
        "string_process": " process join_results {\n     publishDir \"${params.outdir}/${barcode}\", mode: 'copy'\n\n     input:\n     tuple val(barcode), file(logs) from classifications_ch.groupTuple()\n\n     output:\n     tuple val(barcode), file('*.nanoclust_out.txt') into output_table_ch\n\n     script:\n     \"\"\"\n     echo \"id;reads_in_cluster;used_for_consensus;reads_after_corr;draft_id;sciname;taxid;length;per_ident\" > ${barcode}.nanoclust_out.txt\n\n     for i in $logs; do\n        cat \\$i >> ${barcode}.nanoclust_out.txt\n     done\n     \"\"\"\n     \n }",
        "nb_lignes_process": 17,
        "string_script": "     \"\"\"\n     echo \"id;reads_in_cluster;used_for_consensus;reads_after_corr;draft_id;sciname;taxid;length;per_ident\" > ${barcode}.nanoclust_out.txt\n\n     for i in $logs; do\n        cat \\$i >> ${barcode}.nanoclust_out.txt\n     done\n     \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "classifications_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "output_table_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/${barcode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "get_abundances": {
        "name_process": "get_abundances",
        "string_process": "\nprocess get_abundances {\n    publishDir \"${params.outdir}/${barcode}\", mode: 'copy'\n\n    input:\n    tuple val(barcode), file(table) from output_table_ch\n\n    output:\n    tuple val(barcode), file('*.csv') into abundance_table_ch mode flatten\n\n    script:\n    template \"get_abundance.py\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    template \"get_abundance.py\"",
        "nb_lignes_script": 0,
        "language_script": "bash",
        "tools": [
            "docxtemplate"
        ],
        "tools_url": [
            "https://bio.tools/docxtemplate"
        ],
        "tools_dico": [
            {
                "name": "docxtemplate",
                "uri": "https://bio.tools/docxtemplate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3314",
                            "term": "Chemistry"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0322",
                                    "term": "Molecular model refinement"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Phenix', 'restraints', 'Amber', 'refinement' | Improved chemistry restraints for crystallographic refinement by integrating the Amber force field into Phenix | Word templates and tools for Windows | The IUCr Word templates utilize the content management features and document styles of Word to format your manuscript and to store essential details for submission of your manuscript",
                "homepage": "http://journals.iucr.org/services/docxtemplate/"
            }
        ],
        "inputs": [
            "output_table_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "abundance_table_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/${barcode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_abundances": {
        "name_process": "plot_abundances",
        "string_process": "\nprocess plot_abundances {\n    publishDir \"${params.outdir}/${barcode}\", mode: 'copy'\n\n    input:\n    tuple val(barcode), file(table) from abundance_table_ch\n\n    output:\n    file(\"*.png\")\n\n    script:\n    template \"plot_abundances_pool.py\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    template \"plot_abundances_pool.py\"",
        "nb_lignes_script": 0,
        "language_script": "bash",
        "tools": [
            "docxtemplate"
        ],
        "tools_url": [
            "https://bio.tools/docxtemplate"
        ],
        "tools_dico": [
            {
                "name": "docxtemplate",
                "uri": "https://bio.tools/docxtemplate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3314",
                            "term": "Chemistry"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0322",
                                    "term": "Molecular model refinement"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Phenix', 'restraints', 'Amber', 'refinement' | Improved chemistry restraints for crystallographic refinement by integrating the Amber force field into Phenix | Word templates and tools for Windows | The IUCr Word templates utilize the content management features and document styles of Word to format your manuscript and to store essential details for submission of your manuscript",
                "homepage": "http://journals.iucr.org/services/docxtemplate/"
            }
        ],
        "inputs": [
            "abundance_table_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/${barcode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "output_documentation": {
        "name_process": "output_documentation",
        "string_process": "\nprocess output_documentation {\n    publishDir \"${params.outdir}/pipeline_info\", mode: 'copy'\n\n    input:\n    file output_docs from ch_output_docs\n\n    output:\n    file \"results_description.html\"\n\n    script:\n    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_output_docs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "genomicsITER__NanoCLUST",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}