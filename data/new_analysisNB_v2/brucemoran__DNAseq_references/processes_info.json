{
    "fasta_dl": {
        "name_process": "fasta_dl",
        "string_process": "\nprocess fasta_dl {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n  validExitStatus 0,1,2\n  errorStrategy 'retry'\n  maxRetries 3\n\n  output:\n  tuple file('*noChr.fasta'), file('*noChr.fasta.fai') into (fasta_bwa, fasta_seqza, fasta_msi, fasta_dict, fasta_2bit, fasta_exome_biall, fasta_wgs_biall)\n\n  script:\n  if( params.version == 'GRCh37' )\n    \"\"\"\n    ##http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use\n    gsutil cp ${params.gsurl37}/human_g1k_v37.fasta.gz ./human_g1k_v37.fasta.gz\n    gunzip -c human_g1k_v37.fasta.gz | sed 's/>chr/>/g' > human_g1k_v37.noChr.fasta\n    samtools faidx human_g1k_v37.noChr.fasta\n    \"\"\"\n\n  else\n    \"\"\"\n    ##http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use\n    ##moved to Verily as gs bucket more reliable\n    gsutil cp gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa ./\n    cat GRCh38_Verily_v1.genome.fa | sed 's/>chr/>/g' > GRCh38_Verily_v1.genome.noChr.fasta\n    samtools faidx GRCh38_Verily_v1.genome.noChr.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "  if( params.version == 'GRCh37' )\n    \"\"\"\n    ##http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use\n    gsutil cp ${params.gsurl37}/human_g1k_v37.fasta.gz ./human_g1k_v37.fasta.gz\n    gunzip -c human_g1k_v37.fasta.gz | sed 's/>chr/>/g' > human_g1k_v37.noChr.fasta\n    samtools faidx human_g1k_v37.noChr.fasta\n    \"\"\"\n\n  else\n    \"\"\"\n    ##http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use\n    ##moved to Verily as gs bucket more reliable\n    gsutil cp gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa ./\n    cat GRCh38_Verily_v1.genome.fa | sed 's/>chr/>/g' > GRCh38_Verily_v1.genome.noChr.fasta\n    samtools faidx GRCh38_Verily_v1.genome.noChr.fasta\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "NGSUtils",
            "SynChr",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/ngsutils",
            "https://bio.tools/synchr",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "NGSUtils",
                "uri": "https://bio.tools/ngsutils",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3187",
                                    "term": "Sequence contamination filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NGSUtils is a suite of software tools for working with next-generation sequencing datasets",
                "homepage": "http://ngsutils.org"
            },
            {
                "name": "SynChr",
                "uri": "https://bio.tools/synchr",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0283",
                                    "term": "Linkage analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A Fast and Easy Tool to Reconstruct and Visualize Synteny Blocks along Eukaryotic Chromosomes.",
                "homepage": "http://www.lcqb.upmc.fr/CHROnicle/SynChro.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\"",
            "validExitStatus 0,1,2",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "dict_pr": {
        "name_process": "dict_pr",
        "string_process": "\nprocess dict_pr {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n\n  input:\n  tuple file(fa), file(fai) from fasta_dict\n\n  output:\n  file('*.dict') into dict_win\n  tuple file(fa), file(fai), file('*.dict') into (fasta_dict_exome, fasta_dict_wgs, fasta_dict_gensiz, fasta_dict_gridss)\n\n  \"\"\"\n  DICTO=\\$(echo $fa | sed 's/fasta/dict/')\n  picard CreateSequenceDictionary \\\n    R=$fa \\\n    O=\\$DICTO\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n  DICTO=\\$(echo $fa | sed 's/fasta/dict/')\n  picard CreateSequenceDictionary \\\n    R=$fa \\\n    O=\\$DICTO\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "fasta_dict"
        ],
        "nb_inputs": 1,
        "outputs": [
            "dict_win",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "dbsnp_dl": {
        "name_process": "dbsnp_dl",
        "string_process": "\nprocess dbsnp_dl {\n\n  validExitStatus 0,1,2\n  errorStrategy 'retry'\n  maxRetries 3\n\n  output:\n  file('*.vcf') into vcf_tabix\n  file('KG_phase1.snps.high_confidence.*.vcf') into ascatloci\n\n  when:\n  !params.nodbsnp\n\n  script:\n  if( params.version == 'GRCh37' )\n    \"\"\"\n    gsutil cp ${params.gsurl37}/1000G_phase1.snps.high_confidence.b37.vcf.gz ./KG_phase1.snps.high_confidence.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/dbsnp_138.b37.vcf.gz ./dbsnp_138.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/hapmap_3.3.b37.vcf.gz ./hapmap_3.3.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/1000G_omni2.5.b37.vcf.gz ./KG_omni2.5.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/Mills_and_1000G_gold_standard.indels.b37.vcf.gz ./Mills_KG_gold.indels.b37.vcf.gz\n\n    gunzip -cd dbsnp_138.b37.vcf.gz | sed 's/chr//g' > dbsnp_138.b37.vcf\n    gunzip -cd hapmap_3.3.b37.vcf.gz | sed 's/chr//g' > hapmap_3.3.b37.sites.vcf\n    gunzip -cd KG_omni2.5.b37.vcf.gz | sed 's/chr//g' > KG_omni2.5.b37.vcf\n    gunzip -cd KG_phase1.snps.high_confidence.b37.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.b37.vcf\n    gunzip -cd Mills_KG_gold.indels.b37.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.b37.vcf\n    \"\"\"\n  else\n    \"\"\"\n    gsutil cp gs://genomics-public-data/cwl-examples/gdc-dnaseq-cwl/input/dbsnp_144.hg38.vcf.gz ./dbsnp_144.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/1000G_phase1.snps.high_confidence.hg38.vcf.gz ./KG_phase1.snps.high_confidence.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/Homo_sapiens_assembly38.dbsnp138.vcf ./Homo_sapiens_assembly38.dbsnp138.vcf\n    gsutil cp ${params.gsurl38}/hapmap_3.3.hg38.vcf.gz ./hapmap_3.3.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/1000G_omni2.5.hg38.vcf.gz ./KG_omni2.5.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz ./Mills_KG_gold.indels.hg38.vcf.gz\n\n    gunzip -cd dbsnp_144.hg38.vcf.gz | sed 's/chr//g' > dbsnp_144.hg38.vcf\n    gunzip -cd hapmap_3.3.hg38.vcf.gz | sed 's/chr//g' > hapmap_3.3.hg38.vcf\n    gunzip -cd KG_omni2.5.hg38.vcf.gz | sed 's/chr//g' > KG_omni2.5.hg38.vcf\n    gunzip -cd KG_phase1.snps.high_confidence.hg38.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.hg38.vcf\n    gunzip -cd Mills_KG_gold.indels.hg38.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.hg38.vcf\n    \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "  if( params.version == 'GRCh37' )\n    \"\"\"\n    gsutil cp ${params.gsurl37}/1000G_phase1.snps.high_confidence.b37.vcf.gz ./KG_phase1.snps.high_confidence.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/dbsnp_138.b37.vcf.gz ./dbsnp_138.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/hapmap_3.3.b37.vcf.gz ./hapmap_3.3.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/1000G_omni2.5.b37.vcf.gz ./KG_omni2.5.b37.vcf.gz\n    gsutil cp ${params.gsurl37}/Mills_and_1000G_gold_standard.indels.b37.vcf.gz ./Mills_KG_gold.indels.b37.vcf.gz\n\n    gunzip -cd dbsnp_138.b37.vcf.gz | sed 's/chr//g' > dbsnp_138.b37.vcf\n    gunzip -cd hapmap_3.3.b37.vcf.gz | sed 's/chr//g' > hapmap_3.3.b37.sites.vcf\n    gunzip -cd KG_omni2.5.b37.vcf.gz | sed 's/chr//g' > KG_omni2.5.b37.vcf\n    gunzip -cd KG_phase1.snps.high_confidence.b37.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.b37.vcf\n    gunzip -cd Mills_KG_gold.indels.b37.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.b37.vcf\n    \"\"\"\n  else\n    \"\"\"\n    gsutil cp gs://genomics-public-data/cwl-examples/gdc-dnaseq-cwl/input/dbsnp_144.hg38.vcf.gz ./dbsnp_144.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/1000G_phase1.snps.high_confidence.hg38.vcf.gz ./KG_phase1.snps.high_confidence.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/Homo_sapiens_assembly38.dbsnp138.vcf ./Homo_sapiens_assembly38.dbsnp138.vcf\n    gsutil cp ${params.gsurl38}/hapmap_3.3.hg38.vcf.gz ./hapmap_3.3.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/1000G_omni2.5.hg38.vcf.gz ./KG_omni2.5.hg38.vcf.gz\n    gsutil cp ${params.gsurl38}/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz ./Mills_KG_gold.indels.hg38.vcf.gz\n\n    gunzip -cd dbsnp_144.hg38.vcf.gz | sed 's/chr//g' > dbsnp_144.hg38.vcf\n    gunzip -cd hapmap_3.3.hg38.vcf.gz | sed 's/chr//g' > hapmap_3.3.hg38.vcf\n    gunzip -cd KG_omni2.5.hg38.vcf.gz | sed 's/chr//g' > KG_omni2.5.hg38.vcf\n    gunzip -cd KG_phase1.snps.high_confidence.hg38.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.hg38.vcf\n    gunzip -cd Mills_KG_gold.indels.hg38.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.hg38.vcf\n    \"\"\"",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [
            "NGSUtils"
        ],
        "tools_url": [
            "https://bio.tools/ngsutils"
        ],
        "tools_dico": [
            {
                "name": "NGSUtils",
                "uri": "https://bio.tools/ngsutils",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3187",
                                    "term": "Sequence contamination filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NGSUtils is a suite of software tools for working with next-generation sequencing datasets",
                "homepage": "http://ngsutils.org"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "vcf_tabix",
            "ascatloci"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "validExitStatus 0,1,2",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "!params.nodbsnp",
        "stub": ""
    },
    "ascat_loci": {
        "name_process": "ascat_loci",
        "string_process": "\nprocess ascat_loci {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n\n  input:\n  file(vcf) from ascatloci\n\n  output:\n  file('*loci') into complete_ascat\n\n  script:\n  \"\"\"\n  LOCIFILE=\\$(echo $vcf | sed 's/vcf/maf0.3.loci/')\n  cat $vcf | \\\n  perl -ane '@s=split(/[=\\\\;]/,\\$F[7]);if(\\$s[3]>0.3){print \"\\$F[0]\\\\t\\$F[1]\\\\n\";}' > \\$LOCIFILE\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  LOCIFILE=\\$(echo $vcf | sed 's/vcf/maf0.3.loci/')\n  cat $vcf | \\\n  perl -ane '@s=split(/[=\\\\;]/,\\$F[7]);if(\\$s[3]>0.3){print \"\\$F[0]\\\\t\\$F[1]\\\\n\";}' > \\$LOCIFILE\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ascatloci"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_ascat"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "bwa_index": {
        "name_process": "bwa_index",
        "string_process": "\nprocess bwa_index {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n\n  input:\n  tuple file(fa), file(fai) from fasta_bwa\n\n  output:\n  file('*') into complete_bwa\n\n  script:\n  \"\"\"\n  ##https://gatkforums.broadinstitute.org/gatk/discussion/2798/howto-prepare-a-reference-for-use-with-bwa-and-gatk\n  bwa index -a bwtsw $fa\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  ##https://gatkforums.broadinstitute.org/gatk/discussion/2798/howto-prepare-a-reference-for-use-with-bwa-and-gatk\n  bwa index -a bwtsw $fa\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "BWA"
        ],
        "tools_url": [
            "https://bio.tools/bwa"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            }
        ],
        "inputs": [
            "fasta_bwa"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_bwa"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "dict_pr2": {
        "name_process": "dict_pr2",
        "string_process": "\nprocess dict_pr2 {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n\n  input:\n  file(win_dict) from dict_win\n\n  output:\n  file('*') into complete_dict\n\n  script:\n  \"\"\"\n  perl -ane 'if(\\$F[0]=~m/SQ\\$/){@sc=split(/:/,\\$F[1]);@ss=split(/:/,\\$F[2]); if(\\$sc[1]!~m/[GLMT]/){ print \"\\$sc[1]\\\\t\\$ss[1]\\\\n\";}}' $win_dict > seq.dict.chr-size\n\n  bedtools makewindows -g seq.dict.chr-size -w 35000000 | perl -ane 'if(\\$F[1]==0){\\$F[1]++;};print \"\\$F[0]:\\$F[1]-\\$F[2]\\n\";' > 35MB-window.bed\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  perl -ane 'if(\\$F[0]=~m/SQ\\$/){@sc=split(/:/,\\$F[1]);@ss=split(/:/,\\$F[2]); if(\\$sc[1]!~m/[GLMT]/){ print \"\\$sc[1]\\\\t\\$ss[1]\\\\n\";}}' $win_dict > seq.dict.chr-size\n\n  bedtools makewindows -g seq.dict.chr-size -w 35000000 | perl -ane 'if(\\$F[1]==0){\\$F[1]++;};print \"\\$F[0]:\\$F[1]-\\$F[2]\\n\";' > 35MB-window.bed\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "dict_win"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_dict"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "exome_url": {
        "name_process": "exome_url",
        "string_process": " process exome_url {\n\n    publishDir path: \"$params.refDir/exome\", mode: \"copy\"\n\n    output:\n    file(\"${params.exometag}.url.bed\") into exome_bed\n\n    script:\n    \"\"\"\n    ##download URL\n    echo \"Exome bed used here is from:\" > README.${params.exometag}.url.bed\n    echo ${params.exomebedurl} >> README.${params.exometag}.url.bed\n\n    wget ${params.exomebedurl}\n    if [[ ${params.exomebedurl} =~ zip\\$ ]]; then\n      unzip -p *.zip > ${params.exometag}.url.bed\n    elif [[ ${params.exomebedurl} =~ bed\\$ ]]; then\n\n      ##remove any non-chr, coord lines in top of file\n      CHR=\\$(tail -n1 ${params.exomebedurl} | perl -ane 'print \\$F[0];')\n      if [[ \\$CHR =~ \"chr\" ]]; then\n        perl -ane 'if(\\$F[0]=~m/^chr/){print \\$_;}' ${params.exomebedurl} >  ${params.exometag}.url.bed\n      else\n        perl -ane 'if(\\$F[0]=~m/^[0-9MXY]/){print \\$_;}' ${params.exomebedurl} >  ${params.exometag}.url.bed\n      fi\n\n    else\n      echo \"No ZIP or BED files resulting from ${params.exomebedurl}\"\n      echo \"Please try another URL with ZIP or BED file resulting\"\n      exit 147\n    fi\n    \"\"\"\n  }",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    ##download URL\n    echo \"Exome bed used here is from:\" > README.${params.exometag}.url.bed\n    echo ${params.exomebedurl} >> README.${params.exometag}.url.bed\n\n    wget ${params.exomebedurl}\n    if [[ ${params.exomebedurl} =~ zip\\$ ]]; then\n      unzip -p *.zip > ${params.exometag}.url.bed\n    elif [[ ${params.exomebedurl} =~ bed\\$ ]]; then\n\n      ##remove any non-chr, coord lines in top of file\n      CHR=\\$(tail -n1 ${params.exomebedurl} | perl -ane 'print \\$F[0];')\n      if [[ \\$CHR =~ \"chr\" ]]; then\n        perl -ane 'if(\\$F[0]=~m/^chr/){print \\$_;}' ${params.exomebedurl} >  ${params.exometag}.url.bed\n      else\n        perl -ane 'if(\\$F[0]=~m/^[0-9MXY]/){print \\$_;}' ${params.exomebedurl} >  ${params.exometag}.url.bed\n      fi\n\n    else\n      echo \"No ZIP or BED files resulting from ${params.exomebedurl}\"\n      echo \"Please try another URL with ZIP or BED file resulting\"\n      exit 147\n    fi\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "exome_bed"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir/exome\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "exome_file": {
        "name_process": "exome_file",
        "string_process": " process exome_file {\n\n    publishDir path: \"$params.refDir/exome\", mode: \"copy\"\n\n    input:\n    file(exomebedfile) from exomebed_file\n\n    output:\n    file(\"${params.exometag}.file.bed\") into exome_bed\n\n    script:\n    \"\"\"\n    ##use file as input\n    echo \"Exome bed used here is from:\" > README.${params.exometag}.file.bed\n    echo $exomebedfile >> README.${params.exometag}.file.bed\n\n    if [[ $exomebedfile =~ bed\\$ ]]; then\n\n      ##remove any non-chr, coord lines in top of file\n      CHR=\\$(tail -n1 $exomebedfile | perl -ane 'print \\$F[0];')\n      if [[ \\$CHR =~ \"chr\" ]]; then\n        perl -ane 'if(\\$F[0]=~m/^chr/){print \\$_;}' $exomebedfile >  ${params.exometag}.file.bed\n      else\n        perl -ane 'if(\\$F[0]=~m/^[0-9MXY]/){print \\$_;}' $exomebedfile >  ${params.exometag}.file.bed\n      fi\n\n    else\n      echo \"BED file $exomebedfile is not a BED file, please retry\"\n      exit 147\n    fi\n    \"\"\"\n  }",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    ##use file as input\n    echo \"Exome bed used here is from:\" > README.${params.exometag}.file.bed\n    echo $exomebedfile >> README.${params.exometag}.file.bed\n\n    if [[ $exomebedfile =~ bed\\$ ]]; then\n\n      ##remove any non-chr, coord lines in top of file\n      CHR=\\$(tail -n1 $exomebedfile | perl -ane 'print \\$F[0];')\n      if [[ \\$CHR =~ \"chr\" ]]; then\n        perl -ane 'if(\\$F[0]=~m/^chr/){print \\$_;}' $exomebedfile >  ${params.exometag}.file.bed\n      else\n        perl -ane 'if(\\$F[0]=~m/^[0-9MXY]/){print \\$_;}' $exomebedfile >  ${params.exometag}.file.bed\n      fi\n\n    else\n      echo \"BED file $exomebedfile is not a BED file, please retry\"\n      exit 147\n    fi\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "exomebed_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "exome_bed"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir/exome\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "lift_over": {
        "name_process": "lift_over",
        "string_process": "\nprocess lift_over {\n\n  errorStrategy 'retry'\n  maxRetries 3\n\n  input:\n  file(exomebed) from exome_bed\n\n  output:\n  file('*.lift.bed') into exome_bed_liftd\n\n  script:\n  \"\"\"\n  if [[ ${params.version} != \"GRCh37\" ]]; then\n    wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz\n    liftOver $exomebed hg19ToHg38.over.chain.gz ${params.exometag}.lift.bed unmapped\n  else\n    cp $exomebed ${params.exometag}.lift.bed\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "  \"\"\"\n  if [[ ${params.version} != \"GRCh37\" ]]; then\n    wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz\n    liftOver $exomebed hg19ToHg38.over.chain.gz ${params.exometag}.lift.bed unmapped\n  else\n    cp $exomebed ${params.exometag}.lift.bed\n  fi\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "LiftOver"
        ],
        "tools_url": [
            "https://bio.tools/liftover"
        ],
        "tools_dico": [
            {
                "name": "LiftOver",
                "uri": "https://bio.tools/liftover",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This service converts genome coordinates and genome annotation files between assemblies.",
                "homepage": "http://api.bioinfo.no/wsdl/LiftOverService.wsdl"
            }
        ],
        "inputs": [
            "exome_bed"
        ],
        "nb_inputs": 1,
        "outputs": [
            "exome_bed_liftd"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "exome_bed_pr": {
        "name_process": "exome_bed_pr",
        "string_process": "\nprocess exome_bed_pr {\n\n  publishDir path: \"$params.refDir/exome\", mode: \"copy\", pattern: \"*[.interval_list,.bed]\"\n\n  input:\n  tuple file(fa), file(fai), file(dict) from fasta_dict_exome\n  file(exomelift) from exome_bed_liftd\n\n  output:\n  file(\"${params.exometag}.bed.interval_list\") into complete_exome\n  file(\"${params.exometag}.bed\") into (exome_tabix, exome_biallgz)\n\n  script:\n  \"\"\"\n  ##must test if all chr in fasta are in exome, else manta cries\n  ##must test if all regions are greater than length zero or strelka cries\n  ##must test if all seq.dict chrs are in bed and only they or BedToIntervalList cries\n  perl -ane 'if(\\$F[1] == \\$F[2]){\\$F[2]++;} if(\\$F[0] !~m/^chrM/){print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";}' $exomelift | grep -v chrM | sed 's/chr//g' > tmp.bed\n\n   grep @SQ $dict | cut -f2 | sed 's/SN://' | while read CHR; do\n   TESTCHR=\\$(awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed | wc -l)\n   if [[ \\$TESTCHR != 0 ]];then\n    awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed\n   fi\n  done >> tmp.dict.bed\n\n  ##always make interval list so we are in line with fasta\n  picard BedToIntervalList I=tmp.dict.bed O=${params.exometag}.interval_list SD=$dict\n\n  ##BedToIntervalList (reason unknown) makes 1bp interval to 0bp interval, replace with original\n  perl -ane 'if(\\$F[0]=~m/^@/){print \\$_;next;} if(\\$F[1] == \\$F[2]){\\$f=\\$F[1]; \\$f--; \\$F[1]=\\$f; print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";} else{print \\$_;}' ${params.exometag}.interval_list > ${params.exometag}.bed.interval_list\n\n  ##output BED\n  grep -v \"@\" ${params.exometag}.bed.interval_list | cut -f 1,2,3,5 > ${params.exometag}.bed\n  \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "  \"\"\"\n  ##must test if all chr in fasta are in exome, else manta cries\n  ##must test if all regions are greater than length zero or strelka cries\n  ##must test if all seq.dict chrs are in bed and only they or BedToIntervalList cries\n  perl -ane 'if(\\$F[1] == \\$F[2]){\\$F[2]++;} if(\\$F[0] !~m/^chrM/){print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";}' $exomelift | grep -v chrM | sed 's/chr//g' > tmp.bed\n\n   grep @SQ $dict | cut -f2 | sed 's/SN://' | while read CHR; do\n   TESTCHR=\\$(awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed | wc -l)\n   if [[ \\$TESTCHR != 0 ]];then\n    awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed\n   fi\n  done >> tmp.dict.bed\n\n  ##always make interval list so we are in line with fasta\n  picard BedToIntervalList I=tmp.dict.bed O=${params.exometag}.interval_list SD=$dict\n\n  ##BedToIntervalList (reason unknown) makes 1bp interval to 0bp interval, replace with original\n  perl -ane 'if(\\$F[0]=~m/^@/){print \\$_;next;} if(\\$F[1] == \\$F[2]){\\$f=\\$F[1]; \\$f--; \\$F[1]=\\$f; print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";} else{print \\$_;}' ${params.exometag}.interval_list > ${params.exometag}.bed.interval_list\n\n  ##output BED\n  grep -v \"@\" ${params.exometag}.bed.interval_list | cut -f 1,2,3,5 > ${params.exometag}.bed\n  \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "Picard",
            "NextSV"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools",
            "https://bio.tools/nextsv"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            }
        ],
        "inputs": [
            "fasta_dict_exome",
            "exome_bed_liftd"
        ],
        "nb_inputs": 2,
        "outputs": [
            "complete_exome",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir/exome\", mode: \"copy\", pattern: \"*[.interval_list,.bed]\""
        ],
        "when": "",
        "stub": ""
    },
    "wgs_bed": {
        "name_process": "wgs_bed",
        "string_process": "\nprocess wgs_bed {\n\n  publishDir path: \"$params.refDir/wgs\", mode: \"copy\"\n\n  input:\n  tuple file(fa), file(fai), file(dict) from fasta_dict_wgs\n\n  output:\n  file('wgs.bed.interval_list') into complete_wgs\n  file('wgs.bed') into (wgs_tabix, wgs_fasta_biallgz)\n\n  script:\n  \"\"\"\n  ##WGS intervals = 1-LN for each chr\n  grep @SQ $dict | cut -f 2,3 | perl -ane '\\$chr=\\$F[0];\\$chr=~s/SN://;\\$end=\\$F[1];\\$end=~s/LN://;print \"\\$chr\\\\t0\\\\t\\$end\\\\n\";' > tmp.wgs.dict.bed\n\n  ##always make interval list so we are in line with fasta\n  picard BedToIntervalList I=tmp.wgs.dict.bed O=wgs.bed.interval_list SD=$dict\n\n  ##output BED\n  grep -v \"@\" wgs.bed.interval_list | cut -f 1,2,3,5 > wgs.bed\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "  \"\"\"\n  ##WGS intervals = 1-LN for each chr\n  grep @SQ $dict | cut -f 2,3 | perl -ane '\\$chr=\\$F[0];\\$chr=~s/SN://;\\$end=\\$F[1];\\$end=~s/LN://;print \"\\$chr\\\\t0\\\\t\\$end\\\\n\";' > tmp.wgs.dict.bed\n\n  ##always make interval list so we are in line with fasta\n  picard BedToIntervalList I=tmp.wgs.dict.bed O=wgs.bed.interval_list SD=$dict\n\n  ##output BED\n  grep -v \"@\" wgs.bed.interval_list | cut -f 1,2,3,5 > wgs.bed\n  \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "fasta_dict_wgs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_wgs",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir/wgs\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "tabix_files": {
        "name_process": "tabix_files",
        "string_process": "\nprocess tabix_files {\n\n  publishDir path: \"$params.refDir/exome\", mode: \"copy\", pattern: \"${params.exometag}*\"\n  publishDir path: \"$params.refDir/wgs\", mode: \"copy\", pattern: \"wgs*\"\n\n  input:\n  file(bed) from bint_tabix\n\n  output:\n  tuple file(\"${bed}.gz\"), file(\"${bed}.gz.tbi\") into complete_tabix\n\n  script:\n  \"\"\"\n  ##tabix\n  bgzip $bed\n  tabix $bed\".gz\"\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  ##tabix\n  bgzip $bed\n  tabix $bed\".gz\"\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bint_tabix"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_tabix"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir/exome\", mode: \"copy\", pattern: \"${params.exometag}*\"",
            "publishDir path: \"$params.refDir/wgs\", mode: \"copy\", pattern: \"wgs*\""
        ],
        "when": "",
        "stub": ""
    },
    "exome_biall": {
        "name_process": "exome_biall",
        "string_process": "\nprocess exome_biall {\n\n  publishDir path: \"$params.refDir/exome\", mode: \"copy\"\n\n  input:\n  file(exomebed) from exome_biallgz\n  tuple file(fasta), file(fai) from fasta_exome_biall\n\n  output:\n  tuple file('af-only-gnomad.*.noChr.vcf.gz'), file('af-only-gnomad.*.noChr.vcf.gz.tbi') into exome_biallelicgz\n  file('exome.biall.bed') into pcgrtoml_exome\n\n  script:\n  \"\"\"\n  cut -f 1,2,3 $exomebed > exome.biall.bed\n\n  if [[ ${params.version} == \"GRCh37\" ]];then\n\n    gsutil cp gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf ./\n    bgzip af-only-gnomad.raw.sites.vcf\n    tabix af-only-gnomad.raw.sites.vcf.gz\n    gunzip -c af-only-gnomad.raw.sites.vcf.gz |\n    bcftools view -R exome.biall.bed af-only-gnomad.raw.sites.vcf.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.hg19.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.hg19.noChr.vcf $fai > af-only-gnomad.${params.exometag}.hg19.noChr.vcf\n    bgzip af-only-gnomad.${params.exometag}.hg19.noChr.vcf\n    tabix af-only-gnomad.${params.exometag}.hg19.noChr.vcf.gz\n\n  else\n\n    gsutil cp gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz ./\n    gunzip -c af-only-gnomad.hg38.vcf.gz | sed 's/chr//' | bgzip > af-only-gnomad.hg38.noChr.vcf.gz\n    tabix af-only-gnomad.hg38.noChr.vcf.gz\n    bcftools view -R exome.biall.bed af-only-gnomad.hg38.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.hg38.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.hg38.noChr.vcf $fai > af-only-gnomad.${params.exometag}.hg38.noChr.vcf\n    bgzip af-only-gnomad.${params.exometag}.hg38.noChr.vcf\n    tabix af-only-gnomad.${params.exometag}.hg38.noChr.vcf.gz\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "  \"\"\"\n  cut -f 1,2,3 $exomebed > exome.biall.bed\n\n  if [[ ${params.version} == \"GRCh37\" ]];then\n\n    gsutil cp gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf ./\n    bgzip af-only-gnomad.raw.sites.vcf\n    tabix af-only-gnomad.raw.sites.vcf.gz\n    gunzip -c af-only-gnomad.raw.sites.vcf.gz |\n    bcftools view -R exome.biall.bed af-only-gnomad.raw.sites.vcf.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.hg19.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.hg19.noChr.vcf $fai > af-only-gnomad.${params.exometag}.hg19.noChr.vcf\n    bgzip af-only-gnomad.${params.exometag}.hg19.noChr.vcf\n    tabix af-only-gnomad.${params.exometag}.hg19.noChr.vcf.gz\n\n  else\n\n    gsutil cp gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz ./\n    gunzip -c af-only-gnomad.hg38.vcf.gz | sed 's/chr//' | bgzip > af-only-gnomad.hg38.noChr.vcf.gz\n    tabix af-only-gnomad.hg38.noChr.vcf.gz\n    bcftools view -R exome.biall.bed af-only-gnomad.hg38.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.hg38.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.hg38.noChr.vcf $fai > af-only-gnomad.${params.exometag}.hg38.noChr.vcf\n    bgzip af-only-gnomad.${params.exometag}.hg38.noChr.vcf\n    tabix af-only-gnomad.${params.exometag}.hg38.noChr.vcf.gz\n  fi\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "NGSUtils",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/ngsutils",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "NGSUtils",
                "uri": "https://bio.tools/ngsutils",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3187",
                                    "term": "Sequence contamination filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NGSUtils is a suite of software tools for working with next-generation sequencing datasets",
                "homepage": "http://ngsutils.org"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "exome_biallgz",
            "fasta_exome_biall"
        ],
        "nb_inputs": 2,
        "outputs": [
            "exome_biallelicgz",
            "pcgrtoml_exome"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir/exome\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "wgs_biall": {
        "name_process": "wgs_biall",
        "string_process": "\nprocess wgs_biall {\n\n  publishDir path: \"$params.refDir/wgs\", mode: \"copy\"\n\n  errorStrategy 'retry'\n  maxRetries 3\n  label 'half_cpu_mem'\n\n  input:\n  file(wgsbed) from wgs_fasta_biallgz\n  tuple file(fasta), file(fai) from fasta_wgs_biall\n\n  output:\n  tuple file('af-only-gnomad.wgs.*.noChr.vcf.gz'), file('af-only-gnomad.wgs.*.noChr.vcf.gz.tbi') into wgs_biallelicgz\n  file('wgs.biall.bed') into pcgrtoml_wgs\n\n  script:\n  \"\"\"\n  cut -f 1,2,3 $wgsbed > wgs.biall.bed\n\n  if [[ ${params.version} == \"GRCh37\" ]];then\n\n    gsutil cp gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf ./\n    bgzip af-only-gnomad.raw.sites.vcf\n    tabix af-only-gnomad.raw.sites.vcf.gz\n    bcftools view -R wgs.biall.bed af-only-gnomad.raw.sites.vcf.gz | bcftools sort -T '.' > af-only-gnomad.wgsh.hg19.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.wgsh.hg19.noChr.vcf $fai > af-only-gnomad.wgs.hg19.noChr.vcf\n    bgzip af-only-gnomad.wgs.hg19.noChr.vcf\n    tabix af-only-gnomad.wgs.hg19.noChr.vcf.gz\n\n  else\n\n    gsutil cp gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz ./\n    gunzip -c af-only-gnomad.hg38.vcf.gz | sed 's/chr//' | bgzip > af-only-gnomad.hg38.noChr.vcf.gz\n    tabix af-only-gnomad.hg38.noChr.vcf.gz\n\n    bcftools view -R wgs.biall.bed af-only-gnomad.hg38.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.wgsh.hg38.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.wgsh.hg38.noChr.vcf $fai > af-only-gnomad.wgs.hg38.noChr.vcf\n    bgzip af-only-gnomad.wgs.hg38.noChr.vcf\n    tabix af-only-gnomad.wgs.hg38.noChr.vcf.gz\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 42,
        "string_script": "  \"\"\"\n  cut -f 1,2,3 $wgsbed > wgs.biall.bed\n\n  if [[ ${params.version} == \"GRCh37\" ]];then\n\n    gsutil cp gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf ./\n    bgzip af-only-gnomad.raw.sites.vcf\n    tabix af-only-gnomad.raw.sites.vcf.gz\n    bcftools view -R wgs.biall.bed af-only-gnomad.raw.sites.vcf.gz | bcftools sort -T '.' > af-only-gnomad.wgsh.hg19.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.wgsh.hg19.noChr.vcf $fai > af-only-gnomad.wgs.hg19.noChr.vcf\n    bgzip af-only-gnomad.wgs.hg19.noChr.vcf\n    tabix af-only-gnomad.wgs.hg19.noChr.vcf.gz\n\n  else\n\n    gsutil cp gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz ./\n    gunzip -c af-only-gnomad.hg38.vcf.gz | sed 's/chr//' | bgzip > af-only-gnomad.hg38.noChr.vcf.gz\n    tabix af-only-gnomad.hg38.noChr.vcf.gz\n\n    bcftools view -R wgs.biall.bed af-only-gnomad.hg38.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.wgsh.hg38.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.wgsh.hg38.noChr.vcf $fai > af-only-gnomad.wgs.hg38.noChr.vcf\n    bgzip af-only-gnomad.wgs.hg38.noChr.vcf\n    tabix af-only-gnomad.wgs.hg38.noChr.vcf.gz\n  fi\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "NGSUtils",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/ngsutils",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "NGSUtils",
                "uri": "https://bio.tools/ngsutils",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3187",
                                    "term": "Sequence contamination filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NGSUtils is a suite of software tools for working with next-generation sequencing datasets",
                "homepage": "http://ngsutils.org"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "wgs_fasta_biallgz",
            "fasta_wgs_biall"
        ],
        "nb_inputs": 2,
        "outputs": [
            "wgs_biallelicgz",
            "pcgrtoml_wgs"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir/wgs\", mode: \"copy\"",
            "errorStrategy 'retry'",
            "maxRetries 3",
            "label 'half_cpu_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "indexfeature_files": {
        "name_process": "indexfeature_files",
        "string_process": "\nprocess indexfeature_files {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n\n  input:\n  file(tbtbx) from vcf_tabix.flatten()\n\n  output:\n  file('*') into indexfeatured\n\n  script:\n  \"\"\"\n  bgzip $tbtbx\n  gatk IndexFeatureFile -F $tbtbx\".gz\"\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  bgzip $tbtbx\n  gatk IndexFeatureFile -F $tbtbx\".gz\"\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "vcf_tabix"
        ],
        "nb_inputs": 1,
        "outputs": [
            "indexfeatured"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "seqnza": {
        "name_process": "seqnza",
        "string_process": "\nprocess seqnza {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n\n  input:\n  set file(fa), file(fai) from fasta_seqza\n\n  output:\n  file('*') into sequenzaout\n\n  script:\n  \"\"\"\n  GENOMEGC50GZ=\\$(echo $fa | sed -r 's/.fasta/.gc50Base.txt.gz/')\n  sequenza\u2212utils.py GC-windows \u2212w 50 $fa | gzip > \\$GENOMEGC50GZ\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  GENOMEGC50GZ=\\$(echo $fa | sed -r 's/.fasta/.gc50Base.txt.gz/')\n  sequenza\u2212utils.py GC-windows \u2212w 50 $fa | gzip > \\$GENOMEGC50GZ\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_seqza"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sequenzaout"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "msisen": {
        "name_process": "msisen",
        "string_process": "\nprocess msisen {\n\n  publishDir \"$params.refDir\", mode: \"copy\"\n\n  input:\n  set file(fa), file(fai) from fasta_msi\n\n  output:\n  file('*') into completedmsisensor\n\n  script:\n  \"\"\"\n  msisensor scan -d $fa -o msisensor_microsatellites.list\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "  \"\"\"\n  msisensor scan -d $fa -o msisensor_microsatellites.list\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MSIsensor"
        ],
        "tools_url": [
            "https://bio.tools/msisensor"
        ],
        "tools_dico": [
            {
                "name": "MSIsensor",
                "uri": "https://bio.tools/msisensor",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Nucleic acid feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Sequence feature detection (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "C++ program for automatically detecting somatic and germline variants at microsatellite regions. It computes length distributions of microsatellites per site in paired tumor and normal sequence data, subsequently using these to statistically compare observed distributions in both samples.",
                "homepage": "https://github.com/ding-lab/msisensor"
            }
        ],
        "inputs": [
            "fasta_msi"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completedmsisensor"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "pcgr_data": {
        "name_process": "pcgr_data",
        "string_process": "\nprocess pcgr_data {\n  publishDir \"$params.refDir/pcgr\", mode: \"copy\", pattern: \"data\"\n\n  errorStrategy 'retry'\n  maxRetries 3\n\n  output:\n  file('data') into completedpcgrdb\n  file(\"data/${params.versionlc}/.vep/\") into pcgrdbvep\n  file(\"data/${params.versionlc}/RELEASE_NOTES\") into pcgrreleasenotes\n  file(\"data/${params.versionlc}/pcgr_configuration_default.toml\") into pcgrtoml\n\n  when:\n  !params.nopcgr\n\n  script:\n  if( params.version == \"GRCh37\" )\n    \"\"\"\n    wget ${params.pcgrURL37}\n    tar -xf *.tgz\n    rm -rf *.tgz\n    \"\"\"\n  else\n    \"\"\"\n    wget ${params.pcgrURL38}\n    tar -xf *.tgz\n    rm -rf *.tgz\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "  if( params.version == \"GRCh37\" )\n    \"\"\"\n    wget ${params.pcgrURL37}\n    tar -xf *.tgz\n    rm -rf *.tgz\n    \"\"\"\n  else\n    \"\"\"\n    wget ${params.pcgrURL38}\n    tar -xf *.tgz\n    rm -rf *.tgz\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "completedpcgrdb",
            "pcgrdbvep",
            "pcgrreleasenotes",
            "pcgrtoml"
        ],
        "nb_outputs": 4,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir \"$params.refDir/pcgr\", mode: \"copy\", pattern: \"data\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "!params.nopcgr",
        "stub": ""
    },
    "pcgr_toml": {
        "name_process": "pcgr_toml",
        "string_process": "\nprocess pcgr_toml {\n\n  publishDir \"$params.refDir/pcgr/data/${params.versionlc}\", mode: \"copy\"\n\n  input:\n  file(toml) from pcgrtoml\n  file(exomebed) from pcgrtoml_exome\n  file(wgsbed) from pcgrtoml_wgs\n\n  output:\n  file(\"pcgr_configuration_${params.exometag}.toml\") into pcgrtomld\n\n  script:\n  \"\"\"\n  ##calculate exome size in MB\n  bedtools merge -i $exomebed > exome.biall.merge.bed\n  EMB=\\$(echo -n \\$(( \\$(awk '{s+=\\$3-\\$2}END{print s}' exome.biall.merge.bed) / 1000000 )))\n  WMB=\\$(echo -n \\$(( \\$(awk '{s+=\\$3-\\$2}END{print s}' $wgsbed) / 1000000 )))\n  export EMB WMB;\n\n  ##perl to parse standard toml config and output ours\n  perl -ane 'if((\\$F[0]=~m/^tmb_intermediate_limit/) || (\\$F[0]=~m/^target_size_mb/)){\n    next;\n  }\n  if(\\$F[0]=~m/^\\\\[mutational_burden/) {\n    print \"[mutational_burden]\\\\ntmb_intermediate_limit = 10\\\\ntarget_size_mb = \\$ENV{'EMB'}\\\\n\";\n  }\n  else { print \\$_; }' $toml > pcgr_configuration_${params.exometag}.toml\n\n  perl -ane 'if((\\$F[0]=~m/^tmb_intermediate_limit/) || (\\$F[0]=~m/^target_size_mb/)){\n    next;\n  }\n  if(\\$F[0]=~m/^\\\\[mutational_burden/) {\n    print \"[mutational_burden]\\\\ntmb_intermediate_limit = 10\\\\ntarget_size_mb = \\$ENV{'WMB'}\\\\n\";\n  }\n  else { print \\$_; }' $toml > pcgr_configuration_wgs.toml\n  \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "  \"\"\"\n  ##calculate exome size in MB\n  bedtools merge -i $exomebed > exome.biall.merge.bed\n  EMB=\\$(echo -n \\$(( \\$(awk '{s+=\\$3-\\$2}END{print s}' exome.biall.merge.bed) / 1000000 )))\n  WMB=\\$(echo -n \\$(( \\$(awk '{s+=\\$3-\\$2}END{print s}' $wgsbed) / 1000000 )))\n  export EMB WMB;\n\n  ##perl to parse standard toml config and output ours\n  perl -ane 'if((\\$F[0]=~m/^tmb_intermediate_limit/) || (\\$F[0]=~m/^target_size_mb/)){\n    next;\n  }\n  if(\\$F[0]=~m/^\\\\[mutational_burden/) {\n    print \"[mutational_burden]\\\\ntmb_intermediate_limit = 10\\\\ntarget_size_mb = \\$ENV{'EMB'}\\\\n\";\n  }\n  else { print \\$_; }' $toml > pcgr_configuration_${params.exometag}.toml\n\n  perl -ane 'if((\\$F[0]=~m/^tmb_intermediate_limit/) || (\\$F[0]=~m/^target_size_mb/)){\n    next;\n  }\n  if(\\$F[0]=~m/^\\\\[mutational_burden/) {\n    print \"[mutational_burden]\\\\ntmb_intermediate_limit = 10\\\\ntarget_size_mb = \\$ENV{'WMB'}\\\\n\";\n  }\n  else { print \\$_; }' $toml > pcgr_configuration_wgs.toml\n  \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "BEDTools",
            "NextSV"
        ],
        "tools_url": [
            "https://bio.tools/bedtools",
            "https://bio.tools/nextsv"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            }
        ],
        "inputs": [
            "pcgrtoml",
            "pcgrtoml_exome",
            "pcgrtoml_wgs"
        ],
        "nb_inputs": 3,
        "outputs": [
            "pcgrtomld"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir \"$params.refDir/pcgr/data/${params.versionlc}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "vepdb": {
        "name_process": "vepdb",
        "string_process": "\nprocess vepdb {\n\n  publishDir \"$params.refDir/pcgr/data/${params.versionlc}\", mode: \"copy\"\n\n  input:\n  file(releasenotes) from pcgrreleasenotes\n  file(pcgrdbvepdir) from pcgrdbvep\n\n  output:\n  file('.vep/homo_sapiens') into complete_vepdb\n\n  \"\"\"\n  #! /bin/bash\n  ##build VEP cache using PCGR Singularity container 'vep_install' script\n  ##however PCGR installs a version of vep cache, so test that matches required version, and only install if not\n\n  ##variables for install and test\n  VEP_INSTALL=\\$(find /opt/miniconda/envs/somatic_exome_n-of-1/share/*/vep_install)\n  VEP_VERSION=\\$(cat $releasenotes | perl -ane 'if(\\$F[0] eq \"VEP\"){@s=split(/\\\\./,\\$F[5]); \\$v=\\$s[0]; \\$v=~s/v//; print \\$v;}')\n\n  ls $pcgrdbvepdir/homo_sapiens/ | cut -d \"_\" -f 1 > test.match\n  if [[ \\$(grep \\$VEP_VERSION test.match | wc -l) != 1 ]];then\n    \\$VEP_INSTALL \\\n      --AUTO cf \\\n      --CACHE_VERSION \\$VEP_VERSION \\\n      --CACHEDIR \"./\" \\\n      --SPECIES \"homo_sapiens\" \\\n      --ASSEMBLY ${params.version} \\\n      --NO_UPDATE \\\n      --NO_HTSLIB \\\n      --NO_BIOPERL \\\n      --NO_TEST\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "\"\"\"\n  #! /bin/bash\n  ##build VEP cache using PCGR Singularity container 'vep_install' script\n  ##however PCGR installs a version of vep cache, so test that matches required version, and only install if not\n\n  ##variables for install and test\n  VEP_INSTALL=\\$(find /opt/miniconda/envs/somatic_exome_n-of-1/share/*/vep_install)\n  VEP_VERSION=\\$(cat $releasenotes | perl -ane 'if(\\$F[0] eq \"VEP\"){@s=split(/\\\\./,\\$F[5]); \\$v=\\$s[0]; \\$v=~s/v//; print \\$v;}')\n\n  ls $pcgrdbvepdir/homo_sapiens/ | cut -d \"_\" -f 1 > test.match\n  if [[ \\$(grep \\$VEP_VERSION test.match | wc -l) != 1 ]];then\n    \\$VEP_INSTALL \\\n      --AUTO cf \\\n      --CACHE_VERSION \\$VEP_VERSION \\\n      --CACHEDIR \"./\" \\\n      --SPECIES \"homo_sapiens\" \\\n      --ASSEMBLY ${params.version} \\\n      --NO_UPDATE \\\n      --NO_HTSLIB \\\n      --NO_BIOPERL \\\n      --NO_TEST\n  fi\n  \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "/bin/bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcgrreleasenotes",
            "pcgrdbvep"
        ],
        "nb_inputs": 2,
        "outputs": [
            "complete_vepdb"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir \"$params.refDir/pcgr/data/${params.versionlc}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "gensizxml": {
        "name_process": "gensizxml",
        "string_process": "\nprocess gensizxml {\n\n  publishDir \"$params.refDir\", mode: \"copy\"\n\n  input:\n  set file(fa), file(fai), file(dict) from fasta_dict_gensiz\n\n  output:\n  file('*') into complete_gensiz\n\n  script:\n  \"\"\"\n  echo \"<sequenceSizes genomeName=\\\"$dict\\\">\" > GenomeSize.xml\n  grep \"@SQ\" $dict | while read LINE; do\n    CONTIGNAME=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[1]);print \\$s[1];' | sed 's/chr//')\n    TOTALBASES=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[2]);print \\$s[1];')\n    MD5SUM=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[3]);print \\$s[1];')\n    echo -e \"\\\\t<chromosome fileName=\\\"$fa\\\" contigName=\\\"\\$CONTIGNAME\\\" totalBases=\\\"\\$TOTALBASES\\\" isCircular=\\\"false\\\" md5=\\\"\\$MD5SUM\\\" ploidy=\\\"2\\\" knownBases=\\\"\\$TOTALBASES\\\" type=\\\"Chromosome\\\" />\" >> GenomeSize.xml\n  done\n  echo \"</sequenceSizes>\" >> GenomeSize.xml\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  \"\"\"\n  echo \"<sequenceSizes genomeName=\\\"$dict\\\">\" > GenomeSize.xml\n  grep \"@SQ\" $dict | while read LINE; do\n    CONTIGNAME=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[1]);print \\$s[1];' | sed 's/chr//')\n    TOTALBASES=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[2]);print \\$s[1];')\n    MD5SUM=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[3]);print \\$s[1];')\n    echo -e \"\\\\t<chromosome fileName=\\\"$fa\\\" contigName=\\\"\\$CONTIGNAME\\\" totalBases=\\\"\\$TOTALBASES\\\" isCircular=\\\"false\\\" md5=\\\"\\$MD5SUM\\\" ploidy=\\\"2\\\" knownBases=\\\"\\$TOTALBASES\\\" type=\\\"Chromosome\\\" />\" >> GenomeSize.xml\n  done\n  echo \"</sequenceSizes>\" >> GenomeSize.xml\n  \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_dict_gensiz"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_gensiz"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "hartwigmed": {
        "name_process": "hartwigmed",
        "string_process": "\nprocess hartwigmed {\n\n  publishDir path: \"$params.refDir\", mode: \"copy\"\n  validExitStatus 0,1,2\n  errorStrategy 'retry'\n  maxRetries 3\n\n  input:\n  tuple file(fa), file(fai), file(dict) from fasta_dict_gridss\n\n  output:\n  file('dbs') into gpldld\n  file('refgenomes/human_virus') into gpldle\n  file('gridss_*') into gridsspon\n\n  script:\n  if( params.version == 'GRCh37' )\n    \"\"\"\n    curl -o gridss-purple-linx-hg19-refdata-Dec2019.tar.gz \"${params.hartwigGPLURL37}\"\n    tar -xf gridss-purple-linx-hg19-refdata-Dec2019.tar.gz\n    mv hg19/dbs/ ./dbs/\n    mv hg19/refgenomes ./refgenomes\n\n    curl -o GRIDSS_PON_37972v1.zip \"${params.hartwigGRIDSSURL37}\"\n    unzip GRIDSS_PON_37972v1.zip\n\n    curl -o gridss_blacklist.bed.gz https://encode-public.s3.amazonaws.com/2011/05/04/f883c6e9-3ffc-4d16-813c-4c7d852d85db/ENCFF001TDObed.gz\n    cut -f 1 $fai > valid_chrs.txt\n    gunzip -c gridss_blacklist.bed.gz | sed 's/chr//g' > gridss_blacklist.bed\n    perl ${workflow.projectDir}/bin/exact_match_by_col.pl $fai,0 gridss_blacklist.bed,0 > gridss_blacklist.noChr.bed\n    \"\"\"\n\n         \n       \"\"\"\n  //   ##no GRCh38 yet=(\n  //   \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "  if( params.version == 'GRCh37' )\n    \"\"\"\n    curl -o gridss-purple-linx-hg19-refdata-Dec2019.tar.gz \"${params.hartwigGPLURL37}\"\n    tar -xf gridss-purple-linx-hg19-refdata-Dec2019.tar.gz\n    mv hg19/dbs/ ./dbs/\n    mv hg19/refgenomes ./refgenomes\n\n    curl -o GRIDSS_PON_37972v1.zip \"${params.hartwigGRIDSSURL37}\"\n    unzip GRIDSS_PON_37972v1.zip\n\n    curl -o gridss_blacklist.bed.gz https://encode-public.s3.amazonaws.com/2011/05/04/f883c6e9-3ffc-4d16-813c-4c7d852d85db/ENCFF001TDObed.gz\n    cut -f 1 $fai > valid_chrs.txt\n    gunzip -c gridss_blacklist.bed.gz | sed 's/chr//g' > gridss_blacklist.bed\n    perl ${workflow.projectDir}/bin/exact_match_by_col.pl $fai,0 gridss_blacklist.bed,0 > gridss_blacklist.noChr.bed\n    \"\"\"\n\n         \n       \"\"\"\n  //   ##no GRCh38 yet=(\n  //   \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "fasta_dict_gridss"
        ],
        "nb_inputs": 1,
        "outputs": [
            "gpldld",
            "gpldle",
            "gridsspon"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\"",
            "validExitStatus 0,1,2",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "gridss": {
        "name_process": "gridss",
        "string_process": "\nprocess gridss {\n\n    publishDir path: \"$params.refDir\", mode: \"copy\"\n\n    output:\n    file('gridss.properties') into gridssout\n\n    script:\n    if( params.version == 'GRCh37' )\n    \"\"\"\n    git clone https://github.com/PapenfussLab/gridss\n    mv gridss/src/main/resources/gridss.properties ./\n    \"\"\"\n\n}",
        "nb_lignes_process": 14,
        "string_script": "    if( params.version == 'GRCh37' )\n    \"\"\"\n    git clone https://github.com/PapenfussLab/gridss\n    mv gridss/src/main/resources/gridss.properties ./\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "gridssout"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__DNAseq_references",
        "directive": [
            "publishDir path: \"$params.refDir\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    }
}