{
    "seq_to_6frames_prot": {
        "name_process": "seq_to_6frames_prot",
        "string_process": "\nprocess seq_to_6frames_prot{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/6_frame_prot\", mode:'link'\n\n  input:\n  set sample_id, seq from contig_files\n  \n  output:\n  set sample_id, \"${sample_id}_prot.fa\" into nucl_seq_to_prot\n  \n  script:\n\"\"\" \ngotranseq -s ${seq[0]} -o ${sample_id}_prot.fa -f 6 --trim --numcpu=5\n\"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\" \ngotranseq -s ${seq[0]} -o ${sample_id}_prot.fa -f 6 --trim --numcpu=5\n\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contig_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "nucl_seq_to_prot"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/6_frame_prot\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "frame_prot_blastp": {
        "name_process": "frame_prot_blastp",
        "string_process": "\nprocess frame_prot_blastp{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'\n\n  input:\n  set sample_id, frame_prot from nucl_seq_to_prot\n\n  output:\n  set sample_id, frame_prot, \"${sample_id}_blastp_fmt6.txt\" into blastp_res\n  \n  script:\n\"\"\" \nblastp -query ${frame_prot} -db TTV_prot_ORFs -out \"${sample_id}_blastp_fmt6.txt\" -outfmt 6\n\"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\" \nblastp -query ${frame_prot} -db TTV_prot_ORFs -out \"${sample_id}_blastp_fmt6.txt\" -outfmt 6\n\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "BLASTP-ACC"
        ],
        "tools_url": [
            "https://bio.tools/BLASTP-ACC"
        ],
        "tools_dico": [
            {
                "name": "BLASTP-ACC",
                "uri": "https://bio.tools/BLASTP-ACC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3297",
                            "term": "Biotechnology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3802",
                                    "term": "Sorting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Sequence alignment (local)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parallel Architecture and Hardware Accelerator Design for BLAST-based Protein Sequence Alignment.\n\nIn this study, we design a hardware accelerator for a widely used sequence alignment algorithm, the basic local alignment search tool for proteins (BLASTP). The architecture of the proposed accelerator consists of five stages: a new systolic-array-based one-hit finding stage, a novel RAM-REG-based two-hit finding stage, a refined ungapped extension stage, a faster gapped extension stage, and a highly efficient parallel sorter. The system is implemented on an Altera Stratix V FPGA with a processing speed of more than 500 giga cell updates per second (GCUPS). It can receive a query sequence, compare it with the sequences in the database, and generate a list sorted in descending order of the similarity scores between the query sequence and the subject sequences.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'accelerator', 'Altera', 'Stratix', 'RAM-REG-based'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31581096"
            }
        ],
        "inputs": [
            "nucl_seq_to_prot"
        ],
        "nb_inputs": 1,
        "outputs": [
            "blastp_res"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "selection_blastp_res": {
        "name_process": "selection_blastp_res",
        "string_process": "\nprocess selection_blastp_res{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'\n\n  input:\n  set sample_id, frame_prot, blastp_fmt6 from blastp_res \n  \n  output:\n  set sample_id, frame_prot, blastp_fmt6, \"${sample_id}_blastp_sel.txt\" into blastp_sel\n  \n  script:\n\"\"\" \nawk '{ if(\\$4 > 500.0) { print }}' ${blastp_fmt6} | grep -i \"ORF1\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' > ${sample_id}_blastp_sel.txt\nawk '{ if(\\$4 > 100.0) { print }}' ${blastp_fmt6} | grep -i \"ORF2\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' >> ${sample_id}_blastp_sel.txt\nawk '{ if(\\$4 > 50.0) { print }}' ${blastp_fmt6} | grep -i \"ORF3\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' >> ${sample_id}_blastp_sel.txt\nawk '{ if(\\$4 > 50.0) { print }}' ${blastp_fmt6} | grep -i \"ORF4\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' >> ${sample_id}_blastp_sel.txt\n \n\"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "\"\"\" \nawk '{ if(\\$4 > 500.0) { print }}' ${blastp_fmt6} | grep -i \"ORF1\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' > ${sample_id}_blastp_sel.txt\nawk '{ if(\\$4 > 100.0) { print }}' ${blastp_fmt6} | grep -i \"ORF2\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' >> ${sample_id}_blastp_sel.txt\nawk '{ if(\\$4 > 50.0) { print }}' ${blastp_fmt6} | grep -i \"ORF3\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' >> ${sample_id}_blastp_sel.txt\nawk '{ if(\\$4 > 50.0) { print }}' ${blastp_fmt6} | grep -i \"ORF4\" | awk '{print \"c\"\\$0}' | awk 'BEGIN { OFS=\"\\t\" } { \\$1 = substr( \\$1, 2, length(\\$1)-2 ); print }' | tr '.' ',' | datamash -g 1 max 3 -f | tr ',' '.' >> ${sample_id}_blastp_sel.txt\n \n\"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "blastp_res"
        ],
        "nb_inputs": 1,
        "outputs": [
            "blastp_sel"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "prot_frame_selection_blastp": {
        "name_process": "prot_frame_selection_blastp",
        "string_process": "\nprocess prot_frame_selection_blastp{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'\n\n  input:\n  set sample_id, frame_prot, blastp_fmt6, blastp_fmt6_sel from blastp_sel \n  \n  output:\n  set sample_id, frame_prot, \"${sample_id}_prot_frame_selected_blastp.txt\" into prot_frame_sel_blastp\n  \n  script:\n\"\"\" \n#!/usr/bin/python\n\nf1 = open(\"$blastp_fmt6_sel\",\"r+\")\nsel_lines = f1.readlines()\n\nf2 = open(\"$blastp_fmt6\",\"r+\")\nres_lines = f2.readlines()\n\nf3 = open(\"${sample_id}_prot_frame_selected_blastp.txt\",\"a+\")\n\nfor s_line in sel_lines:\n    arr = s_line.split()\n    m_arr = arr[1:]\n    s_str = ' '.join(map(str, m_arr[:-1]))\n    for r_line in res_lines:\n        r_arr = r_line.split()\n        r_str = ' '.join(map(str, r_arr[1:]))\n        if arr[0] in r_arr[0] and s_str == r_str:\n            f3.write(r_line)\n\nf1.close()\nf2.close()\nf3.close()\n\nprint(\"$sample_id\")\n\"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "\"\"\" \n#!/usr/bin/python\n\nf1 = open(\"$blastp_fmt6_sel\",\"r+\")\nsel_lines = f1.readlines()\n\nf2 = open(\"$blastp_fmt6\",\"r+\")\nres_lines = f2.readlines()\n\nf3 = open(\"${sample_id}_prot_frame_selected_blastp.txt\",\"a+\")\n\nfor s_line in sel_lines:\n    arr = s_line.split()\n    m_arr = arr[1:]\n    s_str = ' '.join(map(str, m_arr[:-1]))\n    for r_line in res_lines:\n        r_arr = r_line.split()\n        r_str = ' '.join(map(str, r_arr[1:]))\n        if arr[0] in r_arr[0] and s_str == r_str:\n            f3.write(r_line)\n\nf1.close()\nf2.close()\nf3.close()\n\nprint(\"$sample_id\")\n\"\"\"",
        "nb_lignes_script": 26,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "blastp_sel"
        ],
        "nb_inputs": 1,
        "outputs": [
            "prot_frame_sel_blastp"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "sort_prot_frame_sel_results": {
        "name_process": "sort_prot_frame_sel_results",
        "string_process": "\nprocess sort_prot_frame_sel_results{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'\n\n  input:\n  set sample_id, frame_prot, prot_sel_blastp from prot_frame_sel_blastp \n  \n  output:\n  set sample_id, frame_prot, \"${sample_id}_blastp_sel_sorted.txt\" into prot_fram_sel_sorted\n  \n  script:\n\"\"\" \nawk '{ if(\\$3 > 40.0) { print }}' ${prot_sel_blastp} | sort -k2 -n > \"${sample_id}_blastp_sel_sorted.txt\"\n\"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\" \nawk '{ if(\\$3 > 40.0) { print }}' ${prot_sel_blastp} | sort -k2 -n > \"${sample_id}_blastp_sel_sorted.txt\"\n\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prot_frame_sel_blastp"
        ],
        "nb_inputs": 1,
        "outputs": [
            "prot_fram_sel_sorted"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "delete_pos_overlap": {
        "name_process": "delete_pos_overlap",
        "string_process": "\nprocess delete_pos_overlap{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'\n\n  input:\n  set sample_id, frame_prot, res_sorted from prot_fram_sel_sorted\n  \n  output:\n  set sample_id, frame_prot, \"${sample_id}_blastp_sel_sorted_overlap_removed.txt\" into overlap_rm\n  \n  script:\n\"\"\"\n#!/usr/bin/python \n\ndef rm_overlap(sel_lines):\n    j = 1\n    bool_ = 0\n    arr_res = []\n    i = 0\n    while i < len(sel_lines):\n        if i == len(sel_lines)-1:\n            j = 0\n        else:\n            j = i + 1\n        x=sel_lines[i].split()\n        x_line=sel_lines[i]\n        y=sel_lines[j].split()\n        y_line=sel_lines[j]\n        if x[0] == y[0] and j != 0:\n            if x[6] == y[6] and x[7] == y[7]:\n                bool_=1\n            elif x[6] >= y[6] and x[6] <= y[7]:\n                bool_=1\n                bool_=0\n            elif x[6] <= y[6] and x[6] <= y[7] and x[7] >= y[7]:\n                bool_=1\n                bool_=0\n            elif x[6] <= y[6] and x[7] <= y[7] and x[7] >= y[6]:\n                bool_=1\n                bool_=0\n            elif y[6] >= x[6] and y[6] <= x[7]:\n                bool_=1\n                bool_=0\n            elif y[6] <= x[6] and y[6] <= x[7] and y[7] >= x[7]:\n                bool_=1\n                bool_=0\n            elif y[6] <= x[6] and y[7] <= x[7] and y[7] >= x[6]:\n                bool_=1\n                bool_=0\n            else:\n                bool_=0\n            if bool_ == 1 and float(x[2]) == float(y[2]):\n                print(\"True\")\n                if float(x[10]) < float(y[10]):\n                    arr_res.append(x_line)\n                    i = j\n                else:\n                    arr_res.append(y_line)\n                    i = j\n            elif bool_ == 1 and float(x[2]) != float(y[2]):\n                if float(x[2]) > float(y[2]):\n                    arr_res.append(x_line)\n                    i = j\n                else:\n                    arr_res.append(y_line)\n                    i = j\n            else:\n                arr_res.append(x_line)\n        elif x[0] != y[0] and j != 0:\n            arr_res.append(x_line)\n        else:\n            arr_res.append(x_line)\n        i += 1\n    return arr_res\n\ndef main():\n    f1 = open(\"$res_sorted\",\"r+\")\n    sel_lines = f1.readlines()\n    f2 = open(\"${sample_id}_blastp_sel_sorted_overlap_removed.txt\",\"a+\")\n    tmp = rm_overlap(sel_lines)\n\n    for i in range(1, 20):\n        tmp2 = rm_overlap(tmp)\n        tmp = tmp2\n\n    for t in tmp:\n        f2.write(t)\n    \n    f1.close()\n    f2.close()\n\nmain()\n\"\"\"\n}",
        "nb_lignes_process": 94,
        "string_script": "\"\"\"\n#!/usr/bin/python \n\ndef rm_overlap(sel_lines):\n    j = 1\n    bool_ = 0\n    arr_res = []\n    i = 0\n    while i < len(sel_lines):\n        if i == len(sel_lines)-1:\n            j = 0\n        else:\n            j = i + 1\n        x=sel_lines[i].split()\n        x_line=sel_lines[i]\n        y=sel_lines[j].split()\n        y_line=sel_lines[j]\n        if x[0] == y[0] and j != 0:\n            if x[6] == y[6] and x[7] == y[7]:\n                bool_=1\n            elif x[6] >= y[6] and x[6] <= y[7]:\n                bool_=1\n                bool_=0\n            elif x[6] <= y[6] and x[6] <= y[7] and x[7] >= y[7]:\n                bool_=1\n                bool_=0\n            elif x[6] <= y[6] and x[7] <= y[7] and x[7] >= y[6]:\n                bool_=1\n                bool_=0\n            elif y[6] >= x[6] and y[6] <= x[7]:\n                bool_=1\n                bool_=0\n            elif y[6] <= x[6] and y[6] <= x[7] and y[7] >= x[7]:\n                bool_=1\n                bool_=0\n            elif y[6] <= x[6] and y[7] <= x[7] and y[7] >= x[6]:\n                bool_=1\n                bool_=0\n            else:\n                bool_=0\n            if bool_ == 1 and float(x[2]) == float(y[2]):\n                print(\"True\")\n                if float(x[10]) < float(y[10]):\n                    arr_res.append(x_line)\n                    i = j\n                else:\n                    arr_res.append(y_line)\n                    i = j\n            elif bool_ == 1 and float(x[2]) != float(y[2]):\n                if float(x[2]) > float(y[2]):\n                    arr_res.append(x_line)\n                    i = j\n                else:\n                    arr_res.append(y_line)\n                    i = j\n            else:\n                arr_res.append(x_line)\n        elif x[0] != y[0] and j != 0:\n            arr_res.append(x_line)\n        else:\n            arr_res.append(x_line)\n        i += 1\n    return arr_res\n\ndef main():\n    f1 = open(\"$res_sorted\",\"r+\")\n    sel_lines = f1.readlines()\n    f2 = open(\"${sample_id}_blastp_sel_sorted_overlap_removed.txt\",\"a+\")\n    tmp = rm_overlap(sel_lines)\n\n    for i in range(1, 20):\n        tmp2 = rm_overlap(tmp)\n        tmp = tmp2\n\n    for t in tmp:\n        f2.write(t)\n    \n    f1.close()\n    f2.close()\n\nmain()\n\"\"\"",
        "nb_lignes_script": 81,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prot_fram_sel_sorted"
        ],
        "nb_inputs": 1,
        "outputs": [
            "overlap_rm"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/blastp\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_frame_prot_seq": {
        "name_process": "extract_frame_prot_seq",
        "string_process": "\nprocess extract_frame_prot_seq{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/6_frame_prot\", mode:'link'\n\n  input:\n  set sample_id, frame_prot, blastp_r from overlap_rm \n  \n  output:\n  set sample_id, \"${sample_id}_extracted_prot.fa\", blastp_r  into ext_prot_seq\n  \n  script:\n\"\"\" \ncat ${blastp_r} | awk '{print \\$1}' > list_prot_tmp.txt\n\nseqtk subseq ${frame_prot} list_prot_tmp.txt > ${sample_id}_extracted_prot.fa\n\"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\" \ncat ${blastp_r} | awk '{print \\$1}' > list_prot_tmp.txt\n\nseqtk subseq ${frame_prot} list_prot_tmp.txt > ${sample_id}_extracted_prot.fa\n\"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "overlap_rm"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ext_prot_seq"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/6_frame_prot\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "cut_pos_multiORFs_using_extProt": {
        "name_process": "cut_pos_multiORFs_using_extProt",
        "string_process": "\nprocess cut_pos_multiORFs_using_extProt{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/multiORF_fasta\", mode:'link'\n\n  input:\n  set sample_id, ext_prot, blastp_r from ext_prot_seq \n  \n  output:\n  set sample_id, \"${sample_id}_ext_ORFs.fa\"  into multiORF\n  \n  script:\n\"\"\" \n#!/usr/bin/python \n\ndef split(seq): \n    return [char for char in seq]\n\ndef convert(s): \n    new = \"\" \n    for x in s: \n        new += x    \n    return new \n\nf1 = open(\"$ext_prot\",\"r+\")\nprot_seq = f1.readlines()\nf2 = open(\"$blastp_r\",\"r+\")\nblastp_res = f2.readlines()\nf3 = open(\"${sample_id}_ext_ORFs.fa\", \"a+\")\n\nfor i in range(len(blastp_res)):\n    for j in range(len(prot_seq)):\n        if blastp_res[i].split()[0] in prot_seq[j]:\n            tmp=split(prot_seq[j+1])\n            start = int(blastp_res[i].split()[6]) - 1\n            stop = int(blastp_res[i].split()[7]) - 1\n            tmp2 = tmp[start:stop]\n            if '\\\\n' not in tmp2:\n                tmp2.append('\\\\n')\n            header = \">\" + \"${sample_id}\" + \"_\" + blastp_res[i].split()[0]\n            if \"orf1\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF1\"\n            elif \"orf2\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF2\"\n            elif \"orf3\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF3\"\n            elif \"orf4\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF4\"\n            header = header + \" pos:\" + blastp_res[i].split()[6] + \"-\" + blastp_res[i].split()[7] + \" alignment_len:\" + blastp_res[i].split()[3] + \" aa_len:\" + str(len(tmp2) - 1) + \"\\\\n\"\n            f3.write(header)\n            f3.write(convert(tmp2))\nf1.close()\nf2.close()\nf3.close()\n\"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "\"\"\" \n#!/usr/bin/python \n\ndef split(seq): \n    return [char for char in seq]\n\ndef convert(s): \n    new = \"\" \n    for x in s: \n        new += x    \n    return new \n\nf1 = open(\"$ext_prot\",\"r+\")\nprot_seq = f1.readlines()\nf2 = open(\"$blastp_r\",\"r+\")\nblastp_res = f2.readlines()\nf3 = open(\"${sample_id}_ext_ORFs.fa\", \"a+\")\n\nfor i in range(len(blastp_res)):\n    for j in range(len(prot_seq)):\n        if blastp_res[i].split()[0] in prot_seq[j]:\n            tmp=split(prot_seq[j+1])\n            start = int(blastp_res[i].split()[6]) - 1\n            stop = int(blastp_res[i].split()[7]) - 1\n            tmp2 = tmp[start:stop]\n            if '\\\\n' not in tmp2:\n                tmp2.append('\\\\n')\n            header = \">\" + \"${sample_id}\" + \"_\" + blastp_res[i].split()[0]\n            if \"orf1\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF1\"\n            elif \"orf2\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF2\"\n            elif \"orf3\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF3\"\n            elif \"orf4\" in blastp_res[i].split()[1].lower():\n                header = header + \"_ORF4\"\n            header = header + \" pos:\" + blastp_res[i].split()[6] + \"-\" + blastp_res[i].split()[7] + \" alignment_len:\" + blastp_res[i].split()[3] + \" aa_len:\" + str(len(tmp2) - 1) + \"\\\\n\"\n            f3.write(header)\n            f3.write(convert(tmp2))\nf1.close()\nf2.close()\nf3.close()\n\"\"\"",
        "nb_lignes_script": 42,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ext_prot_seq"
        ],
        "nb_inputs": 1,
        "outputs": [
            "multiORF"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/multiORF_fasta\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    },
    "divide_by_ORFs": {
        "name_process": "divide_by_ORFs",
        "string_process": "\nprocess divide_by_ORFs{\n  tag {\"${sample_id}\"}\n\n  publishDir \"${params.publish_base_dir}/${sample_id}/final_ORFs_results\", mode:'link'\n\n  input:\n  set sample_id, ext_ORF  from multiORF\n  \n  output:\n  set sample_id, \"${sample_id}_ORF1.fa\", \"${sample_id}_ORF2.fa\", \"${sample_id}_ORF3.fa\", \"${sample_id}_ORF4.fa\"  into div_ORF\n  \n  script:\n\"\"\" \ncat $ext_ORF | grep -i \"ORF1\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp1.txt\nsleep 1\ncat $ext_ORF | grep -i \"ORF2\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp2.txt\nsleep 1\ncat $ext_ORF | grep -i \"ORF3\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp3.txt\nsleep 1\ncat $ext_ORF | grep -i \"ORF4\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp4.txt\nsleep 1\nseqtk subseq ${ext_ORF} tmp1.txt | awk '!x[\\$0]++' > ${sample_id}_ORF1.fa\nsleep 1\nseqtk subseq ${ext_ORF} tmp2.txt | awk '!x[\\$0]++' > ${sample_id}_ORF2.fa\nsleep 1\nseqtk subseq ${ext_ORF} tmp3.txt | awk '!x[\\$0]++' > ${sample_id}_ORF3.fa\nsleep 1\nseqtk subseq ${ext_ORF} tmp4.txt | awk '!x[\\$0]++' > ${sample_id}_ORF4.fa\n\"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "\"\"\" \ncat $ext_ORF | grep -i \"ORF1\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp1.txt\nsleep 1\ncat $ext_ORF | grep -i \"ORF2\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp2.txt\nsleep 1\ncat $ext_ORF | grep -i \"ORF3\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp3.txt\nsleep 1\ncat $ext_ORF | grep -i \"ORF4\" | awk '{print \\$1}' | cut -c2- | awk '!x[\\$0]++' > tmp4.txt\nsleep 1\nseqtk subseq ${ext_ORF} tmp1.txt | awk '!x[\\$0]++' > ${sample_id}_ORF1.fa\nsleep 1\nseqtk subseq ${ext_ORF} tmp2.txt | awk '!x[\\$0]++' > ${sample_id}_ORF2.fa\nsleep 1\nseqtk subseq ${ext_ORF} tmp3.txt | awk '!x[\\$0]++' > ${sample_id}_ORF3.fa\nsleep 1\nseqtk subseq ${ext_ORF} tmp4.txt | awk '!x[\\$0]++' > ${sample_id}_ORF4.fa\n\"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "multiORF"
        ],
        "nb_inputs": 1,
        "outputs": [
            "div_ORF"
        ],
        "nb_outputs": 1,
        "name_workflow": "Amanj1__TTVnucleoTranslations",
        "directive": [
            "tag {\"${sample_id}\"}",
            "publishDir \"${params.publish_base_dir}/${sample_id}/final_ORFs_results\", mode:'link'"
        ],
        "when": "",
        "stub": ""
    }
}