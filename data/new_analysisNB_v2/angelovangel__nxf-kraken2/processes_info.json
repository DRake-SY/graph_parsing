{
    "SoftwareVersions": {
        "name_process": "SoftwareVersions",
        "string_process": "\nprocess SoftwareVersions {\n    publishDir \"${params.outdir}/software_versions\", mode: 'copy'\n\n    output:\n        file(\"software_versions.txt\")\n\n    script:\n    \"\"\"\n    echo \"software\\tversion\\tbuild\\tchannel\" > tempfile\n    \n    conda list | \\\n    grep 'fastp\\\\|kraken2\\\\|bracken\\\\|krona\\\\|r-data.table\\\\|r-dplyr\\\\|r-tidyr\\\\|r-dt\\\\|r-d3heatmap\\\\|r-base' \\\n    >> tempfile\n\n    echo \"kaiju \\$(cd /kaiju && git tag | tail -n 1)\" >> tempfile\n    echo 'nextflow\\t${nextflow.version}\\t${nextflow.build}' >> tempfile\n    multiqc --version | sed 's/, version//' >> tempfile\n\n    # replace blanks with tab for easier processing downstream\n    tr -s '[:blank:]' '\\t' < tempfile > software_versions.txt\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    echo \"software\\tversion\\tbuild\\tchannel\" > tempfile\n    \n    conda list | \\\n    grep 'fastp\\\\|kraken2\\\\|bracken\\\\|krona\\\\|r-data.table\\\\|r-dplyr\\\\|r-tidyr\\\\|r-dt\\\\|r-d3heatmap\\\\|r-base' \\\n    >> tempfile\n\n    echo \"kaiju \\$(cd /kaiju && git tag | tail -n 1)\" >> tempfile\n    echo 'nextflow\\t${nextflow.version}\\t${nextflow.build}' >> tempfile\n    multiqc --version | sed 's/, version//' >> tempfile\n\n    # replace blanks with tab for easier processing downstream\n    tr -s '[:blank:]' '\\t' < tempfile > software_versions.txt\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "ANACONDA",
            "MR-Base",
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/anaconda",
            "https://bio.tools/MR-Base",
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "ANACONDA",
                "uri": "https://bio.tools/anaconda",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software package specially developed for the study of genes\u2019 primary structure. It uses gene sequences downloaded from public databases, as FASTA and GenBank, and it applies a set of statistical and visualization methods in different ways, to reveal information about codon context, codon usage, nucleotide repeats within open reading frames (ORFeome) and others.",
                "homepage": "http://bioinformatics.ua.pt/software/anaconda/"
            },
            {
                "name": "MR-Base",
                "uri": "https://bio.tools/MR-Base",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3659",
                                    "term": "Regression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0488",
                                    "term": "Linkage disequilibrium calculation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Using the MR-Base platform to investigate risk factors and drug targets for thousands of phenotypes | This repository contains the case studies associated with the manuscript \"Using the MR-Base platform to investigate risk factors and drug targets for thousands of phenotypes\" | 2-sample Mendelian Randomisation | MR-base is a database and analytical platform for Mendelian randomization being developed by the MRC Integrative Epidemiology Unit at the University of Bristol",
                "homepage": "http://www.mrbase.org/"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "publishDir \"${params.outdir}/software_versions\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "Fastp": {
        "name_process": "Fastp",
        "string_process": "\nprocess Fastp {\n\n    tag \"fastp on $sample_id\"\n               \n    publishDir \"${params.outdir}/trimmed_fastq\", mode: 'copy', pattern: 'trim_*'                                    \n\n    input:\n        tuple sample_id, file(x) from read_ch\n    \n    output:\n        tuple sample_id, file('trim_*') into fastp_ch\n        file(\"${sample_id}_fastp.json\") into fastp4mqc_ch\n                                                       \n\n\n    script:\n    def single = x instanceof Path                                                                                    \n    def fastp_input = single ? \"-i \\\"${ x }\\\"\" : \"-i \\\"${ x[0] }\\\" -I \\\"${ x[1] }\\\"\"\n    def fastp_output = single ? \"-o \\\"trim_${ x }\\\"\" : \"-o \\\"trim_${ x[0] }\\\" -O \\\"trim_${ x[1] }\\\"\"\n    def qscore_cutoff = params.ontreads ? 7 : 15                        \n\n    \"\"\"\n    fastp \\\n    -q $qscore_cutoff \\\n    $fastp_input \\\n    $fastp_output \\\n    -j ${sample_id}_fastp.json\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    def single = x instanceof Path                                                                                    \n    def fastp_input = single ? \"-i \\\"${ x }\\\"\" : \"-i \\\"${ x[0] }\\\" -I \\\"${ x[1] }\\\"\"\n    def fastp_output = single ? \"-o \\\"trim_${ x }\\\"\" : \"-o \\\"trim_${ x[0] }\\\" -O \\\"trim_${ x[1] }\\\"\"\n    def qscore_cutoff = params.ontreads ? 7 : 15                        \n\n    \"\"\"\n    fastp \\\n    -q $qscore_cutoff \\\n    $fastp_input \\\n    $fastp_output \\\n    -j ${sample_id}_fastp.json\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "read_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastp_ch",
            "fastp4mqc_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "tag \"fastp on $sample_id\"",
            "publishDir \"${params.outdir}/trimmed_fastq\", mode: 'copy', pattern: 'trim_*'"
        ],
        "when": "",
        "stub": ""
    },
    "Kraken2": {
        "name_process": "Kraken2",
        "string_process": "\nprocess Kraken2 {\n    tag \"kraken2 on $sample_id\"\n               \n    publishDir \"${params.outdir}/samples\", mode: 'copy', pattern: '*.{report,tsv}'\n    \n    input:\n                                                      \n        path db from kraken_db_ch.first()                                   \n        tuple sample_id, file(x) from fastp1\n    \n    output:\n        file(\"*report\") into kraken2mqc_ch                                                                                          \n        file(\"*kraken2.krona\") into kraken2krona_ch\n        tuple sample_id, file(\"*bracken.tsv\") into bracken2dt_ch\n        file(\"*bracken.tsv\") into bracken2summary_ch\n    \n    script:\n    def single = x instanceof Path\n    def kraken_input = single ? \"\\\"${ x }\\\"\" : \"--paired \\\"${ x[0] }\\\"  \\\"${ x[1] }\\\"\"\n    def memory = params.weakmem ? \"--memory-mapping\" : \"\"                                                                    \n    def rlength = params.ontreads ? 250 : params.readlen                                                                                             \n    \n        \"\"\"\n        kraken2 \\\n            -db $db \\\n            $memory \\\n            --report ${sample_id}_kraken2.report \\\n            $kraken_input \\\n            > kraken2.output\n        cut -f 2,3 kraken2.output > ${sample_id}_kraken2.krona\n\n        bracken \\\n            -d $db \\\n            -r $rlength \\\n            -i ${sample_id}_kraken2.report \\\n            -l ${params.taxlevel} \\\n            -o ${sample_id}_bracken.tsv\n        \"\"\"\n\n}",
        "nb_lignes_process": 39,
        "string_script": "    def single = x instanceof Path\n    def kraken_input = single ? \"\\\"${ x }\\\"\" : \"--paired \\\"${ x[0] }\\\"  \\\"${ x[1] }\\\"\"\n    def memory = params.weakmem ? \"--memory-mapping\" : \"\"                                                                    \n    def rlength = params.ontreads ? 250 : params.readlen                                                                                             \n    \n        \"\"\"\n        kraken2 \\\n            -db $db \\\n            $memory \\\n            --report ${sample_id}_kraken2.report \\\n            $kraken_input \\\n            > kraken2.output\n        cut -f 2,3 kraken2.output > ${sample_id}_kraken2.krona\n\n        bracken \\\n            -d $db \\\n            -r $rlength \\\n            -i ${sample_id}_kraken2.report \\\n            -l ${params.taxlevel} \\\n            -o ${sample_id}_bracken.tsv\n        \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "kraken2",
            "Bracken"
        ],
        "tools_url": [
            "https://bio.tools/kraken2",
            "https://bio.tools/bracken"
        ],
        "tools_dico": [
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            },
            {
                "name": "Bracken",
                "uri": "https://bio.tools/bracken",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Microbial ecology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Environmental microbiology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Statistical method that computes the abundance of species in DNA sequences from a metagenomics sample.",
                "homepage": "https://ccb.jhu.edu/software/bracken/"
            }
        ],
        "inputs": [
            "kraken_db_ch",
            "fastp1"
        ],
        "nb_inputs": 2,
        "outputs": [
            "kraken2mqc_ch",
            "kraken2krona_ch",
            "bracken2dt_ch",
            "bracken2summary_ch"
        ],
        "nb_outputs": 4,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "tag \"kraken2 on $sample_id\"",
            "publishDir \"${params.outdir}/samples\", mode: 'copy', pattern: '*.{report,tsv}'"
        ],
        "when": "",
        "stub": ""
    },
    "KaijuDBPrep": {
        "name_process": "KaijuDBPrep",
        "string_process": "\nprocess  KaijuDBPrep {\n  input:\n    val(x) from kaiju_db\n  \n  output:\n    path(\"${x}/*.fmi\") into fmi_ch\n    path(\"*.dmp\") into dmp_ch_1             \n    path(\"*.dmp\") into dmp_ch_2                   \n  \n  script:\n  \"\"\"\n  kaiju-makedb -s $x \n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  kaiju-makedb -s $x \n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "kaiju_db"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fmi_ch",
            "dmp_ch_1",
            "dmp_ch_2"
        ],
        "nb_outputs": 3,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Kaiju": {
        "name_process": "Kaiju",
        "string_process": "\nprocess Kaiju {\n                                                                         \n\n  input:\n    tuple sample_id, file(x) from fastp2\n    path(\"*\") from dmp_ch_1.first()                                                               \n    file fmi from fmi_ch.first()\n  \n  output:\n    file(\"*_kaiju.out\") into kaiju_summary_ch\n    file(\"*kaiju.out.krona\") into kaiju2krona_ch\n\n  script:\n  def single = x instanceof Path\n  def kaiju_input = single ? \"-i \\\"${ x[0] }\\\"\" : \"-i \\\"${ x[0] }\\\" -j \\\"${ x[1] }\\\"\"\n  \"\"\"\n  kaiju \\\n    -z 6 \\\n    -t nodes.dmp \\\n    -f $fmi \\\n    $kaiju_input \\\n    -o ${sample_id}_kaiju.out\n\n  kaiju2krona -t nodes.dmp -n names.dmp -i ${sample_id}_kaiju.out -o ${sample_id}_kaiju.out.krona\n  \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "  def single = x instanceof Path\n  def kaiju_input = single ? \"-i \\\"${ x[0] }\\\"\" : \"-i \\\"${ x[0] }\\\" -j \\\"${ x[1] }\\\"\"\n  \"\"\"\n  kaiju \\\n    -z 6 \\\n    -t nodes.dmp \\\n    -f $fmi \\\n    $kaiju_input \\\n    -o ${sample_id}_kaiju.out\n\n  kaiju2krona -t nodes.dmp -n names.dmp -i ${sample_id}_kaiju.out -o ${sample_id}_kaiju.out.krona\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "Kaiju"
        ],
        "tools_url": [
            "https://bio.tools/kaiju"
        ],
        "tools_dico": [
            {
                "name": "Kaiju",
                "uri": "https://bio.tools/kaiju",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2975",
                                "term": "Nucleic acid sequence (raw)"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Program for the taxonomic assignment of high-throughput sequencing reads, e.g., Illumina or Roche/454, from whole-genome sequencing of metagenomic DNA. Reads are directly assigned to taxa using the NCBI taxonomy and a reference database of protein sequences from Bacteria, Archaea, Fungi, microbial eukaryotes and viruses.",
                "homepage": "http://kaiju.binf.ku.dk"
            }
        ],
        "inputs": [
            "fastp2",
            "dmp_ch_1",
            "fmi_ch"
        ],
        "nb_inputs": 3,
        "outputs": [
            "kaiju_summary_ch",
            "kaiju2krona_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "KaijuSummary": {
        "name_process": "KaijuSummary",
        "string_process": "\nprocess KaijuSummary {\n  publishDir params.outdir, mode: 'copy'\n  \n  input:\n    path(\"*\") from dmp_ch_2\n    path x from kaiju_summary_ch.collect()\n  \n  output:\n    path 'kaiju_summary.tsv' into kaiju2mqc_ch\n  \n  script:\n  \"\"\"\n  kaiju2table \\\n    -t nodes.dmp \\\n    -n names.dmp \\\n    -r genus -m 1.0 \\\n    -o kaiju_summary.tsv \\\n    $x\n  \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  kaiju2table \\\n    -t nodes.dmp \\\n    -n names.dmp \\\n    -r genus -m 1.0 \\\n    -o kaiju_summary.tsv \\\n    $x\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dmp_ch_2",
            "kaiju_summary_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "kaiju2mqc_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "publishDir params.outdir, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "KronaDB": {
        "name_process": "KronaDB",
        "string_process": "\nprocess KronaDB {\n    output:\n        file(\"krona_db/taxonomy.tab\") optional true into krona_db_ch                       \n\n    when: \n        !params.skip_krona\n        \n    script:\n    \"\"\"\n    ktUpdateTaxonomy.sh krona_db\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    ktUpdateTaxonomy.sh krona_db\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "krona_db_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [],
        "when": "!params.skip_krona",
        "stub": ""
    },
    "KronaFromKraken": {
        "name_process": "KronaFromKraken",
        "string_process": "\nprocess KronaFromKraken {\n    publishDir params.outdir, mode: 'copy'\n\n    input:\n        file(x) from kraken2krona_ch.collect()\n                                               \n        file(\"krona_db/taxonomy.tab\") from krona_db_ch\n    \n    output:\n        file(\"*_taxonomy_krona.html\")\n\n    when:\n        !params.skip_krona\n    \n    script:\n    \"\"\"\n    mkdir krona\n    ktImportTaxonomy -o kraken2_taxonomy_krona.html -tax krona_db $x\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir krona\n    ktImportTaxonomy -o kraken2_taxonomy_krona.html -tax krona_db $x\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "kraken2krona_ch",
            "krona_db_ch"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "publishDir params.outdir, mode: 'copy'"
        ],
        "when": "!params.skip_krona",
        "stub": ""
    },
    "KronaFromKaiju": {
        "name_process": "KronaFromKaiju",
        "string_process": "\nprocess KronaFromKaiju {\n    publishDir params.outdir, mode: 'copy'\n\n    input:\n                                                \n        file(y) from kaiju2krona_ch.collect()\n        file(\"krona_db/taxonomy.tab\") from krona_db_ch\n    \n    output:\n        file(\"*_taxonomy_krona.html\")\n\n    when:\n        !params.skip_krona\n    \n    script:\n    \"\"\"\n    mkdir krona\n    ktImportText -o kaiju_taxonomy_krona.html $y\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir krona\n    ktImportText -o kaiju_taxonomy_krona.html $y\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "kaiju2krona_ch",
            "krona_db_ch"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "publishDir params.outdir, mode: 'copy'"
        ],
        "when": "!params.skip_krona",
        "stub": ""
    },
    "DataTables1": {
        "name_process": "DataTables1",
        "string_process": "\nprocess DataTables1 {\n    tag \"DataTables1 on $sample_id\"\n    publishDir \"${params.outdir}/samples\", mode: 'copy', pattern: '*.html'\n\n    input:\n        tuple sample_id, file(x) from bracken2dt_ch\n        \n    output:\n        file(\"*.html\")\n\n    script: \n    \"\"\"\n    bracken2dt.R $x ${sample_id}_bracken.html\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    bracken2dt.R $x ${sample_id}_bracken.html\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bracken2dt_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "tag \"DataTables1 on $sample_id\"",
            "publishDir \"${params.outdir}/samples\", mode: 'copy', pattern: '*.html'"
        ],
        "when": "",
        "stub": ""
    },
    "DataTables2": {
        "name_process": "DataTables2",
        "string_process": "\nprocess DataTables2 {\n    tag \"DataTables2\"\n    publishDir params.outdir, mode: 'copy'\n\n    input:\n        file(x) from bracken2summary_ch.collect()                                                                 \n    output:\n        file(\"*.html\") optional true                                                 \n        file(\"*.csv\")\n\n                                                                              \n                                                                                      \n    script:\n    \"\"\"\n    bracken2summary.R $x\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    bracken2summary.R $x\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bracken2summary_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "tag \"DataTables2\"",
            "publishDir params.outdir, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "MultiQC": {
        "name_process": "MultiQC",
        "string_process": "\nprocess MultiQC {\n    tag \"MultiQC\"\n    publishDir params.outdir, mode: 'copy'\n\n    input:\n        file x from fastp4mqc_ch.collect()\n        file y from kraken2mqc_ch.collect().ifEmpty([])                                                       \n        file z from kaiju2mqc_ch.ifEmpty([])                                                       \n    output:\n        file \"multiqc_report.html\"\n    \n    script:\n    \"\"\"\n    multiqc --interactive .\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    multiqc --interactive .\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastp4mqc_ch",
            "kraken2mqc_ch",
            "kaiju2mqc_ch"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "angelovangel__nxf-kraken2",
        "directive": [
            "tag \"MultiQC\"",
            "publishDir params.outdir, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}