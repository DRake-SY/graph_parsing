{
    "RiboDBSetUp": {
        "name_process": "RiboDBSetUp",
        "string_process": "\nprocess RiboDBSetUp {\n\t              \n\n\t              \n    input:\n    val ribodb from ribodb_ch\n    \n    output:\n    val ribodir into ribodir_ch1\n    \n\n            \n    script:\n\n    ribo = 'na'\n\n    if (params.ribodb == 'local'){\n        println \"ORPER-INFO: RiboDB not specified -> project dir\"\n\n        if( !workingribo.exists() ) {\n            println \"ORPER-INFO: RiboDB dir not found in project dir -> Created\"\n            if( !workingribo.mkdirs() )    {\n                exit 1, \"Cannot create working directory\"\n            }\n\n            ribodir = workingribo\n\n            \"\"\"\n            cd $workingribo\n            git clone https://bitbucket.org/phylogeno/42-ribo-msas/src/master/MSAs/prokaryotes/\n            mv prokaryotes/MSAs/prokaryotes/*.ali .\n            ali2fasta.pl *.ali --degap 2> log\n            find *.fasta | cut -f1 -d'.' > ribo.list\n            #for f in `cat ribo.list`; do mv \\$f.fasta \\$f-prot_abbr.fasta; done\n            rm -f *.ali\n            echo $workingribo > ribodb_path.txt\n            \"\"\"\n        }\n        else {\n            println \"ORPER-INFO: RiboDB dir found in project dir -> Used\"\n\n            ribodir = workingribo \n\n \t        \"\"\"\n            echo $workingribo > ribodb_path.txt\n\t\t    \"\"\"           \n\n        }\n    }\n\n\telse{\n        println \"ORPER-INFO: RiboDB specified\"\n\n        ribodir = ribodb\n\n\t\t\"\"\"\n        echo $ribodb > ribodb_path.txt\n\t\t\"\"\"\t\t\n    }\n}",
        "nb_lignes_process": 59,
        "string_script": "    ribo = 'na'\n\n    if (params.ribodb == 'local'){\n        println \"ORPER-INFO: RiboDB not specified -> project dir\"\n\n        if( !workingribo.exists() ) {\n            println \"ORPER-INFO: RiboDB dir not found in project dir -> Created\"\n            if( !workingribo.mkdirs() )    {\n                exit 1, \"Cannot create working directory\"\n            }\n\n            ribodir = workingribo\n\n            \"\"\"\n            cd $workingribo\n            git clone https://bitbucket.org/phylogeno/42-ribo-msas/src/master/MSAs/prokaryotes/\n            mv prokaryotes/MSAs/prokaryotes/*.ali .\n            ali2fasta.pl *.ali --degap 2> log\n            find *.fasta | cut -f1 -d'.' > ribo.list\n            #for f in `cat ribo.list`; do mv \\$f.fasta \\$f-prot_abbr.fasta; done\n            rm -f *.ali\n            echo $workingribo > ribodb_path.txt\n            \"\"\"\n        }\n        else {\n            println \"ORPER-INFO: RiboDB dir found in project dir -> Used\"\n\n            ribodir = workingribo \n\n \t        \"\"\"\n            echo $workingribo > ribodb_path.txt\n\t\t    \"\"\"           \n\n        }\n    }\n\n\telse{\n        println \"ORPER-INFO: RiboDB specified\"\n\n        ribodir = ribodb\n\n\t\t\"\"\"\n        echo $ribodb > ribodb_path.txt\n\t\t\"\"\"\t\t\n    }",
        "nb_lignes_script": 44,
        "language_script": "bash",
        "tools": [
            "Ribo",
            "project",
            "GLOGS"
        ],
        "tools_url": [
            "https://bio.tools/ribo",
            "https://bio.tools/project",
            "https://bio.tools/glogs"
        ],
        "tools_dico": [
            {
                "name": "Ribo",
                "uri": "https://bio.tools/ribo",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0099",
                            "term": "RNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Human-computing game that aims to improve the accuracy of RNA alignments already stored in Rfam.",
                "homepage": "http://ribo.cs.mcgill.ca/"
            },
            {
                "name": "project",
                "uri": "https://bio.tools/project",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "project is a program that projects genomic features onto their sequences. Please contact Sarah Djebali (sarah dot djebali at crg dot es for any question).",
                "homepage": "http://big.crg.cat/services/project"
            },
            {
                "name": "GLOGS",
                "uri": "https://bio.tools/glogs",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A method for using covariates to improve power in GWAS with related individuals",
                "homepage": "http://www.bioinformatics.org/~stanhope/GLOGS/"
            }
        ],
        "inputs": [
            "ribodb_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ribodir_ch1"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Taxonomy": {
        "name_process": "Taxonomy",
        "string_process": "\nprocess Taxonomy {\n\t              \n\n\t              \n    input:\n    val taxdump from taxdump_ch\n    \n    output:\n    file \"taxdump_path.txt\" into taxdump_path1\n    file \"taxdump_path.txt\" into taxdump_path2\n    val taxdir into taxdir_ch1\n    val taxdir into taxdir_ch2\n\n            \n    script:\n\n    taxdir = 'na'\n\n    if (params.taxdump == 'local'){\n        println \"ORPER-INFO: Taxdump not specified -> project dir\"\n\n        if( !workingdir.exists() ) {\n            println \"ORPER-INFO: Taxdump dir not found in project dir -> Created\"\n            if( !workingdir.mkdirs() )    {\n                exit 1, \"Cannot create working directory\"\n            }\n\n            taxdir = workingdir \n\n            \"\"\"\n            setup-taxdir.pl --taxdir=$workingdir\n            echo $workingdir > taxdump_path.txt\n            \"\"\"\n        }\n        else {\n            println \"ORPER-INFO: Taxdump dir found in project dir -> Used\"\n\n            taxdir = workingdir \n\n \t        \"\"\"\n            echo $workingdir > taxdump_path.txt\n\t\t    \"\"\"           \n\n        }\n    }\n\n\telse{\n        println \"ORPER-INFO: Taxdump specified\"\n\n        taxdir = taxdump\n\n\t\t\"\"\"\n        echo $taxdump > taxdump_path.txt\n\t\t\"\"\"\t\t\n    }\n}",
        "nb_lignes_process": 55,
        "string_script": "    taxdir = 'na'\n\n    if (params.taxdump == 'local'){\n        println \"ORPER-INFO: Taxdump not specified -> project dir\"\n\n        if( !workingdir.exists() ) {\n            println \"ORPER-INFO: Taxdump dir not found in project dir -> Created\"\n            if( !workingdir.mkdirs() )    {\n                exit 1, \"Cannot create working directory\"\n            }\n\n            taxdir = workingdir \n\n            \"\"\"\n            setup-taxdir.pl --taxdir=$workingdir\n            echo $workingdir > taxdump_path.txt\n            \"\"\"\n        }\n        else {\n            println \"ORPER-INFO: Taxdump dir found in project dir -> Used\"\n\n            taxdir = workingdir \n\n \t        \"\"\"\n            echo $workingdir > taxdump_path.txt\n\t\t    \"\"\"           \n\n        }\n    }\n\n\telse{\n        println \"ORPER-INFO: Taxdump specified\"\n\n        taxdir = taxdump\n\n\t\t\"\"\"\n        echo $taxdump > taxdump_path.txt\n\t\t\"\"\"\t\t\n    }",
        "nb_lignes_script": 38,
        "language_script": "bash",
        "tools": [
            "project"
        ],
        "tools_url": [
            "https://bio.tools/project"
        ],
        "tools_dico": [
            {
                "name": "project",
                "uri": "https://bio.tools/project",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "project is a program that projects genomic features onto their sequences. Please contact Sarah Djebali (sarah dot djebali at crg dot es for any question).",
                "homepage": "http://big.crg.cat/services/project"
            }
        ],
        "inputs": [
            "taxdump_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "taxdump_path1",
            "taxdump_path2",
            "taxdir_ch1",
            "taxdir_ch2"
        ],
        "nb_outputs": 4,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "RefSeq": {
        "name_process": "RefSeq",
        "string_process": "\nprocess RefSeq {\n\t              \n\n\t              \n    input:\n    file taxdump from taxdump_path1\n    val companion from params.companion\n    \n    output:\n    file \"ftp.sh\" into refseq_ftp1\n    file \"ftp.sh\" into refseq_ftp2\n    file \"GCF.tax\" into refseq_tax1\n    file \"GCF.tax\" into refseq_tax2\n\n            \n    script:\n\n    \"\"\"\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/assembly_summary_refseq.txt -O refseq_sum.txt\n    $companion refseq_sum.txt --mode=sum\n    grep -v \"#\" refseq_sum-filt.txt | cut -f1 > GCF.list\n    fetch-tax.pl GCF.list  --taxdir=\\$(<taxdump_path.txt) --item-type=taxid --levels=phylum class order family\n    grep -v \"#\" refseq_sum-filt.txt | cut -f20 > ftp.list\n    grep -v \"#\" refseq_sum-filt.txt | cut -f20 | cut -f10 -d\"/\" > names.list\n    for f in `cat ftp.list `; do echo \"/\"; done > slash.list\n    for f in `cat ftp.list `; do echo \"_genomic.fna.gz\"; done > end1.list\n    for f in `cat ftp.list `; do echo \"wget \"; done > get.list\n    for f in `cat ftp.list `; do echo \" -O \"; done > out.list\n    for f in `cat ftp.list `; do echo \".fna.gz\"; done > end2.list\n    cut -f1,2 -d\"_\" names.list > id.list\n    paste get.list ftp.list slash.list names.list end1.list out.list id.list end2.list > ftp.sh\n    sed -i -e 's/\\t//g' ftp.sh\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/assembly_summary_refseq.txt -O refseq_sum.txt\n    $companion refseq_sum.txt --mode=sum\n    grep -v \"#\" refseq_sum-filt.txt | cut -f1 > GCF.list\n    fetch-tax.pl GCF.list  --taxdir=\\$(<taxdump_path.txt) --item-type=taxid --levels=phylum class order family\n    grep -v \"#\" refseq_sum-filt.txt | cut -f20 > ftp.list\n    grep -v \"#\" refseq_sum-filt.txt | cut -f20 | cut -f10 -d\"/\" > names.list\n    for f in `cat ftp.list `; do echo \"/\"; done > slash.list\n    for f in `cat ftp.list `; do echo \"_genomic.fna.gz\"; done > end1.list\n    for f in `cat ftp.list `; do echo \"wget \"; done > get.list\n    for f in `cat ftp.list `; do echo \" -O \"; done > out.list\n    for f in `cat ftp.list `; do echo \".fna.gz\"; done > end2.list\n    cut -f1,2 -d\"_\" names.list > id.list\n    paste get.list ftp.list slash.list names.list end1.list out.list id.list end2.list > ftp.sh\n    sed -i -e 's/\\t//g' ftp.sh\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "taxdump_path1",
            "params"
        ],
        "nb_inputs": 2,
        "outputs": [
            "refseq_ftp1",
            "refseq_ftp2",
            "refseq_tax1",
            "refseq_tax2"
        ],
        "nb_outputs": 4,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "GenBank": {
        "name_process": "GenBank",
        "string_process": "\nprocess GenBank {\n\n                  \n\n\t              \n    input:\n    file taxdump from taxdump_path2\n    val companion from params.companion\n    \n    output:\n    file \"GCA-ftp.sh\" into genbank_ftp1\n    file \"GCA-ftp.sh\" into genbank_ftp2\n    file \"GCA.tax\" into genbank_tax1\n    file \"GCA.tax\" into genbank_tax2\n\n            \n    script:\n    if (params.genbank == 'yes'){\n        println \"Add GenBank Genomes activated\"\n        \"\"\"\n        wget ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/assembly_summary_genbank.txt -O genbank_sum.txt\n        $companion genbank_sum.txt --mode=sum\n        grep -v \"#\" genbank_sum-filt.txt | cut -f1 > GCA.list\n        fetch-tax.pl GCA.list  --taxdir=\\$(<taxdump_path.txt) --item-type=taxid --levels=phylum class order family\n        grep -v \"#\" genbank_sum-filt.txt | cut -f20 > ftp.list\n        grep -v \"#\" genbank_sum-filt.txt | cut -f20 | cut -f10 -d\"/\" > names.list\n        for f in `cat ftp.list `; do echo \"/\"; done > slash.list\n        for f in `cat ftp.list `; do echo \"_genomic.fna.gz\"; done > end1.list\n        for f in `cat ftp.list `; do echo \"wget \"; done > get.list\n        for f in `cat ftp.list `; do echo \" -O \"; done > out.list\n        for f in `cat ftp.list `; do echo \".fna.gz\"; done > end2.list\n        cut -f1,2 -d\"_\" names.list > id.list\n        paste get.list ftp.list slash.list names.list end1.list out.list id.list end2.list > GCA-ftp.sh\n        sed -i -e 's/\\t//g' GCA-ftp.sh\n        \"\"\"\n    }\n    else {\n        println \"Add GenBank Genomes NOT activated\"\n        \"\"\"\n        echo \"Add GenBank Genomes NOT activated\" > GCA.tax\n        echo \"Add GenBank Genomes NOT activated\" > GCA-ftp.sh\n        \"\"\"\n\n    }\n\n}",
        "nb_lignes_process": 45,
        "string_script": "    if (params.genbank == 'yes'){\n        println \"Add GenBank Genomes activated\"\n        \"\"\"\n        wget ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/assembly_summary_genbank.txt -O genbank_sum.txt\n        $companion genbank_sum.txt --mode=sum\n        grep -v \"#\" genbank_sum-filt.txt | cut -f1 > GCA.list\n        fetch-tax.pl GCA.list  --taxdir=\\$(<taxdump_path.txt) --item-type=taxid --levels=phylum class order family\n        grep -v \"#\" genbank_sum-filt.txt | cut -f20 > ftp.list\n        grep -v \"#\" genbank_sum-filt.txt | cut -f20 | cut -f10 -d\"/\" > names.list\n        for f in `cat ftp.list `; do echo \"/\"; done > slash.list\n        for f in `cat ftp.list `; do echo \"_genomic.fna.gz\"; done > end1.list\n        for f in `cat ftp.list `; do echo \"wget \"; done > get.list\n        for f in `cat ftp.list `; do echo \" -O \"; done > out.list\n        for f in `cat ftp.list `; do echo \".fna.gz\"; done > end2.list\n        cut -f1,2 -d\"_\" names.list > id.list\n        paste get.list ftp.list slash.list names.list end1.list out.list id.list end2.list > GCA-ftp.sh\n        sed -i -e 's/\\t//g' GCA-ftp.sh\n        \"\"\"\n    }\n    else {\n        println \"Add GenBank Genomes NOT activated\"\n        \"\"\"\n        echo \"Add GenBank Genomes NOT activated\" > GCA.tax\n        echo \"Add GenBank Genomes NOT activated\" > GCA-ftp.sh\n        \"\"\"\n\n    }",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "taxdump_path2",
            "params"
        ],
        "nb_inputs": 2,
        "outputs": [
            "genbank_ftp1",
            "genbank_ftp2",
            "genbank_tax1",
            "genbank_tax2"
        ],
        "nb_outputs": 4,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "GetRefGenomesRefseq": {
        "name_process": "GetRefGenomesRefseq",
        "string_process": "\nprocess GetRefGenomesRefseq {\n\t              \n\n\t              \n    input:\n    val refgroup from params.refgroup\n    val taxa from params.reftaxolevel\n    val companion from params.companion\n    file \"ftp.sh\" from refseq_ftp1\n    file \"GCF.tax\" from refseq_tax1\n    \n    output:\n    file '*-abbr.fna' into refgenomes_ch1\n    file '*-abbr.fna' into refgenomes_ch2\n    file '*-abbr.fna' into refgenomes_ch3\n    file 'reduce-ftp.sh' into reduceRefFtp_ch\n    file 'GCF.refgroup.uniq' into refgroupRefseqGC_ch\n\n            \n    script:\n\n    \"\"\"\n    #Produce list of GCF IDs with reference group and taxa levels\n    $companion GCF.tax --mode=fetch --taxa=$taxa --refgroup=$refgroup\n    for f in `cat GCF.refgroup.uniq`; do grep \\$f ftp.sh; done > reduce-ftp.sh\n    bash reduce-ftp.sh\n    gunzip *.gz\n    find *.fna | cut -f1,2 -d\".\" > fna.list\n    for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    #Produce list of GCF IDs with reference group and taxa levels\n    $companion GCF.tax --mode=fetch --taxa=$taxa --refgroup=$refgroup\n    for f in `cat GCF.refgroup.uniq`; do grep \\$f ftp.sh; done > reduce-ftp.sh\n    bash reduce-ftp.sh\n    gunzip *.gz\n    find *.fna | cut -f1,2 -d\".\" > fna.list\n    for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "params",
            "params",
            "params",
            "refseq_ftp1",
            "refseq_tax1"
        ],
        "nb_inputs": 5,
        "outputs": [
            "refgenomes_ch1",
            "refgenomes_ch2",
            "refgenomes_ch3",
            "reduceRefFtp_ch",
            "refgroupRefseqGC_ch"
        ],
        "nb_outputs": 5,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "GetRefGenomesGenbank": {
        "name_process": "GetRefGenomesGenbank",
        "string_process": "\nprocess GetRefGenomesGenbank {\n\n                  \n\n\t              \n    input:\n    val refgroup from params.refgroup\n    val taxa from params.reftaxolevel\n    val companion from params.companion\n    file \"GCA-ftp.sh\" from genbank_ftp1\n    file \"GCA.tax\" from genbank_tax1\n    file 'GCF.refgroup.uniq' from refgroupRefseqGC_ch\n    \n    output:\n    file '*-abbr.fna' into refgenomesGB_ch1\n    file '*-abbr.fna' into refgenomesGB_ch2\n    file '*-abbr.fna' into refgenomesGB_ch3\n    file 'GCA-reduce-ftp.sh' into reduceRefFtpGB_ch\n\n            \n    script:\n    if (params.refgenbank == 'yes'){\n        println \"Add GenBank Genomes activated\"\n        \"\"\"\n        #Produce list of GCA IDs with reference group and taxa levels\n        $companion GCA.tax --mode=fetch --taxa=$taxa --refgroup=$refgroup\n        for f in `cat GCA.refgroup.uniq`; do grep \\$f GCA-ftp.sh; done > GCA-reduce-ftp.sh\n        bash GCA-reduce-ftp.sh\n        gunzip *.gz\n        find *.fna | cut -f1,2 -d\".\" > fna.list\n        for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n        #for fix and proceed , false genbank files\n        echo \"Add GenBank Genomes activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes activated\" > FALSE-GCA-reduce-ftp.sh\n        \"\"\"\n    }\n    else {\n        println \"Add GenBank Genomes NOT activated\"\n        \"\"\"\n        echo \"Add GenBank Genomes NOT activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes NOT activated\" > GCA-reduce-ftp.sh\n        \"\"\"\n\n    }\n\n}",
        "nb_lignes_process": 45,
        "string_script": "    if (params.refgenbank == 'yes'){\n        println \"Add GenBank Genomes activated\"\n        \"\"\"\n        #Produce list of GCA IDs with reference group and taxa levels\n        $companion GCA.tax --mode=fetch --taxa=$taxa --refgroup=$refgroup\n        for f in `cat GCA.refgroup.uniq`; do grep \\$f GCA-ftp.sh; done > GCA-reduce-ftp.sh\n        bash GCA-reduce-ftp.sh\n        gunzip *.gz\n        find *.fna | cut -f1,2 -d\".\" > fna.list\n        for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n        #for fix and proceed , false genbank files\n        echo \"Add GenBank Genomes activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes activated\" > FALSE-GCA-reduce-ftp.sh\n        \"\"\"\n    }\n    else {\n        println \"Add GenBank Genomes NOT activated\"\n        \"\"\"\n        echo \"Add GenBank Genomes NOT activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes NOT activated\" > GCA-reduce-ftp.sh\n        \"\"\"\n\n    }",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "params",
            "params",
            "params",
            "genbank_ftp1",
            "genbank_tax1",
            "refgroupRefseqGC_ch"
        ],
        "nb_inputs": 6,
        "outputs": [
            "refgenomesGB_ch1",
            "refgenomesGB_ch2",
            "refgenomesGB_ch3",
            "reduceRefFtpGB_ch"
        ],
        "nb_outputs": 4,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "RefGenomesCheckm": {
        "name_process": "RefGenomesCheckm",
        "string_process": "\nprocess RefGenomesCheckm {\n\t              \n\n\t              \n    input:\n    file x from refgenomes_ch1\n    file x from refgenomesGB_ch1\n    val cpu from params.cpu\n\n    output:\n    file \"RefGenomes.Checkm\" into refGenomesCheckm_ch\n\n            \n    script:\n\n    \"\"\"\n    #Delete false Genbak files\n    rm -rf FALSE*\n    mkdir RefGenomes\n    mv *.fna RefGenomes/\n    checkm lineage_wf -t $cpu -x fna RefGenomes runc > checkm.result\n    echo \"#genome,completeness,contamination\" > part1\n    tr -s \" \" < checkm.result | grep \"GC\" | cut -f2,14,15 -d\" \" > part2\n    sed -i -e 's/ /,/g' part2\n    cat part1 part2 > RefGenomes.Checkm\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    #Delete false Genbak files\n    rm -rf FALSE*\n    mkdir RefGenomes\n    mv *.fna RefGenomes/\n    checkm lineage_wf -t $cpu -x fna RefGenomes runc > checkm.result\n    echo \"#genome,completeness,contamination\" > part1\n    tr -s \" \" < checkm.result | grep \"GC\" | cut -f2,14,15 -d\" \" > part2\n    sed -i -e 's/ /,/g' part2\n    cat part1 part2 > RefGenomes.Checkm\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "refgenomes_ch1",
            "refgenomesGB_ch1",
            "params"
        ],
        "nb_inputs": 3,
        "outputs": [
            "refGenomesCheckm_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "RefGenomesBarnapp": {
        "name_process": "RefGenomesBarnapp",
        "string_process": "\nprocess RefGenomesBarnapp  {\n\t              \n\n\t              \n    input:\n    file x from refgenomes_ch2\n    file x from refgenomesGB_ch2\n    val companion from params.companion\n\n    output:\n    file \"genome-with-ssu.list\" into refGenomeWithSsu_ch\n    file \"all_16s-nodupe.fna\" into refRnammer_ch\n\n            \n    script:\n\n    \"\"\"\n    #Delete false Genbak files\n    rm -rf FALSE*\n    find *.fna | cut -f1 -d\"-\" > fna.list\n    for f in `cat fna.list`; do barrnap \\$f-abbr.fna --outseq \\$f-barnap.fna --threads 1; done\n    #for f in `cat fna.list`; do fasta2ali.pl \\$f-barnap.fna; done\n    #for f in `cat fna.list`; do grep -A1 '16S' \\$f-barnap.ali > \\$f-16s.ali; done\n    #for f in `cat fna.list`; do ali2fasta.pl \\$f-16s.ali; mv \\$f-16s.fasta \\$f-16s.fna; done\n    cat *barnap.fna > all_barnap.fna\n    $companion all_barnap.fna --mode=barnap\n    #cat *-16s.fna > all_16s.fna\n    #$companion all_16s.fna --mode=barnap\n    #RNAMMER\n    #for f in `cat fna.list`; do rnammer -S bac -m ssu -d -gff \\$f.gff -h \\$f.hmm -f `basename \\$f .fa`_16s.fna < \\$f-abbr.fna; done\n    #cat *_16s.fna > all_16s.fna\n    #$companion all_16s.fna --mode=rnammer\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n    #Delete false Genbak files\n    rm -rf FALSE*\n    find *.fna | cut -f1 -d\"-\" > fna.list\n    for f in `cat fna.list`; do barrnap \\$f-abbr.fna --outseq \\$f-barnap.fna --threads 1; done\n    #for f in `cat fna.list`; do fasta2ali.pl \\$f-barnap.fna; done\n    #for f in `cat fna.list`; do grep -A1 '16S' \\$f-barnap.ali > \\$f-16s.ali; done\n    #for f in `cat fna.list`; do ali2fasta.pl \\$f-16s.ali; mv \\$f-16s.fasta \\$f-16s.fna; done\n    cat *barnap.fna > all_barnap.fna\n    $companion all_barnap.fna --mode=barnap\n    #cat *-16s.fna > all_16s.fna\n    #$companion all_16s.fna --mode=barnap\n    #RNAMMER\n    #for f in `cat fna.list`; do rnammer -S bac -m ssu -d -gff \\$f.gff -h \\$f.hmm -f `basename \\$f .fa`_16s.fna < \\$f-abbr.fna; done\n    #cat *_16s.fna > all_16s.fna\n    #$companion all_16s.fna --mode=rnammer\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "refgenomes_ch2",
            "refgenomesGB_ch2",
            "params"
        ],
        "nb_inputs": 3,
        "outputs": [
            "refGenomeWithSsu_ch",
            "refRnammer_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "RefGenomesFilter": {
        "name_process": "RefGenomesFilter",
        "string_process": "\nprocess RefGenomesFilter {\n\t              \n\n\t              \n    input:\n    file \"genome-with-ssu.list\" from refGenomeWithSsu_ch\n    file \"RefGenomes.Checkm\" from refGenomesCheckm_ch\n    val companion from params.companion\n\n    output:\n    file \"reliable-genomes.list\" into refReliablegenomes_ch\n\n            \n    script:\n\n    \"\"\"\n    $companion RefGenomes.Checkm --mode=checkm --ssu=yes\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    $companion RefGenomes.Checkm --mode=checkm --ssu=yes\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "refGenomeWithSsu_ch",
            "refGenomesCheckm_ch",
            "params"
        ],
        "nb_inputs": 3,
        "outputs": [
            "refReliablegenomes_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "RefGenomesDereplication": {
        "name_process": "RefGenomesDereplication",
        "string_process": "\nprocess RefGenomesDereplication {\n\n                  \n\n\t              \n    input:\n    file x from refgenomes_ch3\n    file x from refgenomesGB_ch3\n    file \"reliable-genomes.list\" from refReliablegenomes_ch\n    val cpu from params.cpu\n    \n    output:\n    file \"reliable-genomes-dereplicated.list\" into refDrepReliablegenomes_ch\n\n            \n    script:\n    if (params.dRep == 'yes'){\n        println \"Ref Genomes dereplication activated\"\n        \"\"\"\n        mkdir Genomes\n        for f in `cat reliable-genomes.list`; do mv \\$f*.fna Genomes; done\n        rm -rf *.fna\n        dRep dereplicate DREP -g Genomes/*.fna -p $cpu\n        cd DREP/dereplicated_genomes/\n        find *.fna | cut -f1 -d'-' > reliable-genomes-dereplicated.list\n        mv reliable-genomes-dereplicated.list ../../\n        \"\"\"\n    }\n    else {\n        println \"Ref Genomes dereplication not activated\"\n        \"\"\"\n        cp reliable-genomes.list reliable-genomes-dereplicated.list\n        \"\"\"\n\n    }\n\n}",
        "nb_lignes_process": 36,
        "string_script": "    if (params.dRep == 'yes'){\n        println \"Ref Genomes dereplication activated\"\n        \"\"\"\n        mkdir Genomes\n        for f in `cat reliable-genomes.list`; do mv \\$f*.fna Genomes; done\n        rm -rf *.fna\n        dRep dereplicate DREP -g Genomes/*.fna -p $cpu\n        cd DREP/dereplicated_genomes/\n        find *.fna | cut -f1 -d'-' > reliable-genomes-dereplicated.list\n        mv reliable-genomes-dereplicated.list ../../\n        \"\"\"\n    }\n    else {\n        println \"Ref Genomes dereplication not activated\"\n        \"\"\"\n        cp reliable-genomes.list reliable-genomes-dereplicated.list\n        \"\"\"\n\n    }",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "dRep"
        ],
        "tools_url": [
            "https://bio.tools/drep"
        ],
        "tools_dico": [
            {
                "name": "dRep",
                "uri": "https://bio.tools/drep",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3209",
                                    "term": "Genome comparison"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3209",
                                    "term": "Genomic region matching"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Fast and accurate genomic comparisons that enables improved genome recovery from metagenomes through de-replication.",
                "homepage": "https://github.com/MrOlm/drep"
            }
        ],
        "inputs": [
            "refgenomes_ch3",
            "refgenomesGB_ch3",
            "refReliablegenomes_ch",
            "params"
        ],
        "nb_inputs": 4,
        "outputs": [
            "refDrepReliablegenomes_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "GetRefRelProteomes": {
        "name_process": "GetRefRelProteomes",
        "string_process": "\nprocess GetRefRelProteomes {\n\t              \n\n\t              \n    input:\n    file \"reliable-genomes.list\" from refDrepReliablegenomes_ch\n    file 'reduce-ftp.sh' from reduceRefFtp_ch\n    file 'GCA-reduce-ftp.sh' from reduceRefFtpGB_ch\n\n    output:\n    file '*-abbr.faa' into refReliableproteomes_ch\n\n            \n    script:\n\n    \"\"\"\n    cat reduce-ftp.sh GCA-reduce-ftp.sh > combined-reduce-ftp.sh\n    for f in `cat reliable-genomes.list `; do grep \"\\$f\" combined-reduce-ftp.sh ; done > reliable.sh\n    sed -i -e 's/_genomic.fna/_protein.faa/g' reliable.sh\n    sed -i -e 's/.fna.gz/.faa.gz/g' reliable.sh\n    bash reliable.sh\n    find . -name '*.gz' -size 0 | cut -f2 -d\"/\" > empty.list\n    for f in `cat empty.list `; do rm -rf \\$f; done\n    gunzip *.gz\n    find *.faa | cut -f1,2 -d\".\" > faa.list\n    for f in `cat faa.list`; do inst-abbr-ids.pl \\$f*.faa --id-regex=:DEF --id-prefix=\\$f; done\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    cat reduce-ftp.sh GCA-reduce-ftp.sh > combined-reduce-ftp.sh\n    for f in `cat reliable-genomes.list `; do grep \"\\$f\" combined-reduce-ftp.sh ; done > reliable.sh\n    sed -i -e 's/_genomic.fna/_protein.faa/g' reliable.sh\n    sed -i -e 's/.fna.gz/.faa.gz/g' reliable.sh\n    bash reliable.sh\n    find . -name '*.gz' -size 0 | cut -f2 -d\"/\" > empty.list\n    for f in `cat empty.list `; do rm -rf \\$f; done\n    gunzip *.gz\n    find *.faa | cut -f1,2 -d\".\" > faa.list\n    for f in `cat faa.list`; do inst-abbr-ids.pl \\$f*.faa --id-regex=:DEF --id-prefix=\\$f; done\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "refDrepReliablegenomes_ch",
            "reduceRefFtp_ch",
            "reduceRefFtpGB_ch"
        ],
        "nb_inputs": 3,
        "outputs": [
            "refReliableproteomes_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "GetOutGenomesRefSeq": {
        "name_process": "GetOutGenomesRefSeq",
        "string_process": "\nprocess GetOutGenomesRefSeq {\n\t              \n\n\t              \n    input:\n    val outgroup from params.outgroup\n    val taxa from params.outtaxolevel\n    val companion from params.companion\n    file \"ftp.sh\" from refseq_ftp2\n    file \"GCF.tax\" from refseq_tax2\n    \n    output:\n    file '*-abbr.fna' into outgenomes_ch1\n    file '*-abbr.fna' into outgenomes_ch2\n    file '*-abbr.fna' into outgenomes_ch3\n    file 'reduce-ftp.sh' into reduceOutFtp_ch\n    file 'GCF.outgroup.uniq' into outgroupRefseqGC_ch\n\n            \n    script:\n\n    \"\"\"\n    #Produce list of GCF IDs with reference outgroup and taxa levels\n    $companion GCF.tax --mode=fetch --taxa=$taxa --refgroup=$outgroup\n    mv GCF.refgroup.uniq GCF.outgroup.uniq\n    for f in `cat GCF.outgroup.uniq`; do grep \\$f ftp.sh; done > reduce-ftp.sh\n    bash reduce-ftp.sh\n    #create a false file, gunziped, in case no outgroup could be found in refseq\n    echo \">FALSE FALSE\" > False.1.fna\n    gzip False.1.fna\n    #all files together, including false\n    gunzip *.gz\n    find *.fna | cut -f1,2 -d\".\" > fna.list\n    for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    \"\"\"\n    #Produce list of GCF IDs with reference outgroup and taxa levels\n    $companion GCF.tax --mode=fetch --taxa=$taxa --refgroup=$outgroup\n    mv GCF.refgroup.uniq GCF.outgroup.uniq\n    for f in `cat GCF.outgroup.uniq`; do grep \\$f ftp.sh; done > reduce-ftp.sh\n    bash reduce-ftp.sh\n    #create a false file, gunziped, in case no outgroup could be found in refseq\n    echo \">FALSE FALSE\" > False.1.fna\n    gzip False.1.fna\n    #all files together, including false\n    gunzip *.gz\n    find *.fna | cut -f1,2 -d\".\" > fna.list\n    for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "params",
            "params",
            "params",
            "refseq_ftp2",
            "refseq_tax2"
        ],
        "nb_inputs": 5,
        "outputs": [
            "outgenomes_ch1",
            "outgenomes_ch2",
            "outgenomes_ch3",
            "reduceOutFtp_ch",
            "outgroupRefseqGC_ch"
        ],
        "nb_outputs": 5,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "GetOutGenomesGenbank": {
        "name_process": "GetOutGenomesGenbank",
        "string_process": "\nprocess GetOutGenomesGenbank {\n\n                  \n\n\t              \n    input:\n    val outgroup from params.outgroup\n    val taxa from params.outtaxolevel\n    val companion from params.companion\n    file \"GCA-ftp.sh\" from genbank_ftp2\n    file \"GCA.tax\" from genbank_tax2\n    file 'GCF.outgroup.uniq' from outgroupRefseqGC_ch\n    \n    output:\n    file '*-abbr.fna' into outgenomesGB_ch1\n    file '*-abbr.fna' into outgenomesGB_ch2\n    file '*-abbr.fna' into outgenomesGB_ch3\n    file 'GCA-reduce-ftp.sh' into reduceOutFtpGB_ch\n\n            \n    script:\n    if (params.outgenbank == 'yes'){\n        println \"Add GenBank Genomes activated\"\n        \"\"\"\n        #Produce list of GCA IDs with outgroup group and taxa levels\n        cp GCF.outgroup.uniq GCF.refgroup.uniq #for companion\n        $companion GCA.tax --mode=fetch --taxa=$taxa --refgroup=$outgroup\n        mv GCA.refgroup.uniq GCA.outgroup.uniq\n        for f in `cat GCA.outgroup.uniq`; do grep \\$f GCA-ftp.sh; done > GCA-reduce-ftp.sh\n        bash GCA-reduce-ftp.sh\n        gunzip *.gz\n        find *.fna | cut -f1,2 -d\".\" > fna.list\n        for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n        #for fix and proceed , false genbank files\n        echo \"Add GenBank Genomes activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes activated\" > FALSE-GCA-reduce-ftp.sh\n        \"\"\"\n    }\n    else {\n        println \"Add GenBank Genomes NOT activated\"\n        \"\"\"\n        echo \"Add GenBank Genomes NOT activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes NOT activated\" > GCA-reduce-ftp.sh\n        \"\"\"\n\n    }\n\n}",
        "nb_lignes_process": 47,
        "string_script": "    if (params.outgenbank == 'yes'){\n        println \"Add GenBank Genomes activated\"\n        \"\"\"\n        #Produce list of GCA IDs with outgroup group and taxa levels\n        cp GCF.outgroup.uniq GCF.refgroup.uniq #for companion\n        $companion GCA.tax --mode=fetch --taxa=$taxa --refgroup=$outgroup\n        mv GCA.refgroup.uniq GCA.outgroup.uniq\n        for f in `cat GCA.outgroup.uniq`; do grep \\$f GCA-ftp.sh; done > GCA-reduce-ftp.sh\n        bash GCA-reduce-ftp.sh\n        gunzip *.gz\n        find *.fna | cut -f1,2 -d\".\" > fna.list\n        for f in `cat fna.list`; do inst-abbr-ids.pl \\$f*.fna --id-regex=:DEF --id-prefix=\\$f; done\n        #for fix and proceed , false genbank files\n        echo \"Add GenBank Genomes activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes activated\" > FALSE-GCA-reduce-ftp.sh\n        \"\"\"\n    }\n    else {\n        println \"Add GenBank Genomes NOT activated\"\n        \"\"\"\n        echo \"Add GenBank Genomes NOT activated\" > FALSE-abbr.fna\n        echo \"Add GenBank Genomes NOT activated\" > GCA-reduce-ftp.sh\n        \"\"\"\n\n    }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "params",
            "params",
            "params",
            "genbank_ftp2",
            "genbank_tax2",
            "outgroupRefseqGC_ch"
        ],
        "nb_inputs": 6,
        "outputs": [
            "outgenomesGB_ch1",
            "outgenomesGB_ch2",
            "outgenomesGB_ch3",
            "reduceOutFtpGB_ch"
        ],
        "nb_outputs": 4,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "OutGenomesCheckm": {
        "name_process": "OutGenomesCheckm",
        "string_process": "\nprocess OutGenomesCheckm {\n\t              \n\n\t              \n    input:\n    file x from outgenomes_ch1\n    file x from outgenomesGB_ch1\n    val cpu from params.cpu\n\n    output:\n    file \"OutGenomes.Checkm\" into outGenomesCheckm_ch\n\n            \n    script:\n\n    \"\"\"\n    #pyenv local 2.7.6\n    #delete false file\n    rm -f False*\n    rm -f FALSE*\n    mkdir OutGenomes\n    mv *.fna OutGenomes/\n    checkm lineage_wf -t $cpu -x fna OutGenomes runc > checkm.result\n    echo \"#genome,completeness,contamination\" > part1\n    tr -s \" \" < checkm.result | grep \"GC\" | cut -f2,14,15 -d\" \" > part2\n    sed -i -e 's/ /,/g' part2\n    cat part1 part2 > OutGenomes.Checkm\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    \"\"\"\n    #pyenv local 2.7.6\n    #delete false file\n    rm -f False*\n    rm -f FALSE*\n    mkdir OutGenomes\n    mv *.fna OutGenomes/\n    checkm lineage_wf -t $cpu -x fna OutGenomes runc > checkm.result\n    echo \"#genome,completeness,contamination\" > part1\n    tr -s \" \" < checkm.result | grep \"GC\" | cut -f2,14,15 -d\" \" > part2\n    sed -i -e 's/ /,/g' part2\n    cat part1 part2 > OutGenomes.Checkm\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "outgenomes_ch1",
            "outgenomesGB_ch1",
            "params"
        ],
        "nb_inputs": 3,
        "outputs": [
            "outGenomesCheckm_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "OutGenomesBarnap": {
        "name_process": "OutGenomesBarnap",
        "string_process": "\nprocess OutGenomesBarnap  {\n\t              \n\n\t              \n    input:\n    file x from outgenomes_ch2\n    file x from outgenomesGB_ch2\n    val companion from params.companion\n\n    output:\n    file \"genome-with-ssu.list\" into outGenomeWithSsu_ch\n    file \"all_16s-nodupe.fna\" into outRnammer_ch\n\n            \n    script:\n\n    \"\"\"\n    #delete false file\n    rm -f False*\n    rm -f FALSE*\n    find *.fna | cut -f1 -d\"-\" > fna.list\n    for f in `cat fna.list`; do barrnap \\$f-abbr.fna --outseq \\$f-barnap.fna --threads 1; done\n    #for f in `cat fna.list`; do fasta2ali.pl \\$f-barnap.fna; done\n    #for f in `cat fna.list`; do grep -A1 '16S' \\$f-barnap.ali > \\$f-16s.ali; done\n    #for f in `cat fna.list`; do ali2fasta.pl \\$f-16s.ali; mv \\$f-16s.fasta \\$f-16s.fna; done\n    #cat *-16s.fna > all_16s.fna\n    cat *barnap.fna > all_barnap.fna\n    $companion all_barnap.fna --mode=barnap\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    #delete false file\n    rm -f False*\n    rm -f FALSE*\n    find *.fna | cut -f1 -d\"-\" > fna.list\n    for f in `cat fna.list`; do barrnap \\$f-abbr.fna --outseq \\$f-barnap.fna --threads 1; done\n    #for f in `cat fna.list`; do fasta2ali.pl \\$f-barnap.fna; done\n    #for f in `cat fna.list`; do grep -A1 '16S' \\$f-barnap.ali > \\$f-16s.ali; done\n    #for f in `cat fna.list`; do ali2fasta.pl \\$f-16s.ali; mv \\$f-16s.fasta \\$f-16s.fna; done\n    #cat *-16s.fna > all_16s.fna\n    cat *barnap.fna > all_barnap.fna\n    $companion all_barnap.fna --mode=barnap\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "outgenomes_ch2",
            "outgenomesGB_ch2",
            "params"
        ],
        "nb_inputs": 3,
        "outputs": [
            "outGenomeWithSsu_ch",
            "outRnammer_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "OutGenomesFilter": {
        "name_process": "OutGenomesFilter",
        "string_process": "\nprocess OutGenomesFilter {\n\t              \n\n\t              \n    input:\n    file \"genome-with-ssu.list\" from outGenomeWithSsu_ch\n    file \"OutGenomes.Checkm\" from outGenomesCheckm_ch\n    val companion from params.companion\n\n    output:\n    file \"reliable-genomes.list\" into outReliablegenomes_ch\n\n            \n    script:\n\n    \"\"\"\n    $companion OutGenomes.Checkm --mode=checkm --ssu=yes\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    $companion OutGenomes.Checkm --mode=checkm --ssu=yes\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "outGenomeWithSsu_ch",
            "outGenomesCheckm_ch",
            "params"
        ],
        "nb_inputs": 3,
        "outputs": [
            "outReliablegenomes_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "GetOutRelProteomes": {
        "name_process": "GetOutRelProteomes",
        "string_process": "\nprocess GetOutRelProteomes {\n\t              \n\n\t              \n    input:\n    file \"reliable-genomes.list\" from outReliablegenomes_ch\n    file 'reduce-ftp.sh' from reduceOutFtp_ch\n    file 'GCA-reduce-ftp.sh' from reduceOutFtpGB_ch\n    file x from outgenomes_ch3\n    file x from outgenomesGB_ch3\n\n    output:\n    file '*-abbr.faa' into outReliableproteomes_ch\n\n            \n    script:\n\n    \"\"\"\n    #Take only 10 Genomes for outgroup\n    head -n10  reliable-genomes.list > reliable-n10.list\n    mkdir N10\n    for f in `cat reliable-n10.list`; do mv \\$f*.fna N10/; done\n    rm -rf *.fna\n    cd N10/\n    for f in `cat ../reliable-n10.list`; do prodigal -i \\$f-abbr.fna -o \\$f.genes -a \\$f.faa; done\n    for f in `cat ../reliable-n10.list`; do inst-abbr-ids.pl \\$f.faa --id-regex=:DEF; done\n    for f in `cat ../reliable-n10.list`; do sed -i -e 's/|GCA_/GCA_/g' \\$f-abbr.faa; done\n    for f in `cat ../reliable-n10.list`; do sed -i -e 's/|GCF_/GCF_/g' \\$f-abbr.faa; done\n    mv *abbr.faa ../\n    cd  ../\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    #Take only 10 Genomes for outgroup\n    head -n10  reliable-genomes.list > reliable-n10.list\n    mkdir N10\n    for f in `cat reliable-n10.list`; do mv \\$f*.fna N10/; done\n    rm -rf *.fna\n    cd N10/\n    for f in `cat ../reliable-n10.list`; do prodigal -i \\$f-abbr.fna -o \\$f.genes -a \\$f.faa; done\n    for f in `cat ../reliable-n10.list`; do inst-abbr-ids.pl \\$f.faa --id-regex=:DEF; done\n    for f in `cat ../reliable-n10.list`; do sed -i -e 's/|GCA_/GCA_/g' \\$f-abbr.faa; done\n    for f in `cat ../reliable-n10.list`; do sed -i -e 's/|GCF_/GCF_/g' \\$f-abbr.faa; done\n    mv *abbr.faa ../\n    cd  ../\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "outReliablegenomes_ch",
            "reduceOutFtp_ch",
            "reduceOutFtpGB_ch",
            "outgenomes_ch3",
            "outgenomesGB_ch3"
        ],
        "nb_inputs": 5,
        "outputs": [
            "outReliableproteomes_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "RiboDBFortytwo": {
        "name_process": "RiboDBFortytwo",
        "string_process": "\nprocess RiboDBFortytwo {\n\t              \n\n\t              \n    input:\n    val cpu from params.cpu\n    file x from refReliableproteomes_ch\n    file x from outReliableproteomes_ch\n    val ribodb from params.ribodb\n    val taxdir from taxdir_ch1\n    val companion from params.companion\n    val ribodir from ribodir_ch1\n\n    output:\n    file '*enrich.fasta' into enrichedRiboDB_ch\n\n            \n    script:\n\n    \"\"\"\n    #Reference organism part \n    mkdir ref-banks\n    cd ref-banks/\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/022/565/GCA_000022565.1_ASM2256v1/GCA_000022565.1_ASM2256v1_protein.faa.gz -O GCA_000022565.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/019/605/GCA_000019605.1_ASM1960v1/GCA_000019605.1_ASM1960v1_protein.faa.gz -O GCA_000019605.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/956/175/GCA_000956175.1_ASM95617v1/GCA_000956175.1_ASM95617v1_protein.faa.gz -O GCA_000956175.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/024/005/GCA_000024005.1_ASM2400v1/GCA_000024005.1_ASM2400v1_protein.faa.gz -O GCA_000024005.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/026/905/GCA_000026905.1_ASM2690v1/GCA_000026905.1_ASM2690v1_protein.faa.gz -O GCA_000026905.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/026/545/GCA_000026545.1_ASM2654v1/GCA_000026545.1_ASM2654v1_protein.faa.gz -O GCA_000026545.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/145/985/GCA_000145985.1_ASM14598v1/GCA_000145985.1_ASM14598v1_protein.faa.gz -O GCA_000145985.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/165/505/GCA_000165505.1_ASM16550v1/GCA_000165505.1_ASM16550v1_protein.faa.gz -O GCA_000165505.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/008/085/GCA_000008085.1_ASM808v1/GCA_000008085.1_ASM808v1_protein.faa.gz -O GCA_000008085.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/698/785/GCA_000698785.1_ASM69878v1/GCA_000698785.1_ASM69878v1_protein.faa.gz -O GCA_000698785.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/725/425/GCA_000725425.1_ASM72542v1/GCA_000725425.1_ASM72542v1_protein.faa.gz -O GCA_000725425.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/091/725/GCA_000091725.1_ASM9172v1/GCA_000091725.1_ASM9172v1_protein.faa.gz -O GCA_000091725.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/011/505/GCA_000011505.1_ASM1150v1/GCA_000011505.1_ASM1150v1_protein.faa.gz -O GCA_000011505.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/012/285/GCA_000012285.1_ASM1228v1/GCA_000012285.1_ASM1228v1_protein.faa.gz -O GCA_000012285.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/014/585/GCA_000014585.1_ASM1458v1/GCA_000014585.1_ASM1458v1_protein.faa.gz -O GCA_000014585.1.faa.gz\n    gunzip *.gz\n    find *.faa | cut -f1,2 -d\".\" > faa.list\n    for f in `cat faa.list`; do makeblastdb -in \\$f.faa -dbtype prot -parse_seqids -out \\$f; done\n    for f in `cat faa.list `; do echo \".psq\" ; done > end.list\n    paste faa.list end.list > part1\n    sed -i -e 's/\\t//g' part1\n    #paste part1 faa.list > ref-bank-mapper.idm\n    paste faa.list part1 > ref-bank-mapper.idm\n    cd ..\n\n    #Define Queries\n    echo \"Sulfolobus solfataricus_2287\" >> queries.idl\n    echo \"Thermoproteus uzoniensis_999630\" >> queries.idl\n    echo \"Vulcanisaeta moutnovskia_985053\" >> queries.idl\n    echo \"Flavobacterium psychrophilum_96345\" >> queries.idl\n    echo \"Brucella suis_645170\" >> queries.idl\n    echo \"Burkholderia mallei_13373\" >> queries.idl\n    echo \"Neisseria meningitidis_487\" >> queries.idl\n    echo \"Helicobacter pylori_210\" >> queries.idl\n    echo \"Escherichia coli_83333\" >> queries.idl\n    echo \"Yersinia pestis_632\" >> queries.idl\n    echo \"Pseudomonas aeruginosa_287\" >> queries.idl\n    echo \"Francisella philomiragia_28110\" >> queries.idl\n    echo \"Xanthomonas citri_611301\" >> queries.idl\n    echo \"Chlamydia pneumoniae_83558\" >> queries.idl\n    echo \"Corynebacterium pseudotuberculosis_1719\" >> queries.idl\n    echo \"Mycobacterium tuberculosis_1773\" >> queries.idl\n    echo \"Bacillus anthracis_1392\" >> queries.idl\n    echo \"Listeria monocytogenes_1639\" >> queries.idl\n    echo \"Staphylococcus aureus_1074919\" >> queries.idl\n    echo \"Streptococcus agalactiae_1311\" >> queries.idl\n\n    #Part for genomes to add\n    mkdir genomes-to-add\n    mv *abbr.faa genomes-to-add/\n    cd genomes-to-add/\n    find *.faa | cut -f1 -d\"-\" > genomes.list\n    for f in `cat genomes.list`; do makeblastdb -in \\$f-abbr.faa -dbtype prot -parse_seqids -out \\$f; done\n    for f in `cat genomes.list`; do echo \".psq\"; done  > end.list\n    paste genomes.list end.list > part1\n    sed -i -e 's/\\t//g' part1\n    find *abbr.faa | cut -f1,2 -d\".\" > part2\n    #paste part1 part2 > bank-mapper.idm\n    paste part2 part1 > bank-mapper.idm\n    cd ..\n   \n    #Part for alignements\n    mkdir ribodb\n    cp $ribodir/*.fasta ribodb/\n    \n    #Generate yaml\n    yaml-generator-42.pl --run_mode=phylogenomic --out_suffix=-ORPER --queries queries.idl --evalue=1e-05 --homologues_seg=yes \\\n    --max_target_seqs=10000 --templates_seg=no --bank_dir genomes-to-add --bank_suffix=.psq --bank_mapper genomes-to-add/bank-mapper.idm --ref_brh=on \\\n    --ref_bank_dir ref-banks --ref_bank_suffix=.psq --ref_bank_mapper ref-banks/ref-bank-mapper.idm --ref_org_mul=0.3 --ref_score_mul=0.99 \\\n    --trim_homologues==off --ali_keep_lengthened_seqs=keep --aligner_mode=off --tax_reports=off --tax_dir $taxdir \\\n    --megan_like --tol_check=off\n\n    #run forty-two\n    forty-two.pl ribodb/*.fasta --config=config-ORPER.yaml --verbosity=1 --threads=$cpu\n\n    #extract new sequences from enriched ribodb\n    cd ribodb/\n    fasta2ali.pl *-ORPER.fasta\n    grep -c \"#NEW\" *ORPER.fasta > count-enrich.list\n    $companion count-enrich.list --mode=forty\n    for f in `cat enrich.list`; do grep -A1 \"#NEW#\" \\$f.ali > \\$f-enrich.ali; done\n    ali2fasta.pl --degap --noguessing *enrich.ali\n    mv *enrich.fasta ../\n    cd ..\n    \"\"\"\n}",
        "nb_lignes_process": 108,
        "string_script": "    \"\"\"\n    #Reference organism part \n    mkdir ref-banks\n    cd ref-banks/\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/022/565/GCA_000022565.1_ASM2256v1/GCA_000022565.1_ASM2256v1_protein.faa.gz -O GCA_000022565.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/019/605/GCA_000019605.1_ASM1960v1/GCA_000019605.1_ASM1960v1_protein.faa.gz -O GCA_000019605.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/956/175/GCA_000956175.1_ASM95617v1/GCA_000956175.1_ASM95617v1_protein.faa.gz -O GCA_000956175.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/024/005/GCA_000024005.1_ASM2400v1/GCA_000024005.1_ASM2400v1_protein.faa.gz -O GCA_000024005.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/026/905/GCA_000026905.1_ASM2690v1/GCA_000026905.1_ASM2690v1_protein.faa.gz -O GCA_000026905.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/026/545/GCA_000026545.1_ASM2654v1/GCA_000026545.1_ASM2654v1_protein.faa.gz -O GCA_000026545.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/145/985/GCA_000145985.1_ASM14598v1/GCA_000145985.1_ASM14598v1_protein.faa.gz -O GCA_000145985.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/165/505/GCA_000165505.1_ASM16550v1/GCA_000165505.1_ASM16550v1_protein.faa.gz -O GCA_000165505.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/008/085/GCA_000008085.1_ASM808v1/GCA_000008085.1_ASM808v1_protein.faa.gz -O GCA_000008085.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/698/785/GCA_000698785.1_ASM69878v1/GCA_000698785.1_ASM69878v1_protein.faa.gz -O GCA_000698785.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/725/425/GCA_000725425.1_ASM72542v1/GCA_000725425.1_ASM72542v1_protein.faa.gz -O GCA_000725425.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/091/725/GCA_000091725.1_ASM9172v1/GCA_000091725.1_ASM9172v1_protein.faa.gz -O GCA_000091725.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/011/505/GCA_000011505.1_ASM1150v1/GCA_000011505.1_ASM1150v1_protein.faa.gz -O GCA_000011505.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/012/285/GCA_000012285.1_ASM1228v1/GCA_000012285.1_ASM1228v1_protein.faa.gz -O GCA_000012285.1.faa.gz\n    wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/014/585/GCA_000014585.1_ASM1458v1/GCA_000014585.1_ASM1458v1_protein.faa.gz -O GCA_000014585.1.faa.gz\n    gunzip *.gz\n    find *.faa | cut -f1,2 -d\".\" > faa.list\n    for f in `cat faa.list`; do makeblastdb -in \\$f.faa -dbtype prot -parse_seqids -out \\$f; done\n    for f in `cat faa.list `; do echo \".psq\" ; done > end.list\n    paste faa.list end.list > part1\n    sed -i -e 's/\\t//g' part1\n    #paste part1 faa.list > ref-bank-mapper.idm\n    paste faa.list part1 > ref-bank-mapper.idm\n    cd ..\n\n    #Define Queries\n    echo \"Sulfolobus solfataricus_2287\" >> queries.idl\n    echo \"Thermoproteus uzoniensis_999630\" >> queries.idl\n    echo \"Vulcanisaeta moutnovskia_985053\" >> queries.idl\n    echo \"Flavobacterium psychrophilum_96345\" >> queries.idl\n    echo \"Brucella suis_645170\" >> queries.idl\n    echo \"Burkholderia mallei_13373\" >> queries.idl\n    echo \"Neisseria meningitidis_487\" >> queries.idl\n    echo \"Helicobacter pylori_210\" >> queries.idl\n    echo \"Escherichia coli_83333\" >> queries.idl\n    echo \"Yersinia pestis_632\" >> queries.idl\n    echo \"Pseudomonas aeruginosa_287\" >> queries.idl\n    echo \"Francisella philomiragia_28110\" >> queries.idl\n    echo \"Xanthomonas citri_611301\" >> queries.idl\n    echo \"Chlamydia pneumoniae_83558\" >> queries.idl\n    echo \"Corynebacterium pseudotuberculosis_1719\" >> queries.idl\n    echo \"Mycobacterium tuberculosis_1773\" >> queries.idl\n    echo \"Bacillus anthracis_1392\" >> queries.idl\n    echo \"Listeria monocytogenes_1639\" >> queries.idl\n    echo \"Staphylococcus aureus_1074919\" >> queries.idl\n    echo \"Streptococcus agalactiae_1311\" >> queries.idl\n\n    #Part for genomes to add\n    mkdir genomes-to-add\n    mv *abbr.faa genomes-to-add/\n    cd genomes-to-add/\n    find *.faa | cut -f1 -d\"-\" > genomes.list\n    for f in `cat genomes.list`; do makeblastdb -in \\$f-abbr.faa -dbtype prot -parse_seqids -out \\$f; done\n    for f in `cat genomes.list`; do echo \".psq\"; done  > end.list\n    paste genomes.list end.list > part1\n    sed -i -e 's/\\t//g' part1\n    find *abbr.faa | cut -f1,2 -d\".\" > part2\n    #paste part1 part2 > bank-mapper.idm\n    paste part2 part1 > bank-mapper.idm\n    cd ..\n   \n    #Part for alignements\n    mkdir ribodb\n    cp $ribodir/*.fasta ribodb/\n    \n    #Generate yaml\n    yaml-generator-42.pl --run_mode=phylogenomic --out_suffix=-ORPER --queries queries.idl --evalue=1e-05 --homologues_seg=yes \\\n    --max_target_seqs=10000 --templates_seg=no --bank_dir genomes-to-add --bank_suffix=.psq --bank_mapper genomes-to-add/bank-mapper.idm --ref_brh=on \\\n    --ref_bank_dir ref-banks --ref_bank_suffix=.psq --ref_bank_mapper ref-banks/ref-bank-mapper.idm --ref_org_mul=0.3 --ref_score_mul=0.99 \\\n    --trim_homologues==off --ali_keep_lengthened_seqs=keep --aligner_mode=off --tax_reports=off --tax_dir $taxdir \\\n    --megan_like --tol_check=off\n\n    #run forty-two\n    forty-two.pl ribodb/*.fasta --config=config-ORPER.yaml --verbosity=1 --threads=$cpu\n\n    #extract new sequences from enriched ribodb\n    cd ribodb/\n    fasta2ali.pl *-ORPER.fasta\n    grep -c \"#NEW\" *ORPER.fasta > count-enrich.list\n    $companion count-enrich.list --mode=forty\n    for f in `cat enrich.list`; do grep -A1 \"#NEW#\" \\$f.ali > \\$f-enrich.ali; done\n    ali2fasta.pl --degap --noguessing *enrich.ali\n    mv *enrich.fasta ../\n    cd ..\n    \"\"\"",
        "nb_lignes_script": 88,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "params",
            "refReliableproteomes_ch",
            "outReliableproteomes_ch",
            "params",
            "taxdir_ch1",
            "params",
            "ribodir_ch1"
        ],
        "nb_inputs": 7,
        "outputs": [
            "enrichedRiboDB_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "AlignmentMUSCLE": {
        "name_process": "AlignmentMUSCLE",
        "string_process": "\nprocess AlignmentMUSCLE {\n\t              \n\n\t              \n    input:\n    file '*enrich.fasta' from enrichedRiboDB_ch\n\n    output:\n    file '*enrich-ali.fasta' into alignments_ch\n\n            \n    script:\n\n    \"\"\"\n    #delete empty file\n    #find *enrich.fasta -size  0 -print -delete\n    find *.fasta | cut -f1 -d\".\" > enrich.list\n    #for f in `cat enrich.list`; do mafft --anysymbol --auto --reorder \\$f.fasta > \\$f-ali.fasta; done\n    for f in `cat enrich.list`; do muscle3.8.31_i86linux64 -in \\$f.fasta -out \\$f-ali.fasta; done\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    #delete empty file\n    #find *enrich.fasta -size  0 -print -delete\n    find *.fasta | cut -f1 -d\".\" > enrich.list\n    #for f in `cat enrich.list`; do mafft --anysymbol --auto --reorder \\$f.fasta > \\$f-ali.fasta; done\n    for f in `cat enrich.list`; do muscle3.8.31_i86linux64 -in \\$f.fasta -out \\$f-ali.fasta; done\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "enrichedRiboDB_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "alignments_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "ConcatScafos": {
        "name_process": "ConcatScafos",
        "string_process": "\nprocess ConcatScafos {\n\t              \n\n\t              \n    input:\n    file '*enrich-ali.fasta' from alignments_ch\n\n    output:\n    file 'data-ass.ali' into matrix_ch\n    \n            \n    script:\n\n    \"\"\"\n    #transform aligned fasta into ali format\n    mkdir aligned\n    mkdir a2p\n    mv *.fasta aligned/\n    cd aligned/\n    fasta2ali.pl *.fasta\n    #Filter with BMGE\n    ali2phylip.pl *.ali --bmge-mask=medium --min=0.5 --ali\n    mv *a2p* ../a2p/\n    cd ../\n\n    #Produce concat with scafos\n    scafos in=a2p out=otu\n    scafos in=a2p out=data otu=otu/otu-freq.otu o=ov\n    scafos in=data out=data-ass otu=otu/otu-freq.otu gamma=yes o=gclv g=30 format=fpm\n    cp data-ass/data-ass.ali .\n\n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    \"\"\"\n    #transform aligned fasta into ali format\n    mkdir aligned\n    mkdir a2p\n    mv *.fasta aligned/\n    cd aligned/\n    fasta2ali.pl *.fasta\n    #Filter with BMGE\n    ali2phylip.pl *.ali --bmge-mask=medium --min=0.5 --ali\n    mv *a2p* ../a2p/\n    cd ../\n\n    #Produce concat with scafos\n    scafos in=a2p out=otu\n    scafos in=a2p out=data otu=otu/otu-freq.otu o=ov\n    scafos in=data out=data-ass otu=otu/otu-freq.otu gamma=yes o=gclv g=30 format=fpm\n    cp data-ass/data-ass.ali .\n\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alignments_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "matrix_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "ReferenceTreeRaxml": {
        "name_process": "ReferenceTreeRaxml",
        "string_process": "\nprocess ReferenceTreeRaxml {\n\t              \n\n\t              \n    input:\n    file 'data-ass.ali' from matrix_ch\n    val cpu from params.cpu\n\n    output:\n    file 'reference.tre' into referenceTree_ch\n    file 'GC.list' into referenceTreeList_ch\n\n            \n    script:\n\n    \"\"\"\n    #transform matrix into phylip file  map-ids\n    ali2phylip.pl data-ass.ali --map-ids\n    #compute tree\n    # -x -f a -N 100 will do a 100x rapid bootstrap analysis\n    raxmlHPC-PTHREADS-AVX -T $cpu -s data-ass.phy -n data-ass-RAXML-PROTGAMMALGF-100xRAPIDBP -m PROTGAMMALGF -N 100 -f a -x 1975021703574 -p 1975021703574\n    cp data-ass.idm RAxML_bipartitions.idm\n    sed -i -e 's/-abbr//g' RAxML_bipartitions.idm\n    cut -f1 -d\"@\" RAxML_bipartitions.idm > f1\n    cut -f2 RAxML_bipartitions.idm > f2\n    paste f1 f2 > RAxML_bipartitions.idm\n    format-tree.pl RAxML_bipartitions.data-ass-RAXML-PROTGAMMALGF-100xRAPIDBP --map-ids\n    mv RAxML_bipartitions.tre reference.tre\n    tree2list.pl reference.tre\n    grep -v \"#\" reference.idl > GC.list\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    #transform matrix into phylip file  map-ids\n    ali2phylip.pl data-ass.ali --map-ids\n    #compute tree\n    # -x -f a -N 100 will do a 100x rapid bootstrap analysis\n    raxmlHPC-PTHREADS-AVX -T $cpu -s data-ass.phy -n data-ass-RAXML-PROTGAMMALGF-100xRAPIDBP -m PROTGAMMALGF -N 100 -f a -x 1975021703574 -p 1975021703574\n    cp data-ass.idm RAxML_bipartitions.idm\n    sed -i -e 's/-abbr//g' RAxML_bipartitions.idm\n    cut -f1 -d\"@\" RAxML_bipartitions.idm > f1\n    cut -f2 RAxML_bipartitions.idm > f2\n    paste f1 f2 > RAxML_bipartitions.idm\n    format-tree.pl RAxML_bipartitions.data-ass-RAXML-PROTGAMMALGF-100xRAPIDBP --map-ids\n    mv RAxML_bipartitions.tre reference.tre\n    tree2list.pl reference.tre\n    grep -v \"#\" reference.idl > GC.list\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "gff2ps"
        ],
        "tools_url": [
            "https://bio.tools/gff2ps"
        ],
        "tools_dico": [
            {
                "name": "gff2ps",
                "uri": "https://bio.tools/gff2ps",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1255",
                                "term": "Sequence features"
                            }
                        ]
                    }
                ],
                "description": "Program for visualizing annotations of genomic sequences. The program takes the annotated features on a genomic sequence in GFF format as input, and produces a visual output in PostScript. While it can be used in a very simple way, it also allows for a great degree of customization through a number of options and/or customization files.",
                "homepage": "http://big.crg.cat/services/gff2ps"
            }
        ],
        "inputs": [
            "matrix_ch",
            "params"
        ],
        "nb_inputs": 2,
        "outputs": [
            "referenceTree_ch",
            "referenceTreeList_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "SSUDereplication": {
        "name_process": "SSUDereplication",
        "string_process": "\nprocess SSUDereplication {\n\n                  \n\n\t              \n    input:\n    file 'SSU.fasta' from ssu_ch\n    val cpu from params.cpu\n    \n    output:\n    file 'derepliacted-SSU.fasta' into ssuDereplicated_ch\n\n            \n    script:\n    if (params.cdhit == 'yes'){\n        println \"SSU CD-HIT dereplication activated\"\n        \"\"\"\n        cd-hit -i SSU.fasta -o derepliacted-SSU.fasta -c 1.0 -T $cpu\n        \"\"\"\n    }\n    else {\n        println \"SSU CD-HIT dereplication not activated\"\n        \"\"\"\n        cp SSU.fasta derepliacted-SSU.fasta\n        \"\"\"\n\n    }\n\n}",
        "nb_lignes_process": 28,
        "string_script": "    if (params.cdhit == 'yes'){\n        println \"SSU CD-HIT dereplication activated\"\n        \"\"\"\n        cd-hit -i SSU.fasta -o derepliacted-SSU.fasta -c 1.0 -T $cpu\n        \"\"\"\n    }\n    else {\n        println \"SSU CD-HIT dereplication not activated\"\n        \"\"\"\n        cp SSU.fasta derepliacted-SSU.fasta\n        \"\"\"\n\n    }",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "cd-hit"
        ],
        "tools_url": [
            "https://bio.tools/cd-hit"
        ],
        "tools_dico": [
            {
                "name": "cd-hit",
                "uri": "https://bio.tools/cd-hit",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "Cluster a nucleotide dataset into representative sequences.",
                "homepage": "https://github.com/weizhongli/cdhit"
            }
        ],
        "inputs": [
            "ssu_ch",
            "params"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ssuDereplicated_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "ConstrainTreeRaxml": {
        "name_process": "ConstrainTreeRaxml",
        "string_process": "\nprocess ConstrainTreeRaxml {\n\t              \n\n\t              \n    input:\n    file 'reference.tre' from referenceTree_ch\n    file \"Refall_16s-nodupe.fna\" from refRnammer_ch\n    file \"Outall_16s-nodupe.fna\" from outRnammer_ch\n    file 'SSU.fasta' from ssuDereplicated_ch\n    file 'GC.list' from referenceTreeList_ch\n    val taxdir from taxdir_ch2\n    val cpu from params.cpu\n    val shrink from params.shrink\n    val companion from params.companion\n\n    output:\n    file 'Constained-tree.nex' into constTreeNexus_ch\n    file 'Constained-tree.tre' into constTreeTre_ch\n    file 'SSU-combined-ali-a2p.fasta' into alignementBmge_ch\n    file 'SSU-combined-ali.fasta' into alignement_ch\n    file 'GC.list' into gcfList_ch\n\n\n            \n    script:\n\n    \"\"\"\n    #Process input SSU fasta file, corrected unix fasta file\n    fasta2ali.pl SSU.fasta\n    ali2fasta.pl SSU.ali\n\n    #Shorten sequence to first blank\n    inst-abbr-ids.pl SSU.fasta --id-regex=:DEF\n    sed -i -e 's/|//g' SSU-abbr.fasta\n\n    #Process refgroup 16s sequences -- to replace in companion --\n    #ensure that rejected sequence in scafos are not present in reference 16s file\n    cat Refall_16s-nodupe.fna Outall_16s-nodupe.fna > all_16s-nodupe.fasta\n    $companion all_16s-nodupe.fasta --mode=ConstrainTreeRaxml\n    \n    #combine reference ans SSU, fasta files\n    cat all_16s-nodupe-list.fasta SSU-abbr.fasta > SSU-combined.fasta\n\n    #align comibined file, use BMGE\n    #mafft --adjustdirection --anysymbol --auto --reorder  SSU-combined.fasta > SSU-combined-ali.fasta\n    muscle3.8.31_i86linux64 -in SSU-combined.fasta -out SSU-combined-ali.fasta\n    fasta2ali.pl SSU-combined-ali.fasta\n    sed -i -e 's/ //g' SSU-combined-ali.ali\n    ali2phylip.pl SSU-combined-ali.ali --bmge-mask=medium --max=0.6 --ali\n    ali2phylip.pl SSU-combined-ali-a2p.ali --p80\n    ali2fasta.pl SSU-combined-ali-a2p.ali\n    raxmlHPC-PTHREADS-AVX -T $cpu -r reference.tre -s SSU-combined-ali-a2p.p80 \\\n    -n SSU-combined-ali-a2p-RAXML-GTRGAMMA-100xRAPIDBP -m GTRGAMMA -N 100 -f a -x 1975021703574 -p 197502170357 \n\n    #Delete long branch\n    cp RAxML_bipartitions.SSU-combined-ali-a2p-RAXML-GTRGAMMA-100xRAPIDBP raxml.tre\n    run_treeshrink.py -t raxml.tre\n    grep \">\" Outall_16s-nodupe.fna | cut -f2 -d'>' >  Out-GCA.list\n    cp raxml_treeshrink/output_summary.txt .\n    $companion output_summary.txt --mode=shrink --shrinkvalue=$shrink\n    cp RAxML_bipartitions.SSU-combined-ali-a2p-RAXML-GTRGAMMA-100xRAPIDBP Constained-tree.tre\n    prune-tree.pl --negate-list Constained-tree.idl \n\n    #format RAxlm output mapping idm file\n    #refgroup part\n    fetch-tax.pl GC.list --taxdir=$taxdir --item-type=taxid\n    cut -f1 GC.tax > f1.tax\n    cut -f2 GC.tax > f2.tax\n    paste f2.tax f1.tax > part1.idm\n    #SSU User file part\n    grep \">\" SSU.fasta | cut -f2 -d \">\" | cut -f1 -d\" \" > ssu.f1\n    grep \">\" SSU.fasta | cut -f2 -d \">\"  > ssu.f2\n    paste ssu.f2 ssu.f1 > part2.idm\n    #combined\n    cat part1.idm part2.idm > SSU.idm\n    cp SSU.idm RAXML.idm\n    mv Constained-tree.tre RAXML.tre\n    format-tree.pl RAXML.tre --map-ids --figtree\n    format-tree.pl RAXML.tre --map-ids\n    mv RAXML.nex Constained-tree.nex\n    mv RAXML.tre Constained-tree.tre\n    \"\"\"\n}",
        "nb_lignes_process": 82,
        "string_script": "    \"\"\"\n    #Process input SSU fasta file, corrected unix fasta file\n    fasta2ali.pl SSU.fasta\n    ali2fasta.pl SSU.ali\n\n    #Shorten sequence to first blank\n    inst-abbr-ids.pl SSU.fasta --id-regex=:DEF\n    sed -i -e 's/|//g' SSU-abbr.fasta\n\n    #Process refgroup 16s sequences -- to replace in companion --\n    #ensure that rejected sequence in scafos are not present in reference 16s file\n    cat Refall_16s-nodupe.fna Outall_16s-nodupe.fna > all_16s-nodupe.fasta\n    $companion all_16s-nodupe.fasta --mode=ConstrainTreeRaxml\n    \n    #combine reference ans SSU, fasta files\n    cat all_16s-nodupe-list.fasta SSU-abbr.fasta > SSU-combined.fasta\n\n    #align comibined file, use BMGE\n    #mafft --adjustdirection --anysymbol --auto --reorder  SSU-combined.fasta > SSU-combined-ali.fasta\n    muscle3.8.31_i86linux64 -in SSU-combined.fasta -out SSU-combined-ali.fasta\n    fasta2ali.pl SSU-combined-ali.fasta\n    sed -i -e 's/ //g' SSU-combined-ali.ali\n    ali2phylip.pl SSU-combined-ali.ali --bmge-mask=medium --max=0.6 --ali\n    ali2phylip.pl SSU-combined-ali-a2p.ali --p80\n    ali2fasta.pl SSU-combined-ali-a2p.ali\n    raxmlHPC-PTHREADS-AVX -T $cpu -r reference.tre -s SSU-combined-ali-a2p.p80 \\\n    -n SSU-combined-ali-a2p-RAXML-GTRGAMMA-100xRAPIDBP -m GTRGAMMA -N 100 -f a -x 1975021703574 -p 197502170357 \n\n    #Delete long branch\n    cp RAxML_bipartitions.SSU-combined-ali-a2p-RAXML-GTRGAMMA-100xRAPIDBP raxml.tre\n    run_treeshrink.py -t raxml.tre\n    grep \">\" Outall_16s-nodupe.fna | cut -f2 -d'>' >  Out-GCA.list\n    cp raxml_treeshrink/output_summary.txt .\n    $companion output_summary.txt --mode=shrink --shrinkvalue=$shrink\n    cp RAxML_bipartitions.SSU-combined-ali-a2p-RAXML-GTRGAMMA-100xRAPIDBP Constained-tree.tre\n    prune-tree.pl --negate-list Constained-tree.idl \n\n    #format RAxlm output mapping idm file\n    #refgroup part\n    fetch-tax.pl GC.list --taxdir=$taxdir --item-type=taxid\n    cut -f1 GC.tax > f1.tax\n    cut -f2 GC.tax > f2.tax\n    paste f2.tax f1.tax > part1.idm\n    #SSU User file part\n    grep \">\" SSU.fasta | cut -f2 -d \">\" | cut -f1 -d\" \" > ssu.f1\n    grep \">\" SSU.fasta | cut -f2 -d \">\"  > ssu.f2\n    paste ssu.f2 ssu.f1 > part2.idm\n    #combined\n    cat part1.idm part2.idm > SSU.idm\n    cp SSU.idm RAXML.idm\n    mv Constained-tree.tre RAXML.tre\n    format-tree.pl RAXML.tre --map-ids --figtree\n    format-tree.pl RAXML.tre --map-ids\n    mv RAXML.nex Constained-tree.nex\n    mv RAXML.tre Constained-tree.tre\n    \"\"\"",
        "nb_lignes_script": 55,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "referenceTree_ch",
            "refRnammer_ch",
            "outRnammer_ch",
            "ssuDereplicated_ch",
            "referenceTreeList_ch",
            "taxdir_ch2",
            "params",
            "params",
            "params"
        ],
        "nb_inputs": 9,
        "outputs": [
            "constTreeNexus_ch",
            "constTreeTre_ch",
            "alignementBmge_ch",
            "alignement_ch",
            "gcfList_ch"
        ],
        "nb_outputs": 5,
        "name_workflow": "Lcornet__ORPER",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "PublicationResults": {
        "name_process": "PublicationResults",
        "string_process": "\nprocess PublicationResults {\n\t              \n    publishDir \"$params.outdir\", mode: 'copy', overwrite: false\n\n\t              \n    input:\n    file 'Constained-tree.nex' from constTreeNexus_ch\n    file 'Constained-tree.tre' from constTreeTre_ch\n    file 'SSU-combined-ali-a2p.fasta' from alignementBmge_ch\n    file 'SSU-combined-ali.fasta' from alignement_ch\n    file 'GC.list' from gcfList_ch\n\n    output:\n    file 'Constained-tree.nex' into outConstTreeNexus_ch\n    file 'Constained-tree.tre' into outConstTreeTre_ch\n    file 'SSU-combined-ali-a2p.fasta' into outAlignementBmge_ch\n    file 'SSU-combined-ali.fasta' into outAlignement_ch\n    file 'GC.list' into outGcfList_ch\n\n            \n    script:\n\n    \"\"\"\n    cp Constained-tree.tre Constained-tree-FINAL.tre\n    cp Constained-tree.nex Constained-tree-FINAL.nex\n    cp SSU-combined-ali-a2p.fasta SSU-combined-ali-a2p-FINAL.fasta\n    cp SSU-combined-ali.fasta SSU-combined-ali-FINAL.fasta\n    cp GC.list GC-FINAL.list\n    echo \"ORPER analyses completed\" > log\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    cp Constained-tree.tre Constained-tree-FINAL.tre\n    cp Constained-tree.nex Constained-tree-FINAL.nex\n    cp SSU-combined-ali-a2p.fasta SSU-combined-ali-a2p-FINAL.fasta\n    cp SSU-combined-ali.fasta SSU-combined-ali-FINAL.fasta\n    cp GC.list GC-FINAL.list\n    echo \"ORPER analyses completed\" > log\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "GLOGS"
        ],
        "tools_url": [
            "https://bio.tools/glogs"
        ],
        "tools_dico": [
            {
                "name": "GLOGS",
                "uri": "https://bio.tools/glogs",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A method for using covariates to improve power in GWAS with related individuals",
                "homepage": "http://www.bioinformatics.org/~stanhope/GLOGS/"
            }
        ],
        "inputs": [
            "constTreeNexus_ch",
            "constTreeTre_ch",
            "alignementBmge_ch",
            "alignement_ch",
            "gcfList_ch"
        ],
        "nb_inputs": 5,
        "outputs": [
            "outConstTreeNexus_ch",
            "outConstTreeTre_ch",
            "outAlignementBmge_ch",
            "outAlignement_ch",
            "outGcfList_ch"
        ],
        "nb_outputs": 5,
        "name_workflow": "Lcornet__ORPER",
        "directive": [
            "publishDir \"$params.outdir\", mode: 'copy', overwrite: false"
        ],
        "when": "",
        "stub": ""
    }
}