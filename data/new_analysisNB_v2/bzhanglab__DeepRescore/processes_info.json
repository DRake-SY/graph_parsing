{
    "calc_basic_features_mq": {
        "name_process": "calc_basic_features_mq",
        "string_process": " process calc_basic_features_mq {\n\n        tag \"$sample\"\n\n        publishDir \"$output_path\", mode: \"copy\", overwrite: true\n\n        input:\n        file result_file\n\n        output:\n        file(\"features.txt\") into all_features_ch1\n        file(\"features.txt\") into all_features_ch2\n        file(\"features.txt\") into all_features_ch3\n        file(\"features.txt\") into all_features_ch4\n\n        script:\n\n        \"\"\"\n        java -Xmx${memory}g -jar ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar \\\n            -r $result_file \\\n            -rt $result_type \\\n            -s \"${result_file}/generatesMGF/\" \\\n            -st 1 \\\n            -i * \\\n            -k s \\\n            -o ./ \\\n            -a 0.05 \\\n            -c 0 \\\n            -decoy \"XXX_\" \\\n            -ft pdf \\\n            --features\n        \"\"\"\n    }",
        "nb_lignes_process": 31,
        "string_script": "        \"\"\"\n        java -Xmx${memory}g -jar ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar \\\n            -r $result_file \\\n            -rt $result_type \\\n            -s \"${result_file}/generatesMGF/\" \\\n            -st 1 \\\n            -i * \\\n            -k s \\\n            -o ./ \\\n            -a 0.05 \\\n            -c 0 \\\n            -decoy \"XXX_\" \\\n            -ft pdf \\\n            --features\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "result_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "all_features_ch1",
            "all_features_ch2",
            "all_features_ch3",
            "all_features_ch4"
        ],
        "nb_outputs": 4,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "publishDir \"$output_path\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "xml2mzid": {
        "name_process": "xml2mzid",
        "string_process": " process xml2mzid{\n\n            tag \"${sample}\"\n\n            container \"bzhanglab/neoflow:1.0\"\n\n            input:\n            file result_file\n\n            output:\n            file(\"${res_file}\") into mzid_file\n    \n\n            script:\n            res_file = \"${sample}.mzid\"\n            \"\"\"\n            #!/bin/sh\n            ## convert xml to mzid\n            java -Xmx${memory}g -jar /opt/mzidlib-1.7/mzidlib-1.7.jar Tandem2mzid \\\n                ${result_file} \\\n                ${res_file} \\\n                -outputFragmentation false \\\n                -decoyRegex ${decoy_prefix} \\\n                -databaseFileFormatID MS:1001348 \\\n                -massSpecFileFormatID MS:1001062 \\\n                -idsStartAtZero false \\\n                -compress false \\\n                -proteinCodeRegex \"\\\\S+\"\n            \"\"\"\n        }",
        "nb_lignes_process": 28,
        "string_script": "            res_file = \"${sample}.mzid\"\n            \"\"\"\n            #!/bin/sh\n            ## convert xml to mzid\n            java -Xmx${memory}g -jar /opt/mzidlib-1.7/mzidlib-1.7.jar Tandem2mzid \\\n                ${result_file} \\\n                ${res_file} \\\n                -outputFragmentation false \\\n                -decoyRegex ${decoy_prefix} \\\n                -databaseFileFormatID MS:1001348 \\\n                -massSpecFileFormatID MS:1001062 \\\n                -idsStartAtZero false \\\n                -compress false \\\n                -proteinCodeRegex \"\\\\S+\"\n            \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "RASH"
        ],
        "tools_url": [
            "https://bio.tools/RASH"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            }
        ],
        "inputs": [
            "result_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mzid_file"
        ],
        "nb_outputs": 1,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"${sample}\"",
            "container \"bzhanglab/neoflow:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "calc_basic_features_xt": {
        "name_process": "calc_basic_features_xt",
        "string_process": " process calc_basic_features_xt {\n\n            tag \"$sample\"\n\n            publishDir \"$output_path\", mode: \"copy\", overwrite: true\n\n            input:\n            file mzid_file\n            file spectrum_file\n\n            output:\n            file(\"features.txt\") into all_features_ch1\n            file(\"features.txt\") into all_features_ch2\n            file(\"features.txt\") into all_features_ch3\n            file(\"features.txt\") into all_features_ch4\n\n            script:\n\n            \"\"\"\n            java -Xmx${memory}g -jar ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar \\\n                -r $mzid_file \\\n                -rt $result_type \\\n                -s $spectrum_file \\\n                -st 1 \\\n                -i * \\\n                -k s \\\n                -o ./ \\\n                -a 0.05 \\\n                -c 0 \\\n                -decoy ${decoy_prefix} \\\n                -ft pdf \\\n                --features\n            \"\"\"\n        }",
        "nb_lignes_process": 32,
        "string_script": "            \"\"\"\n            java -Xmx${memory}g -jar ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar \\\n                -r $mzid_file \\\n                -rt $result_type \\\n                -s $spectrum_file \\\n                -st 1 \\\n                -i * \\\n                -k s \\\n                -o ./ \\\n                -a 0.05 \\\n                -c 0 \\\n                -decoy ${decoy_prefix} \\\n                -ft pdf \\\n                --features\n            \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mzid_file",
            "spectrum_file"
        ],
        "nb_inputs": 2,
        "outputs": [
            "all_features_ch1",
            "all_features_ch2",
            "all_features_ch3",
            "all_features_ch4"
        ],
        "nb_outputs": 4,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "publishDir \"$output_path\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "calc_basic_features": {
        "name_process": "calc_basic_features",
        "string_process": " process calc_basic_features {\n\n            tag \"$sample\"\n\n            publishDir \"$output_path\", mode: \"copy\", overwrite: true\n\n            input:\n            file result_file\n            file spectrum_file\n\n            output:\n            file(\"features.txt\") into all_features_ch1\n            file(\"features.txt\") into all_features_ch2\n            file(\"features.txt\") into all_features_ch3\n            file(\"features.txt\") into all_features_ch4\n\n            script:\n\n            \"\"\"\n            java -Xmx${memory}g -jar ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar \\\n                -r $result_file \\\n                -rt $result_type \\\n                -s $spectrum_file \\\n                -st 1 \\\n                -i * \\\n                -k s \\\n                -o ./ \\\n                -a 0.05 \\\n                -c 0 \\\n                -decoy ${decoy_prefix} \\\n                -ft pdf \\\n                --features\n            \"\"\"\n        }",
        "nb_lignes_process": 32,
        "string_script": "            \"\"\"\n            java -Xmx${memory}g -jar ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar \\\n                -r $result_file \\\n                -rt $result_type \\\n                -s $spectrum_file \\\n                -st 1 \\\n                -i * \\\n                -k s \\\n                -o ./ \\\n                -a 0.05 \\\n                -c 0 \\\n                -decoy ${decoy_prefix} \\\n                -ft pdf \\\n                --features\n            \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "result_file",
            "spectrum_file"
        ],
        "nb_inputs": 2,
        "outputs": [
            "all_features_ch1",
            "all_features_ch2",
            "all_features_ch3",
            "all_features_ch4"
        ],
        "nb_outputs": 4,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "publishDir \"$output_path\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "pga_fdr_control": {
        "name_process": "pga_fdr_control",
        "string_process": "\nprocess pga_fdr_control {\n\n    tag \"$sample\"\n\n    container \"proteomics/pga:latest\"\n\n    publishDir \"$output_path\", mode: \"copy\", overwrite: true\n\n    input:\n    file feature_file from all_features_ch1\n\n    output:\n    set file(\"${sample}-rawPSMs.txt\"), file(\"./peptide_level/\"), file(\"./psm_level/\") into pga_results_ch\n    file(\"${sample}-rawPSMs.txt\") into pga_results_ch2\n    file(\"${sample}-rawPSMs.txt\") into pga_results_ch3\n\n    script:\n    \"\"\"\n    mkdir peptide_level psm_level\n    Rscript ${baseDir}/bin/got_pga_input.R $feature_file $software ./${sample}-rawPSMs.txt\n    Rscript ${baseDir}/bin/calculate_fdr.R ./ $sample ${baseDir}/bin/protein.pro-ref.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    mkdir peptide_level psm_level\n    Rscript ${baseDir}/bin/got_pga_input.R $feature_file $software ./${sample}-rawPSMs.txt\n    Rscript ${baseDir}/bin/calculate_fdr.R ./ $sample ${baseDir}/bin/protein.pro-ref.fasta\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_features_ch1"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pga_results_ch",
            "pga_results_ch2",
            "pga_results_ch3"
        ],
        "nb_outputs": 3,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "container \"proteomics/pga:latest\"",
            "publishDir \"$output_path\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "generate_train_prediction_data": {
        "name_process": "generate_train_prediction_data",
        "string_process": "\nprocess generate_train_prediction_data {\n\n    tag \"$sample\"\n\n    container \"proteomics/pga:latest\"\n\n    publishDir \"$output_path\", mode: \"copy\", overwrite: true\n\n    input:\n    file feature_file from all_features_ch2\n    set file(rawPSMs_file), file(peptide_pga_results_file), file(psm_pga_results_file) from pga_results_ch\n\n    output:\n    file(\"./pDeep2_prediction/\") into pDeep2_prediction_ch\n    file(\"./autoRT_train/\") into autoRT_train_ch\n    file(\"./autoRT_prediction/\") into autoRT_prediction_ch\n\n    script:\n    \"\"\"\n    mkdir autoRT_train autoRT_prediction pDeep2_prediction\n    Rscript ${baseDir}/bin/got_train_prediction.R ${peptide_pga_results_file}/pga-peptideSummary.txt \\\n        ${psm_pga_results_file}/pga-peptideSummary.txt $feature_file ./autoRT_train/ ./autoRT_prediction/ \\\n        ./pDeep2_prediction/${sample}_pdeep2_prediction $rawPSMs_file\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    mkdir autoRT_train autoRT_prediction pDeep2_prediction\n    Rscript ${baseDir}/bin/got_train_prediction.R ${peptide_pga_results_file}/pga-peptideSummary.txt \\\n        ${psm_pga_results_file}/pga-peptideSummary.txt $feature_file ./autoRT_train/ ./autoRT_prediction/ \\\n        ./pDeep2_prediction/${sample}_pdeep2_prediction $rawPSMs_file\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_features_ch2",
            "pga_results_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "pDeep2_prediction_ch",
            "autoRT_train_ch",
            "autoRT_prediction_ch"
        ],
        "nb_outputs": 3,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "container \"proteomics/pga:latest\"",
            "publishDir \"$output_path\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "run_pdeep2": {
        "name_process": "run_pdeep2",
        "string_process": "\nprocess run_pdeep2 {\n\n    tag \"$sample\"\n    \n    cpus \"$params.cpu\"\n\n    container \"proteomics/pdeep2:latest\"\n\n    publishDir \"${output_path}/pDeep2_prediction/\", mode: \"copy\", overwrite: true\n\n    input:\n                        \n    \n    file(pdeep2_folder) from pDeep2_prediction_ch\n\n    output:\n    set file(\"${sample}_pdeep2_prediction_results.txt\"), file{\"${pdeep2_folder}/${sample}_pdeep2_prediction.txt\"} into pDeep2_results_ch\n\n    script:\n    \"\"\"\n    #export CUDA_VISIBLE_DEVICES=0\n    python /opt/pDeep2/predict.py -e $energy -i $instrument -in ${pdeep2_folder}/${sample}_pdeep2_prediction_unique.txt -out ./${sample}_pdeep2_prediction_results.txt\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    #export CUDA_VISIBLE_DEVICES=0\n    python /opt/pDeep2/predict.py -e $energy -i $instrument -in ${pdeep2_folder}/${sample}_pdeep2_prediction_unique.txt -out ./${sample}_pdeep2_prediction_results.txt\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pDeep2_prediction_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pDeep2_results_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "cpus \"$params.cpu\"",
            "container \"proteomics/pdeep2:latest\"",
            "publishDir \"${output_path}/pDeep2_prediction/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "process_pDeep2_results": {
        "name_process": "process_pDeep2_results",
        "string_process": "\nprocess process_pDeep2_results {\n\n    tag \"$sample\"\n    \n    cpus \"$params.cpu\"\n\n    container \"proteomics/pga:latest\"\n\n    publishDir \"${output_path}/pDeep2_prediction/\", mode: \"copy\", overwrite: true\n\n    input:\n    file (rawPSMs_file) from pga_results_ch2\n    file (spectrum_file)\n    set file(pDeep2_results), file(pDeep2_prediction) from pDeep2_results_ch\n\n    output:\n    set file(\"./${sample}_format_titles.txt\"), file(\"./${sample}_spectrum_pairs.txt\"), file(\"./${sample}_similarity_SA.txt\") into similarity_ch\n    file (\"./${sample}_similarity_SA.txt\") into pDee2_next_ch\n\n    script:\n    \"\"\"\n    #!/bin/sh\n    mv $pDeep2_results ${pDeep2_results}.mgf\n    Rscript ${baseDir}/bin/format_pDeep2_titile.R $pDeep2_prediction $rawPSMs_file ./${sample}_format_titles.txt\n    \n    java -Xmx${memory}g -cp ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar PDVGUI.GenerateSpectrumTable \\\n        ./${sample}_format_titles.txt $spectrum_file ${pDeep2_results}.mgf ./${sample}_spectrum_pairs.txt $software\n    mkdir sections sections_results\n    Rscript ${baseDir}/bin/similarity/devide_file.R ./${sample}_spectrum_pairs.txt $threads ./sections/\n    for file in ./sections/*\n    do\n        name=`basename \\$file`\n        Rscript ${baseDir}/bin/similarity/calculate_similarity_SA.R \\$file ./sections_results/\\${name}_results.txt &\n    done\n    wait\n    awk 'NR==1 {header=\\$_} FNR==1 && NR!=1 { \\$_ ~ \\$header getline; } {print}' ./sections_results/*_results.txt > ./${sample}_similarity_SA.txt\n    \n    \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "    \"\"\"\n    #!/bin/sh\n    mv $pDeep2_results ${pDeep2_results}.mgf\n    Rscript ${baseDir}/bin/format_pDeep2_titile.R $pDeep2_prediction $rawPSMs_file ./${sample}_format_titles.txt\n    \n    java -Xmx${memory}g -cp ${baseDir}/bin/PDV-1.6.1.beta.features/PDV-1.6.1.beta.features-jar-with-dependencies.jar PDVGUI.GenerateSpectrumTable \\\n        ./${sample}_format_titles.txt $spectrum_file ${pDeep2_results}.mgf ./${sample}_spectrum_pairs.txt $software\n    mkdir sections sections_results\n    Rscript ${baseDir}/bin/similarity/devide_file.R ./${sample}_spectrum_pairs.txt $threads ./sections/\n    for file in ./sections/*\n    do\n        name=`basename \\$file`\n        Rscript ${baseDir}/bin/similarity/calculate_similarity_SA.R \\$file ./sections_results/\\${name}_results.txt &\n    done\n    wait\n    awk 'NR==1 {header=\\$_} FNR==1 && NR!=1 { \\$_ ~ \\$header getline; } {print}' ./sections_results/*_results.txt > ./${sample}_similarity_SA.txt\n    \n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "RASH"
        ],
        "tools_url": [
            "https://bio.tools/RASH"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            }
        ],
        "inputs": [
            "pga_results_ch2",
            "spectrum_file",
            "pDeep2_results_ch"
        ],
        "nb_inputs": 3,
        "outputs": [
            "similarity_ch",
            "pDee2_next_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "cpus \"$params.cpu\"",
            "container \"proteomics/pga:latest\"",
            "publishDir \"${output_path}/pDeep2_prediction/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "train_autoRT": {
        "name_process": "train_autoRT",
        "string_process": "\nprocess train_autoRT {\n\n    tag \"$sample\"\n    \n    cpus \"$params.cpu\"\n\n    container \"proteomics/autort:latest\"\n\n    publishDir \"${output_path}/autoRT_train/\", mode: \"copy\", overwrite: true\n\n    input:\n                              \n                                   \n    file(sa_file) from pDee2_next_ch\n    file(autoRT_train_folder) from autoRT_train_ch\n\n    output:\n    file (\"./autoRT_models/\") into model_prediction_ch\n\n    script:\n    \"\"\"\n    #!/bin/sh\n    set -e\n    mkdir -p ./autoRT_models\n    for file in ${autoRT_train_folder}/*.txt\n    do\n        fraction=`basename \\${file} .txt`\n        mkdir -p ./autoRT_models/\\${fraction}\n        python /opt/AutoRT/autort.py train \\\n        -i \\$file \\\n        -o ./autoRT_models/\\${fraction} \\\n        -e 40 \\\n        -b 64 \\\n        -u m \\\n        -m /opt/AutoRT/models/base_models_PXD006109/model.json \\\n        -rlr \\\n        -n 10 \n    done\n    wait\n    \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "    \"\"\"\n    #!/bin/sh\n    set -e\n    mkdir -p ./autoRT_models\n    for file in ${autoRT_train_folder}/*.txt\n    do\n        fraction=`basename \\${file} .txt`\n        mkdir -p ./autoRT_models/\\${fraction}\n        python /opt/AutoRT/autort.py train \\\n        -i \\$file \\\n        -o ./autoRT_models/\\${fraction} \\\n        -e 40 \\\n        -b 64 \\\n        -u m \\\n        -m /opt/AutoRT/models/base_models_PXD006109/model.json \\\n        -rlr \\\n        -n 10 \n    done\n    wait\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "RASH"
        ],
        "tools_url": [
            "https://bio.tools/RASH"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            }
        ],
        "inputs": [
            "pDee2_next_ch",
            "autoRT_train_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "model_prediction_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "cpus \"$params.cpu\"",
            "container \"proteomics/autort:latest\"",
            "publishDir \"${output_path}/autoRT_train/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "predicte_autoRT": {
        "name_process": "predicte_autoRT",
        "string_process": "\nprocess predicte_autoRT {\n\n    tag \"$sample\"\n    \n    cpus \"$params.cpu\"\n\n    container \"proteomics/autort:latest\"\n\n    publishDir \"${output_path}/\", mode: \"copy\", overwrite: true\n\n    input:\n    file autoRT_prediction_folder from autoRT_prediction_ch\n    file (autoRT_models_folder)from model_prediction_ch\n\n    output:\n\n    file(\"./autoRT_prediction/\") into autoRT_results_ch\n\n    script:\n    \"\"\"\n    #!/bin/sh\n    set -e\n    mkdir -p ./autoRT_prediction\n    mkdir -p ./autoRT_prediction/results\n    for file in ${autoRT_prediction_folder}/*.txt\n    do\n        fraction=`basename \\${file} .txt`\n        mkdir -p ./autoRT_prediction/\\${fraction}\n        python /opt/AutoRT/autort.py predict \\\n        -t \\$file \\\n        -s ${autoRT_models_folder}/\\${fraction}/model.json \\\n        -o ./autoRT_prediction/\\${fraction} \\\n        -p \\${fraction}\n    done\n    wait\n    for file in ${autoRT_prediction_folder}/*.txt\n    do\n        fraction=`basename \\${file} .txt`\n        cp ./autoRT_prediction/\\${fraction}/\\${fraction}.tsv ./autoRT_prediction/results/\n    done\n    awk 'NR==1 {header=\\$_} FNR==1 && NR!=1 { \\$_ ~ \\$header getline; } {print}' ./autoRT_prediction/results/*.tsv \\\n    > ./autoRT_prediction/results/${sample}_results.txt\n    \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "    \"\"\"\n    #!/bin/sh\n    set -e\n    mkdir -p ./autoRT_prediction\n    mkdir -p ./autoRT_prediction/results\n    for file in ${autoRT_prediction_folder}/*.txt\n    do\n        fraction=`basename \\${file} .txt`\n        mkdir -p ./autoRT_prediction/\\${fraction}\n        python /opt/AutoRT/autort.py predict \\\n        -t \\$file \\\n        -s ${autoRT_models_folder}/\\${fraction}/model.json \\\n        -o ./autoRT_prediction/\\${fraction} \\\n        -p \\${fraction}\n    done\n    wait\n    for file in ${autoRT_prediction_folder}/*.txt\n    do\n        fraction=`basename \\${file} .txt`\n        cp ./autoRT_prediction/\\${fraction}/\\${fraction}.tsv ./autoRT_prediction/results/\n    done\n    awk 'NR==1 {header=\\$_} FNR==1 && NR!=1 { \\$_ ~ \\$header getline; } {print}' ./autoRT_prediction/results/*.tsv \\\n    > ./autoRT_prediction/results/${sample}_results.txt\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "RASH"
        ],
        "tools_url": [
            "https://bio.tools/RASH"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            }
        ],
        "inputs": [
            "autoRT_prediction_ch",
            "autoRT_models_folder"
        ],
        "nb_inputs": 2,
        "outputs": [
            "autoRT_results_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "cpus \"$params.cpu\"",
            "container \"proteomics/autort:latest\"",
            "publishDir \"${output_path}/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "generate_percolator_input": {
        "name_process": "generate_percolator_input",
        "string_process": "\nprocess generate_percolator_input {\n\n    tag \"$sample\"\n\n    container \"proteomics/pga:latest\"\n\n    publishDir \"${output_path}/percolator_input/\", mode: \"copy\", overwrite: true\n\n    input:\n    file (feature_file) from all_features_ch3\n    file (rawPSMs_file) from pga_results_ch3\n    file (autoRT_results_folder) from autoRT_results_ch\n    set file(similarity_title_file), file(similarity_pair_file), file(similarity_SA_file) from similarity_ch\n\n    output:\n    file (\"./format.pin\") into percolator_input_ch\n    file (\"./format.pin\") into percolator_input_ch2\n\n    script:\n    \"\"\"\n    Rscript ${baseDir}/bin/percolator/format_percolator_input.R $feature_file $rawPSMs_file \\\n        ${autoRT_results_folder}/results/${sample}_results.txt $similarity_SA_file ./format.pin $software\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    Rscript ${baseDir}/bin/percolator/format_percolator_input.R $feature_file $rawPSMs_file \\\n        ${autoRT_results_folder}/results/${sample}_results.txt $similarity_SA_file ./format.pin $software\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_features_ch3",
            "pga_results_ch3",
            "autoRT_results_ch",
            "similarity_ch"
        ],
        "nb_inputs": 4,
        "outputs": [
            "percolator_input_ch",
            "percolator_input_ch2"
        ],
        "nb_outputs": 2,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "container \"proteomics/pga:latest\"",
            "publishDir \"${output_path}/percolator_input/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "run_percolator": {
        "name_process": "run_percolator",
        "string_process": "\nprocess run_percolator {\n    tag \"$sample\"\n    \n    cpus \"$params.cpu\"\n\n    container \"bzhanglab/percolator:3.4\"\n\n    publishDir \"${output_path}/percolator_results/\", mode: \"copy\", overwrite: true\n\n    input:\n    file (percolator_input_file) from percolator_input_ch\n\n    output:\n    set file(\"${sample}_pep.txt\"), file(\"${sample}_psms.txt\") into percolator_output_ch\n\n    script:\n    \"\"\"\n    percolator -r ${sample}_pep.txt -m ${sample}_psms.txt format.pin\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    percolator -r ${sample}_pep.txt -m ${sample}_psms.txt format.pin\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Percolator"
        ],
        "tools_url": [
            "https://bio.tools/percolator"
        ],
        "tools_dico": [
            {
                "name": "Percolator",
                "uri": "https://bio.tools/percolator",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3631",
                                    "term": "Peptide identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3648",
                                    "term": "Validation of peptide-spectrum matches"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3767",
                                    "term": "Protein identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fragment weight comparison"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Blind peptide database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3649",
                                    "term": "Target-Decoy"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3631",
                                    "term": "Peptide-spectrum-matching"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3767",
                                    "term": "Protein inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "PMF"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Peptide mass fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Modification-tolerant peptide database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Unrestricted peptide database search"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0945",
                                "term": "Peptide identification"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0945",
                                "term": "Peptide identification"
                            }
                        ]
                    }
                ],
                "description": "Semi-supervised learning for peptide identification from MS/MS data.",
                "homepage": "http://noble.gs.washington.edu/proj/percolator/"
            }
        ],
        "inputs": [
            "percolator_input_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "percolator_output_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "cpus \"$params.cpu\"",
            "container \"bzhanglab/percolator:3.4\"",
            "publishDir \"${output_path}/percolator_results/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "generate_pdv_input": {
        "name_process": "generate_pdv_input",
        "string_process": "\nprocess generate_pdv_input {\n    tag \"$sample\"\n\n    container \"proteomics/pga:latest\"   \n\t\n    publishDir \"${output_path}/DeepRescore_results/\", mode: \"copy\", overwrite: true\n\n    input:\n    set file(pep_level_result), file(psm_level_result) from percolator_output_ch\n    file (features_file) from all_features_ch4\n    file (percolator_input_file) from percolator_input_ch2\n\n    output:\n    set file(\"${sample}_pep_final*.tsv\"), file(\"${sample}_psm_final*.tsv\") into pdv_input_ch\n\n    script:\n    \"\"\"\n    Rscript ${baseDir}/bin/PDV/generate_pdv_input.R ./ $sample $features_file $percolator_input_file\n    \"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    Rscript ${baseDir}/bin/PDV/generate_pdv_input.R ./ $sample $features_file $percolator_input_file\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "percolator_output_ch",
            "all_features_ch4",
            "percolator_input_ch2"
        ],
        "nb_inputs": 3,
        "outputs": [
            "pdv_input_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "bzhanglab__DeepRescore",
        "directive": [
            "tag \"$sample\"",
            "container \"proteomics/pga:latest\"",
            "publishDir \"${output_path}/DeepRescore_results/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    }
}