{
    "gunzipFasta": {
        "name_process": "gunzipFasta",
        "string_process": " process gunzipFasta {\n            tag \"$fasta\"\n\n            input:\n            file fasta from fastaGunzipChannel\n\n            output:\n            file \"ref.fa\" into fastaMapChannel,\n                               fastaSnpChannel,\n                               fastaCountChannel,\n                               fastaRatesChannel,\n                               fastaUtrRatesChannel,\n                               fastaReadPosChannel,\n                               fastaUtrPosChannel\n\n            script:\n            \"\"\"\n            gunzip -c $fasta > ref.fa\n            \"\"\"\n        }",
        "nb_lignes_process": 18,
        "string_script": "            \"\"\"\n            gunzip -c $fasta > ref.fa\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastaGunzipChannel"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastaMapChannel",
            "fastaSnpChannel",
            "fastaCountChannel",
            "fastaRatesChannel",
            "fastaUtrRatesChannel",
            "fastaReadPosChannel",
            "fastaUtrPosChannel"
        ],
        "nb_outputs": 7,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$fasta\""
        ],
        "when": "",
        "stub": ""
    },
    "gtf2bed": {
        "name_process": "gtf2bed",
        "string_process": " process gtf2bed {\n        tag \"$gtf\"\n\n        input:\n        file gtf from gtfChannel\n\n        output:\n        file \"*.bed\" into utrFilterChannel,\n                          utrCountChannel,\n                          utrratesChannel,\n                          utrposChannel\n\n        script:\n        \"\"\"\n        gtf2bed.py $gtf | sort -k1,1 -k2,2n > ${gtf.baseName}.3utr.bed\n        \"\"\"\n    }",
        "nb_lignes_process": 15,
        "string_script": "        \"\"\"\n        gtf2bed.py $gtf | sort -k1,1 -k2,2n > ${gtf.baseName}.3utr.bed\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gtfChannel"
        ],
        "nb_inputs": 1,
        "outputs": [
            "utrFilterChannel",
            "utrCountChannel",
            "utrratesChannel",
            "utrposChannel"
        ],
        "nb_outputs": 4,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$gtf\""
        ],
        "when": "",
        "stub": ""
    },
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n    publishDir \"${params.outdir}/pipeline_info\", mode: 'copy',\n        saveAs: { filename ->\n                      if (filename.indexOf(\".csv\") > 0) filename\n                      else null\n                }\n\n    output:\n    file 'software_versions_mqc.yaml' into ch_software_versions_yaml\n    file \"software_versions.csv\"\n\n    script:\n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    trim_galore --version > v_trimgalore.txt\n    slamdunk --version > v_slamdunk.txt\n    echo \\$(R --version 2>&1) > v_R.txt\n    R -e 'packageVersion(\"DESeq2\")' | grep \"\\\\[1\\\\]\" > v_DESeq2.txt\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    trim_galore --version > v_trimgalore.txt\n    slamdunk --version > v_slamdunk.txt\n    echo \\$(R --version 2>&1) > v_R.txt\n    R -e 'packageVersion(\"DESeq2\")' | grep \"\\\\[1\\\\]\" > v_DESeq2.txt\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "FastQC",
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc",
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "ch_software_versions_yaml"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: 'copy' , saveAs: { filename -> if (filename.indexOf(\".csv\") > 0) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "checkDesign": {
        "name_process": "checkDesign",
        "string_process": "\nprocess checkDesign {\n    tag \"$design\"\n\n    input:\n    file design from checkChannel\n\n    output:\n    file \"*.txt\" into rawFileChannel,\n                      deseq2ConditionChannel,\n                      splitChannel,\n                      vcfSampleChannel\n\n    script:\n    \"\"\"\n    check_design.py $design nfcore_slamseq_design.txt\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    check_design.py $design nfcore_slamseq_design.txt\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "checkChannel"
        ],
        "nb_inputs": 1,
        "outputs": [
            "rawFileChannel",
            "deseq2ConditionChannel",
            "splitChannel",
            "vcfSampleChannel"
        ],
        "nb_outputs": 4,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$design\""
        ],
        "when": "",
        "stub": ""
    },
    "trim": {
        "name_process": "trim",
        "string_process": " process trim {\n        tag \"$meta.name\"\n\n        input:\n        set val(meta), file(reads) from rawFiles\n\n        output:\n        set val(meta), file(\"TrimGalore/${meta.name}_trimmed.fq.gz\") into trimmedFiles\n        file (\"TrimGalore/*.txt\") into trimgaloreQC\n        file (\"TrimGalore/*.{zip,html}\") into trimgaloreFastQC\n\n        script:\n        \"\"\"\n        mkdir -p TrimGalore\n        trim_galore \\\\\n            $reads \\\\\n            --stringency 3 \\\\\n            --fastqc \\\\\n            --cores $task.cpus \\\\\n            --output_dir TrimGalore \\\\\n            --basename ${meta.name}\n        \"\"\"\n    }",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        mkdir -p TrimGalore\n        trim_galore \\\\\n            $reads \\\\\n            --stringency 3 \\\\\n            --fastqc \\\\\n            --cores $task.cpus \\\\\n            --output_dir TrimGalore \\\\\n            --basename ${meta.name}\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "rawFiles"
        ],
        "nb_inputs": 1,
        "outputs": [
            "trimmedFiles",
            "trimgaloreQC",
            "trimgaloreFastQC"
        ],
        "nb_outputs": 3,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$meta.name\""
        ],
        "when": "",
        "stub": ""
    },
    "map": {
        "name_process": "map",
        "string_process": "\nprocess map {\n    tag \"$meta.name\"\n\n    input:\n    set val(meta), file(fastq) from trimmedFiles\n    each file(fasta) from fastaMapChannel\n\n    output:\n    set val(meta.name), file(\"map/*bam\") into slamdunkMap\n\n    script:\n    quantseq = params.quantseq ? \"-q\" : \"\"\n    endtoend = params.endtoend ? \"-e\" : \"\"\n    \"\"\"\n    slamdunk map \\\\\n        -r $fasta \\\\\n        -o map \\\\\n        -5 $params.trim5 \\\\\n        -n 100 \\\\\n        -a $params.polyA \\\\\n        -t $task.cpus \\\\\n        --sampleName ${meta.name} \\\\\n        --sampleType ${meta.type} \\\\\n        --sampleTime ${meta.time} \\\\\n        --skip-sam \\\\\n        $quantseq \\\\\n        $endtoend \\\\\n        $fastq\n    \"\"\"\n }",
        "nb_lignes_process": 29,
        "string_script": "    quantseq = params.quantseq ? \"-q\" : \"\"\n    endtoend = params.endtoend ? \"-e\" : \"\"\n    \"\"\"\n    slamdunk map \\\\\n        -r $fasta \\\\\n        -o map \\\\\n        -5 $params.trim5 \\\\\n        -n 100 \\\\\n        -a $params.polyA \\\\\n        -t $task.cpus \\\\\n        --sampleName ${meta.name} \\\\\n        --sampleType ${meta.type} \\\\\n        --sampleTime ${meta.time} \\\\\n        --skip-sam \\\\\n        $quantseq \\\\\n        $endtoend \\\\\n        $fastq\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimmedFiles",
            "fastaMapChannel"
        ],
        "nb_inputs": 2,
        "outputs": [
            "slamdunkMap"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$meta.name\""
        ],
        "when": "",
        "stub": ""
    },
    "filter": {
        "name_process": "filter",
        "string_process": "\nprocess filter {\n    tag \"$name\"\n    label 'slamdunk_process'\n\n    publishDir path: \"${params.outdir}/slamdunk/bam\", mode: 'copy',\n               overwrite: 'true', pattern: \"filter/*bam*\",\n               saveAs: { filename ->\n                             if (filename.endsWith(\".bam\")) file(filename).getName()\n                             else if (filename.endsWith(\".bai\")) file(filename).getName()\n                       }\n\n    input:\n    set val(name), file(map) from slamdunkMap\n    each file(bed) from utrFilterChannel\n\n    output:\n    set val(name), file(\"filter/*bam*\") into slamdunkFilter,\n                                             slamdunkCount,\n                                             slamdunkFilterSummary\n\n    script:\n    multimappers = params.multimappers ? \"-b ${bed}\" : \"\"\n    \"\"\"\n    slamdunk filter \\\\\n        -o filter \\\\\n        $multimappers \\\\\n       -t $task.cpus \\\\\n       $map\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    multimappers = params.multimappers ? \"-b ${bed}\" : \"\"\n    \"\"\"\n    slamdunk filter \\\\\n        -o filter \\\\\n        $multimappers \\\\\n       -t $task.cpus \\\\\n       $map\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkMap",
            "utrFilterChannel"
        ],
        "nb_inputs": 2,
        "outputs": [
            "slamdunkFilter",
            "slamdunkCount",
            "slamdunkFilterSummary"
        ],
        "nb_outputs": 3,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "label 'slamdunk_process'",
            "publishDir path: \"${params.outdir}/slamdunk/bam\", mode: 'copy' , overwrite: 'true', pattern: \"filter/*bam*\" , saveAs: { filename -> if (filename.endsWith(\".bam\")) file(filename).getName() else if (filename.endsWith(\".bai\")) file(filename).getName() }"
        ],
        "when": "",
        "stub": ""
    },
    "snp": {
        "name_process": "snp",
        "string_process": "\nprocess snp {\n    tag \"$name\"\n    publishDir path: \"${params.outdir}/slamdunk/vcf\", mode: 'copy',\n               overwrite: 'true', pattern: \"snp/*vcf\",\n               saveAs: { it.endsWith(\".vcf\") ? file(it).getName() : it }\n\n    input:\n    set val(name), file(filter) from slamdunkFilter\n    each file(fasta) from fastaSnpChannel\n\n    output:\n    set val(name), file(\"snp/*vcf\") into slamdunkSnp\n\n    when:\n    !params.vcf && !params.quantseq\n\n    script:\n    \"\"\"\n    slamdunk snp \\\\\n        -o snp \\\\\n        -r $fasta \\\\\n        -c $params.min_coverage \\\\\n        -f $params.var_fraction \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    slamdunk snp \\\\\n        -o snp \\\\\n        -r $fasta \\\\\n        -c $params.min_coverage \\\\\n        -f $params.var_fraction \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkFilter",
            "fastaSnpChannel"
        ],
        "nb_inputs": 2,
        "outputs": [
            "slamdunkSnp"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "publishDir path: \"${params.outdir}/slamdunk/vcf\", mode: 'copy' , overwrite: 'true', pattern: \"snp/*vcf\" , saveAs: { it.endsWith(\".vcf\") ? file(it).getName() : it }"
        ],
        "when": "!params.vcf && !params.quantseq",
        "stub": ""
    },
    "count": {
        "name_process": "count",
        "string_process": "\nprocess count {\n    tag \"$name\"\n    label 'slamdunk_process'\n\n    publishDir path: \"${params.outdir}/slamdunk/count/utrs\", mode: 'copy',\n               overwrite: 'true', pattern: \"count/*.tsv\",\n               saveAs: { it.endsWith(\".tsv\") ? file(it).getName() : it }\n\n    input:\n    set val(name), file(filter), file(snp) from slamdunkResultsChannel\n    each file(bed) from utrCountChannel\n    each file(fasta) from fastaCountChannel\n\n    output:\n    set val(name), file(\"count/*tsv\") into slamdunkCountOut,\n                                           slamdunkCountAlleyoop\n\n    when:\n    !params.quantseq\n\n    script:\n    snpMode = params.vcf ? \"-v $params.vcf\" : \"-s . \"\n    \"\"\"\n    slamdunk count -o count \\\\\n        -r $fasta \\\\\n        $snpMode \\\\\n        -b $bed \\\\\n        -l $params.read_length \\\\\n        -c $params.conversions \\\\\n        -q $params.base_quality \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    snpMode = params.vcf ? \"-v $params.vcf\" : \"-s . \"\n    \"\"\"\n    slamdunk count -o count \\\\\n        -r $fasta \\\\\n        $snpMode \\\\\n        -b $bed \\\\\n        -l $params.read_length \\\\\n        -c $params.conversions \\\\\n        -q $params.base_quality \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkResultsChannel",
            "utrCountChannel",
            "fastaCountChannel"
        ],
        "nb_inputs": 3,
        "outputs": [
            "slamdunkCountOut",
            "slamdunkCountAlleyoop"
        ],
        "nb_outputs": 2,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "label 'slamdunk_process'",
            "publishDir path: \"${params.outdir}/slamdunk/count/utrs\", mode: 'copy' , overwrite: 'true', pattern: \"count/*.tsv\" , saveAs: { it.endsWith(\".tsv\") ? file(it).getName() : it }"
        ],
        "when": "!params.quantseq",
        "stub": ""
    },
    "collapse": {
        "name_process": "collapse",
        "string_process": "\nprocess collapse {\n    tag \"$name\"\n    label 'slamdunk_process'\n\n    publishDir path: \"${params.outdir}/slamdunk/count/genes\", mode: 'copy',\n               overwrite: 'true', pattern: \"collapse/*.csv\",\n               saveAs: { it.endsWith(\".csv\") ? file(it).getName() : it }\n\n    input:\n    set val(name), file(count) from slamdunkCountOut\n\n    output:\n    set val(name), file(\"collapse/*csv\") into slamdunkCollapseOut\n\n    when:\n    !params.quantseq\n\n    script:\n    \"\"\"\n    alleyoop collapse \\\\\n        -o collapse \\\\\n        -t $task.cpus \\\n        $count\n    sed -i \"1i# name:${name}\" collapse/*csv\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    alleyoop collapse \\\\\n        -o collapse \\\\\n        -t $task.cpus \\\n        $count\n    sed -i \"1i# name:${name}\" collapse/*csv\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkCountOut"
        ],
        "nb_inputs": 1,
        "outputs": [
            "slamdunkCollapseOut"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "label 'slamdunk_process'",
            "publishDir path: \"${params.outdir}/slamdunk/count/genes\", mode: 'copy' , overwrite: 'true', pattern: \"collapse/*.csv\" , saveAs: { it.endsWith(\".csv\") ? file(it).getName() : it }"
        ],
        "when": "!params.quantseq",
        "stub": ""
    },
    "rates": {
        "name_process": "rates",
        "string_process": "\nprocess rates {\n    tag \"$name\"\n    label 'slamdunk_process'\n\n    input:\n    set val(name), file(filter), file(snp) from slamdunkForRatesChannel\n    each file(fasta) from fastaRatesChannel\n\n    output:\n    file(\"rates/*csv\") into alleyoopRatesOut\n\n    when:\n    !params.quantseq\n\n    script:\n    \"\"\"\n    alleyoop rates \\\\\n        -o rates \\\\\n        -r $fasta \\\\\n        -mq $params.base_quality \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    alleyoop rates \\\\\n        -o rates \\\\\n        -r $fasta \\\\\n        -mq $params.base_quality \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkForRatesChannel",
            "fastaRatesChannel"
        ],
        "nb_inputs": 2,
        "outputs": [
            "alleyoopRatesOut"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "label 'slamdunk_process'"
        ],
        "when": "!params.quantseq",
        "stub": ""
    },
    "utrrates": {
        "name_process": "utrrates",
        "string_process": "\nprocess utrrates {\n    tag \"$name\"\n    label 'slamdunk_process'\n\n    input:\n    set val(name), file(filter), file(snp) from slamdunkForUtrRatesChannel\n    each file(fasta) from fastaUtrRatesChannel\n    each file(bed) from utrratesChannel\n\n    output:\n    file(\"utrrates/*csv\") into alleyoopUtrRatesOut\n\n    when:\n    !params.quantseq\n\n    script:\n    \"\"\"\n    alleyoop utrrates \\\\\n        -o utrrates \\\\\n        -r $fasta \\\\\n        -mq $params.base_quality \\\\\n        -b $bed \\\\\n        -l $params.read_length \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    alleyoop utrrates \\\\\n        -o utrrates \\\\\n        -r $fasta \\\\\n        -mq $params.base_quality \\\\\n        -b $bed \\\\\n        -l $params.read_length \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkForUtrRatesChannel",
            "fastaUtrRatesChannel",
            "utrratesChannel"
        ],
        "nb_inputs": 3,
        "outputs": [
            "alleyoopUtrRatesOut"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "label 'slamdunk_process'"
        ],
        "when": "!params.quantseq",
        "stub": ""
    },
    "tcperreadpos": {
        "name_process": "tcperreadpos",
        "string_process": "\nprocess tcperreadpos {\n    tag \"$name\"\n    label 'slamdunk_process'\n\n    input:\n    set val(name), file(filter), file(snp) from slamdunkForTcPerReadPosChannel\n    each file(fasta) from fastaReadPosChannel\n\n    output:\n    file(\"tcperreadpos/*csv\") into alleyoopTcPerReadPosOut\n\n    when:\n    !params.quantseq\n\n    script:\n    snpMode = params.vcf ? \"-v $params.vcf\" : \"-s . \"\n    \"\"\"\n    alleyoop tcperreadpos \\\\\n        -o tcperreadpos \\\\\n        -r $fasta \\\\\n        $snpMode \\\\\n        -mq $params.base_quality \\\\\n        -l $params.read_length \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    snpMode = params.vcf ? \"-v $params.vcf\" : \"-s . \"\n    \"\"\"\n    alleyoop tcperreadpos \\\\\n        -o tcperreadpos \\\\\n        -r $fasta \\\\\n        $snpMode \\\\\n        -mq $params.base_quality \\\\\n        -l $params.read_length \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkForTcPerReadPosChannel",
            "fastaReadPosChannel"
        ],
        "nb_inputs": 2,
        "outputs": [
            "alleyoopTcPerReadPosOut"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "label 'slamdunk_process'"
        ],
        "when": "!params.quantseq",
        "stub": ""
    },
    "tcperutrpos": {
        "name_process": "tcperutrpos",
        "string_process": "\nprocess tcperutrpos {\n    tag \"$name\"\n    label 'slamdunk_process'\n\n    input:\n    set val(name), file(filter), file(snp) from slamdunkForTcPerUtrPosChannel\n    each file(fasta) from fastaUtrPosChannel\n    each file(bed) from utrposChannel\n\n    output:\n    file(\"tcperutrpos/*csv\") into alleyoopTcPerUtrPosOut\n\n    when:\n    !params.quantseq\n\n    script:\n    snpMode = params.vcf ? \"-v $params.vcf\" : \"-s . \"\n    \"\"\"\n    alleyoop tcperutrpos \\\\\n        -o tcperutrpos \\\\\n        -r $fasta \\\\\n        -b $bed \\\\\n        $snpMode \\\\\n        -mq $params.base_quality \\\\\n        -l $params.read_length \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    snpMode = params.vcf ? \"-v $params.vcf\" : \"-s . \"\n    \"\"\"\n    alleyoop tcperutrpos \\\\\n        -o tcperutrpos \\\\\n        -r $fasta \\\\\n        -b $bed \\\\\n        $snpMode \\\\\n        -mq $params.base_quality \\\\\n        -l $params.read_length \\\\\n        -t $task.cpus \\\\\n        ${filter[0]}\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkForTcPerUtrPosChannel",
            "fastaUtrPosChannel",
            "utrposChannel"
        ],
        "nb_inputs": 3,
        "outputs": [
            "alleyoopTcPerUtrPosOut"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "tag \"$name\"",
            "label 'slamdunk_process'"
        ],
        "when": "!params.quantseq",
        "stub": ""
    },
    "summary": {
        "name_process": "summary",
        "string_process": "\nprocess summary {\n\n    input:\n    file(\"filter/*\") from slamdunkFilterSummaryCollected\n    file(\"count/*\") from slamdunkCountAlleyoopCollected.ifEmpty([])\n\n    output:\n    file(\"summary*.txt\") into summaryQC\n\n    script:\n    countFolderFlag = !params.quantseq ? \"-t ./count\" : \"\"\n    \"\"\"\n    alleyoop summary \\\\\n        -o summary.txt \\\\\n        $countFolderFlag \\\\\n        ./filter/*bam\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    countFolderFlag = !params.quantseq ? \"-t ./count\" : \"\"\n    \"\"\"\n    alleyoop summary \\\\\n        -o summary.txt \\\\\n        $countFolderFlag \\\\\n        ./filter/*bam\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "slamdunkFilterSummaryCollected",
            "slamdunkCountAlleyoopCollected"
        ],
        "nb_inputs": 2,
        "outputs": [
            "summaryQC"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "deseq2": {
        "name_process": "deseq2",
        "string_process": "\nprocess deseq2 {\n    label 'slamdunk_process'\n\n    publishDir path: \"${params.outdir}/deseq2\", mode: 'copy', overwrite: 'true'\n\n    input:\n    file (conditions) from deseq2ConditionChannel.collect()\n    set val(group), file(\"counts/*\") from deseq2FileChannel\n\n    output:\n    file(\"${group}\") optional true into deseq2out\n\n    when:\n    !params.quantseq && !params.skip_deseq2\n\n    script:\n    \"\"\"\n    deseq2_slamdunk.r -t $group -d $conditions -c counts -p $params.pvalue -O $group\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    deseq2_slamdunk.r -t $group -d $conditions -c counts -p $params.pvalue -O $group\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "deseq2ConditionChannel",
            "deseq2FileChannel"
        ],
        "nb_inputs": 2,
        "outputs": [
            "deseq2out"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "label 'slamdunk_process'",
            "publishDir path: \"${params.outdir}/deseq2\", mode: 'copy', overwrite: 'true'"
        ],
        "when": "!params.quantseq && !params.skip_deseq2",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc {\n    publishDir \"${params.outdir}/multiqc\", mode: 'copy'\n\n    input:\n    file (multiqc_config) from ch_multiqc_config\n    file (mqc_custom_config) from ch_multiqc_custom_config.collect().ifEmpty([])\n    file(\"rates/*\") from alleyoopRatesOut.collect().ifEmpty([])\n    file(\"utrrates/*\") from alleyoopUtrRatesOut.collect().ifEmpty([])\n    file(\"tcperreadpos/*\") from alleyoopTcPerReadPosOut.collect().ifEmpty([])\n    file(\"tcperutrpos/*\") from alleyoopTcPerUtrPosOut.collect().ifEmpty([])\n    file(summary) from summaryQC\n    file (\"TrimGalore/*\") from trimgaloreQC.collect().ifEmpty([])\n    file (\"TrimGalore/*\") from trimgaloreFastQC.collect().ifEmpty([])\n    file ('software_versions/*') from ch_software_versions_yaml.collect()\n    file workflow_summary from ch_workflow_summary.collectFile(name: \"workflow_summary_mqc.yaml\")\n\n    output:\n    file \"*multiqc_report.html\" into ch_multiqc_report\n    file \"*_data\"\n    file \"multiqc_plots\"\n\n    script:\n    rtitle = custom_runName ? \"--title \\\"$custom_runName\\\"\" : ''\n    rfilename = custom_runName ? \"--filename \" + custom_runName.replaceAll('\\\\W','_').replaceAll('_+','_') + \"_multiqc_report\" : ''\n    custom_config_file = params.multiqc_config ? \"--config $mqc_custom_config\" : ''\n    \"\"\"\n    multiqc -m fastqc -m cutadapt -m slamdunk -f $rtitle $rfilename $custom_config_file .\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    rtitle = custom_runName ? \"--title \\\"$custom_runName\\\"\" : ''\n    rfilename = custom_runName ? \"--filename \" + custom_runName.replaceAll('\\\\W','_').replaceAll('_+','_') + \"_multiqc_report\" : ''\n    custom_config_file = params.multiqc_config ? \"--config $mqc_custom_config\" : ''\n    \"\"\"\n    multiqc -m fastqc -m cutadapt -m slamdunk -f $rtitle $rfilename $custom_config_file .\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "ch_multiqc_config",
            "ch_multiqc_custom_config",
            "alleyoopRatesOut",
            "alleyoopUtrRatesOut",
            "alleyoopTcPerReadPosOut",
            "alleyoopTcPerUtrPosOut",
            "summaryQC",
            "trimgaloreQC",
            "trimgaloreFastQC",
            "ch_software_versions_yaml",
            "ch_workflow_summary"
        ],
        "nb_inputs": 11,
        "outputs": [
            "ch_multiqc_report"
        ],
        "nb_outputs": 1,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "publishDir \"${params.outdir}/multiqc\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "output_documentation": {
        "name_process": "output_documentation",
        "string_process": "\nprocess output_documentation {\n    publishDir \"${params.outdir}/pipeline_info\", mode: 'copy'\n\n    input:\n    file output_docs from ch_output_docs\n    file images from ch_output_docs_images\n\n    output:\n    file \"results_description.html\"\n\n    script:\n    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_output_docs",
            "ch_output_docs_images"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "t-neumann__slamseq",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}