{
    "Database_Check": {
        "name_process": "Database_Check",
        "string_process": " process Database_Check {\n            script:\n                \"\"\"\n                cd ${params.workingdir}\n                echo -e \"-- Checking if specified database directory exists --\\\\n\"\n                if [ ! -d ${params.dbdir} ];then\n                    echo \"-- Directory does not exist where you say it does...\"\n                    echo \"Maybe it was a mistake, looking for the Databases directory in vAMPdir\"\n                    if [ ! -d ${params.vampdir}/Databases ];then\n                        echo \"-- Databases directory is not present, check the configuration file and help documentation to set path to databases\"\n                        exit 1\n                    else\n                        echo \"Ok, you have the database directory present in ${params.vampdir}\"\n                        echo \"Checking now for any databases that matched the database name specified..\"\n                        if [ ! -e ${params.vampdir}/Databases/${params.dbname} ];then\n                            echo \"Nope, no database by that name here. Check the configuration file and help documentation to set path to the database.\"\n                            exit 1\n                        else\n                            echo \"Ok, found the database specified here. Lets move it to the directory you wanted.\"\n                            mkdir ${params.dbdir}\n                            cp ${params.vampdir}/Databases/${params.dbname}* ${params.dbdir}/\n                            if [ ! -e ${params.dbdir}/${params.dbname}.dmnd ];then\n                                echo \"It needs to be built upp, doing it now\"\n                                if [[ ${params.ncbitax} == \"true\" && ${params.dbtype} == \"NCBI\" ]]\n                                then    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname} --taxonmap ${params.dbdir}/NCBItaxonomy/prot.accession2taxid.FULL --taxonnodes ${params.dbdir}/NCBItaxonomy/nodes.dmp --taxonnames ${params.dbdir}/NCBItaxonomy/names.dmp\n                                else    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname}\n                                fi\n                                export virdb=${params.dbdir}/${params.dbname}\n                            else\n                                echo \"Database looks to be present and built.\"\n                            fi\n                        fi\n                    fi\n                    cd  ${params.workingdir}\n                elif [ -d ${params.dbdir} ];then\n                    echo -e \"-- Directory exists. Checking if specified database is present now.. --\\\\n\"\n                    if [ ! -e ${params.dbdir}/${params.dbname} ];then\n                        echo \"Specified database not present, edit the configuraton file with the database name plz.\"\n                        exit 1\n                    else\n                        echo \"Database present, checking if built now..\"\n                        if [ ! -e ${params.dbdir}/${params.dbname}.dmnd  ];then\n                            echo \"Database not built, building now...\"\n                            if [ ! -e ${params.dbdir}/${params.dbname}.dmnd ];then\n                                echo \"It needs to be built upp, doing it now\"\n                                if [[ ${params.ncbitax} == \"true\" && ${params.dbtype} == \"NCBI\" ]]\n                                then    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname} --taxonmap ${params.dbdir}/NCBItaxonomy/prot.accession2taxid.FULL --taxonnodes ${params.dbdir}/NCBItaxonomy/nodes.dmp --taxonnames ${params.dbdir}/NCBItaxonomy/names.dmp\n                                else    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname}\n                                fi\n                                export virdb=${params.dbdir}/${params.dbname}\n                            else\n                                echo \"Database looks to be present and built.\"\n                            fi\n                        else\n                            echo \"-- Database is ready to go!\"\n                            export virdb=${params.dbdir}/${params.dbname}\n                        fi\n                    fi\n                    cd  ${params.workingdir}\n                fi\n                \"\"\"\n        }",
        "nb_lignes_process": 60,
        "string_script": "                \"\"\"\n                cd ${params.workingdir}\n                echo -e \"-- Checking if specified database directory exists --\\\\n\"\n                if [ ! -d ${params.dbdir} ];then\n                    echo \"-- Directory does not exist where you say it does...\"\n                    echo \"Maybe it was a mistake, looking for the Databases directory in vAMPdir\"\n                    if [ ! -d ${params.vampdir}/Databases ];then\n                        echo \"-- Databases directory is not present, check the configuration file and help documentation to set path to databases\"\n                        exit 1\n                    else\n                        echo \"Ok, you have the database directory present in ${params.vampdir}\"\n                        echo \"Checking now for any databases that matched the database name specified..\"\n                        if [ ! -e ${params.vampdir}/Databases/${params.dbname} ];then\n                            echo \"Nope, no database by that name here. Check the configuration file and help documentation to set path to the database.\"\n                            exit 1\n                        else\n                            echo \"Ok, found the database specified here. Lets move it to the directory you wanted.\"\n                            mkdir ${params.dbdir}\n                            cp ${params.vampdir}/Databases/${params.dbname}* ${params.dbdir}/\n                            if [ ! -e ${params.dbdir}/${params.dbname}.dmnd ];then\n                                echo \"It needs to be built upp, doing it now\"\n                                if [[ ${params.ncbitax} == \"true\" && ${params.dbtype} == \"NCBI\" ]]\n                                then    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname} --taxonmap ${params.dbdir}/NCBItaxonomy/prot.accession2taxid.FULL --taxonnodes ${params.dbdir}/NCBItaxonomy/nodes.dmp --taxonnames ${params.dbdir}/NCBItaxonomy/names.dmp\n                                else    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname}\n                                fi\n                                export virdb=${params.dbdir}/${params.dbname}\n                            else\n                                echo \"Database looks to be present and built.\"\n                            fi\n                        fi\n                    fi\n                    cd  ${params.workingdir}\n                elif [ -d ${params.dbdir} ];then\n                    echo -e \"-- Directory exists. Checking if specified database is present now.. --\\\\n\"\n                    if [ ! -e ${params.dbdir}/${params.dbname} ];then\n                        echo \"Specified database not present, edit the configuraton file with the database name plz.\"\n                        exit 1\n                    else\n                        echo \"Database present, checking if built now..\"\n                        if [ ! -e ${params.dbdir}/${params.dbname}.dmnd  ];then\n                            echo \"Database not built, building now...\"\n                            if [ ! -e ${params.dbdir}/${params.dbname}.dmnd ];then\n                                echo \"It needs to be built upp, doing it now\"\n                                if [[ ${params.ncbitax} == \"true\" && ${params.dbtype} == \"NCBI\" ]]\n                                then    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname} --taxonmap ${params.dbdir}/NCBItaxonomy/prot.accession2taxid.FULL --taxonnodes ${params.dbdir}/NCBItaxonomy/nodes.dmp --taxonnames ${params.dbdir}/NCBItaxonomy/names.dmp\n                                else    diamond makedb --in ${params.dbdir}/${params.dbname} -d ${params.dbdir}/${params.dbname}\n                                fi\n                                export virdb=${params.dbdir}/${params.dbname}\n                            else\n                                echo \"Database looks to be present and built.\"\n                            fi\n                        else\n                            echo \"-- Database is ready to go!\"\n                            export virdb=${params.dbdir}/${params.dbname}\n                        fi\n                    fi\n                    cd  ${params.workingdir}\n                fi\n                \"\"\"",
        "nb_lignes_script": 58,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "QualityCheck_1": {
        "name_process": "QualityCheck_1",
        "string_process": " process QualityCheck_1 {\n\n                label 'low_cpus'\n\n                tag \"${sample_id}\"\n\n                publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/FastQC/PreClean\", mode: \"copy\", overwrite: true\n\n                input:\n                    tuple sample_id, file(reads) from reads_qc_ch\n\n                output:\n                    tuple sample_id, file(\"*_fastqc.{zip,html}\") into fastqc_results\n\n                script:\n                    \"\"\"\n                    fastqc --quiet --threads ${task.cpus} ${reads}\n                    \"\"\"\n            }",
        "nb_lignes_process": 17,
        "string_script": "                    \"\"\"\n                    fastqc --quiet --threads ${task.cpus} ${reads}\n                    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "reads_qc_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "tag \"${sample_id}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/FastQC/PreClean\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Adapter_Removal": {
        "name_process": "Adapter_Removal",
        "string_process": " process Adapter_Removal {\n\n                label 'norm_cpus'\n\n                tag \"${sample_id}\"\n\n                publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/AdapterRemoval\", mode: \"copy\", overwrite: true, pattern: \"*.filter.fq\"\n                publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/AdapterRemoval/fastpOut\", mode: \"copy\", overwrite: true, pattern: \"*.fastp.{json,html}\"\n\n                input:\n                    tuple sample_id, file(reads) from reads_ch\n\n                output:\n                    tuple sample_id, file(\"*.fastp.{json,html}\") into fastp_results\n                    tuple sample_id, file(\"*.filter.fq\") into reads_fastp_ch\n                    file(\"*.csv\") into ( fastp_csv_in1, fastp_csv_in2 )\n\n                script:\n                    \"\"\"\n                    echo ${sample_id}\n\n                    fastp -i ${reads[0]} -I ${reads[1]} -o left-${sample_id}.filter.fq -O right-${sample_id}.filter.fq --detect_adapter_for_pe \\\n                    --average_qual ${params.avQ} -n ${params.mN} -c --overrepresentation_analysis --html ${sample_id}.fastp.html --json ${sample_id}.fastp.json --thread ${task.cpus} \\\n                    --report_title ${sample_id}\n\n                    bash get_readstats.sh ${sample_id}.fastp.json\n                    \"\"\"\n                }",
        "nb_lignes_process": 26,
        "string_script": "                    \"\"\"\n                    echo ${sample_id}\n\n                    fastp -i ${reads[0]} -I ${reads[1]} -o left-${sample_id}.filter.fq -O right-${sample_id}.filter.fq --detect_adapter_for_pe \\\n                    --average_qual ${params.avQ} -n ${params.mN} -c --overrepresentation_analysis --html ${sample_id}.fastp.html --json ${sample_id}.fastp.json --thread ${task.cpus} \\\n                    --report_title ${sample_id}\n\n                    bash get_readstats.sh ${sample_id}.fastp.json\n                    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "reads_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastp_results",
            "reads_fastp_ch",
            ""
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${sample_id}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/AdapterRemoval\", mode: \"copy\", overwrite: true, pattern: \"*.filter.fq\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/AdapterRemoval/fastpOut\", mode: \"copy\", overwrite: true, pattern: \"*.fastp.{json,html}\""
        ],
        "when": "",
        "stub": ""
    },
    "Primer_Removal": {
        "name_process": "Primer_Removal",
        "string_process": " process Primer_Removal {\n\n                label 'norm_cpus'\n\n                tag \"${sample_id}\"\n\n                publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/PrimerRemoval\", mode: \"copy\", overwrite: true\n\n                input:\n                    tuple sample_id, file(reads) from reads_fastp_ch\n\n                output:\n                    tuple sample_id, file(\"*bbduk*.fastq.gz\") into ( reads_bbduk_ch, readsforqc2 )\n\n                script:\n                                                                       \n                    if ( params.fwd == \"\" && params.rev == \"\" && !params.multi) {\n                        \"\"\"\n                        bbduk.sh in1=${reads[0]} out=${sample_id}_bb_R1.fastq.gz ftl=${params.defaultFwdTrim} t=${task.cpus}\n                        bbduk.sh in=${reads[1]} out=${sample_id}_bb_R2.fastq.gz ftl=${params.defaultRevTrim} t=${task.cpus}\n        \t\t            repair.sh in1=${sample_id}_bb_R1.fastq.gz in2=${sample_id}_bb_R2.fastq.gz out1=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz outs=sing.fq repair\n                        \"\"\"\n                    } else if ( params.GlobTrim && !params.GlobTrim == \"\" ) {\n                        \"\"\"\n                        FTRIM=\\$( echo ${GlobTrim} | cut -f 1 -d \",\" )\n                        RTRIM=\\$( echo ${GlobTrim} | cut -f 2 -d \",\" )\n                        bbduk.sh in=${reads[0]} out=${sample_id}_bb_R1.fastq.gz ftl=\\${FTRIM} t=${task.cpus}\n                        bbduk.sh in=${reads[1]} out=${sample_id}_bb_R2.fastq.gz ftl=\\${RTRIM} t=${task.cpus}\n        \t\t            repair.sh in1=${sample_id}_bb_R1.fastq.gz in2=${sample_id}_bb_R2.fastq.gz out1=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz outs=sing.fq repair\n                        \"\"\"\n                    } else if ( params.multi && params.primers ) {\n                        \"\"\"\n                        bbduk.sh in=${reads[0]} in2=${reads[1]} out=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz ref=${params.primers} copyundefined=t t=${task.cpus} restrictleft=${params.primerLength} k=${params.maxkmer} ordered=t mink=${params.minkmer} ktrim=l ecco=t rcomp=t minlength=${params.minilen} tbo tpe\n                        \"\"\"\n                    } else {\n                        \"\"\"\n                        bbduk.sh in=${reads[0]} in2=${reads[1]} out=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz literal=${params.fwd},${params.rev} copyundefined=t t=${task.cpus} restrictleft=${params.primerLength} k=${params.maxkmer} ordered=t mink=${params.minkmer} ktrim=l ecco=t rcomp=t minlength=${params.minilen} tbo tpe\n                        \"\"\"\n                    }\n        \t  }",
        "nb_lignes_process": 38,
        "string_script": "                    if ( params.fwd == \"\" && params.rev == \"\" && !params.multi) {\n                        \"\"\"\n                        bbduk.sh in1=${reads[0]} out=${sample_id}_bb_R1.fastq.gz ftl=${params.defaultFwdTrim} t=${task.cpus}\n                        bbduk.sh in=${reads[1]} out=${sample_id}_bb_R2.fastq.gz ftl=${params.defaultRevTrim} t=${task.cpus}\n        \t\t            repair.sh in1=${sample_id}_bb_R1.fastq.gz in2=${sample_id}_bb_R2.fastq.gz out1=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz outs=sing.fq repair\n                        \"\"\"\n                    } else if ( params.GlobTrim && !params.GlobTrim == \"\" ) {\n                        \"\"\"\n                        FTRIM=\\$( echo ${GlobTrim} | cut -f 1 -d \",\" )\n                        RTRIM=\\$( echo ${GlobTrim} | cut -f 2 -d \",\" )\n                        bbduk.sh in=${reads[0]} out=${sample_id}_bb_R1.fastq.gz ftl=\\${FTRIM} t=${task.cpus}\n                        bbduk.sh in=${reads[1]} out=${sample_id}_bb_R2.fastq.gz ftl=\\${RTRIM} t=${task.cpus}\n        \t\t            repair.sh in1=${sample_id}_bb_R1.fastq.gz in2=${sample_id}_bb_R2.fastq.gz out1=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz outs=sing.fq repair\n                        \"\"\"\n                    } else if ( params.multi && params.primers ) {\n                        \"\"\"\n                        bbduk.sh in=${reads[0]} in2=${reads[1]} out=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz ref=${params.primers} copyundefined=t t=${task.cpus} restrictleft=${params.primerLength} k=${params.maxkmer} ordered=t mink=${params.minkmer} ktrim=l ecco=t rcomp=t minlength=${params.minilen} tbo tpe\n                        \"\"\"\n                    } else {\n                        \"\"\"\n                        bbduk.sh in=${reads[0]} in2=${reads[1]} out=${sample_id}_bbduk_R1.fastq.gz out2=${sample_id}_bbduk_R2.fastq.gz literal=${params.fwd},${params.rev} copyundefined=t t=${task.cpus} restrictleft=${params.primerLength} k=${params.maxkmer} ordered=t mink=${params.minkmer} ktrim=l ecco=t rcomp=t minlength=${params.minilen} tbo tpe\n                        \"\"\"\n                    }",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_fastp_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${sample_id}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/PrimerRemoval\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "QualityCheck_2": {
        "name_process": "QualityCheck_2",
        "string_process": " process QualityCheck_2 {\n\n                label 'low_cpus'\n\n                tag \"${sample_id}\"\n\n                publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/FastQC/PostClean\", mode: \"copy\", overwrite: true\n\n                input:\n                    tuple sample_id, file(reads) from readsforqc2\n\n                output:\n                    tuple sample_id, file(\"*_fastqc.{zip,html}\") into fastqc2_results\n\n                script:\n                    \"\"\"\n                    fastqc --quiet --threads ${task.cpus} ${reads}\n                    \"\"\"\n            }",
        "nb_lignes_process": 17,
        "string_script": "                    \"\"\"\n                    fastqc --quiet --threads ${task.cpus} ${reads}\n                    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "readsforqc2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc2_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "tag \"${sample_id}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/FastQC/PostClean\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Read_Merging": {
        "name_process": "Read_Merging",
        "string_process": " process Read_Merging {\n\n            label 'norm_cpus'\n\n            tag \"${sample_id}\"\n\n            publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Individual\", mode: \"copy\", overwrite: true, pattern: \"*mergedclean.fastq\"\n            publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Individual/notmerged\", mode: \"copy\", overwrite: true, pattern: \"*notmerged*.fastq\"\n\n            input:\n                tuple sample_id, file(reads) from reads_bbduk_ch\n\n            output:\n                file(\"*_mergedclean.fastq\") into reads_vsearch1_ch\n                file(\"*.name\") into names\n                file(\"*notmerged*.fastq\") into notmerged\n\n            script:\n                \"\"\"\n                vsearch --fastq_mergepairs ${reads[0]} --reverse ${reads[1]} --threads ${task.cpus} --fastqout ${sample_id}_mergedclean.fastq --fastqout_notmerged_fwd ${sample_id}_notmerged_fwd.fastq --fastqout_notmerged_rev ${sample_id}_notmerged_rev.fastq  --fastq_maxdiffs ${params.diffs} --fastq_maxns ${params.maxn} --fastq_allowmergestagger --fastq_maxee ${params.maxEE} --fastq_minovlen ${params.minoverlap} --relabel ${sample_id}.\n                echo ${sample_id} > ${sample_id}.name\n                \"\"\"\n\n        }",
        "nb_lignes_process": 22,
        "string_script": "                \"\"\"\n                vsearch --fastq_mergepairs ${reads[0]} --reverse ${reads[1]} --threads ${task.cpus} --fastqout ${sample_id}_mergedclean.fastq --fastqout_notmerged_fwd ${sample_id}_notmerged_fwd.fastq --fastqout_notmerged_rev ${sample_id}_notmerged_rev.fastq  --fastq_maxdiffs ${params.diffs} --fastq_maxns ${params.maxn} --fastq_allowmergestagger --fastq_maxee ${params.maxEE} --fastq_minovlen ${params.minoverlap} --relabel ${sample_id}.\n                echo ${sample_id} > ${sample_id}.name\n                \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "reads_bbduk_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reads_vsearch1_ch",
            "names",
            "notmerged"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${sample_id}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Individual\", mode: \"copy\", overwrite: true, pattern: \"*mergedclean.fastq\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Individual/notmerged\", mode: \"copy\", overwrite: true, pattern: \"*notmerged*.fastq\""
        ],
        "when": "",
        "stub": ""
    },
    "Filtering_Prep1": {
        "name_process": "Filtering_Prep1",
        "string_process": " process Filtering_Prep1 {\n\n        label 'low_cpus'\n\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/LengthFiltering\", mode: \"copy\", overwrite: true\n\n        input:\n            file(reads) from reads_vsearch1_ch\n                .collect()\n\n        output:\n            file(\"*_all_merged_preFilt_preClean.fastq\") into collect_samples_ch\n\n        script:\n            \"\"\"\n            cat ${reads} >>${params.projtag}_all_merged_preFilt_preClean.fastq\n\t        \"\"\"\n    }",
        "nb_lignes_process": 16,
        "string_script": "            \"\"\"\n            cat ${reads} >>${params.projtag}_all_merged_preFilt_preClean.fastq\n\t        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_vsearch1_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collect_samples_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/LengthFiltering\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Filtering_Prep2": {
        "name_process": "Filtering_Prep2",
        "string_process": " process Filtering_Prep2 {\n\n        label 'low_cpus'\n\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging\", mode: \"copy\", overwrite: true\n\n        input:\n            file(names) from names\n                .collect()\n\n        output:\n            file(\"*sample_ids.list\") into ( samplelist, samplistpotu )\n\n        script:\n            \"\"\"\n            cat ${names} >>${params.projtag}_sample_ids.list\n            \"\"\"\n\n    }",
        "nb_lignes_process": 17,
        "string_script": "            \"\"\"\n            cat ${names} >>${params.projtag}_sample_ids.list\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "names"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Length_Filtering": {
        "name_process": "Length_Filtering",
        "string_process": " process Length_Filtering {\n\n        label 'norm_cpus'\n\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/LengthFiltering\", mode: \"copy\", overwrite: true, pattern: \"*_merged_preFilt*.fasta\"\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging\", mode: \"copy\", overwrite: true, pattern: \"*Lengthfiltered.fastq\"\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Histograms/pre_length_filtering\", mode: \"copy\", overwrite: true, pattern: \"*preFilt_*st.txt\"\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Histograms/post_length_filtering\", mode: \"copy\", overwrite: true, pattern: \"*postFilt_*st.txt\"\n\n        input:\n            file(reads) from collect_samples_ch\n\n        output:\n            file(\"*_merged_preFilt_clean.fastq\") into (  mergeforprotcounts, mergeforpcASVaacounts )\n\n            file(\"*_merged_preFilt_clean.fasta\") into ( nuclCounts_mergedreads_asv_ch, nuclCounts_mergedreads_ncasv_ch, pcASV_mergedreads_ch )\n            file(\"*_merged_clean_Lengthfiltered.fastq\") into reads_vsearch2_ch\n\n            file(\"*preFilt_preClean_baseFrequency_hist.csv\") into prefilt_basefreq\n            file(\"*preFilt_preClean_qualityScore_hist.csv\") into prefilt_qualityscore\n            file(\"*preFilt_preClean_gcContent_hist.csv\") into prefilt_gccontent\n            file(\"*preFilt_preClean_averageQuality_hist.csv\") into prefilt_averagequality\n            file(\"*preFilt_preClean_length_hist.csv\") into prefilt_length\n\n            file(\"*postFilt_baseFrequency_hist.csv\") into postFilt_basefreq\n            file(\"*postFilt_qualityScore_hist.csv\") into postFilt_qualityscore\n            file(\"*postFilt_gcContent_hist.csv\") into postFilt_gccontent\n            file(\"*postFilt_averageQuaulity_hist.csv\") into postFilt_averagequality\n            file(\"*postFilt_length_hist.csv\") into postFilt_length\n\n            file(\"reads_per_sample_preFilt_preClean.csv\") into reads_per_sample_preFilt\n            file(\"read_per_sample_postFilt_postClean.csv\") into reads_per_sample_postFilt\n\n        script:\n            \"\"\"\n            # from DC\n            bbduk.sh in=${reads} bhist=${params.projtag}_all_merged_preFilt_preClean_baseFrequency_hist.txt qhist=${params.projtag}_all_merged_preFilt_preClean_qualityScore_hist.txt gchist=${params.projtag}_all_merged_preFilt_preClean_gcContent_hist.txt aqhist=${params.projtag}_all_merged_preFilt_preClean_averageQuality_hist.txt lhist=${params.projtag}_all_merged_preFilt_preClean_length_hist.txt gcbins=auto\n            for x in *preFilt*hist.txt;do\n                pre=\\$(echo \\$x | awk -F \".txt\" '{print \\$1}')\n                cat \\$x | tr \"\\t\" \",\" > \\${pre}.csv\n                rm \\$x\n            done\n            bbduk.sh in=${reads} out=${params.projtag}_qtrimmed.fastq t=${task.cpu} qtrim=rl trimq=${params.trimq}\n            reformat.sh in=${params.projtag}_qtrimmed.fastq out=${params.projtag}_preFilt_preclean.fasta t=${task.cpus}\n            echo \"sample,reads\" >> reads_per_sample_preFilt_preClean.csv\n            grep \">\" ${params.projtag}_preFilt_preclean.fasta | awk -F \">\" '{print \\$2}' | awk -F \".\" '{print \\$1}' | sort --parallel=${task.cpus} | uniq -c | sort -brg --parallel=${task.cpus} | awk '{print \\$2\",\"\\$1}' >> reads_per_sample_preFilt_preClean.csv\n            rm ${params.projtag}_preFilt_preclean.fasta\n            fastp -i ${reads} -o ${params.projtag}_merged_preFilt_clean.fastq -b ${params.maxLen} -l ${params.minLen} --thread ${task.cpus} -n ${params.maxn}\n            reformat.sh in=${params.projtag}_merged_preFilt_clean.fastq out=${params.projtag}_merged_preFilt_clean.fasta t=${task.cpus}\n            bbduk.sh in=${params.projtag}_merged_preFilt_clean.fastq out=${params.projtag}_merged_clean_Lengthfiltered.fastq minlength=${params.maxLen} maxlength=${params.maxLen} t=${task.cpus}\n            bbduk.sh in=${params.projtag}_merged_clean_Lengthfiltered.fastq bhist=${params.projtag}_all_merged_postFilt_baseFrequency_hist.txt qhist=${params.projtag}_all_merged_postFilt_qualityScore_hist.txt gchist=${params.projtag}_all_merged_postFilt_gcContent_hist.txt aqhist=${params.projtag}_all_merged_postFilt_averageQuaulity_hist.txt lhist=${params.projtag}_all_merged_postFilt_length_hist.txt gcbins=auto\n            for x in *postFilt*hist.txt;do\n                pre=\\$(echo \\$x | awk -F \".txt\" '{print \\$1}')\n                cat \\$x | tr \"\\t\" \",\" > \\${pre}.csv\n                rm \\$x\n            done\n            reformat.sh in=${params.projtag}_merged_clean_Lengthfiltered.fastq out=${params.projtag}_merged_clean_Lengthfiltered.fasta t=${task.cpus}\n            echo \"sample,reads\" >> read_per_sample_postFilt_postClean.csv\n            grep \">\" ${params.projtag}_merged_clean_Lengthfiltered.fasta | awk -F \">\" '{print \\$2}' | awk -F \".\" '{print \\$1}' | sort --parallel=${task.cpus} | uniq -c | sort -brg --parallel=${task.cpus} | awk '{print \\$2\",\"\\$1}' >> read_per_sample_postFilt_postClean.csv\n            \"\"\"\n    }",
        "nb_lignes_process": 59,
        "string_script": "            \"\"\"\n            # from DC\n            bbduk.sh in=${reads} bhist=${params.projtag}_all_merged_preFilt_preClean_baseFrequency_hist.txt qhist=${params.projtag}_all_merged_preFilt_preClean_qualityScore_hist.txt gchist=${params.projtag}_all_merged_preFilt_preClean_gcContent_hist.txt aqhist=${params.projtag}_all_merged_preFilt_preClean_averageQuality_hist.txt lhist=${params.projtag}_all_merged_preFilt_preClean_length_hist.txt gcbins=auto\n            for x in *preFilt*hist.txt;do\n                pre=\\$(echo \\$x | awk -F \".txt\" '{print \\$1}')\n                cat \\$x | tr \"\\t\" \",\" > \\${pre}.csv\n                rm \\$x\n            done\n            bbduk.sh in=${reads} out=${params.projtag}_qtrimmed.fastq t=${task.cpu} qtrim=rl trimq=${params.trimq}\n            reformat.sh in=${params.projtag}_qtrimmed.fastq out=${params.projtag}_preFilt_preclean.fasta t=${task.cpus}\n            echo \"sample,reads\" >> reads_per_sample_preFilt_preClean.csv\n            grep \">\" ${params.projtag}_preFilt_preclean.fasta | awk -F \">\" '{print \\$2}' | awk -F \".\" '{print \\$1}' | sort --parallel=${task.cpus} | uniq -c | sort -brg --parallel=${task.cpus} | awk '{print \\$2\",\"\\$1}' >> reads_per_sample_preFilt_preClean.csv\n            rm ${params.projtag}_preFilt_preclean.fasta\n            fastp -i ${reads} -o ${params.projtag}_merged_preFilt_clean.fastq -b ${params.maxLen} -l ${params.minLen} --thread ${task.cpus} -n ${params.maxn}\n            reformat.sh in=${params.projtag}_merged_preFilt_clean.fastq out=${params.projtag}_merged_preFilt_clean.fasta t=${task.cpus}\n            bbduk.sh in=${params.projtag}_merged_preFilt_clean.fastq out=${params.projtag}_merged_clean_Lengthfiltered.fastq minlength=${params.maxLen} maxlength=${params.maxLen} t=${task.cpus}\n            bbduk.sh in=${params.projtag}_merged_clean_Lengthfiltered.fastq bhist=${params.projtag}_all_merged_postFilt_baseFrequency_hist.txt qhist=${params.projtag}_all_merged_postFilt_qualityScore_hist.txt gchist=${params.projtag}_all_merged_postFilt_gcContent_hist.txt aqhist=${params.projtag}_all_merged_postFilt_averageQuaulity_hist.txt lhist=${params.projtag}_all_merged_postFilt_length_hist.txt gcbins=auto\n            for x in *postFilt*hist.txt;do\n                pre=\\$(echo \\$x | awk -F \".txt\" '{print \\$1}')\n                cat \\$x | tr \"\\t\" \",\" > \\${pre}.csv\n                rm \\$x\n            done\n            reformat.sh in=${params.projtag}_merged_clean_Lengthfiltered.fastq out=${params.projtag}_merged_clean_Lengthfiltered.fasta t=${task.cpus}\n            echo \"sample,reads\" >> read_per_sample_postFilt_postClean.csv\n            grep \">\" ${params.projtag}_merged_clean_Lengthfiltered.fasta | awk -F \">\" '{print \\$2}' | awk -F \".\" '{print \\$1}' | sort --parallel=${task.cpus} | uniq -c | sort -brg --parallel=${task.cpus} | awk '{print \\$2\",\"\\$1}' >> read_per_sample_postFilt_postClean.csv\n            \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "collect_samples_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "",
            "reads_vsearch2_ch",
            "prefilt_basefreq",
            "prefilt_qualityscore",
            "prefilt_gccontent",
            "prefilt_averagequality",
            "prefilt_length",
            "postFilt_basefreq",
            "postFilt_qualityscore",
            "postFilt_gccontent",
            "postFilt_averagequality",
            "postFilt_length",
            "reads_per_sample_preFilt",
            "reads_per_sample_postFilt"
        ],
        "nb_outputs": 15,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/LengthFiltering\", mode: \"copy\", overwrite: true, pattern: \"*_merged_preFilt*.fasta\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging\", mode: \"copy\", overwrite: true, pattern: \"*Lengthfiltered.fastq\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Histograms/pre_length_filtering\", mode: \"copy\", overwrite: true, pattern: \"*preFilt_*st.txt\"",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Histograms/post_length_filtering\", mode: \"copy\", overwrite: true, pattern: \"*postFilt_*st.txt\""
        ],
        "when": "",
        "stub": ""
    },
    "Extracting_Uniques": {
        "name_process": "Extracting_Uniques",
        "string_process": " process Extracting_Uniques {\n\n        label 'low_cpus'\n\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Uniques\", mode: \"copy\", overwrite: true\n\n        input:\n            file(reads) from reads_vsearch2_ch\n\n        output:\n            file(\"*unique_sequences.fasta\") into reads_vsearch3_ch\n\n        script:\n            \"\"\"\n            vsearch --derep_fulllength ${reads} --sizeout --relabel_keep --output ${params.projtag}_unique_sequences.fasta\n            \"\"\"\n    }",
        "nb_lignes_process": 15,
        "string_script": "            \"\"\"\n            vsearch --derep_fulllength ${reads} --sizeout --relabel_keep --output ${params.projtag}_unique_sequences.fasta\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "reads_vsearch2_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reads_vsearch3_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ReadMerging/Uniques\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Identify_ASVs": {
        "name_process": "Identify_ASVs",
        "string_process": " process Identify_ASVs {\n\n        label 'norm_cpus'\n\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/Clustering/ASVs/ChimeraCheck\", mode: \"copy\", overwrite: true\n\n        input:\n            file(reads) from reads_vsearch3_ch\n\n        output:\n            file(\"*notChecked.fasta\") into reads_vsearch4_ch\n\n        script:\n            \"\"\"\n            vsearch --cluster_unoise ${reads} --unoise_alpha ${params.alpha} --relabel ASV --centroids ${params.projtag}_notChecked.fasta --minsize ${params.minSize}\n            \"\"\"\n    }",
        "nb_lignes_process": 15,
        "string_script": "            \"\"\"\n            vsearch --cluster_unoise ${reads} --unoise_alpha ${params.alpha} --relabel ASV --centroids ${params.projtag}_notChecked.fasta --minsize ${params.minSize}\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "reads_vsearch3_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reads_vsearch4_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/Clustering/ASVs/ChimeraCheck\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Chimera_Check": {
        "name_process": "Chimera_Check",
        "string_process": " process Chimera_Check {\n\n        label 'low_cpus'\n\n        publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ASVs\", mode: \"copy\", overwrite: true\n\n        input:\n            file(fasta) from reads_vsearch4_ch\n\n        output:\n            file(\"*ASVs.fasta\") into asvforfilt\n\n\n        script:\n            \"\"\"\n\t        vsearch --uchime3_denovo ${fasta} --relabel ASV --nonchimeras ${params.projtag}_ASVs.fasta\n            \"\"\"\n    }",
        "nb_lignes_process": 16,
        "string_script": "            \"\"\"\n\t        vsearch --uchime3_denovo ${fasta} --relabel ASV --nonchimeras ${params.projtag}_ASVs.fasta\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_vsearch4_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "asvforfilt"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ASVs\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "ASV_Filtering": {
        "name_process": "ASV_Filtering",
        "string_process": " process ASV_Filtering {\n\n            label 'norm_cpus'\n\n            publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ASVFiltering\", mode: \"copy\", overwrite: true\n\n            input:\n                file(asv) from asvforfilt\n\n            output:\n                file(\"*ASV.fasta\") into ( reads_vsearch5_ch, asv_med, nucl2aa, asvsforAminotyping, asvfastaforcounts, asvaminocheck )\n                file(\"*.csv\") into ( nothing )\n                file(\"*diamondfilter.out\") into ( noth)\n            script:\n                \"\"\"\n                cp ${params.vampdir}/bin/rename_seq.py .\n\n                #create and rename  filter database\n                grep \">\" ${params.filtDB} | sed 's/ //g' | awk -F \">\" '{print \\$2}' >> filt.head\n                j=1\n                for y in \\$( cat filt.head );do\n                    echo \">Filt\"\\$j\"\" >> filt.headers\n                    j=\\$(( \\${j}+1 ))\n                done\n                ./rename_seq.py ${params.filtDB} filt.headers filterdatabaserenamed.fasta\n                cat filterdatabaserenamed.fasta >> combodatabase.fasta\n                paste -d',' filt.head filt.headers > filtername_map.csv\n\n                #create and rename keep database\n                grep \">\" ${params.keepDB} | sed 's/ //g' | awk -F \">\" '{print \\$2}' >> keep.head\n                d=1\n                for y in \\$( cat keep.head );do\n                    echo \">keep\"\\$d\"\" >> keep.headers\n                    d=\\$(( \\${d}+1 ))\n                done\n                ./rename_seq.py ${params.keepDB} keep.headers keepdatabaserenamed.fasta\n                cat keepdatabaserenamed.fasta >> combodatabase.fasta\n                paste -d',' keep.head keep.headers > keepername_map.csv\n                rm filterdatabaserenamed.fasta\n                #index database\n                diamond makedb --in combodatabase.fasta --db combodatabase.fasta\n                #run diamond_db\n                diamond blastx -q ${asv} -d combodatabase.fasta -p ${task.cpus} --id ${params.filtminID} -l ${params.filtminaln} -e ${params.filtevalue} --${params.filtsensitivity} -o ${params.projtag}_diamondfilter.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident --max-target-seqs 1 --max-hsps 1\n                #get asvs\n                grep \">\" ${asv} | awk -F \">\" '{print \\$2}' > asv.list\n                for x in \\$(cat asv.list)\n                do  #check for a hit\n                    if [[ \\$(grep -c \"\\$x\" ${params.projtag}_diamondfilter.out) -eq 1 ]]\n                    then    #check if hit is to filter\n                            hit=\\$(grep \"\\$x\" ${params.projtag}_diamondfilter.out | awk '{print \\$3}')\n                            if [[ \\$(grep -c \"\\$hit\" filt.headers) -eq 1 ]]\n                            then    echo \"\\$x,\\$hit\" >> filtered_asvs_summary.csv\n                            elif [[ \\$(grep -c \"\\$hit\" keep.headers) -eq 1 ]]\n                            then    echo \"\\$x\" >> kep.list\n                            fi\n                    else    echo \\$x >> nohit.list\n                    fi\n                done\n                if [[ ${params.keepnohit} == \"true\" ]]\n                then    cat nohit.list >> kep.list\n                        cat kep.list | sort >> keep.list\n                        seqtk subseq ${asv} keep.list > kept.fasta\n                        u=1\n                        for y in \\$( cat keep.list );do\n                            echo \">ASV\\${u}\" >> asvrename.list\n                            u=\\$(( \\${u}+1 ))\n                        done\n                        ./rename_seq.py ${asv} asvrename.list ${params.projtag}_ASV.fasta\n                else\n                        cat kep.list | sort > keep.list\n                        seqtk subseq ${asv} keep.list > kept.fasta\n                        u=1\n                        for y in \\$( cat keep.list );do\n                            echo \">ASV\\${u}\" >> asvrename.list\n                            u=\\$(( \\${u}+1 ))\n                        done\n                        ./rename_seq.py ${asv} asvrename.list ${params.projtag}_ASV.fasta\n                fi\n                paste -d',' keep.list asvrename.list > ASV_rename_map.csv\n                \"\"\"\n        }",
        "nb_lignes_process": 79,
        "string_script": "                \"\"\"\n                cp ${params.vampdir}/bin/rename_seq.py .\n\n                #create and rename  filter database\n                grep \">\" ${params.filtDB} | sed 's/ //g' | awk -F \">\" '{print \\$2}' >> filt.head\n                j=1\n                for y in \\$( cat filt.head );do\n                    echo \">Filt\"\\$j\"\" >> filt.headers\n                    j=\\$(( \\${j}+1 ))\n                done\n                ./rename_seq.py ${params.filtDB} filt.headers filterdatabaserenamed.fasta\n                cat filterdatabaserenamed.fasta >> combodatabase.fasta\n                paste -d',' filt.head filt.headers > filtername_map.csv\n\n                #create and rename keep database\n                grep \">\" ${params.keepDB} | sed 's/ //g' | awk -F \">\" '{print \\$2}' >> keep.head\n                d=1\n                for y in \\$( cat keep.head );do\n                    echo \">keep\"\\$d\"\" >> keep.headers\n                    d=\\$(( \\${d}+1 ))\n                done\n                ./rename_seq.py ${params.keepDB} keep.headers keepdatabaserenamed.fasta\n                cat keepdatabaserenamed.fasta >> combodatabase.fasta\n                paste -d',' keep.head keep.headers > keepername_map.csv\n                rm filterdatabaserenamed.fasta\n                #index database\n                diamond makedb --in combodatabase.fasta --db combodatabase.fasta\n                #run diamond_db\n                diamond blastx -q ${asv} -d combodatabase.fasta -p ${task.cpus} --id ${params.filtminID} -l ${params.filtminaln} -e ${params.filtevalue} --${params.filtsensitivity} -o ${params.projtag}_diamondfilter.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident --max-target-seqs 1 --max-hsps 1\n                #get asvs\n                grep \">\" ${asv} | awk -F \">\" '{print \\$2}' > asv.list\n                for x in \\$(cat asv.list)\n                do  #check for a hit\n                    if [[ \\$(grep -c \"\\$x\" ${params.projtag}_diamondfilter.out) -eq 1 ]]\n                    then    #check if hit is to filter\n                            hit=\\$(grep \"\\$x\" ${params.projtag}_diamondfilter.out | awk '{print \\$3}')\n                            if [[ \\$(grep -c \"\\$hit\" filt.headers) -eq 1 ]]\n                            then    echo \"\\$x,\\$hit\" >> filtered_asvs_summary.csv\n                            elif [[ \\$(grep -c \"\\$hit\" keep.headers) -eq 1 ]]\n                            then    echo \"\\$x\" >> kep.list\n                            fi\n                    else    echo \\$x >> nohit.list\n                    fi\n                done\n                if [[ ${params.keepnohit} == \"true\" ]]\n                then    cat nohit.list >> kep.list\n                        cat kep.list | sort >> keep.list\n                        seqtk subseq ${asv} keep.list > kept.fasta\n                        u=1\n                        for y in \\$( cat keep.list );do\n                            echo \">ASV\\${u}\" >> asvrename.list\n                            u=\\$(( \\${u}+1 ))\n                        done\n                        ./rename_seq.py ${asv} asvrename.list ${params.projtag}_ASV.fasta\n                else\n                        cat kep.list | sort > keep.list\n                        seqtk subseq ${asv} keep.list > kept.fasta\n                        u=1\n                        for y in \\$( cat keep.list );do\n                            echo \">ASV\\${u}\" >> asvrename.list\n                            u=\\$(( \\${u}+1 ))\n                        done\n                        ./rename_seq.py ${asv} asvrename.list ${params.projtag}_ASV.fasta\n                fi\n                paste -d',' keep.list asvrename.list > ASV_rename_map.csv\n                \"\"\"",
        "nb_lignes_script": 65,
        "language_script": "bash",
        "tools": [
            "Diamond",
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/diamond",
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "asvforfilt"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "",
            ""
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/ReadProcessing/ASVFiltering\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "NucleotideBased_ASV_clustering_DC": {
        "name_process": "NucleotideBased_ASV_clustering_DC",
        "string_process": " process NucleotideBased_ASV_clustering_DC {\n\n            label 'norm_cpus'\n\n            publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Nucleotide\", mode: \"copy\", overwrite: true, pattern: '*{.csv}'\n\n            input:\n                file(fasta) from reads_vsearch5_ch\n\n            output:\n                file(\"number_per_percentage_nucl.csv\") into number_per_percent_nucl_plot\n                file(\"${params.projtag}_ASV_PairwiseDistance.matrix\") into asvpdm\n            script:\n            if (params.datacheckntIDlist) {\n                \"\"\"\n                for id in `echo ${params.datacheckntIDlist} | tr \",\" \"\\\\n\"`;do\n                    vsearch --cluster_fast ${fasta} --centroids ${params.projtag}_ncASV\\${id}.fasta --threads ${task.cpus} --relabel OTU --id \\${id}\n                done\n                for x in *ncASV*.fasta;do\n                    id=\\$( echo \\$x | awk -F \"_ncASV\" '{print \\$2}' | awk -F \".fasta\" '{print \\$1}')\n                    numb=\\$( grep -c \">\" \\$x )\n                    echo \"\\${id},\\${numb}\" >> number_per_percentage_nucl.csv\n                done\n                yo=\\$(grep -c \">\" ${fasta})\n    \t          echo \"1.0,\\${yo}\" >> number_per_percentage_nucl.csv\n                clustalo -i ${fasta} --distmat-out=${params.projtag}_distance.matrix --full --force --threads=${task.cpus}\n                cat ${params.projtag}_distance.matrix | tr \" \" \",\"  | grep \",\" >${params.projtag}_ASV_PairwiseDistance.matrix\n                rm ${params.projtag}_distance.matrix\n                \"\"\"\n                }\n            }",
        "nb_lignes_process": 29,
        "string_script": "            if (params.datacheckntIDlist) {\n                \"\"\"\n                for id in `echo ${params.datacheckntIDlist} | tr \",\" \"\\\\n\"`;do\n                    vsearch --cluster_fast ${fasta} --centroids ${params.projtag}_ncASV\\${id}.fasta --threads ${task.cpus} --relabel OTU --id \\${id}\n                done\n                for x in *ncASV*.fasta;do\n                    id=\\$( echo \\$x | awk -F \"_ncASV\" '{print \\$2}' | awk -F \".fasta\" '{print \\$1}')\n                    numb=\\$( grep -c \">\" \\$x )\n                    echo \"\\${id},\\${numb}\" >> number_per_percentage_nucl.csv\n                done\n                yo=\\$(grep -c \">\" ${fasta})\n    \t          echo \"1.0,\\${yo}\" >> number_per_percentage_nucl.csv\n                clustalo -i ${fasta} --distmat-out=${params.projtag}_distance.matrix --full --force --threads=${task.cpus}\n                cat ${params.projtag}_distance.matrix | tr \" \" \",\"  | grep \",\" >${params.projtag}_ASV_PairwiseDistance.matrix\n                rm ${params.projtag}_distance.matrix\n                \"\"\"\n                }",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "reads_vsearch5_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "number_per_percent_nucl_plot",
            "asvpdm"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Nucleotide\", mode: \"copy\", overwrite: true, pattern: '*{.csv}'"
        ],
        "when": "",
        "stub": ""
    },
    "Translation_For_ProteinBased_Clustering_DC": {
        "name_process": "Translation_For_ProteinBased_Clustering_DC",
        "string_process": " process Translation_For_ProteinBased_Clustering_DC {\n\n           label 'norm_cpus'\n\n           publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Aminoacid/translation\", mode: \"copy\", overwrite: true\n\n           input:\n                file(fasta) from nucl2aa\n\n            output:\n                file(\"*ASVtranslations.fasta\") into clustering_aa\n                file(\"*_translation_report\") into reportaa_VR\n                file(\"*_ASV_all.fasta\") into asvfastaforaaclust\n\n            script:\n                \"\"\"\n                ${tools}/virtualribosomev2/dna2pep.py ${fasta} -r all -x -o none --fasta ${params.projtag}_ASVprot.fasta --report ${params.projtag}_translation_report\n                awk '/^>/ { print (NR==1 ? \"\" : RS) \\$0; next } { printf \"%s\", \\$0 } END { printf RS }' ${params.projtag}_ASVprot.fasta > ${params.projtag}_ASVtranslations.fasta\n                cp ${fasta} ${params.projtag}_ASV_all.fasta\n                \"\"\"\n       }",
        "nb_lignes_process": 19,
        "string_script": "                \"\"\"\n                ${tools}/virtualribosomev2/dna2pep.py ${fasta} -r all -x -o none --fasta ${params.projtag}_ASVprot.fasta --report ${params.projtag}_translation_report\n                awk '/^>/ { print (NR==1 ? \"\" : RS) \\$0; next } { printf \"%s\", \\$0 } END { printf RS }' ${params.projtag}_ASVprot.fasta > ${params.projtag}_ASVtranslations.fasta\n                cp ${fasta} ${params.projtag}_ASV_all.fasta\n                \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "NextSV"
        ],
        "tools_url": [
            "https://bio.tools/nextsv"
        ],
        "tools_dico": [
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            }
        ],
        "inputs": [
            "nucl2aa"
        ],
        "nb_inputs": 1,
        "outputs": [
            "clustering_aa",
            "reportaa_VR",
            "asvfastaforaaclust"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Aminoacid/translation\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Protein_clustering_DC": {
        "name_process": "Protein_clustering_DC",
        "string_process": " process Protein_clustering_DC {\n\n            label 'norm_cpus'\n\n            publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Aminoacid\", mode: \"copy\", overwrite: true, pattern: '*{.csv}'\n\n            input:\n                file(fasta) from clustering_aa\n                file(asvs) from asvfastaforaaclust\n\n            output:\n                file(\"number_per_percentage_prot.csv\") into number_per_percent_prot_plot\n                file(\"*aminoacid_pcASV1.0_noTaxonomy.fasta\") into amino_med\n                file(\"${params.projtag}_AminoType_PairwiseDistance.matrix\") into aminopdm\n\n            script:\n                                           \n                \"\"\"\n                set +e\n                cp ${params.vampdir}/bin/rename_seq.py .\n                for id in `echo ${params.datacheckaaIDlist} | tr \",\" \"\\\\n\"`;do\n                    if [ \\${id} == \".55\" ];then\n                        word=3\n                    elif [ \\${id} == \".65\" ];then\n                        word=4\n                    else\n                        word=5\n                    fi\n                    awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)>=\"${params.minAA}\"{print \">\"\\$0}' ${fasta} > ${params.projtag}_filtered_proteins.fasta\n                    cd-hit -i ${params.projtag}_filtered_proteins.fasta -n \\${word} -c \\${id} -o ${params.projtag}_pcASV\\${id}.fasta\n                    sed 's/>Cluster />Cluster_/g' ${params.projtag}_pcASV\\${id}.fasta.clstr >${params.projtag}_pcASV\\${id}.clstr\n                    grep \">Cluster_\" ${params.projtag}_pcASV\\${id}.clstr >temporaryclusters.list\n                    y=\\$(grep -c \">Cluster_\" ${params.projtag}_pcASV\\${id}.clstr)\n                    echo \">Cluster_\"\\${y}\"\" >> ${params.projtag}_pcASV\\${id}.clstr\n                    t=1\n                    b=1\n                    for x in \\$(cat temporaryclusters.list);do\n                        echo \"Extracting \\$x\"\n                        name=\"\\$( echo \\$x | awk -F \">\" '{print \\$2}')\"\n                        clust=\"pcASV\"\\${t}\"\"\n                        echo \"\\${name}\"\n                        awk '/^>'\\${name}'\\$/,/^>Cluster_'\\${b}'\\$/' ${params.projtag}_pcASV\\${id}.clstr > \"\\${name}\"_\"\\${clust}\"_tmp.list\n                        t=\\$(( \\${t}+1 ))\n                        b=\\$(( \\${b}+1 ))\n                    done\n                    ls *_tmp.list\n                    u=1\n                    for x in *_tmp.list;do\n                        name=\"\\$(echo \\$x | awk -F \"_p\" '{print \\$1}')\"\n                        echo \"\\${name}\"\n                        cluster=\"\\$(echo \\$x | awk -F \"_\" '{print \\$3}')\"\n                        echo \"\\${cluster}\"\n                        grep \"ASV\" \\$x | awk -F \", \" '{print \\$2}' | awk -F \"_\" '{print \\$1}' | awk -F \">\" '{print \\$2}' > \\${name}_\\${cluster}_seqs_tmps.list\n                        seqtk subseq ${asvs} \\${name}_\\${cluster}_seqs_tmps.list > \\${name}_\\${cluster}_nucleotide_sequences.fasta\n                        vsearch --cluster_fast \\${name}_\\${cluster}_nucleotide_sequences.fasta --id 0.2 --centroids \\${name}_\\${cluster}_centroids.fasta\n                        grep \">\" \\${name}_\\${cluster}_centroids.fasta >> \\${name}_\\${cluster}_tmp_centroids.list\n                        for y in \\$( cat \\${name}_\\${cluster}_tmp_centroids.list );do\n                            echo \">\\${cluster}_type\"\\$u\"\" >> \\${name}_\\${cluster}_tmp_centroid.newheaders\n                            u=\\$(( \\${u}+1 ))\n                        done\n                        u=1\n                        ./rename_seq.py \\${name}_\\${cluster}_centroids.fasta \\${name}_\\${cluster}_tmp_centroid.newheaders \\${cluster}_types_labeled.fasta\n                    done\n                    cat *_types_labeled.fasta >> ${params.projtag}_nucleotide_pcASV\\${id}_noTaxonomy.fasta\n                    grep -w \"*\" ${params.projtag}_pcASV\\${id}.clstr | awk '{print \\$3}' | awk -F \".\" '{print \\$1}' >tmphead.list\n                    grep -w \"*\" ${params.projtag}_pcASV\\${id}.clstr | awk '{print \\$2}' | awk -F \",\" '{print \\$1}' >tmplen.list\n                    paste -d\",\" temporaryclusters.list tmphead.list >tmp.info.csv\n                    grep \">\" ${params.projtag}_pcASV\\${id}.fasta >lala.list\n                    j=1\n                    for x in \\$(cat lala.list);do\n                        echo \">${params.projtag}_pcASV\\${j}\" >>${params.projtag}_aminoheaders.list\n                        echo \"\\${x},>${params.projtag}_pcASV\\${j}\" >>tmpaminotype.info.csv\n                        j=\\$(( \\${j}+1 ))\n                    done\n                    rm lala.list\n                    awk -F \",\" '{print \\$2}' tmp.info.csv >>tmporder.list\n                    for x in \\$(cat tmporder.list);do\n                        grep -w \"\\$x\" tmpaminotype.info.csv | awk -F \",\" '{print \\$2}' >>tmpder.list\n                    done\n                    paste -d \",\" temporaryclusters.list tmplen.list tmphead.list tmpder.list >${params.projtag}_pcASVCluster\\${id}_summary.csv\n                    ./rename_seq.py ${params.projtag}_pcASV\\${id}.fasta ${params.projtag}_aminoheaders.list ${params.projtag}_aminoacid_pcASV\\${id}_noTaxonomy.fasta\n                    stats.sh in=${params.projtag}_aminoacid_pcASV\\${id}_noTaxonomy.fasta gc=${params.projtag}_pcASV\\${id}_aminoacid_clustered.gc gcformat=4 overwrite=true\n                    stats.sh in=${params.projtag}_nucleotide_pcASV\\${id}_noTaxonomy.fasta gc=${params.projtag}_pcASV\\${id}_nucleotide_clustered.gc gcformat=4 overwrite=true\n                    awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)<\"${params.minAA}\"{print \">\"\\$0}' ${fasta} >${params.projtag}_pcASV\\${id}_problematic_translations.fasta\n                    if [ `wc -l ${params.projtag}_pcASV\\${id}_problematic_translations.fasta | awk '{print \\$1}'` -gt 1 ];then\n                        grep \">\" ${params.projtag}_pcASV\\${id}_problematic_translations.fasta | awk -F \">\" '{print \\$2}' > problem_tmp.list\n                        seqtk subseq ${asvs} problem_tmp.list > ${params.projtag}_pcASV\\${id}_problematic_nucleotides.fasta\n                    else\n                       rm ${params.projtag}_pcASV\\${id}_problematic_translations.fasta\n                    fi\n                    rm *.list\n                    rm Cluster*\n                    rm *types*\n                    rm *tmp*\n                    rm ${params.projtag}_pcASV\\${id}.fast*\n                done\n                for x in *aminoacid*noTaxonomy.fasta;do\n                    id=\\$( echo \\$x | awk -F \"_noTax\" '{print \\$1}' | awk -F \"pcASV\" '{print \\$2}')\n                    numb=\\$( grep -c \">\" \\$x)\n                    echo \"\\${id},\\${numb}\" >> number_per_percentage_protz.csv\n                done\n                yesirr=\\$( wc -l number_per_percentage_protz.csv | awk '{print \\$1}')\n                tail -\\$(( \\${yesirr}-1 )) number_per_percentage_protz.csv > number_per_percentage_prot.csv\n                head -1 number_per_percentage_protz.csv >> number_per_percentage_prot.csv\n                rm number_per_percentage_protz.csv\n                clustalo -i *aminoacid_pcASV1.0_noTaxonomy.fasta --distmat-out=${params.projtag}_distance.matrix --full --force --threads=${task.cpus}\n                cat ${params.projtag}_distance.matrix | tr \" \" \",\"  | grep \",\" >${params.projtag}_AminoType_PairwiseDistance.matrix\n                rm ${params.projtag}_distance.matrix\n                \"\"\"\n        }",
        "nb_lignes_process": 108,
        "string_script": "                \"\"\"\n                set +e\n                cp ${params.vampdir}/bin/rename_seq.py .\n                for id in `echo ${params.datacheckaaIDlist} | tr \",\" \"\\\\n\"`;do\n                    if [ \\${id} == \".55\" ];then\n                        word=3\n                    elif [ \\${id} == \".65\" ];then\n                        word=4\n                    else\n                        word=5\n                    fi\n                    awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)>=\"${params.minAA}\"{print \">\"\\$0}' ${fasta} > ${params.projtag}_filtered_proteins.fasta\n                    cd-hit -i ${params.projtag}_filtered_proteins.fasta -n \\${word} -c \\${id} -o ${params.projtag}_pcASV\\${id}.fasta\n                    sed 's/>Cluster />Cluster_/g' ${params.projtag}_pcASV\\${id}.fasta.clstr >${params.projtag}_pcASV\\${id}.clstr\n                    grep \">Cluster_\" ${params.projtag}_pcASV\\${id}.clstr >temporaryclusters.list\n                    y=\\$(grep -c \">Cluster_\" ${params.projtag}_pcASV\\${id}.clstr)\n                    echo \">Cluster_\"\\${y}\"\" >> ${params.projtag}_pcASV\\${id}.clstr\n                    t=1\n                    b=1\n                    for x in \\$(cat temporaryclusters.list);do\n                        echo \"Extracting \\$x\"\n                        name=\"\\$( echo \\$x | awk -F \">\" '{print \\$2}')\"\n                        clust=\"pcASV\"\\${t}\"\"\n                        echo \"\\${name}\"\n                        awk '/^>'\\${name}'\\$/,/^>Cluster_'\\${b}'\\$/' ${params.projtag}_pcASV\\${id}.clstr > \"\\${name}\"_\"\\${clust}\"_tmp.list\n                        t=\\$(( \\${t}+1 ))\n                        b=\\$(( \\${b}+1 ))\n                    done\n                    ls *_tmp.list\n                    u=1\n                    for x in *_tmp.list;do\n                        name=\"\\$(echo \\$x | awk -F \"_p\" '{print \\$1}')\"\n                        echo \"\\${name}\"\n                        cluster=\"\\$(echo \\$x | awk -F \"_\" '{print \\$3}')\"\n                        echo \"\\${cluster}\"\n                        grep \"ASV\" \\$x | awk -F \", \" '{print \\$2}' | awk -F \"_\" '{print \\$1}' | awk -F \">\" '{print \\$2}' > \\${name}_\\${cluster}_seqs_tmps.list\n                        seqtk subseq ${asvs} \\${name}_\\${cluster}_seqs_tmps.list > \\${name}_\\${cluster}_nucleotide_sequences.fasta\n                        vsearch --cluster_fast \\${name}_\\${cluster}_nucleotide_sequences.fasta --id 0.2 --centroids \\${name}_\\${cluster}_centroids.fasta\n                        grep \">\" \\${name}_\\${cluster}_centroids.fasta >> \\${name}_\\${cluster}_tmp_centroids.list\n                        for y in \\$( cat \\${name}_\\${cluster}_tmp_centroids.list );do\n                            echo \">\\${cluster}_type\"\\$u\"\" >> \\${name}_\\${cluster}_tmp_centroid.newheaders\n                            u=\\$(( \\${u}+1 ))\n                        done\n                        u=1\n                        ./rename_seq.py \\${name}_\\${cluster}_centroids.fasta \\${name}_\\${cluster}_tmp_centroid.newheaders \\${cluster}_types_labeled.fasta\n                    done\n                    cat *_types_labeled.fasta >> ${params.projtag}_nucleotide_pcASV\\${id}_noTaxonomy.fasta\n                    grep -w \"*\" ${params.projtag}_pcASV\\${id}.clstr | awk '{print \\$3}' | awk -F \".\" '{print \\$1}' >tmphead.list\n                    grep -w \"*\" ${params.projtag}_pcASV\\${id}.clstr | awk '{print \\$2}' | awk -F \",\" '{print \\$1}' >tmplen.list\n                    paste -d\",\" temporaryclusters.list tmphead.list >tmp.info.csv\n                    grep \">\" ${params.projtag}_pcASV\\${id}.fasta >lala.list\n                    j=1\n                    for x in \\$(cat lala.list);do\n                        echo \">${params.projtag}_pcASV\\${j}\" >>${params.projtag}_aminoheaders.list\n                        echo \"\\${x},>${params.projtag}_pcASV\\${j}\" >>tmpaminotype.info.csv\n                        j=\\$(( \\${j}+1 ))\n                    done\n                    rm lala.list\n                    awk -F \",\" '{print \\$2}' tmp.info.csv >>tmporder.list\n                    for x in \\$(cat tmporder.list);do\n                        grep -w \"\\$x\" tmpaminotype.info.csv | awk -F \",\" '{print \\$2}' >>tmpder.list\n                    done\n                    paste -d \",\" temporaryclusters.list tmplen.list tmphead.list tmpder.list >${params.projtag}_pcASVCluster\\${id}_summary.csv\n                    ./rename_seq.py ${params.projtag}_pcASV\\${id}.fasta ${params.projtag}_aminoheaders.list ${params.projtag}_aminoacid_pcASV\\${id}_noTaxonomy.fasta\n                    stats.sh in=${params.projtag}_aminoacid_pcASV\\${id}_noTaxonomy.fasta gc=${params.projtag}_pcASV\\${id}_aminoacid_clustered.gc gcformat=4 overwrite=true\n                    stats.sh in=${params.projtag}_nucleotide_pcASV\\${id}_noTaxonomy.fasta gc=${params.projtag}_pcASV\\${id}_nucleotide_clustered.gc gcformat=4 overwrite=true\n                    awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)<\"${params.minAA}\"{print \">\"\\$0}' ${fasta} >${params.projtag}_pcASV\\${id}_problematic_translations.fasta\n                    if [ `wc -l ${params.projtag}_pcASV\\${id}_problematic_translations.fasta | awk '{print \\$1}'` -gt 1 ];then\n                        grep \">\" ${params.projtag}_pcASV\\${id}_problematic_translations.fasta | awk -F \">\" '{print \\$2}' > problem_tmp.list\n                        seqtk subseq ${asvs} problem_tmp.list > ${params.projtag}_pcASV\\${id}_problematic_nucleotides.fasta\n                    else\n                       rm ${params.projtag}_pcASV\\${id}_problematic_translations.fasta\n                    fi\n                    rm *.list\n                    rm Cluster*\n                    rm *types*\n                    rm *tmp*\n                    rm ${params.projtag}_pcASV\\${id}.fast*\n                done\n                for x in *aminoacid*noTaxonomy.fasta;do\n                    id=\\$( echo \\$x | awk -F \"_noTax\" '{print \\$1}' | awk -F \"pcASV\" '{print \\$2}')\n                    numb=\\$( grep -c \">\" \\$x)\n                    echo \"\\${id},\\${numb}\" >> number_per_percentage_protz.csv\n                done\n                yesirr=\\$( wc -l number_per_percentage_protz.csv | awk '{print \\$1}')\n                tail -\\$(( \\${yesirr}-1 )) number_per_percentage_protz.csv > number_per_percentage_prot.csv\n                head -1 number_per_percentage_protz.csv >> number_per_percentage_prot.csv\n                rm number_per_percentage_protz.csv\n                clustalo -i *aminoacid_pcASV1.0_noTaxonomy.fasta --distmat-out=${params.projtag}_distance.matrix --full --force --threads=${task.cpus}\n                cat ${params.projtag}_distance.matrix | tr \" \" \",\"  | grep \",\" >${params.projtag}_AminoType_PairwiseDistance.matrix\n                rm ${params.projtag}_distance.matrix\n                \"\"\"",
        "nb_lignes_script": 91,
        "language_script": "bash",
        "tools": [
            "cd-hit",
            "Clusterv",
            "seqtk",
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/cd-hit",
            "https://bio.tools/clusterv",
            "https://bio.tools/seqtk",
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "cd-hit",
                "uri": "https://bio.tools/cd-hit",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "Cluster a nucleotide dataset into representative sequences.",
                "homepage": "https://github.com/weizhongli/cdhit"
            },
            {
                "name": "Clusterv",
                "uri": "https://bio.tools/clusterv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The clusterv R package implements a set of functions to assess the reliability of clusters discovered by clustering algorithms. This library is tailored to the analysis of high dimensional data and in particular it is conceived for the analysis of the reliability of clusters discovered using DNA microarray data.",
                "homepage": "http://homes.di.unimi.it/~valenti/SW/clusterv/"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            },
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "clustering_aa",
            "asvfastaforaaclust"
        ],
        "nb_inputs": 2,
        "outputs": [
            "number_per_percent_prot_plot",
            "amino_med",
            "aminopdm"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Aminoacid\", mode: \"copy\", overwrite: true, pattern: '*{.csv}'"
        ],
        "when": "",
        "stub": ""
    },
    "ASV_Shannon_Entropy_Analysis": {
        "name_process": "ASV_Shannon_Entropy_Analysis",
        "string_process": " process ASV_Shannon_Entropy_Analysis {\n\n                  label 'norm_cpus'\n\n                  publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Nucleotide/ShannonEntropy\", mode: \"copy\", overwrite: true\n\n                  input:\n                      file(asvs) from asv_med\n\n                  output:\n\n                      file(\"*_ASV_entropy_breakdown.csv\") into asv_entro_csv\n                      file(\"*Aligned_informativeonly.fasta-ENTROPY\") into asv_entropy\n                      file(\"*ASV*\") into entrop\n\n                  script:\n                  \"\"\"\n                    set +e\n                    #alignment\n                    ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out ${params.projtag}_ASVs_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_ASVs_muscleAlign.fasta -out ${params.projtag}_ASVs_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_ASVs_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_ASVs_muscleAligned.fasta\n                    mv ${params.projtag}_ASVs_muscleAligned.fasta-TRIMMED ./${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #entopy analysis\n                    entropy-analysis ${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #summarize entropy peaks\n                    awk '{print \\$2}' ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY >> tmp_value.list\n                    for x in \\$(cat tmp_value.list)\n                    do      echo \"\\$x\"\n                            if [[ \\$(echo \"\\$x > 0.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 2.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-2.0-.list\n                            fi\n                    done\n                    echo \"Entropy,Peaks_above\" >> ${params.projtag}_ASV_entropy_breakdown.csv\n                    for z in above*.list;\n                    do      entrop=\\$(echo \\$z | awk -F \"-\" '{print \\$2}')\n                            echo \"\"\\$entrop\", \"\\$(wc -l \\$z | awk '{print \\$1}')\"\" >> ${params.projtag}_ASV_entropy_breakdown.csv\n                    done\n                    rm above*\n                    mv ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY ./tmp2.tsv\n                    cat tmp2.tsv | tr \"\\\\t\" \",\" > tmp.csv\n                    rm tmp2.tsv\n                    echo \"Base_position,Shannons_Entropy\" >> ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY\n                    cat tmp.csv >> ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY\n                    rm tmp.csv\n\n                  \"\"\"\n\n                }",
        "nb_lignes_process": 109,
        "string_script": "                  \"\"\"\n                    set +e\n                    #alignment\n                    ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out ${params.projtag}_ASVs_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_ASVs_muscleAlign.fasta -out ${params.projtag}_ASVs_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_ASVs_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_ASVs_muscleAligned.fasta\n                    mv ${params.projtag}_ASVs_muscleAligned.fasta-TRIMMED ./${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #entopy analysis\n                    entropy-analysis ${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #summarize entropy peaks\n                    awk '{print \\$2}' ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY >> tmp_value.list\n                    for x in \\$(cat tmp_value.list)\n                    do      echo \"\\$x\"\n                            if [[ \\$(echo \"\\$x > 0.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 2.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-2.0-.list\n                            fi\n                    done\n                    echo \"Entropy,Peaks_above\" >> ${params.projtag}_ASV_entropy_breakdown.csv\n                    for z in above*.list;\n                    do      entrop=\\$(echo \\$z | awk -F \"-\" '{print \\$2}')\n                            echo \"\"\\$entrop\", \"\\$(wc -l \\$z | awk '{print \\$1}')\"\" >> ${params.projtag}_ASV_entropy_breakdown.csv\n                    done\n                    rm above*\n                    mv ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY ./tmp2.tsv\n                    cat tmp2.tsv | tr \"\\\\t\" \",\" > tmp.csv\n                    rm tmp2.tsv\n                    echo \"Base_position,Shannons_Entropy\" >> ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY\n                    cat tmp.csv >> ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY\n                    rm tmp.csv\n\n                  \"\"\"",
        "nb_lignes_script": 92,
        "language_script": "bash",
        "tools": [
            "trimAl"
        ],
        "tools_url": [
            "https://bio.tools/trimal"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            }
        ],
        "inputs": [
            "asv_med"
        ],
        "nb_inputs": 1,
        "outputs": [
            "asv_entro_csv",
            "asv_entropy",
            "entrop"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Nucleotide/ShannonEntropy\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_Shannon_Entropy_Analysis": {
        "name_process": "AminoType_Shannon_Entropy_Analysis",
        "string_process": " process AminoType_Shannon_Entropy_Analysis {\n\n                  label 'norm_cpus'\n\n                  publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Aminoacid/ShannonEntropy\", mode: \"copy\", overwrite: true, pattern: '*{.csv}'\n\n                  input:\n                      file(aminos) from amino_med\n\n                  output:\n                      file(\"*AminoType_entropy_breakdown.csv\") into amino_entro_csv\n                      file (\"*Aligned_informativeonly.fasta-ENTROPY\") into amino_entropy\n                      file(\"*AminoTypes*\") into aminos\n\n                  script:\n                    \"\"\"\n                    #alignment\n                    if [[ \\$(grep -c \">\" ${aminos}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                    ${tools}/muscle5.0.1278_linux64 -\\${algo} ${aminos} -out ${params.projtag}_AminoTypes_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_AminoTypes_muscleAlign.fasta -out ${params.projtag}_AminoTypes_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_AminoTypes_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_AminoTypes_muscleAligned.fasta\n                    mv ${params.projtag}_AminoTypes_muscleAligned.fasta-TRIMMED ./${params.projtag}_AminoTypes_Aligned_informativeonly.fasta\n                    #entropy analysis\n                    entropy-analysis ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta --amino-acid-sequences\n                    #summarize entropy peaks\n                    awk '{print \\$2}' ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY >> tmp_value.list\n                    for x in \\$(cat tmp_value.list)\n                    do      echo \"\\$x\"\n                            if [[ \\$(echo \"\\$x > 0.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 2.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-2.0-.list\n                            fi\n                    done\n                    echo \"Entropy,Peaks_above\" >> ${params.projtag}_AminoType_entropy_breakdown.csv\n                    for z in above*.list;\n                    do      entrop=\\$(echo \\$z | awk -F \"-\" '{print \\$2}')\n                            echo \"\"\\$entrop\", \"\\$(wc -l \\$z | awk '{print \\$1}')\"\" >> ${params.projtag}_AminoType_entropy_breakdown.csv\n                    done\n                    rm above*\n                    mv ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY ./tmp2.tsv\n                    cat tmp2.tsv | tr \"\\t\" \",\" > tmp.csv\n                    rm tmp2.tsv\n                    echo \"Base_position,Shannons_Entropy\" >> ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY\n                    cat tmp.csv >> ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY\n                    rm tmp.csv\n                    \"\"\"\n                }",
        "nb_lignes_process": 106,
        "string_script": "                    \"\"\"\n                    #alignment\n                    if [[ \\$(grep -c \">\" ${aminos}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                    ${tools}/muscle5.0.1278_linux64 -\\${algo} ${aminos} -out ${params.projtag}_AminoTypes_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_AminoTypes_muscleAlign.fasta -out ${params.projtag}_AminoTypes_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_AminoTypes_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_AminoTypes_muscleAligned.fasta\n                    mv ${params.projtag}_AminoTypes_muscleAligned.fasta-TRIMMED ./${params.projtag}_AminoTypes_Aligned_informativeonly.fasta\n                    #entropy analysis\n                    entropy-analysis ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta --amino-acid-sequences\n                    #summarize entropy peaks\n                    awk '{print \\$2}' ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY >> tmp_value.list\n                    for x in \\$(cat tmp_value.list)\n                    do      echo \"\\$x\"\n                            if [[ \\$(echo \"\\$x > 0.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 0.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-0.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.0-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.1\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.1-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.2\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.2-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.3\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.3-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.4\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.4-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.5\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.5-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.6\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.6-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.7\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.7-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.8\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.8-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 1.9\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-1.9-.list\n                            fi\n                            if [[ \\$(echo \"\\$x > 2.0\"|bc -l) -eq 1 ]];\n                            then    echo dope >> above-2.0-.list\n                            fi\n                    done\n                    echo \"Entropy,Peaks_above\" >> ${params.projtag}_AminoType_entropy_breakdown.csv\n                    for z in above*.list;\n                    do      entrop=\\$(echo \\$z | awk -F \"-\" '{print \\$2}')\n                            echo \"\"\\$entrop\", \"\\$(wc -l \\$z | awk '{print \\$1}')\"\" >> ${params.projtag}_AminoType_entropy_breakdown.csv\n                    done\n                    rm above*\n                    mv ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY ./tmp2.tsv\n                    cat tmp2.tsv | tr \"\\t\" \",\" > tmp.csv\n                    rm tmp2.tsv\n                    echo \"Base_position,Shannons_Entropy\" >> ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY\n                    cat tmp.csv >> ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY\n                    rm tmp.csv\n                    \"\"\"",
        "nb_lignes_script": 91,
        "language_script": "bash",
        "tools": [
            "trimAl"
        ],
        "tools_url": [
            "https://bio.tools/trimal"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            }
        ],
        "inputs": [
            "amino_med"
        ],
        "nb_inputs": 1,
        "outputs": [
            "amino_entro_csv",
            "amino_entropy",
            "aminos"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/DataCheck/ClusteringTest/Aminoacid/ShannonEntropy\", mode: \"copy\", overwrite: true, pattern: '*{.csv}'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_csv_DC": {
        "name_process": "combine_csv_DC",
        "string_process": " process combine_csv_DC {\n\n                input:\n                    file(csv) from fastp_csv_in1\n                        .collect()\n\n                output:\n                    file(\"final_reads_stats.csv\") into fastp_csv_dc\n\n                script:\n                    \"\"\"\n                    cat ${csv} >all_reads_stats.csv\n                    head -n1 all_reads_stats.csv >tmp.names.csv\n                    cat all_reads_stats.csv | grep -v \"\"Sample,Total_\"\" >tmp.reads.stats.csv\n                    cat tmp.names.csv tmp.reads.stats.csv >final_reads_stats.csv\n                    rm tmp.names.csv tmp.reads.stats.csv\n                    \"\"\"\n\n            }",
        "nb_lignes_process": 17,
        "string_script": "                    \"\"\"\n                    cat ${csv} >all_reads_stats.csv\n                    head -n1 all_reads_stats.csv >tmp.names.csv\n                    cat all_reads_stats.csv | grep -v \"\"Sample,Total_\"\" >tmp.reads.stats.csv\n                    cat tmp.names.csv tmp.reads.stats.csv >final_reads_stats.csv\n                    rm tmp.names.csv tmp.reads.stats.csv\n                    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastp_csv_in1"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastp_csv_dc"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "skip_combine_csv_DC": {
        "name_process": "skip_combine_csv_DC",
        "string_process": " process skip_combine_csv_DC {\n                output:\n                    file(\"filter_reads.txt\") into fastp_csv_dc\n\n                script:\n                    \"\"\"\n                    echo \"Read processing steps skipped.\" >filter_reads.txt\n                    \"\"\"\n            }",
        "nb_lignes_process": 7,
        "string_script": "                    \"\"\"\n                    echo \"Read processing steps skipped.\" >filter_reads.txt\n                    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "fastp_csv_dc"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Report_DataCheck": {
        "name_process": "Report_DataCheck",
        "string_process": " process Report_DataCheck {\n\n            label 'norm_cpus'\n\n            publishDir \"${params.workingdir}/${params.outdir}/DataCheck/Report\", mode: \"copy\", overwrite: true, pattern: '*.{html}'\n\n            input:\n                file(files) from report_dc_in\n                    .collect()\n\n            output:\n                file(\"*.html\") into datacheckreport\n\n            script:\n                \"\"\"\n                cp ${params.vampdir}/bin/vAMPirus_DC_Report.Rmd .\n                cp ${params.vampdir}/example_data/conf/vamplogo.png .\n                Rscript -e \"rmarkdown::render('vAMPirus_DC_Report.Rmd',output_file='${params.projtag}_DataCheck_Report.html')\" ${params.projtag} \\\n                ${params.skipReadProcessing} \\\n                ${params.skipMerging} \\\n                ${params.skipAdapterRemoval} \\\n                ${params.asvMED} \\\n                ${params.aminoMED}\n                \"\"\"\n        }",
        "nb_lignes_process": 23,
        "string_script": "                \"\"\"\n                cp ${params.vampdir}/bin/vAMPirus_DC_Report.Rmd .\n                cp ${params.vampdir}/example_data/conf/vamplogo.png .\n                Rscript -e \"rmarkdown::render('vAMPirus_DC_Report.Rmd',output_file='${params.projtag}_DataCheck_Report.html')\" ${params.projtag} \\\n                ${params.skipReadProcessing} \\\n                ${params.skipMerging} \\\n                ${params.skipAdapterRemoval} \\\n                ${params.asvMED} \\\n                ${params.aminoMED}\n                \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "report_dc_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "datacheckreport"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/DataCheck/Report\", mode: \"copy\", overwrite: true, pattern: '*.{html}'"
        ],
        "when": "",
        "stub": ""
    },
    "NucleotideBased_ASV_clustering": {
        "name_process": "NucleotideBased_ASV_clustering",
        "string_process": " process NucleotideBased_ASV_clustering {\n\n                label 'norm_cpus'\n\n                tag \"${mtag}\"\n\n                publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/ncASV\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.fasta'\n\n                input:\n                    each x from 1..nnuc\n                    file(fasta) from asv_file_for_ncasvs\n\n                output:\n                    tuple nid, file(\"*_ncASV*.fasta\") into ( nuclFastas_forphylogeny_ncasv, nuclFastas_forDiamond_ncasv_ch, nuclFastas_forCounts_ncasv_ch, nuclFastas_forMatrix_ncasv_ch )\n\n                script:\n                    nid=slist.get(x-1)\n                    mtag=\"ID=\" + slist.get(x-1)\n                    \"\"\"\n                    vsearch --cluster_fast ${fasta} --centroids ${params.projtag}_ncASV${nid}.fasta --threads ${task.cpus} --relabel ncASV --id .${nid}\n                    \"\"\"\n            }",
        "nb_lignes_process": 20,
        "string_script": "                    nid=slist.get(x-1)\n                    mtag=\"ID=\" + slist.get(x-1)\n                    \"\"\"\n                    vsearch --cluster_fast ${fasta} --centroids ${params.projtag}_ncASV${nid}.fasta --threads ${task.cpus} --relabel ncASV --id .${nid}\n                    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "1",
            "asv_file_for_ncasvs"
        ],
        "nb_inputs": 2,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/ncASV\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.fasta'"
        ],
        "when": "",
        "stub": ""
    },
    "ncASV_Taxonomy_Inference_NCBI": {
        "name_process": "ncASV_Taxonomy_Inference_NCBI",
        "string_process": " process ncASV_Taxonomy_Inference_NCBI {        \n\n                    label 'high_cpus'\n\n                    tag \"${mtag}\"\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.{fasta,csv,tsv}'\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*ncASV*dmd.out'\n\n                    input:\n                        tuple nid, file(asvs) from nuclFastas_forDiamond_ncasv_ch\n\n                    output:\n                        file(\"*.fasta\") into tax_labeled_fasta_ncasv\n                        tuple file(\"*_phyloformat.csv\"), file(\"*summaryTable.tsv\"), file(\"*dmd.out\") into summary_diamond_ncasv\n                        tuple nid, file(\"*ncASV*summary_for_plot.csv\") into taxplot_ncasv\n                        tuple nid, file(\"*_quick_Taxbreakdown.csv\") into tax_table_ncasv\n                        tuple nid, file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_ncasv\n\n                    script:\n                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        virdb=${params.dbdir}/${params.dbname}\n                        if [[ ${params.measurement} == \"bitscore\" ]]\n                        then    measure=\"--min-score ${params.bitscore}\"\n                        elif    [[ ${params.measurement} == \"evalue\" ]]\n                        then    measure=\"-e ${params.evalue}\"\n                        else    measure=\"--min-score ${params.bitscore}\"\n                        fi\n                        grep \">\" \\${virdb} > headers.list\n                        headers=\"headers.list\"\n                        name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                        else   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                        fi\n                        echo \"Preparing lists to generate summary .csv's\"\n                        echo \"[Best hit accession number]\" > access.list\n                        echo \"[e-value]\" > evalue.list\n                        echo \"[Bitscore]\" > bit.list\n                        echo \"[Percent ID (aa)]\" > pid.list\n                        echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                        echo \"[Gene]\" > \"\\$name\"_genes.list\n                        echo \"[ncASV#]\" > otu.list\n                        echo \"[Sequence length]\" > length.list\n                        grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                        if [[ ${params.lca} == \"T\" ]]\n                        then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        else\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        fi\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                        fi\n                        echo \"extracting genes and names\"\n                        touch new_\"\\$name\"_asvnames.txt\n                        for s in \\$(cat seqids.lst);do\n                            echo \"Checking for \\$s hit in diamond output\"\n                            if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                        echo \"Yep, there was a hit for \\$s\"\n                                        echo \"Extracting the information now:\"\n                                        acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"\\$acc\" >> access.list\n                                        line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                        echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                        echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                        echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                        echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                        echo \"Extracting virus and gene ID for \\$s now\"\n                                        gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                        echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                        virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                        echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                        echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                      lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                      echo \"\\$lcla\" >> lca_classification.list\n                                                else  echo \"Viruses\" >> lca_classification.list\n                                                fi\n                                        fi\n                                        if [[ ${params.ncbitax} == \"true\" ]]\n                                        then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                            else\n                                        echo \"Ugh, there was no hit for \\$s ..\"\n                                        echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"NO_HIT\" >> access.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                        echo \"NO_HIT\" >> evalue.list\n                                        echo \"NO_HIT\" >> bit.list\n                                        echo \"NO_HIT\" >> pid.list\n                                        echo \"NO_HIT\" >> length.list\n                                        virus=\"NO\"\n                                        gene=\"HIT\"\n                                        echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    echo \"N/A\" >> lca_classification.list\n                                        fi\n                                        if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                        then  echo \"N/A\" >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                           fi\n                        done\n                        echo \"Now editing \"\\$name\" fasta headers\"\n                        ###### rename_seq.py\n                        ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                        awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                        echo \"[Sequence header]\" > newnames.list\n                        cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                        touch sequence.list\n                        echo \"     \" > sequence.list\n                        grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                        rm \"\\$name\"_tmpssasv.fasta\n                        if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        else\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                        fi\n                        for x in *phyloformat.csv;do\n                            echo \"\\$x\"\n                            lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                            tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                            sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                            cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                            rm tmpcol.list tmp2col.list\n                        done\n                        awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                        rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                        \"\"\"\n                      }",
        "nb_lignes_process": 152,
        "string_script": "                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        virdb=${params.dbdir}/${params.dbname}\n                        if [[ ${params.measurement} == \"bitscore\" ]]\n                        then    measure=\"--min-score ${params.bitscore}\"\n                        elif    [[ ${params.measurement} == \"evalue\" ]]\n                        then    measure=\"-e ${params.evalue}\"\n                        else    measure=\"--min-score ${params.bitscore}\"\n                        fi\n                        grep \">\" \\${virdb} > headers.list\n                        headers=\"headers.list\"\n                        name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                        else   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                        fi\n                        echo \"Preparing lists to generate summary .csv's\"\n                        echo \"[Best hit accession number]\" > access.list\n                        echo \"[e-value]\" > evalue.list\n                        echo \"[Bitscore]\" > bit.list\n                        echo \"[Percent ID (aa)]\" > pid.list\n                        echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                        echo \"[Gene]\" > \"\\$name\"_genes.list\n                        echo \"[ncASV#]\" > otu.list\n                        echo \"[Sequence length]\" > length.list\n                        grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                        if [[ ${params.lca} == \"T\" ]]\n                        then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        else\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        fi\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                        fi\n                        echo \"extracting genes and names\"\n                        touch new_\"\\$name\"_asvnames.txt\n                        for s in \\$(cat seqids.lst);do\n                            echo \"Checking for \\$s hit in diamond output\"\n                            if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                        echo \"Yep, there was a hit for \\$s\"\n                                        echo \"Extracting the information now:\"\n                                        acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"\\$acc\" >> access.list\n                                        line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                        echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                        echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                        echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                        echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                        echo \"Extracting virus and gene ID for \\$s now\"\n                                        gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                        echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                        virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                        echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                        echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                      lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                      echo \"\\$lcla\" >> lca_classification.list\n                                                else  echo \"Viruses\" >> lca_classification.list\n                                                fi\n                                        fi\n                                        if [[ ${params.ncbitax} == \"true\" ]]\n                                        then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                            else\n                                        echo \"Ugh, there was no hit for \\$s ..\"\n                                        echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"NO_HIT\" >> access.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                        echo \"NO_HIT\" >> evalue.list\n                                        echo \"NO_HIT\" >> bit.list\n                                        echo \"NO_HIT\" >> pid.list\n                                        echo \"NO_HIT\" >> length.list\n                                        virus=\"NO\"\n                                        gene=\"HIT\"\n                                        echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    echo \"N/A\" >> lca_classification.list\n                                        fi\n                                        if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                        then  echo \"N/A\" >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                           fi\n                        done\n                        echo \"Now editing \"\\$name\" fasta headers\"\n                        ###### rename_seq.py\n                        ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                        awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                        echo \"[Sequence header]\" > newnames.list\n                        cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                        touch sequence.list\n                        echo \"     \" > sequence.list\n                        grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                        rm \"\\$name\"_tmpssasv.fasta\n                        if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        else\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                        fi\n                        for x in *phyloformat.csv;do\n                            echo \"\\$x\"\n                            lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                            tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                            sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                            cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                            rm tmpcol.list tmp2col.list\n                        done\n                        awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                        rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                        \"\"\"",
        "nb_lignes_script": 132,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nuclFastas_forDiamond_ncasv_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tax_labeled_fasta_ncasv",
            "summary_diamond_ncasv",
            "taxplot_ncasv",
            "tax_table_ncasv",
            "tax_nodCol_ncasv"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.{fasta,csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*ncASV*dmd.out'"
        ],
        "when": "",
        "stub": ""
    },
    "ncASV_Taxonomy_Inference_RVDB": {
        "name_process": "ncASV_Taxonomy_Inference_RVDB",
        "string_process": " process ncASV_Taxonomy_Inference_RVDB {        \n\n                  label 'high_cpus'\n\n                  tag \"${mtag}\"\n\n                  publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.{fasta,csv,tsv}'\n                  publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*ncASV*dmd.out'\n\n                  input:\n                      tuple nid, file(asvs) from nuclFastas_forDiamond_ncasv_ch\n\n                  output:\n                      file(\"*.fasta\") into tax_labeled_fasta_ncasv\n                      tuple file(\"*_phyloformat.csv\"), file(\"*summaryTable.tsv\"), file(\"*dmd.out\") into summary_diamond_ncasv\n                      tuple nid, file(\"*ncASV*summary_for_plot.csv\") into taxplot_ncasv\n                      tuple nid, file(\"*_quick_Taxbreakdown.csv\") into tax_table_ncasv\n                      tuple nid, file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_ncasv\n\n                  script:\n                      mtag=\"ID=\" + nid\n                      \"\"\"\n                      cp ${params.vampdir}/bin/rename_seq.py .\n                      virdb=${params.dbdir}/${params.dbname}\n                      if [[ ${params.measurement} == \"bitscore\" ]]\n                      then    measure=\"--min-score ${params.bitscore}\"\n                      elif    [[ ${params.measurement} == \"evalue\" ]]\n                      then    measure=\"-e ${params.evalue}\"\n                      else    measure=\"--min-score ${params.bitscore}\"\n                      fi\n                      grep \">\" \\${virdb} > headers.list\n                      headers=\"headers.list\"\n                      name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                      diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                      echo \"Preparing lists to generate summary .csv's\"\n                      echo \"[Best hit accession number]\" > access.list\n                      echo \"[e-value]\" > evalue.list\n                      echo \"[Bitscore]\" > bit.list\n                      echo \"[Percent ID (aa)]\" > pid.list\n                      echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                      echo \"[Gene]\" > \"\\$name\"_genes.list\n                      echo \"[ncASV#]\" > otu.list\n                      echo \"[Sequence length]\" > length.list\n                      grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                      if [[ ${params.lca} == \"T\" ]]\n                      then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                            echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                      else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                      fi\n                      echo \"extracting genes and names\"\n                      touch new_\"\\$name\"_asvnames.txt\n                      for s in \\$(cat seqids.lst);do\n                          echo \"Using RVDB headers.\"\n                          if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                              echo \"Yep, there was a hit for \\$s\"\n                              echo \"Extracting the information now:\"\n                              acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                              echo \"\\$s\" >> otu.list\n                              echo \"\\$acc\" >> access.list\n                              line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                              echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                              echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                              echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                              echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                              echo \"Extracting virus and gene ID for \\$s now\"\n                              gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                              echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                              virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                              echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                              echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                      then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                            lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                            echo \"\\$lcla\" >> lca_classification.list\n                                      else  echo \"Viruses\" >> lca_classification.list\n                                      fi\n                              fi\n                              echo \"\\$s done.\"\n                          else\n                              echo \"Ugh, there was no hit for \\$s ..\"\n                              echo \"We still love \\$s though and we will add it to the final fasta file\"\n                              echo \"\\$s\" >> otu.list\n                              echo \"NO_HIT\" >> access.list\n                              echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                              echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                              echo \"NO_HIT\" >> evalue.list\n                              echo \"NO_HIT\" >> bit.list\n                              echo \"NO_HIT\" >> pid.list\n                              echo \"NO_HIT\" >> length.list\n                              virus=\"NO\"\n                              gene=\"HIT\"\n                              echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then    echo \"N/A\" >> lca_classification.list\n                              fi\n                              echo \"\\$s done.\"\n                          fi\n                      echo \"Done with \\$s\"\n                      done\n                      echo \"Now editing \"\\$name\" fasta headers\"\n                      ###### rename_seq.py\n                      ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                      awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                      echo \"[Sequence header]\" > newnames.list\n                      cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                      touch sequence.list\n                      echo \"     \" > sequence.list\n                      grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                      rm \"\\$name\"_tmpssasv.fasta\n                      if [[ \"${params.lca}\" == \"T\" ]]\n                      then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                            paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                            paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                      else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                            paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                      fi\n                      for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                      done\n                      awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                      rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                      \"\"\"\n                }",
        "nb_lignes_process": 128,
        "string_script": "                      mtag=\"ID=\" + nid\n                      \"\"\"\n                      cp ${params.vampdir}/bin/rename_seq.py .\n                      virdb=${params.dbdir}/${params.dbname}\n                      if [[ ${params.measurement} == \"bitscore\" ]]\n                      then    measure=\"--min-score ${params.bitscore}\"\n                      elif    [[ ${params.measurement} == \"evalue\" ]]\n                      then    measure=\"-e ${params.evalue}\"\n                      else    measure=\"--min-score ${params.bitscore}\"\n                      fi\n                      grep \">\" \\${virdb} > headers.list\n                      headers=\"headers.list\"\n                      name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                      diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                      echo \"Preparing lists to generate summary .csv's\"\n                      echo \"[Best hit accession number]\" > access.list\n                      echo \"[e-value]\" > evalue.list\n                      echo \"[Bitscore]\" > bit.list\n                      echo \"[Percent ID (aa)]\" > pid.list\n                      echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                      echo \"[Gene]\" > \"\\$name\"_genes.list\n                      echo \"[ncASV#]\" > otu.list\n                      echo \"[Sequence length]\" > length.list\n                      grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                      if [[ ${params.lca} == \"T\" ]]\n                      then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                            echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                      else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                      fi\n                      echo \"extracting genes and names\"\n                      touch new_\"\\$name\"_asvnames.txt\n                      for s in \\$(cat seqids.lst);do\n                          echo \"Using RVDB headers.\"\n                          if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                              echo \"Yep, there was a hit for \\$s\"\n                              echo \"Extracting the information now:\"\n                              acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                              echo \"\\$s\" >> otu.list\n                              echo \"\\$acc\" >> access.list\n                              line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                              echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                              echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                              echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                              echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                              echo \"Extracting virus and gene ID for \\$s now\"\n                              gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                              echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                              virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                              echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                              echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                      then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                            lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                            echo \"\\$lcla\" >> lca_classification.list\n                                      else  echo \"Viruses\" >> lca_classification.list\n                                      fi\n                              fi\n                              echo \"\\$s done.\"\n                          else\n                              echo \"Ugh, there was no hit for \\$s ..\"\n                              echo \"We still love \\$s though and we will add it to the final fasta file\"\n                              echo \"\\$s\" >> otu.list\n                              echo \"NO_HIT\" >> access.list\n                              echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                              echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                              echo \"NO_HIT\" >> evalue.list\n                              echo \"NO_HIT\" >> bit.list\n                              echo \"NO_HIT\" >> pid.list\n                              echo \"NO_HIT\" >> length.list\n                              virus=\"NO\"\n                              gene=\"HIT\"\n                              echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then    echo \"N/A\" >> lca_classification.list\n                              fi\n                              echo \"\\$s done.\"\n                          fi\n                      echo \"Done with \\$s\"\n                      done\n                      echo \"Now editing \"\\$name\" fasta headers\"\n                      ###### rename_seq.py\n                      ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                      awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                      echo \"[Sequence header]\" > newnames.list\n                      cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                      touch sequence.list\n                      echo \"     \" > sequence.list\n                      grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                      rm \"\\$name\"_tmpssasv.fasta\n                      if [[ \"${params.lca}\" == \"T\" ]]\n                      then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                            paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                            paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                      else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                            paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                      fi\n                      for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                      done\n                      awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                      rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                      \"\"\"",
        "nb_lignes_script": 108,
        "language_script": "bash",
        "tools": [
            "Diamond"
        ],
        "tools_url": [
            "https://bio.tools/diamond"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            }
        ],
        "inputs": [
            "nuclFastas_forDiamond_ncasv_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tax_labeled_fasta_ncasv",
            "summary_diamond_ncasv",
            "taxplot_ncasv",
            "tax_table_ncasv",
            "tax_nodCol_ncasv"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.{fasta,csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*ncASV*dmd.out'"
        ],
        "when": "",
        "stub": ""
    },
    "skipncASVtaxonomy": {
        "name_process": "skipncASVtaxonomy",
        "string_process": " process skipncASVtaxonomy {\n\n                  input:\n                      tuple nid, file(asvs) from nuclFastas_forDiamond_ncasv_ch\n\n                  output:\n                      tuple nid, file(\"skipncASVtaxonomy1.txt\") into ( taxplot_ncasv )\n                      tuple nid, file(\"skipncASVtaxonomy2.txt\") into ( tax_table_ncasv )\n                      tuple nid, file(\"skipncASVtaxonomy3.txt\") into ( tax_nodCol_ncasv )\n\n                  script:\n                      \"\"\"\n                      echo \"Skipped\" >skipncASVtaxonomy1.txt\n                      echo \"Skipped\" >skipncASVtaxonomy2.txt\n                      echo \"Skipped\" >skipncASVtaxonomy3.txt\n                      \"\"\"\n              }",
        "nb_lignes_process": 15,
        "string_script": "                      \"\"\"\n                      echo \"Skipped\" >skipncASVtaxonomy1.txt\n                      echo \"Skipped\" >skipncASVtaxonomy2.txt\n                      echo \"Skipped\" >skipncASVtaxonomy3.txt\n                      \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nuclFastas_forDiamond_ncasv_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "",
            ""
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Generate_ncASV_Counts_Table": {
        "name_process": "Generate_ncASV_Counts_Table",
        "string_process": " process Generate_ncASV_Counts_Table {\n\n                label 'norm_cpus'\n\n                tag \"${mtag}\"\n\n                publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Counts\", mode: \"copy\", overwrite: true, pattern: '*_ASV*.{biome,csv}'\n                publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Counts\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.{biome,csv}'\n\n                input:\n                    tuple nid, file(notus) from nuclFastas_forCounts_ncasv_ch\n                    file(merged) from nuclCounts_mergedreads_ncasv_ch\n\n                output:\n                    tuple file(\"*_counts.csv\"), file(\"*_counts.biome\") into counts_vsearch_ncasv\n                    tuple nid, file(\"*ncASV*counts.csv\") into notu_counts_plots\n\n                script:\n                    mtag=\"ID=\" + nid\n                    \"\"\"\n                    name=\\$( echo ${notus} | awk -F \".fasta\" '{print \\$1}')\n                    vsearch --usearch_global ${merged} --db ${notus} --id .${nid} --threads ${task.cpus} --otutabout \\${name}_counts.txt --biomout \\${name}_counts.biome\n                    cat \\${name}_counts.txt | tr \"\\t\" \",\" >\\${name}_count.csv\n                    sed 's/#OTU ID/OTU_ID/g' \\${name}_count.csv >\\${name}_counts.csv\n                    rm \\${name}_count.csv\n                    \"\"\"\n            }",
        "nb_lignes_process": 25,
        "string_script": "                    mtag=\"ID=\" + nid\n                    \"\"\"\n                    name=\\$( echo ${notus} | awk -F \".fasta\" '{print \\$1}')\n                    vsearch --usearch_global ${merged} --db ${notus} --id .${nid} --threads ${task.cpus} --otutabout \\${name}_counts.txt --biomout \\${name}_counts.biome\n                    cat \\${name}_counts.txt | tr \"\\t\" \",\" >\\${name}_count.csv\n                    sed 's/#OTU ID/OTU_ID/g' \\${name}_count.csv >\\${name}_counts.csv\n                    rm \\${name}_count.csv\n                    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "nuclFastas_forCounts_ncasv_ch",
            "nuclCounts_mergedreads_ncasv_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "counts_vsearch_ncasv",
            "notu_counts_plots"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Counts\", mode: \"copy\", overwrite: true, pattern: '*_ASV*.{biome,csv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Counts\", mode: \"copy\", overwrite: true, pattern: '*ncASV*.{biome,csv}'"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_ncASV_Matrices": {
        "name_process": "Generate_ncASV_Matrices",
        "string_process": " process Generate_ncASV_Matrices {\n                label 'low_cpus'\n\n                tag \"${mtag}\"\n\n                publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Matrices\", mode: \"copy\", overwrite: true, pattern: '*ncASV*PercentID.matrix'\n\n                input:\n                    tuple nid, file(asvs) from nuclFastas_forMatrix_ncasv_ch\n\n                output:\n                    file(\"*.matrix\") into clustmatrices_ncasv\n                    tuple nid, file(\"*ncASV*PercentID.matrix\") into notu_heatmap\n\n                script:\n                    mtag=\"ID=\" + nid\n                    \"\"\"\n                    name=\\$( echo ${asvs}| awk -F \".fasta\" '{print \\$1}')\n                    clustalo -i ${asvs} --distmat-out=\\${name}_PairwiseDistance.matrix --full --force --threads=${task.cpus}\n                    clustalo -i ${asvs} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                    cat \\${name}_PercentIDq.matrix | tr \" \" \",\"  | grep \",\" >\\${name}_PercentID.matrix\n                    rm \\${name}_PercentIDq.matrix\n                    \"\"\"\n                }",
        "nb_lignes_process": 22,
        "string_script": "                    mtag=\"ID=\" + nid\n                    \"\"\"\n                    name=\\$( echo ${asvs}| awk -F \".fasta\" '{print \\$1}')\n                    clustalo -i ${asvs} --distmat-out=\\${name}_PairwiseDistance.matrix --full --force --threads=${task.cpus}\n                    clustalo -i ${asvs} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                    cat \\${name}_PercentIDq.matrix | tr \" \" \",\"  | grep \",\" >\\${name}_PercentID.matrix\n                    rm \\${name}_PercentIDq.matrix\n                    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nuclFastas_forMatrix_ncasv_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "clustmatrices_ncasv",
            "notu_heatmap"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Matrices\", mode: \"copy\", overwrite: true, pattern: '*ncASV*PercentID.matrix'"
        ],
        "when": "",
        "stub": ""
    },
    "ncASV_Phylogeny": {
        "name_process": "ncASV_Phylogeny",
        "string_process": " process ncASV_Phylogeny {\n\n                          label 'norm_cpus'\n\n                          tag \"${mtag}\"\n\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Phylogeny/Alignment\", mode: \"copy\", overwrite: true,  pattern: '*ncASV*aln.*'\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*ncASV*mt*'\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*ncASV*iq*'\n\n                          input:\n                              tuple nid, file(asvs) from nuclFastas_forphylogeny_ncasv\n\n                          output:\n                              tuple nid, file(\"*_aln.fasta\"), file(\"*_aln.html\"), file(\"*.tree\"), file(\"*.log\"), file(\"*iq*\"), file(\"*mt*\") into align_results_ncasv\n                              tuple nid, file(\"*iq.treefile\") into nucl_phyl_plot_ncasv\n\n                          script:\n                              mtag=\"ID=\" + nid\n                              \"\"\"\n                              pre=\\$(echo ${asvs} | awk -F \".fasta\" '{print \\$1}' )\n                              ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                              trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                              o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                              mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                              # Nucleotide_ModelTest\n                              modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d nt -s 203 --disable-checkpoint\n                              # Nucleotide_Phylogeny\n                              if [ \"${params.iqCustomnt}\" != \"\" ];then\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -t \\${pre}_mt.tree -T auto ${params.iqCustomnt}\n                              elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                  mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -t \\${pre}_mt.tree -nt auto -b ${params.boots}\n                              elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                  mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -t \\${pre}_mt.tree -nt auto -bb ${params.boots} -bnni\n                              elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -t \\${pre}_mt.tree -nt auto -b ${params.boots}\n                              elif [ \"${params.parametric}\" != \"false\" ];then\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -t \\${pre}_mt.tree -nt auto -bb ${params.boots} -bnni\n                              else\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -t \\${pre}_mt.tree -nt auto -bb ${params.boots} -bnni\n                              fi\n                              \"\"\"\n                      }",
        "nb_lignes_process": 43,
        "string_script": "                              mtag=\"ID=\" + nid\n                              \"\"\"\n                              pre=\\$(echo ${asvs} | awk -F \".fasta\" '{print \\$1}' )\n                              ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                              trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                              o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                              mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                              # Nucleotide_ModelTest\n                              modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d nt -s 203 --disable-checkpoint\n                              # Nucleotide_Phylogeny\n                              if [ \"${params.iqCustomnt}\" != \"\" ];then\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -t \\${pre}_mt.tree -T auto ${params.iqCustomnt}\n                              elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                  mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -t \\${pre}_mt.tree -nt auto -b ${params.boots}\n                              elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                  mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -t \\${pre}_mt.tree -nt auto -bb ${params.boots} -bnni\n                              elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -t \\${pre}_mt.tree -nt auto -b ${params.boots}\n                              elif [ \"${params.parametric}\" != \"false\" ];then\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -t \\${pre}_mt.tree -nt auto -bb ${params.boots} -bnni\n                              else\n                                  iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -t \\${pre}_mt.tree -nt auto -bb ${params.boots} -bnni\n                              fi\n                              \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "trimAl",
            "ModelTest-NG"
        ],
        "tools_url": [
            "https://bio.tools/trimal",
            "https://bio.tools/ModelTest-NG"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            },
            {
                "name": "ModelTest-NG",
                "uri": "https://bio.tools/ModelTest-NG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3293",
                            "term": "Phylogenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3316",
                            "term": "Computer science"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A new and scalable tool for the selection of DNA and protein evolutionary models | ModelTest-NG is a tool for selecting the best-fit model of evolution for DNA and protein alignments. ModelTest-NG supersedes jModelTest and ProtTest in one single tool, with graphical and command console interfaces",
                "homepage": "https://github.com/ddarriba/modeltest"
            }
        ],
        "inputs": [
            "nuclFastas_forphylogeny_ncasv"
        ],
        "nb_inputs": 1,
        "outputs": [
            "align_results_ncasv",
            "nucl_phyl_plot_ncasv"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*ncASV*aln.*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*ncASV*mt*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ncASV/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*ncASV*iq*'"
        ],
        "when": "",
        "stub": ""
    },
    "skipncASVphylogeny": {
        "name_process": "skipncASVphylogeny",
        "string_process": " process skipncASVphylogeny {\n                        input:\n                            tuple nid, file(asvs) from nuclFastas_forphylogeny_ncasv\n\n                        output:\n                            tuple nid, file(\"skipncASVphylogeny.txt\") into nucl_phyl_plot_ncasv\n\n                        script:\n                            \"\"\"\n                            echo \"Skipped\" >skipncASVphylogeny.txt\n                            \"\"\"\n                    }",
        "nb_lignes_process": 10,
        "string_script": "                            \"\"\"\n                            echo \"Skipped\" >skipncASVphylogeny.txt\n                            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nuclFastas_forphylogeny_ncasv"
        ],
        "nb_inputs": 1,
        "outputs": [
            "nucl_phyl_plot_ncasv"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "ASV_Taxonomy_Inference_NCBI": {
        "name_process": "ASV_Taxonomy_Inference_NCBI",
        "string_process": " process ASV_Taxonomy_Inference_NCBI {        \n\n                    label 'high_cpus'\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*_ASV*.{fasta,csv,tsv}'\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*_ASV*dmd.out'\n\n                    input:\n                        file(asvs) from nuclFastas_forDiamond_asv_ch\n\n                    output:\n                        file(\"*.fasta\") into tax_labeled_fasta_asv\n                        tuple file(\"*_phyloformat.csv\"), file(\"*summaryTable.tsv\"), file(\"*dmd.out\") into summary_diamond_asv\n                        file(\"*_ASV*_summary_for_plot.csv\") into taxplot_asv\n                        file(\"*_quick_Taxbreakdown.csv\") into tax_table_asv\n                        file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_asv\n\n                    script:\n                        \"\"\"\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        virdb=${params.dbdir}/${params.dbname}\n                        if [[ ${params.measurement} == \"bitscore\" ]]\n                        then    measure=\"--min-score ${params.bitscore}\"\n                        elif    [[ ${params.measurement} == \"evalue\" ]]\n                        then    measure=\"-e ${params.evalue}\"\n                        else    measure=\"--min-score ${params.bitscore}\"\n                        fi\n                        grep \">\" \\${virdb} > headers.list\n                        headers=\"headers.list\"\n                        name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                        else   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                        fi\n                        echo \"Preparing lists to generate summary .csv's\"\n                        echo \"[Best hit accession number]\" > access.list\n                        echo \"[e-value]\" > evalue.list\n                        echo \"[Bitscore]\" > bit.list\n                        echo \"[Percent ID (aa)]\" > pid.list\n                        echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                        echo \"[Gene]\" > \"\\$name\"_genes.list\n                        echo \"[ASV#]\" > otu.list\n                        echo \"[Sequence length]\" > length.list\n                        grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                        if [[ ${params.lca} == \"T\" ]]\n                        then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        else\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        fi\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                        fi\n                        echo \"extracting genes and names\"\n                        touch new_\"\\$name\"_asvnames.txt\n                        for s in \\$(cat seqids.lst);do\n                            echo \"Checking for \\$s hit in diamond output\"\n                            if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                        echo \"Yep, there was a hit for \\$s\"\n                                        echo \"Extracting the information now:\"\n                                        acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"\\$acc\" >> access.list\n                                        line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                        echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                        echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                        echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                        echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                        echo \"Extracting virus and gene ID for \\$s now\"\n                                        gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                        echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                        virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                        echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                        echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                      lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                      echo \"\\$lcla\" >> lca_classification.list\n                                                else  echo \"Viruses\" >> lca_classification.list\n                                                fi\n                                        fi\n                                        if [[ ${params.ncbitax} == \"true\" ]]\n                                        then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                            else\n                                        echo \"Ugh, there was no hit for \\$s ..\"\n                                        echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"NO_HIT\" >> access.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                        echo \"NO_HIT\" >> evalue.list\n                                        echo \"NO_HIT\" >> bit.list\n                                        echo \"NO_HIT\" >> pid.list\n                                        echo \"NO_HIT\" >> length.list\n                                        virus=\"NO\"\n                                        gene=\"HIT\"\n                                        echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    echo \"N/A\" >> lca_classification.list\n                                        fi\n                                        if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                        then  echo \"N/A\" >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                           fi\n                        done\n                        echo \"Now editing \"\\$name\" fasta headers\"\n                        ###### rename_seq.py\n                        ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                        awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                        echo \"[Sequence header]\" > newnames.list\n                        cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                        touch sequence.list\n                        echo \"     \" > sequence.list\n                        grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                        rm \"\\$name\"_tmpssasv.fasta\n                        if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        else\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                        fi\n                        for x in *phyloformat.csv;do\n                            echo \"\\$x\"\n                            lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                            tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                            sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                            cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                            rm tmpcol.list tmp2col.list\n                        done\n                        awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                        rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                        \"\"\"\n                      }",
        "nb_lignes_process": 149,
        "string_script": "                        \"\"\"\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        virdb=${params.dbdir}/${params.dbname}\n                        if [[ ${params.measurement} == \"bitscore\" ]]\n                        then    measure=\"--min-score ${params.bitscore}\"\n                        elif    [[ ${params.measurement} == \"evalue\" ]]\n                        then    measure=\"-e ${params.evalue}\"\n                        else    measure=\"--min-score ${params.bitscore}\"\n                        fi\n                        grep \">\" \\${virdb} > headers.list\n                        headers=\"headers.list\"\n                        name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                        else   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                        fi\n                        echo \"Preparing lists to generate summary .csv's\"\n                        echo \"[Best hit accession number]\" > access.list\n                        echo \"[e-value]\" > evalue.list\n                        echo \"[Bitscore]\" > bit.list\n                        echo \"[Percent ID (aa)]\" > pid.list\n                        echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                        echo \"[Gene]\" > \"\\$name\"_genes.list\n                        echo \"[ASV#]\" > otu.list\n                        echo \"[Sequence length]\" > length.list\n                        grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                        if [[ ${params.lca} == \"T\" ]]\n                        then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        else\n                              echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                        fi\n                        if [[ ${params.ncbitax} == \"true\" ]]\n                        then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                        fi\n                        echo \"extracting genes and names\"\n                        touch new_\"\\$name\"_asvnames.txt\n                        for s in \\$(cat seqids.lst);do\n                            echo \"Checking for \\$s hit in diamond output\"\n                            if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                        echo \"Yep, there was a hit for \\$s\"\n                                        echo \"Extracting the information now:\"\n                                        acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"\\$acc\" >> access.list\n                                        line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                        echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                        echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                        echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                        echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                        echo \"Extracting virus and gene ID for \\$s now\"\n                                        gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                        echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                        virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                        echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                        echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                      lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                      echo \"\\$lcla\" >> lca_classification.list\n                                                else  echo \"Viruses\" >> lca_classification.list\n                                                fi\n                                        fi\n                                        if [[ ${params.ncbitax} == \"true\" ]]\n                                        then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                            else\n                                        echo \"Ugh, there was no hit for \\$s ..\"\n                                        echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                        echo \"\\$s\" >> otu.list\n                                        echo \"NO_HIT\" >> access.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                        echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                        echo \"NO_HIT\" >> evalue.list\n                                        echo \"NO_HIT\" >> bit.list\n                                        echo \"NO_HIT\" >> pid.list\n                                        echo \"NO_HIT\" >> length.list\n                                        virus=\"NO\"\n                                        gene=\"HIT\"\n                                        echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                        if [[ \"${params.lca}\" == \"T\" ]]\n                                        then    echo \"N/A\" >> lca_classification.list\n                                        fi\n                                        if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                        then  echo \"N/A\" >> ncbi_classification.list\n                                        fi\n                                        echo \"\\$s done.\"\n                           fi\n                        done\n                        echo \"Now editing \"\\$name\" fasta headers\"\n                        ###### rename_seq.py\n                        ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                        awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                        echo \"[Sequence header]\" > newnames.list\n                        cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                        touch sequence.list\n                        echo \"     \" > sequence.list\n                        grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                        rm \"\\$name\"_tmpssasv.fasta\n                        if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                        then\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                        else\n                              paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                              paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                        fi\n                        for x in *phyloformat.csv;do\n                            echo \"\\$x\"\n                            lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                            tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                            sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                            cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                            rm tmpcol.list tmp2col.list\n                        done\n                        awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                        rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                        \"\"\"",
        "nb_lignes_script": 131,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nuclFastas_forDiamond_asv_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tax_labeled_fasta_asv",
            "summary_diamond_asv",
            "taxplot_asv",
            "tax_table_asv",
            "tax_nodCol_asv"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*_ASV*.{fasta,csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*_ASV*dmd.out'"
        ],
        "when": "",
        "stub": ""
    },
    "ASV_Taxonomy_Inference_RVDB": {
        "name_process": "ASV_Taxonomy_Inference_RVDB",
        "string_process": " process ASV_Taxonomy_Inference_RVDB {        \n\n                      label 'high_cpus'\n\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*_ASV*.{fasta,csv,tsv}'\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*_ASV*dmd.out'\n\n                      input:\n                          file(asvs) from nuclFastas_forDiamond_asv_ch\n\n                      output:\n                          file(\"*.fasta\") into tax_labeled_fasta_asv\n                          tuple file(\"*_phyloformat.csv\"), file(\"*summaryTable.tsv\"), file(\"*dmd.out\") into summary_diamond_asv\n                          file(\"*_ASV*_summary_for_plot.csv\") into taxplot_asv\n                          file(\"*_quick_Taxbreakdown.csv\") into tax_table_asv\n                          file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_asv\n\n                      script:\n                          \"\"\"\n                          cp ${params.vampdir}/bin/rename_seq.py .\n                          virdb=${params.dbdir}/${params.dbname}\n                          grep \">\" \\${virdb} > headers.list\n                          if [[ ${params.measurement} == \"bitscore\" ]]\n                          then    measure=\"--min-score ${params.bitscore}\"\n                          elif    [[ ${params.measurement} == \"evalue\" ]]\n                          then    measure=\"-e ${params.evalue}\"\n                          else    measure=\"--min-score ${params.bitscore}\"\n                          fi\n                          headers=\"headers.list\"\n                          name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                          diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                          echo \"Preparing lists to generate summary .csv's\"\n                          echo \"[Best hit accession number]\" > access.list\n                          echo \"[e-value]\" > evalue.list\n                          echo \"[Bitscore]\" > bit.list\n                          echo \"[Percent ID (aa)]\" > pid.list\n                          echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                          echo \"[Gene]\" > \"\\$name\"_genes.list\n                          echo \"[ASV#]\" > otu.list\n                          echo \"[Sequence length]\" > length.list\n                          grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                          if [[ ${params.lca} == \"T\" ]]\n                          then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                          else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                          fi\n                          echo \"extracting genes and names\"\n                          touch new_\"\\$name\"_asvnames.txt\n                          for s in \\$(cat seqids.lst);do\n                              echo \"Using RVDB headers.\"\n                              if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                  echo \"Yep, there was a hit for \\$s\"\n                                  echo \"Extracting the information now:\"\n                                  acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                  echo \"\\$s\" >> otu.list\n                                  echo \"\\$acc\" >> access.list\n                                  line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                  echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                  echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                  echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                  echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                  echo \"Extracting virus and gene ID for \\$s now\"\n                                  gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                  echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                  virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                  echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                  echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                  if [[ \"${params.lca}\" == \"T\" ]]\n                                  then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                          then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                echo \"\\$lcla\" >> lca_classification.list\n                                          else  echo \"Viruses\" >> lca_classification.list\n                                          fi\n                                  fi\n                                  echo \"\\$s done.\"\n                              else\n                                  echo \"Ugh, there was no hit for \\$s ..\"\n                                  echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                  echo \"\\$s\" >> otu.list\n                                  echo \"NO_HIT\" >> access.list\n                                  echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                  echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                  echo \"NO_HIT\" >> evalue.list\n                                  echo \"NO_HIT\" >> bit.list\n                                  echo \"NO_HIT\" >> pid.list\n                                  echo \"NO_HIT\" >> length.list\n                                  virus=\"NO\"\n                                  gene=\"HIT\"\n                                  echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                  if [[ \"${params.lca}\" == \"T\" ]]\n                                  then    echo \"N/A\" >> lca_classification.list\n                                  fi\n                                  echo \"\\$s done.\"\n                              fi\n                          echo \"Done with \\$s\"\n                          done\n                          echo \"Now editing \"\\$name\" fasta headers\"\n                          ###### rename_seq.py\n                          ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                          awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                          echo \"[Sequence header]\" > newnames.list\n                          cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                          touch sequence.list\n                          echo \"     \" > sequence.list\n                          grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                          rm \"\\$name\"_tmpssasv.fasta\n                          if [[ \"${params.lca}\" == \"T\" ]]\n                          then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                          else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                          fi\n                          for x in *phyloformat.csv;do\n                                    echo \"\\$x\"\n                                    lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                    tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                    sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                    cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                    rm tmpcol.list tmp2col.list\n                          done\n                          awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                          rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                          \"\"\"\n                }",
        "nb_lignes_process": 125,
        "string_script": "                          \"\"\"\n                          cp ${params.vampdir}/bin/rename_seq.py .\n                          virdb=${params.dbdir}/${params.dbname}\n                          grep \">\" \\${virdb} > headers.list\n                          if [[ ${params.measurement} == \"bitscore\" ]]\n                          then    measure=\"--min-score ${params.bitscore}\"\n                          elif    [[ ${params.measurement} == \"evalue\" ]]\n                          then    measure=\"-e ${params.evalue}\"\n                          else    measure=\"--min-score ${params.bitscore}\"\n                          fi\n                          headers=\"headers.list\"\n                          name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                          diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                          echo \"Preparing lists to generate summary .csv's\"\n                          echo \"[Best hit accession number]\" > access.list\n                          echo \"[e-value]\" > evalue.list\n                          echo \"[Bitscore]\" > bit.list\n                          echo \"[Percent ID (aa)]\" > pid.list\n                          echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                          echo \"[Gene]\" > \"\\$name\"_genes.list\n                          echo \"[ASV#]\" > otu.list\n                          echo \"[Sequence length]\" > length.list\n                          grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                          if [[ ${params.lca} == \"T\" ]]\n                          then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                          else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                          fi\n                          echo \"extracting genes and names\"\n                          touch new_\"\\$name\"_asvnames.txt\n                          for s in \\$(cat seqids.lst);do\n                              echo \"Using RVDB headers.\"\n                              if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                  echo \"Yep, there was a hit for \\$s\"\n                                  echo \"Extracting the information now:\"\n                                  acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                  echo \"\\$s\" >> otu.list\n                                  echo \"\\$acc\" >> access.list\n                                  line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                  echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                  echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                  echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                  echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                  echo \"Extracting virus and gene ID for \\$s now\"\n                                  gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                  echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                  virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                  echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                  echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                  if [[ \"${params.lca}\" == \"T\" ]]\n                                  then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                          then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                echo \"\\$lcla\" >> lca_classification.list\n                                          else  echo \"Viruses\" >> lca_classification.list\n                                          fi\n                                  fi\n                                  echo \"\\$s done.\"\n                              else\n                                  echo \"Ugh, there was no hit for \\$s ..\"\n                                  echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                  echo \"\\$s\" >> otu.list\n                                  echo \"NO_HIT\" >> access.list\n                                  echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                  echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                  echo \"NO_HIT\" >> evalue.list\n                                  echo \"NO_HIT\" >> bit.list\n                                  echo \"NO_HIT\" >> pid.list\n                                  echo \"NO_HIT\" >> length.list\n                                  virus=\"NO\"\n                                  gene=\"HIT\"\n                                  echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                  if [[ \"${params.lca}\" == \"T\" ]]\n                                  then    echo \"N/A\" >> lca_classification.list\n                                  fi\n                                  echo \"\\$s done.\"\n                              fi\n                          echo \"Done with \\$s\"\n                          done\n                          echo \"Now editing \"\\$name\" fasta headers\"\n                          ###### rename_seq.py\n                          ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                          awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                          echo \"[Sequence header]\" > newnames.list\n                          cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                          touch sequence.list\n                          echo \"     \" > sequence.list\n                          grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                          rm \"\\$name\"_tmpssasv.fasta\n                          if [[ \"${params.lca}\" == \"T\" ]]\n                          then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                          else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                          fi\n                          for x in *phyloformat.csv;do\n                                    echo \"\\$x\"\n                                    lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                    tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                    sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                    cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                    rm tmpcol.list tmp2col.list\n                          done\n                          awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                          rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                          \"\"\"",
        "nb_lignes_script": 107,
        "language_script": "bash",
        "tools": [
            "Diamond"
        ],
        "tools_url": [
            "https://bio.tools/diamond"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            }
        ],
        "inputs": [
            "nuclFastas_forDiamond_asv_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tax_labeled_fasta_asv",
            "summary_diamond_asv",
            "taxplot_asv",
            "tax_table_asv",
            "tax_nodCol_asv"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*_ASV*.{fasta,csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*_ASV*dmd.out'"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_ASV_Counts_Tables": {
        "name_process": "Generate_ASV_Counts_Tables",
        "string_process": " process Generate_ASV_Counts_Tables {\n\n            label 'norm_cpus'\n\n            publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Counts\", mode: \"copy\", overwrite: true, pattern: '*ASV*.{biome,csv}'\n\n            input:\n                file(asvs) from nuclFastas_forCounts_asv_ch\n                file(merged) from nuclCounts_mergedreads_asv_ch\n\n            output:\n                tuple file(\"*_counts.csv\"), file(\"*_counts.biome\") into counts_vsearch_asv\n                file(\"*_ASV*counts.csv\") into (asv_counts_plots, asvcount_med, asvcount_phylogr)\n\n            script:\n                \"\"\"\n                name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}' | sed 's/ASVs/ASV/g')\n                vsearch --usearch_global ${merged} --db ${asvs} --id .${params.asvcountID} --threads ${task.cpus} --otutabout \"\\$name\"_counts.txt --biomout \"\\$name\"_counts.biome\n                cat \\${name}_counts.txt | tr \"\\t\" \",\" >\\${name}_count.csv\n                sed 's/#OTU ID/OTU_ID/g' \\${name}_count.csv >\\${name}_counts.csv\n                rm \\${name}_count.csv\n                \"\"\"\n        }",
        "nb_lignes_process": 21,
        "string_script": "                \"\"\"\n                name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}' | sed 's/ASVs/ASV/g')\n                vsearch --usearch_global ${merged} --db ${asvs} --id .${params.asvcountID} --threads ${task.cpus} --otutabout \"\\$name\"_counts.txt --biomout \"\\$name\"_counts.biome\n                cat \\${name}_counts.txt | tr \"\\t\" \",\" >\\${name}_count.csv\n                sed 's/#OTU ID/OTU_ID/g' \\${name}_count.csv >\\${name}_counts.csv\n                rm \\${name}_count.csv\n                \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "nuclFastas_forCounts_asv_ch",
            "nuclCounts_mergedreads_asv_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "counts_vsearch_asv",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Counts\", mode: \"copy\", overwrite: true, pattern: '*ASV*.{biome,csv}'"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_ASV_Matrices": {
        "name_process": "Generate_ASV_Matrices",
        "string_process": " process Generate_ASV_Matrices {\n\n            label 'low_cpus'\n\n            publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Matrices\", mode: \"copy\", overwrite: true, pattern: '*ASV*PercentID.matrix'\n\n            input:\n                file(reads) from nuclFastas_forMatrix_asv_ch\n\n            output:\n                file(\"*.matrix\") into clustmatrices_asv\n                file(\"*_ASV*PercentID.matrix\") into asv_heatmap\n\n            script:\n                                                     \n                \"\"\"\n                for filename in ${reads};do\n                    if [ `echo \\${filename} | grep -c \"ncASV\"` -eq 1 ];then\n                        ident=\\$( echo \\${filename} | awk -F \"ncASV\" '{print \\$2}' | awk -F \".fasta\" '{print \\$1}')\n                        name=\\$( echo \\${filename}| awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PairwiseDistance.matrix --full --force --threads=${task.cpus}\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        for x in *q.matrix;do\n                            pre=\\$(echo \"\\$x\" | awk -F \"q.matrix\" '{print \\$1}')\n                            ya=\\$(wc -l \\$x | awk '{print \\$1}')\n                            echo \"\\$((\\$ya-1))\"\n                            tail -\"\\$((\\$ya-1))\" \\$x > \\${pre}z.matrix\n                            rm \\$x\n                            cat \\${pre}z.matrix | sed 's/ /,/g' | sed -E 's/(,*),/,/g' >\\${pre}.matrix\n                            rm \\${pre}z.matrix\n                        done\n                    else\n                        name=\\$( echo \\${filename} | awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PairwiseDistance.matrix --full --force --threads=${task.cpus}\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        for x in *q.matrix;do\n                            pre=\\$(echo \"\\$x\" | awk -F \"q.matrix\" '{print \\$1}')\n                            ya=\\$(wc -l \\$x | awk '{print \\$1}')\n                            echo \"\\$((\\$ya-1))\"\n                            tail -\"\\$((\\$ya-1))\" \\$x > \\${pre}z.matrix\n                            rm \\$x\n                            cat \\${pre}z.matrix | sed 's/ /,/g' | sed -E 's/(,*),/,/g' >\\${pre}.matrix\n                            rm \\${pre}z.matrix\n                        done\n                    fi\n                done\n                \"\"\"\n            }",
        "nb_lignes_process": 46,
        "string_script": "                \"\"\"\n                for filename in ${reads};do\n                    if [ `echo \\${filename} | grep -c \"ncASV\"` -eq 1 ];then\n                        ident=\\$( echo \\${filename} | awk -F \"ncASV\" '{print \\$2}' | awk -F \".fasta\" '{print \\$1}')\n                        name=\\$( echo \\${filename}| awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PairwiseDistance.matrix --full --force --threads=${task.cpus}\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        for x in *q.matrix;do\n                            pre=\\$(echo \"\\$x\" | awk -F \"q.matrix\" '{print \\$1}')\n                            ya=\\$(wc -l \\$x | awk '{print \\$1}')\n                            echo \"\\$((\\$ya-1))\"\n                            tail -\"\\$((\\$ya-1))\" \\$x > \\${pre}z.matrix\n                            rm \\$x\n                            cat \\${pre}z.matrix | sed 's/ /,/g' | sed -E 's/(,*),/,/g' >\\${pre}.matrix\n                            rm \\${pre}z.matrix\n                        done\n                    else\n                        name=\\$( echo \\${filename} | awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PairwiseDistance.matrix --full --force --threads=${task.cpus}\n                        clustalo -i \\${filename} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        for x in *q.matrix;do\n                            pre=\\$(echo \"\\$x\" | awk -F \"q.matrix\" '{print \\$1}')\n                            ya=\\$(wc -l \\$x | awk '{print \\$1}')\n                            echo \"\\$((\\$ya-1))\"\n                            tail -\"\\$((\\$ya-1))\" \\$x > \\${pre}z.matrix\n                            rm \\$x\n                            cat \\${pre}z.matrix | sed 's/ /,/g' | sed -E 's/(,*),/,/g' >\\${pre}.matrix\n                            rm \\${pre}z.matrix\n                        done\n                    fi\n                done\n                \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nuclFastas_forMatrix_asv_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "clustmatrices_asv",
            "asv_heatmap"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Matrices\", mode: \"copy\", overwrite: true, pattern: '*ASV*PercentID.matrix'"
        ],
        "when": "",
        "stub": ""
    },
    "ASV_Phylogeny": {
        "name_process": "ASV_Phylogeny",
        "string_process": " process ASV_Phylogeny {\n\n                      label 'norm_cpus'\n\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Phylogeny/Alignment\", mode: \"copy\", overwrite: true,  pattern: '*ASV*aln.*'\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*ASV*mt*'\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*ASV*iq*'\n\n                      input:\n                          file(asvs) from nuclFastas_forphylogeny_asv\n\n                      output:\n                          tuple file(\"*_aln.fasta\"), file(\"*_aln.html\"), file(\"*.tree\"), file(\"*.log\"), file(\"*iq*\"), file(\"*mt*\") into align_results_asv\n                          file(\"*iq.treefile\") into (nucl_phyl_plot_asv, asvphy_med, asv_treeclust)\n\n                      script:\n                          \"\"\"\n                          pre=\\$(echo ${asvs} | awk -F \".fasta\" '{print \\$1}' )\n                          ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                          trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                          o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                          mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                          # Nucleotide_ModelTest\n                          modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d nt -s 203 --disable-checkpoint\n                          # Nucleotide_Phylogeny\n                          if [ \"${params.iqCustomnt}\" != \"\" ];then\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -T auto ${params.iqCustomnt}\n                          elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                              mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n                          elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                              mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n                          elif [ \"${params.nonparametric}\" != \"false\" ];then\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -b ${params.boots}\n                          elif [ \"${params.parametric}\" != \"false\" ];then\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                          else\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                          fi\n                          \"\"\"\n                  }",
        "nb_lignes_process": 40,
        "string_script": "                          \"\"\"\n                          pre=\\$(echo ${asvs} | awk -F \".fasta\" '{print \\$1}' )\n                          ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                          trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                          o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                          mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                          # Nucleotide_ModelTest\n                          modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d nt -s 203 --disable-checkpoint\n                          # Nucleotide_Phylogeny\n                          if [ \"${params.iqCustomnt}\" != \"\" ];then\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -T auto ${params.iqCustomnt}\n                          elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                              mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n                          elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                              mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n                          elif [ \"${params.nonparametric}\" != \"false\" ];then\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -b ${params.boots}\n                          elif [ \"${params.parametric}\" != \"false\" ];then\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                          else\n                              iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                          fi\n                          \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "trimAl",
            "ModelTest-NG"
        ],
        "tools_url": [
            "https://bio.tools/trimal",
            "https://bio.tools/ModelTest-NG"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            },
            {
                "name": "ModelTest-NG",
                "uri": "https://bio.tools/ModelTest-NG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3293",
                            "term": "Phylogenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3316",
                            "term": "Computer science"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A new and scalable tool for the selection of DNA and protein evolutionary models | ModelTest-NG is a tool for selecting the best-fit model of evolution for DNA and protein alignments. ModelTest-NG supersedes jModelTest and ProtTest in one single tool, with graphical and command console interfaces",
                "homepage": "https://github.com/ddarriba/modeltest"
            }
        ],
        "inputs": [
            "nuclFastas_forphylogeny_asv"
        ],
        "nb_inputs": 1,
        "outputs": [
            "align_results_asv",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*ASV*aln.*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*ASV*mt*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*ASV*iq*'"
        ],
        "when": "",
        "stub": ""
    },
    "ASV_PhyloClustering": {
        "name_process": "ASV_PhyloClustering",
        "string_process": " process ASV_PhyloClustering {\n\n                      label 'norm_cpus'\n\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/TreeClustering\", mode: \"copy\", overwrite: true\n\n                      input:\n                         file(tree) from asv_treeclust\n                         file(counts) from asvcount_phylogr\n                      output:\n                          file(\"*treeclustering*.out\") into asvtreeclustering_res\n                          file(\"${params.projtag}_ASV_phylogroup.csv\") into asv_phylogroupcsv\n                          file(\"${params.projtag}_ASV_phyloGroupingcounts.csv\") into asv_phylogroupingcsv\n\n                      script:\n                          \"\"\"\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_ASV_treeclustering.out\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_ASV_treeclustering_verbose.out\n                          #create headless treeclustering.out\n                          tail -n +2 ${params.projtag}_ASV_treeclustering.out | sed 's/-1/0X/g' > headless.treeout\n                          #extracting singletons\n                          grep -w \"0X\" headless.treeout > single.out\n                          awk -F \"\\\\t\" '{print \\$1}' single.out > single.list\n                          #assigning groupID to singletons\n                          for x in \\$(awk -F \"\\\\t\" '{print \\$1}' single.out); do echo \"\"\\$x\"XX\" >> single.groups;done\n\n                          #summarizing clustering results\n                          awk -F \"\\\\t\" '{print \\$2}' headless.treeout | grep -v \"0X\" | sort | uniq > grp.list\n                          cat single.groups >> group.list\n                          cat grp.list >> group.list\n                          echo \"Sequence_ID,phyloGroup_ID\" > ${params.projtag}_ASV_phylogroup.csv\n\n                          for x in \\$(seq \"\\$(wc -l group.list | awk '{print \\$1}')\");\n                          do      echo \"phyloGroup\"\\$x\"\" >> grup.list\n                          done\n                          paste -d \",\" grup.list group.list > groups.csv\n                          rm grup.list group.list\n                          awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > asv.list\n                          for z in \\$(cat asv.list);\n                          do      if [[ \\$(grep -wc \"\\$z\" single.list) -ge 1 ]]\n                                  then\n                                          group=\\$(grep -w \"\"\\$z\"XX\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  else\n                                          grp=\\$(grep -w \"\\$z\" headless.treeout | awk -F \"\\\\t\" '{print \\$2}')\n                                          group=\\$(grep -w \"\\$grp\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  fi\n                                  echo \"\"\\$z\",\"\\$group\"\" >> ${params.projtag}_ASV_phylogroup.csv\n                          done\n                          awk -F \",\" '{print \\$2}' ${params.projtag}_ASV_phylogroup.csv > groups.list\n                          paste -d\",\" groups.list ${counts} > ${params.projtag}_ASV_phyloGroupingcounts.csv\n                          \"\"\"\n                }",
        "nb_lignes_process": 50,
        "string_script": "                          \"\"\"\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_ASV_treeclustering.out\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_ASV_treeclustering_verbose.out\n                          #create headless treeclustering.out\n                          tail -n +2 ${params.projtag}_ASV_treeclustering.out | sed 's/-1/0X/g' > headless.treeout\n                          #extracting singletons\n                          grep -w \"0X\" headless.treeout > single.out\n                          awk -F \"\\\\t\" '{print \\$1}' single.out > single.list\n                          #assigning groupID to singletons\n                          for x in \\$(awk -F \"\\\\t\" '{print \\$1}' single.out); do echo \"\"\\$x\"XX\" >> single.groups;done\n\n                          #summarizing clustering results\n                          awk -F \"\\\\t\" '{print \\$2}' headless.treeout | grep -v \"0X\" | sort | uniq > grp.list\n                          cat single.groups >> group.list\n                          cat grp.list >> group.list\n                          echo \"Sequence_ID,phyloGroup_ID\" > ${params.projtag}_ASV_phylogroup.csv\n\n                          for x in \\$(seq \"\\$(wc -l group.list | awk '{print \\$1}')\");\n                          do      echo \"phyloGroup\"\\$x\"\" >> grup.list\n                          done\n                          paste -d \",\" grup.list group.list > groups.csv\n                          rm grup.list group.list\n                          awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > asv.list\n                          for z in \\$(cat asv.list);\n                          do      if [[ \\$(grep -wc \"\\$z\" single.list) -ge 1 ]]\n                                  then\n                                          group=\\$(grep -w \"\"\\$z\"XX\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  else\n                                          grp=\\$(grep -w \"\\$z\" headless.treeout | awk -F \"\\\\t\" '{print \\$2}')\n                                          group=\\$(grep -w \"\\$grp\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  fi\n                                  echo \"\"\\$z\",\"\\$group\"\" >> ${params.projtag}_ASV_phylogroup.csv\n                          done\n                          awk -F \",\" '{print \\$2}' ${params.projtag}_ASV_phylogroup.csv > groups.list\n                          paste -d\",\" groups.list ${counts} > ${params.projtag}_ASV_phyloGroupingcounts.csv\n                          \"\"\"",
        "nb_lignes_script": 35,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "asv_treeclust",
            "asvcount_phylogr"
        ],
        "nb_inputs": 2,
        "outputs": [
            "asvtreeclustering_res",
            "asv_phylogroupcsv",
            "asv_phylogroupingcsv"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/TreeClustering\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "ASV_Minimum_Entropy_Decomposition": {
        "name_process": "ASV_Minimum_Entropy_Decomposition",
        "string_process": " process ASV_Minimum_Entropy_Decomposition {\n\n                label 'low_cpus'\n\n                publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/ASVs/MED\", mode: \"copy\", overwrite: true\n\n                input:\n                  file(asvs) from asv_for_med\n\n                output:\n                  file(\"*_ASV_Grouping.csv\") into asvgroupscsv\n                  file(\"${params.projtag}_ASV_group_reps_aligned.fasta\") into groupreps\n                  file(\"${params.projtag}_asvMED_${params.asvC}\")\n\n                script:\n                    \"\"\"\n                    #alignment\n                    ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out ${params.projtag}_ASVs_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_ASVs_muscleAlign.fasta -out ${params.projtag}_ASVs_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_ASVs_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_ASVs_muscleAligned.fasta\n                    mv ${params.projtag}_ASVs_muscleAligned.fasta-TRIMMED ./${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #entopy analysis\n                    entropy-analysis ${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #Decomposition\n                    if [[ \\$(echo ${params.asvC} | grep -c \",\") -eq 1 || \"${params.asvSingle}\" == \"true\" ]]\n                    then\n                          tag=\\$(echo ${params.asvC} | sed 's/,/_/g')\n                          oligotype ${params.projtag}_ASVs_Aligned_informativeonly.fasta ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_asvMED_\"\\$tag\" -M 1 -C ${params.asvC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    elif [[ \"${params.asvSingle}\" == \"true\" ]]\n                    then\n                          tag=\"${params.asvC}\"\n                          oligotype ${params.projtag}_ASVs_Aligned_informativeonly.fasta ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_asvMED_\"\\$tag\" -M 1 -C ${params.asvC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    else\n                          oligotype ${params.projtag}_ASVs_Aligned_informativeonly.fasta ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_asvMED_${params.asvC} -M 1 -c ${params.asvC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    fi\n                    #generatemaps\n                    cd ./${params.projtag}_asvMED_${params.asvC}/OLIGO-REPRESENTATIVES/\n                    echo \"ASV,GroupID,IDPattern\"\n                    j=1\n                    for x in *_unique;\n                    do      gid=\\$(echo \\$x | awk -F \"_\" '{print \\$1}')\n                            uni=\\$(echo \\$x | awk -F \"\"\\${gid}\"_\" '{print \\$2}' | awk -F \"_uni\" '{print \\$1}')\n                            grep \">\"  \"\\$gid\"_\"\\$uni\" | awk -F \">\" '{print \\$2}' > asv.list\n                            seqtk subseq ../../${asvs} asv.list > Group\"\\${j}\"_sequences.fasta\n                            for z in \\$( cat asv.list)\n                            do      echo \"\"\\$z\",Group\"\\$j\",\"\\$uni\"\" >> ${params.projtag}_ASV_Grouping.csv\n\n                            done\n                            rm asv.list\n                            echo \">Group\\${j}\" >> ${params.projtag}_ASV_group_reps_aligned.fasta\n                            echo \"\\$uni\" > group.list\n                            seqtk subseq ../OLIGO-REPRESENTATIVES.fasta group.list > group.fasta\n                            tail -1 group.fasta >> ${params.projtag}_ASV_group_reps_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\" ./Group\"\\$j\"_\"\\$uni\"_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\"_unique ./Group\"\\$j\"_\"\\$uni\"_unqiues_aligned.fasta\n                            rm \"\\$gid\"*.cPickle\n                            j=\\$((\\$j+1))\n                    done\n                    mv ${params.projtag}_ASV_Grouping.csv ../../\n                    mv ${params.projtag}_ASV_group_reps_aligned.fasta ../../\n                    cd ..\n                    \"\"\"\n                }",
        "nb_lignes_process": 63,
        "string_script": "                    \"\"\"\n                    #alignment\n                    ${tools}/muscle5.0.1278_linux64 -in ${asvs} -out ${params.projtag}_ASVs_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_ASVs_muscleAlign.fasta -out ${params.projtag}_ASVs_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_ASVs_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_ASVs_muscleAligned.fasta\n                    mv ${params.projtag}_ASVs_muscleAligned.fasta-TRIMMED ./${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #entopy analysis\n                    entropy-analysis ${params.projtag}_ASVs_Aligned_informativeonly.fasta\n                    #Decomposition\n                    if [[ \\$(echo ${params.asvC} | grep -c \",\") -eq 1 || \"${params.asvSingle}\" == \"true\" ]]\n                    then\n                          tag=\\$(echo ${params.asvC} | sed 's/,/_/g')\n                          oligotype ${params.projtag}_ASVs_Aligned_informativeonly.fasta ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_asvMED_\"\\$tag\" -M 1 -C ${params.asvC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    elif [[ \"${params.asvSingle}\" == \"true\" ]]\n                    then\n                          tag=\"${params.asvC}\"\n                          oligotype ${params.projtag}_ASVs_Aligned_informativeonly.fasta ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_asvMED_\"\\$tag\" -M 1 -C ${params.asvC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    else\n                          oligotype ${params.projtag}_ASVs_Aligned_informativeonly.fasta ${params.projtag}_ASVs_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_asvMED_${params.asvC} -M 1 -c ${params.asvC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    fi\n                    #generatemaps\n                    cd ./${params.projtag}_asvMED_${params.asvC}/OLIGO-REPRESENTATIVES/\n                    echo \"ASV,GroupID,IDPattern\"\n                    j=1\n                    for x in *_unique;\n                    do      gid=\\$(echo \\$x | awk -F \"_\" '{print \\$1}')\n                            uni=\\$(echo \\$x | awk -F \"\"\\${gid}\"_\" '{print \\$2}' | awk -F \"_uni\" '{print \\$1}')\n                            grep \">\"  \"\\$gid\"_\"\\$uni\" | awk -F \">\" '{print \\$2}' > asv.list\n                            seqtk subseq ../../${asvs} asv.list > Group\"\\${j}\"_sequences.fasta\n                            for z in \\$( cat asv.list)\n                            do      echo \"\"\\$z\",Group\"\\$j\",\"\\$uni\"\" >> ${params.projtag}_ASV_Grouping.csv\n\n                            done\n                            rm asv.list\n                            echo \">Group\\${j}\" >> ${params.projtag}_ASV_group_reps_aligned.fasta\n                            echo \"\\$uni\" > group.list\n                            seqtk subseq ../OLIGO-REPRESENTATIVES.fasta group.list > group.fasta\n                            tail -1 group.fasta >> ${params.projtag}_ASV_group_reps_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\" ./Group\"\\$j\"_\"\\$uni\"_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\"_unique ./Group\"\\$j\"_\"\\$uni\"_unqiues_aligned.fasta\n                            rm \"\\$gid\"*.cPickle\n                            j=\\$((\\$j+1))\n                    done\n                    mv ${params.projtag}_ASV_Grouping.csv ../../\n                    mv ${params.projtag}_ASV_group_reps_aligned.fasta ../../\n                    cd ..\n                    \"\"\"",
        "nb_lignes_script": 48,
        "language_script": "bash",
        "tools": [
            "trimAl",
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/trimal",
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "asv_for_med"
        ],
        "nb_inputs": 1,
        "outputs": [
            "asvgroupscsv",
            "groupreps"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/ASVs/MED\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "ASV_MED_Reps_phylogeny": {
        "name_process": "ASV_MED_Reps_phylogeny",
        "string_process": " process ASV_MED_Reps_phylogeny {\n\n                label 'low_cpus'\n\n                publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/MED/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*ASV*mt*'\n                publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/MED/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*ASV*iq*'\n\n                input:\n                  file(reps) from groupreps\n\n                output:\n                  file(\"*_ASV_Group_Reps*\") into align_results_asvmed\n                  file(\"*iq.treefile\") into asv_group_rep_tree\n\n                script:\n                    \"\"\"\n                    # Protein_ModelTest\n                    modeltest-ng -i ${reps} -p ${task.cpus} -o ${params.projtag}_ASV_Group_Reps_mt -d aa -s 203 --disable-checkpoint\n\n                    # Protein_Phylogeny\n                    if [ \"${params.iqCustomaa}\" != \"\" ];then\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq --redo -T auto ${params.iqCustomaa}\n\n                    elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                        mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n\n                    elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                        mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                    elif [ \"${params.nonparametric}\" != \"false\" ];then\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                    elif [ \"${params.parametric}\" != \"false\" ];then\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                    else\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                    fi\n                    \"\"\"\n                }",
        "nb_lignes_process": 40,
        "string_script": "                    \"\"\"\n                    # Protein_ModelTest\n                    modeltest-ng -i ${reps} -p ${task.cpus} -o ${params.projtag}_ASV_Group_Reps_mt -d aa -s 203 --disable-checkpoint\n\n                    # Protein_Phylogeny\n                    if [ \"${params.iqCustomaa}\" != \"\" ];then\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq --redo -T auto ${params.iqCustomaa}\n\n                    elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                        mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n\n                    elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                        mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                    elif [ \"${params.nonparametric}\" != \"false\" ];then\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                    elif [ \"${params.parametric}\" != \"false\" ];then\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                    else\n                        iqtree -s ${reps} --prefix ${params.projtag}_ASV_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                    fi\n                    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "ModelTest-NG"
        ],
        "tools_url": [
            "https://bio.tools/ModelTest-NG"
        ],
        "tools_dico": [
            {
                "name": "ModelTest-NG",
                "uri": "https://bio.tools/ModelTest-NG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3293",
                            "term": "Phylogenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3316",
                            "term": "Computer science"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A new and scalable tool for the selection of DNA and protein evolutionary models | ModelTest-NG is a tool for selecting the best-fit model of evolution for DNA and protein alignments. ModelTest-NG supersedes jModelTest and ProtTest in one single tool, with graphical and command console interfaces",
                "homepage": "https://github.com/ddarriba/modeltest"
            }
        ],
        "inputs": [
            "groupreps"
        ],
        "nb_inputs": 1,
        "outputs": [
            "align_results_asvmed",
            "asv_group_rep_tree"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/MED/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*ASV*mt*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/MED/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*ASV*iq*'"
        ],
        "when": "",
        "stub": ""
    },
    "Adding_ASV_MED_Info": {
        "name_process": "Adding_ASV_MED_Info",
        "string_process": " process Adding_ASV_MED_Info {\n\n              label 'low_cpus'\n\n              publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/MED/\", mode: \"copy\", overwrite: true\n\n              input:\n                  file(counts) from asvcount_med\n                  file(map) from asvgroupscsv\n\n              output:\n                  file(\"${params.projtag}_ASV_Groupingcounts.csv\") into asvgroupcounts\n\n              script:\n                  \"\"\"\n                  awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > asv.list\n                  echo \"GroupID\" >> group.list\n                  for x in \\$(cat asv.list);\n                  do    group=\\$(grep -w \\$x ${map} | awk -F \",\" '{print \\$2}')\n                        echo \"\\$group\" >> group.list\n                  done\n                  paste -d',' group.list ${counts} > ${params.projtag}_ASV_Groupingcounts.csv\n                  \"\"\"\n              }",
        "nb_lignes_process": 22,
        "string_script": "                  \"\"\"\n                  awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > asv.list\n                  echo \"GroupID\" >> group.list\n                  for x in \\$(cat asv.list);\n                  do    group=\\$(grep -w \\$x ${map} | awk -F \",\" '{print \\$2}')\n                        echo \"\\$group\" >> group.list\n                  done\n                  paste -d',' group.list ${counts} > ${params.projtag}_ASV_Groupingcounts.csv\n                  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "asvcount_med",
            "asvgroupscsv"
        ],
        "nb_inputs": 2,
        "outputs": [
            "asvgroupcounts"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/ASVs/MED/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Translate_For_AminoTyping": {
        "name_process": "Translate_For_AminoTyping",
        "string_process": " process Translate_For_AminoTyping {\n\n                  label 'low_cpus'\n\n                  publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/Translation\", mode: \"copy\", overwrite: true\n\n                  input:\n                      file(fasta) from asvsforAminotyping\n\n                  output:\n                      file(\"${params.projtag}_all_translations.fasta\") into amintypegen\n                      file(\"${params.projtag}_translation_report\") into proteinstage_vap_report\n\n                  script:\n                      \"\"\"\n                      ${tools}/virtualribosomev2/dna2pep.py ${fasta} -r all -x -o none --fasta ${params.projtag}_all_translaton.fasta --report ${params.projtag}_translation_report\n                      awk '/^>/ { print (NR==1 ? \"\" : RS) \\$0; next } { printf \"%s\", \\$0 } END { printf RS }' ${params.projtag}_all_translaton.fasta > ${params.projtag}_all_translations.fasta\n                      rm ${params.projtag}_all_translaton.fasta\n                      \"\"\"\n                }",
        "nb_lignes_process": 18,
        "string_script": "                      \"\"\"\n                      ${tools}/virtualribosomev2/dna2pep.py ${fasta} -r all -x -o none --fasta ${params.projtag}_all_translaton.fasta --report ${params.projtag}_translation_report\n                      awk '/^>/ { print (NR==1 ? \"\" : RS) \\$0; next } { printf \"%s\", \\$0 } END { printf RS }' ${params.projtag}_all_translaton.fasta > ${params.projtag}_all_translations.fasta\n                      rm ${params.projtag}_all_translaton.fasta\n                      \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "NextSV"
        ],
        "tools_url": [
            "https://bio.tools/nextsv"
        ],
        "tools_dico": [
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            }
        ],
        "inputs": [
            "asvsforAminotyping"
        ],
        "nb_inputs": 1,
        "outputs": [
            "amintypegen",
            "proteinstage_vap_report"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/Translation\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_AminoTypes": {
        "name_process": "Generate_AminoTypes",
        "string_process": " process Generate_AminoTypes {\n\n                    label 'norm_cpus'\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{clstr,csv,gc}'\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/Problematic\", mode: \"copy\", overwrite: true, pattern: '*problematic*.{fasta}'\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes\", mode: \"copy\", overwrite: true, pattern: '*AminoTypes_noTaxonomy.{fasta}'\n\n                    input:\n                        file(prot) from amintypegen\n                        file(asvs) from asvaminocheck\n\n                    output:\n                        tuple file(\"*.fasta\"), file(\"${params.projtag}_AminoTypes.clstr\"), file(\"${params.projtag}_clustered.gc\") into ( supplementalfiles )\n                        file(\"${params.projtag}_AminoTypes_noTaxonomy.fasta\") into ( aminotypesCounts, aminotypesMafft, aminotypesClustal, aminotypesBlast, aminotypesEmboss, aminos_for_med )\n                        file(\"${params.projtag}_AminoType_summary_map.csv\") into aminomapmed\n\n                    script:\n                        \"\"\"\n                        set +e\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)>=\"${params.minAA}\"{print \">\"\\$0}' ${prot} >${params.projtag}_filtered_translations.fasta\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)<\"${params.minAA}\"{print \">\"\\$0}' ${prot} >${params.projtag}_problematic_translations.fasta\n                        if [ `wc -l ${params.projtag}_problematic_translations.fasta | awk '{print \\$1}'` -gt 1 ];then\n                            grep \">\" ${params.projtag}_problematic_translations.fasta | awk -F \">\" '{print \\$2}' > problem_tmp.list\n                            seqtk subseq ${asvs} problem_tmp.list > ${params.projtag}_problematic_nucleotides.fasta\n                        else\n                            rm ${params.projtag}_problematic_translations.fasta\n                        fi\n                        cd-hit -i ${params.projtag}_filtered_translations.fasta -c 1.0 -o ${params.projtag}_unlabeled_types.fasta\n                        sed 's/>Cluster />Cluster_/g' ${params.projtag}_unlabeled_types.fasta.clstr >${params.projtag}_AminoTypes.clstr\n                        grep \">Cluster_\" ${params.projtag}_AminoTypes.clstr >tmpclusters.list\n                        grep -w \"*\" ${params.projtag}_AminoTypes.clstr | awk '{print \\$3}' | awk -F \".\" '{print \\$1}' >tmphead.list\n                        grep -w \"*\" ${params.projtag}_AminoTypes.clstr | awk '{print \\$2}' | awk -F \",\" '{print \\$1}' >tmplen.list\n                        paste -d\",\" tmpclusters.list tmphead.list >tmp.info.csv\n                        grep \">\" ${params.projtag}_unlabeled_types.fasta >lala.list\n                        j=1\n                        for x in \\$(cat lala.list);do\n                            echo \">${params.projtag}_AminoType\\${j}\" >>${params.projtag}_aminoheaders.list\n                            echo \"\\${x},>${params.projtag}_AminoType\\${j}\" >>tmpaminotype.info.csv\n                            j=\\$(( \\${j}+1 ))\n                        done\n                        rm lala.list\n                        awk -F \",\" '{print \\$2}' tmp.info.csv >>tmporder.list\n                        for x in \\$(cat tmporder.list);do\n                         \tgrep -w \"\\$x\" tmpaminotype.info.csv | awk -F \",\" '{print \\$2}' >>tmpder.list\n                        done\n                        paste -d \",\" tmpclusters.list tmplen.list tmphead.list tmpder.list >${params.projtag}_AminoType_summary_map.csv\n                        rm tmp*\n                        ./rename_seq.py ${params.projtag}_unlabeled_types.fasta ${params.projtag}_aminoheaders.list ${params.projtag}_AminoTypes_noTaxonomy.fasta\n                        stats.sh in=${params.projtag}_AminoTypes_noTaxonomy.fasta gc=${params.projtag}_clustered.gc gcformat=4\n                        \"\"\"\n        \t    }",
        "nb_lignes_process": 51,
        "string_script": "                        \"\"\"\n                        set +e\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)>=\"${params.minAA}\"{print \">\"\\$0}' ${prot} >${params.projtag}_filtered_translations.fasta\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)<\"${params.minAA}\"{print \">\"\\$0}' ${prot} >${params.projtag}_problematic_translations.fasta\n                        if [ `wc -l ${params.projtag}_problematic_translations.fasta | awk '{print \\$1}'` -gt 1 ];then\n                            grep \">\" ${params.projtag}_problematic_translations.fasta | awk -F \">\" '{print \\$2}' > problem_tmp.list\n                            seqtk subseq ${asvs} problem_tmp.list > ${params.projtag}_problematic_nucleotides.fasta\n                        else\n                            rm ${params.projtag}_problematic_translations.fasta\n                        fi\n                        cd-hit -i ${params.projtag}_filtered_translations.fasta -c 1.0 -o ${params.projtag}_unlabeled_types.fasta\n                        sed 's/>Cluster />Cluster_/g' ${params.projtag}_unlabeled_types.fasta.clstr >${params.projtag}_AminoTypes.clstr\n                        grep \">Cluster_\" ${params.projtag}_AminoTypes.clstr >tmpclusters.list\n                        grep -w \"*\" ${params.projtag}_AminoTypes.clstr | awk '{print \\$3}' | awk -F \".\" '{print \\$1}' >tmphead.list\n                        grep -w \"*\" ${params.projtag}_AminoTypes.clstr | awk '{print \\$2}' | awk -F \",\" '{print \\$1}' >tmplen.list\n                        paste -d\",\" tmpclusters.list tmphead.list >tmp.info.csv\n                        grep \">\" ${params.projtag}_unlabeled_types.fasta >lala.list\n                        j=1\n                        for x in \\$(cat lala.list);do\n                            echo \">${params.projtag}_AminoType\\${j}\" >>${params.projtag}_aminoheaders.list\n                            echo \"\\${x},>${params.projtag}_AminoType\\${j}\" >>tmpaminotype.info.csv\n                            j=\\$(( \\${j}+1 ))\n                        done\n                        rm lala.list\n                        awk -F \",\" '{print \\$2}' tmp.info.csv >>tmporder.list\n                        for x in \\$(cat tmporder.list);do\n                         \tgrep -w \"\\$x\" tmpaminotype.info.csv | awk -F \",\" '{print \\$2}' >>tmpder.list\n                        done\n                        paste -d \",\" tmpclusters.list tmplen.list tmphead.list tmpder.list >${params.projtag}_AminoType_summary_map.csv\n                        rm tmp*\n                        ./rename_seq.py ${params.projtag}_unlabeled_types.fasta ${params.projtag}_aminoheaders.list ${params.projtag}_AminoTypes_noTaxonomy.fasta\n                        stats.sh in=${params.projtag}_AminoTypes_noTaxonomy.fasta gc=${params.projtag}_clustered.gc gcformat=4\n                        \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "seqtk",
            "cd-hit",
            "Clusterv"
        ],
        "tools_url": [
            "https://bio.tools/seqtk",
            "https://bio.tools/cd-hit",
            "https://bio.tools/clusterv"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            },
            {
                "name": "cd-hit",
                "uri": "https://bio.tools/cd-hit",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "Cluster a nucleotide dataset into representative sequences.",
                "homepage": "https://github.com/weizhongli/cdhit"
            },
            {
                "name": "Clusterv",
                "uri": "https://bio.tools/clusterv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The clusterv R package implements a set of functions to assess the reliability of clusters discovered by clustering algorithms. This library is tailored to the analysis of high dimensional data and in particular it is conceived for the analysis of the reliability of clusters discovered using DNA microarray data.",
                "homepage": "http://homes.di.unimi.it/~valenti/SW/clusterv/"
            }
        ],
        "inputs": [
            "amintypegen",
            "asvaminocheck"
        ],
        "nb_inputs": 2,
        "outputs": [
            "",
            "",
            "aminomapmed"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{clstr,csv,gc}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/Problematic\", mode: \"copy\", overwrite: true, pattern: '*problematic*.{fasta}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes\", mode: \"copy\", overwrite: true, pattern: '*AminoTypes_noTaxonomy.{fasta}'"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_AminoType_Matrices": {
        "name_process": "Generate_AminoType_Matrices",
        "string_process": " process Generate_AminoType_Matrices {\n\n                    label 'low_cpus'\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Matrices\", mode: \"copy\", overwrite: true\n\n                    input:\n                        file(prot) from aminotypesClustal\n\n                    output:\n                        file(\"*.matrix\") into proclustmatrices\n                        file(\"*PercentID.matrix\") into aminotype_heatmap\n\n                    script:\n                        \"\"\"\n                        name=\\$( echo ${prot} | awk -F \"_noTax\" '{print \\$1}')\n                        clustalo -i ${prot} --distmat-out=\\${name}_PairwiseDistanceq.matrix --full --force --threads=${task.cpus}\n                        clustalo -i ${prot} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        for x in *q.matrix;do\n                            pre=\\$(echo \"\\$x\" | awk -F \"q.matrix\" '{print \\$1}')\n                            ya=\\$(wc -l \\$x | awk '{print \\$1}')\n                            echo \"\\$((\\$ya-1))\"\n                            tail -\"\\$(( \\$ya-1))\" \\$x > \\${pre}z.matrix\n                            rm \\$x\n                            cat \\${pre}z.matrix | sed 's/ /,/g' | sed -E 's/(,*),/,/g' >\\${pre}.matrix\n                            rm \\${pre}z.matrix\n                        done\n                        \"\"\"\n                }",
        "nb_lignes_process": 27,
        "string_script": "                        \"\"\"\n                        name=\\$( echo ${prot} | awk -F \"_noTax\" '{print \\$1}')\n                        clustalo -i ${prot} --distmat-out=\\${name}_PairwiseDistanceq.matrix --full --force --threads=${task.cpus}\n                        clustalo -i ${prot} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        for x in *q.matrix;do\n                            pre=\\$(echo \"\\$x\" | awk -F \"q.matrix\" '{print \\$1}')\n                            ya=\\$(wc -l \\$x | awk '{print \\$1}')\n                            echo \"\\$((\\$ya-1))\"\n                            tail -\"\\$(( \\$ya-1))\" \\$x > \\${pre}z.matrix\n                            rm \\$x\n                            cat \\${pre}z.matrix | sed 's/ /,/g' | sed -E 's/(,*),/,/g' >\\${pre}.matrix\n                            rm \\${pre}z.matrix\n                        done\n                        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "aminotypesClustal"
        ],
        "nb_inputs": 1,
        "outputs": [
            "proclustmatrices",
            "aminotype_heatmap"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Matrices\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_EMBOSS_Analyses": {
        "name_process": "AminoType_EMBOSS_Analyses",
        "string_process": " process AminoType_EMBOSS_Analyses {\n\n                        label 'low_cpus'\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/2dStructure\", mode: \"copy\", overwrite: true, pattern: '*.{garnier}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/HydrophobicMoment\", mode: \"copy\", overwrite: true, pattern: '*HydrophobicMoments.{svg}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/IsoelectricPoint\", mode: \"copy\", overwrite: true, pattern: '*IsoelectricPoint.{iep,svg}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/ProteinProperties\", mode: \"copy\", overwrite: true, pattern: '*.{pepstats,pepinfo}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/ProteinProperties/Plots\", mode: \"copy\", overwrite: true, pattern: '*PropertiesPlot.{svg}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/2dStructure/Plots\", mode: \"copy\", overwrite: true, pattern: '*Helical*.{svg}'\n\n                        input:\n                            file(prot) from aminotypesEmboss\n\n                        output:\n                            tuple file(\"*.garnier\"), file(\"*HydrophobicMoments.svg\"), file(\"*IsoelectricPoint*\"), file(\"*.pepstats\"), file(\"*PropertiesPlot*\"), file(\"*Helical*\")  into amino_emboss\n\n                        script:\n                            \"\"\"\n                            name=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}')\n                            garnier -sequence ${prot} -outfile \\${name}_2dStructures.garnier\n                            hmoment -seqall ${prot} -graph svg -plot\n                            mv hmoment.svg ./\"\\${name}\"_HydrophobicMoments.svg\n                            iep -sequence ${prot} -graph svg -plot -outfile \"\\${name}\"_IsoelectricPoint.iep\n                            mv iep.svg ./\"\\${name}\"_IsoelectricPoint.svg\n                            pepstats -sequence ${prot} -outfile \\${name}_ProteinProperties.pepstats\n                            grep \">\" ${prot} | awk -F \">\" '{print \\$2}' > tmpsequence.list\n                            for x in \\$(cat tmpsequence.list);do\n                                echo \\$x > tmp1.list\n                                seqtk subseq ${prot} tmp1.list > tmp2.fasta\n                                len=\\$(tail -1 tmp2.fasta | awk '{print length}')\n                                pepinfo -sequence tmp2.fasta -graph svg -outfile \"\\$x\"_PropertiesPlot.pepinfo\n                                mv pepinfo.svg ./\"\\$x\"_PropertiesPlot.svg\n                                cat \"\\$x\"_PropertiesPlot.pepinfo >> \"\\${name}\"_PropertiesPlot.pepinfo\n                                rm \"\\$x\"_PropertiesPlot.pepinfo\n                                pepnet -sask -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepnet.svg ./\"\\$x\"_HelicalNet.svg\n                                pepwheel -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepwheel.svg ./\"\\$x\"_HelicalWheel.svg\n                                rm tmp1.list tmp2.fasta\n                            done\n                            rm tmpsequence.list\n                            \"\"\"\n                    }",
        "nb_lignes_process": 42,
        "string_script": "                            \"\"\"\n                            name=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}')\n                            garnier -sequence ${prot} -outfile \\${name}_2dStructures.garnier\n                            hmoment -seqall ${prot} -graph svg -plot\n                            mv hmoment.svg ./\"\\${name}\"_HydrophobicMoments.svg\n                            iep -sequence ${prot} -graph svg -plot -outfile \"\\${name}\"_IsoelectricPoint.iep\n                            mv iep.svg ./\"\\${name}\"_IsoelectricPoint.svg\n                            pepstats -sequence ${prot} -outfile \\${name}_ProteinProperties.pepstats\n                            grep \">\" ${prot} | awk -F \">\" '{print \\$2}' > tmpsequence.list\n                            for x in \\$(cat tmpsequence.list);do\n                                echo \\$x > tmp1.list\n                                seqtk subseq ${prot} tmp1.list > tmp2.fasta\n                                len=\\$(tail -1 tmp2.fasta | awk '{print length}')\n                                pepinfo -sequence tmp2.fasta -graph svg -outfile \"\\$x\"_PropertiesPlot.pepinfo\n                                mv pepinfo.svg ./\"\\$x\"_PropertiesPlot.svg\n                                cat \"\\$x\"_PropertiesPlot.pepinfo >> \"\\${name}\"_PropertiesPlot.pepinfo\n                                rm \"\\$x\"_PropertiesPlot.pepinfo\n                                pepnet -sask -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepnet.svg ./\"\\$x\"_HelicalNet.svg\n                                pepwheel -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepwheel.svg ./\"\\$x\"_HelicalWheel.svg\n                                rm tmp1.list tmp2.fasta\n                            done\n                            rm tmpsequence.list\n                            \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "garnier",
            "hmoment",
            "iep",
            "pepstats",
            "seqtk",
            "pepinfo",
            "pepnet",
            "pepwheel"
        ],
        "tools_url": [
            "https://bio.tools/garnier",
            "https://bio.tools/hmoment",
            "https://bio.tools/iep",
            "https://bio.tools/pepstats",
            "https://bio.tools/seqtk",
            "https://bio.tools/pepinfo",
            "https://bio.tools/pepnet",
            "https://bio.tools/pepwheel"
        ],
        "tools_dico": [
            {
                "name": "garnier",
                "uri": "https://bio.tools/garnier",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein secondary structure"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein features (secondary structure)"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Protein secondary structure prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Secondary structure prediction (protein)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1277",
                                "term": "Protein features"
                            }
                        ]
                    }
                ],
                "description": "Predict protein secondary structure using GOR method.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/garnier.html"
            },
            {
                "name": "hmoment",
                "uri": "https://bio.tools/hmoment",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2574",
                                    "term": "Protein hydropathy calculation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1520",
                                "term": "Peptide hydrophobic moment"
                            }
                        ]
                    }
                ],
                "description": "Calculate and plot hydrophobic moment for protein sequence(s).",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/hmoment.html"
            },
            {
                "name": "iep",
                "uri": "https://bio.tools/iep",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0403",
                                    "term": "Protein isoelectric point calculation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1528",
                                "term": "Protein isoelectric point"
                            }
                        ]
                    }
                ],
                "description": "Calculate the isoelectric point of proteins.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/iep.html"
            },
            {
                "name": "pepstats",
                "uri": "https://bio.tools/pepstats",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property rendering"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_1505",
                                "term": "Amino acid index (molecular weight)"
                            },
                            {
                                "uri": "http://edamontology.org/data_1502",
                                "term": "Amino acid index (chemical classes)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0897",
                                "term": "Protein property"
                            }
                        ]
                    }
                ],
                "description": "Calculate statistics of protein properties.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepstats.html"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            },
            {
                "name": "pepinfo",
                "uri": "https://bio.tools/pepinfo",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property rendering"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_1506",
                                "term": "Amino acid index (hydropathy)"
                            },
                            {
                                "uri": "http://edamontology.org/data_1502",
                                "term": "Amino acid index (chemical classes)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1522",
                                "term": "Protein sequence hydropathy plot"
                            },
                            {
                                "uri": "http://edamontology.org/data_0897",
                                "term": "Protein property"
                            }
                        ]
                    }
                ],
                "description": "Plot amino acid properties of a protein sequence in parallel.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepinfo.html"
            },
            {
                "name": "pepnet",
                "uri": "https://bio.tools/pepnet",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2574",
                                    "term": "Protein hydropathy calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0319",
                                    "term": "Protein secondary structure assignment"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2163",
                                "term": "Helical net"
                            }
                        ]
                    }
                ],
                "description": "Draw a helical net for a protein sequence.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepnet.html"
            },
            {
                "name": "pepwheel",
                "uri": "https://bio.tools/pepwheel",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Protein secondary structure prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Secondary structure prediction (protein)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2162",
                                "term": "Helical wheel"
                            }
                        ]
                    }
                ],
                "description": "Draw a helical wheel diagram for a protein sequence.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepwheel.html"
            }
        ],
        "inputs": [
            "aminotypesEmboss"
        ],
        "nb_inputs": 1,
        "outputs": [
            "amino_emboss"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/2dStructure\", mode: \"copy\", overwrite: true, pattern: '*.{garnier}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/HydrophobicMoment\", mode: \"copy\", overwrite: true, pattern: '*HydrophobicMoments.{svg}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/IsoelectricPoint\", mode: \"copy\", overwrite: true, pattern: '*IsoelectricPoint.{iep,svg}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/ProteinProperties\", mode: \"copy\", overwrite: true, pattern: '*.{pepstats,pepinfo}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/ProteinProperties/Plots\", mode: \"copy\", overwrite: true, pattern: '*PropertiesPlot.{svg}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/EMBOSS/2dStructure/Plots\", mode: \"copy\", overwrite: true, pattern: '*Helical*.{svg}'"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_Taxonomy_Inference_NCBI": {
        "name_process": "AminoType_Taxonomy_Inference_NCBI",
        "string_process": " process AminoType_Taxonomy_Inference_NCBI {\n\n                        label 'high_cpus'\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*TaxonomyLabels.fasta'\n\n                        input:\n                            file(asvs) from aminotypesBlast\n\n                        output:\n                            tuple file(\"*_phyloformat.csv\"), file(\"*_summaryTable.tsv\"), file(\"*dmd.out\") into summary_AA_diamond\n                            file(\"*_summary_for_plot.csv\") into taxplot2\n                            file(\"*TaxonomyLabels.fasta\") into tax_labeled_fasta2\n                            file(\"*_quick_Taxbreakdown.csv\") into tax_table_amino\n                            file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_amino\n\n                        script:\n                            \"\"\"\n                            cp ${params.vampdir}/bin/rename_seq.py .\n                            virdb=${params.dbdir}/${params.dbname}\n                            if [[ ${params.measurement} == \"bitscore\" ]]\n                            then    measure=\"--min-score ${params.bitscore}\"\n                            elif    [[ ${params.measurement} == \"evalue\" ]]\n                            then    measure=\"-e ${params.evalue}\"\n                            else    measure=\"--min-score ${params.bitscore}\"\n                            fi\n                            grep \">\" \\${virdb} > headers.list\n                            headers=\"headers.list\"\n                            name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                            else   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                            fi\n                            echo \"Preparing lists to generate summary .csv's\"\n                            echo \"[Best hit accession number]\" > access.list\n                            echo \"[e-value]\" > evalue.list\n                            echo \"[Bitscore]\" > bit.list\n                            echo \"[Percent ID (aa)]\" > pid.list\n                            echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                            echo \"[Gene]\" > \"\\$name\"_genes.list\n                            echo \"[AminoType#]\" > otu.list\n                            echo \"[Sequence length]\" > length.list\n                            grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                            if [[ ${params.lca} == \"T\" ]]\n                            then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            else\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            fi\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                            fi\n                            echo \"extracting genes and names\"\n                            touch new_\"\\$name\"_asvnames.txt\n                            for s in \\$(cat seqids.lst);do\n                                echo \"Checking for \\$s hit in diamond output\"\n                                if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                            echo \"Yep, there was a hit for \\$s\"\n                                            echo \"Extracting the information now:\"\n                                            acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"\\$acc\" >> access.list\n                                            line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                            echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                            echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                            echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                            echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                            echo \"Extracting virus and gene ID for \\$s now\"\n                                            gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                            echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                            virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                            echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                            echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                    then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                          lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\\\t\" '{print \\$2}')\n                                                          echo \"\\$lcla\" >> lca_classification.list\n                                                    else  echo \"Viruses\" >> lca_classification.list\n                                                    fi\n                                            fi\n                                            if [[ ${params.ncbitax} == \"true\" ]]\n                                            then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                                else\n                                            echo \"Ugh, there was no hit for \\$s ..\"\n                                            echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"NO_HIT\" >> access.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                            echo \"NO_HIT\" >> evalue.list\n                                            echo \"NO_HIT\" >> bit.list\n                                            echo \"NO_HIT\" >> pid.list\n                                            echo \"NO_HIT\" >> length.list\n                                            virus=\"NO\"\n                                            gene=\"HIT\"\n                                            echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    echo \"N/A\" >> lca_classification.list\n                                            fi\n                                            if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                            then  echo \"N/A\" >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                               fi\n                            done\n                            echo \"Now editing \"\\$name\" fasta headers\"\n                            ###### rename_seq.py\n                            ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                            awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                            echo \"[Sequence header]\" > newnames.list\n                            cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                            touch sequence.list\n                            echo \"     \" > sequence.list\n                            grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                            rm \"\\$name\"_tmpssasv.fasta\n                            if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            else\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            fi\n                            for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                            done\n                            awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                            rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                            \"\"\"\n                        }",
        "nb_lignes_process": 149,
        "string_script": "                            \"\"\"\n                            cp ${params.vampdir}/bin/rename_seq.py .\n                            virdb=${params.dbdir}/${params.dbname}\n                            if [[ ${params.measurement} == \"bitscore\" ]]\n                            then    measure=\"--min-score ${params.bitscore}\"\n                            elif    [[ ${params.measurement} == \"evalue\" ]]\n                            then    measure=\"-e ${params.evalue}\"\n                            else    measure=\"--min-score ${params.bitscore}\"\n                            fi\n                            grep \">\" \\${virdb} > headers.list\n                            headers=\"headers.list\"\n                            name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                            else   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                            fi\n                            echo \"Preparing lists to generate summary .csv's\"\n                            echo \"[Best hit accession number]\" > access.list\n                            echo \"[e-value]\" > evalue.list\n                            echo \"[Bitscore]\" > bit.list\n                            echo \"[Percent ID (aa)]\" > pid.list\n                            echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                            echo \"[Gene]\" > \"\\$name\"_genes.list\n                            echo \"[AminoType#]\" > otu.list\n                            echo \"[Sequence length]\" > length.list\n                            grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                            if [[ ${params.lca} == \"T\" ]]\n                            then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            else\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            fi\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                            fi\n                            echo \"extracting genes and names\"\n                            touch new_\"\\$name\"_asvnames.txt\n                            for s in \\$(cat seqids.lst);do\n                                echo \"Checking for \\$s hit in diamond output\"\n                                if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                            echo \"Yep, there was a hit for \\$s\"\n                                            echo \"Extracting the information now:\"\n                                            acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"\\$acc\" >> access.list\n                                            line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                            echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                            echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                            echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                            echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                            echo \"Extracting virus and gene ID for \\$s now\"\n                                            gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                            echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                            virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                            echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                            echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                    then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                          lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\\\t\" '{print \\$2}')\n                                                          echo \"\\$lcla\" >> lca_classification.list\n                                                    else  echo \"Viruses\" >> lca_classification.list\n                                                    fi\n                                            fi\n                                            if [[ ${params.ncbitax} == \"true\" ]]\n                                            then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                                else\n                                            echo \"Ugh, there was no hit for \\$s ..\"\n                                            echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"NO_HIT\" >> access.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                            echo \"NO_HIT\" >> evalue.list\n                                            echo \"NO_HIT\" >> bit.list\n                                            echo \"NO_HIT\" >> pid.list\n                                            echo \"NO_HIT\" >> length.list\n                                            virus=\"NO\"\n                                            gene=\"HIT\"\n                                            echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    echo \"N/A\" >> lca_classification.list\n                                            fi\n                                            if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                            then  echo \"N/A\" >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                               fi\n                            done\n                            echo \"Now editing \"\\$name\" fasta headers\"\n                            ###### rename_seq.py\n                            ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                            awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                            echo \"[Sequence header]\" > newnames.list\n                            cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                            touch sequence.list\n                            echo \"     \" > sequence.list\n                            grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                            rm \"\\$name\"_tmpssasv.fasta\n                            if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            else\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            fi\n                            for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                            done\n                            awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                            rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                            \"\"\"",
        "nb_lignes_script": 131,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "aminotypesBlast"
        ],
        "nb_inputs": 1,
        "outputs": [
            "summary_AA_diamond",
            "taxplot2",
            "tax_labeled_fasta2",
            "tax_table_amino",
            "tax_nodCol_amino"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*TaxonomyLabels.fasta'"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_Taxonomy_Inference_RVDB": {
        "name_process": "AminoType_Taxonomy_Inference_RVDB",
        "string_process": " process AminoType_Taxonomy_Inference_RVDB {\n\n                          label 'high_cpus'\n\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*TaxonomyLabels.fasta'\n\n                          input:\n                              file(asvs) from aminotypesBlast\n\n                          output:\n                              tuple file(\"*_phyloformat.csv\"), file(\"*_summaryTable.tsv\"), file(\"*dmd.out\") into summary_AA_diamond\n                              file(\"*_summary_for_plot.csv\") into taxplot2\n                              file(\"*TaxonomyLabels.fasta\") into tax_labeled_fasta2\n                              file(\"*_quick_Taxbreakdown.csv\") into tax_table_amino\n                              file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_amino\n\n                          script:\n                              \"\"\"\n                              cp ${params.vampdir}/bin/rename_seq.py .\n                              virdb=${params.dbdir}/${params.dbname}\n                              if [[ ${params.measurement} == \"bitscore\" ]]\n                              then    measure=\"--min-score ${params.bitscore}\"\n                              elif    [[ ${params.measurement} == \"evalue\" ]]\n                              then    measure=\"-e ${params.evalue}\"\n                              else    measure=\"--min-score ${params.bitscore}\"\n                              fi\n                              grep \">\" \\${virdb} > headers.list\n                              headers=\"headers.list\"\n                              name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                              diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                              echo \"Preparing lists to generate summary .csv's\"\n                              echo \"[Best hit accession number]\" > access.list\n                              echo \"[e-value]\" > evalue.list\n                              echo \"[Bitscore]\" > bit.list\n                              echo \"[Percent ID (aa)]\" > pid.list\n                              echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                              echo \"[Gene]\" > \"\\$name\"_genes.list\n                              echo \"[AminoType#]\" > otu.list\n                              echo \"[Sequence length]\" > length.list\n                              grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                              if [[ ${params.lca} == \"T\" ]]\n                              then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              fi\n                              echo \"extracting genes and names\"\n                              touch new_\"\\$name\"_asvnames.txt\n                              for s in \\$(cat seqids.lst);do\n                                  echo \"Using RVDB headers.\"\n                                  if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                      echo \"Yep, there was a hit for \\$s\"\n                                      echo \"Extracting the information now:\"\n                                      acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"\\$acc\" >> access.list\n                                      line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                      echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                      echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                      echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                      echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                      echo \"Extracting virus and gene ID for \\$s now\"\n                                      gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                      echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                      virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                      echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                              then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                    lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                    echo \"\\$lcla\" >> lca_classification.list\n                                              else  echo \"Viruses\" >> lca_classification.list\n                                              fi\n                                      fi\n                                      echo \"\\$s done.\"\n                                  else\n                                      echo \"Ugh, there was no hit for \\$s ..\"\n                                      echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"NO_HIT\" >> access.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                      echo \"NO_HIT\" >> evalue.list\n                                      echo \"NO_HIT\" >> bit.list\n                                      echo \"NO_HIT\" >> pid.list\n                                      echo \"NO_HIT\" >> length.list\n                                      virus=\"NO\"\n                                      gene=\"HIT\"\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    echo \"N/A\" >> lca_classification.list\n                                      fi\n                                      echo \"\\$s done.\"\n                                  fi\n                              echo \"Done with \\$s\"\n                              done\n                              echo \"Now editing \"\\$name\" fasta headers\"\n                              ###### rename_seq.py\n                              ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                              awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                              echo \"[Sequence header]\" > newnames.list\n                              cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                              touch sequence.list\n                              echo \"     \" > sequence.list\n                              grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                              rm \"\\$name\"_tmpssasv.fasta\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                    paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                              else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              fi\n                              for x in *phyloformat.csv;do\n                                        echo \"\\$x\"\n                                        lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                        tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                        sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                        cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                        rm tmpcol.list tmp2col.list\n                              done\n                              awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                              rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                              \"\"\"\n                    }",
        "nb_lignes_process": 125,
        "string_script": "                              \"\"\"\n                              cp ${params.vampdir}/bin/rename_seq.py .\n                              virdb=${params.dbdir}/${params.dbname}\n                              if [[ ${params.measurement} == \"bitscore\" ]]\n                              then    measure=\"--min-score ${params.bitscore}\"\n                              elif    [[ ${params.measurement} == \"evalue\" ]]\n                              then    measure=\"-e ${params.evalue}\"\n                              else    measure=\"--min-score ${params.bitscore}\"\n                              fi\n                              grep \">\" \\${virdb} > headers.list\n                              headers=\"headers.list\"\n                              name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                              diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                              echo \"Preparing lists to generate summary .csv's\"\n                              echo \"[Best hit accession number]\" > access.list\n                              echo \"[e-value]\" > evalue.list\n                              echo \"[Bitscore]\" > bit.list\n                              echo \"[Percent ID (aa)]\" > pid.list\n                              echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                              echo \"[Gene]\" > \"\\$name\"_genes.list\n                              echo \"[AminoType#]\" > otu.list\n                              echo \"[Sequence length]\" > length.list\n                              grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                              if [[ ${params.lca} == \"T\" ]]\n                              then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              fi\n                              echo \"extracting genes and names\"\n                              touch new_\"\\$name\"_asvnames.txt\n                              for s in \\$(cat seqids.lst);do\n                                  echo \"Using RVDB headers.\"\n                                  if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                      echo \"Yep, there was a hit for \\$s\"\n                                      echo \"Extracting the information now:\"\n                                      acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"\\$acc\" >> access.list\n                                      line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                      echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                      echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                      echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                      echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                      echo \"Extracting virus and gene ID for \\$s now\"\n                                      gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                      echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                      virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                      echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                              then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                    lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                    echo \"\\$lcla\" >> lca_classification.list\n                                              else  echo \"Viruses\" >> lca_classification.list\n                                              fi\n                                      fi\n                                      echo \"\\$s done.\"\n                                  else\n                                      echo \"Ugh, there was no hit for \\$s ..\"\n                                      echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"NO_HIT\" >> access.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                      echo \"NO_HIT\" >> evalue.list\n                                      echo \"NO_HIT\" >> bit.list\n                                      echo \"NO_HIT\" >> pid.list\n                                      echo \"NO_HIT\" >> length.list\n                                      virus=\"NO\"\n                                      gene=\"HIT\"\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    echo \"N/A\" >> lca_classification.list\n                                      fi\n                                      echo \"\\$s done.\"\n                                  fi\n                              echo \"Done with \\$s\"\n                              done\n                              echo \"Now editing \"\\$name\" fasta headers\"\n                              ###### rename_seq.py\n                              ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                              awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                              echo \"[Sequence header]\" > newnames.list\n                              cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                              touch sequence.list\n                              echo \"     \" > sequence.list\n                              grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                              rm \"\\$name\"_tmpssasv.fasta\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                    paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                              else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              fi\n                              for x in *phyloformat.csv;do\n                                        echo \"\\$x\"\n                                        lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                        tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                        sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                        cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                        rm tmpcol.list tmp2col.list\n                              done\n                              awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                              rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                              \"\"\"",
        "nb_lignes_script": 107,
        "language_script": "bash",
        "tools": [
            "Diamond"
        ],
        "tools_url": [
            "https://bio.tools/diamond"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            }
        ],
        "inputs": [
            "aminotypesBlast"
        ],
        "nb_inputs": 1,
        "outputs": [
            "summary_AA_diamond",
            "taxplot2",
            "tax_labeled_fasta2",
            "tax_table_amino",
            "tax_nodCol_amino"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*TaxonomyLabels.fasta'"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_Phylogeny": {
        "name_process": "AminoType_Phylogeny",
        "string_process": " process AminoType_Phylogeny {\n\n                        label 'norm_cpus'\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*aln.*'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Phylogeny/Modeltest\", mode: \"copy\", overwrite: true, pattern: '*mt*'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'\n\n                        input:\n                            file(prot) from aminotypesMafft\n\n                        output:\n                            tuple file(\"*_aln.fasta\"), file(\"*_aln.html\"), file(\"*.log\"), file(\"*iq*\"), file(\"*mt*\") into alignprot_results\n                            file(\"*iq.treefile\") into (amino_rax_plot, amino_repphy, amino_treeclust)\n\n                        script:\n                            \"\"\"\n                            # Protein_Alignment\n                            pre=\\$(echo ${prot} | awk -F \"_noTax\" '{print \\$1}' )\n                            if [[ \\$(grep -c \">\" ${prot}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                            ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${prot} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                            trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                            o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                            mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                            # Protein_ModelTest\n                            modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d aa -s 203 --disable-checkpoint\n\n                            # Protein_Phylogeny\n                            if [ \"${params.iqCustomaa}\" != \"\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -T auto ${params.iqCustomaa}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            else\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"\n                    }",
        "nb_lignes_process": 47,
        "string_script": "                            \"\"\"\n                            # Protein_Alignment\n                            pre=\\$(echo ${prot} | awk -F \"_noTax\" '{print \\$1}' )\n                            if [[ \\$(grep -c \">\" ${prot}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                            ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${prot} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                            trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                            o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                            mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                            # Protein_ModelTest\n                            modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d aa -s 203 --disable-checkpoint\n\n                            # Protein_Phylogeny\n                            if [ \"${params.iqCustomaa}\" != \"\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -T auto ${params.iqCustomaa}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            else\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "trimAl",
            "ModelTest-NG"
        ],
        "tools_url": [
            "https://bio.tools/trimal",
            "https://bio.tools/ModelTest-NG"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            },
            {
                "name": "ModelTest-NG",
                "uri": "https://bio.tools/ModelTest-NG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3293",
                            "term": "Phylogenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3316",
                            "term": "Computer science"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A new and scalable tool for the selection of DNA and protein evolutionary models | ModelTest-NG is a tool for selecting the best-fit model of evolution for DNA and protein alignments. ModelTest-NG supersedes jModelTest and ProtTest in one single tool, with graphical and command console interfaces",
                "homepage": "https://github.com/ddarriba/modeltest"
            }
        ],
        "inputs": [
            "aminotypesMafft"
        ],
        "nb_inputs": 1,
        "outputs": [
            "alignprot_results",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*aln.*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Phylogeny/Modeltest\", mode: \"copy\", overwrite: true, pattern: '*mt*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_AminoTypes_Counts_Table": {
        "name_process": "Generate_AminoTypes_Counts_Table",
        "string_process": " process Generate_AminoTypes_Counts_Table {\n\n                    label 'high_cpus'\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Counts\", mode: \"copy\", overwrite: true\n\n                    input:\n                        file(fasta) from aminotypesCounts\n                        file(merged) from mergeforprotcounts\n                        file(samplist) from samplelist\n\n                    output:\n                        tuple file(\"*_AminoType_counts.csv\"), file(\"*dmd.out\") into counts_summary\n                        file(\"*_AminoType_counts.csv\") into (aminocounts_plot, aminocountmed, amino_countphylo)\n\n                    script:\n                        \"\"\"\n                        set +e\n                        diamond makedb --in ${fasta} --db ${fasta}\n                        diamond blastx -q ${merged} -d ${fasta} -p ${task.cpus} --min-score ${params.ProtCountsBit} --id ${params.ProtCountID} -l ${params.ProtCountsLength} --${params.sensitivity} -o ${params.projtag}_protCounts_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1 --max-hsps 1\n                        echo \"OTU_ID\" >tmp.col1.txt\n                        echo \"Generating sample id list\"\n                        grep \">\" ${fasta} | awk -F \">\" '{print \\$2}' | sort | uniq > otuid.list\n                        cat otuid.list >> tmp.col1.txt\n                        echo \"Beginning them counts tho my g\"\n                        for y in \\$( cat ${samplist} );do\n                            echo \"Starting with \\$y now ...\"\n                            grep \"\\$y\" ${params.projtag}_protCounts_dmd.out > tmp.\"\\$y\".out\n                            echo \"Isolated hits\"\n                            echo \"Created uniq subject id list\"\n                            echo \"\\$y\" > \"\\$y\"_col.txt\n                            echo \"Starting my counts\"\n                            for z in \\$(cat otuid.list);do\n                                echo \"Counting \\$z hits\"\n                \t            echo \"grep -wc \"\\$z\" >> \"\\$y\"_col.txt\"\n                \t            grep -wc \"\\$z\" tmp.\"\\$y\".out >> \"\\$y\"_col.txt\n            \t\t            echo \"\\$z counted\"\n            \t            done\n                       done\n                       paste -d \",\" tmp.col1.txt *col.txt > ${params.projtag}_AminoType_counts.csv\n                       rm tmp*\n                       rm *col.txt\n                       \"\"\"\n                }",
        "nb_lignes_process": 42,
        "string_script": "                        \"\"\"\n                        set +e\n                        diamond makedb --in ${fasta} --db ${fasta}\n                        diamond blastx -q ${merged} -d ${fasta} -p ${task.cpus} --min-score ${params.ProtCountsBit} --id ${params.ProtCountID} -l ${params.ProtCountsLength} --${params.sensitivity} -o ${params.projtag}_protCounts_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1 --max-hsps 1\n                        echo \"OTU_ID\" >tmp.col1.txt\n                        echo \"Generating sample id list\"\n                        grep \">\" ${fasta} | awk -F \">\" '{print \\$2}' | sort | uniq > otuid.list\n                        cat otuid.list >> tmp.col1.txt\n                        echo \"Beginning them counts tho my g\"\n                        for y in \\$( cat ${samplist} );do\n                            echo \"Starting with \\$y now ...\"\n                            grep \"\\$y\" ${params.projtag}_protCounts_dmd.out > tmp.\"\\$y\".out\n                            echo \"Isolated hits\"\n                            echo \"Created uniq subject id list\"\n                            echo \"\\$y\" > \"\\$y\"_col.txt\n                            echo \"Starting my counts\"\n                            for z in \\$(cat otuid.list);do\n                                echo \"Counting \\$z hits\"\n                \t            echo \"grep -wc \"\\$z\" >> \"\\$y\"_col.txt\"\n                \t            grep -wc \"\\$z\" tmp.\"\\$y\".out >> \"\\$y\"_col.txt\n            \t\t            echo \"\\$z counted\"\n            \t            done\n                       done\n                       paste -d \",\" tmp.col1.txt *col.txt > ${params.projtag}_AminoType_counts.csv\n                       rm tmp*\n                       rm *col.txt\n                       \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [
            "Diamond"
        ],
        "tools_url": [
            "https://bio.tools/diamond"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            }
        ],
        "inputs": [
            "aminotypesCounts",
            "mergeforprotcounts",
            "samplelist"
        ],
        "nb_inputs": 3,
        "outputs": [
            "counts_summary",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/Counts\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_PhyloClustering": {
        "name_process": "AminoType_PhyloClustering",
        "string_process": " process AminoType_PhyloClustering {\n\n                      label 'norm_cpus'\n\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/TreeCluster\", mode: \"copy\", overwrite: true\n\n                      input:\n                         file(tree) from amino_treeclust\n                         file(counts) from amino_countphylo\n                      output:\n                         file(\"*treeclustering*.out\") into aminotreeclustering_res\n                         file(\"${params.projtag}_amino_phylogroup.csv\") into amino_phylogroupcsv\n                         file(\"${params.projtag}_amino_phyloGroupingcounts.csv\") into amino_phylogroupingcsv\n\n                      script:\n                          \"\"\"\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_AminoType_treeclustering.out\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_AminoType_treeclustering_verbose.out\n                          #create headless treeclustering.out\n                          tail -n +2 ${params.projtag}_AminoType_treeclustering.out | sed 's/-1/0X/g' > headless.treeout\n                          #extracting singletons\n                          grep -w \"0X\" headless.treeout > single.out\n                          awk -F \"\\\\t\" '{print \\$1}' single.out > single.list\n                          #assigning groupID to singletons\n                          for x in \\$(awk -F \"\\\\t\" '{print \\$1}' single.out); do echo \"\"\\$x\"XX\" >> single.groups;done\n                          #summarizing clustering results\n                          awk -F \"\\\\t\" '{print \\$2}' headless.treeout | grep -v \"0X\" | sort | uniq > grp.list\n                          cat single.groups >> group.list\n                          cat grp.list >> group.list\n                          echo \"Sequence_ID,phyloGroup_ID\" > ${params.projtag}_amino_phylogroup.csv\n\n                          for x in \\$(seq \"\\$(wc -l group.list | awk '{print \\$1}')\");\n                          do      echo \"phyloGroup\"\\$x\"\" >> grup.list\n                          done\n                          paste -d \",\" grup.list group.list > groups.csv\n                          rm grup.list group.list\n                          awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > asv.list\n                          for z in \\$(cat asv.list);\n                          do      if [[ \\$(grep -wc \"\\$z\" single.list) -ge 1 ]]\n                                  then\n                                          group=\\$(grep -w \"\"\\$z\"XX\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  else\n                                          grp=\\$(grep -w \"\\$z\" headless.treeout | awk -F \"\\\\t\" '{print \\$2}')\n                                          group=\\$(grep -w \"\\$grp\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  fi\n                                  echo \"\"\\$z\",\"\\$group\"\" >> ${params.projtag}_amino_phylogroup.csv\n                          done\n                          awk -F \",\" '{print \\$2}' ${params.projtag}_amino_phylogroup.csv > groups.list\n                          paste -d\",\" groups.list ${counts} > ${params.projtag}_amino_phyloGroupingcounts.csv\n                         \"\"\"\n                     }",
        "nb_lignes_process": 49,
        "string_script": "                          \"\"\"\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_AminoType_treeclustering.out\n                          TreeCluster.py -i ${tree} ${params.asvTCopp} > ${params.projtag}_AminoType_treeclustering_verbose.out\n                          #create headless treeclustering.out\n                          tail -n +2 ${params.projtag}_AminoType_treeclustering.out | sed 's/-1/0X/g' > headless.treeout\n                          #extracting singletons\n                          grep -w \"0X\" headless.treeout > single.out\n                          awk -F \"\\\\t\" '{print \\$1}' single.out > single.list\n                          #assigning groupID to singletons\n                          for x in \\$(awk -F \"\\\\t\" '{print \\$1}' single.out); do echo \"\"\\$x\"XX\" >> single.groups;done\n                          #summarizing clustering results\n                          awk -F \"\\\\t\" '{print \\$2}' headless.treeout | grep -v \"0X\" | sort | uniq > grp.list\n                          cat single.groups >> group.list\n                          cat grp.list >> group.list\n                          echo \"Sequence_ID,phyloGroup_ID\" > ${params.projtag}_amino_phylogroup.csv\n\n                          for x in \\$(seq \"\\$(wc -l group.list | awk '{print \\$1}')\");\n                          do      echo \"phyloGroup\"\\$x\"\" >> grup.list\n                          done\n                          paste -d \",\" grup.list group.list > groups.csv\n                          rm grup.list group.list\n                          awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > asv.list\n                          for z in \\$(cat asv.list);\n                          do      if [[ \\$(grep -wc \"\\$z\" single.list) -ge 1 ]]\n                                  then\n                                          group=\\$(grep -w \"\"\\$z\"XX\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  else\n                                          grp=\\$(grep -w \"\\$z\" headless.treeout | awk -F \"\\\\t\" '{print \\$2}')\n                                          group=\\$(grep -w \"\\$grp\" groups.csv | awk -F \",\" '{print \\$1}')\n                                  fi\n                                  echo \"\"\\$z\",\"\\$group\"\" >> ${params.projtag}_amino_phylogroup.csv\n                          done\n                          awk -F \",\" '{print \\$2}' ${params.projtag}_amino_phylogroup.csv > groups.list\n                          paste -d\",\" groups.list ${counts} > ${params.projtag}_amino_phyloGroupingcounts.csv\n                         \"\"\"",
        "nb_lignes_script": 34,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "amino_treeclust",
            "amino_countphylo"
        ],
        "nb_inputs": 2,
        "outputs": [
            "aminotreeclustering_res",
            "amino_phylogroupcsv",
            "amino_phylogroupingcsv"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/TreeCluster\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_Minimum_Entropy_Decomposition": {
        "name_process": "AminoType_Minimum_Entropy_Decomposition",
        "string_process": " process AminoType_Minimum_Entropy_Decomposition {\n\n                    label 'low_cpus'\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/MED\", mode: \"copy\", overwrite: true\n\n                    input:\n                        file(aminos) from aminos_for_med\n\n                    output:\n                        file(\"*_AminoType_Grouping.csv\") into atygroupscsv\n                        file(\"${params.projtag}_AminoType_group_reps_aligned.fasta\") into atygroupreps\n\n                    script:\n                    \"\"\"\n                    #alignment\n                    if [[ \\$(grep -c \">\" ${aminos}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                    ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${aminos} -out ${params.projtag}_AminoTypes_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_AminoTypes_muscleAlign.fasta -out ${params.projtag}_AminoTypes_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_AminoTypes_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_AminoTypes_muscleAligned.fasta\n                    mv ${params.projtag}_AminoTypes_muscleAligned.fasta-TRIMMED ./${params.projtag}_AminoTypes_Aligned_informativeonly.fasta\n                    #entopy analysis\n                    entropy-analysis ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta\n                    #Decomposition\n                    if [[ \\$(echo ${params.aminoC} | grep -c \",\") -gt 0 ]]\n                    then\n                          tag=\\$(echo ${params.aminoC} | sed 's/,/_/g')\n                          oligotype ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_AminoTypeMED_\"\\$tag\" -M 1 -C ${params.aminoC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    elif [[ \"${params.aminoSingle}\" == \"true\" ]]\n                    then\n                          tag=\"${params.aminoC}\"\n                          oligotype ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_AminoTypeMED_\"\\$tag\" -M 1 -C ${params.aminoC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    else\n                          oligotype ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_AminoTypeMED_${params.aminoC} -M 1 -c ${params.aminoC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    fi\n                    #generatemaps\n                    cd ./${params.projtag}_AminoTypeMED_${params.aminoC}/OLIGO-REPRESENTATIVES/\n                    echo \"AminoType,Group,IDPattern\"\n                    j=1\n                    for x in *_unique;\n                    do      gid=\\$(echo \\$x | awk -F \"_\" '{print \\$1}')\n                            uni=\\$(echo \\$x | awk -F \"\"\\${gid}\"_\" '{print \\$2}' | awk -F \"_uni\" '{print \\$1}')\n                            grep \">\"  \"\\$gid\"_\"\\$uni\" | awk -F \">\" '{print \\$2}' > asv.list\n                            seqtk subseq ../../${aminos} asv.list > Group\"\\${j}\"_sequences.fasta\n                            for z in \\$( cat asv.list)\n                            do      echo \"\"\\$z\",Group\"\\$j\",\"\\$uni\"\" >> ${params.projtag}_AminoType_Grouping.csv\n\n                            done\n                            rm asv.list\n                            echo \">Group\\${j}\" >> ${params.projtag}_AminoType_group_reps_aligned.fasta\n                            echo \"\\$uni\" > group.list\n                            seqtk subseq ../OLIGO-REPRESENTATIVES.fasta group.list > group.fasta\n                            tail -1 group.fasta >> ${params.projtag}_AminoType_group_reps_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\" ./Group\"\\$j\"_\"\\$uni\"_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\"_unique ./Group\"\\$j\"_\"\\$uni\"_unqiues_aligned.fasta\n                            rm \"\\$gid\"*.cPickle\n                            j=\\$((\\$j+1))\n                    done\n                    mv ${params.projtag}_AminoType_Grouping.csv ../../\n                    mv ${params.projtag}_AminoType_group_reps_aligned.fasta ../../\n                    cd ..\n\n                    \"\"\"\n                    }",
        "nb_lignes_process": 64,
        "string_script": "                    \"\"\"\n                    #alignment\n                    if [[ \\$(grep -c \">\" ${aminos}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                    ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${aminos} -out ${params.projtag}_AminoTypes_muscleAlign.fasta -threads ${task.cpus} -quiet\n                    #trimming\n                    trimal -in ${params.projtag}_AminoTypes_muscleAlign.fasta -out ${params.projtag}_AminoTypes_muscleAligned.fasta  -keepheader -fasta -automated1\n                    rm ${params.projtag}_AminoTypes_muscleAlign.fasta\n                    o-trim-uninformative-columns-from-alignment ${params.projtag}_AminoTypes_muscleAligned.fasta\n                    mv ${params.projtag}_AminoTypes_muscleAligned.fasta-TRIMMED ./${params.projtag}_AminoTypes_Aligned_informativeonly.fasta\n                    #entopy analysis\n                    entropy-analysis ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta\n                    #Decomposition\n                    if [[ \\$(echo ${params.aminoC} | grep -c \",\") -gt 0 ]]\n                    then\n                          tag=\\$(echo ${params.aminoC} | sed 's/,/_/g')\n                          oligotype ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_AminoTypeMED_\"\\$tag\" -M 1 -C ${params.aminoC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    elif [[ \"${params.aminoSingle}\" == \"true\" ]]\n                    then\n                          tag=\"${params.aminoC}\"\n                          oligotype ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_AminoTypeMED_\"\\$tag\" -M 1 -C ${params.aminoC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    else\n                          oligotype ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta ${params.projtag}_AminoTypes_Aligned_informativeonly.fasta-ENTROPY -o ${params.projtag}_AminoTypeMED_${params.aminoC} -M 1 -c ${params.aminoC} -N ${task.cpus} --skip-check-input --no-figures --skip-gen-html\n                    fi\n                    #generatemaps\n                    cd ./${params.projtag}_AminoTypeMED_${params.aminoC}/OLIGO-REPRESENTATIVES/\n                    echo \"AminoType,Group,IDPattern\"\n                    j=1\n                    for x in *_unique;\n                    do      gid=\\$(echo \\$x | awk -F \"_\" '{print \\$1}')\n                            uni=\\$(echo \\$x | awk -F \"\"\\${gid}\"_\" '{print \\$2}' | awk -F \"_uni\" '{print \\$1}')\n                            grep \">\"  \"\\$gid\"_\"\\$uni\" | awk -F \">\" '{print \\$2}' > asv.list\n                            seqtk subseq ../../${aminos} asv.list > Group\"\\${j}\"_sequences.fasta\n                            for z in \\$( cat asv.list)\n                            do      echo \"\"\\$z\",Group\"\\$j\",\"\\$uni\"\" >> ${params.projtag}_AminoType_Grouping.csv\n\n                            done\n                            rm asv.list\n                            echo \">Group\\${j}\" >> ${params.projtag}_AminoType_group_reps_aligned.fasta\n                            echo \"\\$uni\" > group.list\n                            seqtk subseq ../OLIGO-REPRESENTATIVES.fasta group.list > group.fasta\n                            tail -1 group.fasta >> ${params.projtag}_AminoType_group_reps_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\" ./Group\"\\$j\"_\"\\$uni\"_aligned.fasta\n                            mv \"\\$gid\"_\"\\$uni\"_unique ./Group\"\\$j\"_\"\\$uni\"_unqiues_aligned.fasta\n                            rm \"\\$gid\"*.cPickle\n                            j=\\$((\\$j+1))\n                    done\n                    mv ${params.projtag}_AminoType_Grouping.csv ../../\n                    mv ${params.projtag}_AminoType_group_reps_aligned.fasta ../../\n                    cd ..\n\n                    \"\"\"",
        "nb_lignes_script": 50,
        "language_script": "bash",
        "tools": [
            "trimAl",
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/trimal",
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "aminos_for_med"
        ],
        "nb_inputs": 1,
        "outputs": [
            "atygroupscsv",
            "atygroupreps"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/AminoTypes/MED\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "AminoType_MED_Reps_phylogeny": {
        "name_process": "AminoType_MED_Reps_phylogeny",
        "string_process": " process AminoType_MED_Reps_phylogeny {\n\n                        label 'low_cpus'\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/MED/Phylogeny/Modeltest\", mode: \"copy\", overwrite: true, pattern: '*mt*'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/MED/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'\n\n                        input:\n                          file(reps) from atygroupreps\n\n                        output:\n                          file(\"*_AminoType_Group_Reps*\") into align_results_aminmed\n                          file(\"*iq.treefile\") into amino_group_rep_tree\n\n                        script:\n                            \"\"\"\n                            # Protein_ModelTest\n                            modeltest-ng -i ${reps} -p ${task.cpus} -o ${params.projtag}_AminoType_Group_Reps_mt -d aa -s 203 --disable-checkpoint\n\n                            # Protein_Phylogeny\n                            if [ \"${params.iqCustomaa}\" != \"\" ];then\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq --redo -T auto ${params.iqCustomaa}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                            else\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"\n                        }",
        "nb_lignes_process": 40,
        "string_script": "                            \"\"\"\n                            # Protein_ModelTest\n                            modeltest-ng -i ${reps} -p ${task.cpus} -o ${params.projtag}_AminoType_Group_Reps_mt -d aa -s 203 --disable-checkpoint\n\n                            # Protein_Phylogeny\n                            if [ \"${params.iqCustomaa}\" != \"\" ];then\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq --redo -T auto ${params.iqCustomaa}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m \\${mod} --redo -nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 ${reps}.log | head -1 | awk '{print \\$6}')\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                            else\n                                iqtree -s ${reps} --prefix ${params.projtag}_AminoType_Group_Reps_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "ModelTest-NG"
        ],
        "tools_url": [
            "https://bio.tools/ModelTest-NG"
        ],
        "tools_dico": [
            {
                "name": "ModelTest-NG",
                "uri": "https://bio.tools/ModelTest-NG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3293",
                            "term": "Phylogenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3316",
                            "term": "Computer science"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A new and scalable tool for the selection of DNA and protein evolutionary models | ModelTest-NG is a tool for selecting the best-fit model of evolution for DNA and protein alignments. ModelTest-NG supersedes jModelTest and ProtTest in one single tool, with graphical and command console interfaces",
                "homepage": "https://github.com/ddarriba/modeltest"
            }
        ],
        "inputs": [
            "atygroupreps"
        ],
        "nb_inputs": 1,
        "outputs": [
            "align_results_aminmed",
            "amino_group_rep_tree"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/MED/Phylogeny/Modeltest\", mode: \"copy\", overwrite: true, pattern: '*mt*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/MED/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'"
        ],
        "when": "",
        "stub": ""
    },
    "Adding_AminoType_MED_Info": {
        "name_process": "Adding_AminoType_MED_Info",
        "string_process": " process Adding_AminoType_MED_Info {\n\n                      label 'low_cpus'\n\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/MED/\", mode: \"copy\", overwrite: true\n\n                      input:\n                          file(counts) from aminocountmed\n                          file(tree) from amino_repphy\n                          file(map) from atygroupscsv\n\n                      output:\n                          file(\"${params.projtag}_AminoType_Groupingcounts.csv\") into amino_groupcounts\n\n                      script:\n                          \"\"\"\n                          awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > amino.list\n                          echo \"GroupID\" >> group.list\n                          for x in \\$(cat amino.list);\n                          do    group=\\$(grep -w \\$x ${map} | awk -F \",\" '{print \\$2}')\n                                echo \"\\$group\" >> group.list\n                          done\n                          paste -d',' group.list ${counts} > ${params.projtag}_AminoType_Groupingcounts.csv\n                          \"\"\"\n                }",
        "nb_lignes_process": 23,
        "string_script": "                          \"\"\"\n                          awk -F \",\" '{print \\$1}' ${counts} | sed '1d' > amino.list\n                          echo \"GroupID\" >> group.list\n                          for x in \\$(cat amino.list);\n                          do    group=\\$(grep -w \\$x ${map} | awk -F \",\" '{print \\$2}')\n                                echo \"\\$group\" >> group.list\n                          done\n                          paste -d',' group.list ${counts} > ${params.projtag}_AminoType_Groupingcounts.csv\n                          \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "aminocountmed",
            "amino_repphy",
            "atygroupscsv"
        ],
        "nb_inputs": 3,
        "outputs": [
            "amino_groupcounts"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/AminoTypes/MED/\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "Translation_For_pcASV_Generation": {
        "name_process": "Translation_For_pcASV_Generation",
        "string_process": " process Translation_For_pcASV_Generation {\n\n                      label 'low_cpus'\n\n                      publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV/Translation\", mode: \"copy\", overwrite: true, pattern: '*_ASV_translations*'\n\n                      input:\n                          file(fasta) from nucl2aa\n\n                      output:\n                          file(\"*ASV*translations.fasta\") into clustering_aa\n                          file(\"*_ASV_translations_report\") into reportaa_VR\n                          file(\"*_ASV_nucleotide.fasta\") into asvfastaforaaclust\n\n                      script:\n                          \"\"\"\n                          ${tools}/virtualribosomev2/dna2pep.py ${fasta} -r all -x -o none --fasta ${params.projtag}_ASV_translations.fasta --report ${params.projtag}_ASV_translations_report\n                          cp ${fasta} ${params.projtag}_ASV_nucleotide.fasta\n                          \"\"\"\n                }",
        "nb_lignes_process": 18,
        "string_script": "                          \"\"\"\n                          ${tools}/virtualribosomev2/dna2pep.py ${fasta} -r all -x -o none --fasta ${params.projtag}_ASV_translations.fasta --report ${params.projtag}_ASV_translations_report\n                          cp ${fasta} ${params.projtag}_ASV_nucleotide.fasta\n                          \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "nucl2aa"
        ],
        "nb_inputs": 1,
        "outputs": [
            "clustering_aa",
            "reportaa_VR",
            "asvfastaforaaclust"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV/Translation\", mode: \"copy\", overwrite: true, pattern: '*_ASV_translations*'"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_pcASVs": {
        "name_process": "Generate_pcASVs",
        "string_process": " process Generate_pcASVs {\n\n                    label 'norm_cpus'\n\n                    tag \"${mtag}\"\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV\", mode: \"copy\", overwrite: true, pattern: '*pcASV*.{fasta}'\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{clstr,csv,gc}'\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV/Problematic\", mode: \"copy\", overwrite: true, pattern: '*problem*.{fasta}'\n\n                    input:\n                        each x from 1..naa\n                        file(fasta) from clustering_aa\n                        file(asvs) from asvfastaforaaclust\n\n                    output:\n                        tuple nid, file(\"${params.projtag}_nucleotide_pcASV*.fasta\") into ( pcASV_ntDiamond_ch, pcASV_nt_counts_ch, pcASV_ntmatrix_ch, pcASV_ntmuscle_ch )\n                        tuple nid, file(\"*_aminoacid_pcASV*_noTaxonomy.fasta\") into ( pcASV_aaMatrix_ch, pcASV_aaDiamond_ch, pcASV_aaMafft_ch, pcASV_aaCounts_ch, pcASVEMBOSS )\n                        tuple nid, file(\"*.fasta\"), file(\"*.clstr\"), file(\"*.csv\"), file(\"*.gc\") into ( pcASVsupplementalfiles )\n\n                    script:\n                                                       \n                        nid=slist2.get(x-1)\n                        mtag=\"ID=\" + slist2.get(x-1)\n                        \"\"\"\n                        set +e\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)>=\"${params.minAA}\"{print \">\"\\$0}' ${fasta} > ${params.projtag}_filtered_proteins.fasta\n                        cd-hit -i ${params.projtag}_filtered_proteins.fasta -c .${nid} -o ${params.projtag}_pcASV${nid}.fasta\n                        sed 's/>Cluster />Cluster_/g' ${params.projtag}_pcASV${nid}.fasta.clstr >${params.projtag}_pcASV${nid}.clstr\n                        grep \">Cluster_\" ${params.projtag}_pcASV${nid}.clstr >temporaryclusters.list\n                        y=\\$(grep -c \">Cluster_\" ${params.projtag}_pcASV${nid}.clstr)\n                        echo \">Cluster_\"\\${y}\"\" >> ${params.projtag}_pcASV${nid}.clstr\n                        t=1\n                        b=1\n                        for x in \\$(cat temporaryclusters.list);do\n                            echo \"Extracting \\$x\"\n                            name=\"\\$( echo \\$x | awk -F \">\" '{print \\$2}')\"\n                            clust=\"pcASV\"\\${t}\"\"\n                            echo \"\\${name}\"\n                            awk '/^>'\\${name}'\\$/,/^>Cluster_'\\${b}'\\$/' ${params.projtag}_pcASV${nid}.clstr > \"\\${name}\"_\"\\${clust}\"_tmp.list\n                            t=\\$(( \\${t}+1 ))\n                            b=\\$(( \\${b}+1 ))\n                        done\n\n        \t\t        ls *_tmp.list\n                        u=1\n                        for x in *_tmp.list;do\n                            name=\"\\$(echo \\$x | awk -F \"_p\" '{print \\$1}')\"\n                            echo \"\\${name}\"\n                            cluster=\"\\$(echo \\$x | awk -F \"_\" '{print \\$3}')\"\n                            echo \"\\${cluster}\"\n                            grep \"ASV\" \\$x | awk -F \", \" '{print \\$2}' | awk -F \"_\" '{print \\$1}' | awk -F \">\" '{print \\$2}' > \\${name}_\\${cluster}_seqs_tmps.list\n                            seqtk subseq ${asvs} \\${name}_\\${cluster}_seqs_tmps.list > \\${name}_\\${cluster}_nucleotide_sequences.fasta\n                            vsearch --cluster_fast \\${name}_\\${cluster}_nucleotide_sequences.fasta --id 0.2 --centroids \\${name}_\\${cluster}_centroids.fasta\n                            grep \">\" \\${name}_\\${cluster}_centroids.fasta >> \\${name}_\\${cluster}_tmp_centroids.list\n                            for y in \\$( cat \\${name}_\\${cluster}_tmp_centroids.list );do\n                                echo \">\\${cluster}_type\"\\$u\"\" >> \\${name}_\\${cluster}_tmp_centroid.newheaders\n                                u=\\$(( \\${u}+1 ))\n                            done\n                            u=1\n                            ./rename_seq.py \\${name}_\\${cluster}_centroids.fasta \\${name}_\\${cluster}_tmp_centroid.newheaders \\${cluster}_types_labeled.fasta\n                        done\n                        cat *_types_labeled.fasta >> ${params.projtag}_nucleotide_pcASV${nid}_noTaxonomy.fasta\n                        grep -w \"*\" ${params.projtag}_pcASV${nid}.clstr | awk '{print \\$3}' | awk -F \".\" '{print \\$1}' >tmphead.list\n                        grep -w \"*\" ${params.projtag}_pcASV${nid}.clstr | awk '{print \\$2}' | awk -F \",\" '{print \\$1}' >tmplen.list\n                        paste -d\",\" temporaryclusters.list tmphead.list >tmp.info.csv\n                        grep \">\" ${params.projtag}_pcASV${nid}.fasta >lala.list\n                        j=1\n                        for x in \\$(cat lala.list);do\n                            echo \">${params.projtag}_pcASV\\${j}\" >>${params.projtag}_aminoheaders.list\n                            echo \"\\${x},>${params.projtag}_pcASV\\${j}\" >>tmpaminotype.info.csv\n                            j=\\$(( \\${j}+1 ))\n                        done\n                        rm lala.list\n                        awk -F \",\" '{print \\$2}' tmp.info.csv >>tmporder.list\n                        for x in \\$(cat tmporder.list);do\n                            grep -w \"\\$x\" tmpaminotype.info.csv | awk -F \",\" '{print \\$2}' >>tmpder.list\n                        done\n                        paste -d \",\" temporaryclusters.list tmplen.list tmphead.list tmpder.list >${params.projtag}_pcASVCluster${nid}_summary.csv\n                        ./rename_seq.py ${params.projtag}_pcASV${nid}.fasta ${params.projtag}_aminoheaders.list ${params.projtag}_aminoacid_pcASV${nid}_noTaxonomy.fasta\n                        stats.sh in=${params.projtag}_aminoacid_pcASV${nid}_noTaxonomy.fasta gc=${params.projtag}_pcASV${nid}_aminoacid_clustered.gc gcformat=4\n                        stats.sh in=${params.projtag}_nucleotide_pcASV${nid}_noTaxonomy.fasta gc=${params.projtag}_pcASV${nid}_nucleotide_clustered.gc gcformat=4\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)<\"${params.minAA}\"{print \">\"\\$0}' ${fasta} >${params.projtag}_pcASV${nid}_problematic_translations.fasta\n                        if [ `wc -l ${params.projtag}_pcASV${nid}_problematic_translations.fasta | awk '{print \\$1}'` -gt 1 ];then\n                            grep \">\" ${params.projtag}_pcASV${nid}_problematic_translations.fasta | awk -F \">\" '{print \\$2}' > problem_tmp.list\n                            seqtk subseq ${asvs} problem_tmp.list > ${params.projtag}_pcASV${nid}_problematic_nucleotides.fasta\n                        else\n                           rm ${params.projtag}_pcASV${nid}_problematic_translations.fasta\n                        fi\n                        rm *.list\n                        rm Cluster*\n                        rm *types*\n                        rm *tmp*\n                        rm ${params.projtag}_pcASV${nid}.fast*\n                        \"\"\"\n                    }",
        "nb_lignes_process": 95,
        "string_script": "                        nid=slist2.get(x-1)\n                        mtag=\"ID=\" + slist2.get(x-1)\n                        \"\"\"\n                        set +e\n                        cp ${params.vampdir}/bin/rename_seq.py .\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)>=\"${params.minAA}\"{print \">\"\\$0}' ${fasta} > ${params.projtag}_filtered_proteins.fasta\n                        cd-hit -i ${params.projtag}_filtered_proteins.fasta -c .${nid} -o ${params.projtag}_pcASV${nid}.fasta\n                        sed 's/>Cluster />Cluster_/g' ${params.projtag}_pcASV${nid}.fasta.clstr >${params.projtag}_pcASV${nid}.clstr\n                        grep \">Cluster_\" ${params.projtag}_pcASV${nid}.clstr >temporaryclusters.list\n                        y=\\$(grep -c \">Cluster_\" ${params.projtag}_pcASV${nid}.clstr)\n                        echo \">Cluster_\"\\${y}\"\" >> ${params.projtag}_pcASV${nid}.clstr\n                        t=1\n                        b=1\n                        for x in \\$(cat temporaryclusters.list);do\n                            echo \"Extracting \\$x\"\n                            name=\"\\$( echo \\$x | awk -F \">\" '{print \\$2}')\"\n                            clust=\"pcASV\"\\${t}\"\"\n                            echo \"\\${name}\"\n                            awk '/^>'\\${name}'\\$/,/^>Cluster_'\\${b}'\\$/' ${params.projtag}_pcASV${nid}.clstr > \"\\${name}\"_\"\\${clust}\"_tmp.list\n                            t=\\$(( \\${t}+1 ))\n                            b=\\$(( \\${b}+1 ))\n                        done\n\n        \t\t        ls *_tmp.list\n                        u=1\n                        for x in *_tmp.list;do\n                            name=\"\\$(echo \\$x | awk -F \"_p\" '{print \\$1}')\"\n                            echo \"\\${name}\"\n                            cluster=\"\\$(echo \\$x | awk -F \"_\" '{print \\$3}')\"\n                            echo \"\\${cluster}\"\n                            grep \"ASV\" \\$x | awk -F \", \" '{print \\$2}' | awk -F \"_\" '{print \\$1}' | awk -F \">\" '{print \\$2}' > \\${name}_\\${cluster}_seqs_tmps.list\n                            seqtk subseq ${asvs} \\${name}_\\${cluster}_seqs_tmps.list > \\${name}_\\${cluster}_nucleotide_sequences.fasta\n                            vsearch --cluster_fast \\${name}_\\${cluster}_nucleotide_sequences.fasta --id 0.2 --centroids \\${name}_\\${cluster}_centroids.fasta\n                            grep \">\" \\${name}_\\${cluster}_centroids.fasta >> \\${name}_\\${cluster}_tmp_centroids.list\n                            for y in \\$( cat \\${name}_\\${cluster}_tmp_centroids.list );do\n                                echo \">\\${cluster}_type\"\\$u\"\" >> \\${name}_\\${cluster}_tmp_centroid.newheaders\n                                u=\\$(( \\${u}+1 ))\n                            done\n                            u=1\n                            ./rename_seq.py \\${name}_\\${cluster}_centroids.fasta \\${name}_\\${cluster}_tmp_centroid.newheaders \\${cluster}_types_labeled.fasta\n                        done\n                        cat *_types_labeled.fasta >> ${params.projtag}_nucleotide_pcASV${nid}_noTaxonomy.fasta\n                        grep -w \"*\" ${params.projtag}_pcASV${nid}.clstr | awk '{print \\$3}' | awk -F \".\" '{print \\$1}' >tmphead.list\n                        grep -w \"*\" ${params.projtag}_pcASV${nid}.clstr | awk '{print \\$2}' | awk -F \",\" '{print \\$1}' >tmplen.list\n                        paste -d\",\" temporaryclusters.list tmphead.list >tmp.info.csv\n                        grep \">\" ${params.projtag}_pcASV${nid}.fasta >lala.list\n                        j=1\n                        for x in \\$(cat lala.list);do\n                            echo \">${params.projtag}_pcASV\\${j}\" >>${params.projtag}_aminoheaders.list\n                            echo \"\\${x},>${params.projtag}_pcASV\\${j}\" >>tmpaminotype.info.csv\n                            j=\\$(( \\${j}+1 ))\n                        done\n                        rm lala.list\n                        awk -F \",\" '{print \\$2}' tmp.info.csv >>tmporder.list\n                        for x in \\$(cat tmporder.list);do\n                            grep -w \"\\$x\" tmpaminotype.info.csv | awk -F \",\" '{print \\$2}' >>tmpder.list\n                        done\n                        paste -d \",\" temporaryclusters.list tmplen.list tmphead.list tmpder.list >${params.projtag}_pcASVCluster${nid}_summary.csv\n                        ./rename_seq.py ${params.projtag}_pcASV${nid}.fasta ${params.projtag}_aminoheaders.list ${params.projtag}_aminoacid_pcASV${nid}_noTaxonomy.fasta\n                        stats.sh in=${params.projtag}_aminoacid_pcASV${nid}_noTaxonomy.fasta gc=${params.projtag}_pcASV${nid}_aminoacid_clustered.gc gcformat=4\n                        stats.sh in=${params.projtag}_nucleotide_pcASV${nid}_noTaxonomy.fasta gc=${params.projtag}_pcASV${nid}_nucleotide_clustered.gc gcformat=4\n                        awk 'BEGIN{RS=\">\";ORS=\"\"}length(\\$2)<\"${params.minAA}\"{print \">\"\\$0}' ${fasta} >${params.projtag}_pcASV${nid}_problematic_translations.fasta\n                        if [ `wc -l ${params.projtag}_pcASV${nid}_problematic_translations.fasta | awk '{print \\$1}'` -gt 1 ];then\n                            grep \">\" ${params.projtag}_pcASV${nid}_problematic_translations.fasta | awk -F \">\" '{print \\$2}' > problem_tmp.list\n                            seqtk subseq ${asvs} problem_tmp.list > ${params.projtag}_pcASV${nid}_problematic_nucleotides.fasta\n                        else\n                           rm ${params.projtag}_pcASV${nid}_problematic_translations.fasta\n                        fi\n                        rm *.list\n                        rm Cluster*\n                        rm *types*\n                        rm *tmp*\n                        rm ${params.projtag}_pcASV${nid}.fast*\n                        \"\"\"",
        "nb_lignes_script": 73,
        "language_script": "bash",
        "tools": [
            "cd-hit",
            "Clusterv",
            "seqtk",
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/cd-hit",
            "https://bio.tools/clusterv",
            "https://bio.tools/seqtk",
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "cd-hit",
                "uri": "https://bio.tools/cd-hit",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "Cluster a nucleotide dataset into representative sequences.",
                "homepage": "https://github.com/weizhongli/cdhit"
            },
            {
                "name": "Clusterv",
                "uri": "https://bio.tools/clusterv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The clusterv R package implements a set of functions to assess the reliability of clusters discovered by clustering algorithms. This library is tailored to the analysis of high dimensional data and in particular it is conceived for the analysis of the reliability of clusters discovered using DNA microarray data.",
                "homepage": "http://homes.di.unimi.it/~valenti/SW/clusterv/"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            },
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "1",
            "clustering_aa",
            "asvfastaforaaclust"
        ],
        "nb_inputs": 3,
        "outputs": [
            "",
            "",
            ""
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV\", mode: \"copy\", overwrite: true, pattern: '*pcASV*.{fasta}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{clstr,csv,gc}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Clustering/pcASV/Problematic\", mode: \"copy\", overwrite: true, pattern: '*problem*.{fasta}'"
        ],
        "when": "",
        "stub": ""
    },
    "pcASV_Nucleotide_Taxonomy_Inference_NCBI": {
        "name_process": "pcASV_Nucleotide_Taxonomy_Inference_NCBI",
        "string_process": " process pcASV_Nucleotide_Taxonomy_Inference_NCBI {\n\n                        label 'high_cpus'\n\n                        tag \"${mtag}\"\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'\n\n                        input:\n                            tuple nid, file(asvs) from pcASV_ntDiamond_ch\n\n                        output:\n                            file(\"*.fasta\") into ( pcASV_labeled )\n                            tuple file(\"*_phyloformat.csv\"), file(\"*_summaryTable.tsv\"), file(\"*dmd.out\") into summary_AAdiamond\n                            tuple nid, file(\"*_summary_for_plot.csv\") into taxplot3\n                            tuple nid, file(\"*_quick_Taxbreakdown.csv\") into tax_table_pcasvnt\n                            tuple nid, file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_pcasvnt\n\n                        script:\n                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            set +e\n                            cp ${params.vampdir}/bin/rename_seq.py .\n                            virdb=${params.dbdir}/${params.dbname}\n                            if [[ ${params.measurement} == \"bitscore\" ]]\n                            then    measure=\"--min-score ${params.bitscore}\"\n                            elif    [[ ${params.measurement} == \"evalue\" ]]\n                            then    measure=\"-e ${params.evalue}\"\n                            else    measure=\"--min-score ${params.bitscore}\"\n                            fi\n                            grep \">\" \\${virdb} > headers.list\n                            headers=\"headers.list\"\n                            name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                            else   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                            fi\n                            echo \"Preparing lists to generate summary .csv's\"\n                            echo \"[Best hit accession number]\" > access.list\n                            echo \"[e-value]\" > evalue.list\n                            echo \"[Bitscore]\" > bit.list\n                            echo \"[Percent ID (aa)]\" > pid.list\n                            echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                            echo \"[Gene]\" > \"\\$name\"_genes.list\n                            echo \"[pcASV#]\" > otu.list\n                            echo \"[Sequence length]\" > length.list\n                            grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                            if [[ ${params.lca} == \"T\" ]]\n                            then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            else\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            fi\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                            fi\n                            echo \"extracting genes and names\"\n                            touch new_\"\\$name\"_asvnames.txt\n                            for s in \\$(cat seqids.lst);do\n                                echo \"Checking for \\$s hit in diamond output\"\n                                if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                            echo \"Yep, there was a hit for \\$s\"\n                                            echo \"Extracting the information now:\"\n                                            acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"\\$acc\" >> access.list\n                                            line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                            echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                            echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                            echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                            echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                            echo \"Extracting virus and gene ID for \\$s now\"\n                                            gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                            echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                            virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                            echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                            echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                    then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                          lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                          echo \"\\$lcla\" >> lca_classification.list\n                                                    else  echo \"Viruses\" >> lca_classification.list\n                                                    fi\n                                            fi\n                                            if [[ ${params.ncbitax} == \"true\" ]]\n                                            then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                                else\n                                            echo \"Ugh, there was no hit for \\$s ..\"\n                                            echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"NO_HIT\" >> access.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                            echo \"NO_HIT\" >> evalue.list\n                                            echo \"NO_HIT\" >> bit.list\n                                            echo \"NO_HIT\" >> pid.list\n                                            echo \"NO_HIT\" >> length.list\n                                            virus=\"NO\"\n                                            gene=\"HIT\"\n                                            echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    echo \"N/A\" >> lca_classification.list\n                                            fi\n                                            if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                            then  echo \"N/A\" >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                               fi\n                            done\n                            echo \"Now editing \"\\$name\" fasta headers\"\n                            ###### rename_seq.py\n                            ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                            awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                            echo \"[Sequence header]\" > newnames.list\n                            cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                            touch sequence.list\n                            echo \"     \" > sequence.list\n                            grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                            rm \"\\$name\"_tmpssasv.fasta\n                            if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            else\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            fi\n                            for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                            done\n                            awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                            rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                            \"\"\"\n                        }",
        "nb_lignes_process": 154,
        "string_script": "                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            set +e\n                            cp ${params.vampdir}/bin/rename_seq.py .\n                            virdb=${params.dbdir}/${params.dbname}\n                            if [[ ${params.measurement} == \"bitscore\" ]]\n                            then    measure=\"--min-score ${params.bitscore}\"\n                            elif    [[ ${params.measurement} == \"evalue\" ]]\n                            then    measure=\"-e ${params.evalue}\"\n                            else    measure=\"--min-score ${params.bitscore}\"\n                            fi\n                            grep \">\" \\${virdb} > headers.list\n                            headers=\"headers.list\"\n                            name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                            else   diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                            fi\n                            echo \"Preparing lists to generate summary .csv's\"\n                            echo \"[Best hit accession number]\" > access.list\n                            echo \"[e-value]\" > evalue.list\n                            echo \"[Bitscore]\" > bit.list\n                            echo \"[Percent ID (aa)]\" > pid.list\n                            echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                            echo \"[Gene]\" > \"\\$name\"_genes.list\n                            echo \"[pcASV#]\" > otu.list\n                            echo \"[Sequence length]\" > length.list\n                            grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                            if [[ ${params.lca} == \"T\" ]]\n                            then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            else\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            fi\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                            fi\n                            echo \"extracting genes and names\"\n                            touch new_\"\\$name\"_asvnames.txt\n                            for s in \\$(cat seqids.lst);do\n                                echo \"Checking for \\$s hit in diamond output\"\n                                if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                            echo \"Yep, there was a hit for \\$s\"\n                                            echo \"Extracting the information now:\"\n                                            acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"\\$acc\" >> access.list\n                                            line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                            echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                            echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                            echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                            echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                            echo \"Extracting virus and gene ID for \\$s now\"\n                                            gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                            echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                            virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                            echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                            echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                    then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                          lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                          echo \"\\$lcla\" >> lca_classification.list\n                                                    else  echo \"Viruses\" >> lca_classification.list\n                                                    fi\n                                            fi\n                                            if [[ ${params.ncbitax} == \"true\" ]]\n                                            then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                                else\n                                            echo \"Ugh, there was no hit for \\$s ..\"\n                                            echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"NO_HIT\" >> access.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                            echo \"NO_HIT\" >> evalue.list\n                                            echo \"NO_HIT\" >> bit.list\n                                            echo \"NO_HIT\" >> pid.list\n                                            echo \"NO_HIT\" >> length.list\n                                            virus=\"NO\"\n                                            gene=\"HIT\"\n                                            echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    echo \"N/A\" >> lca_classification.list\n                                            fi\n                                            if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                            then  echo \"N/A\" >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                               fi\n                            done\n                            echo \"Now editing \"\\$name\" fasta headers\"\n                            ###### rename_seq.py\n                            ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                            awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                            echo \"[Sequence header]\" > newnames.list\n                            cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                            touch sequence.list\n                            echo \"     \" > sequence.list\n                            grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                            rm \"\\$name\"_tmpssasv.fasta\n                            if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            else\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            fi\n                            for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                            done\n                            awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                            rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                            \"\"\"",
        "nb_lignes_script": 133,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_ntDiamond_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "summary_AAdiamond",
            "taxplot3",
            "tax_table_pcasvnt",
            "tax_nodCol_pcasvnt"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'"
        ],
        "when": "",
        "stub": ""
    },
    "pcASV_Nucleotide_Taxonomy_Inference_RVDB": {
        "name_process": "pcASV_Nucleotide_Taxonomy_Inference_RVDB",
        "string_process": " process pcASV_Nucleotide_Taxonomy_Inference_RVDB {\n\n                          label 'high_cpus'\n\n                          tag \"${mtag}\"\n\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'\n\n                          input:\n                              tuple nid, file(asvs) from pcASV_ntDiamond_ch\n\n                          output:\n                              file(\"*.fasta\") into ( pcASV_labeled )\n                              tuple file(\"*_phyloformat.csv\"), file(\"*_summaryTable.tsv\"), file(\"*dmd.out\") into summary_AAdiamond\n                              tuple nid, file(\"*_summary_for_plot.csv\") into taxplot3\n                              tuple nid, file(\"*_quick_Taxbreakdown.csv\") into tax_table_pcasvnt\n                              tuple nid, file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_pcasvnt\n\n                          script:\n                              mtag=\"ID=\" + nid\n                              \"\"\"\n                              set +e\n                              cp ${params.vampdir}/bin/rename_seq.py .\n                              virdb=${params.dbdir}/${params.dbname}\n                              if [[ ${params.measurement} == \"bitscore\" ]]\n                              then    measure=\"--min-score ${params.bitscore}\"\n                              elif    [[ ${params.measurement} == \"evalue\" ]]\n                              then    measure=\"-e ${params.evalue}\"\n                              else    measure=\"--min-score ${params.bitscore}\"\n                              fi\n                              grep \">\" \\${virdb} > headers.list\n                              headers=\"headers.list\"\n                              name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                              diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                              echo \"Preparing lists to generate summary .csv's\"\n                              echo \"[Best hit accession number]\" > access.list\n                              echo \"[e-value]\" > evalue.list\n                              echo \"[Bitscore]\" > bit.list\n                              echo \"[Percent ID (aa)]\" > pid.list\n                              echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                              echo \"[Gene]\" > \"\\$name\"_genes.list\n                              echo \"[pcASV#]\" > otu.list\n                              echo \"[Sequence length]\" > length.list\n                              grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                              if [[ ${params.lca} == \"T\" ]]\n                              then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              fi\n                              echo \"extracting genes and names\"\n                              touch new_\"\\$name\"_asvnames.txt\n                              for s in \\$(cat seqids.lst);do\n                                  echo \"Using RVDB headers.\"\n                                  if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                      echo \"Yep, there was a hit for \\$s\"\n                                      echo \"Extracting the information now:\"\n                                      acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"\\$acc\" >> access.list\n                                      line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                      echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                      echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                      echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                      echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                      echo \"Extracting virus and gene ID for \\$s now\"\n                                      gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                      echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                      virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                      echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                              then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                    lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                    echo \"\\$lcla\" >> lca_classification.list\n                                              else  echo \"Viruses\" >> lca_classification.list\n                                              fi\n                                      fi\n                                      echo \"\\$s done.\"\n                                  else\n                                      echo \"Ugh, there was no hit for \\$s ..\"\n                                      echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"NO_HIT\" >> access.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                      echo \"NO_HIT\" >> evalue.list\n                                      echo \"NO_HIT\" >> bit.list\n                                      echo \"NO_HIT\" >> pid.list\n                                      echo \"NO_HIT\" >> length.list\n                                      virus=\"NO\"\n                                      gene=\"HIT\"\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    echo \"N/A\" >> lca_classification.list\n                                      fi\n                                      echo \"\\$s done.\"\n                                  fi\n                              echo \"Done with \\$s\"\n                              done\n                              echo \"Now editing \"\\$name\" fasta headers\"\n                              ###### rename_seq.py\n                              ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                              awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                              echo \"[Sequence header]\" > newnames.list\n                              cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                              touch sequence.list\n                              echo \"     \" > sequence.list\n                              grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                              rm \"\\$name\"_tmpssasv.fasta\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                    paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                              else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              fi\n                              for x in *phyloformat.csv;do\n                                        echo \"\\$x\"\n                                        lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                        tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                        sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                        cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                        rm tmpcol.list tmp2col.list\n                              done\n                              awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                              rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                              \"\"\"\n                    }",
        "nb_lignes_process": 130,
        "string_script": "                              mtag=\"ID=\" + nid\n                              \"\"\"\n                              set +e\n                              cp ${params.vampdir}/bin/rename_seq.py .\n                              virdb=${params.dbdir}/${params.dbname}\n                              if [[ ${params.measurement} == \"bitscore\" ]]\n                              then    measure=\"--min-score ${params.bitscore}\"\n                              elif    [[ ${params.measurement} == \"evalue\" ]]\n                              then    measure=\"-e ${params.evalue}\"\n                              else    measure=\"--min-score ${params.bitscore}\"\n                              fi\n                              grep \">\" \\${virdb} > headers.list\n                              headers=\"headers.list\"\n                              name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                              diamond blastx -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                              echo \"Preparing lists to generate summary .csv's\"\n                              echo \"[Best hit accession number]\" > access.list\n                              echo \"[e-value]\" > evalue.list\n                              echo \"[Bitscore]\" > bit.list\n                              echo \"[Percent ID (aa)]\" > pid.list\n                              echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                              echo \"[Gene]\" > \"\\$name\"_genes.list\n                              echo \"[pcASV#]\" > otu.list\n                              echo \"[Sequence length]\" > length.list\n                              grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                              if [[ ${params.lca} == \"T\" ]]\n                              then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              fi\n                              echo \"extracting genes and names\"\n                              touch new_\"\\$name\"_asvnames.txt\n                              for s in \\$(cat seqids.lst);do\n                                  echo \"Using RVDB headers.\"\n                                  if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                      echo \"Yep, there was a hit for \\$s\"\n                                      echo \"Extracting the information now:\"\n                                      acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"\\$acc\" >> access.list\n                                      line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                      echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                      echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                      echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                      echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                      echo \"Extracting virus and gene ID for \\$s now\"\n                                      gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                      echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                      virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                      echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                              then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                    lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                    echo \"\\$lcla\" >> lca_classification.list\n                                              else  echo \"Viruses\" >> lca_classification.list\n                                              fi\n                                      fi\n                                      echo \"\\$s done.\"\n                                  else\n                                      echo \"Ugh, there was no hit for \\$s ..\"\n                                      echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"NO_HIT\" >> access.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                      echo \"NO_HIT\" >> evalue.list\n                                      echo \"NO_HIT\" >> bit.list\n                                      echo \"NO_HIT\" >> pid.list\n                                      echo \"NO_HIT\" >> length.list\n                                      virus=\"NO\"\n                                      gene=\"HIT\"\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    echo \"N/A\" >> lca_classification.list\n                                      fi\n                                      echo \"\\$s done.\"\n                                  fi\n                              echo \"Done with \\$s\"\n                              done\n                              echo \"Now editing \"\\$name\" fasta headers\"\n                              ###### rename_seq.py\n                              ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                              awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                              echo \"[Sequence header]\" > newnames.list\n                              cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                              touch sequence.list\n                              echo \"     \" > sequence.list\n                              grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                              rm \"\\$name\"_tmpssasv.fasta\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                    paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                              else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              fi\n                              for x in *phyloformat.csv;do\n                                        echo \"\\$x\"\n                                        lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                        tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                        sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                        cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                        rm tmpcol.list tmp2col.list\n                              done\n                              awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                              rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                              \"\"\"",
        "nb_lignes_script": 109,
        "language_script": "bash",
        "tools": [
            "Diamond"
        ],
        "tools_url": [
            "https://bio.tools/diamond"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            }
        ],
        "inputs": [
            "pcASV_ntDiamond_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "summary_AAdiamond",
            "taxplot3",
            "tax_table_pcasvnt",
            "tax_nodCol_pcasvnt"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'"
        ],
        "when": "",
        "stub": ""
    },
    "skippcASVnuctaxonomy": {
        "name_process": "skippcASVnuctaxonomy",
        "string_process": " process skippcASVnuctaxonomy {\n\n                     input:\n                         tuple nid, file(asvs) from pcASV_ntDiamond_ch\n\n                     output:\n                         tuple nid, file(\"skipncASVnubtaxonomy1.txt\") into ( taxplot3 )\n                         tuple nid, file(\"skipncASVnubtaxonomy2.txt\") into ( tax_table_pcasvnt )\n                         tuple nid, file(\"skipncASVnubtaxonomy3.txt\") into ( tax_nodCol_pcasvnt )\n\n                     script:\n                         \"\"\"\n                         echo \"Skipped\" >skipncASVnubtaxonomy1.txt\n                         echo \"Skipped\" >skipncASVnubtaxonomy2.txt\n                         echo \"Skipped\" >skipncASVnubtaxonomy3.txt\n                         \"\"\"\n                 }",
        "nb_lignes_process": 15,
        "string_script": "                         \"\"\"\n                         echo \"Skipped\" >skipncASVnubtaxonomy1.txt\n                         echo \"Skipped\" >skipncASVnubtaxonomy2.txt\n                         echo \"Skipped\" >skipncASVnubtaxonomy3.txt\n                         \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_ntDiamond_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "",
            ""
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Generate_Nucleotide_pcASV_Counts": {
        "name_process": "Generate_Nucleotide_pcASV_Counts",
        "string_process": " process Generate_Nucleotide_pcASV_Counts {\n\n                    label 'norm_cpus'\n\n                    tag \"${mtag}\"\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Counts\", mode: \"copy\", overwrite: true, pattern: '*.{biome,csv,txt}'\n\n                    input:\n                        tuple nid, file(potus) from pcASV_nt_counts_ch\n                        file(merged) from pcASV_mergedreads_ch\n\n                    output:\n                        tuple file(\"*_counts.txt\"), file(\"*_counts.biome\") into pcASVcounts_vsearch\n                        tuple nid, file(\"*.csv\") into potu_Ncounts_for_report\n\n                    script:\n                        mtag=\"ID=\" + nid\n                        \"\"\"\n                    \tname=\\$( echo ${potus} | awk -F \".fasta\" '{print \\$1}')\n                    \tvsearch --usearch_global ${merged} --db ${potus} --id .${nid} --threads ${task.cpus} --otutabout \\${name}_counts.txt --biomout \\${name}_counts.biome\n                    \tcat \\${name}_counts.txt | tr \"\\t\" \",\" >\\${name}_count.csv\n                    \tsed 's/#OTU ID/OTU_ID/g' \\${name}_count.csv >\\${name}_counts.csv\n                    \trm \\${name}_count.csv\n                        \"\"\"\n                }",
        "nb_lignes_process": 24,
        "string_script": "                        mtag=\"ID=\" + nid\n                        \"\"\"\n                    \tname=\\$( echo ${potus} | awk -F \".fasta\" '{print \\$1}')\n                    \tvsearch --usearch_global ${merged} --db ${potus} --id .${nid} --threads ${task.cpus} --otutabout \\${name}_counts.txt --biomout \\${name}_counts.biome\n                    \tcat \\${name}_counts.txt | tr \"\\t\" \",\" >\\${name}_count.csv\n                    \tsed 's/#OTU ID/OTU_ID/g' \\${name}_count.csv >\\${name}_counts.csv\n                    \trm \\${name}_count.csv\n                        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "VSEARCH"
        ],
        "tools_url": [
            "https://bio.tools/vsearch"
        ],
        "tools_dico": [
            {
                "name": "VSEARCH",
                "uri": "https://bio.tools/vsearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2520",
                                    "term": "DNA mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimera detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0450",
                                    "term": "Chimeric sequence detection"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2977",
                                "term": "Nucleic acid sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0865",
                                "term": "Sequence similarity score"
                            }
                        ]
                    }
                ],
                "description": "High-throughput search and clustering sequence analysis tool. It supports de novo and reference based chimera detection, clustering, full-length and prefix dereplication, reverse complementation, masking, all-vs-all pairwise global alignment, exact and global alignment searching, shuffling, subsampling and sorting. It also supports FASTQ file analysis, filtering and conversion.",
                "homepage": "https://github.com/torognes/vsearch"
            }
        ],
        "inputs": [
            "pcASV_nt_counts_ch",
            "pcASV_mergedreads_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "pcASVcounts_vsearch",
            "potu_Ncounts_for_report"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Counts\", mode: \"copy\", overwrite: true, pattern: '*.{biome,csv,txt}'"
        ],
        "when": "",
        "stub": ""
    },
    "Generate_pcASV_Nucleotide_Matrix": {
        "name_process": "Generate_pcASV_Nucleotide_Matrix",
        "string_process": " process Generate_pcASV_Nucleotide_Matrix {\n\n                    label 'low_cpus'\n\n                    tag \"${mtag}\"\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Matrix\", mode: \"copy\", overwrite: true\n\n                    input:\n                        tuple nid, file(potus) from pcASV_ntmatrix_ch\n\n                    output:\n                        file(\"*.matrix\") into pcASVclustmatrices\n                        tuple nid, file(\"*PercentID.matrix\") into potu_nucl_heatmap\n\n                    script:\n                                                            \n                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        name=\\$( echo ${potus} | awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i ${potus} --distmat-out=\\${name}_PairwiseDistanceq.matrix --full --force --threads=${task.cpus}\n                        clustalo -i ${potus} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        cat \\${name}_PercentIDq.matrix | tr \" \" \",\" | grep \",\" >\\${name}_PercentID.matrix\n                        rm \\${name}_PercentIDq.matrix\n                        \"\"\"\n                }",
        "nb_lignes_process": 24,
        "string_script": "                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        name=\\$( echo ${potus} | awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i ${potus} --distmat-out=\\${name}_PairwiseDistanceq.matrix --full --force --threads=${task.cpus}\n                        clustalo -i ${potus} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        cat \\${name}_PercentIDq.matrix | tr \" \" \",\" | grep \",\" >\\${name}_PercentID.matrix\n                        rm \\${name}_PercentIDq.matrix\n                        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_ntmatrix_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcASVclustmatrices",
            "potu_nucl_heatmap"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Matrix\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "pcASV_Nucleotide_Phylogeny": {
        "name_process": "pcASV_Nucleotide_Phylogeny",
        "string_process": " process pcASV_Nucleotide_Phylogeny {\n\n                        label 'norm_cpus'\n\n                        tag \"${mtag}\"\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*aln.*'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*mt*'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'\n\n                        input:\n                            tuple nid, file(prot) from pcASV_ntmuscle_ch\n\n                        output:\n                            tuple file(\"*_aln.fasta\"), file(\"*_aln.html\"), file(\"*.tree\"), file(\"*.log\"), file(\"*iq*\"), file(\"*mt*\") into pcASV_nucleotide_phylogeny_results\n                            tuple nid, file(\"*iq.treefile\") into potu_Ntree_plot\n\n                        script:\n                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            pre=\\$( echo ${prot} | awk -F \"_noTax\" '{print \\$1}' )\n                            if [[ \\$(grep -c \">\" ${prot}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                            ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${prot} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                            trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                            o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                            mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                            # pcASV_Nucleotide_ModelTest\n                            modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_noTaxonomy_mt -d nt -s 203 --disable-checkpoint\n\n                            # pcASV_Nucleotide_Phylogeny\n                            if [ \"${params.iqCustomnt}\" != \"\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq --redo -T auto ${params.iqCustomnt}\n\n                            elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m \\${mod} --redo-nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                            else\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"\n                    }",
        "nb_lignes_process": 50,
        "string_script": "                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            pre=\\$( echo ${prot} | awk -F \"_noTax\" '{print \\$1}' )\n                            if [[ \\$(grep -c \">\" ${prot}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                            ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${prot} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                            trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                            o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                            mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                            # pcASV_Nucleotide_ModelTest\n                            modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_noTaxonomy_mt -d nt -s 203 --disable-checkpoint\n\n                            # pcASV_Nucleotide_Phylogeny\n                            if [ \"${params.iqCustomnt}\" != \"\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq --redo -T auto ${params.iqCustomnt}\n\n                            elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m \\${mod} --redo-nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTnt}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                            else\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_noTaxonomy_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "trimAl",
            "ModelTest-NG"
        ],
        "tools_url": [
            "https://bio.tools/trimal",
            "https://bio.tools/ModelTest-NG"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            },
            {
                "name": "ModelTest-NG",
                "uri": "https://bio.tools/ModelTest-NG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3293",
                            "term": "Phylogenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3316",
                            "term": "Computer science"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A new and scalable tool for the selection of DNA and protein evolutionary models | ModelTest-NG is a tool for selecting the best-fit model of evolution for DNA and protein alignments. ModelTest-NG supersedes jModelTest and ProtTest in one single tool, with graphical and command console interfaces",
                "homepage": "https://github.com/ddarriba/modeltest"
            }
        ],
        "inputs": [
            "pcASV_ntmuscle_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcASV_nucleotide_phylogeny_results",
            "potu_Ntree_plot"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*aln.*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Phylogeny/ModelTest\", mode: \"copy\", overwrite: true, pattern: '*mt*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Nucleotide/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'"
        ],
        "when": "",
        "stub": ""
    },
    "skippcASVnucphylogeny": {
        "name_process": "skippcASVnucphylogeny",
        "string_process": " process skippcASVnucphylogeny {\n\n                        input:\n                            tuple nid, file(prot) from pcASV_ntmuscle_ch\n\n                        output:\n                            tuple nid, file(\"skipncASVnucphy.txt\") into ( potu_Ntree_plot )\n\n                        script:\n                            \"\"\"\n                            echo \"Skipped\" >skipncASVnucphy.txt\n                            \"\"\"\n                    }",
        "nb_lignes_process": 11,
        "string_script": "                            \"\"\"\n                            echo \"Skipped\" >skipncASVnucphy.txt\n                            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_ntmuscle_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "pcASV_AminoAcid_Matrix": {
        "name_process": "pcASV_AminoAcid_Matrix",
        "string_process": " process pcASV_AminoAcid_Matrix {\n\n                    label 'low_cpus'\n\n                    tag \"${mtag}\"\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Matrix\", mode: \"copy\", overwrite: true\n\n                    input:\n                        tuple nid, file(prot) from pcASV_aaMatrix_ch\n\n                    output:\n                        file(\"*.matrix\") into pcASVaaMatrix\n                        tuple nid, file(\"*PercentID.matrix\") into potu_aa_heatmap\n\n                    script:\n                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        name=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i ${prot} --distmat-out=\\${name}_PairwiseDistanceq.matrix --full --force --threads=${task.cpus}\n                        clustalo -i ${prot} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        cat \\${name}_PercentIDq.matrix | tr \" \" \",\" | grep \",\" >\\${name}_PercentID.matrix\n                        rm \\${name}_PercentIDq.matrix\n                        \"\"\"\n                }",
        "nb_lignes_process": 23,
        "string_script": "                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        name=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}')\n                        clustalo -i ${prot} --distmat-out=\\${name}_PairwiseDistanceq.matrix --full --force --threads=${task.cpus}\n                        clustalo -i ${prot} --distmat-out=\\${name}_PercentIDq.matrix --percent-id --full --force --threads=${task.cpus}\n                        cat \\${name}_PercentIDq.matrix | tr \" \" \",\" | grep \",\" >\\${name}_PercentID.matrix\n                        rm \\${name}_PercentIDq.matrix\n                        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_aaMatrix_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcASVaaMatrix",
            "potu_aa_heatmap"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Matrix\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "pcASV_EMBOSS_Analyses": {
        "name_process": "pcASV_EMBOSS_Analyses",
        "string_process": " process pcASV_EMBOSS_Analyses {\n\n                        label 'low_cpus'\n\n                        tag \"${mtag}\"\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/2dStructure\", mode: \"copy\", overwrite: true, pattern: '*.{garnier}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/HydrophobicMoment\", mode: \"copy\", overwrite: true, pattern: '*HydrophobicMoments.{svg}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/IsoelectricPoint\", mode: \"copy\", overwrite: true, pattern: '*IsoelectricPoint.{iep,svg}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/ProteinProperties\", mode: \"copy\", overwrite: true, pattern: '*.{pepstats,pepinfo}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/ProteinProperties/Plots\", mode: \"copy\", overwrite: true, pattern: '*PropertiesPlot.{svg}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/2dStructure/Plots\", mode: \"copy\", overwrite: true, pattern: '*Helical*.{svg}'\n\n                        input:\n                            tuple nid, file(prot) from pcASVEMBOSS\n\n                        output:\n                            tuple file(\"*.garnier\"), file(\"*HydrophobicMoments.svg\"), file(\"*IsoelectricPoint*\"), file(\"*.pepstats\"), file(\"*PropertiesPlot*\"), file(\"*Helical*\")  into pcASV_emboss\n\n                        script:\n                                                       \n                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            name=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}')\n                            garnier -sequence ${prot} -outfile \\${name}_2dStructures.garnier\n                            hmoment -seqall ${prot} -graph svg -plot\n                            mv hmoment.svg ./\"\\${name}\"_HydrophobicMoments.svg\n                            iep -sequence ${prot} -graph svg -plot -outfile \"\\${name}\"_IsoelectricPoint.iep\n                            mv iep.svg ./\"\\${name}\"_IsoelectricPoint.svg\n                            pepstats -sequence ${prot} -outfile \\${name}_ProteinProperties.pepstats\n                            grep \">\" ${prot} | awk -F \">\" '{print \\$2}' > tmpsequence.list\n                            for x in \\$(cat tmpsequence.list);do\n                                echo \\$x > tmp1.list\n                                seqtk subseq ${prot} tmp1.list > tmp2.fasta\n                                len=\\$(tail -1 tmp2.fasta | awk '{print length}')\n                                pepinfo -sequence tmp2.fasta -graph svg -outfile \"\\$x\"_PropertiesPlot.pepinfo\n                                mv pepinfo.svg ./\"\\$x\"_PropertiesPlot.svg\n                                cat \"\\$x\"_PropertiesPlot.pepinfo >> \"\\${name}\"_PropertiesPlot.pepinfo\n                                rm \"\\$x\"_PropertiesPlot.pepinfo\n                                pepnet -sask -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepnet.svg ./\"\\$x\"_HelicalNet.svg\n                                pepwheel -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepwheel.svg ./\"\\$x\"_HelicalWheel.svg\n                                rm tmp1.list tmp2.fasta\n                            done\n                            rm tmpsequence.list\n                            \"\"\"\n                        }",
        "nb_lignes_process": 46,
        "string_script": "                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            name=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}')\n                            garnier -sequence ${prot} -outfile \\${name}_2dStructures.garnier\n                            hmoment -seqall ${prot} -graph svg -plot\n                            mv hmoment.svg ./\"\\${name}\"_HydrophobicMoments.svg\n                            iep -sequence ${prot} -graph svg -plot -outfile \"\\${name}\"_IsoelectricPoint.iep\n                            mv iep.svg ./\"\\${name}\"_IsoelectricPoint.svg\n                            pepstats -sequence ${prot} -outfile \\${name}_ProteinProperties.pepstats\n                            grep \">\" ${prot} | awk -F \">\" '{print \\$2}' > tmpsequence.list\n                            for x in \\$(cat tmpsequence.list);do\n                                echo \\$x > tmp1.list\n                                seqtk subseq ${prot} tmp1.list > tmp2.fasta\n                                len=\\$(tail -1 tmp2.fasta | awk '{print length}')\n                                pepinfo -sequence tmp2.fasta -graph svg -outfile \"\\$x\"_PropertiesPlot.pepinfo\n                                mv pepinfo.svg ./\"\\$x\"_PropertiesPlot.svg\n                                cat \"\\$x\"_PropertiesPlot.pepinfo >> \"\\${name}\"_PropertiesPlot.pepinfo\n                                rm \"\\$x\"_PropertiesPlot.pepinfo\n                                pepnet -sask -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepnet.svg ./\"\\$x\"_HelicalNet.svg\n                                pepwheel -sequence tmp2.fasta -graph svg -sbegin1 1 -send1 \\$len\n                                mv pepwheel.svg ./\"\\$x\"_HelicalWheel.svg\n                                rm tmp1.list tmp2.fasta\n                            done\n                            rm tmpsequence.list\n                            \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "garnier",
            "hmoment",
            "iep",
            "pepstats",
            "seqtk",
            "pepinfo",
            "pepnet",
            "pepwheel"
        ],
        "tools_url": [
            "https://bio.tools/garnier",
            "https://bio.tools/hmoment",
            "https://bio.tools/iep",
            "https://bio.tools/pepstats",
            "https://bio.tools/seqtk",
            "https://bio.tools/pepinfo",
            "https://bio.tools/pepnet",
            "https://bio.tools/pepwheel"
        ],
        "tools_dico": [
            {
                "name": "garnier",
                "uri": "https://bio.tools/garnier",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein secondary structure"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein features (secondary structure)"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Protein secondary structure prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Secondary structure prediction (protein)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1277",
                                "term": "Protein features"
                            }
                        ]
                    }
                ],
                "description": "Predict protein secondary structure using GOR method.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/garnier.html"
            },
            {
                "name": "hmoment",
                "uri": "https://bio.tools/hmoment",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2574",
                                    "term": "Protein hydropathy calculation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1520",
                                "term": "Peptide hydrophobic moment"
                            }
                        ]
                    }
                ],
                "description": "Calculate and plot hydrophobic moment for protein sequence(s).",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/hmoment.html"
            },
            {
                "name": "iep",
                "uri": "https://bio.tools/iep",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0403",
                                    "term": "Protein isoelectric point calculation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1528",
                                "term": "Protein isoelectric point"
                            }
                        ]
                    }
                ],
                "description": "Calculate the isoelectric point of proteins.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/iep.html"
            },
            {
                "name": "pepstats",
                "uri": "https://bio.tools/pepstats",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property rendering"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_1505",
                                "term": "Amino acid index (molecular weight)"
                            },
                            {
                                "uri": "http://edamontology.org/data_1502",
                                "term": "Amino acid index (chemical classes)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0897",
                                "term": "Protein property"
                            }
                        ]
                    }
                ],
                "description": "Calculate statistics of protein properties.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepstats.html"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            },
            {
                "name": "pepinfo",
                "uri": "https://bio.tools/pepinfo",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0250",
                                    "term": "Protein property rendering"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_1506",
                                "term": "Amino acid index (hydropathy)"
                            },
                            {
                                "uri": "http://edamontology.org/data_1502",
                                "term": "Amino acid index (chemical classes)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2886",
                                "term": "Protein sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1522",
                                "term": "Protein sequence hydropathy plot"
                            },
                            {
                                "uri": "http://edamontology.org/data_0897",
                                "term": "Protein property"
                            }
                        ]
                    }
                ],
                "description": "Plot amino acid properties of a protein sequence in parallel.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepinfo.html"
            },
            {
                "name": "pepnet",
                "uri": "https://bio.tools/pepnet",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein properties"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0123",
                            "term": "Protein physicochemistry"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2574",
                                    "term": "Protein hydropathy calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0319",
                                    "term": "Protein secondary structure assignment"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2163",
                                "term": "Helical net"
                            }
                        ]
                    }
                ],
                "description": "Draw a helical net for a protein sequence.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepnet.html"
            },
            {
                "name": "pepwheel",
                "uri": "https://bio.tools/pepwheel",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Protein secondary structure prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Secondary structure prediction (protein)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2162",
                                "term": "Helical wheel"
                            }
                        ]
                    }
                ],
                "description": "Draw a helical wheel diagram for a protein sequence.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/pepwheel.html"
            }
        ],
        "inputs": [
            "pcASVEMBOSS"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcASV_emboss"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'low_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/2dStructure\", mode: \"copy\", overwrite: true, pattern: '*.{garnier}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/HydrophobicMoment\", mode: \"copy\", overwrite: true, pattern: '*HydrophobicMoments.{svg}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/IsoelectricPoint\", mode: \"copy\", overwrite: true, pattern: '*IsoelectricPoint.{iep,svg}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/ProteinProperties\", mode: \"copy\", overwrite: true, pattern: '*.{pepstats,pepinfo}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/ProteinProperties/Plots\", mode: \"copy\", overwrite: true, pattern: '*PropertiesPlot.{svg}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/EMBOSS/2dStructure/Plots\", mode: \"copy\", overwrite: true, pattern: '*Helical*.{svg}'"
        ],
        "when": "",
        "stub": ""
    },
    "pcASV_AminoAcid_Taxonomy_Inference_NCBI": {
        "name_process": "pcASV_AminoAcid_Taxonomy_Inference_NCBI",
        "string_process": " process pcASV_AminoAcid_Taxonomy_Inference_NCBI {\n\n                        label 'high_cpus'\n\n                        tag \"${mtag}\"\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'\n\n                        input:\n                            tuple nid, file(asvs) from pcASV_aaDiamond_ch\n\n                        output:\n                            file(\"*.fasta\") into ( pcASV_labeledAA )\n                            tuple file(\"*phyloformat.csv\"), file(\"*summaryTable.tsv\"), file(\"*dmd.out\") into summary_potuaadiamond\n                            tuple nid, file(\"*_summary_for_plot.csv\") into taxplot4\n                            tuple nid, file(\"*_quick_Taxbreakdown.csv\") into tax_table_pcasvaa\n                            tuple nid, file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_pcasvaa\n\n                        script:\n                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            cp ${params.vampdir}/bin/rename_seq.py .\n                            virdb=${params.dbdir}/${params.dbname}\n                            if [[ ${params.measurement} == \"bitscore\" ]]\n                            then    measure=\"--min-score ${params.bitscore}\"\n                            elif    [[ ${params.measurement} == \"evalue\" ]]\n                            then    measure=\"-e ${params.evalue}\"\n                            else    measure=\"--min-score ${params.bitscore}\"\n                            fi\n                            grep \">\" \\${virdb} > headers.list\n                            headers=\"headers.list\"\n                            name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                            else   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                            fi\n                            echo \"Preparing lists to generate summary .csv's\"\n                            echo \"[Best hit accession number]\" > access.list\n                            echo \"[e-value]\" > evalue.list\n                            echo \"[Bitscore]\" > bit.list\n                            echo \"[Percent ID (aa)]\" > pid.list\n                            echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                            echo \"[Gene]\" > \"\\$name\"_genes.list\n                            echo \"[pcASV#]\" > otu.list\n                            echo \"[Sequence length]\" > length.list\n                            grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                            if [[ ${params.lca} == \"T\" ]]\n                            then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            fi\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                            fi\n                            echo \"extracting genes and names\"\n                            touch new_\"\\$name\"_asvnames.txt\n                            for s in \\$(cat seqids.lst);do\n                                echo \"Checking for \\$s hit in diamond output\"\n                                if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                            echo \"Yep, there was a hit for \\$s\"\n                                            echo \"Extracting the information now:\"\n                                            acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"\\$acc\" >> access.list\n                                            line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                            echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                            echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                            echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                            echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                            echo \"Extracting virus and gene ID for \\$s now\"\n                                            gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                            echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                            virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                            echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                            echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                    then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                          lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                          echo \"\\$lcla\" >> lca_classification.list\n                                                    else  echo \"Viruses\" >> lca_classification.list\n                                                    fi\n                                            fi\n                                            if [[ ${params.ncbitax} == \"true\" ]]\n                                            then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                                else\n                                            echo \"Ugh, there was no hit for \\$s ..\"\n                                            echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"NO_HIT\" >> access.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                            echo \"NO_HIT\" >> evalue.list\n                                            echo \"NO_HIT\" >> bit.list\n                                            echo \"NO_HIT\" >> pid.list\n                                            echo \"NO_HIT\" >> length.list\n                                            virus=\"NO\"\n                                            gene=\"HIT\"\n                                            echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    echo \"N/A\" >> lca_classification.list\n                                            fi\n                                            if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                            then  echo \"N/A\" >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                               fi\n                            done\n                            echo \"Now editing \"\\$name\" fasta headers\"\n                            ###### rename_seq.py\n                            ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                            awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                            echo \"[Sequence header]\" > newnames.list\n                            cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                            touch sequence.list\n                            echo \"     \" > sequence.list\n                            grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                            rm \"\\$name\"_tmpssasv.fasta\n                            if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            else\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            fi\n                            for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                            done\n                            awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                            rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                            \"\"\"\n                        }",
        "nb_lignes_process": 153,
        "string_script": "                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            cp ${params.vampdir}/bin/rename_seq.py .\n                            virdb=${params.dbdir}/${params.dbname}\n                            if [[ ${params.measurement} == \"bitscore\" ]]\n                            then    measure=\"--min-score ${params.bitscore}\"\n                            elif    [[ ${params.measurement} == \"evalue\" ]]\n                            then    measure=\"-e ${params.evalue}\"\n                            else    measure=\"--min-score ${params.bitscore}\"\n                            fi\n                            grep \">\" \\${virdb} > headers.list\n                            headers=\"headers.list\"\n                            name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop staxids sskingdoms skingdoms sphylums --max-target-seqs 1 --max-hsps 1\n                            else   diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                            fi\n                            echo \"Preparing lists to generate summary .csv's\"\n                            echo \"[Best hit accession number]\" > access.list\n                            echo \"[e-value]\" > evalue.list\n                            echo \"[Bitscore]\" > bit.list\n                            echo \"[Percent ID (aa)]\" > pid.list\n                            echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                            echo \"[Gene]\" > \"\\$name\"_genes.list\n                            echo \"[pcASV#]\" > otu.list\n                            echo \"[Sequence length]\" > length.list\n                            grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                            if [[ ${params.lca} == \"T\" ]]\n                            then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                  echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                            fi\n                            if [[ ${params.ncbitax} == \"true\" ]]\n                            then echo \"[NCBI Taxonomy ID],[Taxonomic classification from NCBI]\" > ncbi_classification.list\n                            fi\n                            echo \"extracting genes and names\"\n                            touch new_\"\\$name\"_asvnames.txt\n                            for s in \\$(cat seqids.lst);do\n                                echo \"Checking for \\$s hit in diamond output\"\n                                if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                            echo \"Yep, there was a hit for \\$s\"\n                                            echo \"Extracting the information now:\"\n                                            acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}')\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"\\$acc\" >> access.list\n                                            line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                            echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                            echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                            echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                            echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                            echo \"Extracting virus and gene ID for \\$s now\"\n                                            gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \".\" '{ print \\$2 }' | awk -F \"[\" '{ print \\$1 }' | awk -F \" \" '{print substr(\\$0, index(\\$0,\\$2))}' | sed 's/ /_/g') &&\n                                            echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                            virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{ print \\$1 }'| sed 's/ /_/g')\n                                            echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                            echo \">\"\\${s}\"_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                                    then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                          lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                          echo \"\\$lcla\" >> lca_classification.list\n                                                    else  echo \"Viruses\" >> lca_classification.list\n                                                    fi\n                                            fi\n                                            if [[ ${params.ncbitax} == \"true\" ]]\n                                            then  echo \"\\$line\" | awk -F \"\\t\" '{print \\$14\",\"\\$16\"::\"\\$18\"::\"\\$17}' >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                                else\n                                            echo \"Ugh, there was no hit for \\$s ..\"\n                                            echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                            echo \"\\$s\" >> otu.list\n                                            echo \"NO_HIT\" >> access.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                            echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                            echo \"NO_HIT\" >> evalue.list\n                                            echo \"NO_HIT\" >> bit.list\n                                            echo \"NO_HIT\" >> pid.list\n                                            echo \"NO_HIT\" >> length.list\n                                            virus=\"NO\"\n                                            gene=\"HIT\"\n                                            echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                            if [[ \"${params.lca}\" == \"T\" ]]\n                                            then    echo \"N/A\" >> lca_classification.list\n                                            fi\n                                            if [[ \"${params.ncbitax}\" == \"true\" ]]\n                                            then  echo \"N/A\" >> ncbi_classification.list\n                                            fi\n                                            echo \"\\$s done.\"\n                               fi\n                            done\n                            echo \"Now editing \"\\$name\" fasta headers\"\n                            ###### rename_seq.py\n                            ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                            awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                            echo \"[Sequence header]\" > newnames.list\n                            cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                            touch sequence.list\n                            echo \"     \" > sequence.list\n                            grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                            rm \"\\$name\"_tmpssasv.fasta\n                            if [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" == \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.lca}\" == \"T\" && \"${params.ncbitax}\" != \"true\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            elif [[ \"${params.ncbitax}\" == \"true\" && \"${params.lca}\" != \"T\" ]]\n                            then\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list ncbi_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list ncbi_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                            else\n                                  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                  paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                            fi\n                            for x in *phyloformat.csv;do\n                                echo \"\\$x\"\n                                lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                rm tmpcol.list tmp2col.list\n                            done\n                            awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                            rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                            \"\"\"",
        "nb_lignes_script": 132,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_aaDiamond_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "summary_potuaadiamond",
            "taxplot4",
            "tax_table_pcasvaa",
            "tax_nodCol_pcasvaa"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'"
        ],
        "when": "",
        "stub": ""
    },
    "pcASV_AminoAcid_Taxonomy_Inference_RVDB": {
        "name_process": "pcASV_AminoAcid_Taxonomy_Inference_RVDB",
        "string_process": " process pcASV_AminoAcid_Taxonomy_Inference_RVDB {\n\n                          label 'high_cpus'\n\n                          tag \"${mtag}\"\n\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'\n                          publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'\n\n                          input:\n                              tuple nid, file(asvs) from pcASV_aaDiamond_ch\n\n                          output:\n                              file(\"*.fasta\") into ( pcASV_labeledAA )\n                              tuple file(\"*phyloformat.csv\"), file(\"*summaryTable.tsv\"), file(\"*dmd.out\") into summary_potuaadiamond\n                              tuple nid, file(\"*_summary_for_plot.csv\") into taxplot4\n                              tuple nid, file(\"*_quick_Taxbreakdown.csv\") into tax_table_pcasvaa\n                              tuple nid, file (\"*_quicker_taxbreakdown.csv\") into tax_nodCol_pcasvaa\n\n                          script:\n                              mtag=\"ID=\" + nid\n                              \"\"\"\n                              cp ${params.vampdir}/bin/rename_seq.py .\n                              virdb=${params.dbdir}/${params.dbname}\n                              if [[ ${params.measurement} == \"bitscore\" ]]\n                              then    measure=\"--min-score ${params.bitscore}\"\n                              elif    [[ ${params.measurement} == \"evalue\" ]]\n                              then    measure=\"-e ${params.evalue}\"\n                              else    measure=\"--min-score ${params.bitscore}\"\n                              fi\n                              grep \">\" \\${virdb} > headers.list\n                              headers=\"headers.list\"\n                              name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                              diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                              echo \"Preparing lists to generate summary .csv's\"\n                              echo \"[Best hit accession number]\" > access.list\n                              echo \"[e-value]\" > evalue.list\n                              echo \"[Bitscore]\" > bit.list\n                              echo \"[Percent ID (aa)]\" > pid.list\n                              echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                              echo \"[Gene]\" > \"\\$name\"_genes.list\n                              echo \"[pcASV#]\" > otu.list\n                              echo \"[Sequence length]\" > length.list\n                              grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                              if [[ ${params.lca} == \"T\" ]]\n                              then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              fi\n                              echo \"extracting genes and names\"\n                              touch new_\"\\$name\"_asvnames.txt\n                              for s in \\$(cat seqids.lst);do\n                                  echo \"Using RVDB headers.\"\n                                  if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                      echo \"Yep, there was a hit for \\$s\"\n                                      echo \"Extracting the information now:\"\n                                      acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"\\$acc\" >> access.list\n                                      line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                      echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                      echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                      echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                      echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                      echo \"Extracting virus and gene ID for \\$s now\"\n                                      gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                      echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                      virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                      echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                              then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                    lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                    echo \"\\$lcla\" >> lca_classification.list\n                                              else  echo \"Viruses\" >> lca_classification.list\n                                              fi\n                                      fi\n                                      echo \"\\$s done.\"\n                                  else\n                                      echo \"Ugh, there was no hit for \\$s ..\"\n                                      echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"NO_HIT\" >> access.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                      echo \"NO_HIT\" >> evalue.list\n                                      echo \"NO_HIT\" >> bit.list\n                                      echo \"NO_HIT\" >> pid.list\n                                      echo \"NO_HIT\" >> length.list\n                                      virus=\"NO\"\n                                      gene=\"HIT\"\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    echo \"N/A\" >> lca_classification.list\n                                      fi\n                                      echo \"\\$s done.\"\n                                  fi\n                              echo \"Done with \\$s\"\n                              done\n                              echo \"Now editing \"\\$name\" fasta headers\"\n                              ###### rename_seq.py\n                              ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                              awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                              echo \"[Sequence header]\" > newnames.list\n                              cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                              touch sequence.list\n                              echo \"     \" > sequence.list\n                              grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                              rm \"\\$name\"_tmpssasv.fasta\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                    paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                              else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              fi\n                              for x in *phyloformat.csv;do\n                                        echo \"\\$x\"\n                                        lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                        tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                        sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                        cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                        rm tmpcol.list tmp2col.list\n                              done\n                              awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                              rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                              \"\"\"\n                    }",
        "nb_lignes_process": 129,
        "string_script": "                              mtag=\"ID=\" + nid\n                              \"\"\"\n                              cp ${params.vampdir}/bin/rename_seq.py .\n                              virdb=${params.dbdir}/${params.dbname}\n                              if [[ ${params.measurement} == \"bitscore\" ]]\n                              then    measure=\"--min-score ${params.bitscore}\"\n                              elif    [[ ${params.measurement} == \"evalue\" ]]\n                              then    measure=\"-e ${params.evalue}\"\n                              else    measure=\"--min-score ${params.bitscore}\"\n                              fi\n                              grep \">\" \\${virdb} > headers.list\n                              headers=\"headers.list\"\n                              name=\\$( echo ${asvs} | awk -F \".fasta\" '{print \\$1}')\n                              diamond blastp -q ${asvs} -d \\${virdb} -p ${task.cpus} --id ${params.minID} -l ${params.minaln} \\${measure} --${params.sensitivity} -o \"\\$name\"_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1\n                              echo \"Preparing lists to generate summary .csv's\"\n                              echo \"[Best hit accession number]\" > access.list\n                              echo \"[e-value]\" > evalue.list\n                              echo \"[Bitscore]\" > bit.list\n                              echo \"[Percent ID (aa)]\" > pid.list\n                              echo \"[Organism ID]\" > \"\\$name\"_virus.list\n                              echo \"[Gene]\" > \"\\$name\"_genes.list\n                              echo \"[pcASV#]\" > otu.list\n                              echo \"[Sequence length]\" > length.list\n                              grep \">\" ${asvs} | awk -F \">\" '{print \\$2}' > seqids.lst\n                              if [[ ${params.lca} == \"T\" ]]\n                              then  grep -w \"LCA\" ${params.dbanno}/*.txt > lcainfo.list\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              else  echo \"skipped\" >> \\${name}_quick_Taxbreakdown.csv\n                                    echo \"[Taxonomic classification from RVDB annotations]\" > lca_classification.list\n                              fi\n                              echo \"extracting genes and names\"\n                              touch new_\"\\$name\"_asvnames.txt\n                              for s in \\$(cat seqids.lst);do\n                                  echo \"Using RVDB headers.\"\n                                  if [[ \"\\$(grep -wc \"\\$s\" \"\\$name\"_dmd.out)\" -eq 1 ]];then\n                                      echo \"Yep, there was a hit for \\$s\"\n                                      echo \"Extracting the information now:\"\n                                      acc=\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out | awk '{print \\$3}' | awk -F \"|\" '{print \\$3}')\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"\\$acc\" >> access.list\n                                      line=\"\\$(grep -w \"\\$s\" \"\\$name\"_dmd.out)\"\n                                      echo \"\\$line\" | awk '{print \\$10}' >> evalue.list\n                                      echo \"\\$line\" | awk '{print \\$11}' >> bit.list\n                                      echo \"\\$line\" | awk '{print \\$12}' >> pid.list\n                                      echo \"\\$line\" | awk '{print \\$2}' >> length.list\n                                      echo \"Extracting virus and gene ID for \\$s now\"\n                                      gene=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$1 }' | sed 's/ /_/g') &&\n                                      echo \"\\$gene\" | sed 's/_/ /g' >> \"\\$name\"_genes.list\n                                      virus=\\$(grep -w \"\\$acc\" \"\\$headers\" | awk -F \"|\" '{ print \\$6 }' | awk -F \"[\" '{ print \\$2 }' | awk -F \"]\" '{print \\$1}' | sed 's/ /_/g') &&\n                                      echo \"\\$virus\" | sed 's/_/ /g' >> \"\\$name\"_virus.list\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    if [[ \\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | wc -l) -eq 1 ]]\n                                              then  group=\\$(grep -w \"\\$acc\" ${params.dbanno}/*.txt | awk -F \":\" '{print \\$1}')\n                                                    lcla=\\$(grep -w \"\\$group\" lcainfo.list | awk -F \"\\t\" '{print \\$2}')\n                                                    echo \"\\$lcla\" >> lca_classification.list\n                                              else  echo \"Viruses\" >> lca_classification.list\n                                              fi\n                                      fi\n                                      echo \"\\$s done.\"\n                                  else\n                                      echo \"Ugh, there was no hit for \\$s ..\"\n                                      echo \"We still love \\$s though and we will add it to the final fasta file\"\n                                      echo \"\\$s\" >> otu.list\n                                      echo \"NO_HIT\" >> access.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_genes.list\n                                      echo \"NO_HIT\" >> \"\\$name\"_virus.list\n                                      echo \"NO_HIT\" >> evalue.list\n                                      echo \"NO_HIT\" >> bit.list\n                                      echo \"NO_HIT\" >> pid.list\n                                      echo \"NO_HIT\" >> length.list\n                                      virus=\"NO\"\n                                      gene=\"HIT\"\n                                      echo \">\\${s}_\"\\$virus\"_\"\\$gene\"\" >> new_\"\\$name\"_asvnames.txt\n                                      if [[ \"${params.lca}\" == \"T\" ]]\n                                      then    echo \"N/A\" >> lca_classification.list\n                                      fi\n                                      echo \"\\$s done.\"\n                                  fi\n                              echo \"Done with \\$s\"\n                              done\n                              echo \"Now editing \"\\$name\" fasta headers\"\n                              ###### rename_seq.py\n                              ./rename_seq.py ${asvs} new_\"\\$name\"_asvnames.txt \"\\$name\"_TaxonomyLabels.fasta\n                              awk 'BEGIN {RS=\">\";FS=\"\\\\n\";OFS=\"\"} NR>1 {print \">\"\\$1; \\$1=\"\"; print}' \"\\$name\"_TaxonomyLabels.fasta >\"\\$name\"_tmpssasv.fasta\n                              echo \"[Sequence header]\" > newnames.list\n                              cat new_\"\\$name\"_asvnames.txt >> newnames.list\n                              touch sequence.list\n                              echo \"     \" > sequence.list\n                              grep -v \">\" \"\\$name\"_tmpssasv.fasta >> sequence.list\n                              rm \"\\$name\"_tmpssasv.fasta\n                              if [[ \"${params.lca}\" == \"T\" ]]\n                              then  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list lca_classification.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                                    paste -d\",\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list lca_classification.list >> \\${name}_quick_Taxbreakdown.csv\n                              else  paste -d \",\" sequence.list \"\\$name\"_virus.list \"\\$name\"_genes.list otu.list newnames.list length.list bit.list evalue.list pid.list access.list >> \"\\$name\"_phyloformat.csv\n                                    paste -d\"\\t\" otu.list access.list \"\\$name\"_virus.list \"\\$name\"_genes.list sequence.list length.list bit.list evalue.list pid.list >> \"\\$name\"_summaryTable.tsv\n                              fi\n                              for x in *phyloformat.csv;do\n                                        echo \"\\$x\"\n                                        lin=\\$(( \\$(wc -l \\$x | awk '{print \\$1}')-1))\n                                        tail -\"\\$lin\" \\$x | awk -F \",\" '{print \\$2}' > tmpcol.list;\n                                        sed 's/ /_/g' tmpcol.list > tmp2col.list;\n                                        cat tmp2col.list | sort | uniq -c | sort -nr | awk '{print \\$2\",\"\\$1}' > \\${name}_summary_for_plot.csv;\n                                        rm tmpcol.list tmp2col.list\n                              done\n                              awk -F \",\" '{print \\$1\",\"\\$3\"(\"\\$2\")\"}' \\${name}_quick_Taxbreakdown.csv >> \\${name}_quicker_taxbreakdown.csv\n                              rm evalue.list sequence.list bit.list pid.list length.list seqids.lst otu.list *asvnames.txt \"\\$name\"_virus.list \"\\$name\"_genes.list newnames.list access.list headers.list\n                              \"\"\"",
        "nb_lignes_script": 108,
        "language_script": "bash",
        "tools": [
            "Diamond"
        ],
        "tools_url": [
            "https://bio.tools/diamond"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            }
        ],
        "inputs": [
            "pcASV_aaDiamond_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "summary_potuaadiamond",
            "taxplot4",
            "tax_table_pcasvaa",
            "tax_nodCol_pcasvaa"
        ],
        "nb_outputs": 5,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/SummaryFiles\", mode: \"copy\", overwrite: true, pattern: '*.{csv,tsv}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy/DiamondOutput\", mode: \"copy\", overwrite: true, pattern: '*dmd.{out}'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Taxonomy\", mode: \"copy\", overwrite: true, pattern: '*.{fasta}'"
        ],
        "when": "",
        "stub": ""
    },
    "skippcASVprotTaxonomy": {
        "name_process": "skippcASVprotTaxonomy",
        "string_process": " process skippcASVprotTaxonomy {\n\n                    input:\n                        tuple nid, file(asvs) from pcASV_aaDiamond_ch\n\n                    output:\n                        tuple nid, file(\"skipncASVprottax1.txt\") into taxplot4\n                        tuple nid, file(\"skipncASVprottax2.txt\") into tax_table_pcasvaa\n                        tuple nid, file(\"skipncASVprottax3.txt\") into tax_nodCol_pcasvaa\n\n                    script:\n                        \"\"\"\n                        echo \"Skipped\" >skipncASVprottax1.txt\n                        echo \"Skipped\" >skipncASVprottax2.txt\n                        echo \"Skipped\" >skipncASVprottax3.txt\n                        \"\"\"\n                }",
        "nb_lignes_process": 15,
        "string_script": "                        \"\"\"\n                        echo \"Skipped\" >skipncASVprottax1.txt\n                        echo \"Skipped\" >skipncASVprottax2.txt\n                        echo \"Skipped\" >skipncASVprottax3.txt\n                        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_aaDiamond_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "taxplot4",
            "tax_table_pcasvaa",
            "tax_nodCol_pcasvaa"
        ],
        "nb_outputs": 3,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "pcASV_Protein_Phylogeny": {
        "name_process": "pcASV_Protein_Phylogeny",
        "string_process": " process pcASV_Protein_Phylogeny {\n\n                        label 'norm_cpus'\n\n                        tag \"${mtag}\"\n\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*aln.*'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Phylogeny/Modeltest\", mode: \"copy\", overwrite: true, pattern: '*mt*'\n                        publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'\n\n            \t        input:\n                            tuple nid, file(prot) from pcASV_aaMafft_ch\n\n                        output:\n                            tuple file(\"*_aln.fasta\"), file(\"*_aln.html\"), file(\"*.tree\"), file(\"*.log\"), file(\"*iq*\"), file(\"*mt*\") into pcASV_protein_phylogeny_results\n                            tuple nid, file(\"*iq.treefile\") into potu_Atree_plot\n\n                        script:\n                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            pre=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}' )\n                            if [[ \\$(grep -c \">\" ${prot}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                            ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${prot} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                            trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                            o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                            mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                            # pcASV_Protein_ModelTest\n                            modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d aa -s 203 --disable-checkpoint\n\n                            # pcASV_Protein_Phylogeny\n                            if [ \"${params.iqCustomaa}\" != \"\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -T auto ${params.iqCustomaa}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo  -nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                            else\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"\n                    }",
        "nb_lignes_process": 50,
        "string_script": "                            mtag=\"ID=\" + nid\n                            \"\"\"\n                            pre=\\$( echo ${prot} | awk -F \".fasta\" '{print \\$1}' )\n                            if [[ \\$(grep -c \">\" ${prot}) -gt 499 ]]; then algo=\"super5\"; else algo=\"mpc\"; fi\n                            ${tools}/muscle5.0.1278_linux64 -\"\\${algo}\" ${prot} -out \\${pre}_ALN.fasta -threads ${task.cpus} -quiet\n                            trimal -in \\${pre}_ALN.fasta -out \\${pre}_aln.fasta -keepheader -fasta -automated1 -htmlout \\${pre}_aln.html\n                            o-trim-uninformative-columns-from-alignment \\${pre}_aln.fasta\n                            mv \\${pre}_aln.fasta-TRIMMED ./\\${pre}_Aligned_informativeonly.fasta\n                            # pcASV_Protein_ModelTest\n                            modeltest-ng -i \\${pre}_Aligned_informativeonly.fasta -p ${task.cpus} -o \\${pre}_mt -d aa -s 203 --disable-checkpoint\n\n                            # pcASV_Protein_Phylogeny\n                            if [ \"${params.iqCustomaa}\" != \"\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq --redo -T auto ${params.iqCustomaa}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.nonparametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo  -nt auto -b ${params.boots}\n\n                            elif [[ \"${params.ModelTaa}\" != \"false\" && \"${params.parametric}\" != \"false\" ]];then\n                                mod=\\$(tail -12 \\${pre}_Aligned_informativeonly.fasta.log | head -1 | awk '{print \\$6}')\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m \\${mod} --redo -nt auto -bb ${params.boots} -bnni\n\n                            elif [ \"${params.nonparametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -b ${params.boots}\n\n                            elif [ \"${params.parametric}\" != \"false\" ];then\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n\n                            else\n                                iqtree -s \\${pre}_Aligned_informativeonly.fasta --prefix \\${pre}_iq -m MFP --redo -nt auto -bb ${params.boots} -bnni\n                            fi\n                            \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "trimAl",
            "ModelTest-NG"
        ],
        "tools_url": [
            "https://bio.tools/trimal",
            "https://bio.tools/ModelTest-NG"
        ],
        "tools_dico": [
            {
                "name": "trimAl",
                "uri": "https://bio.tools/trimal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            }
                        ]
                    }
                ],
                "description": "Tool for the automated removal of spurious sequences or poorly aligned regions from a multiple sequence alignment.",
                "homepage": "http://trimal.cgenomics.org"
            },
            {
                "name": "ModelTest-NG",
                "uri": "https://bio.tools/ModelTest-NG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3293",
                            "term": "Phylogenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3316",
                            "term": "Computer science"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A new and scalable tool for the selection of DNA and protein evolutionary models | ModelTest-NG is a tool for selecting the best-fit model of evolution for DNA and protein alignments. ModelTest-NG supersedes jModelTest and ProtTest in one single tool, with graphical and command console interfaces",
                "homepage": "https://github.com/ddarriba/modeltest"
            }
        ],
        "inputs": [
            "pcASV_aaMafft_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcASV_protein_phylogeny_results",
            "potu_Atree_plot"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Phylogeny/Alignment\", mode: \"copy\", overwrite: true, pattern: '*aln.*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Phylogeny/Modeltest\", mode: \"copy\", overwrite: true, pattern: '*mt*'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Phylogeny/IQ-TREE\", mode: \"copy\", overwrite: true, pattern: '*iq*'"
        ],
        "when": "",
        "stub": ""
    },
    "skippcASVprotPhylogeny": {
        "name_process": "skippcASVprotPhylogeny",
        "string_process": " process skippcASVprotPhylogeny {\n\n                        input:\n                            tuple nid, file(prot) from pcASV_aaMafft_ch\n\n                        output:\n                            tuple nid, file(\"skippcASVprotPhylogeny.txt\") into ( potu_Atree_plot )\n\n                        script:\n                            \"\"\"\n                            echo \"Skipped\" >skippcASVprotPhylogeny.txt\n                            \"\"\"\n                    }",
        "nb_lignes_process": 11,
        "string_script": "                            \"\"\"\n                            echo \"Skipped\" >skippcASVprotPhylogeny.txt\n                            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcASV_aaMafft_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Generate_pcASV_Protein_Counts": {
        "name_process": "Generate_pcASV_Protein_Counts",
        "string_process": " process Generate_pcASV_Protein_Counts {\n\n                    label 'high_cpus'\n\n                    tag \"${mtag}\"\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Counts\", mode: \"copy\", overwrite: true\n\n                    input:\n                        tuple nid, file(fasta) from pcASV_aaCounts_ch\n                        file(merged) from mergeforpcASVaacounts\n                        file(samplist) from samplistpotu\n\n                    output:\n                        tuple file(\"*_counts.csv\"), file(\"*dmd.out\") into potuaacounts_summary\n                        tuple nid, file(\"*counts.csv\") into potu_Acounts\n\n                    script:\n                                                   \n                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        set +e\n                        potu=\"\\$( echo ${fasta} | awk -F \"_\" '{print \\$3}')\"\n                        diamond makedb --in ${fasta} --db ${fasta}\n                        diamond blastx -q ${merged} -d ${fasta} -p ${task.cpus} --min-score ${params.ProtCountsBit} --id ${params.ProtCountID} -l ${params.ProtCountsLength} --${params.sensitivity} -o ${params.projtag}_\\${potu}_Counts_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1 --max-hsps 1\n                        echo \"OTU_ID\" >tmp.col1.txt\n                        echo \"Generating sample id list\"\n                        grep \">\" ${fasta} | awk -F \">\" '{print \\$2}' | sort | uniq > otuid.list\n                        cat otuid.list >> tmp.col1.txt\n                        echo \"Beginning them counts tho my g\"\n                        for y in \\$( cat ${samplist} );do\n                            echo \"Starting with \\$y now ...\"\n                            grep \"\\$y\" ${params.projtag}_\\${potu}_Counts_dmd.out > tmp.\"\\$y\".out\n                            echo \"Isolated hits\"\n                            echo \"Created uniq subject id list\"\n                            echo \"\\$y\" > \"\\$y\"_col.txt\n                            echo \"Starting my counts\"\n                            for z in \\$(cat otuid.list);do\n                                echo \"Counting \\$z hits\"\n                \t            echo \"grep -wc \"\\$z\" >> \"\\$y\"_col.txt\"\n                \t            grep -wc \"\\$z\" tmp.\"\\$y\".out >> \"\\$y\"_col.txt\n            \t\t            echo \"\\$z counted\"\n            \t            done\n                       done\n                       paste -d \",\" tmp.col1.txt *col.txt > ${params.projtag}_aminoacid_\\${potu}_noTaxonomy_counts.csv\n                       rm tmp*\n                       rm *col.txt\n                       \"\"\"\n                   }",
        "nb_lignes_process": 47,
        "string_script": "                        mtag=\"ID=\" + nid\n                        \"\"\"\n                        set +e\n                        potu=\"\\$( echo ${fasta} | awk -F \"_\" '{print \\$3}')\"\n                        diamond makedb --in ${fasta} --db ${fasta}\n                        diamond blastx -q ${merged} -d ${fasta} -p ${task.cpus} --min-score ${params.ProtCountsBit} --id ${params.ProtCountID} -l ${params.ProtCountsLength} --${params.sensitivity} -o ${params.projtag}_\\${potu}_Counts_dmd.out -f 6 qseqid qlen sseqid qstart qend qseq sseq length qframe evalue bitscore pident btop --max-target-seqs 1 --max-hsps 1 --max-hsps 1\n                        echo \"OTU_ID\" >tmp.col1.txt\n                        echo \"Generating sample id list\"\n                        grep \">\" ${fasta} | awk -F \">\" '{print \\$2}' | sort | uniq > otuid.list\n                        cat otuid.list >> tmp.col1.txt\n                        echo \"Beginning them counts tho my g\"\n                        for y in \\$( cat ${samplist} );do\n                            echo \"Starting with \\$y now ...\"\n                            grep \"\\$y\" ${params.projtag}_\\${potu}_Counts_dmd.out > tmp.\"\\$y\".out\n                            echo \"Isolated hits\"\n                            echo \"Created uniq subject id list\"\n                            echo \"\\$y\" > \"\\$y\"_col.txt\n                            echo \"Starting my counts\"\n                            for z in \\$(cat otuid.list);do\n                                echo \"Counting \\$z hits\"\n                \t            echo \"grep -wc \"\\$z\" >> \"\\$y\"_col.txt\"\n                \t            grep -wc \"\\$z\" tmp.\"\\$y\".out >> \"\\$y\"_col.txt\n            \t\t            echo \"\\$z counted\"\n            \t            done\n                       done\n                       paste -d \",\" tmp.col1.txt *col.txt > ${params.projtag}_aminoacid_\\${potu}_noTaxonomy_counts.csv\n                       rm tmp*\n                       rm *col.txt\n                       \"\"\"",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [
            "Diamond"
        ],
        "tools_url": [
            "https://bio.tools/diamond"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            }
        ],
        "inputs": [
            "pcASV_aaCounts_ch",
            "mergeforpcASVaacounts",
            "samplistpotu"
        ],
        "nb_inputs": 3,
        "outputs": [
            "potuaacounts_summary",
            "potu_Acounts"
        ],
        "nb_outputs": 2,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'high_cpus'",
            "tag \"${mtag}\"",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/Analyses/pcASV/Aminoacid/Counts\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "combine_csv": {
        "name_process": "combine_csv",
        "string_process": " process combine_csv {\n\n                        input:\n                            file(csv) from fastp_csv_in2\n                                .collect()\n\n                        output:\n                            file(\"final_reads_stats.csv\") into fastp_csv_in\n\n                        script:\n                            \"\"\"\n                            cat ${csv} >all_reads_stats.csv\n                            head -n1 all_reads_stats.csv >tmp.names.csv\n                            cat all_reads_stats.csv | grep -v \"\"Sample,Total_\"\" >tmp.reads.stats.csv\n                            cat tmp.names.csv tmp.reads.stats.csv >final_reads_stats.csv\n                            rm tmp.names.csv tmp.reads.stats.csv\n                            \"\"\"\n                    }",
        "nb_lignes_process": 16,
        "string_script": "                            \"\"\"\n                            cat ${csv} >all_reads_stats.csv\n                            head -n1 all_reads_stats.csv >tmp.names.csv\n                            cat all_reads_stats.csv | grep -v \"\"Sample,Total_\"\" >tmp.reads.stats.csv\n                            cat tmp.names.csv tmp.reads.stats.csv >final_reads_stats.csv\n                            rm tmp.names.csv tmp.reads.stats.csv\n                            \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastp_csv_in2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastp_csv_in"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "skip_combine_csv": {
        "name_process": "skip_combine_csv",
        "string_process": " process skip_combine_csv {\n\n                        output:\n                            file(\"filter_reads.txt\") into fastp_csv_in\n\n                        script:\n                            \"\"\"\n                            echo \"Read processing steps skipped.\" >filter_reads.txt\n                            \"\"\"\n                    }",
        "nb_lignes_process": 8,
        "string_script": "                            \"\"\"\n                            echo \"Read processing steps skipped.\" >filter_reads.txt\n                            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "fastp_csv_in"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Report": {
        "name_process": "Report",
        "string_process": " process Report {\n\n                    label 'norm_cpus'\n\n                    publishDir \"${params.workingdir}/${params.outdir}/Analyze/FinalReports\", mode: \"copy\", overwrite: true\n\n                    input:\n                        file(csv) from fastp_csv_in\n                        file(files) from report_all_ch\n\n                    output:\n                        file(\"*.html\") into report_all_out\n\n                    script:\n                        \"\"\"\n                        name=\\$( ls *_counts.csv | awk -F \"_counts.csv\" '{print \\$1}')\n                        type=\\$( ls *_counts.csv | awk -F \"${params.projtag}\" '{print \\$2}' | awk -F \"_\" '{print \\$2}'  )\n                        cp ${params.vampdir}/bin/vAMPirus_Report.Rmd .\n                        cp ${params.vampdir}/example_data/conf/vamplogo.png .\n                        Rscript -e \"rmarkdown::render('vAMPirus_Report.Rmd',output_file='\\${name}_Report.html')\" \\${name} \\\n                        ${params.skipReadProcessing} \\\n                        ${params.skipMerging} \\\n                        ${params.skipAdapterRemoval} \\\n                        ${params.skipTaxonomy} \\\n                        ${params.skipPhylogeny} \\\n                        ${params.trymax} \\\n                        ${params.stats} \\\n                        ${params.metadata} \\\n                        ${params.minimumCounts} \\\n                        ${params.asvMED} \\\n                        ${params.aminoMED} \\\n                        \\${type} \\\n                        ${params.nodeCol} \\\n                        ${params.asvTClust} \\\n                        ${params.aminoTClust}\n                        \"\"\"\n                }",
        "nb_lignes_process": 35,
        "string_script": "                        \"\"\"\n                        name=\\$( ls *_counts.csv | awk -F \"_counts.csv\" '{print \\$1}')\n                        type=\\$( ls *_counts.csv | awk -F \"${params.projtag}\" '{print \\$2}' | awk -F \"_\" '{print \\$2}'  )\n                        cp ${params.vampdir}/bin/vAMPirus_Report.Rmd .\n                        cp ${params.vampdir}/example_data/conf/vamplogo.png .\n                        Rscript -e \"rmarkdown::render('vAMPirus_Report.Rmd',output_file='\\${name}_Report.html')\" \\${name} \\\n                        ${params.skipReadProcessing} \\\n                        ${params.skipMerging} \\\n                        ${params.skipAdapterRemoval} \\\n                        ${params.skipTaxonomy} \\\n                        ${params.skipPhylogeny} \\\n                        ${params.trymax} \\\n                        ${params.stats} \\\n                        ${params.metadata} \\\n                        ${params.minimumCounts} \\\n                        ${params.asvMED} \\\n                        ${params.aminoMED} \\\n                        \\${type} \\\n                        ${params.nodeCol} \\\n                        ${params.asvTClust} \\\n                        ${params.aminoTClust}\n                        \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastp_csv_in",
            "report_all_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "report_all_out"
        ],
        "nb_outputs": 1,
        "name_workflow": "Aveglia__vAMPirus",
        "directive": [
            "label 'norm_cpus'",
            "publishDir \"${params.workingdir}/${params.outdir}/Analyze/FinalReports\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    }
}