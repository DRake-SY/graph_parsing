{
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n    publishDir \"${params.outdir}/pipeline_info\", mode: 'copy',\n    saveAs: {filename ->\n        if (filename.indexOf(\".csv\") > 0) filename\n        else null\n    }\n\n    output:\n    file 'software_versions_mqc.yaml' into software_versions_yaml\n    file \"software_versions.csv\"\n\n    script:\n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    msgf_plus | head -n1 > v_msgf.txt\n    percolator -h |& head -n1 > v_perco.txt || true\n    msspsmtable --version > v_mss.txt\n    source activate openms-2.4.0\n    IsobaricAnalyzer |& grep Version > v_openms.txt || true\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    msgf_plus | head -n1 > v_msgf.txt\n    percolator -h |& head -n1 > v_perco.txt || true\n    msspsmtable --version > v_mss.txt\n    source activate openms-2.4.0\n    IsobaricAnalyzer |& grep Version > v_openms.txt || true\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "Percolator"
        ],
        "tools_url": [
            "https://bio.tools/percolator"
        ],
        "tools_dico": [
            {
                "name": "Percolator",
                "uri": "https://bio.tools/percolator",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3631",
                                    "term": "Peptide identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3648",
                                    "term": "Validation of peptide-spectrum matches"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3767",
                                    "term": "Protein identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fragment weight comparison"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Blind peptide database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3649",
                                    "term": "Target-Decoy"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3631",
                                    "term": "Peptide-spectrum-matching"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3767",
                                    "term": "Protein inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "PMF"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Peptide mass fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Modification-tolerant peptide database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Unrestricted peptide database search"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0945",
                                "term": "Peptide identification"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0945",
                                "term": "Peptide identification"
                            }
                        ]
                    }
                ],
                "description": "Semi-supervised learning for peptide identification from MS/MS data.",
                "homepage": "http://noble.gs.washington.edu/proj/percolator/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "software_versions_yaml"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: 'copy' , saveAs: {filename -> if (filename.indexOf(\".csv\") > 0) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "quantifySpectra": {
        "name_process": "quantifySpectra",
        "string_process": "\nprocess quantifySpectra {\n\n  input:\n  set file(infile), val(filename), val(channel), val(sample) from mzml_quant\n\n  output:\n  set val(filename), file(\"${infile}.consensusXML\") into isobaricxml\n\n  script:\n  activationtype = [hcd:'High-energy collision-induced dissociation', cid:'Collision-induced dissociation', etd:'Electron transfer dissociation'][params.activation]\n  massshift = [tmt:0.0013, itraq:0.00125][plextype]\n  \"\"\"\n  source activate openms-2.4.0\n  IsobaricAnalyzer  -type $params.isobaric -in $infile -out \\\"${infile}.consensusXML\\\" -extraction:select_activation \\\"$activationtype\\\" -extraction:reporter_mass_shift $massshift -extraction:min_precursor_intensity 1.0 -extraction:keep_unannotated_precursor true -quantification:isotope_correction true\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  activationtype = [hcd:'High-energy collision-induced dissociation', cid:'Collision-induced dissociation', etd:'Electron transfer dissociation'][params.activation]\n  massshift = [tmt:0.0013, itraq:0.00125][plextype]\n  \"\"\"\n  source activate openms-2.4.0\n  IsobaricAnalyzer  -type $params.isobaric -in $infile -out \\\"${infile}.consensusXML\\\" -extraction:select_activation \\\"$activationtype\\\" -extraction:reporter_mass_shift $massshift -extraction:min_precursor_intensity 1.0 -extraction:keep_unannotated_precursor true -quantification:isotope_correction true\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mzml_quant"
        ],
        "nb_inputs": 1,
        "outputs": [
            "isobaricxml"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "createSpectraLookup": {
        "name_process": "createSpectraLookup",
        "string_process": "\nprocess createSpectraLookup {\n\n  input:\n  set file(mzmlfiles), val(filenames) from mzmlfiles_all\n\n  output:\n  file 'mslookup_db.sqlite' into speclookup \n\n  script:\n  \"\"\"\n  msslookup spectra -i ${mzmlfiles.join(' ')} --setnames ${filenames.join(' ')}\n  \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "  \"\"\"\n  msslookup spectra -i ${mzmlfiles.join(' ')} --setnames ${filenames.join(' ')}\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mzmlfiles_all"
        ],
        "nb_inputs": 1,
        "outputs": [
            "speclookup"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "quantLookup": {
        "name_process": "quantLookup",
        "string_process": "\nprocess quantLookup {\n\n  input:\n  file lookup from speclookup\n  file(isofns) from isofiles_sorted\n\n  output:\n  file 'db.sqlite' into quantlookup\n\n  script:\n  \"\"\"\n  # SQLite lookup needs copying to not modify the input file which would mess up a rerun with -resume\n  cat $lookup > db.sqlite\n  msslookup isoquant --dbfile db.sqlite -i ${isofns.join(' ')} --spectra ${isofns.collect{ x -> x.baseName.replaceFirst(/\\.consensusXML/, \"\")}.join(' ')}\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  # SQLite lookup needs copying to not modify the input file which would mess up a rerun with -resume\n  cat $lookup > db.sqlite\n  msslookup isoquant --dbfile db.sqlite -i ${isofns.join(' ')} --spectra ${isofns.collect{ x -> x.baseName.replaceFirst(/\\.consensusXML/, \"\")}.join(' ')}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "speclookup",
            "isofiles_sorted"
        ],
        "nb_inputs": 2,
        "outputs": [
            "quantlookup"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "createTargetDecoyFasta": {
        "name_process": "createTargetDecoyFasta",
        "string_process": "\nprocess createTargetDecoyFasta {\n \n  input:\n  file(tdb)\n\n  output:\n  file('db.fa') into concatdb\n\n  script:\n  \"\"\"\n  msslookup makedecoy -i \"$tdb\" -o decoy.fa --scramble tryp_rev --ignore-target-hits\n  cat \"$tdb\" decoy.fa > db.fa\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  msslookup makedecoy -i \"$tdb\" -o decoy.fa --scramble tryp_rev --ignore-target-hits\n  cat \"$tdb\" decoy.fa > db.fa\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tdb"
        ],
        "nb_inputs": 1,
        "outputs": [
            "concatdb"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "msgfPlus": {
        "name_process": "msgfPlus",
        "string_process": "\nprocess msgfPlus {\n  cpus = config.poolSize < 2 ? config.poolSize : 2\n\n  input:\n  set file(x), val(filename), val(channel), val(sample) from mzml_msgf\n  file(db) from concatdb\n  file mods\n\n  output:\n  set val(filename), val(channel), val(sample), file(\"${filename}.mzid\") into mzids\n  set val(filename), file(\"${filename}.mzid\"), file('out.mzid.tsv') into mzidtsvs\n  \n  script:\n  plex = plexmap[params.isobaric]\n  msgfprotocol = 0                             \n  msgfinstrument = [orbi:1, velos:1, qe:3, lowres:0, tof:2][params.instrument]\n  \"\"\"\n  # dynamically add isobaric type to mod file\n  cat $mods > iso_mods\n  echo ${plex[1]},*,opt,N-term,${plex[0]} >> iso_mods\n  echo ${plex[1]},K,opt,any,${plex[0]} >> iso_mods\n  # run search and create TSV, cleanup afterwards\n  msgf_plus -Xmx8G -d $db -s $x -o \"${filename}.mzid\" -thread ${task.cpus * 3} -mod iso_mods -tda 0 -t 10.0ppm -ti -1,2 -m 0 -inst ${msgfinstrument} -e 1 -protocol ${msgfprotocol} -ntt 2 -minLength 7 -maxLength 50 -minCharge 2 -maxCharge 6 -n 1 -addFeatures 1\n  msgf_plus -Xmx3500M edu.ucsd.msjava.ui.MzIDToTsv -i \"${filename}.mzid\" -o out.mzid.tsv\n  rm ${db.baseName.replaceFirst(/\\.fasta/, \"\")}.c*\n  \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "  plex = plexmap[params.isobaric]\n  msgfprotocol = 0                             \n  msgfinstrument = [orbi:1, velos:1, qe:3, lowres:0, tof:2][params.instrument]\n  \"\"\"\n  # dynamically add isobaric type to mod file\n  cat $mods > iso_mods\n  echo ${plex[1]},*,opt,N-term,${plex[0]} >> iso_mods\n  echo ${plex[1]},K,opt,any,${plex[0]} >> iso_mods\n  # run search and create TSV, cleanup afterwards\n  msgf_plus -Xmx8G -d $db -s $x -o \"${filename}.mzid\" -thread ${task.cpus * 3} -mod iso_mods -tda 0 -t 10.0ppm -ti -1,2 -m 0 -inst ${msgfinstrument} -e 1 -protocol ${msgfprotocol} -ntt 2 -minLength 7 -maxLength 50 -minCharge 2 -maxCharge 6 -n 1 -addFeatures 1\n  msgf_plus -Xmx3500M edu.ucsd.msjava.ui.MzIDToTsv -i \"${filename}.mzid\" -o out.mzid.tsv\n  rm ${db.baseName.replaceFirst(/\\.fasta/, \"\")}.c*\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "PLEXY"
        ],
        "tools_url": [
            "https://bio.tools/plexy"
        ],
        "tools_dico": [
            {
                "name": "PLEXY",
                "uri": "https://bio.tools/plexy",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0082",
                            "term": "Structure prediction"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0278",
                                    "term": "RNA secondary structure prediction"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0850",
                                "term": "Sequence set"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0880",
                                "term": "RNA secondary structure"
                            }
                        ]
                    }
                ],
                "description": "PLEXY is a tool for computation of optimal thermodynamical interactions of a box C/D snoRNA with a putative target RNA. It is based on RNAPLEX.",
                "homepage": "http://www.bioinf.uni-leipzig.de/Software/PLEXY/"
            }
        ],
        "inputs": [
            "mzml_msgf",
            "concatdb",
            "mods"
        ],
        "nb_inputs": 3,
        "outputs": [
            "mzids",
            "mzidtsvs"
        ],
        "nb_outputs": 2,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [
            "cpus = config.poolSize < 2 ? config.poolSize : 2"
        ],
        "when": "",
        "stub": ""
    },
    "percolator": {
        "name_process": "percolator",
        "string_process": "\nprocess percolator {\n\n  input:\n  set val(filename), val(channel), val(sample), file(mzids) from mzids_2pin\n\n  output:\n  set val(filename), val(channel), val(sample), file('perco.xml') into percolated\n\n  \"\"\"\n  for mzid in ${mzids.join(' ')}; do echo \\${mzid} >> metafile; done\n  msgf2pin -o percoin.xml -e trypsin -P \"decoy_\" metafile\n  percolator -j percoin.xml -X perco.xml -N 500000 --decoy-xml-output\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n  for mzid in ${mzids.join(' ')}; do echo \\${mzid} >> metafile; done\n  msgf2pin -o percoin.xml -e trypsin -P \"decoy_\" metafile\n  percolator -j percoin.xml -X perco.xml -N 500000 --decoy-xml-output\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "Percolator"
        ],
        "tools_url": [
            "https://bio.tools/percolator"
        ],
        "tools_dico": [
            {
                "name": "Percolator",
                "uri": "https://bio.tools/percolator",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3631",
                                    "term": "Peptide identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3648",
                                    "term": "Validation of peptide-spectrum matches"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3767",
                                    "term": "Protein identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fragment weight comparison"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Blind peptide database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3649",
                                    "term": "Target-Decoy"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3631",
                                    "term": "Peptide-spectrum-matching"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3767",
                                    "term": "Protein inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "PMF"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Peptide mass fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Modification-tolerant peptide database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3647",
                                    "term": "Unrestricted peptide database search"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0945",
                                "term": "Peptide identification"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0945",
                                "term": "Peptide identification"
                            }
                        ]
                    }
                ],
                "description": "Semi-supervised learning for peptide identification from MS/MS data.",
                "homepage": "http://noble.gs.washington.edu/proj/percolator/"
            }
        ],
        "inputs": [
            "mzids_2pin"
        ],
        "nb_inputs": 1,
        "outputs": [
            "percolated"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "svmToTSV": {
        "name_process": "svmToTSV",
        "string_process": "\nprocess svmToTSV {\n\n  input:\n  set val(filename), file(mzids), file(tsvs), val(channel), val(sample), file(perco) from mzperco \n\n  output:\n  set val(filename), val(channel), val(sample), file('target.tsv') into tmzidtsv_perco\n\n  script:\n  \"\"\"\n  mkdir outtables\n  msspsmtable percolator --perco $perco -d outtables -i ${tsvs.collect() { \"'$it'\" }.join(' ')} --mzids ${mzids.collect() { \"'$it'\" }.join(' ')}\n  msspsmtable merge -i outtables/* -o psms\n  msspsmtable conffilt -i psms -o filtpsm --confidence-better lower --confidence-lvl $params.psmconflvl --confcolpattern 'PSM q-value'\n  msspsmtable conffilt -i filtpsm -o filtpep --confidence-better lower --confidence-lvl $params.pepconflvl --confcolpattern 'peptide q-value'\n  msspsmtable split -i filtpep --splitcol \\$(head -n1 psms | tr '\\t' '\\n' | grep -n ^TD\\$ | cut -f 1 -d':')\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  mkdir outtables\n  msspsmtable percolator --perco $perco -d outtables -i ${tsvs.collect() { \"'$it'\" }.join(' ')} --mzids ${mzids.collect() { \"'$it'\" }.join(' ')}\n  msspsmtable merge -i outtables/* -o psms\n  msspsmtable conffilt -i psms -o filtpsm --confidence-better lower --confidence-lvl $params.psmconflvl --confcolpattern 'PSM q-value'\n  msspsmtable conffilt -i filtpsm -o filtpep --confidence-better lower --confidence-lvl $params.pepconflvl --confcolpattern 'peptide q-value'\n  msspsmtable split -i filtpep --splitcol \\$(head -n1 psms | tr '\\t' '\\n' | grep -n ^TD\\$ | cut -f 1 -d':')\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mzperco"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tmzidtsv_perco"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "createPSMTable": {
        "name_process": "createPSMTable",
        "string_process": "\nprocess createPSMTable {\n\n  input:\n  set val(filenames), val(channels), val(samples), file('psms?'), file('lookup') from prepsm\n\n  output:\n  set val(filenames), val(channels), val(samples), file({filenames.collect() { it + '.tsv' }}) into setpsmtables\n  \n\n  script:\n  psmlookup = \"psmlookup.sql\"\n  outpsms = \"psmtable.txt\"\n  \"\"\"\n  msspsmtable merge -i psms* -o psms.txt\n  # SQLite lookup needs copying to not modify the input file which would mess up a rerun with -resume\n  cat lookup > $psmlookup\n  msslookup psms -i psms.txt --dbfile $psmlookup \n  msspsmtable specdata -i psms.txt --dbfile $psmlookup -o prepsms.txt --addmiscleav --addbioset\n  msspsmtable quant -i prepsms.txt -o \"${outpsms}\" --dbfile $psmlookup --isobaric\n  sed 's/\\\\#SpecFile/SpectraFile/' -i \"${outpsms}\"\n  msspsmtable split -i \"${outpsms}\" --bioset\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "  psmlookup = \"psmlookup.sql\"\n  outpsms = \"psmtable.txt\"\n  \"\"\"\n  msspsmtable merge -i psms* -o psms.txt\n  # SQLite lookup needs copying to not modify the input file which would mess up a rerun with -resume\n  cat lookup > $psmlookup\n  msslookup psms -i psms.txt --dbfile $psmlookup \n  msspsmtable specdata -i psms.txt --dbfile $psmlookup -o prepsms.txt --addmiscleav --addbioset\n  msspsmtable quant -i prepsms.txt -o \"${outpsms}\" --dbfile $psmlookup --isobaric\n  sed 's/\\\\#SpecFile/SpectraFile/' -i \"${outpsms}\"\n  msspsmtable split -i \"${outpsms}\" --bioset\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prepsm"
        ],
        "nb_inputs": 1,
        "outputs": [
            "setpsmtables"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "psm2Peptides": {
        "name_process": "psm2Peptides",
        "string_process": "\nprocess psm2Peptides {\n\n  input:\n  set val(filename), val(channel), val(sample), file(psms) from psm_pep\n  \n  output:\n  set val(filename), val(channel), val(sample), file(\"means\"), file(\"${psms}_stats.json\"), file(\"${filename}.peps_stats.json\") into psmmeans\n\n  script:\n  col = accolmap.peptides + 1                          \n  modweight = Math.round(plexmap[params.isobaric][1] * 1000) / 1000\n  \"\"\"\n  # Create peptide table from PSM table, picking best scoring unique peptides\n  msspeptable psm2pep -i $psms -o peptides --scorecolpattern svm --spectracol 1 --isobquantcolpattern plex \n  # Move peptide sequence to first column\n  paste <( cut -f ${col} peptides) <( cut -f 1-${col-1},${col+1}-500 peptides) > \"${filename}.peps\"\n  echo -n \\$(calc_psmstats.py $psms 'Peptide' \"+${modweight}\") \\$(calc_psmstats.py \"${filename}.peps\" 'Peptide sequence' \"+${modweight}\") | tr ' ' '\\t'\n  \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "  col = accolmap.peptides + 1                          \n  modweight = Math.round(plexmap[params.isobaric][1] * 1000) / 1000\n  \"\"\"\n  # Create peptide table from PSM table, picking best scoring unique peptides\n  msspeptable psm2pep -i $psms -o peptides --scorecolpattern svm --spectracol 1 --isobquantcolpattern plex \n  # Move peptide sequence to first column\n  paste <( cut -f ${col} peptides) <( cut -f 1-${col-1},${col+1}-500 peptides) > \"${filename}.peps\"\n  echo -n \\$(calc_psmstats.py $psms 'Peptide' \"+${modweight}\") \\$(calc_psmstats.py \"${filename}.peps\" 'Peptide sequence' \"+${modweight}\") | tr ' ' '\\t'\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "OBCOL"
        ],
        "tools_url": [
            "https://bio.tools/obcol"
        ],
        "tools_dico": [
            {
                "name": "OBCOL",
                "uri": "https://bio.tools/obcol",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0140",
                            "term": "Protein targeting and localisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3382",
                            "term": "Imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3443",
                                    "term": "Image analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3552",
                                    "term": "Microscope image visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2489",
                                    "term": "Subcellular localisation prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2489",
                                    "term": "Protein cellular localization prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2489",
                                    "term": "Protein targeting prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2489",
                                    "term": "Protein subcellular localisation prediction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software we designed to perform organelle-based colocalisation analysis from multi-fluorophore microscopy 2D, 3D and 4D cell imaging.",
                "homepage": "http://obcol.imb.uq.edu.au/"
            }
        ],
        "inputs": [
            "psm_pep"
        ],
        "nb_inputs": 1,
        "outputs": [
            "psmmeans"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "reportLabelCheck": {
        "name_process": "reportLabelCheck",
        "string_process": "\nprocess reportLabelCheck {\n\n  cache false\n  publishDir \"${params.outdir}\", mode: 'copy'\n\n  input:\n  set val(ordered_fns), val(filenames), val(channels), val(samples), file('means????'), file('psmstats????'), file('pepstats????') from psm_values\n\n  output:\n  file('qc.html') into results\n\n  script:\n  \"\"\"\n#!/usr/bin/env python \n  \nfrom glob import glob\nimport json\nfrom jinja2 import Template\n  \n# Data arrives, \nordered_fns = [${ordered_fns.collect() { x -> \"'$x'\"}.join(',')}]\nfilenames = [${filenames.collect() { x -> \"'$x'\"}.join(',')}]\nsamples = [${samples.collect() { x -> \"'$x'\" }.join(',')}]\ninputchannels = [${channels.collect() {x -> \"'$x'\" }.join(',')}]\n\n# sort on user inputted file order from mzmldef\nsort_order = [filenames.index(fn) for fn in ordered_fns]\nfilenames = [filenames[ix] for ix in sort_order]\nif len(inputchannels) > 0 and any([x != 'NA' for x in inputchannels]):\n    sorted_channels = [inputchannels[ix] for ix in sort_order]\nelse:\n    sorted_channels = []\nif all([x == 'NA' for x in samples]):\n    samples = []\nelse:\n    samples = [samples[ix] for ix in sort_order]\n\n# collect tmt mean intensities (keep input sort order for bars)\nisomeans = {}\nmeanfns = sorted(glob('means*'), key=lambda x: int(x[x.index('ns')+2:]))\nfor ix in sort_order:\n    with open(meanfns[ix]) as fp:\n        for ch,val in json.load(fp).items():\n            try:\n                isomeans[ch].append(val)\n            except KeyError:\n                isomeans[ch] = [val]\nchannels = sorted([x for x in isomeans.keys()], key=lambda x: x.replace('N', 'A'))\n    \nlabeldata = {\n    'psm': {'labeled': [], 'nonlabeled': []},\n    'pep': {'labeled': [], 'nonlabeled': []},\n}\nmiscleav = []\n\n# data for % labeled in input-file order\nfor ftype in ['pep', 'psm']:\n   statfns = sorted(glob('{}stats*'.format(ftype)), key=lambda x: int(x[x.index('ts')+2:]))\n   for ix in sort_order:\n       with open(statfns[ix]) as fp:\n           stat = json.load(fp)\n           labeldata[ftype]['labeled'].append(stat['pass'])\n           labeldata[ftype]['nonlabeled'].append(stat['fails'])\n           if ftype == 'psm': \n               miscleav.append(stat['missed'])\n\n# write to HTML template\nwith open(\"${baseDir}/assets/report.html\") as fp: \n    main = Template(fp.read())\nwith open('qc.html', 'w') as fp:\n    fp.write(main.render(reportname='$custom_runName', filenames=filenames, labeldata=labeldata, channels=channels, inputchannels=sorted_channels, samples=samples, isomeans=isomeans, miscleav=miscleav))\n\"\"\"\n}",
        "nb_lignes_process": 72,
        "string_script": "  \"\"\"\n#!/usr/bin/env python \n  \nfrom glob import glob\nimport json\nfrom jinja2 import Template\n  \n# Data arrives, \nordered_fns = [${ordered_fns.collect() { x -> \"'$x'\"}.join(',')}]\nfilenames = [${filenames.collect() { x -> \"'$x'\"}.join(',')}]\nsamples = [${samples.collect() { x -> \"'$x'\" }.join(',')}]\ninputchannels = [${channels.collect() {x -> \"'$x'\" }.join(',')}]\n\n# sort on user inputted file order from mzmldef\nsort_order = [filenames.index(fn) for fn in ordered_fns]\nfilenames = [filenames[ix] for ix in sort_order]\nif len(inputchannels) > 0 and any([x != 'NA' for x in inputchannels]):\n    sorted_channels = [inputchannels[ix] for ix in sort_order]\nelse:\n    sorted_channels = []\nif all([x == 'NA' for x in samples]):\n    samples = []\nelse:\n    samples = [samples[ix] for ix in sort_order]\n\n# collect tmt mean intensities (keep input sort order for bars)\nisomeans = {}\nmeanfns = sorted(glob('means*'), key=lambda x: int(x[x.index('ns')+2:]))\nfor ix in sort_order:\n    with open(meanfns[ix]) as fp:\n        for ch,val in json.load(fp).items():\n            try:\n                isomeans[ch].append(val)\n            except KeyError:\n                isomeans[ch] = [val]\nchannels = sorted([x for x in isomeans.keys()], key=lambda x: x.replace('N', 'A'))\n    \nlabeldata = {\n    'psm': {'labeled': [], 'nonlabeled': []},\n    'pep': {'labeled': [], 'nonlabeled': []},\n}\nmiscleav = []\n\n# data for % labeled in input-file order\nfor ftype in ['pep', 'psm']:\n   statfns = sorted(glob('{}stats*'.format(ftype)), key=lambda x: int(x[x.index('ts')+2:]))\n   for ix in sort_order:\n       with open(statfns[ix]) as fp:\n           stat = json.load(fp)\n           labeldata[ftype]['labeled'].append(stat['pass'])\n           labeldata[ftype]['nonlabeled'].append(stat['fails'])\n           if ftype == 'psm': \n               miscleav.append(stat['missed'])\n\n# write to HTML template\nwith open(\"${baseDir}/assets/report.html\") as fp: \n    main = Template(fp.read())\nwith open('qc.html', 'w') as fp:\n    fp.write(main.render(reportname='$custom_runName', filenames=filenames, labeldata=labeldata, channels=channels, inputchannels=sorted_channels, samples=samples, isomeans=isomeans, miscleav=miscleav))\n\"\"\"",
        "nb_lignes_script": 59,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "psm_values"
        ],
        "nb_inputs": 1,
        "outputs": [
            "results"
        ],
        "nb_outputs": 1,
        "name_workflow": "glormph__nf-core-labelcheck",
        "directive": [
            "cache false",
            "publishDir \"${params.outdir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}