{
    "_report_Nbseqreads": {
        "name_process": "_report_Nbseqreads",
        "string_process": " process _report_Nbseqreads {\n      tag \"$LibName\"\n      input:\n      tuple val(LibName), LibIdx, file(LibFastq1), file(LibFastq2), MappingPrefix from ch_Toreport_reads_nb\n      output:\n      tuple val(LibName), LibIdx, stdout into ( ch_Toreport_trim_nb, test1_ch )\n      script:\n      \"\"\"\n      nb_line1=`gunzip -dc ${LibFastq1} | wc -l`\n      nb_line2=`gunzip -dc ${LibFastq2} | wc -l`\n      let nb_reads1=\\$nb_line1/4\n      let nb_reads2=\\$nb_line2/4\n      let nb_reads=\\$nb_reads1+\\$nb_reads2\n      echo -n \\$nb_reads\n      \"\"\"\n   }",
        "nb_lignes_process": 14,
        "string_script": "      \"\"\"\n      nb_line1=`gunzip -dc ${LibFastq1} | wc -l`\n      nb_line2=`gunzip -dc ${LibFastq2} | wc -l`\n      let nb_reads1=\\$nb_line1/4\n      let nb_reads2=\\$nb_line2/4\n      let nb_reads=\\$nb_reads1+\\$nb_reads2\n      echo -n \\$nb_reads\n      \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "carlet"
        ],
        "tools_url": [
            "https://bio.tools/carlet"
        ],
        "tools_dico": [
            {
                "name": "carlet",
                "uri": "https://bio.tools/carlet",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Targeted exome capture"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "WES"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Whole exome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome capture"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phlyogenetic tree construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic tree generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Single-cell tumor phylogeny inference with copy-number constrained mutation losses.\n\nSCARLET (Single-cell Algorithm for Reconstructing Loss-supported Evolution of Tumors) is an algorithm that reconstructs tumor phylogenies from single-cell DNA sequencing data. SCARLET uses a loss-supported model that constrains mutation losses based on observed copy-number data.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'S carlet', 'loss-supported'",
                "homepage": "http://github.com/raphael-group/scarlet"
            }
        ],
        "inputs": [
            "ch_Toreport_reads_nb"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName\""
        ],
        "when": "",
        "stub": ""
    },
    "trimming": {
        "name_process": "trimming",
        "string_process": " process trimming {\n      tag \"$LibName\"\n      label \"multiCpu\"\n      publishDir \"${params.outdir}/TrimedReads\", mode: 'copy',                           \n      saveAs: { filename ->\n               if (filename.endsWith('.fq.gz')) \"./$filename\"\n               else null\n      }\n\n      input:\n      tuple val(LibName), val(LibIdx), file(LibFastq1), file(LibFastq2), MappingPrefix from design_reads_csv\n      output:\n      tuple val(LibName), file(\"${LibName}_val_1.fq.gz\"), file(\"${LibName}_val_2.fq.gz\"), MappingPrefix into design_mapping_ch \n      tuple val(LibName), file(\"${LibName}_val_1.fq.gz\"), file(\"${LibName}_val_2.fq.gz\") into trimed_reads_ch                                                                      \n      script:\n      \"\"\"\n      trim_galore ${params.trim_galore_options} \\\n      --cores ${task.cpus} \\\n      --basename ${LibName} \\\n      ${LibFastq1} ${LibFastq2}\n      \"\"\"\n   }",
        "nb_lignes_process": 20,
        "string_script": "      \"\"\"\n      trim_galore ${params.trim_galore_options} \\\n      --cores ${task.cpus} \\\n      --basename ${LibName} \\\n      ${LibFastq1} ${LibFastq2}\n      \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "design_reads_csv"
        ],
        "nb_inputs": 1,
        "outputs": [
            "design_mapping_ch",
            "trimed_reads_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName\"",
            "label \"multiCpu\"",
            "publishDir \"${params.outdir}/TrimedReads\", mode: 'copy' , saveAs: { filename -> if (filename.endsWith('.fq.gz')) \"./$filename\" else null }"
        ],
        "when": "",
        "stub": ""
    },
    "_report_Nbtrimreads": {
        "name_process": "_report_Nbtrimreads",
        "string_process": " process _report_Nbtrimreads {\n      tag \"$LibName\"\n      input:\n      tuple val(LibName), val(LibIdx),  NbSeqReads, file(LibFastq1), file(LibFastq2) from ch_report_trim_nb\n      output:\n      tuple val(LibName), val(LibIdx),  NbSeqReads, stdout into (ch_Toreport_mapped_nb, ch_Toreport_uniq_nb)\n\n      script:\n      \"\"\"\n      nb_line1=`gunzip -dc ${LibFastq1} | wc -l`\n      nb_line2=`gunzip -dc ${LibFastq2} | wc -l`\n      let nb_reads1=\\$nb_line1/4\n      let nb_reads2=\\$nb_line2/4\n      let nb_reads=\\$nb_reads1+\\$nb_reads2\n      echo -n \\$nb_reads\n      \"\"\"\n   }",
        "nb_lignes_process": 15,
        "string_script": "      \"\"\"\n      nb_line1=`gunzip -dc ${LibFastq1} | wc -l`\n      nb_line2=`gunzip -dc ${LibFastq2} | wc -l`\n      let nb_reads1=\\$nb_line1/4\n      let nb_reads2=\\$nb_line2/4\n      let nb_reads=\\$nb_reads1+\\$nb_reads2\n      echo -n \\$nb_reads\n      \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "carlet"
        ],
        "tools_url": [
            "https://bio.tools/carlet"
        ],
        "tools_dico": [
            {
                "name": "carlet",
                "uri": "https://bio.tools/carlet",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Targeted exome capture"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "WES"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Whole exome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome capture"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phlyogenetic tree construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic tree generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Single-cell tumor phylogeny inference with copy-number constrained mutation losses.\n\nSCARLET (Single-cell Algorithm for Reconstructing Loss-supported Evolution of Tumors) is an algorithm that reconstructs tumor phylogenies from single-cell DNA sequencing data. SCARLET uses a loss-supported model that constrains mutation losses based on observed copy-number data.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'S carlet', 'loss-supported'",
                "homepage": "http://github.com/raphael-group/scarlet"
            }
        ],
        "inputs": [
            "ch_report_trim_nb"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName\""
        ],
        "when": "",
        "stub": ""
    },
    "buildIndexBT": {
        "name_process": "buildIndexBT",
        "string_process": " process buildIndexBT {\n      tag \"$genome.baseName\"\n      label \"multiCpu\"\n      input:\n      path genome from params.genome\n         \n      output:\n      path 'genome.index*' into index_ch\n         \n      \"\"\"\n      bowtie2-build --threads ${task.cpus} ${genome} genome.index\n      \"\"\"\n   }",
        "nb_lignes_process": 11,
        "string_script": "\"\"\"\n      bowtie2-build --threads ${task.cpus} ${genome} genome.index\n      \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "params"
        ],
        "nb_inputs": 1,
        "outputs": [
            "index_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$genome.baseName\"",
            "label \"multiCpu\""
        ],
        "when": "",
        "stub": ""
    },
    "mapping_Bowtie2": {
        "name_process": "mapping_Bowtie2",
        "string_process": " process mapping_Bowtie2 {\n      echo true\n      tag \"$LibName\"\n      label 'multiCpu'\n      input:\n      tuple val(LibName), file(LibFastq1), file(LibFastq2), MappingPrefix from design_mapping_ch\n      path genome from params.genome\n      file index from index_ch\n\n      output:\n      tuple val(LibName),  val(MappingPrefix), file(\"${MappingPrefix}.bam\") into mapping_ch\n      val LibName into libName_ch\n\n      \"\"\"\n      bowtie2 \\\n      --very-sensitive \\\n      --threads ${task.cpus} \\\n      -x genome.index \\\n      -1 ${LibFastq1} \\\n      -2 ${LibFastq2} 2>/dev/null | samtools view -bSh ${params.samtools_flag_filter} -q ${params.samtools_q_filter} - > ${MappingPrefix}.bam \n      \"\"\"\n                                    \n        \n                                                   \n                                                                                           \n        \n\n   }",
        "nb_lignes_process": 26,
        "string_script": "\"\"\"\n      bowtie2 \\\n      --very-sensitive \\\n      --threads ${task.cpus} \\\n      -x genome.index \\\n      -1 ${LibFastq1} \\\n      -2 ${LibFastq2} 2>/dev/null | samtools view -bSh ${params.samtools_flag_filter} -q ${params.samtools_q_filter} - > ${MappingPrefix}.bam \n      \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Rbowtie2",
            "NullSeq",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/rbowtie2",
            "https://bio.tools/nullseq",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "design_mapping_ch",
            "params",
            "index_ch"
        ],
        "nb_inputs": 3,
        "outputs": [
            "mapping_ch",
            "libName_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "echo true",
            "tag \"$LibName\"",
            "label 'multiCpu'"
        ],
        "when": "",
        "stub": ""
    },
    "buildIndexSR": {
        "name_process": "buildIndexSR",
        "string_process": " process buildIndexSR {\n      tag \"$genome.baseName\"\n      input:\n      path genome from params.genome\n\n\n      output:\n      path 'genome.index*' into index_ch\n      file(\"log\")\n      \"\"\"\n      subread-buildindex -o genome.index ${genome} 2>log 1>>log\n      \"\"\"\n   }",
        "nb_lignes_process": 11,
        "string_script": "\"\"\"\n      subread-buildindex -o genome.index ${genome} 2>log 1>>log\n      \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "GLOGS"
        ],
        "tools_url": [
            "https://bio.tools/glogs"
        ],
        "tools_dico": [
            {
                "name": "GLOGS",
                "uri": "https://bio.tools/glogs",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A method for using covariates to improve power in GWAS with related individuals",
                "homepage": "http://www.bioinformatics.org/~stanhope/GLOGS/"
            }
        ],
        "inputs": [
            "params"
        ],
        "nb_inputs": 1,
        "outputs": [
            "index_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$genome.baseName\""
        ],
        "when": "",
        "stub": ""
    },
    "mapping_Subread": {
        "name_process": "mapping_Subread",
        "string_process": " process mapping_Subread {\n      echo true\n      tag \"$LibName\"\n      label 'multiCpu_short'\n      maxForks 8\n      input:\n      tuple val(LibName), file(LibFastq1), file(LibFastq2), MappingPrefix from design_mapping_ch\n      path genome from params.genome\n      file index from index_ch\n\n      output:\n      tuple val(LibName), val(MappingPrefix), file(\"${MappingPrefix}.bam\") into mapping_ch\n      val LibName into libName_ch\n      file(\"log\")\n      file(\"${MappingPrefix}.tmp.bam*\")\n                                                                           \n                                                             \n      \"\"\"\n      subread-align \\\n      -t 1 \\\n      -T ${task.cpus} \\\n      -i genome.index \\\n      -r ${LibFastq1} \\\n      -R ${LibFastq2} \\\n      --multiMapping -B 3 \\\n      -o ${MappingPrefix}.tmp.bam &>log && samtools view -bh ${params.samtools_flag_filter} -q ${params.samtools_q_filter} ${MappingPrefix}.tmp.bam  > ${MappingPrefix}.bam\n      \"\"\"\n\n                                    \n        \n                                                   \n                                                                                           \n        \n\n   }",
        "nb_lignes_process": 33,
        "string_script": "\"\"\"\n      subread-align \\\n      -t 1 \\\n      -T ${task.cpus} \\\n      -i genome.index \\\n      -r ${LibFastq1} \\\n      -R ${LibFastq2} \\\n      --multiMapping -B 3 \\\n      -o ${MappingPrefix}.tmp.bam &>log && samtools view -bh ${params.samtools_flag_filter} -q ${params.samtools_q_filter} ${MappingPrefix}.tmp.bam  > ${MappingPrefix}.bam\n      \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "GLOGS"
        ],
        "tools_url": [
            "https://bio.tools/glogs"
        ],
        "tools_dico": [
            {
                "name": "GLOGS",
                "uri": "https://bio.tools/glogs",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A method for using covariates to improve power in GWAS with related individuals",
                "homepage": "http://www.bioinformatics.org/~stanhope/GLOGS/"
            }
        ],
        "inputs": [
            "design_mapping_ch",
            "params",
            "index_ch"
        ],
        "nb_inputs": 3,
        "outputs": [
            "mapping_ch",
            "libName_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "echo true",
            "tag \"$LibName\"",
            "label 'multiCpu_short'",
            "maxForks 8"
        ],
        "when": "",
        "stub": ""
    },
    "mergeBamFiles": {
        "name_process": "mergeBamFiles",
        "string_process": " process mergeBamFiles {\n      echo true\n      tag \"$LibExp\"\n      label 'usePicard'\n      input:\n      tuple val(LibExp), val(LibIdx), path(bams) from design_bam_merged\n      output:\n      tuple val(LibExp), val(MappingPrefix), file(\"${MappingPrefix}.bam\") into mapping_ch\n      tuple val(LibExp), val(LibIdx), val(\"NA\") , val(\"NA\") into (ch_Toreport_mapped_nb, ch_Toreport_uniq_nb)                                                                          \n      script:\n      MappingPrefix=\"${LibExp}.${params.mapper_id}.${params.genome_prefix}.pe.merged\"\n      bam_files=bams\n                                                                       \n      \"\"\"\n      gatk MergeSamFiles ${'-I='+bam_files.join(' -I=')} -O=${MappingPrefix}.bam --TMP_DIR=tmp\n      \"\"\"\n   }",
        "nb_lignes_process": 15,
        "string_script": "      MappingPrefix=\"${LibExp}.${params.mapper_id}.${params.genome_prefix}.pe.merged\"\n      bam_files=bams\n                                                                       \n      \"\"\"\n      gatk MergeSamFiles ${'-I='+bam_files.join(' -I=')} -O=${MappingPrefix}.bam --TMP_DIR=tmp\n      \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "design_bam_merged"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mapping_ch",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "echo true",
            "tag \"$LibExp\"",
            "label 'usePicard'"
        ],
        "when": "",
        "stub": ""
    },
    "samtools": {
        "name_process": "samtools",
        "string_process": "\nprocess samtools {\n   echo true\n   tag \"$LibName\"\n   publishDir \"${params.outdir}/Mapping\", mode: 'copy'                           \n\n   input:\n   tuple val(LibName),  val(prefix),  file(RawMapping) from mapping_ch\n   output:\n   file(\"${prefix}.*.bam*\") \n   tuple val(LibName), val(prefix), file(\"${prefix}.sorted.bam*\") into samtooled_ch\n   tuple val(LibName), file(\"${prefix}.sorted.bam*\") into mapped_reads_ch\n   tuple val(LibName), val(prefix),  file(\"${prefix}.sorted.rmdup.bam*\") into samtooled_rmdup_ch\n   tuple val(LibName), file(\"${prefix}.sorted.rmdup.bam*\") into mapped_uniq_reads_ch\n\n\t                                                                                               \n   script:\n\t\"\"\"\n   samtools sort ${prefix}.bam ${prefix}.sorted\n   samtools index ${prefix}.sorted.bam\n\n   samtools rmdup ${prefix}.sorted.bam ${prefix}.sorted.rmdup.bam\n   samtools index ${prefix}.sorted.rmdup.bam\n   \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "\t\"\"\"\n   samtools sort ${prefix}.bam ${prefix}.sorted\n   samtools index ${prefix}.sorted.bam\n\n   samtools rmdup ${prefix}.sorted.bam ${prefix}.sorted.rmdup.bam\n   samtools index ${prefix}.sorted.rmdup.bam\n   \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "mapping_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "samtooled_ch",
            "mapped_reads_ch",
            "samtooled_rmdup_ch",
            "mapped_uniq_reads_ch"
        ],
        "nb_outputs": 4,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "echo true",
            "tag \"$LibName\"",
            "publishDir \"${params.outdir}/Mapping\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "genome_coverage_bam": {
        "name_process": "genome_coverage_bam",
        "string_process": "\nprocess genome_coverage_bam {\n   tag \"$LibName genome coverage .bam\"\n   label 'multiCpu'\n   publishDir \"${params.outdir}/GenomeCoverage\", mode: 'copy',                           \n      saveAs: { filename ->\n               if (filename.endsWith('.bw')) \"./$filename\"\n               else null\n      }\n   input:\n  \ttuple val(LibName), val(prefix), path(bamFiles) from samtooled_ch\n   output:\n\ttuple val(LibName), val(prefix), bamFiles, val(\"${prefix}.bin${params.bin_size}.RPM.bamCoverage.bw\") into genCoved_ch\n   file(\"${prefix}.bin${params.bin_size}.RPM.bamCoverage.bw\")\n   \"\"\"\n   bamCoverage \\\n   -b ${bamFiles[0]} \\\n   -o ${prefix}.bin${params.bin_size}.RPM.bamCoverage.bw -of bigwig \\\n   ${params.bamcoverage_options} --binSize ${params.bin_size} -p ${task.cpus}\n   \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "\"\"\"\n   bamCoverage \\\n   -b ${bamFiles[0]} \\\n   -o ${prefix}.bin${params.bin_size}.RPM.bamCoverage.bw -of bigwig \\\n   ${params.bamcoverage_options} --binSize ${params.bin_size} -p ${task.cpus}\n   \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samtooled_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "genCoved_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName genome coverage .bam\"",
            "label 'multiCpu'",
            "publishDir \"${params.outdir}/GenomeCoverage\", mode: 'copy' , saveAs: { filename -> if (filename.endsWith('.bw')) \"./$filename\" else null }"
        ],
        "when": "",
        "stub": ""
    },
    "genome_coverage_rmdup": {
        "name_process": "genome_coverage_rmdup",
        "string_process": "\nprocess genome_coverage_rmdup {\n   tag \"$LibName genome coverage rmdup.bam\"\n   label 'multiCpu'\n   publishDir \"${params.outdir}/GenomeCoverage\", mode: 'copy',                           \n      saveAs: { filename ->\n               if (filename.endsWith('.bw')) \"./$filename\"\n               else null\n      }\n   input:\n  \ttuple val(LibName), val(prefix), path(bamFiles) from samtooled_rmdup_ch\n   output:\n\ttuple val(LibName), val(prefix), bamFiles, val(\"${prefix}.bin${params.bin_size}.RPM.rmdup.bamCoverage.bw\") into genCoved_uniq_ch\n   file(\"${prefix}.bin${params.bin_size}.RPM.rmdup.bamCoverage.bw\") \n   \"\"\"\n   bamCoverage \\\n   -b ${bamFiles[0]} \\\n   -o ${prefix}.bin${params.bin_size}.RPM.rmdup.bamCoverage.bw -of bigwig \\\n   ${params.bamcoverage_options} --binSize ${params.bin_size} -p ${task.cpus}\n   \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "\"\"\"\n   bamCoverage \\\n   -b ${bamFiles[0]} \\\n   -o ${prefix}.bin${params.bin_size}.RPM.rmdup.bamCoverage.bw -of bigwig \\\n   ${params.bamcoverage_options} --binSize ${params.bin_size} -p ${task.cpus}\n   \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samtooled_rmdup_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "genCoved_uniq_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName genome coverage rmdup.bam\"",
            "label 'multiCpu'",
            "publishDir \"${params.outdir}/GenomeCoverage\", mode: 'copy' , saveAs: { filename -> if (filename.endsWith('.bw')) \"./$filename\" else null }"
        ],
        "when": "",
        "stub": ""
    },
    "_report_nb_mapped_reads": {
        "name_process": "_report_nb_mapped_reads",
        "string_process": "\nprocess _report_nb_mapped_reads {\n\ttag \"$LibName \"\n\tinput:\n\ttuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), path(bamFiles) from ch_report_mapped_nb\n\toutput:\n\ttuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), stdout, path(bamFiles) into ch_Toreport_insert_size\n\n\tscript:\n\t\"\"\"\n\tmapped_reads=`samtools view -c ${bamFiles[0]}`\n\techo -n \\$mapped_reads\n\t\"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\t\"\"\"\n\tmapped_reads=`samtools view -c ${bamFiles[0]}`\n\techo -n \\$mapped_reads\n\t\"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_report_mapped_nb"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_Toreport_insert_size"
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName \""
        ],
        "when": "",
        "stub": ""
    },
    "_report_insert_size": {
        "name_process": "_report_insert_size",
        "string_process": "\nprocess _report_insert_size {\n   tag \"$LibName\"\n   input:\n   tuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), val(NbMapReads), path(bamFiles) from ch_Toreport_insert_size\n   output:\n   tuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), val(NbMapReads), stdout into (ch_Toreport_all_stats, ch_ToAoC)\n   file(table)\n   script:\n   \"\"\"\n   bamPEFragmentSize --bamfiles ${bamFiles[0]} --table table >/dev/null 2>&1\n   ins_size=`tail -1 table | awk '{ print \\$6}'`\n   echo -n \\$ins_size\n   \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "   \"\"\"\n   bamPEFragmentSize --bamfiles ${bamFiles[0]} --table table >/dev/null 2>&1\n   ins_size=`tail -1 table | awk '{ print \\$6}'`\n   echo -n \\$ins_size\n   \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "ch_Toreport_insert_size"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "table"
        ],
        "nb_outputs": 2,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName\""
        ],
        "when": "",
        "stub": ""
    },
    "_report_mapping_stats_csv": {
        "name_process": "_report_mapping_stats_csv",
        "string_process": "\nprocess _report_mapping_stats_csv {\n   publishDir \"${params.outdir}/Stats\", mode: 'copy'\n   input:\n   val x from ch_report_all_stats\n   output:\n   path(\"mapping_stats.txt\")\n                                                                             \n   script:\n   \"\"\"\n   echo \"LibName;Nb_sequenced_read;Nb_trimmed_reads;Nb_mapped_reads;Median_insert_size\" > mapping_stats.txt\n   echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> mapping_stats.txt\n   \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "   \"\"\"\n   echo \"LibName;Nb_sequenced_read;Nb_trimmed_reads;Nb_mapped_reads;Median_insert_size\" > mapping_stats.txt\n   echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> mapping_stats.txt\n   \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_report_all_stats"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "publishDir \"${params.outdir}/Stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "_report_nb_uniq_reads": {
        "name_process": "_report_nb_uniq_reads",
        "string_process": "\nprocess _report_nb_uniq_reads {\n\ttag \"$LibName rmdup.bam\"\n\tinput:\n\ttuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), path(bamFiles) from ch_report_uniq_nb\n\toutput:\n\ttuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), stdout, path(bamFiles) into ch_Toreport_uniq_insert_size\n\tscript:\n\t\"\"\"\n\tmapped_reads=`samtools view -c ${bamFiles[0]}`\n\techo -n \\$mapped_reads\n\t\"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "\t\"\"\"\n\tmapped_reads=`samtools view -c ${bamFiles[0]}`\n\techo -n \\$mapped_reads\n\t\"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_report_uniq_nb"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_Toreport_uniq_insert_size"
        ],
        "nb_outputs": 1,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName rmdup.bam\""
        ],
        "when": "",
        "stub": ""
    },
    "_report_uniq_insert_size": {
        "name_process": "_report_uniq_insert_size",
        "string_process": "\nprocess _report_uniq_insert_size {\n   tag \"$LibName\"\n   input:\n   tuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), val(NbMapReads), path(bamFiles) from ch_Toreport_uniq_insert_size\n   output:\n   tuple val(LibName), val(LibIdx),  val(NbSeqReads), val(NbTrimReads), val(NbMapReads), stdout into (ch_Toreport_uniq_stats, ch_ToAoC_uniq)\n   file(table_uniq)\n   script:\n   \"\"\"\n   bamPEFragmentSize --bamfiles ${bamFiles[0]} --table table_uniq >/dev/null 2>&1\n   ins_size_uniq=`tail -1 table_uniq | awk '{ print \\$6}'`\n   echo -n \\$ins_size_uniq\n   \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "   \"\"\"\n   bamPEFragmentSize --bamfiles ${bamFiles[0]} --table table_uniq >/dev/null 2>&1\n   ins_size_uniq=`tail -1 table_uniq | awk '{ print \\$6}'`\n   echo -n \\$ins_size_uniq\n   \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "ch_Toreport_uniq_insert_size"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "table_uniq"
        ],
        "nb_outputs": 2,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "tag \"$LibName\""
        ],
        "when": "",
        "stub": ""
    },
    "_report_mapping_uniq_stats_csv": {
        "name_process": "_report_mapping_uniq_stats_csv",
        "string_process": "\nprocess _report_mapping_uniq_stats_csv {\n   publishDir \"${params.outdir}/Stats\", mode: 'copy'\n   input:\n   val x from ch_report_uniq_stats\n   output:\n   path(\"mapping_uniq_stats.txt\")\n                                                                             \n   script:\n   \"\"\"\n   echo \"LibName;Nb_sequenced_read;Nb_trimmed_reads;Nb_mapped_reads;Median_insert_size\" > mapping_uniq_stats.txt\n   echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> mapping_uniq_stats.txt\n   \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "   \"\"\"\n   echo \"LibName;Nb_sequenced_read;Nb_trimmed_reads;Nb_mapped_reads;Median_insert_size\" > mapping_uniq_stats.txt\n   echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> mapping_uniq_stats.txt\n   \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_report_uniq_stats"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "publishDir \"${params.outdir}/Stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "_report_AoC_csv": {
        "name_process": "_report_AoC_csv",
        "string_process": "\nprocess _report_AoC_csv {\n   publishDir \"${params.outdir}\", mode: 'copy'\n   input:\n   val x from ch_report_Aoc\n   output:\n   path(\"${params.name}.bigwigDesign.csv\")\n                                                                                             \n   script:\n   \"\"\"\n   echo \"LibName;LibBam;LibBW;LibSequenced;LibMapped;LibUnique;LibInsertSize;LibQpcrNorm;LibType;LibProj;LibExp;LibCondition;LibOrder;LibIsControl;LibControl\" > ${params.name}.bigwigDesign.csv\n   echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> ${params.name}.bigwigDesign.csv\n   \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "   \"\"\"\n   echo \"LibName;LibBam;LibBW;LibSequenced;LibMapped;LibUnique;LibInsertSize;LibQpcrNorm;LibType;LibProj;LibExp;LibCondition;LibOrder;LibIsControl;LibControl\" > ${params.name}.bigwigDesign.csv\n   echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> ${params.name}.bigwigDesign.csv\n   \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_report_Aoc"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "_report_AoC_uniq_csv": {
        "name_process": "_report_AoC_uniq_csv",
        "string_process": "\nprocess _report_AoC_uniq_csv {\n   publishDir \"${params.outdir}\", mode: 'copy'\n   input:\n   val x from ch_report_Aoc_uniq\n   output:\n   path(\"${params.name}.rmdup.bigwigDesign.csv\")\n                                                                                                   \n   script:\n   \"\"\"\n   echo \"LibName;LibBam;LibBW;LibSequenced;LibMapped;LibUnique;LibInsertSize;LibQpcrNorm;LibType;LibProj;LibExp;LibCondition;LibOrder;LibIsControl;LibControl\" > ${params.name}.rmdup.bigwigDesign.csv\n  echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> ${params.name}.rmdup.bigwigDesign.csv\n   \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "   \"\"\"\n   echo \"LibName;LibBam;LibBW;LibSequenced;LibMapped;LibUnique;LibInsertSize;LibQpcrNorm;LibType;LibProj;LibExp;LibCondition;LibOrder;LibIsControl;LibControl\" > ${params.name}.rmdup.bigwigDesign.csv\n  echo \"${x.join('\\n')}\" | sort -k1 | awk '{for(i=2;i<=NF;i++) printf \\$i\";\"; print \"\"}' >> ${params.name}.rmdup.bigwigDesign.csv\n   \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_report_Aoc_uniq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "cyrildw__nf-MappingOrMerging",
        "directive": [
            "publishDir \"${params.outdir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}