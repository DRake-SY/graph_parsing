{
    "concatenate": {
        "name_process": "concatenate",
        "string_process": "\nprocess concatenate {\n    tag \"$id\"\n\n    container params.docker_container_multiqc\n\n                                                                                     \n\n    input:\n    set val(id), file(read_files) from reads_concat\n\n    output:\n    tuple(id, file(\"${id}.merged.R{1,2}.fastq.gz\")) into concat_fq \n    \n    script:\n    \"\"\"\n    concatenate_fastqs.py ${id} ${params.singleEnd} $read_files\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    concatenate_fastqs.py ${id} ${params.singleEnd} $read_files\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_concat"
        ],
        "nb_inputs": 1,
        "outputs": [
            "concat_fq"
        ],
        "nb_outputs": 1,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "tag \"$id\"",
            "container params.docker_container_multiqc"
        ],
        "when": "",
        "stub": ""
    },
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n\n    container params.docker_container_multiqc\n\n    output:\n    file \"software_versions_mqc.yaml\" into software_versions_yaml\n\n    script:\n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n\n    echo $params.docker_container_fastqc | cut -d: -f 2 > v_fastqc.txt\n    echo $params.docker_container_bbmap | cut -d: -f 2 > v_bbmap.txt\n    \n    echo $params.docker_container_multiqc | cut -d: -f 2 > v_multiqc.txt\n    \n    scrape_software_versions.py > software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n\n    echo $params.docker_container_fastqc | cut -d: -f 2 > v_fastqc.txt\n    echo $params.docker_container_bbmap | cut -d: -f 2 > v_bbmap.txt\n    \n    echo $params.docker_container_multiqc | cut -d: -f 2 > v_multiqc.txt\n    \n    scrape_software_versions.py > software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "software_versions_yaml"
        ],
        "nb_outputs": 1,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "container params.docker_container_multiqc"
        ],
        "when": "",
        "stub": ""
    },
    "dedup": {
        "name_process": "dedup",
        "string_process": "\nprocess dedup {\n    \n    tag \"$name\"\n    container params.docker_container_bbmap\n        \n    input:\n    tuple val(name), file(reads) from read_files_dedup\n\n    output:\n    tuple val(name), path(\"${name}_dedup*.fq.gz\") into to_synthetic_contaminants\n    file \"dedup_mqc.yaml\" into dedup_log\n    \n    when:\n    params.dedup\n\n    script:\n                                                       \n    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\" in2=\\\"${reads[1]}\\\"\"\n    def output = params.singleEnd ? \"out=\\\"${name}_dedup.fq.gz\\\"\" :  \"out1=\\\"${name}_dedup_R1.fq.gz\\\" out2=\\\"${name}_dedup_R2.fq.gz\\\"\"\n    \n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo \\\"$task.memory\\\" | sed 's/ //g' | sed 's/B//g')\n    echo \\\"$reads\\\"\n    clumpify.sh -Xmx\\\"\\$maxmem\\\" $input $output qin=$params.qin dedupe subs=0 threads=${task.cpus} &> dedup_mqc.txt\n    \n    # MultiQC doesn't have a module for clumpify yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_dedup_log.sh > dedup_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\" in2=\\\"${reads[1]}\\\"\"\n    def output = params.singleEnd ? \"out=\\\"${name}_dedup.fq.gz\\\"\" :  \"out1=\\\"${name}_dedup_R1.fq.gz\\\" out2=\\\"${name}_dedup_R2.fq.gz\\\"\"\n    \n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo \\\"$task.memory\\\" | sed 's/ //g' | sed 's/B//g')\n    echo \\\"$reads\\\"\n    clumpify.sh -Xmx\\\"\\$maxmem\\\" $input $output qin=$params.qin dedupe subs=0 threads=${task.cpus} &> dedup_mqc.txt\n    \n    # MultiQC doesn't have a module for clumpify yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_dedup_log.sh > dedup_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "read_files_dedup"
        ],
        "nb_inputs": 1,
        "outputs": [
            "to_synthetic_contaminants",
            "dedup_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "tag \"$name\"",
            "container params.docker_container_bbmap"
        ],
        "when": "params.dedup",
        "stub": ""
    },
    "remove_synthetic_contaminants": {
        "name_process": "remove_synthetic_contaminants",
        "string_process": "\nprocess remove_synthetic_contaminants {\n    tag \"$name\"\n    \n    container params.docker_container_bbmap\n\n    input:\n    tuple file(artefacts), file(phix174ill), val(name), file(reads) from artefacts.combine(phix174ill).combine(to_synthetic_contaminants)\n   \n    output:\n    tuple val(name), path(\"${name}_no_synthetic_contaminants*.fq.gz\") into to_trim\n    file \"synthetic_contaminants_mqc.yaml\" into synthetic_contaminants_log\n\n       script:\n    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\" in2=\\\"${reads[1]}\\\"\"\n    def output = params.singleEnd ? \"out=\\\"${name}_no_synthetic_contaminants.fq.gz\\\"\" :  \"out=\\\"${name}_no_synthetic_contaminants_R1.fq.gz\\\" out2=\\\"${name}_no_synthetic_contaminants_R2.fq.gz\\\"\"\n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n    bbduk.sh -Xmx\\\"\\$maxmem\\\" $input $output k=31 ref=$phix174ill,$artefacts qin=$params.qin threads=${task.cpus} ow &> synthetic_contaminants_mqc.txt\n    \n    # MultiQC doesn't have a module for bbduk yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_remove_synthetic_contaminants_log.sh > synthetic_contaminants_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\" in2=\\\"${reads[1]}\\\"\"\n    def output = params.singleEnd ? \"out=\\\"${name}_no_synthetic_contaminants.fq.gz\\\"\" :  \"out=\\\"${name}_no_synthetic_contaminants_R1.fq.gz\\\" out2=\\\"${name}_no_synthetic_contaminants_R2.fq.gz\\\"\"\n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n    bbduk.sh -Xmx\\\"\\$maxmem\\\" $input $output k=31 ref=$phix174ill,$artefacts qin=$params.qin threads=${task.cpus} ow &> synthetic_contaminants_mqc.txt\n    \n    # MultiQC doesn't have a module for bbduk yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_remove_synthetic_contaminants_log.sh > synthetic_contaminants_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "artefacts",
            "phix174ill",
            "to_synthetic_contaminants"
        ],
        "nb_inputs": 3,
        "outputs": [
            "to_trim",
            "synthetic_contaminants_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "tag \"$name\"",
            "container params.docker_container_bbmap"
        ],
        "when": "",
        "stub": ""
    },
    "trim": {
        "name_process": "trim",
        "string_process": "\nprocess trim {\n    tag \"$name\"\n    \n    container params.docker_container_bbmap\n    \n    input:\n    tuple file(adapters), val(name), file(reads) from adapters.combine(to_trim) \n    \n    output:\n    tuple val(name), path(\"${name}_trimmed*.fq.gz\") into to_decontaminate\n    file \"trimming_mqc.yaml\" into trimming_log\n\n       script:\n    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\" in2=\\\"${reads[1]}\\\"\"\n    def output = params.singleEnd ? \"out=\\\"${name}_trimmed.fq.gz\\\"\" :  \"out=\\\"${name}_trimmed_R1.fq.gz\\\" out2=\\\"${name}_trimmed_R2.fq.gz\\\" outs=\\\"${name}_trimmed_singletons.fq.gz\\\"\"\n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n    bbduk.sh -Xmx\\\"\\$maxmem\\\" $input $output ktrim=r k=$params.kcontaminants mink=$params.mink hdist=$params.hdist qtrim=rl trimq=$params.phred  minlength=$params.minlength ref=$adapters qin=$params.qin threads=${task.cpus} tbo tpe ow &> trimming_mqc.txt\n\n    # MultiQC doesn't have a module for bbduk yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_trimming_log.sh > trimming_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\" in2=\\\"${reads[1]}\\\"\"\n    def output = params.singleEnd ? \"out=\\\"${name}_trimmed.fq.gz\\\"\" :  \"out=\\\"${name}_trimmed_R1.fq.gz\\\" out2=\\\"${name}_trimmed_R2.fq.gz\\\" outs=\\\"${name}_trimmed_singletons.fq.gz\\\"\"\n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n    bbduk.sh -Xmx\\\"\\$maxmem\\\" $input $output ktrim=r k=$params.kcontaminants mink=$params.mink hdist=$params.hdist qtrim=rl trimq=$params.phred  minlength=$params.minlength ref=$adapters qin=$params.qin threads=${task.cpus} tbo tpe ow &> trimming_mqc.txt\n\n    # MultiQC doesn't have a module for bbduk yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_trimming_log.sh > trimming_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "adapters",
            "to_trim"
        ],
        "nb_inputs": 2,
        "outputs": [
            "to_decontaminate",
            "trimming_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "tag \"$name\"",
            "container params.docker_container_bbmap"
        ],
        "when": "",
        "stub": ""
    },
    "index_foreign_genome": {
        "name_process": "index_foreign_genome",
        "string_process": "\nprocess index_foreign_genome {\n\n    container params.docker_container_bbmap\n\n                                                                                       \n\n    input:\n    val(some_value) from foreign_genome_ch \n\n    output:\n    path(\"ref/\", type: 'dir') into ref_foreign_genome\n    \n    when:\n    params.foreign_genome_ref == \"\"\n\n    script:\n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n    # This step will have a boilerplate log because the information saved by bbmap are not relevant\n    bbmap.sh -Xmx\\\"\\$maxmem\\\" ref=${params.foreign_genome} &> foreign_genome_index_mqc.txt    \n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n    # This step will have a boilerplate log because the information saved by bbmap are not relevant\n    bbmap.sh -Xmx\\\"\\$maxmem\\\" ref=${params.foreign_genome} &> foreign_genome_index_mqc.txt    \n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "foreign_genome_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ref_foreign_genome"
        ],
        "nb_outputs": 1,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "container params.docker_container_bbmap"
        ],
        "when": "params.foreign_genome_ref == \"\"",
        "stub": ""
    },
    "decontaminate": {
        "name_process": "decontaminate",
        "string_process": "\nprocess decontaminate {\n    tag \"$name\"\n\n    container params.docker_container_bbmap\n\n    publishDir \"${workingpath}/02_ReadQC_Output\", mode: 'copy', pattern: \"*.qcd.fq.gz\"\n\n    input:\n    tuple path(ref_foreign_genome), val(name), file(reads) from ref_foreign_genome.combine(to_decontaminate)\n\n    output:\n    tuple val(name), path(\"*.qcd.fq.gz\") into qcd_reads\n    file \"decontamination_mqc.yaml\" into decontaminate_log\n\n    script:\n                                                                                            \n                                                                                         \n                                                                                  \n    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\",\\\"${reads[2]}\\\" in2=\\\"${reads[1]}\\\",null\"\n    def output = \"outu=\\\"${name}_QCd.fq.gz\\\" outm=\\\"${name}_contamination.fq.gz\\\"\"\n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n    bbwrap.sh \\\\\n        -Xmx\\\"\\$maxmem\\\"  \\\\\n        mapper=bbmap \\\\\n        append=t \\\\\n        $input \\\\\n        $output \\\\\n        minid=$params.mind \\\\\n        maxindel=$params.maxindel \\\\\n        bwr=$params.bwr \\\\\n        bw=12 \\\\\n        minhits=2 \\\\\n        qtrim=rl \\\\\n        trimq=$params.phred \\\\\n        path=\"./\" \\\\\n        qin=$params.qin \\\\\n        threads=${task.cpus} \\\\\n        untrim \\\\\n        quickmatch \\\\\n        fast \\\\\n        ow &> decontamination_mqc.txt\n\n    if [ $params.singleEnd = true ]; then\n        # Rename\n        mv ${name}_QCd.fq.gz ${name}_R1.qcd.fq.gz\n    else\n        # Deinterleave\n        reformat.sh in=${name}_QCd.fq.gz out1=${name}_R1.qcd.fq.gz out2=${name}_R2.qcd.fq.gz\n    fi\n\n    # MultiQC doesn't have a module for bbwrap yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_decontamination_log.sh > decontamination_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 57,
        "string_script": "    def input = params.singleEnd ? \"in=\\\"${reads[0]}\\\"\" :  \"in1=\\\"${reads[0]}\\\",\\\"${reads[2]}\\\" in2=\\\"${reads[1]}\\\",null\"\n    def output = \"outu=\\\"${name}_QCd.fq.gz\\\" outm=\\\"${name}_contamination.fq.gz\\\"\"\n    \"\"\"\n    #Sets the maximum memory to the value requested in the config file\n    maxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n    bbwrap.sh \\\\\n        -Xmx\\\"\\$maxmem\\\"  \\\\\n        mapper=bbmap \\\\\n        append=t \\\\\n        $input \\\\\n        $output \\\\\n        minid=$params.mind \\\\\n        maxindel=$params.maxindel \\\\\n        bwr=$params.bwr \\\\\n        bw=12 \\\\\n        minhits=2 \\\\\n        qtrim=rl \\\\\n        trimq=$params.phred \\\\\n        path=\"./\" \\\\\n        qin=$params.qin \\\\\n        threads=${task.cpus} \\\\\n        untrim \\\\\n        quickmatch \\\\\n        fast \\\\\n        ow &> decontamination_mqc.txt\n\n    if [ $params.singleEnd = true ]; then\n        # Rename\n        mv ${name}_QCd.fq.gz ${name}_R1.qcd.fq.gz\n    else\n        # Deinterleave\n        reformat.sh in=${name}_QCd.fq.gz out1=${name}_R1.qcd.fq.gz out2=${name}_R2.qcd.fq.gz\n    fi\n\n    # MultiQC doesn't have a module for bbwrap yet. As a consequence, I\n    # had to create a YAML file with all the info I need via a bash script\n    bash scrape_decontamination_log.sh > decontamination_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 38,
        "language_script": "bash",
        "tools": [
            "DFAST",
            "BOW"
        ],
        "tools_url": [
            "https://bio.tools/dfast",
            "https://bio.tools/bow"
        ],
        "tools_dico": [
            {
                "name": "DFAST",
                "uri": "https://bio.tools/dfast",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Flexible prokaryotic genome annotation pipeline for faster genome publication.",
                "homepage": "https://dfast.nig.ac.jp/"
            },
            {
                "name": "BOW",
                "uri": "https://bio.tools/bow",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3762",
                                    "term": "Service composition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3763",
                                    "term": "Service invocation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BOW - Bioinformatics On Windows is essentially a windows port of Linux tools, such as BWA and SAMTOOLS",
                "homepage": "http://bow.codeplex.com/"
            }
        ],
        "inputs": [
            "ref_foreign_genome",
            "to_decontaminate"
        ],
        "nb_inputs": 2,
        "outputs": [
            "qcd_reads",
            "decontaminate_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "tag \"$name\"",
            "container params.docker_container_bbmap",
            "publishDir \"${workingpath}/02_ReadQC_Output\", mode: 'copy', pattern: \"*.qcd.fq.gz\""
        ],
        "when": "",
        "stub": ""
    },
    "quality_assessment": {
        "name_process": "quality_assessment",
        "string_process": "\nprocess quality_assessment {\n    tag \"$name\"\n    \n    container params.docker_container_fastqc\n    \n    publishDir \"${workingpath}/01_fastqc\"\n\n    input:\n    set val(name), file(reads) from read_files_fastqc.mix(qcd_reads)\n\n    output:\n    path \"*_fastqc.{zip,html}\" into fastqc_log\n\n    script:\n    \"\"\"\n    fastqc -q $reads\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    fastqc -q $reads\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "read_files_fastqc",
            "qcd_reads"
        ],
        "nb_inputs": 2,
        "outputs": [
            "fastqc_log"
        ],
        "nb_outputs": 1,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "tag \"$name\"",
            "container params.docker_container_fastqc",
            "publishDir \"${workingpath}/01_fastqc\""
        ],
        "when": "",
        "stub": ""
    },
    "log": {
        "name_process": "log",
        "string_process": "\nprocess log {\n    \n    publishDir \"${workingpath}\", mode: 'copy'\n\n    container params.docker_container_multiqc\n\n    input:\n    file multiqc_config\n    file workflow_summary from create_workflow_summary(summary)\n    file \"software_versions_mqc.yaml\" from software_versions_yaml\n    path \"fastqc/*\" from fastqc_log.collect().ifEmpty([])\n    file \"dedup_mqc.yaml\" from dedup_log.ifEmpty([])\n    file \"synthetic_contaminants_mqc.yaml\" from synthetic_contaminants_log.ifEmpty([])\n    file \"trimming_mqc.yaml\" from trimming_log.ifEmpty([])\n    file \"foreign_genome_indexing_mqc.yaml\" from index_foreign_genome_log.ifEmpty([])\n    file \"decontamination_mqc.yaml\" from decontaminate_log.ifEmpty([])\n    \n    output:\n    path \"*multiqc_report*.html\" into multiqc_report\n    path \"*multiqc_data*\"\n\n    script:\n    \"\"\"\n    multiqc --config $multiqc_config . -f\n    mv multiqc_report.html ${params.prefix}_multiqc_report.html\n    mv multiqc_data ${params.prefix}_multiqc_data\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    multiqc --config $multiqc_config . -f\n    mv multiqc_report.html ${params.prefix}_multiqc_report.html\n    mv multiqc_data ${params.prefix}_multiqc_data\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "multiqc_config",
            "summary",
            "software_versions_yaml",
            "fastqc_log",
            "dedup_log",
            "synthetic_contaminants_log",
            "trimming_log",
            "index_foreign_genome_log",
            "decontaminate_log"
        ],
        "nb_inputs": 9,
        "outputs": [
            "multiqc_report"
        ],
        "nb_outputs": 1,
        "name_workflow": "FischbachLab__nf-readqc",
        "directive": [
            "publishDir \"${workingpath}\", mode: 'copy'",
            "container params.docker_container_multiqc"
        ],
        "when": "",
        "stub": ""
    }
}