{
    "generateGTF": {
        "name_process": "generateGTF",
        "string_process": "\nprocess generateGTF {\n  tag \"Retrieving and processing Ensembl GTF file\"\n  publishDir \"${params.output_dir}/Output/GTF\"\n\n  output:\n  file(ensembl_gtf_file) \\\n    into (\n      generateGTF_to_generateBED,\n      generateGTF_to_runSTARgenomeGenerate,\n      generateGTF_to_runRSEMprepareReference,\n      generateGTF_to_createSE\n    )\n\n  script:\n                                                \n  chromAlias_url =\n    \"${params.urls.ucsc_base_url}/goldenPath/\" +\n    \"${params.genome.ucsc}/database/chromAlias.txt.gz\"\n  chromAlias_join_field = 1\n\n                              \n  ensembl_gtf_url =\n    \"${params.urls.ensembl_base_url}/release-${params.genome.ensembl}/gtf/\" +\n    \"${params.genome.species.toLowerCase().replaceAll(\" \",\"_\")}\" + \"/\" +\n    \"${params.genome.species.replaceAll(\" \",\"_\")}\" + \".\" +\n    \"${params.genome.assembly}.${params.genome.ensembl}.gtf.gz\"\n                                                                           \n  ensembl_gtf_file = \"${file(ensembl_gtf_url).name}\"\n  ensembl_gtf_file =\n    \"${ensembl_gtf_file.replaceFirst(\"\\\\.gtf\\\\.gz\", \"\")}\" + \".\" +\n    \"ucsc.${params.genome.set}.gtf.gz\"\n\n  \"\"\"\n  # Retrieve and gunzip chromAlias file from UCSC, keeping only first two\n  # columns, and sorting on first column (non-UCSC alias) \n  wget ${chromAlias_url} -O - | zcat | cut -f1-2 | sort -k1 > chromAlias.txt\n\n  # Create a regex that will match any GTF lines\n  # beginning with one of the sequence names present in the FASTA file\n  readarray -t seq_names < <(grep '^>' ${params.ref_fasta} | sed -r 's/^>//')\n  seq_name_regex=\"\\$(IFS='|'; echo \"^(\\${seq_names[*]})\")\"\n\n  # The following command:\n  # - retrieves and extracts the GTF file from Ensembl,\n  #   removing comments and sorting on first column\n  # - uses `join` to convert chromosome names in first column of GTF file\n  #   to UCSC nomenclature, and removes redundant first column of output\n  # - Limits the output to only those sequence names in the FASTA file\n  # - writes the modified GTF to a gzipped file\n  join -t \\$'\\\\t' -1 ${chromAlias_join_field} -2 1 \\\n    chromAlias.txt \\\n    <(wget ${ensembl_gtf_url} -O - | zgrep -v \"^#\" | sort -k1) \\\n    | cut -f2- \\\n    | grep -E \"\\${seq_name_regex}\" \\\n    | gzip -c > ${ensembl_gtf_file}\n  \"\"\"\n}",
        "nb_lignes_process": 56,
        "string_script": "  chromAlias_url =\n    \"${params.urls.ucsc_base_url}/goldenPath/\" +\n    \"${params.genome.ucsc}/database/chromAlias.txt.gz\"\n  chromAlias_join_field = 1\n\n                              \n  ensembl_gtf_url =\n    \"${params.urls.ensembl_base_url}/release-${params.genome.ensembl}/gtf/\" +\n    \"${params.genome.species.toLowerCase().replaceAll(\" \",\"_\")}\" + \"/\" +\n    \"${params.genome.species.replaceAll(\" \",\"_\")}\" + \".\" +\n    \"${params.genome.assembly}.${params.genome.ensembl}.gtf.gz\"\n                                                                           \n  ensembl_gtf_file = \"${file(ensembl_gtf_url).name}\"\n  ensembl_gtf_file =\n    \"${ensembl_gtf_file.replaceFirst(\"\\\\.gtf\\\\.gz\", \"\")}\" + \".\" +\n    \"ucsc.${params.genome.set}.gtf.gz\"\n\n  \"\"\"\n  # Retrieve and gunzip chromAlias file from UCSC, keeping only first two\n  # columns, and sorting on first column (non-UCSC alias) \n  wget ${chromAlias_url} -O - | zcat | cut -f1-2 | sort -k1 > chromAlias.txt\n\n  # Create a regex that will match any GTF lines\n  # beginning with one of the sequence names present in the FASTA file\n  readarray -t seq_names < <(grep '^>' ${params.ref_fasta} | sed -r 's/^>//')\n  seq_name_regex=\"\\$(IFS='|'; echo \"^(\\${seq_names[*]})\")\"\n\n  # The following command:\n  # - retrieves and extracts the GTF file from Ensembl,\n  #   removing comments and sorting on first column\n  # - uses `join` to convert chromosome names in first column of GTF file\n  #   to UCSC nomenclature, and removes redundant first column of output\n  # - Limits the output to only those sequence names in the FASTA file\n  # - writes the modified GTF to a gzipped file\n  join -t \\$'\\\\t' -1 ${chromAlias_join_field} -2 1 \\\n    chromAlias.txt \\\n    <(wget ${ensembl_gtf_url} -O - | zgrep -v \"^#\" | sort -k1) \\\n    | cut -f2- \\\n    | grep -E \"\\${seq_name_regex}\" \\\n    | gzip -c > ${ensembl_gtf_file}\n  \"\"\"",
        "nb_lignes_script": 40,
        "language_script": "bash",
        "tools": [
            "GTfold",
            "joineRML"
        ],
        "tools_url": [
            "https://bio.tools/gtfold",
            "https://bio.tools/joinerml"
        ],
        "tools_dico": [
            {
                "name": "GTfold",
                "uri": "https://bio.tools/gtfold",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0082",
                            "term": "Structure prediction"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0099",
                            "term": "RNA"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0271",
                                    "term": "Structure prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0278",
                                    "term": "RNA secondary structure prediction"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "GTfold is a fast, scalable multicore code for predicting RNA secondary structure that is one to two orders of magnitude faster than the de facto standard programs and achieves comparable accuracy of prediction.",
                "homepage": "http://gtfold.sourceforge.net/"
            },
            {
                "name": "joineRML",
                "uri": "https://bio.tools/joinerml",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3569",
                            "term": "Applied mathematics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Joint Modelling of Multivariate Longitudinal Data and Time-to-Event Outcomes.",
                "homepage": "https://cran.r-project.org/web/packages/joineRML/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Retrieving and processing Ensembl GTF file\"",
            "publishDir \"${params.output_dir}/Output/GTF\""
        ],
        "when": "",
        "stub": ""
    },
    "generateBED": {
        "name_process": "generateBED",
        "string_process": "\nprocess generateBED {\n  tag \"Generating Ensembl BED file\"\n  publishDir \"${params.output_dir}/Output/BED\"\n\n  input:\n  file(ensembl_gtf_file) from generateGTF_to_generateBED\n\n  output:\n  file(ensembl_bed_file) \\\n    into (\n      generateBED_to_runRSeQCgeneBodyCoverage,\n      generateBED_to_runRSeQCinferExperiment,\n      generateBED_to_runRSeQCinnerDistance,\n      generateBED_to_runRSeQCjunctionAnnotation,\n      generateBED_to_runRSeQCjunctionSaturation,\n      generateBED_to_runRSeQCreadDistribution,\n      generateBED_to_runRSeQCtin\n    )\n\n  script:\n  ensembl_gp_file =\n    \"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gtf\\\\.gz\", \".gp\")}\"\n  ensembl_bed_file =\n    \"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gtf\\\\.gz\", \".bed\")}\"\n\n  \"\"\"\n  # Retrieve command-line utilities from UCSC and make them executable\n  wget ${params.urls.ucsc_app_url}/gtfToGenePred\n  wget ${params.urls.ucsc_app_url}/genePredToBed\n  chmod +x gtfToGenePred genePredToBed\n  # Convert GTF file to BED file via intermediate genePred format\n  ./gtfToGenePred ${ensembl_gtf_file} ${ensembl_gp_file}\n  ./genePredToBed ${ensembl_gp_file} ${ensembl_bed_file}\n  \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "  ensembl_gp_file =\n    \"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gtf\\\\.gz\", \".gp\")}\"\n  ensembl_bed_file =\n    \"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gtf\\\\.gz\", \".bed\")}\"\n\n  \"\"\"\n  # Retrieve command-line utilities from UCSC and make them executable\n  wget ${params.urls.ucsc_app_url}/gtfToGenePred\n  wget ${params.urls.ucsc_app_url}/genePredToBed\n  chmod +x gtfToGenePred genePredToBed\n  # Convert GTF file to BED file via intermediate genePred format\n  ./gtfToGenePred ${ensembl_gtf_file} ${ensembl_gp_file}\n  ./genePredToBed ${ensembl_gp_file} ${ensembl_bed_file}\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "generateGTF_to_generateBED"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Generating Ensembl BED file\"",
            "publishDir \"${params.output_dir}/Output/BED\""
        ],
        "when": "",
        "stub": ""
    },
    "runSTAR1pass": {
        "name_process": "runSTAR1pass",
        "string_process": "\nprocess runSTAR1pass {\n  tag \"Running STAR first pass on ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/STAR_1Pass\"\n\n  module params.modules.star\n\n  input:\n  set indivID, sampleID, libraryID, rgID, platform_unit, platform,\n    platform_model, run_date, center, R1, R2 \\\n    from readInput_to_runSTAR1pass\n\n  output:\n  file(\"${star_outFileNamePrefix}SJ.out.tab\") \\\n    into runSTAR1pass_to_runSTARgenomeGenerate\n\n  script:\n  star_outFileNamePrefix = \"${sampleID}.1pass.\"\n\n  \"\"\"\n  module list\n\n  STAR \\\n    --genomeDir ${params.STAR.genomeDir} \\\n    --readFilesIn '${R1}' '${params.paired_end ? \"${R2}\": \"\"}' \\\n    --runThreadN \\$NSLOTS \\\n    --outFileNamePrefix ${star_outFileNamePrefix} \\\n    --outSAMtype BAM Unsorted \\\n    --outFilterMultimapNmax ${params.STAR.outFilterMultimapNmax} \\\n    --outFilterType BySJout \\\n    --readFilesCommand zcat\n  \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "  star_outFileNamePrefix = \"${sampleID}.1pass.\"\n\n  \"\"\"\n  module list\n\n  STAR \\\n    --genomeDir ${params.STAR.genomeDir} \\\n    --readFilesIn '${R1}' '${params.paired_end ? \"${R2}\": \"\"}' \\\n    --runThreadN \\$NSLOTS \\\n    --outFileNamePrefix ${star_outFileNamePrefix} \\\n    --outSAMtype BAM Unsorted \\\n    --outFilterMultimapNmax ${params.STAR.outFilterMultimapNmax} \\\n    --outFilterType BySJout \\\n    --readFilesCommand zcat\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "readInput_to_runSTAR1pass"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runSTAR1pass_to_runSTARgenomeGenerate"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running STAR first pass on ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/STAR_1Pass\"",
            "module params.modules.star"
        ],
        "when": "",
        "stub": ""
    },
    "runSTARgenomeGenerate": {
        "name_process": "runSTARgenomeGenerate",
        "string_process": "\nprocess runSTARgenomeGenerate {\n  tag \"Generating STAR genome reference with splice junctions\"\n  publishDir \"${params.output_dir}/Output/STAR\"\n\n  module params.modules.star\n\n  input:\n                                                                              \n  val sjdb_files from runSTAR1pass_to_runSTARgenomeGenerate.toSortedList()\n  file(ensembl_gtf_file) from generateGTF_to_runSTARgenomeGenerate\n\n  output:\n  file(\"Log.out\") into runSTARgenomeGenerateOutput\n  file(\"${genomeDir}\") into runSTARgenomeGenerate_to_runSTAR2pass\n\n  script:\n  genomeDir=\"genomeGenerate\"\n  sjdbGTFfile=\"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gz\", \"\")}\"\n\n  \"\"\"\n  module list\n\n  # Create output directory\n  mkdir ${genomeDir}/\n  # Decompress GTF to temporary file\n  zcat ${ensembl_gtf_file} > ${sjdbGTFfile}\n\n  STAR \\\n    --runMode genomeGenerate \\\n    --genomeDir ${genomeDir} \\\n    --genomeFastaFiles ${params.ref_fasta} \\\n    --sjdbFileChrStartEnd ${sjdb_files.join(' ')} \\\n    --sjdbGTFfile ${sjdbGTFfile} \\\n    --sjdbOverhang ${params.read_length - 1} \\\n    --runThreadN \\$NSLOTS \\\n    --limitSjdbInsertNsj ${params.STAR.limitSjdbInsertNsj}\n  \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "  genomeDir=\"genomeGenerate\"\n  sjdbGTFfile=\"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gz\", \"\")}\"\n\n  \"\"\"\n  module list\n\n  # Create output directory\n  mkdir ${genomeDir}/\n  # Decompress GTF to temporary file\n  zcat ${ensembl_gtf_file} > ${sjdbGTFfile}\n\n  STAR \\\n    --runMode genomeGenerate \\\n    --genomeDir ${genomeDir} \\\n    --genomeFastaFiles ${params.ref_fasta} \\\n    --sjdbFileChrStartEnd ${sjdb_files.join(' ')} \\\n    --sjdbGTFfile ${sjdbGTFfile} \\\n    --sjdbOverhang ${params.read_length - 1} \\\n    --runThreadN \\$NSLOTS \\\n    --limitSjdbInsertNsj ${params.STAR.limitSjdbInsertNsj}\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "runSTAR1pass_to_runSTARgenomeGenerate",
            "generateGTF_to_runSTARgenomeGenerate"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runSTARgenomeGenerateOutput",
            "runSTARgenomeGenerate_to_runSTAR2pass"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Generating STAR genome reference with splice junctions\"",
            "publishDir \"${params.output_dir}/Output/STAR\"",
            "module params.modules.star"
        ],
        "when": "",
        "stub": ""
    },
    "runSTAR2pass": {
        "name_process": "runSTAR2pass",
        "string_process": "\nprocess runSTAR2pass {\n  tag \"Running STAR second pass on ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}\"\n\n  module params.modules.star\n  module params.modules.htslib\n  module params.modules.samtools\n\n  input:\n  set indivID, sampleID, libraryID, rgID, platform_unit, platform,\n    platform_model, run_date, center, R1, R2 \\\n    from readInput_to_runSTAR2pass\n  file(genomeDir) from runSTARgenomeGenerate_to_runSTAR2pass\n\n  output:\n                      \n  file(star_log_file) into runSTAR2pass_to_runMultiQCSample\n                    \n  set indivID, sampleID, file(outfile_bam) \\\n    into (\n      runSTAR2pass_to_runRSeQCbamStat,\n      runSTAR2pass_to_runRSeQCgeneBodyCoverage,\n      runSTAR2pass_to_runRSeQCjunctionAnnotation,\n      runSTAR2pass_to_runRSeQCjunctionSaturation,\n      runSTAR2pass_to_runRSeQCtin,\n      runSTAR2pass_to_runRSeQCinnerDistance,\n      runSTAR2pass_to_runRSeQCclippingProfile,\n      runSTAR2pass_to_runRSeQCinferExperiment,\n      runSTAR2pass_to_runRSeQCinsertionProfile,\n      runSTAR2pass_to_runRSeQCdeletionProfile,\n      runSTAR2pass_to_runRSeQCreadDistribution,\n      runSTAR2pass_to_runRSeQCreadGC,\n      runSTAR2pass_to_runRSeQCreadDuplication,\n      runSTAR2pass_to_runRSeQCreadNVC,\n      runSTAR2pass_to_runRSeQCreadQuality\n    )\n                   \n  set indivID, sampleID, file(star_transcriptome_bam) \\\n    into runSTAR2pass_to_runRSEMcalculateExpression\n                                                             \n  set file(outfile_bai), file(outfile_bambai) \\\n    into runSTAR2passOutput\n\n  script:\n  star_output_path = \"Processing/Libraries/${libraryID}/${rgID}/STAR_2Pass\"\n  star_outFileNamePrefix = \"${star_output_path}/${sampleID}.\"\n  star_coordinate_bam =\n    \"${star_outFileNamePrefix}Aligned.sortedByCoord.out.bam\"\n  star_transcriptome_bam = \n    \"${star_outFileNamePrefix}Aligned.toTranscriptome.out.bam\"\n  star_log_file = \"${star_outFileNamePrefix}Log.final.out\"\n  outfile_bam = \"${sampleID}.bam\"\n  outfile_bai = \"${sampleID}.bai\"\n  outfile_bambai = \"${sampleID}.bam.bai\"\n\n  \"\"\"\n  module list\n\n  # Extract the 'mem_total' qsub parameter, which should be an integer followed\n  # by the letter 'G' (e.g., '30G') or an empty string if not specified\n  MEM_TOTAL=\"\\$(qstat -j \\$JOB_ID | grep -oP \"mem_total=[^,]+\" | cut -f2 -d'=')\"\n\n  # Create @RG (read group) header line for STAR output\n  # Note: --outSAMattrRGline flag replaces call to Picard AddOrReplaceReadGroups\n  # Read group fields are discussed at:\n  # https://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups\n  RGline=\"ID:${rgID} SM:${sampleID} LB:${libraryID}\"\n  RGline=\"\\${RGline} PL:${platform} PU:${platform_unit}\"\n\n  # Perform second-pass STAR alignment\n  mkdir -p ${star_output_path}/\n  STAR \\\n    --genomeDir ${genomeDir} \\\n    --readFilesIn '${R1}' '${params.paired_end ? \"${R2}\": \"\"}' \\\n    --runThreadN \\$NSLOTS \\\n    --outFileNamePrefix ${star_outFileNamePrefix} \\\n    --outSAMtype BAM SortedByCoordinate \\\n    --quantMode TranscriptomeSAM \\\n    --outFilterMultimapNmax ${params.STAR.outFilterMultimapNmax} \\\n    --outFilterType BySJout \\\n    --outSAMunmapped Within \\\n    --readFilesCommand zcat \\\n    --outSAMattrRGline \\${RGline} \\\n    \\$([[ \\$MEM_TOTAL != \"\" ]] && \\\n      echo \"--limitBAMsortRAM \\$((\\${MEM_TOTAL/G/} * 1024**3))\")\n\n  # Rename coordinate-sorted BAM file\n  mv -v \"${star_coordinate_bam}\" \"${outfile_bam}\"\n  # Index coordinate-sorted BAM file\n  samtools index \"${outfile_bam}\"\n  # Copy the .bam.bai index to .bai index for convenience\n  cp -av ${outfile_bambai} ${outfile_bai}\n  \"\"\"\n}",
        "nb_lignes_process": 93,
        "string_script": "  star_output_path = \"Processing/Libraries/${libraryID}/${rgID}/STAR_2Pass\"\n  star_outFileNamePrefix = \"${star_output_path}/${sampleID}.\"\n  star_coordinate_bam =\n    \"${star_outFileNamePrefix}Aligned.sortedByCoord.out.bam\"\n  star_transcriptome_bam = \n    \"${star_outFileNamePrefix}Aligned.toTranscriptome.out.bam\"\n  star_log_file = \"${star_outFileNamePrefix}Log.final.out\"\n  outfile_bam = \"${sampleID}.bam\"\n  outfile_bai = \"${sampleID}.bai\"\n  outfile_bambai = \"${sampleID}.bam.bai\"\n\n  \"\"\"\n  module list\n\n  # Extract the 'mem_total' qsub parameter, which should be an integer followed\n  # by the letter 'G' (e.g., '30G') or an empty string if not specified\n  MEM_TOTAL=\"\\$(qstat -j \\$JOB_ID | grep -oP \"mem_total=[^,]+\" | cut -f2 -d'=')\"\n\n  # Create @RG (read group) header line for STAR output\n  # Note: --outSAMattrRGline flag replaces call to Picard AddOrReplaceReadGroups\n  # Read group fields are discussed at:\n  # https://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups\n  RGline=\"ID:${rgID} SM:${sampleID} LB:${libraryID}\"\n  RGline=\"\\${RGline} PL:${platform} PU:${platform_unit}\"\n\n  # Perform second-pass STAR alignment\n  mkdir -p ${star_output_path}/\n  STAR \\\n    --genomeDir ${genomeDir} \\\n    --readFilesIn '${R1}' '${params.paired_end ? \"${R2}\": \"\"}' \\\n    --runThreadN \\$NSLOTS \\\n    --outFileNamePrefix ${star_outFileNamePrefix} \\\n    --outSAMtype BAM SortedByCoordinate \\\n    --quantMode TranscriptomeSAM \\\n    --outFilterMultimapNmax ${params.STAR.outFilterMultimapNmax} \\\n    --outFilterType BySJout \\\n    --outSAMunmapped Within \\\n    --readFilesCommand zcat \\\n    --outSAMattrRGline \\${RGline} \\\n    \\$([[ \\$MEM_TOTAL != \"\" ]] && \\\n      echo \"--limitBAMsortRAM \\$((\\${MEM_TOTAL/G/} * 1024**3))\")\n\n  # Rename coordinate-sorted BAM file\n  mv -v \"${star_coordinate_bam}\" \"${outfile_bam}\"\n  # Index coordinate-sorted BAM file\n  samtools index \"${outfile_bam}\"\n  # Copy the .bam.bai index to .bai index for convenience\n  cp -av ${outfile_bambai} ${outfile_bai}\n  \"\"\"",
        "nb_lignes_script": 48,
        "language_script": "bash",
        "tools": [
            "STAR",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/star",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "readInput_to_runSTAR2pass",
            "runSTARgenomeGenerate_to_runSTAR2pass"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runSTAR2pass_to_runMultiQCSample",
            "",
            "runSTAR2pass_to_runRSEMcalculateExpression",
            "runSTAR2passOutput"
        ],
        "nb_outputs": 4,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running STAR second pass on ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}\"",
            "module params.modules.star",
            "module params.modules.htslib",
            "module params.modules.samtools"
        ],
        "when": "",
        "stub": ""
    },
    "runRSEMprepareReference": {
        "name_process": "runRSEMprepareReference",
        "string_process": "\nprocess runRSEMprepareReference {\n  tag \"Preparing RSEM reference\"\n  publishDir \"${params.output_dir}/Output/RSEM\"\n\n  module params.modules.rsem\n\n  input:\n  file(ensembl_gtf_file) from generateGTF_to_runRSEMprepareReference\n\n  output:\n                                                                                \n  file(reference_name) \\\n    into runRSEMprepareReference_to_runRSEMcalculateExpression\n\n  script:\n  reference_name=\"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gtf\\\\.gz\", \"\")}\"\n  rsem_gtf_file=\"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gz\", \"\")}\"\n  \"\"\"\n  module list\n\n  # Create output directory, named after prefix of GTF file\n  mkdir ${reference_name}/\n  # Decompress GTF to temporary file\n  zcat ${ensembl_gtf_file} > ${rsem_gtf_file}\n\n  # Prepare RSEM reference files, named after prefix of GTF file\n  rsem-prepare-reference \\\n    -p \\$NSLOTS \\\n    --gtf ${rsem_gtf_file} \\\n    ${params.ref_fasta} \\\n    ${reference_name}/${reference_name}\n  \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "  reference_name=\"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gtf\\\\.gz\", \"\")}\"\n  rsem_gtf_file=\"${ensembl_gtf_file.name.replaceFirst(\"\\\\.gz\", \"\")}\"\n  \"\"\"\n  module list\n\n  # Create output directory, named after prefix of GTF file\n  mkdir ${reference_name}/\n  # Decompress GTF to temporary file\n  zcat ${ensembl_gtf_file} > ${rsem_gtf_file}\n\n  # Prepare RSEM reference files, named after prefix of GTF file\n  rsem-prepare-reference \\\n    -p \\$NSLOTS \\\n    --gtf ${rsem_gtf_file} \\\n    ${params.ref_fasta} \\\n    ${reference_name}/${reference_name}\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "generateGTF_to_runRSEMprepareReference"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSEMprepareReference_to_runRSEMcalculateExpression"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Preparing RSEM reference\"",
            "publishDir \"${params.output_dir}/Output/RSEM\"",
            "module params.modules.rsem"
        ],
        "when": "",
        "stub": ""
    },
    "runRSEMcalculateExpression": {
        "name_process": "runRSEMcalculateExpression",
        "string_process": "\nprocess runRSEMcalculateExpression {\n  tag \"Using RSEM to calculate expression values for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSEM\"\n\n  module params.modules.R\n  module params.modules.rsem\n\n  input:\n  set indivID, sampleID, star_transcriptome_bam \\\n    from runSTAR2pass_to_runRSEMcalculateExpression\n                                                                                \n  file(rsemReference) \\\n    from runRSEMprepareReference_to_runRSEMcalculateExpression\n\n  output:\n                                                                  \n  file(\"${sampleID}.genes.results\") \\\n    into runRSEMcalculateExpressionGenes_to_createSE\n  file(\"${sampleID}.isoforms.results\") \\\n    into runRSEMcalculateExpressionIsoforms_to_createSE\n                                                             \n  file(outfile_plot) into runRSEMcalculateExpressionOutput\n\n  script:\n  outfile_plot = \"${sampleID}_RSEM.pdf\"\n\n  \"\"\"\n  module list\n\n  # Extract the 'mem_total' qsub parameter, which should be an integer followed\n  # by the letter 'G' (e.g., '30G') or an empty string if not specified\n  MEM_TOTAL=\"\\$(qstat -j \\$JOB_ID | grep -oP \"mem_total=[^,]+\" | cut -f2 -d'=')\"\n\n  # Compute expression values using RSEM\n  rsem-calculate-expression \\\n    --calc-ci --estimate-rspd --no-bam-output --bam \\\n    ${params.paired_end ? \"--paired-end\" : \"\"} \\\n    --forward-prob ${params.stranded ? 0 : 0.5} \\\n    -p \\$NSLOTS \\\n    ${star_transcriptome_bam} \\\n    ${rsemReference}/${rsemReference} \\\n    ${sampleID}\n\n  rsem-plot-model ${sampleID} ${outfile_plot}\n  \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "  outfile_plot = \"${sampleID}_RSEM.pdf\"\n\n  \"\"\"\n  module list\n\n  # Extract the 'mem_total' qsub parameter, which should be an integer followed\n  # by the letter 'G' (e.g., '30G') or an empty string if not specified\n  MEM_TOTAL=\"\\$(qstat -j \\$JOB_ID | grep -oP \"mem_total=[^,]+\" | cut -f2 -d'=')\"\n\n  # Compute expression values using RSEM\n  rsem-calculate-expression \\\n    --calc-ci --estimate-rspd --no-bam-output --bam \\\n    ${params.paired_end ? \"--paired-end\" : \"\"} \\\n    --forward-prob ${params.stranded ? 0 : 0.5} \\\n    -p \\$NSLOTS \\\n    ${star_transcriptome_bam} \\\n    ${rsemReference}/${rsemReference} \\\n    ${sampleID}\n\n  rsem-plot-model ${sampleID} ${outfile_plot}\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSEMcalculateExpression",
            "runRSEMprepareReference_to_runRSEMcalculateExpression"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSEMcalculateExpressionGenes_to_createSE",
            "runRSEMcalculateExpressionIsoforms_to_createSE",
            "runRSEMcalculateExpressionOutput"
        ],
        "nb_outputs": 3,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Using RSEM to calculate expression values for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSEM\"",
            "module params.modules.R",
            "module params.modules.rsem"
        ],
        "when": "",
        "stub": ""
    },
    "runFastQC": {
        "name_process": "runFastQC",
        "string_process": "\nprocess runFastQC {\n  tag \"Running FastQC for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/FastQC\"\n\n  module params.modules.fastqc\n\n  input:\n  set indivID, sampleID, libraryID, rgID, platform_unit, platform,\n    platform_model, run_date, center, R1, R2 \\\n    from readInput_to_runFastQC\n\n  output:\n  file(\"*.zip\") into runFastQC_to_runMultiQCFastq\n\n  script:\n  \"\"\"\n  module list\n\n  # Run FastQC\n  fastqc -t \\$NSLOTS -o . '${R1}' '${params.paired_end ? \"${R2}\" : \"\"}'\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  \"\"\"\n  module list\n\n  # Run FastQC\n  fastqc -t \\$NSLOTS -o . '${R1}' '${params.paired_end ? \"${R2}\" : \"\"}'\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "readInput_to_runFastQC"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runFastQC_to_runMultiQCFastq"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running FastQC for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/Processing/Libraries/${libraryID}/${rgID}/FastQC\"",
            "module params.modules.fastqc"
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCbamStat": {
        "name_process": "runRSeQCbamStat",
        "string_process": "\nprocess runRSeQCbamStat {\n  tag \"Running RSeQC bam_stat for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCbamStat\n  output:\n  file(\"${sampleID}.bam_stat.txt\") into runRSeQCbamStat_to_runMultiQCSample\n  script:\n  \"\"\"\n  module list\n  bam_stat.py -i ${bam} > ${sampleID}.bam_stat.txt\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  module list\n  bam_stat.py -i ${bam} > ${sampleID}.bam_stat.txt\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCbamStat"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCbamStat_to_runMultiQCSample"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC bam_stat for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCclippingProfile": {
        "name_process": "runRSeQCclippingProfile",
        "string_process": "\nprocess runRSeQCclippingProfile {\n  tag \"Running RSeQC clipping_profile for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCclippingProfile\n  output:\n  file(\"${sampleID}.*\") into runRSeQCclippingProfileOutput\n  script:\n  \"\"\"\n  module list\n  clipping_profile.py -i ${bam} -o ${sampleID} \\\n    -s ${params.paired_end ? \"PE\" : \"SE\"}\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "  \"\"\"\n  module list\n  clipping_profile.py -i ${bam} -o ${sampleID} \\\n    -s ${params.paired_end ? \"PE\" : \"SE\"}\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCclippingProfile"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCclippingProfileOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC clipping_profile for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCdeletionProfile": {
        "name_process": "runRSeQCdeletionProfile",
        "string_process": "\nprocess runRSeQCdeletionProfile {\n  tag \"Running RSeQC deletion_profile for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCdeletionProfile\n  output:\n  file(\"${sampleID}.*\") into runRSeQCdeletionProfileOutput\n  script:\n  \"\"\"\n  module list\n  deletion_profile.py -i ${bam} -l ${params.read_length} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  module list\n  deletion_profile.py -i ${bam} -l ${params.read_length} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCdeletionProfile"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCdeletionProfileOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC deletion_profile for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCgeneBodyCoverage": {
        "name_process": "runRSeQCgeneBodyCoverage",
        "string_process": "\nprocess runRSeQCgeneBodyCoverage {\n  tag \"Running RSeQC geneBody_coverage for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCgeneBodyCoverage\n  file(ensembl_bed_file) from generateBED_to_runRSeQCgeneBodyCoverage\n  output:\n  file(\"${sampleID}.geneBodyCoverage.txt\") \\\n    into runRSeQCgeneBodyCoverage_to_runMultiQCSample\n  file(\"${sampleID}.*\") into runRSeQCgeneBodyCoverageOutput\n  script:\n  \"\"\"\n  module list\n  geneBody_coverage.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  module list\n  geneBody_coverage.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCgeneBodyCoverage",
            "generateBED_to_runRSeQCgeneBodyCoverage"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSeQCgeneBodyCoverage_to_runMultiQCSample",
            "runRSeQCgeneBodyCoverageOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC geneBody_coverage for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCinferExperiment": {
        "name_process": "runRSeQCinferExperiment",
        "string_process": "\nprocess runRSeQCinferExperiment {\n  tag \"Running RSeQC infer_experiment for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCinferExperiment\n  file(ensembl_bed_file) from generateBED_to_runRSeQCinferExperiment\n  output:\n  file(\"${sampleID}.infer_experiment.txt\") \\\n    into runRSeQCinferExperiment_to_runMultiQCSample\n  script:\n  \"\"\"\n  module list\n  infer_experiment.py -i ${bam} -r ${ensembl_bed_file} > \\\n    ${sampleID}.infer_experiment.txt\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  module list\n  infer_experiment.py -i ${bam} -r ${ensembl_bed_file} > \\\n    ${sampleID}.infer_experiment.txt\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCinferExperiment",
            "generateBED_to_runRSeQCinferExperiment"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSeQCinferExperiment_to_runMultiQCSample"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC infer_experiment for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCinnerDistance": {
        "name_process": "runRSeQCinnerDistance",
        "string_process": "\nprocess runRSeQCinnerDistance {\n  tag \"Running RSeQC inner_distance for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCinnerDistance\n  file(ensembl_bed_file) from generateBED_to_runRSeQCinnerDistance\n  output:\n  file(\"${sampleID}.inner_distance_freq.txt\") \\\n    into runRSeQCinnerDistance_to_runMultiQCSample\n  file(\"${sampleID}.*\") into runRSeQCinnerDistanceOutput\n  script:\n  \"\"\"\n  module list\n  inner_distance.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  module list\n  inner_distance.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCinnerDistance",
            "generateBED_to_runRSeQCinnerDistance"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSeQCinnerDistance_to_runMultiQCSample",
            "runRSeQCinnerDistanceOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC inner_distance for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCinsertionProfile": {
        "name_process": "runRSeQCinsertionProfile",
        "string_process": "\nprocess runRSeQCinsertionProfile {\n  tag \"Running RSeQC insertion_profile for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCinsertionProfile\n  output:\n  file(\"${sampleID}.*\") into runRSeQCinsertionProfileOutput\n  script:\n  \"\"\"\n  module list\n  insertion_profile.py -i ${bam} -o ${sampleID} \\\n    -s ${params.paired_end ? \"PE\" : \"SE\"}\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "  \"\"\"\n  module list\n  insertion_profile.py -i ${bam} -o ${sampleID} \\\n    -s ${params.paired_end ? \"PE\" : \"SE\"}\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCinsertionProfile"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCinsertionProfileOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC insertion_profile for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCjunctionAnnotation": {
        "name_process": "runRSeQCjunctionAnnotation",
        "string_process": "\nprocess runRSeQCjunctionAnnotation {\n  tag \"Running RSeQC junction_annotation for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCjunctionAnnotation\n  file(ensembl_bed_file) from generateBED_to_runRSeQCjunctionAnnotation\n  output:\n  file(\"${sampleID}.junction_annotation.txt\") \\\n    into runRSeQCjunctionAnnotation_to_runMultiQCSample\n  file(\"${sampleID}.*\") into runRSeQCjunctionAnnotationOutput\n  script:\n  \"\"\"\n  module list\n  junction_annotation.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID} 2> \\\n    ${sampleID}.junction_annotation.txt\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  module list\n  junction_annotation.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID} 2> \\\n    ${sampleID}.junction_annotation.txt\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCjunctionAnnotation",
            "generateBED_to_runRSeQCjunctionAnnotation"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSeQCjunctionAnnotation_to_runMultiQCSample",
            "runRSeQCjunctionAnnotationOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC junction_annotation for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCjunctionSaturation": {
        "name_process": "runRSeQCjunctionSaturation",
        "string_process": "\nprocess runRSeQCjunctionSaturation {\n  tag \"Running RSeQC junction_saturation for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCjunctionSaturation\n  file(ensembl_bed_file) from generateBED_to_runRSeQCjunctionSaturation\n  output:\n  file(\"${sampleID}.junctionSaturation_plot.r\") \\\n    into runRSeQCjunctionSaturation_to_runMultiQCSample\n  file(\"${sampleID}.*\") into runRSeQCjunctionSaturationOutput\n  script:\n  \"\"\"\n  module list\n  junction_saturation.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  module list\n  junction_saturation.py -i ${bam} -r ${ensembl_bed_file} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCjunctionSaturation",
            "generateBED_to_runRSeQCjunctionSaturation"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSeQCjunctionSaturation_to_runMultiQCSample",
            "runRSeQCjunctionSaturationOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC junction_saturation for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCreadDistribution": {
        "name_process": "runRSeQCreadDistribution",
        "string_process": "\nprocess runRSeQCreadDistribution {\n  tag \"Running RSeQC read_distribution for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCreadDistribution\n  file(ensembl_bed_file) from generateBED_to_runRSeQCreadDistribution\n  output:\n  file(\"${sampleID}.read_distribution.txt\") \\\n    into runRSeQCreadDistribution_to_runMultiQCSample\n  script:\n  \"\"\"\n  module list\n  read_distribution.py -i ${bam} -r ${ensembl_bed_file} > \\\n    ${sampleID}.read_distribution.txt\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  module list\n  read_distribution.py -i ${bam} -r ${ensembl_bed_file} > \\\n    ${sampleID}.read_distribution.txt\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCreadDistribution",
            "generateBED_to_runRSeQCreadDistribution"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSeQCreadDistribution_to_runMultiQCSample"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC read_distribution for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCreadDuplication": {
        "name_process": "runRSeQCreadDuplication",
        "string_process": "\nprocess runRSeQCreadDuplication {\n  tag \"Running RSeQC read_duplication for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCreadDuplication\n  output:\n  file(\"${sampleID}.pos.DupRate.xls\") \\\n    into runRSeQCreadDuplication_to_runMultiQCSample\n  file(\"${sampleID}.*\") into runRSeQCreadDuplicationOutput\n  script:\n  \"\"\"\n  module list\n  read_duplication.py -i ${bam} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  module list\n  read_duplication.py -i ${bam} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCreadDuplication"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCreadDuplication_to_runMultiQCSample",
            "runRSeQCreadDuplicationOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC read_duplication for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCreadGC": {
        "name_process": "runRSeQCreadGC",
        "string_process": "\nprocess runRSeQCreadGC {\n  tag \"Running RSeQC read_GC for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCreadGC\n  output:\n  file(\"${sampleID}.GC.xls\") into runRSeQCreadGC_to_runMultiQCSample\n  file(\"${sampleID}.*\") into runRSeQCreadGCOutput\n  script:\n  \"\"\"\n  module list\n  read_GC.py -i ${bam} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "  \"\"\"\n  module list\n  read_GC.py -i ${bam} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCreadGC"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCreadGC_to_runMultiQCSample",
            "runRSeQCreadGCOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC read_GC for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCreadNVC": {
        "name_process": "runRSeQCreadNVC",
        "string_process": "\nprocess runRSeQCreadNVC {\n  tag \"Running RSeQC read_NVC for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCreadNVC\n  output:\n  file(\"${sampleID}.*\") into runRSeQCreadNVCOutput\n  script:\n  \"\"\"\n  module list\n  read_NVC.py -i ${bam} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  module list\n  read_NVC.py -i ${bam} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCreadNVC"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCreadNVCOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC read_NVC for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCreadQuality": {
        "name_process": "runRSeQCreadQuality",
        "string_process": "\nprocess runRSeQCreadQuality {\n  tag \"Running RSeQC read_quality for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCreadQuality\n  output:\n  file(\"${sampleID}.*\") into runRSeQCreadQualityOutput\n  script:\n  \"\"\"\n  module list\n  read_quality.py -i ${bam} -o ${sampleID}\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  module list\n  read_quality.py -i ${bam} -o ${sampleID}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCreadQuality"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runRSeQCreadQualityOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC read_quality for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runRSeQCtin": {
        "name_process": "runRSeQCtin",
        "string_process": "\nprocess runRSeQCtin {\n  tag \"Running RSeQC tin for ${sampleID}\"\n  publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"\n  module \"${params.modules.python3}:${params.modules.rseqc}\"\n  input:\n  set indivID, sampleID, bam from runSTAR2pass_to_runRSeQCtin\n  file(ensembl_bed_file) from generateBED_to_runRSeQCtin\n  output:\n  file(\"${sampleID}.summary.txt\") into runRSeQCtin_to_createSE\n  file(\"${file(bam).baseName}.*\") into runRSeQCtinOutput\n  script:\n  \"\"\"\n  module list\n  tin.py -i ${bam} -r ${ensembl_bed_file} > ${sampleID}.summary.txt\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  module list\n  tin.py -i ${bam} -r ${ensembl_bed_file} > ${sampleID}.summary.txt\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runSTAR2pass_to_runRSeQCtin",
            "generateBED_to_runRSeQCtin"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runRSeQCtin_to_createSE",
            "runRSeQCtinOutput"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Running RSeQC tin for ${sampleID}\"",
            "publishDir \"${params.output_dir}/${indivID}/${sampleID}/RSeQC\"",
            "module \"${params.modules.python3}:${params.modules.rseqc}\""
        ],
        "when": "",
        "stub": ""
    },
    "runMultiQCFastq": {
        "name_process": "runMultiQCFastq",
        "string_process": "\nprocess runMultiQCFastq {\n  tag \"Generating FASTQ-level summary and QC plots\"\n  publishDir \"${params.output_dir}/Output/QC/Fastq\"\n\n  module params.modules.python2\n  module params.modules.multiqc\n\n  input:\n                                                                              \n  val fastqc_files from runFastQC_to_runMultiQCFastq.flatten().toSortedList()\n\n  output:\n  set file(\"fastq_multiqc.html\"), file(\"fastq_multiqc_data/*\") \\\n    into runMultiQCFastqOutput\n  file(\"fastq_multiqc_data/multiqc_fastqc.txt\") \\\n    into runMultiQCFastq_to_createSE\n\n  script:\n  \"\"\"\n  module list\n  # Create temporary MultiQC input file\n  multiqc_input_tempfile=\\$(mktemp)\n  echo -e \"${fastqc_files.join('\\n')}\" > \\$multiqc_input_tempfile\n  # Run MultiQC\n  multiqc -n fastq_multiqc --file-list \\$multiqc_input_tempfile\n  \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "  \"\"\"\n  module list\n  # Create temporary MultiQC input file\n  multiqc_input_tempfile=\\$(mktemp)\n  echo -e \"${fastqc_files.join('\\n')}\" > \\$multiqc_input_tempfile\n  # Run MultiQC\n  multiqc -n fastq_multiqc --file-list \\$multiqc_input_tempfile\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "runFastQC_to_runMultiQCFastq"
        ],
        "nb_inputs": 1,
        "outputs": [
            "runMultiQCFastqOutput",
            "runMultiQCFastq_to_createSE"
        ],
        "nb_outputs": 2,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Generating FASTQ-level summary and QC plots\"",
            "publishDir \"${params.output_dir}/Output/QC/Fastq\"",
            "module params.modules.python2",
            "module params.modules.multiqc"
        ],
        "when": "",
        "stub": ""
    },
    "runMultiQCSample": {
        "name_process": "runMultiQCSample",
        "string_process": "\nprocess runMultiQCSample {\n  tag \"Generating sample-level summary and QC plots\"\n  publishDir \"${params.output_dir}/Output/QC/Sample\"\n\n  module params.modules.python2\n  module params.modules.multiqc\n\n  input:\n                                                                              \n  val rseqc_bam_stat_files \\\n    from runRSeQCbamStat_to_runMultiQCSample.toSortedList()\n  val rseqc_geneBody_coverage_files \\\n    from runRSeQCgeneBodyCoverage_to_runMultiQCSample.toSortedList()\n  val rseqc_infer_experiment_files \\\n    from runRSeQCinferExperiment_to_runMultiQCSample.toSortedList()\n  val rseqc_inner_distance_files \\\n    from runRSeQCinnerDistance_to_runMultiQCSample.toSortedList()\n  val rseqc_junction_annotation_files \\\n    from runRSeQCjunctionAnnotation_to_runMultiQCSample.toSortedList()\n  val rseqc_junction_saturation_files \\\n    from runRSeQCjunctionSaturation_to_runMultiQCSample.toSortedList()\n  val rseqc_read_distribution_files \\\n    from runRSeQCreadDistribution_to_runMultiQCSample.toSortedList()\n  val rseqc_read_duplication_files \\\n    from runRSeQCreadDuplication_to_runMultiQCSample.toSortedList()\n  val rseqc_read_GC_files \\\n    from runRSeQCreadGC_to_runMultiQCSample.toSortedList()\n  val star_files \\\n    from runSTAR2pass_to_runMultiQCSample.toSortedList()\n\n  output:\n  set file(\"sample_multiqc.html\"), file(\"sample_multiqc_data/*\") \\\n    into runMultiQCSampleOutput\n  file(\"sample_multiqc_data/multiqc_rseqc_*.txt\") \\\n    into runMultiQCSampleRSeQC_to_createSE\n  file(\"sample_multiqc_data/multiqc_star.txt\") \\\n    into runMultiQCSampleSTAR_to_createSE\n\n  script:\n  \"\"\"\n  module list\n\n  # Create temporary MultiQC input file\n  multiqc_input_tempfile=\\$(mktemp)\n  for filename in \\\n    '${rseqc_bam_stat_files.join(\"' '\")}' \\\n    '${rseqc_geneBody_coverage_files.join(\"' '\")}' \\\n    '${rseqc_infer_experiment_files.join(\"' '\")}' \\\n    '${rseqc_inner_distance_files.join(\"' '\")}' \\\n    '${rseqc_junction_annotation_files.join(\"' '\")}' \\\n    '${rseqc_junction_saturation_files.join(\"' '\")}' \\\n    '${rseqc_read_distribution_files.join(\"' '\")}' \\\n    '${rseqc_read_duplication_files.join(\"' '\")}' \\\n    '${rseqc_read_GC_files.join(\"' '\")}' \\\n    '${star_files.join(\"' '\")}'\n  do\n    echo \"\\$filename\" >> \\$multiqc_input_tempfile\n  done\n  # Run MultiQC\n  multiqc -n sample_multiqc --file-list \\$multiqc_input_tempfile\n  \"\"\"\n}",
        "nb_lignes_process": 61,
        "string_script": "  \"\"\"\n  module list\n\n  # Create temporary MultiQC input file\n  multiqc_input_tempfile=\\$(mktemp)\n  for filename in \\\n    '${rseqc_bam_stat_files.join(\"' '\")}' \\\n    '${rseqc_geneBody_coverage_files.join(\"' '\")}' \\\n    '${rseqc_infer_experiment_files.join(\"' '\")}' \\\n    '${rseqc_inner_distance_files.join(\"' '\")}' \\\n    '${rseqc_junction_annotation_files.join(\"' '\")}' \\\n    '${rseqc_junction_saturation_files.join(\"' '\")}' \\\n    '${rseqc_read_distribution_files.join(\"' '\")}' \\\n    '${rseqc_read_duplication_files.join(\"' '\")}' \\\n    '${rseqc_read_GC_files.join(\"' '\")}' \\\n    '${star_files.join(\"' '\")}'\n  do\n    echo \"\\$filename\" >> \\$multiqc_input_tempfile\n  done\n  # Run MultiQC\n  multiqc -n sample_multiqc --file-list \\$multiqc_input_tempfile\n  \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "runRSeQCbamStat_to_runMultiQCSample",
            "runRSeQCgeneBodyCoverage_to_runMultiQCSample",
            "runRSeQCinferExperiment_to_runMultiQCSample",
            "runRSeQCinnerDistance_to_runMultiQCSample",
            "runRSeQCjunctionAnnotation_to_runMultiQCSample",
            "runRSeQCjunctionSaturation_to_runMultiQCSample",
            "runRSeQCreadDistribution_to_runMultiQCSample",
            "runRSeQCreadDuplication_to_runMultiQCSample",
            "runRSeQCreadGC_to_runMultiQCSample",
            "runSTAR2pass_to_runMultiQCSample"
        ],
        "nb_inputs": 10,
        "outputs": [
            "runMultiQCSampleOutput",
            "runMultiQCSampleRSeQC_to_createSE",
            "runMultiQCSampleSTAR_to_createSE"
        ],
        "nb_outputs": 3,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Generating sample-level summary and QC plots\"",
            "publishDir \"${params.output_dir}/Output/QC/Sample\"",
            "module params.modules.python2",
            "module params.modules.multiqc"
        ],
        "when": "",
        "stub": ""
    },
    "createSE": {
        "name_process": "createSE",
        "string_process": "\nprocess createSE {\n  tag \"Combining results into SummarizedExperiment objects\"\n  publishDir \"${params.output_dir}/Output/Expression\"\n\n  module params.modules.R\n\n  input:\n                                                                              \n  val multiqcfastqc_file from runMultiQCFastq_to_createSE\n  val rseqc_tin_files from runRSeQCtin_to_createSE.toSortedList()\n  val multiqc_rseqc_files \\\n    from runMultiQCSampleRSeQC_to_createSE.flatten().toSortedList()\n  val multiqc_star_file from runMultiQCSampleSTAR_to_createSE\n  val rsem_genes_files \\\n    from runRSEMcalculateExpressionGenes_to_createSE.toSortedList()\n  val rsem_isoforms_files \\\n    from runRSEMcalculateExpressionIsoforms_to_createSE.toSortedList()\n  file(ensembl_gtf_file) from generateGTF_to_createSE\n\n  output:\n  file(\"*.rds\") into runCreateSEOutput\n\n  script:\n  rds_files = [\n    gene: \"${params.prefix}_Gene_Expression.rds\",\n    isoform: \"${params.prefix}_Isoform_Expression.rds\"\n  ]\n  \"\"\"\n  #!/usr/bin/env Rscript\n\n  # Load and list packages\n  library(biomaRt)\n  library(GenomicFeatures)\n  library(SummarizedExperiment)\n  sessionInfo()\n\n  # Convenience function to read whitespace-separated values file with a header,\n  # and leaving character values and column names as-is\n  read.wsv <- function (file, ...) {\n    read.table(\n      file, header=TRUE, check.names=FALSE, stringsAsFactors=FALSE,\n      ...\n    )\n  }\n\n  output <- list()\n\n  # Parse input file ###########################################################\n\n  output[[\"inputfile\"]] <- read.delim(\n    \"${params.infile}\", stringsAsFactors=FALSE\n  )\n  n.samples <- nrow(output[[\"inputfile\"]])\n  # Aggregate input data frame by specified variables\n  aggregate.by <- c(\"SAMPLE_ID\")\n  output[[\"inputfile\"]] <- aggregate(\n    output[[\"inputfile\"]],\n    by=output[[\"inputfile\"]][aggregate.by],\n    FUN=paste, collapse=\",\"\n  )\n  # Remove any aggregation columns and copy SAMPLE_ID column into row names\n  output[[\"inputfile\"]] <- output[[\"inputfile\"]][-seq_along(aggregate.by)]\n  rownames(output[[\"inputfile\"]]) <- output[[\"inputfile\"]][[\"SAMPLE_ID\"]]\n\n  # Parse MultiQC FastQC output table ##########################################\n\n  # FILE FORMAT\n  # 'Filename' column: (base) FASTQ filename.\n  # 'Sample' column: (base) FASTQ filename, without \".fastq.gz\" extension.\n  # The remaining columns have the following types:\n  # 'pass', 'fail', or 'warn':\n  #   adapter_content, sequence_duplication_levels, per_base_sequence_quality,\n  #   sequence_length_distribution, basic_statistics, per_sequence_gc_content,\n  #   per_base_n_content, per_base_sequence_content, overrepresented_sequences,\n  #   per_tile_sequence_quality, per_sequence_quality_scores\n  # Percentages [0..100]:\n  #   %GC, total_deduplicated_percentage\n  # Floating point values:\n  #   avg_sequence_length\n  # Integer values (represented as floating-point with trailing .0):\n  #   Sequences flagged as poor quality, Total Sequences\n  # Range of integers (mm-nn):\n  #   Sequence length\n  # Text:\n  #   Encoding, File type\n\n  # Read file, placing \"Sample\" column in row names\n  output[[\"multiqcfastqc\"]] <- read.wsv(\n    \"${multiqcfastqc_file}\", sep=\"\\\\t\", row.names=1\n  )\n\n  # Initialize a data frame with FASTQ filenames in the row names\n  aggregate.by <- data.frame(row.names=output[[\"multiqcfastqc\"]][[\"Filename\"]])\n  # Extract the read ID (R1 or R2) from FASTQ filenames, and use filenames\n  # and read IDs to look up the sample IDs from input table\n  aggregate.by[[\"sample\"]] <- NA_character_\n  aggregate.by[[\"read\"]] <- sub(\n    \".+_(R[12]).+\", \"\\\\\\\\1\", rownames(aggregate.by)\n  )\n\n  for (read in ${params.paired_end ? 'c(\"R1\", \"R2\")' : 'c(\"R1\")'}) {\n    i <- which(aggregate.by[[\"read\"]] == read)\n    aggregate.by[[\"sample\"]][i] <- output[[\"inputfile\"]][[\"SAMPLE_ID\"]][\n      match(rownames(aggregate.by)[i], basename(output[[\"inputfile\"]][[read]]))\n    ]\n  }\n  # Collapse the MultiQC results first by sample ID, then by read\n  output[[\"multiqcfastqc\"]] <- aggregate(\n    output[[\"multiqcfastqc\"]], by=aggregate.by, FUN=c, simplify=FALSE\n  )\n\n  # Simplify columns with multiple sets of FASTQ files\n  # using an appropriate function\n  columns.to.simplify <- list(\n    sum = c(\"Sequences flagged as poor quality\"),\n    mean = c(\"avg_sequence_length\", \"%GC\", \"total_deduplicated_percentage\")\n  )\n  for (f in names(columns.to.simplify)) {\n    for (j in columns.to.simplify[[f]]) {\n      output[[\"multiqcfastqc\"]][[j]] <- sapply(\n        output[[\"multiqcfastqc\"]][[j]], f\n      )\n    }\n  }\n  # Aggregate data frame again by sample ID\n  # (so R1 and R2 metrics are on the same row)\n  output[[\"multiqcfastqc\"]] <- aggregate(\n    output[[\"multiqcfastqc\"]][-(1:2)],\n    by=output[[\"multiqcfastqc\"]][\"sample\"], FUN=c, simplify=FALSE\n  )\n  # Move the sample IDs into the row names of the data frame\n  rownames(output[[\"multiqcfastqc\"]]) <- output[[\"multiqcfastqc\"]][[\"sample\"]]\n  output[[\"multiqcfastqc\"]][[\"sample\"]] <- NULL\n  # Add a prefix to the column names\n  colnames(output[[\"multiqcfastqc\"]]) <- paste(\n    \"FastQC\", colnames(output[[\"multiqcfastqc\"]])\n  )\n\n  # Parse tables of TIN metrics from RSeQC #####################################\n\n  # FILE FORMAT\n  # 'Bam_file' column: (base) BAM filename.\n  # The remaining columns have the following types:\n  # Floating point values:\n  #   TIN(mean), TIN(median), TIN(stdev)\n\n  tinfiles <- c(\n    '${rseqc_tin_files.join(\"',\\n'\")}'\n  )\n  output[[\"tinfiles\"]] <- c(\n    # Get tab-delimited column names from first line of first file\n    readLines(tinfiles[1], n=1),\n    # Read tab-delimited contents of second lines of all files\n    sapply(tinfiles, scan, what=\"\", n=1, sep=\"\\\\n\", skip=1, quiet=TRUE)\n  )\n  # Parse the character vector into a data frame\n  output[[\"tinfiles\"]] <- read.wsv(\n    textConnection(output[[\"tinfiles\"]]), row.names=1\n  )\n  # Add a prefix to the column names\n  colnames(output[[\"tinfiles\"]]) <- paste(\n    \"RSeQC\", colnames(output[[\"tinfiles\"]])\n  )\n\n  # Parse remaining MultiQC output files #######################################\n\n  # Read tables, placing first column (\"Sample\") in row names\n  # and adding prefix to column names\n  multiqc.rseqc.filenames <- c(\n    '${multiqc_rseqc_files.join(\"',\\n'\")}'\n  )\n  for (filename in multiqc.rseqc.filenames) {\n    output[[basename(filename)]] <- read.wsv(filename, row.names=1)\n    colnames(output[[basename(filename)]]) <- paste(\n      \"RSeQC\", colnames(output[[basename(filename)]])\n    )\n  }\n  output[[\"starfile\"]] <- read.wsv(\"${multiqc_star_file}\", row.names=1)\n  colnames(output[[\"starfile\"]]) <- paste(\n    \"STAR\", colnames(output[[\"starfile\"]])\n  )\n\n  # Reformat each data frame ###################################################\n\n  for (i in which(names(output) != \"inputfile\")) {\n    # Reorder rows of each data frame to match order of rows in input file\n    # Note: a while loop is used because pmatch() returns NA where there are\n    #       multiple matches, e.g.,\n    #         pmatch(\"Sample_1\", c(\"Sample_1.bam\", \"Sample_10.bam\")) == NA\n    #       Each iteration excludes any values that were previously matched.\n    j <- rep(NA_integer_, n.samples)\n    k <- seq(n.samples)\n    while (any(is.na(j))) {\n      j[is.na(j)] <- pmatch(\n        rownames(output[[\"inputfile\"]])[is.na(j)], rownames(output[[i]])[k]\n      )\n      k[j[!is.na(j)]] <- NA_integer_\n    }\n    output[[i]] <- output[[i]][j, , drop=FALSE]\n    # 1. Replace \"%\" with \"percent\", e.g., \"%GC\" -> \"percent GC\"\n    # 2. Replace whitespace/punctuation in column names with underscores\n    # 3. Remove trailing underscores from column names\n    colnames(output[[i]]) <- gsub(\"% ?\", \"percent \", colnames(output[[i]]))\n    colnames(output[[i]]) <- gsub(\n      \"_\\$\", \"\", gsub(\"[' \\\\\"\\\\\\\\(\\\\\\\\)\\\\\\\\-]\", \"_\", colnames(output[[i]]))\n    )\n  }\n\n  # Combine output into a single data frame ####################################\n\n  # Initialize with sample names from input file, then add each table in turn\n  SE.colData <- data.frame(row.names=rownames(output[[\"inputfile\"]]))\n  for (i in seq_along(output)) {\n    SE.colData <- cbind(SE.colData, output[[i]])\n  }\n\n  # Open connection to Biomart #################################################\n\n  # Determine from parameters which Biomart dataset and hostname should be used\n  biomart <- list(\n    database = \"ENSEMBL_MART_ENSEMBL\",\n    dataset = paste(\n      tolower(\n        sub(\"^(.)[^ ]+ (.+)\\$\", \"\\\\\\\\1\\\\\\\\2\", \"${params.genome.species}\")\n      ),\n      \"gene_ensembl\", sep=\"_\"\n    ),\n    host = with(\n      listEnsemblArchives(), url[version == \"${params.genome.ensembl}\"]\n    )\n  )\n  # Note: this connection is done in a repeat loop because it doesn't always\n  #       work on the first try; a maximum number of attempts is included to\n  #       keep it from endlessly looping if Biomart is down\n  cat(\n    \"Opening connection to Biomart\",\n    with(\n      biomart,\n      sprintf(\n        \"(database %s, dataset %s, host %s, Ensembl version %s).\\\\n\",\n        database, dataset, host, \"${params.genome.ensembl}\"\n      )\n    )\n  )\n  max.attempts <- 10\n  attempt <- 1\n  repeat {\n    cat(sprintf(\"Connection attempt #%d of %d...\", attempt, max.attempts))\n    mart <- try(\n      with(biomart, useMart(biomart=database, dataset=dataset, host=host)),\n      silent=TRUE\n    )\n    if (inherits(mart, \"Mart\")) {\n      cat(\"successful.\\\\n\")\n      break\n    }\n    cat(\"\\\\n\")\n    if (attempt == max.attempts) {\n      stop(\"Could not connect to Biomart after \", max.attempts, \" attempts\")\n    }\n    attempt <- attempt + 1\n  }\n\n  # Create SummarizedExperiment objects ########################################\n\n  # Copy Nextflow variables into R variables\n  rsem.filenames <- list(\n    gene=c(\n      '${rsem_genes_files.join(\"',\\n'\")}'\n    ),\n    isoform=c(\n      '${rsem_isoforms_files.join(\"',\\n'\")}'\n    )\n  )\n  biomart.attributes <- list(\n    gene = c(\n      '${params.createSE.biomart_attributes.gene.join(\"',\\n'\")}'\n    ),\n    isoform = c(\n      '${params.createSE.biomart_attributes.isoform.join(\"',\\n'\")}'\n    )\n  )\n  rds.files <- c(gene='${rds_files.gene}', isoform='${rds_files.isoform}')\n\n  # RSEM output columns related to gene/isoform-level annotation\n  rsem.annotation.columns <- c(\n    \"gene_id\", \"transcript_id(s)\", \"length\", \"effective_length\"\n  )\n  # Names of RSEM output columns holding gene/isoform IDs\n  rsem.id.columns <- c(gene=\"gene_id\", isoform=\"transcript_id\")\n\n  # Create a TxDb object from the GTF file; this will be used to populate the\n  # rowRanges of the SummarizedExperiment objects\n  txdb <- makeTxDbFromGFF(\"${ensembl_gtf_file}\")\n\n  for (type in c(\"gene\", \"isoform\")) {\n    # Reorder RSEM output files to match order of sample annotation\n    filename.suffix <- paste0(\"\\\\\\\\.\", type, \"s\", \"\\\\\\\\.results\\$\")\n    rsem.filenames[[type]] <- rsem.filenames[[type]][\n      match(\n        rownames(SE.colData),\n        sub(filename.suffix, \"\", basename(rsem.filenames[[type]]))\n      )\n    ]\n    # Read the RSEM output files into a list of matrices\n    SE.assays <- list()\n    n <- length(rsem.filenames[[type]])\n    for (i in seq(n)) {\n      cat(\"Processing\", type, \"level RSEM output file\", i, \"of\", n, \"\\\\r\")\n      rsem.output <- read.wsv(\n        rsem.filenames[[type]][i], row.names=rsem.id.columns[type]\n      )\n      # Copy each RSEM column (minus any annotation columns) into assay list\n      for (j in setdiff(colnames(rsem.output), rsem.annotation.columns)) {\n        SE.assays[[j]] <- cbind(SE.assays[[j]], rsem.output[[j]])\n      }\n    }\n    cat(\"\\\\n\")\n    # Name the rows and columns of each matrix\n    SE.assays <- lapply(SE.assays, `rownames<-`, rownames(rsem.output))\n    SE.assays <- lapply(SE.assays, `colnames<-`, rownames(SE.colData))\n\n    # Retrieve annotation from Biomart\n    BM <- getBM(attributes=biomart.attributes[[type]], mart=mart)\n    # Collapse by first column (either gene or transcript ID)\n    BM <- aggregate(BM[-1], BM[1], unique)\n    # Reorder to match order of features from RSEM output\n    BM <- BM[match(rownames(SE.assays[[1]]), BM[[1]]), ]\n    # Combine Biomart annotation with data from TxDb object\n    SE.rowRanges <- switch(type, gene=genes(txdb), isoform=transcripts(txdb))\n    mcols(SE.rowRanges) <- c(mcols(SE.rowRanges), BM[-1])\n\n    # Assemble variables into a SummarizedExperiment and write to RDS file\n    dataset <- SummarizedExperiment(\n      assays=SE.assays, colData=DataFrame(SE.colData), rowRanges=SE.rowRanges\n    )\n    saveRDS(dataset, rds.files[[type]])\n  }\n  \"\"\"\n}",
        "nb_lignes_process": 339,
        "string_script": "  rds_files = [\n    gene: \"${params.prefix}_Gene_Expression.rds\",\n    isoform: \"${params.prefix}_Isoform_Expression.rds\"\n  ]\n  \"\"\"\n  #!/usr/bin/env Rscript\n\n  # Load and list packages\n  library(biomaRt)\n  library(GenomicFeatures)\n  library(SummarizedExperiment)\n  sessionInfo()\n\n  # Convenience function to read whitespace-separated values file with a header,\n  # and leaving character values and column names as-is\n  read.wsv <- function (file, ...) {\n    read.table(\n      file, header=TRUE, check.names=FALSE, stringsAsFactors=FALSE,\n      ...\n    )\n  }\n\n  output <- list()\n\n  # Parse input file ###########################################################\n\n  output[[\"inputfile\"]] <- read.delim(\n    \"${params.infile}\", stringsAsFactors=FALSE\n  )\n  n.samples <- nrow(output[[\"inputfile\"]])\n  # Aggregate input data frame by specified variables\n  aggregate.by <- c(\"SAMPLE_ID\")\n  output[[\"inputfile\"]] <- aggregate(\n    output[[\"inputfile\"]],\n    by=output[[\"inputfile\"]][aggregate.by],\n    FUN=paste, collapse=\",\"\n  )\n  # Remove any aggregation columns and copy SAMPLE_ID column into row names\n  output[[\"inputfile\"]] <- output[[\"inputfile\"]][-seq_along(aggregate.by)]\n  rownames(output[[\"inputfile\"]]) <- output[[\"inputfile\"]][[\"SAMPLE_ID\"]]\n\n  # Parse MultiQC FastQC output table ##########################################\n\n  # FILE FORMAT\n  # 'Filename' column: (base) FASTQ filename.\n  # 'Sample' column: (base) FASTQ filename, without \".fastq.gz\" extension.\n  # The remaining columns have the following types:\n  # 'pass', 'fail', or 'warn':\n  #   adapter_content, sequence_duplication_levels, per_base_sequence_quality,\n  #   sequence_length_distribution, basic_statistics, per_sequence_gc_content,\n  #   per_base_n_content, per_base_sequence_content, overrepresented_sequences,\n  #   per_tile_sequence_quality, per_sequence_quality_scores\n  # Percentages [0..100]:\n  #   %GC, total_deduplicated_percentage\n  # Floating point values:\n  #   avg_sequence_length\n  # Integer values (represented as floating-point with trailing .0):\n  #   Sequences flagged as poor quality, Total Sequences\n  # Range of integers (mm-nn):\n  #   Sequence length\n  # Text:\n  #   Encoding, File type\n\n  # Read file, placing \"Sample\" column in row names\n  output[[\"multiqcfastqc\"]] <- read.wsv(\n    \"${multiqcfastqc_file}\", sep=\"\\\\t\", row.names=1\n  )\n\n  # Initialize a data frame with FASTQ filenames in the row names\n  aggregate.by <- data.frame(row.names=output[[\"multiqcfastqc\"]][[\"Filename\"]])\n  # Extract the read ID (R1 or R2) from FASTQ filenames, and use filenames\n  # and read IDs to look up the sample IDs from input table\n  aggregate.by[[\"sample\"]] <- NA_character_\n  aggregate.by[[\"read\"]] <- sub(\n    \".+_(R[12]).+\", \"\\\\\\\\1\", rownames(aggregate.by)\n  )\n\n  for (read in ${params.paired_end ? 'c(\"R1\", \"R2\")' : 'c(\"R1\")'}) {\n    i <- which(aggregate.by[[\"read\"]] == read)\n    aggregate.by[[\"sample\"]][i] <- output[[\"inputfile\"]][[\"SAMPLE_ID\"]][\n      match(rownames(aggregate.by)[i], basename(output[[\"inputfile\"]][[read]]))\n    ]\n  }\n  # Collapse the MultiQC results first by sample ID, then by read\n  output[[\"multiqcfastqc\"]] <- aggregate(\n    output[[\"multiqcfastqc\"]], by=aggregate.by, FUN=c, simplify=FALSE\n  )\n\n  # Simplify columns with multiple sets of FASTQ files\n  # using an appropriate function\n  columns.to.simplify <- list(\n    sum = c(\"Sequences flagged as poor quality\"),\n    mean = c(\"avg_sequence_length\", \"%GC\", \"total_deduplicated_percentage\")\n  )\n  for (f in names(columns.to.simplify)) {\n    for (j in columns.to.simplify[[f]]) {\n      output[[\"multiqcfastqc\"]][[j]] <- sapply(\n        output[[\"multiqcfastqc\"]][[j]], f\n      )\n    }\n  }\n  # Aggregate data frame again by sample ID\n  # (so R1 and R2 metrics are on the same row)\n  output[[\"multiqcfastqc\"]] <- aggregate(\n    output[[\"multiqcfastqc\"]][-(1:2)],\n    by=output[[\"multiqcfastqc\"]][\"sample\"], FUN=c, simplify=FALSE\n  )\n  # Move the sample IDs into the row names of the data frame\n  rownames(output[[\"multiqcfastqc\"]]) <- output[[\"multiqcfastqc\"]][[\"sample\"]]\n  output[[\"multiqcfastqc\"]][[\"sample\"]] <- NULL\n  # Add a prefix to the column names\n  colnames(output[[\"multiqcfastqc\"]]) <- paste(\n    \"FastQC\", colnames(output[[\"multiqcfastqc\"]])\n  )\n\n  # Parse tables of TIN metrics from RSeQC #####################################\n\n  # FILE FORMAT\n  # 'Bam_file' column: (base) BAM filename.\n  # The remaining columns have the following types:\n  # Floating point values:\n  #   TIN(mean), TIN(median), TIN(stdev)\n\n  tinfiles <- c(\n    '${rseqc_tin_files.join(\"',\\n'\")}'\n  )\n  output[[\"tinfiles\"]] <- c(\n    # Get tab-delimited column names from first line of first file\n    readLines(tinfiles[1], n=1),\n    # Read tab-delimited contents of second lines of all files\n    sapply(tinfiles, scan, what=\"\", n=1, sep=\"\\\\n\", skip=1, quiet=TRUE)\n  )\n  # Parse the character vector into a data frame\n  output[[\"tinfiles\"]] <- read.wsv(\n    textConnection(output[[\"tinfiles\"]]), row.names=1\n  )\n  # Add a prefix to the column names\n  colnames(output[[\"tinfiles\"]]) <- paste(\n    \"RSeQC\", colnames(output[[\"tinfiles\"]])\n  )\n\n  # Parse remaining MultiQC output files #######################################\n\n  # Read tables, placing first column (\"Sample\") in row names\n  # and adding prefix to column names\n  multiqc.rseqc.filenames <- c(\n    '${multiqc_rseqc_files.join(\"',\\n'\")}'\n  )\n  for (filename in multiqc.rseqc.filenames) {\n    output[[basename(filename)]] <- read.wsv(filename, row.names=1)\n    colnames(output[[basename(filename)]]) <- paste(\n      \"RSeQC\", colnames(output[[basename(filename)]])\n    )\n  }\n  output[[\"starfile\"]] <- read.wsv(\"${multiqc_star_file}\", row.names=1)\n  colnames(output[[\"starfile\"]]) <- paste(\n    \"STAR\", colnames(output[[\"starfile\"]])\n  )\n\n  # Reformat each data frame ###################################################\n\n  for (i in which(names(output) != \"inputfile\")) {\n    # Reorder rows of each data frame to match order of rows in input file\n    # Note: a while loop is used because pmatch() returns NA where there are\n    #       multiple matches, e.g.,\n    #         pmatch(\"Sample_1\", c(\"Sample_1.bam\", \"Sample_10.bam\")) == NA\n    #       Each iteration excludes any values that were previously matched.\n    j <- rep(NA_integer_, n.samples)\n    k <- seq(n.samples)\n    while (any(is.na(j))) {\n      j[is.na(j)] <- pmatch(\n        rownames(output[[\"inputfile\"]])[is.na(j)], rownames(output[[i]])[k]\n      )\n      k[j[!is.na(j)]] <- NA_integer_\n    }\n    output[[i]] <- output[[i]][j, , drop=FALSE]\n    # 1. Replace \"%\" with \"percent\", e.g., \"%GC\" -> \"percent GC\"\n    # 2. Replace whitespace/punctuation in column names with underscores\n    # 3. Remove trailing underscores from column names\n    colnames(output[[i]]) <- gsub(\"% ?\", \"percent \", colnames(output[[i]]))\n    colnames(output[[i]]) <- gsub(\n      \"_\\$\", \"\", gsub(\"[' \\\\\"\\\\\\\\(\\\\\\\\)\\\\\\\\-]\", \"_\", colnames(output[[i]]))\n    )\n  }\n\n  # Combine output into a single data frame ####################################\n\n  # Initialize with sample names from input file, then add each table in turn\n  SE.colData <- data.frame(row.names=rownames(output[[\"inputfile\"]]))\n  for (i in seq_along(output)) {\n    SE.colData <- cbind(SE.colData, output[[i]])\n  }\n\n  # Open connection to Biomart #################################################\n\n  # Determine from parameters which Biomart dataset and hostname should be used\n  biomart <- list(\n    database = \"ENSEMBL_MART_ENSEMBL\",\n    dataset = paste(\n      tolower(\n        sub(\"^(.)[^ ]+ (.+)\\$\", \"\\\\\\\\1\\\\\\\\2\", \"${params.genome.species}\")\n      ),\n      \"gene_ensembl\", sep=\"_\"\n    ),\n    host = with(\n      listEnsemblArchives(), url[version == \"${params.genome.ensembl}\"]\n    )\n  )\n  # Note: this connection is done in a repeat loop because it doesn't always\n  #       work on the first try; a maximum number of attempts is included to\n  #       keep it from endlessly looping if Biomart is down\n  cat(\n    \"Opening connection to Biomart\",\n    with(\n      biomart,\n      sprintf(\n        \"(database %s, dataset %s, host %s, Ensembl version %s).\\\\n\",\n        database, dataset, host, \"${params.genome.ensembl}\"\n      )\n    )\n  )\n  max.attempts <- 10\n  attempt <- 1\n  repeat {\n    cat(sprintf(\"Connection attempt #%d of %d...\", attempt, max.attempts))\n    mart <- try(\n      with(biomart, useMart(biomart=database, dataset=dataset, host=host)),\n      silent=TRUE\n    )\n    if (inherits(mart, \"Mart\")) {\n      cat(\"successful.\\\\n\")\n      break\n    }\n    cat(\"\\\\n\")\n    if (attempt == max.attempts) {\n      stop(\"Could not connect to Biomart after \", max.attempts, \" attempts\")\n    }\n    attempt <- attempt + 1\n  }\n\n  # Create SummarizedExperiment objects ########################################\n\n  # Copy Nextflow variables into R variables\n  rsem.filenames <- list(\n    gene=c(\n      '${rsem_genes_files.join(\"',\\n'\")}'\n    ),\n    isoform=c(\n      '${rsem_isoforms_files.join(\"',\\n'\")}'\n    )\n  )\n  biomart.attributes <- list(\n    gene = c(\n      '${params.createSE.biomart_attributes.gene.join(\"',\\n'\")}'\n    ),\n    isoform = c(\n      '${params.createSE.biomart_attributes.isoform.join(\"',\\n'\")}'\n    )\n  )\n  rds.files <- c(gene='${rds_files.gene}', isoform='${rds_files.isoform}')\n\n  # RSEM output columns related to gene/isoform-level annotation\n  rsem.annotation.columns <- c(\n    \"gene_id\", \"transcript_id(s)\", \"length\", \"effective_length\"\n  )\n  # Names of RSEM output columns holding gene/isoform IDs\n  rsem.id.columns <- c(gene=\"gene_id\", isoform=\"transcript_id\")\n\n  # Create a TxDb object from the GTF file; this will be used to populate the\n  # rowRanges of the SummarizedExperiment objects\n  txdb <- makeTxDbFromGFF(\"${ensembl_gtf_file}\")\n\n  for (type in c(\"gene\", \"isoform\")) {\n    # Reorder RSEM output files to match order of sample annotation\n    filename.suffix <- paste0(\"\\\\\\\\.\", type, \"s\", \"\\\\\\\\.results\\$\")\n    rsem.filenames[[type]] <- rsem.filenames[[type]][\n      match(\n        rownames(SE.colData),\n        sub(filename.suffix, \"\", basename(rsem.filenames[[type]]))\n      )\n    ]\n    # Read the RSEM output files into a list of matrices\n    SE.assays <- list()\n    n <- length(rsem.filenames[[type]])\n    for (i in seq(n)) {\n      cat(\"Processing\", type, \"level RSEM output file\", i, \"of\", n, \"\\\\r\")\n      rsem.output <- read.wsv(\n        rsem.filenames[[type]][i], row.names=rsem.id.columns[type]\n      )\n      # Copy each RSEM column (minus any annotation columns) into assay list\n      for (j in setdiff(colnames(rsem.output), rsem.annotation.columns)) {\n        SE.assays[[j]] <- cbind(SE.assays[[j]], rsem.output[[j]])\n      }\n    }\n    cat(\"\\\\n\")\n    # Name the rows and columns of each matrix\n    SE.assays <- lapply(SE.assays, `rownames<-`, rownames(rsem.output))\n    SE.assays <- lapply(SE.assays, `colnames<-`, rownames(SE.colData))\n\n    # Retrieve annotation from Biomart\n    BM <- getBM(attributes=biomart.attributes[[type]], mart=mart)\n    # Collapse by first column (either gene or transcript ID)\n    BM <- aggregate(BM[-1], BM[1], unique)\n    # Reorder to match order of features from RSEM output\n    BM <- BM[match(rownames(SE.assays[[1]]), BM[[1]]), ]\n    # Combine Biomart annotation with data from TxDb object\n    SE.rowRanges <- switch(type, gene=genes(txdb), isoform=transcripts(txdb))\n    mcols(SE.rowRanges) <- c(mcols(SE.rowRanges), BM[-1])\n\n    # Assemble variables into a SummarizedExperiment and write to RDS file\n    dataset <- SummarizedExperiment(\n      assays=SE.assays, colData=DataFrame(SE.colData), rowRanges=SE.rowRanges\n    )\n    saveRDS(dataset, rds.files[[type]])\n  }\n  \"\"\"",
        "nb_lignes_script": 315,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "runMultiQCFastq_to_createSE",
            "runRSeQCtin_to_createSE",
            "runMultiQCSampleRSeQC_to_createSE",
            "runMultiQCSampleSTAR_to_createSE",
            "runRSEMcalculateExpressionGenes_to_createSE",
            "runRSEMcalculateExpressionIsoforms_to_createSE",
            "generateGTF_to_createSE"
        ],
        "nb_inputs": 7,
        "outputs": [
            "runCreateSEOutput"
        ],
        "nb_outputs": 1,
        "name_workflow": "compbiomed__RNA_Seq",
        "directive": [
            "tag \"Combining results into SummarizedExperiment objects\"",
            "publishDir \"${params.output_dir}/Output/Expression\"",
            "module params.modules.R"
        ],
        "when": "",
        "stub": ""
    }
}