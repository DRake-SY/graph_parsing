{
    "unicyclerShortReadsOnly": {
        "name_process": "unicyclerShortReadsOnly",
        "string_process": " process unicyclerShortReadsOnly {\n        container \"quay.io/biocontainers/unicycler:0.4.7--py37hdbcaa40_1\"\n        cpus 16\n        memory \"128 GB\"\n        errorStrategy \"retry\"\n        publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\"\n\n        input:\n        val threads from 16\n        val read_type from \"short_reads\"\n        val min_fasta_length from params.min_fasta_length\n        set val(genome_name), file(short_R1), file(short_R2) from illumina_ch\n        each mode from unicycler_modes\n\n        output:\n        file \"${genome_name}/${genome_name}.${read_type}.${mode}.gfa\"\n        file \"${genome_name}/${genome_name}.${read_type}.${mode}.log\"\n        set val(\"${genome_name}\"), file(\"${genome_name}/${genome_name}.${read_type}.${mode}.fasta.gz\"), val(\"${mode}\"), val(\"short_reads\") into contigsShortReadsOnly\n        \n\n        afterScript \"rm -rf *\"\n\n    \"\"\"\n    set -e\n\n    mkdir ${genome_name}\n\n    unicycler \\\n        -1 ${short_R1} \\\n        -2 ${short_R2} \\\n        -o ${genome_name} \\\n        --min_fasta_length ${min_fasta_length} \\\n        --keep 0 \\\n        --mode ${mode} \\\n        -t ${threads}\n\n    mv ${genome_name}/assembly.gfa ${genome_name}/${genome_name}.${read_type}.${mode}.gfa\n    mv ${genome_name}/assembly.fasta ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    mv ${genome_name}/unicycler.log ${genome_name}/${genome_name}.${read_type}.${mode}.log\n    gzip ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    \"\"\"\n    }",
        "nb_lignes_process": 40,
        "string_script": "\"\"\"\n    set -e\n\n    mkdir ${genome_name}\n\n    unicycler \\\n        -1 ${short_R1} \\\n        -2 ${short_R2} \\\n        -o ${genome_name} \\\n        --min_fasta_length ${min_fasta_length} \\\n        --keep 0 \\\n        --mode ${mode} \\\n        -t ${threads}\n\n    mv ${genome_name}/assembly.gfa ${genome_name}/${genome_name}.${read_type}.${mode}.gfa\n    mv ${genome_name}/assembly.fasta ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    mv ${genome_name}/unicycler.log ${genome_name}/${genome_name}.${read_type}.${mode}.log\n    gzip ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "Unicycler"
        ],
        "tools_url": [
            "https://bio.tools/unicycler"
        ],
        "tools_dico": [
            {
                "name": "Unicycler",
                "uri": "https://bio.tools/unicycler",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3301",
                            "term": "Microbiology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0925",
                                "term": "Sequence assembly"
                            }
                        ]
                    }
                ],
                "description": "A tool for assembling bacterial genomes from a combination of short (2nd generation) and long (3rd generation) sequencing reads.",
                "homepage": "https://github.com/rrwick/Unicycler"
            }
        ],
        "inputs": [
            "16",
            "\"short_reads\"",
            "params",
            "illumina_ch",
            "unicycler_modes"
        ],
        "nb_inputs": 5,
        "outputs": [
            "contigsShortReadsOnly"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__unicycler-nf",
        "directive": [
            "container \"quay.io/biocontainers/unicycler:0.4.7--py37hdbcaa40_1\"",
            "cpus 16",
            "memory \"128 GB\"",
            "errorStrategy \"retry\"",
            "publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\""
        ],
        "when": "",
        "stub": ""
    },
    "unicyclerLongReadsOnly": {
        "name_process": "unicyclerLongReadsOnly",
        "string_process": " process unicyclerLongReadsOnly {\n        container \"quay.io/biocontainers/unicycler:0.4.7--py37hdbcaa40_1\"\n        cpus 16\n        memory \"128 GB\"\n        errorStrategy \"retry\"\n        publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\"\n\n        input:\n        val threads from 16\n        val read_type from \"long_reads\"\n        val min_fasta_length from params.min_fasta_length\n        set val(genome_name), file(long_reads) from long_read_ch\n        each mode from unicycler_modes\n\n        output:\n        file \"${genome_name}/${genome_name}.${read_type}.${mode}.gfa\"\n        set val(\"${genome_name}\"), file(\"${genome_name}/${genome_name}.${read_type}.${mode}.fasta.gz\"), val(\"${mode}\"), val(\"long_reads\") into contigsLongReadsOnly\n        file \"${genome_name}/${genome_name}.${read_type}.${mode}.log\"\n\n        afterScript \"rm -rf *\"\n\n    \"\"\"\n    set -e\n\n    mkdir ${genome_name}\n\n    unicycler \\\n        -l ${long_reads} \\\n        -o ${genome_name} \\\n        --min_fasta_length ${min_fasta_length} \\\n        --keep 0 \\\n        --mode ${mode} \\\n        -t ${threads}\n\n    mv ${genome_name}/assembly.gfa ${genome_name}/${genome_name}.${read_type}.${mode}.gfa\n    mv ${genome_name}/assembly.fasta ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    mv ${genome_name}/unicycler.log ${genome_name}/${genome_name}.${read_type}.${mode}.log\n    gzip ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    \"\"\"\n    }",
        "nb_lignes_process": 38,
        "string_script": "\"\"\"\n    set -e\n\n    mkdir ${genome_name}\n\n    unicycler \\\n        -l ${long_reads} \\\n        -o ${genome_name} \\\n        --min_fasta_length ${min_fasta_length} \\\n        --keep 0 \\\n        --mode ${mode} \\\n        -t ${threads}\n\n    mv ${genome_name}/assembly.gfa ${genome_name}/${genome_name}.${read_type}.${mode}.gfa\n    mv ${genome_name}/assembly.fasta ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    mv ${genome_name}/unicycler.log ${genome_name}/${genome_name}.${read_type}.${mode}.log\n    gzip ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "Unicycler"
        ],
        "tools_url": [
            "https://bio.tools/unicycler"
        ],
        "tools_dico": [
            {
                "name": "Unicycler",
                "uri": "https://bio.tools/unicycler",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3301",
                            "term": "Microbiology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0925",
                                "term": "Sequence assembly"
                            }
                        ]
                    }
                ],
                "description": "A tool for assembling bacterial genomes from a combination of short (2nd generation) and long (3rd generation) sequencing reads.",
                "homepage": "https://github.com/rrwick/Unicycler"
            }
        ],
        "inputs": [
            "16",
            "\"long_reads\"",
            "params",
            "long_read_ch",
            "unicycler_modes"
        ],
        "nb_inputs": 5,
        "outputs": [
            "contigsLongReadsOnly"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__unicycler-nf",
        "directive": [
            "container \"quay.io/biocontainers/unicycler:0.4.7--py37hdbcaa40_1\"",
            "cpus 16",
            "memory \"128 GB\"",
            "errorStrategy \"retry\"",
            "publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\""
        ],
        "when": "",
        "stub": ""
    },
    "unicyclerHybrid": {
        "name_process": "unicyclerHybrid",
        "string_process": " process unicyclerHybrid {\n            container \"quay.io/biocontainers/unicycler:0.4.7--py37hdbcaa40_1\"\n            cpus 16\n            memory \"128 GB\"\n            errorStrategy \"retry\"\n            publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\"\n\n            input:\n            val threads from 16\n            val read_type from \"hybrid\"\n            val min_fasta_length from params.min_fasta_length\n            set val(genome_name), file(long_reads), file(short_R1), file(short_R2) from hybrid_ch\n            each mode from unicycler_modes\n\n            output:\n            file \"${genome_name}/${genome_name}.${read_type}.${mode}.gfa\"\n            set val(\"${genome_name}\"), file(\"${genome_name}/${genome_name}.${read_type}.${mode}.fasta.gz\"), val(\"${mode}\"), val(\"hybrid\") into contigsHybrid\n            file \"${genome_name}/${genome_name}.${read_type}.${mode}.log\"\n\n            afterScript \"rm -rf *\"\n\n        \"\"\"\n        set -e\n\n        mkdir ${genome_name}\n\n        unicycler \\\n            -1 ${short_R1} \\\n            -2 ${short_R2} \\\n            -l ${long_reads} \\\n            -o ${genome_name} \\\n            --min_fasta_length ${min_fasta_length} \\\n            --keep 0 \\\n            --mode ${mode} \\\n            -t ${threads}\n\n        mv ${genome_name}/assembly.gfa ${genome_name}/${genome_name}.${read_type}.${mode}.gfa\n        mv ${genome_name}/assembly.fasta ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n        mv ${genome_name}/unicycler.log ${genome_name}/${genome_name}.${read_type}.${mode}.log\n        gzip ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n        \"\"\"\n        }",
        "nb_lignes_process": 40,
        "string_script": "\"\"\"\n        set -e\n\n        mkdir ${genome_name}\n\n        unicycler \\\n            -1 ${short_R1} \\\n            -2 ${short_R2} \\\n            -l ${long_reads} \\\n            -o ${genome_name} \\\n            --min_fasta_length ${min_fasta_length} \\\n            --keep 0 \\\n            --mode ${mode} \\\n            -t ${threads}\n\n        mv ${genome_name}/assembly.gfa ${genome_name}/${genome_name}.${read_type}.${mode}.gfa\n        mv ${genome_name}/assembly.fasta ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n        mv ${genome_name}/unicycler.log ${genome_name}/${genome_name}.${read_type}.${mode}.log\n        gzip ${genome_name}/${genome_name}.${read_type}.${mode}.fasta\n        \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "Unicycler"
        ],
        "tools_url": [
            "https://bio.tools/unicycler"
        ],
        "tools_dico": [
            {
                "name": "Unicycler",
                "uri": "https://bio.tools/unicycler",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3301",
                            "term": "Microbiology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0925",
                                "term": "Sequence assembly"
                            }
                        ]
                    }
                ],
                "description": "A tool for assembling bacterial genomes from a combination of short (2nd generation) and long (3rd generation) sequencing reads.",
                "homepage": "https://github.com/rrwick/Unicycler"
            }
        ],
        "inputs": [
            "16",
            "\"hybrid\"",
            "params",
            "hybrid_ch",
            "unicycler_modes"
        ],
        "nb_inputs": 5,
        "outputs": [
            "contigsHybrid"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__unicycler-nf",
        "directive": [
            "container \"quay.io/biocontainers/unicycler:0.4.7--py37hdbcaa40_1\"",
            "cpus 16",
            "memory \"128 GB\"",
            "errorStrategy \"retry\"",
            "publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\""
        ],
        "when": "",
        "stub": ""
    },
    "summarizeAssemblies": {
        "name_process": "summarizeAssemblies",
        "string_process": "\nprocess summarizeAssemblies {\n    container \"quay.io/fhcrc-microbiome/python-pandas:latest\"\n    cpus 1\n    memory \"4 GB\"\n    errorStrategy \"retry\"\n    publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\"\n\n    input:\n    set val(genome_name), file(contigs_fasta_gz), val(mode), val(read_type) from contigsForSummary\n\n    output:\n    file \"${genome_name}.${read_type}.${mode}.json\" into assembly_summaries_ch\n\n    afterScript \"rm -rf *\"\n\n\"\"\"\n#!/usr/bin/env python3\nimport gzip\nimport json\nimport pandas as pd\n\n# Count the size, depth, and circularity of each contig\ncontig_info = []\ncontig_lengths = dict()\nlength_buffer = 0\ncontig_name = None\nfor l in gzip.open(\"${contigs_fasta_gz}\", \"rt\"):\n    if l.startswith(\">\"):\n        if contig_name is not None:\n            contig_lengths[contig_name] = length_buffer\n            length_buffer = 0\n        if \" \" in l:\n            contig_name, contig_dict = l.lstrip(\">\").rstrip(\"\\\\n\").split(\" \", 1)\n            contig_dict = dict([\n                (i.split(\"=\")[0], i.split(\"=\")[1])\n                for i in contig_dict.split(\" \")\n            ])\n            contig_dict[\"name\"] = contig_name\n            contig_dict[\"circular\"] = contig_dict.get(\"circular\", \"false\")\n            contig_info.append(contig_dict)\n        else:\n            contig_name = l.lstrip(\">\").rstrip(\"\\\\n\")\n    else:\n        length_buffer += len(l.rstrip(\"\\\\n\"))\n# Add the final contig\ncontig_lengths[contig_name] = length_buffer\n\n# Make into a DataFrame\nif len(contig_info) > 0:\n    contig_info = pd.DataFrame(contig_info)\n    contig_info[\"length\"] = contig_info[\"length\"].apply(int)\n    contig_info[\"depth\"] = contig_info[\"depth\"].apply(lambda s: float(s.rstrip(\"x\")))\n    contig_info[\"circular\"] = contig_info[\"circular\"].fillna(\"false\") == \"true\"\nelse:\n    contig_info = pd.DataFrame(dict([(\"length\", contig_lengths)])).reset_index()\n    contig_info[\"depth\"] = 1\n    contig_info[\"circular\"] = False\ncontig_info.sort_values(by=\"length\", ascending=False, inplace=True)\n\n# Calculate N50\nrunning_total = 0\nn50 = None\nfor nbases in contig_info[\"length\"].values:\n    running_total += nbases\n    if running_total >= contig_info[\"length\"].sum() / 2.:\n        n50 = int(nbases)\n        break\nassert n50 is not None\n\n# Summarize these contigs\noutput = {\n    \"mode\": \"${mode}\",\n    \"read_type\": \"${read_type}\",\n    \"genome_name\": \"${genome_name}\",\n    \"num_contigs\": int(contig_info.shape[0]),\n    \"num_circular_contigs\": int(contig_info[\"circular\"].sum()),\n    \"circular_contig_lengths\": \", \".join(contig_info.query(\"circular\")[\"length\"].apply(str).tolist()),\n    \"linear_contig_lengths\": \", \".join(contig_info.query(\"circular == False\")[\"length\"].apply(str).tolist()),\n    \"num_bases\": int(contig_info[\"length\"].sum()),\n    \"longest_contig\": int(contig_info[\"length\"].max()),\n    \"num_over_1Mb\": int((contig_info[\"length\"] >= 1000000).sum()),\n    \"num_100kb_to_1Mb\": int(((contig_info[\"length\"] < 1000000) & (contig_info[\"length\"] >= 100000)).sum()),\n    \"num_10kb_to_100kb\": int(((contig_info[\"length\"] < 100000) & (contig_info[\"length\"] >= 10000)).sum()),\n    \"num_1kb_to_10kb\":    int(((contig_info[\"length\"] < 10000) & (contig_info[\"length\"] >= 1000)).sum()),\n    \"num_under_1kb\":        int((contig_info[\"length\"] < 1000).sum()),\n    \"N50\": n50,\n}\n\njson.dump(output, open(\"${genome_name}.${read_type}.${mode}.json\", \"wt\"), indent=4)\n\n\"\"\"\n}",
        "nb_lignes_process": 91,
        "string_script": "\"\"\"\n#!/usr/bin/env python3\nimport gzip\nimport json\nimport pandas as pd\n\n# Count the size, depth, and circularity of each contig\ncontig_info = []\ncontig_lengths = dict()\nlength_buffer = 0\ncontig_name = None\nfor l in gzip.open(\"${contigs_fasta_gz}\", \"rt\"):\n    if l.startswith(\">\"):\n        if contig_name is not None:\n            contig_lengths[contig_name] = length_buffer\n            length_buffer = 0\n        if \" \" in l:\n            contig_name, contig_dict = l.lstrip(\">\").rstrip(\"\\\\n\").split(\" \", 1)\n            contig_dict = dict([\n                (i.split(\"=\")[0], i.split(\"=\")[1])\n                for i in contig_dict.split(\" \")\n            ])\n            contig_dict[\"name\"] = contig_name\n            contig_dict[\"circular\"] = contig_dict.get(\"circular\", \"false\")\n            contig_info.append(contig_dict)\n        else:\n            contig_name = l.lstrip(\">\").rstrip(\"\\\\n\")\n    else:\n        length_buffer += len(l.rstrip(\"\\\\n\"))\n# Add the final contig\ncontig_lengths[contig_name] = length_buffer\n\n# Make into a DataFrame\nif len(contig_info) > 0:\n    contig_info = pd.DataFrame(contig_info)\n    contig_info[\"length\"] = contig_info[\"length\"].apply(int)\n    contig_info[\"depth\"] = contig_info[\"depth\"].apply(lambda s: float(s.rstrip(\"x\")))\n    contig_info[\"circular\"] = contig_info[\"circular\"].fillna(\"false\") == \"true\"\nelse:\n    contig_info = pd.DataFrame(dict([(\"length\", contig_lengths)])).reset_index()\n    contig_info[\"depth\"] = 1\n    contig_info[\"circular\"] = False\ncontig_info.sort_values(by=\"length\", ascending=False, inplace=True)\n\n# Calculate N50\nrunning_total = 0\nn50 = None\nfor nbases in contig_info[\"length\"].values:\n    running_total += nbases\n    if running_total >= contig_info[\"length\"].sum() / 2.:\n        n50 = int(nbases)\n        break\nassert n50 is not None\n\n# Summarize these contigs\noutput = {\n    \"mode\": \"${mode}\",\n    \"read_type\": \"${read_type}\",\n    \"genome_name\": \"${genome_name}\",\n    \"num_contigs\": int(contig_info.shape[0]),\n    \"num_circular_contigs\": int(contig_info[\"circular\"].sum()),\n    \"circular_contig_lengths\": \", \".join(contig_info.query(\"circular\")[\"length\"].apply(str).tolist()),\n    \"linear_contig_lengths\": \", \".join(contig_info.query(\"circular == False\")[\"length\"].apply(str).tolist()),\n    \"num_bases\": int(contig_info[\"length\"].sum()),\n    \"longest_contig\": int(contig_info[\"length\"].max()),\n    \"num_over_1Mb\": int((contig_info[\"length\"] >= 1000000).sum()),\n    \"num_100kb_to_1Mb\": int(((contig_info[\"length\"] < 1000000) & (contig_info[\"length\"] >= 100000)).sum()),\n    \"num_10kb_to_100kb\": int(((contig_info[\"length\"] < 100000) & (contig_info[\"length\"] >= 10000)).sum()),\n    \"num_1kb_to_10kb\":    int(((contig_info[\"length\"] < 10000) & (contig_info[\"length\"] >= 1000)).sum()),\n    \"num_under_1kb\":        int((contig_info[\"length\"] < 1000).sum()),\n    \"N50\": n50,\n}\n\njson.dump(output, open(\"${genome_name}.${read_type}.${mode}.json\", \"wt\"), indent=4)\n\n\"\"\"",
        "nb_lignes_script": 75,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigsForSummary"
        ],
        "nb_inputs": 1,
        "outputs": [
            "assembly_summaries_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__unicycler-nf",
        "directive": [
            "container \"quay.io/fhcrc-microbiome/python-pandas:latest\"",
            "cpus 1",
            "memory \"4 GB\"",
            "errorStrategy \"retry\"",
            "publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\""
        ],
        "when": "",
        "stub": ""
    },
    "prokkaAnnotate": {
        "name_process": "prokkaAnnotate",
        "string_process": " process prokkaAnnotate {\n        container 'ummidock/prokka:1.13.3-01'\n        cpus 16\n        memory \"120 GB\"\n        errorStrategy \"retry\"\n        publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\"\n\n        input:\n        set val(genome_name), file(contigs_fasta_gz), val(mode), val(read_type) from contigsForProkka\n        val threads from 16\n        \n        output:\n        file \"prokka/${genome_name}.${read_type}.${mode}.faa.gz\"\n        file \"prokka/${genome_name}.${read_type}.${mode}.gff.gz\"\n        file \"prokka/${genome_name}.${read_type}.${mode}.tsv.gz\"\n        \n        \"\"\"\n    #!/bin/bash\n    set -e;\n\n    # Decompress the assembly\n    gunzip -c ${contigs_fasta_gz} > ${contigs_fasta_gz.simpleName}.fasta\n\n    prokka \\\n        --outdir prokka/ \\\n        --prefix ${genome_name}.${read_type}.${mode} \\\n        --cpus ${threads} \\\n        --compliant \\\n        ${contigs_fasta_gz.simpleName}.fasta\n\n\n    gzip prokka/${genome_name}.${read_type}.${mode}.faa &&\n    gzip prokka/${genome_name}.${read_type}.${mode}.gff &&\n    gzip prokka/${genome_name}.${read_type}.${mode}.tsv\n        \"\"\"\n    }",
        "nb_lignes_process": 34,
        "string_script": "\"\"\"\n    #!/bin/bash\n    set -e;\n\n    # Decompress the assembly\n    gunzip -c ${contigs_fasta_gz} > ${contigs_fasta_gz.simpleName}.fasta\n\n    prokka \\\n        --outdir prokka/ \\\n        --prefix ${genome_name}.${read_type}.${mode} \\\n        --cpus ${threads} \\\n        --compliant \\\n        ${contigs_fasta_gz.simpleName}.fasta\n\n\n    gzip prokka/${genome_name}.${read_type}.${mode}.faa &&\n    gzip prokka/${genome_name}.${read_type}.${mode}.gff &&\n    gzip prokka/${genome_name}.${read_type}.${mode}.tsv\n        \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "Prokka"
        ],
        "tools_url": [
            "https://bio.tools/prokka"
        ],
        "tools_dico": [
            {
                "name": "Prokka",
                "uri": "https://bio.tools/prokka",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0781",
                            "term": "Virology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.",
                "homepage": "https://github.com/tseemann/prokka"
            }
        ],
        "inputs": [
            "contigsForProkka",
            "16"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__unicycler-nf",
        "directive": [
            "container 'ummidock/prokka:1.13.3-01'",
            "cpus 16",
            "memory \"120 GB\"",
            "errorStrategy \"retry\"",
            "publishDir \"${params.output_folder}/${genome_name}/${read_type}/${mode}/\""
        ],
        "when": "",
        "stub": ""
    },
    "summarizeAll": {
        "name_process": "summarizeAll",
        "string_process": "\nprocess summarizeAll {\n    container \"quay.io/fhcrc-microbiome/python-pandas:latest\"\n    cpus 1\n    memory \"4 GB\"\n    errorStrategy \"retry\"\n    publishDir \"${params.output_folder}/\"\n\n    input:\n    file all_summary_jsons from assembly_summaries_ch.collect()\n\n    output:\n    file \"assembly_summary_table.csv\"\n\n    afterScript \"rm -rf *\"\n\n\"\"\"\n#!/usr/bin/env python3\nimport gzip\nimport json\nimport pandas as pd\nimport os\n\nall_summary_jsons = \"${all_summary_jsons}\".split(\" \")\n\n# Make sure that the right columns exist\ncol_names = [\"genome_name\", \"read_type\", \"mode\", \"num_contigs\", \"num_bases\", \"longest_contig\"]\n\ndf = []\nfor fp in all_summary_jsons:\n    assert os.path.exists(fp), \"File not found in working directory (%s) -- try running again\" % (fp)\n\n    print(\"Reading in %s\" % (fp))\n    dat = json.load(open(fp, \"rt\"))\n    assert isinstance(dat, dict), \"%s is not the correct format\" % (fp)\n\n    for k in col_names:\n        assert k in dat, \"%s not found in summary (%s)\" % (k, fp)\n\n    df.append(dat)\n\nprint(\"Making a single summary table\")\ndf = pd.DataFrame(df).sort_values(by=[\"genome_name\", \"read_type\", \"mode\"])\n\ndf = df.reindex(columns=[\n    \"genome_name\",\n    \"read_type\",\n    \"mode\",\n    \"num_contigs\",\n    \"num_circular_contigs\",\n    \"num_bases\",\n    \"N50\",\n    \"circular_contig_lengths\",\n    \"linear_contig_lengths\",\n    \"longest_contig\",\n    \"num_over_1Mb\",\n    \"num_100kb_to_1Mb\",\n    \"num_10kb_to_100kb\",\n    \"num_1kb_to_10kb\",\n    \"num_under_1kb\",\n])\n\nprint(\"Writing out the summary table\")\ndf.to_csv(\"assembly_summary_table.csv\", index=None)\n\n\"\"\"\n}",
        "nb_lignes_process": 65,
        "string_script": "\"\"\"\n#!/usr/bin/env python3\nimport gzip\nimport json\nimport pandas as pd\nimport os\n\nall_summary_jsons = \"${all_summary_jsons}\".split(\" \")\n\n# Make sure that the right columns exist\ncol_names = [\"genome_name\", \"read_type\", \"mode\", \"num_contigs\", \"num_bases\", \"longest_contig\"]\n\ndf = []\nfor fp in all_summary_jsons:\n    assert os.path.exists(fp), \"File not found in working directory (%s) -- try running again\" % (fp)\n\n    print(\"Reading in %s\" % (fp))\n    dat = json.load(open(fp, \"rt\"))\n    assert isinstance(dat, dict), \"%s is not the correct format\" % (fp)\n\n    for k in col_names:\n        assert k in dat, \"%s not found in summary (%s)\" % (k, fp)\n\n    df.append(dat)\n\nprint(\"Making a single summary table\")\ndf = pd.DataFrame(df).sort_values(by=[\"genome_name\", \"read_type\", \"mode\"])\n\ndf = df.reindex(columns=[\n    \"genome_name\",\n    \"read_type\",\n    \"mode\",\n    \"num_contigs\",\n    \"num_circular_contigs\",\n    \"num_bases\",\n    \"N50\",\n    \"circular_contig_lengths\",\n    \"linear_contig_lengths\",\n    \"longest_contig\",\n    \"num_over_1Mb\",\n    \"num_100kb_to_1Mb\",\n    \"num_10kb_to_100kb\",\n    \"num_1kb_to_10kb\",\n    \"num_under_1kb\",\n])\n\nprint(\"Writing out the summary table\")\ndf.to_csv(\"assembly_summary_table.csv\", index=None)\n\n\"\"\"",
        "nb_lignes_script": 49,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "assembly_summaries_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__unicycler-nf",
        "directive": [
            "container \"quay.io/fhcrc-microbiome/python-pandas:latest\"",
            "cpus 1",
            "memory \"4 GB\"",
            "errorStrategy \"retry\"",
            "publishDir \"${params.output_folder}/\""
        ],
        "when": "",
        "stub": ""
    }
}