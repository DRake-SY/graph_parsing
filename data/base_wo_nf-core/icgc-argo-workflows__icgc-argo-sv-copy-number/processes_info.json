{
    "demoCopyFile": {
        "name_process": "demoCopyFile",
        "string_process": "\nprocess demoCopyFile {\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  input:\n    path input_file\n\n  output:\n    path \"output_dir/*\", emit: output_file\n\n  script:\n    \"\"\"\n    mkdir output_dir\n    cp ${input_file} output_dir/\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    mkdir output_dir\n    cp ${input_file} output_dir/\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_file"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir"
        ],
        "when": "",
        "stub": ""
    },
    "manta": {
        "name_process": "manta",
        "string_process": "\nprocess manta {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path normalBam\n    path tumorBam\n    path referenceFasta\n    path normalBai\n    path tumorBai\n    path referenceFai\n\n  output:                                  \n    path \"output_dir\", emit: output_file\n\n  script:\n                                                  \n\n    \"\"\"\n\n    mkdir -p output_dir\n\n    echo \"RUNNING VARIANT CALLER\"\n\n    configManta.py \\\n    --normalBam ${normalBam} \\\n    --tumorBam ${tumorBam} \\\n    --referenceFasta ${referenceFasta} \\\n    --runDir output_dir \n    \n    output_dir/runWorkflow.py --memGb ${params.mem} \n    \n    \"\"\"\n\n\n}",
        "nb_lignes_process": 38,
        "string_script": "    \"\"\"\n\n    mkdir -p output_dir\n\n    echo \"RUNNING VARIANT CALLER\"\n\n    configManta.py \\\n    --normalBam ${normalBam} \\\n    --tumorBam ${tumorBam} \\\n    --referenceFasta ${referenceFasta} \\\n    --runDir output_dir \n    \n    output_dir/runWorkflow.py --memGb ${params.mem} \n    \n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "normalBam",
            "tumorBam",
            "referenceFasta",
            "normalBai",
            "tumorBai",
            "referenceFai"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "seqzPreprocess": {
        "name_process": "seqzPreprocess",
        "string_process": "\nprocess seqzPreprocess {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path tumor_bam\n    path tumour_bai\n    path normal_bam\n    path normal_bai\n    path fasta\n    path fasta_fai\n    path gcwiggle\n    each chrom\n\n  output:                                  \n    path \"${params.output_pattern}\", emit: seqzperchromosome\n  \n  shell:\n                                                \n  '''\n  sequenza-utils bam2seqz --chromosome !{chrom} -n !{normal_bam} -t !{tumor_bam} --fasta !{fasta} -gc !{gcwiggle} -o \"!{chrom}.seqz.gz\"\n  '''\n\n\n}",
        "nb_lignes_process": 27,
        "string_script": "  '''\n  sequenza-utils bam2seqz --chromosome !{chrom} -n !{normal_bam} -t !{tumor_bam} --fasta !{fasta} -gc !{gcwiggle} -o \"!{chrom}.seqz.gz\"\n  '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tumor_bam",
            "tumour_bai",
            "normal_bam",
            "normal_bai",
            "fasta",
            "fasta_fai",
            "gcwiggle",
            "chrom"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "file_smart_diff": {
        "name_process": "file_smart_diff",
        "string_process": "\nprocess file_smart_diff {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n\n  input:\n    path output_file\n    path expected_file\n\n  output:\n    stdout()\n\n  script:\n    \"\"\"\n    #For the comparison of VCFs files produced by manta, we need to remove several fields of the header. \n    #For simplicity reasons, the following test will compare one of the main outputs of manta (somaticSV.vcf) and will not consider the header at all. \n    #Further versions will also include other output files and specific header tags.\n\n    zcat ${output_file}/results/variants/somaticSV.vcf.gz| grep -v \"#\" > normalized_output\n    zcat ${expected_file} | grep -v \"#\" > normalized_expected\n\n    diff normalized_output normalized_expected \\\n      && ( echo \"Test PASSED\" && exit 0 ) || ( echo \"Test FAILED, output file mismatch.\" && exit 1 )\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    #For the comparison of VCFs files produced by manta, we need to remove several fields of the header. \n    #For simplicity reasons, the following test will compare one of the main outputs of manta (somaticSV.vcf) and will not consider the header at all. \n    #Further versions will also include other output files and specific header tags.\n\n    zcat ${output_file}/results/variants/somaticSV.vcf.gz| grep -v \"#\" > normalized_output\n    zcat ${expected_file} | grep -v \"#\" > normalized_expected\n\n    diff normalized_output normalized_expected \\\n      && ( echo \"Test PASSED\" && exit 0 ) || ( echo \"Test FAILED, output file mismatch.\" && exit 1 )\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "RDiff"
        ],
        "tools_url": [
            "https://bio.tools/rdiff"
        ],
        "tools_dico": [
            {
                "name": "RDiff",
                "uri": "https://bio.tools/rdiff",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3320",
                            "term": "RNA splicing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3320",
                            "term": "Alternative splicing"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "rDiff is an open source tool for accurate detection of differential RNA processing from RNA-Seq data. It implements two statistical tests to detect changes of the RNA processing between two samples. rDiff.parametric is a powerful test, which can be applied for well annotated organisms to detect changes in the relative abundance of isoforms. rDiff.nonparametric is an alternative when the annotation is incomplete or missing.",
                "homepage": "http://bioweb.me/rdiff"
            }
        ],
        "inputs": [
            "output_file",
            "expected_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\""
        ],
        "when": "",
        "stub": ""
    },
    "snpPileup": {
        "name_process": "snpPileup",
        "string_process": "\nprocess snpPileup {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path tumor\n    path normal\n    path dbsnp\n    path ref\n    path ref_idx\n\n  output:                                  \n    path \"${params.output_pattern}\", emit: output_file\n\n  shell:\n    '''\n    main.sh -t !{tumor} -n !{normal} -g !{ref} -s !{dbsnp} -P !{params.P} -d !{params.d} -q !{params.q} -Q !{params.Q} -r !{params.r} -o !{tumor}.bc.gz\n    '''\n}",
        "nb_lignes_process": 21,
        "string_script": "    '''\n    main.sh -t !{tumor} -n !{normal} -g !{ref} -s !{dbsnp} -P !{params.P} -d !{params.d} -q !{params.q} -Q !{params.Q} -r !{params.r} -o !{tumor}.bc.gz\n    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tumor",
            "normal",
            "dbsnp",
            "ref",
            "ref_idx"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "facets": {
        "name_process": "facets",
        "string_process": "\nprocess facets {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path pileup\n\n\n  output:\n    path \"*.tgz\", emit: facets_results\n\n\n  shell:\n    '''\n        #run facets\n        facetsRun.R --seed !{params.seed} --minNDepth !{params.minNDepth} --maxNDepth !{params.maxNDepth} --snp_nbhd !{params.snp_nbhd} --minGC !{params.minGC} --maxGC !{params.maxGC} --cval !{params.cval} --pre_cval !{params.pre_cval} --genome !{params.genome} --min_nhet !{params.min_nhet} --outPrefix !{params.out_prefix} --tumorName !{params.out_prefix} !{pileup}\n        \n        #fetch results (cncf and plot can be missing from facets results, but if produced both will be available)\n        facetsResults.sh -s !{params.out_prefix}.out $(if [[ -f !{params.out_prefix}.cncf.txt && -f !{params.out_prefix}.cncf.pdf ]]; then echo -c !{params.out_prefix}.cncf.txt -p !{params.out_prefix}.cncf.pdf; fi)\n    '''\n}",
        "nb_lignes_process": 23,
        "string_script": "    '''\n        #run facets\n        facetsRun.R --seed !{params.seed} --minNDepth !{params.minNDepth} --maxNDepth !{params.maxNDepth} --snp_nbhd !{params.snp_nbhd} --minGC !{params.minGC} --maxGC !{params.maxGC} --cval !{params.cval} --pre_cval !{params.pre_cval} --genome !{params.genome} --min_nhet !{params.min_nhet} --outPrefix !{params.out_prefix} --tumorName !{params.out_prefix} !{pileup}\n        \n        #fetch results (cncf and plot can be missing from facets results, but if produced both will be available)\n        facetsResults.sh -s !{params.out_prefix}.out $(if [[ -f !{params.out_prefix}.cncf.txt && -f !{params.out_prefix}.cncf.pdf ]]; then echo -c !{params.out_prefix}.cncf.txt -p !{params.out_prefix}.cncf.pdf; fi)\n    '''",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pileup"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "scoreDownload": {
        "name_process": "scoreDownload",
        "string_process": "\nprocess scoreDownload {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/score:${params.container_version}\"\n    publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n    label \"scoreDownload\"\n    tag \"${analysis_id}\"\n\n    input:\n        path analysis\n        val study_id\n        val analysis_id\n\n    output:\n        path analysis, emit: analysis_json\n        path 'out/*', emit: files\n\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export METADATA_URL=${params.song_url}\n        export STORAGE_URL=${params.score_url}\n        export TRANSPORT_PARALLEL=${params.cpus}\n        export TRANSPORT_MEMORY=${params.transport_mem}\n        export ACCESSTOKEN=${accessToken}\n        \n        score-client download --analysis-id ${analysis_id} --study-id ${study_id} --output-dir ./out \n        \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export METADATA_URL=${params.song_url}\n        export STORAGE_URL=${params.score_url}\n        export TRANSPORT_PARALLEL=${params.cpus}\n        export TRANSPORT_MEMORY=${params.transport_mem}\n        export ACCESSTOKEN=${accessToken}\n        \n        score-client download --analysis-id ${analysis_id} --study-id ${study_id} --output-dir ./out \n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "analysis",
            "study_id",
            "analysis_id"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/score:${params.container_version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "label \"scoreDownload\"",
            "tag \"${analysis_id}\""
        ],
        "when": "",
        "stub": ""
    },
    "seqzMain": {
        "name_process": "seqzMain",
        "string_process": "\nprocess seqzMain {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path seqz\n\n  output:                                  \n    path \"${params.output_pattern}\", emit: results\n    path \"*segments.txt\", emit: segments\n\n  shell:\n                                                  \n\n    \"\"\"\n    Rscript /tools/runSequenza.R --seqz !{seqz} --genome !{params.genome}\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    Rscript /tools/runSequenza.R --seqz !{seqz} --genome !{params.genome}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqz"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "battenberg": {
        "name_process": "battenberg",
        "string_process": "\nprocess battenberg {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path tumour_bam\n    path tumour_bai\n    path normal_bam\n    path normal_bai\n    path fasta_file\n    path fasta_fai\n    path battenberg_ref_dir\n\n  output:                                  \n    path \"${params.output_pattern}\", emit: output_file\n\n  script:\n\n                                                  \n\n    arg_test = params.test ? \"--test\" : \"\"\n\n      \"\"\"\n      mkdir -p output_dir\n      \n      run_battenberg.R \\\n      -t ${tumour_bam} \\\n      -n ${normal_bam} \\\n      --sex ${params.sex} \\\n      -f ${fasta_file} \\\n      -r ${battenberg_ref_dir} \\\n      --imputeinfofile ${battenberg_ref_dir}/impute_info.txt \\\n      --cpu ${params.cpus} ${arg_test}\n      \n      \"\"\"\n      \n}",
        "nb_lignes_process": 39,
        "string_script": "    arg_test = params.test ? \"--test\" : \"\"\n\n      \"\"\"\n      mkdir -p output_dir\n      \n      run_battenberg.R \\\n      -t ${tumour_bam} \\\n      -n ${normal_bam} \\\n      --sex ${params.sex} \\\n      -f ${fasta_file} \\\n      -r ${battenberg_ref_dir} \\\n      --imputeinfofile ${battenberg_ref_dir}/impute_info.txt \\\n      --cpu ${params.cpus} ${arg_test}\n      \n      \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tumour_bam",
            "tumour_bai",
            "normal_bam",
            "normal_bai",
            "fasta_file",
            "fasta_fai",
            "battenberg_ref_dir"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "cram2bam": {
        "name_process": "cram2bam",
        "string_process": "\nprocess cram2bam {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path input_cram\n    path reference\n    path reference_idx\n\n  output:                                  \n    path \"*.bam\", emit: output_bam\n    path \"*.bai\", emit: output_bai\n\n  shell:\n    '''\n    filename=`basename \"!{input_cram}\"`\n    fname=\"${filename%.*}\"\n    ext=\"${filename##*.}\"\n\n    if [ \"$ext\" != \"cram\" ]; then\n      echo \"Error: input CRAM file must have .cram extension.\"\n      exit 1\n    fi\n\n    samtools view -T !{reference} -b --threads !{params.cpus} -o ${fname}.bam !{input_cram}\n    samtools index ${fname}.bam\n    '''\n}",
        "nb_lignes_process": 30,
        "string_script": "    '''\n    filename=`basename \"!{input_cram}\"`\n    fname=\"${filename%.*}\"\n    ext=\"${filename##*.}\"\n\n    if [ \"$ext\" != \"cram\" ]; then\n      echo \"Error: input CRAM file must have .cram extension.\"\n      exit 1\n    fi\n\n    samtools view -T !{reference} -b --threads !{params.cpus} -o ${fname}.bam !{input_cram}\n    samtools index ${fname}.bam\n    '''",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "input_cram",
            "reference",
            "reference_idx"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "svaba": {
        "name_process": "svaba",
        "string_process": "\nprocess svaba {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path input_tumour_bam\n    path input_normal_bam\n    path input_tumour_bai\n    path input_normal_bai\n    path ref_genome_gz\n    path ref_genome_gz_secondary_files\n    path dbsnp_file\n\n  output:                                  \n    path \"${params.sample_id}/${params.sample_id}.svaba.somatic.indel.vcf\", emit: output_file\n\n  script:\n                                                  \n    arg_dbsnp_file = !dbsnp_file.name.startsWith(\"NO_FILE\") ? \"-D ${dbsnp_file}\" : \"\"\n    \"\"\"\n    mkdir -p ${params.sample_id}\n    svaba run -t ${input_tumour_bam} \\\n-n ${input_normal_bam} \\\n-G ${ref_genome_gz} \\\n-p ${params.mem} \\\n-a ${params.sample_id} ${arg_dbsnp_file}\n\n    mv ${params.sample_id}.* ${params.sample_id}/\n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    arg_dbsnp_file = !dbsnp_file.name.startsWith(\"NO_FILE\") ? \"-D ${dbsnp_file}\" : \"\"\n    \"\"\"\n    mkdir -p ${params.sample_id}\n    svaba run -t ${input_tumour_bam} \\\n-n ${input_normal_bam} \\\n-G ${ref_genome_gz} \\\n-p ${params.mem} \\\n-a ${params.sample_id} ${arg_dbsnp_file}\n\n    mv ${params.sample_id}.* ${params.sample_id}/\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_tumour_bam",
            "input_normal_bam",
            "input_tumour_bai",
            "input_normal_bai",
            "ref_genome_gz",
            "ref_genome_gz_secondary_files",
            "dbsnp_file"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "songGetAnalysis": {
        "name_process": "songGetAnalysis",
        "string_process": "\nprocess songGetAnalysis {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/song-client:${params.container_version}\"\n    publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n    tag \"${analysis_id}\"\n\n    input:\n        val study_id\n        val analysis_id\n\n    output:\n        path \"*.analysis.json\", emit: json\n\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing search -a ${analysis_id} > ${analysis_id}.analysis.json\n        \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing search -a ${analysis_id} > ${analysis_id}.analysis.json\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Nursing"
        ],
        "tools_url": [
            "https://bio.tools/Nursing"
        ],
        "tools_dico": [
            {
                "name": "Nursing",
                "uri": "https://bio.tools/Nursing",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Medical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Critical care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Medicines research and development"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Biomedical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Healthcare informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health and disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Clinical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Acute medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Emergency medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Intensive care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Drug discovery and development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The use and abuse of credentials.\n\nA Guide to Nursing Credentials and Degrees.\n\nComplete List of Common Nursing Certifications.\n\nFrom LPN to MSN, the jumble of letters following a nurse's name can be confusing. Learn what these nursing credentials mean and how they should be listed.\n\nView 183 commonly recognized nursing certifications along with links to their certifying organizations.\n\nThe confusing nature of nursing credentials has led to widespread use of the term \u201calphabet soup.\u201d The letters that follow a nurse\u2019s name can be perplexing to professionals in the medical field, and especially to patients and families. To solve this problem, nursing credentials need to be displayed properly.\n\nNever fear. Nurse.org has compiled an alphabetical list of 183 different nursing certifications along with the appropriate acronyms and links to their certifying organizations",
                "homepage": "https://online.alvernia.edu/program-resources/nursing-credentials/"
            }
        ],
        "inputs": [
            "study_id",
            "analysis_id"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/song-client:${params.container_version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "tag \"${analysis_id}\""
        ],
        "when": "",
        "stub": ""
    },
    "seqzPreprocessMerge": {
        "name_process": "seqzPreprocessMerge",
        "string_process": "\nprocess seqzPreprocessMerge {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    file seqzperchromosome\n\n  output:                                  \n    path \"sample_bin50.seqz.gz\", emit: seqz\n  \n  shell:\n                                                \n  seqzfiles = params.chromosomes.join('.seqz.gz ')\n  '''\n  zcat !{seqzfiles}.seqz.gz | awk '{if (NR!=1 && $1 != \"chromosome\") {print $0}}' | bgzip > sample.seqz.gz\n  tabix -f -s 1 -b 2 -e 2 -S 1 sample.seqz.gz\n  sequenza-utils seqz_binning --seqz sample.seqz.gz --window 50 -o sample_bin50.seqz.gz\n  '''\n\n\n}",
        "nb_lignes_process": 23,
        "string_script": "  seqzfiles = params.chromosomes.join('.seqz.gz ')\n  '''\n  zcat !{seqzfiles}.seqz.gz | awk '{if (NR!=1 && $1 != \"chromosome\") {print $0}}' | bgzip > sample.seqz.gz\n  tabix -f -s 1 -b 2 -e 2 -S 1 sample.seqz.gz\n  sequenza-utils seqz_binning --seqz sample.seqz.gz --window 50 -o sample_bin50.seqz.gz\n  '''",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqzperchromosome"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__icgc-argo-sv-copy-number",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    }
}