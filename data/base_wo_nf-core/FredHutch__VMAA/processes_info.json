{
    "build_kraken2_db": {
        "name_process": "build_kraken2_db",
        "string_process": " process build_kraken2_db {\n    container \"${container__kraken2}\"\n    errorStrategy 'retry'\n    publishDir \"${params.output_folder}\"\n    memory 240.Gb\n    cpus 32\n    \n    output:\n    file \"${params.output_prefix}*\"\n\n  \"\"\"\n#!/bin/bash\n\nset -e\n\nkraken2-build \\\n    --standard \\\n    --threads ${task.cpus} \\\n    --db ${params.output_prefix} \\\n    --use-ftp\n\n  \"\"\"\n\n  }",
        "nb_lignes_process": 22,
        "string_script": "\"\"\"\n#!/bin/bash\n\nset -e\n\nkraken2-build \\\n    --standard \\\n    --threads ${task.cpus} \\\n    --db ${params.output_prefix} \\\n    --use-ftp\n\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__kraken2}\"",
            "errorStrategy 'retry'",
            "publishDir \"${params.output_folder}\"",
            "memory 240.Gb",
            "cpus 32"
        ],
        "when": "",
        "stub": ""
    },
    "build_kraken2_db_protein": {
        "name_process": "build_kraken2_db_protein",
        "string_process": " process build_kraken2_db_protein {\n      container \"${container__kraken2}\"\n      errorStrategy 'retry'\n      publishDir \"${params.output_folder}\"\n      memory 240.Gb\n      cpus 32\n      \n      output:\n      file \"${params.output_prefix}*\"\n\n  \"\"\"\n#!/bin/bash\n\nset -e\n\nkraken2-build \\\n    --standard \\\n    --threads ${task.cpus} \\\n    --db ${params.output_prefix} \\\n    --protein \\\n    --use-ftp\n\n  \"\"\"\n\n    }",
        "nb_lignes_process": 23,
        "string_script": "\"\"\"\n#!/bin/bash\n\nset -e\n\nkraken2-build \\\n    --standard \\\n    --threads ${task.cpus} \\\n    --db ${params.output_prefix} \\\n    --protein \\\n    --use-ftp\n\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__kraken2}\"",
            "errorStrategy 'retry'",
            "publishDir \"${params.output_folder}\"",
            "memory 240.Gb",
            "cpus 32"
        ],
        "when": "",
        "stub": ""
    },
    "joinFastq": {
        "name_process": "joinFastq",
        "string_process": "\nprocess joinFastq {\n  container \"${container__ubuntu}\"\n  errorStrategy 'retry'\n  \n  input:\n  tuple val(specimen), path(fastq_list)\n  \n  output:\n  tuple val(specimen), path(\"${specimen}.fastq.gz\")\n\n  \"\"\"\n#!/bin/bash\n\nset -e\n\ncat ${fastq_list} > TEMP && mv TEMP \"${specimen}.fastq.gz\"\n  \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "\"\"\"\n#!/bin/bash\n\nset -e\n\ncat ${fastq_list} > TEMP && mv TEMP \"${specimen}.fastq.gz\"\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "TEMP"
        ],
        "tools_url": [
            "https://bio.tools/temp"
        ],
        "tools_dico": [
            {
                "name": "TEMP",
                "uri": "https://bio.tools/temp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0427",
                                    "term": "Transposon prediction"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A software package for detecting transposable elements (TEs) insertions and excisions from pooled high-throughput sequencing data.",
                "homepage": "https://github.com/JialiUMassWengLab/TEMP"
            }
        ],
        "inputs": [
            "specimen",
            "fastq_list"
        ],
        "nb_inputs": 2,
        "outputs": [
            "specimen"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__ubuntu}\"",
            "errorStrategy 'retry'"
        ],
        "when": "",
        "stub": ""
    },
    "cutadapt": {
        "name_process": "cutadapt",
        "string_process": "\nprocess cutadapt {\n    tag \"Trim adapters from WGS reads\"\n    container \"${container__cutadapt}\"\n    label 'mem_medium'\n    errorStrategy 'retry'\n    maxRetries 10\n\n    input:\n    tuple val(sample_name), file(FASTQ)\n\n    output:\n    tuple val(sample_name), file(\"${sample_name}.cutadapt.fq.gz\") optional true\n\n\"\"\"\nset -e \n\ncutadapt \\\n--minimum-length ${params.min_len} \\\n-j ${task.cpus} \\\n--cut ${params.bases_before_adapter} \\\n-g ^${params.adapter_F}...${params.adapter_R} \\\n-q ${params.qual_threshold},${params.qual_threshold} \\\n--discard-untrimmed \\\n--max-n ${params.max_n_prop} \\\n--times 3 \\\n--trim-n \\\n${FASTQ} | \\\nawk '{if(NR % 4 != 0){printf \\$1 \"\\t\"}else{print \\$1}}' | \\\ngrep -v ${params.adapter_F} | \\\ngrep -v ${params.adapter_R} | \\\ntr '\\t' '\\n' | gzip -c > \\\n${sample_name}.cutadapt.fq.gz\n\n# If the file is empty, delete it entirely\nif (( \\$(gunzip -c ${sample_name}.cutadapt.fq.gz | wc -l) == 0 )); then\n  rm ${sample_name}.cutadapt.fq.gz\nfi\n\"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "\"\"\"\nset -e \n\ncutadapt \\\n--minimum-length ${params.min_len} \\\n-j ${task.cpus} \\\n--cut ${params.bases_before_adapter} \\\n-g ^${params.adapter_F}...${params.adapter_R} \\\n-q ${params.qual_threshold},${params.qual_threshold} \\\n--discard-untrimmed \\\n--max-n ${params.max_n_prop} \\\n--times 3 \\\n--trim-n \\\n${FASTQ} | \\\nawk '{if(NR % 4 != 0){printf \\$1 \"\\t\"}else{print \\$1}}' | \\\ngrep -v ${params.adapter_F} | \\\ngrep -v ${params.adapter_R} | \\\ntr '\\t' '\\n' | gzip -c > \\\n${sample_name}.cutadapt.fq.gz\n\n# If the file is empty, delete it entirely\nif (( \\$(gunzip -c ${sample_name}.cutadapt.fq.gz | wc -l) == 0 )); then\n  rm ${sample_name}.cutadapt.fq.gz\nfi\n\"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "Cutadapt"
        ],
        "tools_url": [
            "https://bio.tools/cutadapt"
        ],
        "tools_dico": [
            {
                "name": "Cutadapt",
                "uri": "https://bio.tools/cutadapt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ]
                    }
                ],
                "description": "Find and remove adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads.",
                "homepage": "https://pypi.python.org/pypi/cutadapt"
            }
        ],
        "inputs": [
            "sample_name",
            "FASTQ"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample_name"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "tag \"Trim adapters from WGS reads\"",
            "container \"${container__cutadapt}\"",
            "label 'mem_medium'",
            "errorStrategy 'retry'",
            "maxRetries 10"
        ],
        "when": "",
        "stub": ""
    },
    "remove_human": {
        "name_process": "remove_human",
        "string_process": "\nprocess remove_human {\n    tag \"Remove human reads\"\n    container \"${container__bwa}\"\n    errorStrategy 'retry'\n    label 'mem_veryhigh'\n\n\n    input:\n        tuple val(sample_name), file(\"${sample_name}.input.fq.gz\")\n        file hg_index_tgz\n\n    output:\n        tuple val(sample_name), file(\"${sample_name}.fq.gz\") optional true\n\n\"\"\"\n#!/bin/bash\n\nset -e\n\n# Get the index name from the first file in the tar\nbwa_index_prefix=\\$(tar -ztvf ${hg_index_tgz} | head -1 | sed \\'s/.* //\\')\n\n# Remove whichever ending this file has\nbwa_index_prefix=\\${bwa_index_prefix%.amb}\nbwa_index_prefix=\\${bwa_index_prefix%.ann}\nbwa_index_prefix=\\${bwa_index_prefix%.bwt}\nbwa_index_prefix=\\${bwa_index_prefix%.fai}\nbwa_index_prefix=\\${bwa_index_prefix%.pac}\nbwa_index_prefix=\\${bwa_index_prefix%.sa}\n\necho BWA index prefix is \\${bwa_index_prefix}\necho \"If this index prefix is not correct, consider remaking the tarball\"\necho \"so that it doesn't include anything other than the index files\"\n\necho Extracting BWA index\n\nmkdir -p hg_index/ \n\ntar -I pigz -xf ${hg_index_tgz} -C hg_index/\n\necho Files in index directory: \nls -l -h hg_index \n\n# Make sure that there are files in the index directory\n(( \\$(ls -l -h hg_index | wc -l) > 0 ))\n\necho Running BWA \n\nbwa mem -t ${task.cpus} \\\n-T ${params.min_hg_align_score} \\\n-o alignment.sam \\\nhg_index/\\$bwa_index_prefix \\\n${sample_name}.input.fq.gz\n\necho Checking if alignment is empty  \nif [[ -s alignment.sam ]]; then\n\n  echo Extracting Unaligned Pairs \n  samtools \\\n    fastq \\\n    alignment.sam \\\n    --threads ${task.cpus} \\\n    -f 4 \\\n    -n \\\n    | gzip -c > ${sample_name}.fq.gz\n\n  \n  echo \"Checking to see how many reads pass the human filtering\"\n\n  gunzip -c ${sample_name}.fq.gz | wc -l\n\n  if (( \\$(gunzip -c ${sample_name}.fq.gz | wc -l) == 0 )); then\n\n    echo \"Removing empty output file\"\n    rm ${sample_name}.fq.gz\n\n  fi\n\nelse\n\n  echo \"Alignment SAM file was empty\"\n\nfi\n\necho Done \n\"\"\"\n}",
        "nb_lignes_process": 86,
        "string_script": "\"\"\"\n#!/bin/bash\n\nset -e\n\n# Get the index name from the first file in the tar\nbwa_index_prefix=\\$(tar -ztvf ${hg_index_tgz} | head -1 | sed \\'s/.* //\\')\n\n# Remove whichever ending this file has\nbwa_index_prefix=\\${bwa_index_prefix%.amb}\nbwa_index_prefix=\\${bwa_index_prefix%.ann}\nbwa_index_prefix=\\${bwa_index_prefix%.bwt}\nbwa_index_prefix=\\${bwa_index_prefix%.fai}\nbwa_index_prefix=\\${bwa_index_prefix%.pac}\nbwa_index_prefix=\\${bwa_index_prefix%.sa}\n\necho BWA index prefix is \\${bwa_index_prefix}\necho \"If this index prefix is not correct, consider remaking the tarball\"\necho \"so that it doesn't include anything other than the index files\"\n\necho Extracting BWA index\n\nmkdir -p hg_index/ \n\ntar -I pigz -xf ${hg_index_tgz} -C hg_index/\n\necho Files in index directory: \nls -l -h hg_index \n\n# Make sure that there are files in the index directory\n(( \\$(ls -l -h hg_index | wc -l) > 0 ))\n\necho Running BWA \n\nbwa mem -t ${task.cpus} \\\n-T ${params.min_hg_align_score} \\\n-o alignment.sam \\\nhg_index/\\$bwa_index_prefix \\\n${sample_name}.input.fq.gz\n\necho Checking if alignment is empty  \nif [[ -s alignment.sam ]]; then\n\n  echo Extracting Unaligned Pairs \n  samtools \\\n    fastq \\\n    alignment.sam \\\n    --threads ${task.cpus} \\\n    -f 4 \\\n    -n \\\n    | gzip -c > ${sample_name}.fq.gz\n\n  \n  echo \"Checking to see how many reads pass the human filtering\"\n\n  gunzip -c ${sample_name}.fq.gz | wc -l\n\n  if (( \\$(gunzip -c ${sample_name}.fq.gz | wc -l) == 0 )); then\n\n    echo \"Removing empty output file\"\n    rm ${sample_name}.fq.gz\n\n  fi\n\nelse\n\n  echo \"Alignment SAM file was empty\"\n\nfi\n\necho Done \n\"\"\"",
        "nb_lignes_script": 71,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools",
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools",
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "sample_name",
            "hg_index_tgz"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample_name"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "tag \"Remove human reads\"",
            "container \"${container__bwa}\"",
            "errorStrategy 'retry'",
            "label 'mem_veryhigh'"
        ],
        "when": "",
        "stub": ""
    },
    "assemble": {
        "name_process": "assemble",
        "string_process": "\nprocess assemble {\n    tag \"De novo metagenomic assembly\"\n    container \"${container__assembler}\"\n    label 'mem_veryhigh'\n    errorStrategy \"retry\"\n    publishDir params.output_folder\n\n    input:\n        path fastq_list\n    \n    output:\n        file \"${params.output_prefix}.fasta.gz\"\n    \n\"\"\"\nset -e \n\necho -e \"Concatenating inputs\"\ncat ${fastq_list} > INPUT.fastq.gz\n\ndate\necho -e \"Running Megahit\\\\n\"\n\nmegahit \\\n    -r INPUT.fastq.gz \\\n    -o OUTPUT \\\n    -t ${task.cpus} \\\n    --k-min ${params.k_min} \\\n    --k-max ${params.k_max} \\\n    --k-step ${params.k_step} \\\n    --min-contig-len ${params.min_len} \\\n\ndate\necho -e \"\\\\nMaking sure output files are not empty\\\\n\"\n[[ \\$(cat OUTPUT/final.contigs.fa | wc -l) > 0 ]]\n\ndate\necho -e \"\\\\nRenaming output files\\\\n\"\n\n# Rename the output file\ncat OUTPUT/final.contigs.fa | gzip -c > ${params.output_prefix}.fasta.gz\n\ndate\necho -e \"\\\\nDone\\\\n\"\n\"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "\"\"\"\nset -e \n\necho -e \"Concatenating inputs\"\ncat ${fastq_list} > INPUT.fastq.gz\n\ndate\necho -e \"Running Megahit\\\\n\"\n\nmegahit \\\n    -r INPUT.fastq.gz \\\n    -o OUTPUT \\\n    -t ${task.cpus} \\\n    --k-min ${params.k_min} \\\n    --k-max ${params.k_max} \\\n    --k-step ${params.k_step} \\\n    --min-contig-len ${params.min_len} \\\n\ndate\necho -e \"\\\\nMaking sure output files are not empty\\\\n\"\n[[ \\$(cat OUTPUT/final.contigs.fa | wc -l) > 0 ]]\n\ndate\necho -e \"\\\\nRenaming output files\\\\n\"\n\n# Rename the output file\ncat OUTPUT/final.contigs.fa | gzip -c > ${params.output_prefix}.fasta.gz\n\ndate\necho -e \"\\\\nDone\\\\n\"\n\"\"\"",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [
            "datelife",
            "MEGAHIT"
        ],
        "tools_url": [
            "https://bio.tools/datelife",
            "https://bio.tools/megahit"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            },
            {
                "name": "MEGAHIT",
                "uri": "https://bio.tools/megahit",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0610",
                            "term": "Ecology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Single node assembler for large and complex metagenomics NGS reads, such as soil. It makes use of succinct de Bruijn graph to achieve low memory usage, whereas its goal is not to make memory usage as low as possible.",
                "homepage": "https://github.com/voutcn/megahit"
            }
        ],
        "inputs": [
            "fastq_list"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "tag \"De novo metagenomic assembly\"",
            "container \"${container__assembler}\"",
            "label 'mem_veryhigh'",
            "errorStrategy \"retry\"",
            "publishDir params.output_folder"
        ],
        "when": "",
        "stub": ""
    },
    "countReads": {
        "name_process": "countReads",
        "string_process": "\nprocess countReads {\n  container \"${container__ubuntu}\"\n  label 'io_limited'\n  errorStrategy 'retry'\n  \n  input:\n  tuple val(sample_name), file(fastq)\n  \n  output:\n  file \"${sample_name}.${params.count_reads_label}.counts.csv\"\n\n  \"\"\"\n#!/bin/bash\n\nset -e\n\necho \"Counting reads\"\nn=\\$(gunzip -c \"${fastq}\" | awk 'NR % 4 == 1' | wc -l)\n\necho \"Found \\$n reads\"\n(( \\$n > 0 ))\n\necho \"${sample_name},\\$n,${params.count_reads_label}\" > \"${sample_name}.${params.count_reads_label}.counts.csv\"\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 26,
        "string_script": "\"\"\"\n#!/bin/bash\n\nset -e\n\necho \"Counting reads\"\nn=\\$(gunzip -c \"${fastq}\" | awk 'NR % 4 == 1' | wc -l)\n\necho \"Found \\$n reads\"\n(( \\$n > 0 ))\n\necho \"${sample_name},\\$n,${params.count_reads_label}\" > \"${sample_name}.${params.count_reads_label}.counts.csv\"\n\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_name",
            "fastq"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__ubuntu}\"",
            "label 'io_limited'",
            "errorStrategy 'retry'"
        ],
        "when": "",
        "stub": ""
    },
    "collectCountReads": {
        "name_process": "collectCountReads",
        "string_process": "\nprocess collectCountReads {\n  container \"${container__ubuntu}\"\n  label 'io_limited'\n  errorStrategy 'retry'\n  publishDir params.output_folder\n  \n  input:\n  file csv_list\n  \n  output:\n  file \"${params.output_prefix}.counts.csv\"\n\n  \"\"\"\n#!/bin/bash\n\nset -e\n\necho \"specimen,nreads,label\" > ${params.output_prefix}.counts.csv\ncat ${csv_list} >> ${params.output_prefix}.counts.csv\n  \"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "\"\"\"\n#!/bin/bash\n\nset -e\n\necho \"specimen,nreads,label\" > ${params.output_prefix}.counts.csv\ncat ${csv_list} >> ${params.output_prefix}.counts.csv\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "csv_list"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__ubuntu}\"",
            "label 'io_limited'",
            "errorStrategy 'retry'",
            "publishDir params.output_folder"
        ],
        "when": "",
        "stub": ""
    },
    "index": {
        "name_process": "index",
        "string_process": "\nprocess index {\n  container \"${container__bwa}\"\n  label \"mem_medium\"\n  errorStrategy 'retry'\n\n  input:\n  file genome_fasta\n  \n  output:\n  file \"${genome_fasta}.tar\"\n  \n  \"\"\"\n#!/bin/bash\nset -e\n\necho \"Indexing ${genome_fasta}\"\nbwa index ${genome_fasta}\n\necho \"Tarring up indexed genome\"\ntar cvf ${genome_fasta}.tar ${genome_fasta}*\necho \"Done\"\n  \"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "\"\"\"\n#!/bin/bash\nset -e\n\necho \"Indexing ${genome_fasta}\"\nbwa index ${genome_fasta}\n\necho \"Tarring up indexed genome\"\ntar cvf ${genome_fasta}.tar ${genome_fasta}*\necho \"Done\"\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "BWA"
        ],
        "tools_url": [
            "https://bio.tools/bwa"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            }
        ],
        "inputs": [
            "genome_fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__bwa}\"",
            "label \"mem_medium\"",
            "errorStrategy 'retry'"
        ],
        "when": "",
        "stub": ""
    },
    "align": {
        "name_process": "align",
        "string_process": "\nprocess align {\n  container \"${container__bwa}\"\n  label \"mem_veryhigh\"\n  errorStrategy 'retry'\n  publishDir \"${params.output_folder}/bam/\", mode: 'copy'\n\n  input:\n  tuple val(sample_name), file(input_fastq)\n  file genome_index\n  \n  output:\n  tuple val(sample_name), file(\"${sample_name}.bam\"), file(\"${sample_name}.bam.bai\")\n\n  \"\"\"\n#!/bin/bash\nset -e\n\necho Unpacking ${genome_index}\ntar xvf ${genome_index}\n\necho \"Running BWA\"\nbwa mem \\\n  -t ${task.cpus} \\\n  ${genome_index.name.replaceAll(/.tar/, \"\")} \\\n  ${input_fastq} \\\n  | samtools view -b -F 4 -o ${sample_name}.bam\n\n# Sort the BAM file\nsamtools sort -o ${sample_name}.SORTED.bam ${sample_name}.bam\nmv ${sample_name}.SORTED.bam ${sample_name}.bam\n\n# Index the BAM file\nsamtools index ${sample_name}.bam\n\necho Done aligning ${sample_name}.bam\n\n    \"\"\"\n\n}",
        "nb_lignes_process": 38,
        "string_script": "\"\"\"\n#!/bin/bash\nset -e\n\necho Unpacking ${genome_index}\ntar xvf ${genome_index}\n\necho \"Running BWA\"\nbwa mem \\\n  -t ${task.cpus} \\\n  ${genome_index.name.replaceAll(/.tar/, \"\")} \\\n  ${input_fastq} \\\n  | samtools view -b -F 4 -o ${sample_name}.bam\n\n# Sort the BAM file\nsamtools sort -o ${sample_name}.SORTED.bam ${sample_name}.bam\nmv ${sample_name}.SORTED.bam ${sample_name}.bam\n\n# Index the BAM file\nsamtools index ${sample_name}.bam\n\necho Done aligning ${sample_name}.bam\n\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_name",
            "input_fastq",
            "genome_index"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample_name"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__bwa}\"",
            "label \"mem_veryhigh\"",
            "errorStrategy 'retry'",
            "publishDir \"${params.output_folder}/bam/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "faidx": {
        "name_process": "faidx",
        "string_process": "\nprocess faidx {\n  container \"${container__bwa}\"\n  label \"mem_medium\"\n  errorStrategy 'retry'\n  publishDir params.output_folder, mode: 'copy'\n\n  input:\n  file fasta\n  \n  output:\n  file \"${fasta.name.replaceAll(/.gz/, '')}.fai\"\n\n  \"\"\"\n#!/bin/bash\nset -e\n\necho \"Decompressing input\"\ngunzip ${fasta}\n\necho \"Running samtools faidx ${fasta.name.replaceAll(/.gz/, '')}\"\nsamtools faidx ${fasta.name.replaceAll(/.gz/, '')}\n    \"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "\"\"\"\n#!/bin/bash\nset -e\n\necho \"Decompressing input\"\ngunzip ${fasta}\n\necho \"Running samtools faidx ${fasta.name.replaceAll(/.gz/, '')}\"\nsamtools faidx ${fasta.name.replaceAll(/.gz/, '')}\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__bwa}\"",
            "label \"mem_medium\"",
            "errorStrategy 'retry'",
            "publishDir params.output_folder, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "calcStats": {
        "name_process": "calcStats",
        "string_process": "\nprocess calcStats {\n  container \"${container__bwa}\"\n  label \"io_limited\"\n  errorStrategy 'retry'\n\n  input:\n  tuple val(sample_name), file(bam), file(bai)\n  \n  output:\n  tuple val(sample_name), file(\"${sample_name}.idxstats\"), file(\"${sample_name}.stats\"), file(\"${sample_name}.pileup\"), file(\"${sample_name}.positions\")\n\n  \"\"\"\n#!/bin/bash\nset -e\n\nsamtools sort ${bam} > ${sample_name}.sorted\nsamtools stats ${sample_name}.sorted > ${sample_name}.stats\nsamtools index ${sample_name}.sorted\nsamtools idxstats ${sample_name}.sorted > ${sample_name}.idxstats\nsamtools mpileup ${sample_name}.sorted > ${sample_name}.pileup\n\n# Make a file with four columns, the contig, the bitwise flag, and the leftmost position, and the length of the mapped segment\nsamtools view ${sample_name}.sorted | awk '{print \\$3 \"\\\\t\" \\$2 \"\\\\t\" \\$4 \"\\\\t\" length(\\$10)}' > ${sample_name}.positions\n\nrm ${sample_name}.sorted\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "\"\"\"\n#!/bin/bash\nset -e\n\nsamtools sort ${bam} > ${sample_name}.sorted\nsamtools stats ${sample_name}.sorted > ${sample_name}.stats\nsamtools index ${sample_name}.sorted\nsamtools idxstats ${sample_name}.sorted > ${sample_name}.idxstats\nsamtools mpileup ${sample_name}.sorted > ${sample_name}.pileup\n\n# Make a file with four columns, the contig, the bitwise flag, and the leftmost position, and the length of the mapped segment\nsamtools view ${sample_name}.sorted | awk '{print \\$3 \"\\\\t\" \\$2 \"\\\\t\" \\$4 \"\\\\t\" length(\\$10)}' > ${sample_name}.positions\n\nrm ${sample_name}.sorted\n\n  \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_name",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample_name"
        ],
        "nb_outputs": 1,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__bwa}\"",
            "label \"io_limited\"",
            "errorStrategy 'retry'"
        ],
        "when": "",
        "stub": ""
    },
    "summarize": {
        "name_process": "summarize",
        "string_process": "\nprocess summarize {\n  container \"${container__pandas}\"\n  label \"mem_medium\"\n  errorStrategy 'retry'\n\n  input:\n  tuple val(sample_name), file(idxstats), file(stats), file(pileup), file(positions)\n  \n  output:\n  file \"${sample_name}.csv.gz\"\n\n  \"\"\"\n#!/usr/bin/env python3\nimport logging\nimport os\nimport gzip\nimport json\nimport pandas as pd\nfrom math import log as ln\n\nlogFormatter = logging.Formatter(\n    '%(asctime)s %(levelname)-8s [nf-viral-metagenomics] %(message)s'\n)\nrootLogger = logging.getLogger()\nrootLogger.setLevel(logging.INFO)\n\n# Write to STDOUT\nconsoleHandler = logging.StreamHandler()\nconsoleHandler.setFormatter(logFormatter)\nrootLogger.addHandler(consoleHandler)\n\ndef read_line(fp, prefix):\n    with open(fp, 'rt') as f:\n        for line in f:\n            if line.startswith(prefix):\n                return line.replace(prefix, '').strip(\" \").strip(\"\\\\t\")\n\ndef parse_flags(int_flags):\n    output = dict()\n    for n, flag in [\n        (2048, \"supplementary\"),\n        (1024, \"duplicate\"),\n        (512, \"fail_filter\"),\n        (256, \"secondary\"),\n        (128, \"last\"),\n        (64, \"first\"),\n        (32, \"next_rc\"),\n        (16, \"rc\"),\n        (8, \"next_unmapped\"),\n        (4, \"unmapped\"),\n        (2, \"aligned_properly\"),\n        (1, \"multiple_segments\"),\n    ]:\n        if int_flags >= n:\n            output[flag] = True\n            int_flags = int_flags - n\n        else:\n            output[flag] = False\n    assert int_flags == 0, int_flags\n    return output\n\n\ndef shannon_divesity(counts):\n    # See https://gist.github.com/audy/783125\n    \n    def p(n, N):\n        # Relative abundance\n        if n is 0:\n            return 0\n        else:\n            return (float(n)/N) * ln(float(n)/N)\n            \n    N = sum(counts)\n    \n    return -sum(p(n, N) for n in counts if n is not 0)\n\n\n# Read in the summary of alignment positions\nlogging.info(\"Reading in ${positions}\")\npositions = pd.read_csv(\n  \"${positions}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\n    \"contig\", \"flags\", \"pos\", \"len\"\n  ]\n)\n\n# Parse the flags columns from the positions file\nlogging.info(\"Parsing flags in ${positions}\")\npositions = pd.concat([positions, pd.DataFrame(map(parse_flags, positions[\"flags\"]))], axis=1)\n\n# Find the read start position\n# If the read is aligned in the forward direction, use the leftmost position, otherwise use the rightmost\npositions = positions.assign(\n  start_pos = positions.apply(\n    lambda r: r[\"pos\"] + r[\"len\"] if r[\"rc\"] else r[\"pos\"],\n    axis=1\n  )\n)\n\n# Calculate Shannon diversity per contig\nlogging.info(\"Calculating Shannon diversity per contig\")\nsdi = positions.groupby(\n  \"contig\"\n).apply(\n  lambda contig_positions: shannon_divesity(contig_positions[\"start_pos\"].value_counts().values)\n)\n\n# Read in the pileup\nlogging.info(\"Reading in ${pileup}\")\npileup = pd.read_csv(\n  \"${pileup}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\"contig\", \"position\", \"base\", \"depth\", \"aligned_bases\", \"aligned_quality\"]\n)\n\n# Get the stats for each contig\nlogging.info(\"Reading in ${idxstats}\")\ncontig_stats = pd.read_csv(\n  \"${idxstats}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\"contig\", \"len\", \"mapped\", \"unmapped\"]\n).set_index(\n  \"contig\"\n)\n\n# Number of positions with any aligned reads per contig\nlogging.info(\"Number of positions with any aligned reads per contig\")\ncovlen = pileup.query(\n  \"depth > 0\"\n)[\"contig\"].value_counts()\n\n# Error rate over the entire alignment\nlogging.info(\"Reading overall error rate\")\nnerror = float(read_line(\"${stats}\", \"SN\\\\terror rate:\").split(\"\\\\t\")[0])\n\n# Number of bases aligned per contig\nnbases = pileup.groupby(\n  \"contig\"\n).apply(\n  lambda df: df[\"depth\"].sum()\n)\n\n# Make a single output object\nlogging.info(\"Making an output object\")\noutput = dict([\n  (\"specimen\", \"${sample_name}\"),\n  (\"reads_aligned\", positions[\"contig\"].value_counts()),\n  (\"bases_aligned\", nbases),\n  (\"bases_covered\", covlen),\n  (\"contig_length\", contig_stats[\"len\"]),\n  (\"error\", nerror),\n  (\"entropy\", sdi),\n  (\"specimen_total_reads\", contig_stats.reindex(columns=[\"mapped\", \"unmapped\"]).sum().sum())\n])\n\n# Format as a DataFrame\nlogging.info(\"Formatting as DataFrame\")\noutput = pd.DataFrame(\n  output\n).drop(  # Drop the pseudo contig name used for unaligned reads\n  index = \"*\"\n)\n\n# Add more summary columns, and reset the index used for the contig name\nlogging.info(\"Adding summary stats\")\noutput = output.assign(\n  depth = output[\"bases_aligned\"] / output[\"contig_length\"],\n  coverage = output[\"bases_covered\"] / output[\"contig_length\"],\n  proportion_of_reads = output[\"reads_aligned\"] / output[\"specimen_total_reads\"]\n).reset_index(\n).rename(\n  columns = dict([(\"index\", \"contig\")])\n)\n\n# Write out as CSV\nlogging.info(\"Writing out to ${sample_name}.csv.gz\")\noutput.to_csv(\n  \"${sample_name}.csv.gz\", \n  index=None\n)\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 187,
        "string_script": "\"\"\"\n#!/usr/bin/env python3\nimport logging\nimport os\nimport gzip\nimport json\nimport pandas as pd\nfrom math import log as ln\n\nlogFormatter = logging.Formatter(\n    '%(asctime)s %(levelname)-8s [nf-viral-metagenomics] %(message)s'\n)\nrootLogger = logging.getLogger()\nrootLogger.setLevel(logging.INFO)\n\n# Write to STDOUT\nconsoleHandler = logging.StreamHandler()\nconsoleHandler.setFormatter(logFormatter)\nrootLogger.addHandler(consoleHandler)\n\ndef read_line(fp, prefix):\n    with open(fp, 'rt') as f:\n        for line in f:\n            if line.startswith(prefix):\n                return line.replace(prefix, '').strip(\" \").strip(\"\\\\t\")\n\ndef parse_flags(int_flags):\n    output = dict()\n    for n, flag in [\n        (2048, \"supplementary\"),\n        (1024, \"duplicate\"),\n        (512, \"fail_filter\"),\n        (256, \"secondary\"),\n        (128, \"last\"),\n        (64, \"first\"),\n        (32, \"next_rc\"),\n        (16, \"rc\"),\n        (8, \"next_unmapped\"),\n        (4, \"unmapped\"),\n        (2, \"aligned_properly\"),\n        (1, \"multiple_segments\"),\n    ]:\n        if int_flags >= n:\n            output[flag] = True\n            int_flags = int_flags - n\n        else:\n            output[flag] = False\n    assert int_flags == 0, int_flags\n    return output\n\n\ndef shannon_divesity(counts):\n    # See https://gist.github.com/audy/783125\n    \n    def p(n, N):\n        # Relative abundance\n        if n is 0:\n            return 0\n        else:\n            return (float(n)/N) * ln(float(n)/N)\n            \n    N = sum(counts)\n    \n    return -sum(p(n, N) for n in counts if n is not 0)\n\n\n# Read in the summary of alignment positions\nlogging.info(\"Reading in ${positions}\")\npositions = pd.read_csv(\n  \"${positions}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\n    \"contig\", \"flags\", \"pos\", \"len\"\n  ]\n)\n\n# Parse the flags columns from the positions file\nlogging.info(\"Parsing flags in ${positions}\")\npositions = pd.concat([positions, pd.DataFrame(map(parse_flags, positions[\"flags\"]))], axis=1)\n\n# Find the read start position\n# If the read is aligned in the forward direction, use the leftmost position, otherwise use the rightmost\npositions = positions.assign(\n  start_pos = positions.apply(\n    lambda r: r[\"pos\"] + r[\"len\"] if r[\"rc\"] else r[\"pos\"],\n    axis=1\n  )\n)\n\n# Calculate Shannon diversity per contig\nlogging.info(\"Calculating Shannon diversity per contig\")\nsdi = positions.groupby(\n  \"contig\"\n).apply(\n  lambda contig_positions: shannon_divesity(contig_positions[\"start_pos\"].value_counts().values)\n)\n\n# Read in the pileup\nlogging.info(\"Reading in ${pileup}\")\npileup = pd.read_csv(\n  \"${pileup}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\"contig\", \"position\", \"base\", \"depth\", \"aligned_bases\", \"aligned_quality\"]\n)\n\n# Get the stats for each contig\nlogging.info(\"Reading in ${idxstats}\")\ncontig_stats = pd.read_csv(\n  \"${idxstats}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\"contig\", \"len\", \"mapped\", \"unmapped\"]\n).set_index(\n  \"contig\"\n)\n\n# Number of positions with any aligned reads per contig\nlogging.info(\"Number of positions with any aligned reads per contig\")\ncovlen = pileup.query(\n  \"depth > 0\"\n)[\"contig\"].value_counts()\n\n# Error rate over the entire alignment\nlogging.info(\"Reading overall error rate\")\nnerror = float(read_line(\"${stats}\", \"SN\\\\terror rate:\").split(\"\\\\t\")[0])\n\n# Number of bases aligned per contig\nnbases = pileup.groupby(\n  \"contig\"\n).apply(\n  lambda df: df[\"depth\"].sum()\n)\n\n# Make a single output object\nlogging.info(\"Making an output object\")\noutput = dict([\n  (\"specimen\", \"${sample_name}\"),\n  (\"reads_aligned\", positions[\"contig\"].value_counts()),\n  (\"bases_aligned\", nbases),\n  (\"bases_covered\", covlen),\n  (\"contig_length\", contig_stats[\"len\"]),\n  (\"error\", nerror),\n  (\"entropy\", sdi),\n  (\"specimen_total_reads\", contig_stats.reindex(columns=[\"mapped\", \"unmapped\"]).sum().sum())\n])\n\n# Format as a DataFrame\nlogging.info(\"Formatting as DataFrame\")\noutput = pd.DataFrame(\n  output\n).drop(  # Drop the pseudo contig name used for unaligned reads\n  index = \"*\"\n)\n\n# Add more summary columns, and reset the index used for the contig name\nlogging.info(\"Adding summary stats\")\noutput = output.assign(\n  depth = output[\"bases_aligned\"] / output[\"contig_length\"],\n  coverage = output[\"bases_covered\"] / output[\"contig_length\"],\n  proportion_of_reads = output[\"reads_aligned\"] / output[\"specimen_total_reads\"]\n).reset_index(\n).rename(\n  columns = dict([(\"index\", \"contig\")])\n)\n\n# Write out as CSV\nlogging.info(\"Writing out to ${sample_name}.csv.gz\")\noutput.to_csv(\n  \"${sample_name}.csv.gz\", \n  index=None\n)\n\n  \"\"\"",
        "nb_lignes_script": 174,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_name",
            "idxstats",
            "stats",
            "pileup",
            "positions"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__pandas}\"",
            "label \"mem_medium\"",
            "errorStrategy 'retry'"
        ],
        "when": "",
        "stub": ""
    },
    "collect": {
        "name_process": "collect",
        "string_process": "\nprocess collect {\n  container \"${container__pandas}\"\n  label \"io_limited\"\n  errorStrategy 'retry'\n  publishDir params.output_folder\n\n  input:\n  file summary_csv_list\n\n  output:\n  file \"${params.output_prefix}.summary.csv.gz\"\n\n  \"\"\"\n#!/usr/bin/env python3\nimport logging\nimport os\nimport gzip\nimport json\nimport pandas as pd\n\nlogFormatter = logging.Formatter(\n    '%(asctime)s %(levelname)-8s [nf-viral-metagenomics] %(message)s'\n)\nrootLogger = logging.getLogger()\nrootLogger.setLevel(logging.INFO)\n\n# Write to STDOUT\nconsoleHandler = logging.StreamHandler()\nconsoleHandler.setFormatter(logFormatter)\nrootLogger.addHandler(consoleHandler)\n\nsummary_csv_list = \"${summary_csv_list}\".split(\" \")\nlogging.info(\"Reading in a list of %d summary CSV files\" % len(summary_csv_list))\nsummary_df = pd.concat([\n  pd.read_csv(fp)\n  for fp in summary_csv_list\n])\n\nlogging.info(\"Saving to ${params.output_prefix}.summary.csv.gz\")\nsummary_df.to_csv(\"${params.output_prefix}.summary.csv.gz\", index=None)\n\nlogging.info(\"Done\")\n\n\"\"\"\n\n}",
        "nb_lignes_process": 45,
        "string_script": "\"\"\"\n#!/usr/bin/env python3\nimport logging\nimport os\nimport gzip\nimport json\nimport pandas as pd\n\nlogFormatter = logging.Formatter(\n    '%(asctime)s %(levelname)-8s [nf-viral-metagenomics] %(message)s'\n)\nrootLogger = logging.getLogger()\nrootLogger.setLevel(logging.INFO)\n\n# Write to STDOUT\nconsoleHandler = logging.StreamHandler()\nconsoleHandler.setFormatter(logFormatter)\nrootLogger.addHandler(consoleHandler)\n\nsummary_csv_list = \"${summary_csv_list}\".split(\" \")\nlogging.info(\"Reading in a list of %d summary CSV files\" % len(summary_csv_list))\nsummary_df = pd.concat([\n  pd.read_csv(fp)\n  for fp in summary_csv_list\n])\n\nlogging.info(\"Saving to ${params.output_prefix}.summary.csv.gz\")\nsummary_df.to_csv(\"${params.output_prefix}.summary.csv.gz\", index=None)\n\nlogging.info(\"Done\")\n\n\"\"\"",
        "nb_lignes_script": 31,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "summary_csv_list"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__pandas}\"",
            "label \"io_limited\"",
            "errorStrategy 'retry'",
            "publishDir params.output_folder"
        ],
        "when": "",
        "stub": ""
    },
    "collect_with_kraken": {
        "name_process": "collect_with_kraken",
        "string_process": "\nprocess collect_with_kraken {\n  container \"${container__pandas}\"\n  label \"io_limited\"\n  errorStrategy 'retry'\n  publishDir params.output_folder\n\n  input:\n  file summary_csv_list\n  file kraken2_tsv\n\n  output:\n  file \"${params.output_prefix}.summary.csv.gz\"\n\n  \"\"\"\n#!/usr/bin/env python3\nimport logging\nimport os\nimport gzip\nimport json\nimport pandas as pd\n\nlogFormatter = logging.Formatter(\n    '%(asctime)s %(levelname)-8s [nf-viral-metagenomics] %(message)s'\n)\nrootLogger = logging.getLogger()\nrootLogger.setLevel(logging.INFO)\n\n# Write to STDOUT\nconsoleHandler = logging.StreamHandler()\nconsoleHandler.setFormatter(logFormatter)\nrootLogger.addHandler(consoleHandler)\n\nsummary_csv_list = \"${summary_csv_list}\".split(\" \")\nlogging.info(\"Reading in a list of %d summary CSV files\" % len(summary_csv_list))\nsummary_df = pd.concat([\n  pd.read_csv(fp)\n  for fp in summary_csv_list\n])\n\n# Read in the Kraken2 results\nkraken_df = pd.read_csv(\n  \"${kraken2_tsv}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\n    \"success\",\n    \"query\",\n    \"tax_id\",\n    \"query_len\",\n    \"hit_string\"\n  ]\n).query(\n  \"success == 'C'\"\n).drop(\n  columns=[\"success\", \"query_len\"]\n).set_index(\n  \"query\"\n)\n\n# Add the Kraken results to the summary DataFrame\nsummary_df = summary_df.assign(\n  tax_id = summary_df[\"contig\"].apply(\n    kraken_df[\"tax_id\"].get\n  ).fillna(\n    0\n  ).apply(\n    int\n  )\n)\nsummary_df = summary_df.assign(\n  hit_string = summary_df[\"contig\"].apply(\n    kraken_df[\"hit_string\"].get\n  )\n)\n\nlogging.info(\"Saving to ${params.output_prefix}.summary.csv.gz\")\nsummary_df.to_csv(\"${params.output_prefix}.summary.csv.gz\", index=None)\n\nlogging.info(\"Done\")\n\n\"\"\"\n\n}",
        "nb_lignes_process": 82,
        "string_script": "\"\"\"\n#!/usr/bin/env python3\nimport logging\nimport os\nimport gzip\nimport json\nimport pandas as pd\n\nlogFormatter = logging.Formatter(\n    '%(asctime)s %(levelname)-8s [nf-viral-metagenomics] %(message)s'\n)\nrootLogger = logging.getLogger()\nrootLogger.setLevel(logging.INFO)\n\n# Write to STDOUT\nconsoleHandler = logging.StreamHandler()\nconsoleHandler.setFormatter(logFormatter)\nrootLogger.addHandler(consoleHandler)\n\nsummary_csv_list = \"${summary_csv_list}\".split(\" \")\nlogging.info(\"Reading in a list of %d summary CSV files\" % len(summary_csv_list))\nsummary_df = pd.concat([\n  pd.read_csv(fp)\n  for fp in summary_csv_list\n])\n\n# Read in the Kraken2 results\nkraken_df = pd.read_csv(\n  \"${kraken2_tsv}\", \n  sep=\"\\\\t\", \n  header=None,\n  names = [\n    \"success\",\n    \"query\",\n    \"tax_id\",\n    \"query_len\",\n    \"hit_string\"\n  ]\n).query(\n  \"success == 'C'\"\n).drop(\n  columns=[\"success\", \"query_len\"]\n).set_index(\n  \"query\"\n)\n\n# Add the Kraken results to the summary DataFrame\nsummary_df = summary_df.assign(\n  tax_id = summary_df[\"contig\"].apply(\n    kraken_df[\"tax_id\"].get\n  ).fillna(\n    0\n  ).apply(\n    int\n  )\n)\nsummary_df = summary_df.assign(\n  hit_string = summary_df[\"contig\"].apply(\n    kraken_df[\"hit_string\"].get\n  )\n)\n\nlogging.info(\"Saving to ${params.output_prefix}.summary.csv.gz\")\nsummary_df.to_csv(\"${params.output_prefix}.summary.csv.gz\", index=None)\n\nlogging.info(\"Done\")\n\n\"\"\"",
        "nb_lignes_script": 67,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "summary_csv_list",
            "kraken2_tsv"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__pandas}\"",
            "label \"io_limited\"",
            "errorStrategy 'retry'",
            "publishDir params.output_folder"
        ],
        "when": "",
        "stub": ""
    },
    "kraken2": {
        "name_process": "kraken2",
        "string_process": "\nprocess kraken2 {\n  container \"${container__kraken2}\"\n  errorStrategy 'retry'\n  label \"mem_veryhigh\"\n\n  input:\n  file input_fasta\n  file \"DB/*\"\n  \n  output:\n  file \"${params.output_prefix}.kraken2.gz\"\n\n  \"\"\"\n#!/bin/bash\n\nset -e\n\nls -lahtr\n\nls -lahtr DB/\n\necho \"Running kraken2\"\n\nKRAKEN2_DB_PATH=\\$PWD kraken2 \\\n    --db DB \\\n    --threads ${task.cpus} \\\n    ${input_fasta} \\\n    | gzip -c > ${params.output_prefix}.kraken2.gz\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 31,
        "string_script": "\"\"\"\n#!/bin/bash\n\nset -e\n\nls -lahtr\n\nls -lahtr DB/\n\necho \"Running kraken2\"\n\nKRAKEN2_DB_PATH=\\$PWD kraken2 \\\n    --db DB \\\n    --threads ${task.cpus} \\\n    ${input_fasta} \\\n    | gzip -c > ${params.output_prefix}.kraken2.gz\n\n  \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "FredHutch__VMAA",
        "directive": [
            "container \"${container__kraken2}\"",
            "errorStrategy 'retry'",
            "label \"mem_veryhigh\""
        ],
        "when": "",
        "stub": ""
    }
}