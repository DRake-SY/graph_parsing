{
    "OPERATION_1": {
        "string": "ch_multiqc_custom_config = Channel.fromPath(params.multiqc_config, checkIfExists: true)",
        "origin": [
            [
                "params.multiqc_config, checkIfExists: true",
                "A"
            ]
        ],
        "gives": [
            [
                "ch_multiqc_custom_config",
                "P"
            ]
        ]
    },
    "OPERATION_2": {
        "string": "ch_multiqc_custom_config = Channel.empty()",
        "origin": [],
        "gives": [
            [
                "ch_multiqc_custom_config",
                "P"
            ]
        ]
    },
    "OPERATION_3": {
        "string": "ch_output_docs = Channel.fromPath(\"$baseDir/docs/output.md\")",
        "origin": [
            [
                "\"$baseDir/docs/output.md\"",
                "A"
            ]
        ],
        "gives": [
            [
                "ch_output_docs",
                "P"
            ]
        ]
    },
    "OPERATION_4": {
        "string": "Channel.from(summary.collect{ [it.key, it.value] })\n    .map { k,v -> \"<dt>$k</dt><dd><samp>${v ?: '<span style=\\\"color:#999999;\\\">N/A</a>'}</samp></dd>\" }\n    .reduce { a, b -> return [a, b].join(\"\\n            \") }\n    .map { x -> \"\"\"\n    id: 'nf-core-influenzangs-summary'\n    description: \" - this information is collected when the pipeline is started.\"\n    section_name: 'nf-core/influenzangs Workflow Summary'\n    section_href: 'https://github.com/nf-core/influenzangs'\n    plot_type: 'html'\n    data: |\n        <dl class=\\\"dl-horizontal\\\">\n            $x\n        </dl>\n    \"\"\".stripIndent() }\n    .set { ch_workflow_summary }",
        "origin": [
            [
                "summary.collect{ [it.key, it.value] }",
                "V"
            ]
        ],
        "gives": [
            [
                "ch_workflow_summary",
                "P"
            ]
        ]
    },
    "OPERATION_5": {
        "string": "Channel.fromFilePairs(params.reads)\n     .into { raw_reads_fastqc; raw_reads_trimgalore }",
        "origin": [
            [
                "params.reads",
                "A"
            ]
        ],
        "gives": [
            [
                "raw_reads_fastqc",
                "P"
            ],
            [
                "raw_reads_trimgalore",
                "P"
            ]
        ]
    },
    "OPERATION_6": {
        "string": "Channel.fromPath(params.genome)\n    .map{path -> [path.simpleName,path]}\n    .into{ labelled_reference_ch; reference_tosplit_ch }",
        "origin": [
            [
                "params.genome",
                "A"
            ]
        ],
        "gives": [
            [
                "labelled_reference_ch",
                "P"
            ],
            [
                "reference_tosplit_ch",
                "P"
            ]
        ]
    },
    "OPERATION_7": {
        "string": "summary.collect { k,v -> \"${k.padRight(18)}: $v\" }.join(\"\\n\")",
        "origin": [
            [
                "summary",
                "P"
            ]
        ],
        "gives": []
    },
    "OPERATION_8": {
        "string": "bwa_mem_input_ch = trimmed_samples_ch.combine(bwa_ref_ch)",
        "origin": [
            [
                "trimmed_samples_ch",
                "P"
            ],
            [
                "bwa_ref_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "bwa_mem_input_ch",
                "P"
            ]
        ]
    },
    "OPERATION_9": {
        "string": "bam_no_dup_ch.combine(gatk_mutect_reference_ch, by: 0)\n    .into{ GATK_input_mutect_ch; GATK_input_realign_ch }",
        "origin": [
            [
                "bam_no_dup_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "GATK_input_mutect_ch",
                "P"
            ],
            [
                "GATK_input_realign_ch",
                "P"
            ]
        ]
    },
    "OPERATION_10": {
        "string": "GATK_input_recalib_ch = GATK_output_mutect_ch.combine(GATK_output_realign_ch, by:[0,1])",
        "origin": [
            [
                "GATK_output_mutect_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "GATK_input_recalib_ch",
                "P"
            ]
        ]
    },
    "OPERATION_11": {
        "string": "split_reference_ch\n    .flatten()\n \t\t.map{path -> [path.simpleName,path]}\n    .into{ split_ref_ch; fastasize_input_ch; ref_make_cons_ch; ref_align_1_ch; ref_align_pre_ch; ref_dummy_align_ch }",
        "origin": [
            [
                "split_reference_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "split_ref_ch",
                "P"
            ],
            [
                "fastasize_input_ch",
                "P"
            ],
            [
                "ref_make_cons_ch",
                "P"
            ],
            [
                "ref_align_1_ch",
                "P"
            ],
            [
                "ref_align_pre_ch",
                "P"
            ],
            [
                "ref_dummy_align_ch",
                "P"
            ]
        ]
    },
    "OPERATION_12": {
        "string": "split_bam_ch\n \t\t.flatten()\n \t\t.map{file -> [file.getFileName().toString().split(\"\\\\.\")[1], file.getFileName().toString().split(\"\\\\.\")[0], file]}\n \t\t.combine(split_ref_ch, by:0)\n    .into{ mpileup_input_ch; cov_input_nosize_ch; bam_choose_consensus_ch; bcftools_bam_ch }",
        "origin": [
            [
                "split_bam_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "mpileup_input_ch",
                "P"
            ],
            [
                "cov_input_nosize_ch",
                "P"
            ],
            [
                "bam_choose_consensus_ch",
                "P"
            ],
            [
                "bcftools_bam_ch",
                "P"
            ]
        ]
    },
    "OPERATION_13": {
        "string": "cov_input_ch = cov_input_nosize_ch\n \t\t.combine(split_fasta_size_ch, by:0)",
        "origin": [
            [
                "cov_input_nosize_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "cov_input_ch",
                "P"
            ]
        ]
    },
    "OPERATION_14": {
        "string": "ref_align_2_ch = ref_align_pre_ch\n    .join(fasta_size_align_ch, by:0)\n    .map{refseg, fastafile, fastasizes-> [refseg.split(\"_\")[1], fastafile, fastasizes]}",
        "origin": [
            [
                "ref_align_pre_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "ref_align_2_ch",
                "P"
            ]
        ]
    },
    "OPERATION_15": {
        "string": "reference_to_align_ch = ref_align_1_ch\n    .map{refseg, fastafile -> [refseg.split(\"_\")[1], fastafile]}\n    .combine(ref_align_2_ch, by:0)\n    .filter { it[1] != it[2]}",
        "origin": [
            [
                "ref_align_1_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "reference_to_align_ch",
                "P"
            ]
        ]
    },
    "OPERATION_16": {
        "string": "aligned_references_ch = dummy_align_out_ch\n  .map{covfile, refseg -> [covfile, refseg.split(\"_\")[1]]}\n  .concat(aligned_references_true_ch)",
        "origin": [
            [
                "dummy_align_out_ch",
                "P"
            ],
            [
                "aligned_references_true_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "aligned_references_ch",
                "P"
            ]
        ]
    },
    "OPERATION_17": {
        "string": "grouped_bam_choose_ch = bam_choose_consensus_ch\n    .map{refseg,id,bam,refsegfasta -> [id,refseg.split(\"_\")[1],bam,refsegfasta]}\n    .groupTuple(by:[0,1])",
        "origin": [
            [
                "bam_choose_consensus_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "grouped_bam_choose_ch",
                "P"
            ]
        ]
    },
    "OPERATION_18": {
        "string": "grouped_cov_summary_choose_ch = cov_summary_choose_consensus_ch\n    .map{id,refseg,covsum -> [id,refseg.split(\"_\")[1],covsum]}\n    .groupTuple(by:[0,1])",
        "origin": [
            [
                "cov_summary_choose_consensus_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "grouped_cov_summary_choose_ch",
                "P"
            ]
        ]
    },
    "OPERATION_19": {
        "string": "grouped_cov_choose_ch = cov_choose_consensus_ch\n    .map{id,refseg,covsum -> [id,refseg.split(\"_\")[1],covsum]}\n    .groupTuple(by:[0,1])",
        "origin": [
            [
                "cov_choose_consensus_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "grouped_cov_choose_ch",
                "P"
            ]
        ]
    },
    "OPERATION_20": {
        "string": "grouped_aligned_references_ch = aligned_references_ch\n      .groupTuple(by: 1)",
        "origin": [
            [
                "aligned_references_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "grouped_aligned_references_ch",
                "P"
            ]
        ]
    },
    "OPERATION_21": {
        "string": "choose_consensus_input_ch = grouped_bam_choose_ch\n    .combine(grouped_cov_summary_choose_ch, by:[0,1])\n    .combine(grouped_cov_choose_ch, by:[0,1])\n    .combine(grouped_aligned_references_ch, by: 1)",
        "origin": [
            [
                "grouped_bam_choose_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "choose_consensus_input_ch",
                "P"
            ]
        ]
    },
    "OPERATION_22": {
        "string": "finalchosen_ch\n    .splitCsv()\n    .flatten()\n    .map{text -> [text.split(\"\\\\.\")[0], text.split(\"\\\\.\")[1], text.split(\"\\\\.\")[2]]}\n    .into{ consensus_keys_ch ; chosen_drop_filter_ch}",
        "origin": [
            [
                "finalchosen_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "consensus_keys_ch",
                "P"
            ],
            [
                "chosen_drop_filter_ch",
                "P"
            ]
        ]
    },
    "OPERATION_23": {
        "string": "chosen_drop_filter_ch\n    .map{ id, refseg, state -> [id, refseg] }\n    .into{varscan_keys_ch; bcftools_keys_ch; bamdepth_keys_ch}",
        "origin": [
            [
                "chosen_drop_filter_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "varscan_keys_ch",
                "P"
            ],
            [
                "bcftools_keys_ch",
                "P"
            ],
            [
                "bamdepth_keys_ch",
                "P"
            ]
        ]
    },
    "OPERATION_24": {
        "string": "make_consensus_input_ch = consensus_keys_ch\n    .combine(mpileup_make_consensus_ch, by: [0,1])\n    .map{ id,refseg, state, mpileupfile -> [refseg,id,state,mpileupfile] }\n    .combine(ref_make_cons_ch, by:0 )",
        "origin": [
            [
                "consensus_keys_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "make_consensus_input_ch",
                "P"
            ]
        ]
    },
    "OPERATION_25": {
        "string": "grouped_consensus_to_concat_ch = consensus_to_concat_ch\n    .filter { it[1] == \"PASS\" }\n    .map{ id,state,file -> [id,file] }\n    .groupTuple()",
        "origin": [
            [
                "consensus_to_concat_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "grouped_consensus_to_concat_ch",
                "P"
            ]
        ]
    },
    "OPERATION_26": {
        "string": "chosen_varscan_ch = varscan_keys_ch.combine(mpileup_varscan_ch, by:[0,1])",
        "origin": [
            [
                "varscan_keys_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "chosen_varscan_ch",
                "P"
            ]
        ]
    },
    "OPERATION_27": {
        "string": "chosen_bcftools_ch = bcftools_keys_ch\n    .map{id,refseg -> [refseg,id]}\n    .combine(bcftools_bam_ch, by:[0,1])",
        "origin": [
            [
                "bcftools_keys_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "chosen_bcftools_ch",
                "P"
            ]
        ]
    },
    "OPERATION_28": {
        "string": "varscan_combine_ch = vcf_varscan_ch\n    .groupTuple()\n    .map { id, file -> [id, file.flatten(), \"varscan\"]}",
        "origin": [
            [
                "vcf_varscan_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "varscan_combine_ch",
                "P"
            ]
        ]
    },
    "OPERATION_29": {
        "string": "varscan_bcftools_ch = vcf_bcftools_ch\n    .groupTuple()\n    .map{ id, file -> [id, file.flatten(), \"bcftools\"]}",
        "origin": [
            [
                "vcf_bcftools_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "varscan_bcftools_ch",
                "P"
            ]
        ]
    },
    "OPERATION_30": {
        "string": "vcf_concat_input_ch = varscan_combine_ch\n    .concat(varscan_bcftools_ch)",
        "origin": [
            [
                "varscan_combine_ch",
                "P"
            ],
            [
                "varscan_bcftools_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "vcf_concat_input_ch",
                "P"
            ]
        ]
    },
    "OPERATION_31": {
        "string": "groupedplotchosen_ch = plotchosen_ch\n    .map{file->[file.getFileName().toString().split(\"\\\\.\")[1],file]}\n    .groupTuple()",
        "origin": [
            [
                "plotchosen_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "groupedplotchosen_ch",
                "P"
            ]
        ]
    },
    "OPERATION_32": {
        "string": "Rplotin_ch = cov_summary_plot_ch\n    .map{id,refseg,covsum -> [refseg.split(\"_\")[1],covsum]}\n    .groupTuple()\n    .combine(groupedplotchosen_ch, by: 0)",
        "origin": [
            [
                "cov_summary_plot_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "Rplotin_ch",
                "P"
            ]
        ]
    },
    "OPERATION_33": {
        "string": "count_input_ch = bwa_count_ch\n\t\t.combine(gatk_count_ch,by:[0,1])\n\t\t.groupTuple( by:0,sort:true )\n\t\t.combine(sample_count_ch, by:0)",
        "origin": [
            [
                "bwa_count_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "count_input_ch",
                "P"
            ]
        ]
    },
    "OPERATION_34": {
        "string": "depth_input_ch = bamdepth_keys_ch\n    .combine(cov_graph_ch, by:[0,1])",
        "origin": [
            [
                "bamdepth_keys_ch",
                "P"
            ]
        ],
        "gives": [
            [
                "depth_input_ch",
                "P"
            ]
        ]
    }
}