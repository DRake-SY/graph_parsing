{
    "FASTQC": {
        "name_process": "FASTQC",
        "string_process": "\nprocess FASTQC {\n    tag \"$meta.id\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\"\n    } else {\n        container \"quay.io/biocontainers/fastqc:0.11.9--0\"\n    }\n\n    input:\n    tuple val(meta), path(reads)\n\n    output:\n    tuple val(meta), path(\"*.html\"), emit: html\n    tuple val(meta), path(\"*.zip\") , emit: zip\n    path  \"*.version.txt\"          , emit: version\n\n    script:\n                                                                          \n    def software = getSoftwareName(task.process)\n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}.fastq.gz\n        fastqc --version | sed -e \"s/FastQC v//g\" > ${software}.version.txt\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n        fastqc --version | sed -e \"s/FastQC v//g\" > ${software}.version.txt\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 40,
        "string_script": "    def software = getSoftwareName(task.process)\n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}.fastq.gz\n        fastqc --version | sed -e \"s/FastQC v//g\" > ${software}.version.txt\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n        fastqc --version | sed -e \"s/FastQC v//g\" > ${software}.version.txt\n        \"\"\"\n    }",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\" } else { container \"quay.io/biocontainers/fastqc:0.11.9--0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "GET_SOFTWARE_VERSIONS": {
        "name_process": "GET_SOFTWARE_VERSIONS",
        "string_process": "\nprocess GET_SOFTWARE_VERSIONS {\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/python:3.8.3\"\n    } else {\n        container \"quay.io/biocontainers/python:3.8.3\"\n    }\n\n    cache false\n\n    input:\n    path versions\n\n    output:\n    path \"software_versions.tsv\"     , emit: tsv\n    path 'software_versions_mqc.yaml', emit: yaml\n\n    script:                                                                  \n    \"\"\"\n    echo $workflow.manifest.version > pipeline.version.txt\n    echo $workflow.nextflow.version > nextflow.version.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > pipeline.version.txt\n    echo $workflow.nextflow.version > nextflow.version.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "versions"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/python:3.8.3\" } else { container \"quay.io/biocontainers/python:3.8.3\" }",
            "cache false"
        ],
        "when": "",
        "stub": ""
    },
    "PREPERE_EXP_BED": {
        "name_process": "PREPERE_EXP_BED",
        "string_process": "\nprocess PREPERE_EXP_BED {\n  label 'process_low'\n  tag {condition}\n  if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n      container \"/software/hgi/containers/eqtl.img\"\n      \n  } else {\n      container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n  }\n\n\n  input:\n    tuple(val(condition),path(mapping_file),path(expression_file),path(phenotype_pcs) )\n    each path(annotation_file)\n    each path(genotype_pcs)\n\n  output:\n    tuple(val(condition),path(\"Expression_Data.bed.gz\"),path('Covariates.tsv'), emit: exp_bed)\n\n  script:\n\n    if(params.sample_covariates==''){\n      sample_covar =''\n    }else{\n      sample_covar =\"--sample_covariates ${params.sample_covariates}\"\n    }\n    \"\"\"\n      echo ${condition}\n      prepere_bed.py --annotation_file ${annotation_file} --mapping_file ${mapping_file} --expression_file ${expression_file}\n      prepere_covariates_file.py --genotype_pcs ${genotype_pcs} --phenotype_pcs ${phenotype_pcs} ${sample_covar} --sample_mapping ${mapping_file}\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    if(params.sample_covariates==''){\n      sample_covar =''\n    }else{\n      sample_covar =\"--sample_covariates ${params.sample_covariates}\"\n    }\n    \"\"\"\n      echo ${condition}\n      prepere_bed.py --annotation_file ${annotation_file} --mapping_file ${mapping_file} --expression_file ${expression_file}\n      prepere_covariates_file.py --genotype_pcs ${genotype_pcs} --phenotype_pcs ${phenotype_pcs} ${sample_covar} --sample_mapping ${mapping_file}\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "condition",
            "mapping_file",
            "expression_file",
            "phenotype_pcs",
            "annotation_file",
            "genotype_pcs"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "label 'process_low'",
            "tag {condition} if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "PREPROCESS_GENOTYPES": {
        "name_process": "PREPROCESS_GENOTYPES",
        "string_process": "process PREPROCESS_GENOTYPES{\n    \n                                                         \n                                                                               \n                        \n                                                  \n    scratch false                          \n    label 'process_medium'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n        \n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n        path(file__vcf)\n    output:\n        path(\"filtered_vcf.vcf.gz\") , emit: filtered_vcf\n    script:\n        \"\"\"\n            bcftools view --known ${params.bcftools_filters}  --min-af ${params.maf}:minor ${file__vcf} -O z -o filtered_vcf.vcf.gz\n            \n        \"\"\"\n    \n}",
        "nb_lignes_process": 24,
        "string_script": "        \"\"\"\n            bcftools view --known ${params.bcftools_filters}  --min-af ${params.maf}:minor ${file__vcf} -O z -o filtered_vcf.vcf.gz\n            \n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "file__vcf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "scratch false",
            "label 'process_medium' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "CHUNK_GENOME": {
        "name_process": "CHUNK_GENOME",
        "string_process": "process CHUNK_GENOME{\n    \n                                                         \n                                                                               \n                        \n                                                  \n    tag{condition}\n    scratch false                          \n    label 'process_low'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n        \n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n        each path(genome_annotation)\n        tuple(val(condition),path(phenotype_file), path(pcs))\n    output:\n                                                              \n                                                                                 \n        tuple val(condition),path(\"Chunging_file.tsv\"),path('annotation_file_processed.tsv'),path(phenotype_file), path(pcs) , emit: filtered_chunking_file\n        path('limix_chunking.tsv'), emit: limix_condition_chunking\n    script:\n        \"\"\"\n            generate_chunking_file.py --genome_annotation ${genome_annotation} --chunk_size ${params.chunkSize} --phenotype_file ${phenotype_file} --covar_file ${pcs} --condition ${condition}\n        \"\"\"\n    \n}",
        "nb_lignes_process": 28,
        "string_script": "        \"\"\"\n            generate_chunking_file.py --genome_annotation ${genome_annotation} --chunk_size ${params.chunkSize} --phenotype_file ${phenotype_file} --covar_file ${pcs} --condition ${condition}\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_annotation",
            "condition",
            "phenotype_file",
            "pcs"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag{condition}",
            "scratch false",
            "label 'process_low' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "TENSORQTL": {
        "name_process": "TENSORQTL",
        "string_process": "\nprocess TENSORQTL {\n    label 'gpu'\n    tag {condition}\n                                  \n    \n                                                                                                 \n    publishDir  path: \"${params.outdir}/TensorQTL_eQTLS/${condition}\",\n                overwrite: \"true\"\n  \n\n  if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n                                                                                                               \n    container \"/software/hgi/containers/eqtl.img\"\n  } else {\n    container \"wtsihgi/nf_cellbender_container:3cc9983\"\n  }\n\n\n  input:\n    tuple(val(condition),path(aggrnorm_counts_bed),path(genotype_pcs_tsv))\n                                  \n    each path(plink_files_prefix)\n\n  output:\n                                                                \n                                                                            \n                                                                      \n    path(\"Cis_eqtls.tsv\"), emit: qtl_bin\n    path(\"Cis_eqtls_qval.tsv\"), emit: q_qtl_bin\n\n  script:\n\n    \n    \n    \"\"\"\n      tensorqtl_analyse.py --plink_prefix_path ${plink_files_prefix}/plink_genotypes --expression_bed ${aggrnorm_counts_bed} --covariates_file ${genotype_pcs_tsv} -window ${params.windowSize} -nperm ${params.numberOfPermutations}\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n      tensorqtl_analyse.py --plink_prefix_path ${plink_files_prefix}/plink_genotypes --expression_bed ${aggrnorm_counts_bed} --covariates_file ${genotype_pcs_tsv} -window ${params.windowSize} -nperm ${params.numberOfPermutations}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "condition",
            "aggrnorm_counts_bed",
            "genotype_pcs_tsv",
            "plink_files_prefix"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "label 'gpu'",
            "tag {condition}",
            "publishDir path: \"${params.outdir}/TensorQTL_eQTLS/${condition}\" , overwrite: \"true\" if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"wtsihgi/nf_cellbender_container:3cc9983\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMPLESHEET_CHECK": {
        "name_process": "SAMPLESHEET_CHECK",
        "string_process": "\nprocess SAMPLESHEET_CHECK {\n    tag \"$samplesheet\"\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/python:3.8.3\"\n    } else {\n        container \"quay.io/biocontainers/python:3.8.3\"\n    }\n\n    input:\n    path samplesheet\n\n    output:\n    path '*.csv'\n\n    script:                                                                  \n    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplesheet"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag \"$samplesheet\"",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/python:3.8.3\" } else { container \"quay.io/biocontainers/python:3.8.3\" }"
        ],
        "when": "",
        "stub": ""
    },
    "KINSHIP_CALCULATION": {
        "name_process": "KINSHIP_CALCULATION",
        "string_process": "\nprocess KINSHIP_CALCULATION {\n    tag \"${samplename}.${sample_subset_file}\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/subset_genotype/\", mode: \"${params.copy_mode}\", pattern: \"${samplename}.${sample_subset_file}.subset.vcf.gz\"\n    \n    \n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n    } else {\n        log.info 'change the docker container - this is not the right one'\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n\n    input:\n        path(plink_path)\n\n    output:\n    \n        path(\"kinship_matrix.tsv\"), emit: kinship_matrix\n\n    script:\n        \"\"\"\n            plink2 --freq counts --bfile ${plink_path}/plink_genotypes --out tmp_gt_plink_freq\n            plink2 --make-rel square --read-freq tmp_gt_plink_freq.acount --bfile ${plink_path}/plink_genotypes\n            generate_kinship.py\n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        \"\"\"\n            plink2 --freq counts --bfile ${plink_path}/plink_genotypes --out tmp_gt_plink_freq\n            plink2 --make-rel square --read-freq tmp_gt_plink_freq.acount --bfile ${plink_path}/plink_genotypes\n            generate_kinship.py\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plink_path"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag \"${samplename}.${sample_subset_file}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/subset_genotype/\", mode: \"${params.copy_mode}\", pattern: \"${samplename}.${sample_subset_file}.subset.vcf.gz\" if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { log.info 'change the docker container - this is not the right one' container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "COLLECT_RESULTS": {
        "name_process": "COLLECT_RESULTS",
        "string_process": "\nprocess COLLECT_RESULTS{\n     tag { condition }\n    \n    input:\n        val(full_output_list)\n                                                                                                                 \n        tuple(val(condition),path(phenotypeFile),path(covariateFile))\n\n    output:\n        path(\"${condition}\"), emit: condition_all_qtls\n    script:\n        full_output_list=full_output_list.join(\"\\n\")\n        \"\"\"\n\n        echo -e \"${full_output_list}\">out.txt\n        link_files.py --files_input out.txt --condition ${condition}\n        \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "        full_output_list=full_output_list.join(\"\\n\")\n        \"\"\"\n\n        echo -e \"${full_output_list}\">out.txt\n        link_files.py --files_input out.txt --condition ${condition}\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "full_output_list",
            "condition",
            "phenotypeFile",
            "covariateFile"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag { condition }"
        ],
        "when": "",
        "stub": ""
    },
    "AGGREGATE_QTL_RESULTS": {
        "name_process": "AGGREGATE_QTL_RESULTS",
        "string_process": "\nprocess AGGREGATE_QTL_RESULTS{\n    tag { condition }\n    scratch false                          \n    label 'process_low'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }    \n    \n\n    publishDir  path: \"${params.outdir}/Limix_eQTLS\",\n                mode: \"${params.copy_mode}\",\n                overwrite: \"true\"\n\n    input:\n        path(all_qtl_results)\n        \n        \n    output:\n        path(\"${all_qtl_results}_qtls\"), emit: limix_qtl_path\n                                                                                                \n                                                                                                        \n                                          \n    script:\n        \n        \"\"\"\n            export NUMBA_CACHE_DIR=/tmp\n            export MPLCONFIGDIR=/tmp\n            mkdir ${all_qtl_results}_all\n            \n            minimal_postprocess.py -id ${all_qtl_results} -od ${all_qtl_results}_all -sfo -tfb \n            minimal_postprocess.py -id ${all_qtl_results} -od ${all_qtl_results}_all -sfo -mrp 0.05 \n\n            cp -Lr ${all_qtl_results}_all ${all_qtl_results}_qtls\n        \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "        \"\"\"\n            export NUMBA_CACHE_DIR=/tmp\n            export MPLCONFIGDIR=/tmp\n            mkdir ${all_qtl_results}_all\n            \n            minimal_postprocess.py -id ${all_qtl_results} -od ${all_qtl_results}_all -sfo -tfb \n            minimal_postprocess.py -id ${all_qtl_results} -od ${all_qtl_results}_all -sfo -mrp 0.05 \n\n            cp -Lr ${all_qtl_results}_all ${all_qtl_results}_qtls\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_qtl_results"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag { condition }",
            "scratch false",
            "label 'process_low' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }",
            "publishDir path: \"${params.outdir}/Limix_eQTLS\" , mode: \"${params.copy_mode}\" , overwrite: \"true\""
        ],
        "when": "",
        "stub": ""
    },
    "TEST": {
        "name_process": "TEST",
        "string_process": "\nprocess TEST{\n    tag { condition }\n    input:\n        each chunking_range\n        tuple(val(condition),path(phenotypeFile),path(covariateFile))\n        each path(genotypeFile)\n        each path(annotationFile)\n\n    output:\n        path(\"out.txt\"), emit: filtered_vcf\n    script:\n        \n        \"\"\"\n        echo \"${chunking_range}\">out.txt\n        multiCorrect.R ${}\n        \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "        \"\"\"\n        echo \"${chunking_range}\">out.txt\n        multiCorrect.R ${}\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "chunking_range",
            "condition",
            "phenotypeFile",
            "covariateFile",
            "genotypeFile",
            "annotationFile"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag { condition }"
        ],
        "when": "",
        "stub": ""
    },
    "MULTIPLE_TESTING_CORRECTION": {
        "name_process": "MULTIPLE_TESTING_CORRECTION",
        "string_process": "\nprocess MULTIPLE_TESTING_CORRECTION{\n    label 'process_low'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }    \n        \n    input:\n        path(limix_qtl_path)\n\n\n    output:\n        path(\"${limix_qtl_path}/qtl_results_all_FDR*\"), emit: filtered_vcf\n    script:\n        \n        \"\"\"\n            multiCorrect.R ${limix_qtl_path}\n        \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "        \"\"\"\n            multiCorrect.R ${limix_qtl_path}\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "limix_qtl_path"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "label 'process_low' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "LIMIX": {
        "name_process": "LIMIX",
        "string_process": "\nprocess LIMIX{\n    \n                                                         \n                                                                               \n    tag { \"${condition} ${chunking_range2}\" }\n                                                  \n                                              \n    label 'process_low'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n        tuple(val(chunking_range),val(condition),path(phenotypeFile),path(covariateFile),path(annotationFile),path(genotypeFile),path(kinship_path),path(individual2sample_filename))\n        \n        \n        \n        \n    output:\n        tuple(path(\"${condition}_snp_metadata*\"),path(\"${condition}_qtl_results_*\"),path(\"${condition}_feature_metadata_*\") , emit: qtl_data)\n    script:\n        numberOfPermutations = params.numberOfPermutations\n        minorAlleleFrequency = params.maf\n        hwe = params.hwe\n        callRate = 0.95\n        windowSize = params.windowSize \n        blockSize = 1500\n\n        outputFolder='./'\n        chunking_range=\"${chunking_range}\"\n        chunking_range=chunking_range.replaceAll('\\\\[', \"\")\n        chunking_range=chunking_range.replaceAll('\\\\]', \"\")\n        chunking_range2 = chunking_range.replaceAll(':', \"_\").replaceAll('-', \"_\")\n        \"\"\"\n            export NUMBA_CACHE_DIR=/tmp\n            export MPLCONFIGDIR=/tmp\n            limix_run --plink ${genotypeFile}/plink_genotypes -af ${annotationFile} -pf ${phenotypeFile} -cf ${covariateFile} -od ${outputFolder} -smf ${individual2sample_filename} -rf ${kinship_path} -gr ${chunking_range} -np ${numberOfPermutations} -maf ${minorAlleleFrequency} -hwe ${hwe} -cr ${callRate} -c -gm standardize -w ${windowSize} --block_size ${blockSize}\n            ln -s snp_metadata_${chunking_range2}.txt ${condition}_snp_metadata_${chunking_range2}.txt\n            ln -s qtl_results_${chunking_range2}.h5 ${condition}_qtl_results_${chunking_range2}.h5\n            ln -s feature_metadata_${chunking_range2}.txt ${condition}_feature_metadata_${chunking_range2}.txt\n        \"\"\"\n    \n}",
        "nb_lignes_process": 44,
        "string_script": "        numberOfPermutations = params.numberOfPermutations\n        minorAlleleFrequency = params.maf\n        hwe = params.hwe\n        callRate = 0.95\n        windowSize = params.windowSize \n        blockSize = 1500\n\n        outputFolder='./'\n        chunking_range=\"${chunking_range}\"\n        chunking_range=chunking_range.replaceAll('\\\\[', \"\")\n        chunking_range=chunking_range.replaceAll('\\\\]', \"\")\n        chunking_range2 = chunking_range.replaceAll(':', \"_\").replaceAll('-', \"_\")\n        \"\"\"\n            export NUMBA_CACHE_DIR=/tmp\n            export MPLCONFIGDIR=/tmp\n            limix_run --plink ${genotypeFile}/plink_genotypes -af ${annotationFile} -pf ${phenotypeFile} -cf ${covariateFile} -od ${outputFolder} -smf ${individual2sample_filename} -rf ${kinship_path} -gr ${chunking_range} -np ${numberOfPermutations} -maf ${minorAlleleFrequency} -hwe ${hwe} -cr ${callRate} -c -gm standardize -w ${windowSize} --block_size ${blockSize}\n            ln -s snp_metadata_${chunking_range2}.txt ${condition}_snp_metadata_${chunking_range2}.txt\n            ln -s qtl_results_${chunking_range2}.h5 ${condition}_qtl_results_${chunking_range2}.h5\n            ln -s feature_metadata_${chunking_range2}.txt ${condition}_feature_metadata_${chunking_range2}.txt\n        \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "GraphWeb"
        ],
        "tools_url": [
            "https://bio.tools/graphweb"
        ],
        "tools_dico": [
            {
                "name": "GraphWeb",
                "uri": "https://bio.tools/graphweb",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3366",
                            "term": "Data integration and warehousing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Gene and protein families"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3473",
                            "term": "Data mining"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Genes, gene family or system"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3459",
                                    "term": "Functional clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2497",
                                    "term": "Pathway or network analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3695",
                                    "term": "Filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3459",
                                    "term": "Functional sequence clustering"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2600",
                                "term": "Pathway or network"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2984",
                                "term": "Pathway or network report"
                            }
                        ]
                    }
                ],
                "description": "Public web server for graph-based analysis of biological networks that: analyses directed and undirected, weighted and unweighted heterogeneous networks of genes, proteins and microarray probesets for many eukaryotic genomes; integrates multiple diverse datasets into global networks; incorporates multispecies data; filters nodes and edges; detects gene modules from networks; interprets discovered modules.",
                "homepage": "http://biit.cs.ut.ee/graphweb"
            }
        ],
        "inputs": [
            "chunking_range",
            "condition",
            "phenotypeFile",
            "covariateFile",
            "annotationFile",
            "genotypeFile",
            "kinship_path",
            "individual2sample_filename"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag { \"${condition} ${chunking_range2}\" }",
            "label 'process_low' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SUBSET_GENOTYPE": {
        "name_process": "SUBSET_GENOTYPE",
        "string_process": "\nprocess SUBSET_GENOTYPE {\n    tag \"${samplename}.${sample_subset_file}\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/subset_genotype/\", mode: \"${params.copy_mode}\", pattern: \"${samplename}.${sample_subset_file}.subset.vcf.gz\"\n    \n    \n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n    } else {\n        log.info 'change the docker container - this is not the right one'\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n\n    input:\n        path(donor_vcf)\n        val(file__reduced_dims)\n\n\n    output:\n    \n        path(\"${samplename}.subset.vcf.gz\"), emit: samplename_subsetvcf\n\n    script:\n        file__reduced_dims = file__reduced_dims.join(\",\")\n        samplename='subset'\n        \"\"\"\n            tabix -p vcf ${donor_vcf} || echo 'not typical VCF'\n            bcftools view ${donor_vcf} -s ${file__reduced_dims} --force-samples -Oz -o ${samplename}.subset.vcf.gz\n            rm ${donor_vcf}.tbi || echo 'not typical VCF'\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "        file__reduced_dims = file__reduced_dims.join(\",\")\n        samplename='subset'\n        \"\"\"\n            tabix -p vcf ${donor_vcf} || echo 'not typical VCF'\n            bcftools view ${donor_vcf} -s ${file__reduced_dims} --force-samples -Oz -o ${samplename}.subset.vcf.gz\n            rm ${donor_vcf}.tbi || echo 'not typical VCF'\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "donor_vcf",
            "file__reduced_dims"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag \"${samplename}.${sample_subset_file}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/subset_genotype/\", mode: \"${params.copy_mode}\", pattern: \"${samplename}.${sample_subset_file}.subset.vcf.gz\" if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { log.info 'change the docker container - this is not the right one' container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "GENOTYPE_PC_CALCULATION": {
        "name_process": "GENOTYPE_PC_CALCULATION",
        "string_process": "\nprocess GENOTYPE_PC_CALCULATION {\n    tag \"${samplename}.${sample_subset_file}\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/subset_genotype/\", mode: \"${params.copy_mode}\", pattern: \"${samplename}.${sample_subset_file}.subset.vcf.gz\"\n    \n    \n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n    } else {\n        log.info 'change the docker container - this is not the right one'\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n\n    input:\n        path(plink_bed)\n\n    output:\n    \n        path(\"gtpca_plink.eigenvec\"), emit: gtpca_plink\n\n    script:\n\n        \"\"\"\n            plink2 --freq counts --bfile ${plink_bed}/plink_genotypes --out tmp_gt_plink_freq\n            plink2 --pca --read-freq tmp_gt_plink_freq.acount  --bfile ${plink_bed}/plink_genotypes --out gtpca_plink\n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        \"\"\"\n            plink2 --freq counts --bfile ${plink_bed}/plink_genotypes --out tmp_gt_plink_freq\n            plink2 --pca --read-freq tmp_gt_plink_freq.acount  --bfile ${plink_bed}/plink_genotypes --out gtpca_plink\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plink_bed"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag \"${samplename}.${sample_subset_file}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/subset_genotype/\", mode: \"${params.copy_mode}\", pattern: \"${samplename}.${sample_subset_file}.subset.vcf.gz\" if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { log.info 'change the docker container - this is not the right one' container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "NORMALISE_and_PCA_PHENOTYPE": {
        "name_process": "NORMALISE_and_PCA_PHENOTYPE",
        "string_process": "process NORMALISE_and_PCA_PHENOTYPE{\n     \n                                                         \n                                                                               \n    tag { condition }\n                                                  \n    scratch false                          \n    label 'process_medium'\n\n    publishDir  path: \"${params.outdir}/norm_data/${condition}\",\n                mode: \"${params.copy_mode}\",\n                overwrite: \"true\"\n\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n        \n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n        tuple(val(condition),path(phenotype_file))\n        path(grouping_file)\n        \n    output:\n        tuple(val(condition),path(\"normalised_phenotype.tsv\"), path(\"pcs.tsv\") , emit: filtered_phenotype)\n        tuple(val(condition),path(grouping_file),path(\"normalised_phenotype.tsv\"),path(\"pcs.tsv\"), emit: for_bed)\n        val(condition), emit: cond1\n        path(\"*.pdf\")\n        path(phenotype_file)\n    script:\n    \n        \"\"\"  \n            normalise_and_pca.R ${phenotype_file} ${grouping_file} ${params.filter_method}\n        \"\"\"\n    \n}",
        "nb_lignes_process": 35,
        "string_script": "        \"\"\"  \n            normalise_and_pca.R ${phenotype_file} ${grouping_file} ${params.filter_method}\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "condition",
            "phenotype_file",
            "grouping_file"
        ],
        "nb_inputs": 3,
        "outputs": [
            "phenotype_file"
        ],
        "nb_outputs": 1,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag { condition }",
            "scratch false",
            "label 'process_medium'",
            "publishDir path: \"${params.outdir}/norm_data/${condition}\" , mode: \"${params.copy_mode}\" , overwrite: \"true\" if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "PREPROCESS_SAMPLE_MAPPING": {
        "name_process": "PREPROCESS_SAMPLE_MAPPING",
        "string_process": "process PREPROCESS_SAMPLE_MAPPING{\n    \n                                                         \n                                                                               \n                        \n                                                  \n    scratch false                          \n    label 'process_low'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n        \n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n        path(genotype_phenotype)\n    output:\n        path(\"genotype_phenotype.tsv\") , emit: genotype_phenotype\n    script:\n        \"\"\"\n        \n          genotype_phenotype_preprocess.py --genotype_phenotype ${genotype_phenotype}\n        \"\"\"\n    \n}",
        "nb_lignes_process": 24,
        "string_script": "        \"\"\"\n        \n          genotype_phenotype_preprocess.py --genotype_phenotype ${genotype_phenotype}\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genotype_phenotype"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "scratch false",
            "label 'process_low' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "PLINK_CONVERT": {
        "name_process": "PLINK_CONVERT",
        "string_process": "process PLINK_CONVERT{\n    \n                                                         \n                                                                               \n                        \n                                                  \n                      \n                   \n                             \n    scratch false                          \n    label 'process_medium'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n        \n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n        path(file__vcf)\n    output:\n        path(\"plink_genotypes\"), emit: plink_path\n    script:\n        \"\"\"\n            mkdir plink_genotypes\n            plink2 --make-bed ${params.plink2_filters} --hwe ${params.hwe} --vcf ${file__vcf} --out plink_genotypes/plink_genotypes\n        \"\"\"\n    \n}",
        "nb_lignes_process": 27,
        "string_script": "        \"\"\"\n            mkdir plink_genotypes\n            plink2 --make-bed ${params.plink2_filters} --hwe ${params.hwe} --vcf ${file__vcf} --out plink_genotypes/plink_genotypes\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "file__vcf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "scratch false",
            "label 'process_medium' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SPLIT_PHENOTYPE_DATA": {
        "name_process": "SPLIT_PHENOTYPE_DATA",
        "string_process": "process SPLIT_PHENOTYPE_DATA{\n    \n                                                         \n                                                                               \n                        \n                                                  \n\n    tag{condition}\n    scratch false                          \n    label 'process_low'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n        \n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n        path(annotation_file)\n        path(phenotype_file)\n        val(condition)\n    output:\n        tuple val(condition),path(\"*_phenotype.tsv\"), emit: phenotye_file\n        \n    script:\n        \n        \"\"\"\n            split_phenotype_for_condition.py --condition '${condition}' --genome_phenotype ${annotation_file} --phenotype ${phenotype_file}\n        \"\"\"\n    \n}",
        "nb_lignes_process": 29,
        "string_script": "        \"\"\"\n            split_phenotype_for_condition.py --condition '${condition}' --genome_phenotype ${annotation_file} --phenotype ${phenotype_file}\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotation_file",
            "phenotype_file",
            "condition"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "tag{condition}",
            "scratch false",
            "label 'process_low' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "AGGREGATE_UMI_COUNTS": {
        "name_process": "AGGREGATE_UMI_COUNTS",
        "string_process": "\nprocess AGGREGATE_UMI_COUNTS {\n  publishDir  path: \"${outdir}/aggregated_counts\",mode: \"${params.copy_mode}\",\n              overwrite: \"true\"\n    label 'process_low'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"/software/hgi/containers/eqtl.img\"\n        \n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n  input:\n    path(adata)                               \n    val(agg_column)\n    val(n_cells_min)\n    val(n_donors_min)\n\n  output:\n    path(\"phenotype_file.tsv\", emit:phenotype_file)\n    path(\"genotype_phenotype_mapping.tsv\", emit:genotype_phenotype_mapping)\n    path('*.tsv')\n\n  script:\n  outdir = params.outdir\n  \"\"\"\n    \n    aggregate_sc_data.py --agg_column '${agg_column}' --n_cells ${n_cells_min} -n_individ ${n_donors_min} -h5ad ${adata} --method ${params.aggregation_method}\n  \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "  outdir = params.outdir\n  \"\"\"\n    \n    aggregate_sc_data.py --agg_column '${agg_column}' --n_cells ${n_cells_min} -n_individ ${n_donors_min} -h5ad ${adata} --method ${params.aggregation_method}\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "adata",
            "agg_column",
            "n_cells_min",
            "n_donors_min"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "publishDir path: \"${outdir}/aggregated_counts\",mode: \"${params.copy_mode}\" , overwrite: \"true\"",
            "label 'process_low' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"/software/hgi/containers/eqtl.img\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "MULTIQC": {
        "name_process": "MULTIQC",
        "string_process": "\nprocess MULTIQC {\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"bioconda::multiqc=1.10.1\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/multiqc:1.10.1--py_0\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n    path multiqc_files\n\n    output:\n    path \"*multiqc_report.html\", emit: report\n    path \"*_data\"              , emit: data\n    path \"*_plots\"             , optional:true, emit: plots\n    path \"*.version.txt\"       , emit: version\n\n    script:\n    def software = getSoftwareName(task.process)\n    \"\"\"\n    multiqc -f $options.args .\n    multiqc --version | sed -e \"s/multiqc, version //g\" > ${software}.version.txt\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    def software = getSoftwareName(task.process)\n    \"\"\"\n    multiqc -f $options.args .\n    multiqc --version | sed -e \"s/multiqc, version //g\" > ${software}.version.txt\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "multiqc_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__eqtl",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"bioconda::multiqc=1.10.1\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/multiqc:1.10.1--py_0\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    }
}