{
    "parseGroup": {
        "name_process": "parseGroup",
        "string_process": "\nprocess parseGroup {\n\ntag \"${id}\"\n\ninput:\nval id from inputParseGroup\n\noutput:\nset id, stdout into outputParseGroup\n\nscript:\n\"\"\"\ngrep $id $GROUP | awk '{printf \\$2}'\n\"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\ngrep $id $GROUP | awk '{printf \\$2}'\n\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputParseGroup"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputParseGroup"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${id}\""
        ],
        "when": "",
        "stub": ""
    },
    "runQC": {
        "name_process": "runQC",
        "string_process": "\nprocess runQC {\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/Decon\", mode: 'copy'\n\n  input:\n  set id, file(left),file(right) from inputQC\n\n  output:\n  set id,file(left_clean),file(right_clean),file(unpaired_clean) into outputQC\n\n  script:\n\n  left_trimmed = \"tmp_\" + id + \"_R1.trimmed.fastq\"\n  right_trimmed = \"tmp_\" + id + \"_R2.trimmed.fastq\"\n  unpaired_trimmed = \"tmp_\" + id + \"_RU.trimmed.fastq\"\n\n  left_nophix = \"tmp_\" + id + \"_R1.nophix.fastq\"\n  right_nophix = \"tmp_\" + id + \"_R2.nophix.fastq\"\n  unpaired_nophix = \"tmp_\" + id + \"_RU.nophix.fastq\"\n\n  left_decon = \"tmp_\" + id + \"_R1.decon.fastq\"\n  right_decon = \"tmp_\" + id + \"_R2.decon.fastq\"\n  unpaired_decon = \"tmp_\" + id + \"_RU.decon.fastq\"\n\n  merged = \"tmp_\" + id + \"_RU.merged.fastq\"\n  left_clean = id + \"_R1.clean.fastq.gz\"\n  right_clean = id + \"_R2.clean.fastq.gz\"\n  unpaired_clean = id + \"_RU.clean.fastq.gz\"\n\n  if( startfrom > 0 )\n    \"\"\"\n    cp ${OUTDIR}/Samples/${id}/Decon/$left_clean $left_clean\n    cp ${OUTDIR}/Samples/${id}/Decon/$right_clean $right_clean\n    cp ${OUTDIR}/Samples/${id}/Decon/$unpaired_clean $unpaired_clean\n    \"\"\"\n  else\n    \"\"\"\n    ${BBDUK} threads=${task.cpus} in=${left} in2=${right} out1=${left_trimmed} out2=${right_trimmed} outs=${unpaired_trimmed} ref=${ADAPTERS} ktrim=r k=23 mink=11 hdist=1 minlength=${READMINLEN} tpe tbo\n    ${BBDUK} threads=${task.cpus} in=${left_trimmed} in2=${right_trimmed} k=31 ref=artifacts,phix ordered cardinality out1=${left_nophix} out2=${right_nophix} minlength=${READMINLEN}\n    ${BBDUK} threads=${task.cpus} in=${unpaired_trimmed}  k=31 ref=artifacts,phix ordered cardinality out1=${unpaired_nophix} minlength=${READMINLEN}\n    ${BBWRAP} -Xmx23g threads=${task.cpus} minid=0.95 maxindel=3 bwr=0.16 bw=12 quickmatch fast minhits=2 qtrim=rl trimq=20 minlength=${READMINLEN} in=${left_nophix},${unpaired_nophix} in2=${right_nophix},NULL path=${HSREF} outu1=${left_decon} outu2=${right_decon} outu=${unpaired_decon}\n    ${BBMERGE} threads=${task.cpus} in1=${left_decon} in2=${right_decon} out=${merged} outu1=${left_clean} outu2=${right_clean} mininsert=${READMINLEN}\n    cat ${merged} ${unpaired_nophix} | gzip -c > ${unpaired_clean}\n    rm tmp*\n    \"\"\"\n}",
        "nb_lignes_process": 46,
        "string_script": "  left_trimmed = \"tmp_\" + id + \"_R1.trimmed.fastq\"\n  right_trimmed = \"tmp_\" + id + \"_R2.trimmed.fastq\"\n  unpaired_trimmed = \"tmp_\" + id + \"_RU.trimmed.fastq\"\n\n  left_nophix = \"tmp_\" + id + \"_R1.nophix.fastq\"\n  right_nophix = \"tmp_\" + id + \"_R2.nophix.fastq\"\n  unpaired_nophix = \"tmp_\" + id + \"_RU.nophix.fastq\"\n\n  left_decon = \"tmp_\" + id + \"_R1.decon.fastq\"\n  right_decon = \"tmp_\" + id + \"_R2.decon.fastq\"\n  unpaired_decon = \"tmp_\" + id + \"_RU.decon.fastq\"\n\n  merged = \"tmp_\" + id + \"_RU.merged.fastq\"\n  left_clean = id + \"_R1.clean.fastq.gz\"\n  right_clean = id + \"_R2.clean.fastq.gz\"\n  unpaired_clean = id + \"_RU.clean.fastq.gz\"\n\n  if( startfrom > 0 )\n    \"\"\"\n    cp ${OUTDIR}/Samples/${id}/Decon/$left_clean $left_clean\n    cp ${OUTDIR}/Samples/${id}/Decon/$right_clean $right_clean\n    cp ${OUTDIR}/Samples/${id}/Decon/$unpaired_clean $unpaired_clean\n    \"\"\"\n  else\n    \"\"\"\n    ${BBDUK} threads=${task.cpus} in=${left} in2=${right} out1=${left_trimmed} out2=${right_trimmed} outs=${unpaired_trimmed} ref=${ADAPTERS} ktrim=r k=23 mink=11 hdist=1 minlength=${READMINLEN} tpe tbo\n    ${BBDUK} threads=${task.cpus} in=${left_trimmed} in2=${right_trimmed} k=31 ref=artifacts,phix ordered cardinality out1=${left_nophix} out2=${right_nophix} minlength=${READMINLEN}\n    ${BBDUK} threads=${task.cpus} in=${unpaired_trimmed}  k=31 ref=artifacts,phix ordered cardinality out1=${unpaired_nophix} minlength=${READMINLEN}\n    ${BBWRAP} -Xmx23g threads=${task.cpus} minid=0.95 maxindel=3 bwr=0.16 bw=12 quickmatch fast minhits=2 qtrim=rl trimq=20 minlength=${READMINLEN} in=${left_nophix},${unpaired_nophix} in2=${right_nophix},NULL path=${HSREF} outu1=${left_decon} outu2=${right_decon} outu=${unpaired_decon}\n    ${BBMERGE} threads=${task.cpus} in1=${left_decon} in2=${right_decon} out=${merged} outu1=${left_clean} outu2=${right_clean} mininsert=${READMINLEN}\n    cat ${merged} ${unpaired_nophix} | gzip -c > ${unpaired_clean}\n    rm tmp*\n    \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputQC"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputQC"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/Decon\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runCoAssembly": {
        "name_process": "runCoAssembly",
        "string_process": "\nprocess runCoAssembly {\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}\", mode: 'copy'\n\n  input:\n  set group, id, file(left_clean), file(right_clean), file(unpaired_clean) from inputCoAssemblyByGroup\n\n  output:\n  set group, file(outcontigs), file(megahitlog) into outCoAssembly\n\n  script:\n  outcontigs = group + \".final_contigs.fasta\"\n  megahitlog = group + \".megahit.log\"\n\n  if( startfrom > 1 )\n  \"\"\"\n  cp ${OUTDIR}/CoAssembly/${group}/$outcontigs $outcontigs\n  cp ${OUTDIR}/CoAssembly/${group}/$megahitlog $megahitlog\n  \"\"\"\n\n  else\n  \"\"\"\n  echo $left_clean > out\n  echo $right_clean >> out\n  echo $unpaired_clean >> out\n\n  awk '\n  {\n      for (i=1; i<=NF; i++)  {\n          a[NR,i] = \\$i\n      }\n  }\n  NF>p { p = NF }\n  END {\n      for(j=1; j<=p; j++) {\n          str=a[1,j]\n          for(i=2; i<=NR; i++){\n              str=str\" \"a[i,j];\n          }\n          print str\n      }\n  }' out > tmp1\n\n  awk '{printf \" -1 \" \\$1 \" -2 \" \\$2 \" -r \" \\$3}' tmp1 > tmp\n\n  $MEGAHIT \\$(cat tmp | tr -d '\\n') --num-cpu-threads ${task.cpus} --presets meta-large -o megahit_out --mem-flag 2 --verbose\n  cat megahit_out/final.contigs.fa | cut -d ' ' -f 1 > $outcontigs\n  mv megahit_out/log $megahitlog\n  rm -r megahit_out\n  \"\"\"\n}",
        "nb_lignes_process": 51,
        "string_script": "  outcontigs = group + \".final_contigs.fasta\"\n  megahitlog = group + \".megahit.log\"\n\n  if( startfrom > 1 )\n  \"\"\"\n  cp ${OUTDIR}/CoAssembly/${group}/$outcontigs $outcontigs\n  cp ${OUTDIR}/CoAssembly/${group}/$megahitlog $megahitlog\n  \"\"\"\n\n  else\n  \"\"\"\n  echo $left_clean > out\n  echo $right_clean >> out\n  echo $unpaired_clean >> out\n\n  awk '\n  {\n      for (i=1; i<=NF; i++)  {\n          a[NR,i] = \\$i\n      }\n  }\n  NF>p { p = NF }\n  END {\n      for(j=1; j<=p; j++) {\n          str=a[1,j]\n          for(i=2; i<=NR; i++){\n              str=str\" \"a[i,j];\n          }\n          print str\n      }\n  }' out > tmp1\n\n  awk '{printf \" -1 \" \\$1 \" -2 \" \\$2 \" -r \" \\$3}' tmp1 > tmp\n\n  $MEGAHIT \\$(cat tmp | tr -d '\\n') --num-cpu-threads ${task.cpus} --presets meta-large -o megahit_out --mem-flag 2 --verbose\n  cat megahit_out/final.contigs.fa | cut -d ' ' -f 1 > $outcontigs\n  mv megahit_out/log $megahitlog\n  rm -r megahit_out\n  \"\"\"",
        "nb_lignes_script": 38,
        "language_script": "bash",
        "tools": [
            "Ragout",
            "SNF",
            "ENdb",
            "TMPD"
        ],
        "tools_url": [
            "https://bio.tools/ragout",
            "https://bio.tools/SNF",
            "https://bio.tools/ENdb",
            "https://bio.tools/tmpd"
        ],
        "tools_dico": [
            {
                "name": "Ragout",
                "uri": "https://bio.tools/ragout",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tool for assisted assembly using multiple references. It takes a short read assembly (a set of contigs), a set of related references and a corresponding phylogenetic tree and then assembles the contigs into scaffolds.",
                "homepage": "http://fenderglass.github.io/Ragout/"
            },
            {
                "name": "SNF",
                "uri": "https://bio.tools/SNF",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3762",
                                    "term": "Service composition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Synthesizing high performance NFV service chains.\n\nIn this paper we introduce SNF, a framework that synthesizes (S) network function (NF) service chains by eliminating redundant I O and repeated elements, while consolidating stateful cross layer packet operations across the chain. SNF uses graph composition and set theory to determine traffic classes handled by a service chain composed of multiple elements. It then synthesizes each traffic class using a minimal set of new elements that apply single-read-single-write and early-discard operations. Our SNF prototype takes a baseline state-of-the-art network functions virtualization (NFV) framework to the level of performance required for practical NFV service deployments. Software-based SNF realizes long (up to 10 NFs) and stateful service chains that achieve line-rate 40 Gbps throughput (up to 8.5x greater than the baseline NFV framework).\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'NFV'",
                "homepage": "https://doi.org/10.7287/PEERJ.PREPRINTS.2477V3"
            },
            {
                "name": "ENdb",
                "uri": "https://bio.tools/ENdb",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0440",
                                    "term": "Promoter prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A manually curated database of experimentally supported enhancers for human and mouse. Enhancers are a class of cis-regulatory elements that can increase gene transcription by forming loops in intergenic regions, introns and exons",
                "homepage": "http://www.licpathway.net/ENdb"
            },
            {
                "name": "TMPD",
                "uri": "https://bio.tools/tmpd",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plants"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Botany"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Tobacco Markers & Primers Database.",
                "homepage": "http://biodb.sdau.edu.cn/tmpd/index.html"
            }
        ],
        "inputs": [
            "inputCoAssemblyByGroup"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outCoAssembly"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runSpades": {
        "name_process": "runSpades",
        "string_process": "\nprocess runSpades {\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/Spades\", mode: 'copy'\n\n  input:\n  set id, file(left_clean), file(right_clean), file(unpaired_clean) from inputSpades\n\n  output:\n  set id, file(outcontigs) into outputSpades\n\n  script:\n  outcontigs = id + \".spades_contigs.fasta\"\n\n  if( startfrom > 1 )\n  \"\"\"\n  cp ${OUTDIR}/Samples/${id}/Spades/$outcontigs $outcontigs\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Spades/3.9.0\n  $SPADES --meta --pe1-1 $left_clean --pe1-2 $right_clean --pe1-s $unpaired_clean -k $SPADES_kmers -o spades_out -t ${task.cpus}\n  mv spades_out/scaffolds.fasta $outcontigs\n  rm -r spades_out\n  \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "  outcontigs = id + \".spades_contigs.fasta\"\n\n  if( startfrom > 1 )\n  \"\"\"\n  cp ${OUTDIR}/Samples/${id}/Spades/$outcontigs $outcontigs\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Spades/3.9.0\n  $SPADES --meta --pe1-1 $left_clean --pe1-2 $right_clean --pe1-s $unpaired_clean -k $SPADES_kmers -o spades_out -t ${task.cpus}\n  mv spades_out/scaffolds.fasta $outcontigs\n  rm -r spades_out\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputSpades"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputSpades"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/Spades\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runSpadesBackmap": {
        "name_process": "runSpadesBackmap",
        "string_process": "\nprocess runSpadesBackmap {\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/Spades\", mode: 'copy'\n\n  input:\n  set id, file(left_clean), file(right_clean), file(unpaired_clean), file(spadescontigs) from inputSpadesBackmapWithContigs\n\n  output:\n  set id, file(outdepth) into outputSpadesBackmap\n\n  script:\n  outdepth = id + \".depth.txt\"\n  if( startfrom > 2 )\n  \"\"\"\n  cp ${OUTDIR}/Samples/${id}/Spades/$outdepth $outdepth\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Java/1.8.0\n  module load BBMap/37.88\n  module load Samtools/1.5\n  ${BBWRAP} -Xmx60g in=$left_clean,$unpaired_clean in2=$right_clean,NULL ref=$spadescontigs t=${task.cpus} out=tmp.sam kfilter=22 subfilter=15 maxindel=80\n  $SAMTOOLS view -u tmp.sam | $SAMTOOLS sort -m 54G -@ 3 -o tmp_final.bam\n  $JGISUM --outputDepth $outdepth tmp_final.bam\n  rm tmp*\n  rm -r ref\n  \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "  outdepth = id + \".depth.txt\"\n  if( startfrom > 2 )\n  \"\"\"\n  cp ${OUTDIR}/Samples/${id}/Spades/$outdepth $outdepth\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Java/1.8.0\n  module load BBMap/37.88\n  module load Samtools/1.5\n  ${BBWRAP} -Xmx60g in=$left_clean,$unpaired_clean in2=$right_clean,NULL ref=$spadescontigs t=${task.cpus} out=tmp.sam kfilter=22 subfilter=15 maxindel=80\n  $SAMTOOLS view -u tmp.sam | $SAMTOOLS sort -m 54G -@ 3 -o tmp_final.bam\n  $JGISUM --outputDepth $outdepth tmp_final.bam\n  rm tmp*\n  rm -r ref\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputSpadesBackmapWithContigs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputSpadesBackmap"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/Spades\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMaxbin": {
        "name_process": "runMaxbin",
        "string_process": "\nprocess runMaxbin {\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/Maxbin\", mode: 'copy'\n\n  input:\n  set id, file(spadescontigs), file(depthfile) from inputMaxbin\n\n  output:\n  set id, file(binfolder) into outputMaxbinSamples\n\n  script:\n  binfolder = id + \"_maxbin_bins\"\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}/Maxbin/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  tail -n+2 $depthfile | cut -f 1,3 > maxbin.cov\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n(\n  set -Ee\n  function _catch {\n    touch summary.txt\n    echo \"exception caught\"\n    exit 0\n}\n  trap _catch ERR\n  $MAXBIN -contig $spadescontigs -abund maxbin.cov -out workfolder/${id}.bin -thread ${task.cpus}\n)\n\n  for bin in \\$(ls workfolder/${id}.bin.*.fasta | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu 1 $MARKERS107 tmp_workfolder/\\$bin.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu 1 $MARKERS40 tmp_workfolder/\\$bin.faa \n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar | tee -a summary.txt\n  done\n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  rm maxbin.cov\n  \"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "  binfolder = id + \"_maxbin_bins\"\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}/Maxbin/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  tail -n+2 $depthfile | cut -f 1,3 > maxbin.cov\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n(\n  set -Ee\n  function _catch {\n    touch summary.txt\n    echo \"exception caught\"\n    exit 0\n}\n  trap _catch ERR\n  $MAXBIN -contig $spadescontigs -abund maxbin.cov -out workfolder/${id}.bin -thread ${task.cpus}\n)\n\n  for bin in \\$(ls workfolder/${id}.bin.*.fasta | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu 1 $MARKERS107 tmp_workfolder/\\$bin.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu 1 $MARKERS40 tmp_workfolder/\\$bin.faa \n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar | tee -a summary.txt\n  done\n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  rm maxbin.cov\n  \"\"\"",
        "nb_lignes_script": 42,
        "language_script": "bash",
        "tools": [
            "GOFunction",
            "TRAP",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/gofunction",
            "https://bio.tools/trap",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "GOFunction",
                "uri": "https://bio.tools/gofunction",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The GO-function package provides a tool to address the redundancy that result from the GO structure or multiple annotation genes and derive biologically relevant functions from the statistically significant functions based on some intuitive assumption and statistical testing.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/GOFunction.html"
            },
            {
                "name": "TRAP",
                "uri": "https://bio.tools/trap",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0157",
                            "term": "Sequence composition, complexity and repeats"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0379",
                                    "term": "Repeat sequence detection"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Program that provides a unified set of analyses for the selection, classification, quantification and automated annotation of tandemly repeated sequences.",
                "homepage": "http://www.coccidia.icb.usp.br/trap/index.html"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "inputMaxbin"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputMaxbinSamples"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/Maxbin\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMaxbin40": {
        "name_process": "runMaxbin40",
        "string_process": "\nprocess runMaxbin40 {\n\n  scratch true\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/Maxbin40\", mode: 'copy'\n\n  input:\n  set id, file(spadescontigs), file(depthfile) from inputMaxbin40\n\n  output:\n  set id, file(binfolder) into outputMaxbin40Samples\n\n  script:\n  binfolder = id + \"_maxbin40_bins\"\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}/Maxbin40/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  tail -n+2 $depthfile | cut -f 1,3 > maxbin.cov\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n(\n  set -Ee\n  function _catch {\n    touch summary.txt\n    echo \"exception caught\"\n    exit 0\n}\n  trap _catch ERR\n  $MAXBIN -contig $spadescontigs -abund maxbin.cov -out $binfolder/${id}.bin40 -thread ${task.cpus} -markerset 40\n)\n\n  \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "  binfolder = id + \"_maxbin40_bins\"\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}/Maxbin40/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  tail -n+2 $depthfile | cut -f 1,3 > maxbin.cov\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n(\n  set -Ee\n  function _catch {\n    touch summary.txt\n    echo \"exception caught\"\n    exit 0\n}\n  trap _catch ERR\n  $MAXBIN -contig $spadescontigs -abund maxbin.cov -out $binfolder/${id}.bin40 -thread ${task.cpus} -markerset 40\n)\n\n  \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "GOFunction",
            "TRAP"
        ],
        "tools_url": [
            "https://bio.tools/gofunction",
            "https://bio.tools/trap"
        ],
        "tools_dico": [
            {
                "name": "GOFunction",
                "uri": "https://bio.tools/gofunction",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The GO-function package provides a tool to address the redundancy that result from the GO structure or multiple annotation genes and derive biologically relevant functions from the statistically significant functions based on some intuitive assumption and statistical testing.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/GOFunction.html"
            },
            {
                "name": "TRAP",
                "uri": "https://bio.tools/trap",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0157",
                            "term": "Sequence composition, complexity and repeats"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0379",
                                    "term": "Repeat sequence detection"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Program that provides a unified set of analyses for the selection, classification, quantification and automated annotation of tandemly repeated sequences.",
                "homepage": "http://www.coccidia.icb.usp.br/trap/index.html"
            }
        ],
        "inputs": [
            "inputMaxbin40"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputMaxbin40Samples"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "scratch true",
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/Maxbin40\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMetabat": {
        "name_process": "runMetabat",
        "string_process": "\nprocess runMetabat {\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/Metabat\", mode: 'copy'\n\n  input:\n  set id, file(spadescontigs), file(depthfile) from inputMetabat\n\n  output:\n  set id, file(binfolder) into outputMetabatSamples\n\n  script:\n  binfolder = id + \"_metabat_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}/Metabat/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n  $METABAT -i $spadescontigs -a $depthfile -o workfolder/${id}.metabat.bin -t ${task.cpus}\n\n  for bin in \\$(ls workfolder/${id}.metabat.bin.*.fa | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu 1 $MARKERS107 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu 1 $MARKERS40 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar | tee -a summary.txt\n  done \n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "  binfolder = id + \"_metabat_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}/Metabat/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n  $METABAT -i $spadescontigs -a $depthfile -o workfolder/${id}.metabat.bin -t ${task.cpus}\n\n  for bin in \\$(ls workfolder/${id}.metabat.bin.*.fa | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu 1 $MARKERS107 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu 1 $MARKERS40 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar | tee -a summary.txt\n  done \n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "inputMetabat"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputMetabatSamples"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/Metabat\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runSpadesMarkergenes": {
        "name_process": "runSpadesMarkergenes",
        "string_process": "\nprocess runSpadesMarkergenes {\n\n  scratch true\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/SpadesMarkergenes\", mode: 'copy'\n\n  input:\n  set id, file(spadescontigs) from inputSpadesMarkergenes\n\n  output:\n  set id, file(markergenes) into outputSpadesMarkergenes\n\n  script:\n  markergenes = id + \"_markergenes.txt\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}//SpadesMarkergenes/$markergenes $markergenes\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n  mkdir tmp\n  cp $spadescontigs tmp\n  perlbrew exec --with perl-5.12.3 $GTDBTK identify --genome_dir tmp -x fasta --cpus ${task.cpus} --out_dir markers\n  cat markers/marker_genes/*/*tophit.tsv | grep -v hits | tr \",\" \"\\t\" | cut -d ';' -f 1 > $markergenes\n  \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "  markergenes = id + \"_markergenes.txt\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}//SpadesMarkergenes/$markergenes $markergenes\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n  mkdir tmp\n  cp $spadescontigs tmp\n  perlbrew exec --with perl-5.12.3 $GTDBTK identify --genome_dir tmp -x fasta --cpus ${task.cpus} --out_dir markers\n  cat markers/marker_genes/*/*tophit.tsv | grep -v hits | tr \",\" \"\\t\" | cut -d ';' -f 1 > $markergenes\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputSpadesMarkergenes"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputSpadesMarkergenes"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "scratch true",
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/SpadesMarkergenes\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runSpadesRefine": {
        "name_process": "runSpadesRefine",
        "string_process": "\nprocess runSpadesRefine {\n\n  tag \"${id}\"\n  publishDir \"${OUTDIR}/Samples/${id}/ContigsRefined\", mode: 'copy'\n\n  input:\n  set id, file(spadescontigs), file(markergenes), file(binmaxbin), file(binmaxbin40), file(binmetabat) from SamplesAllbins\n\n  output:\n  set id, file(refinedcontigsout) into SampleRefinedContigs\n\n  script:\n  refinedcontigsout = id + \"_refined\"\n\n  if( startfrom > 3 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}//ContigsRefined/$refinedcontigsout $refinedcontigsout\n  \"\"\"\n\n  else\n  \"\"\"\n  module load R/3.4.0\n  mkdir $refinedcontigsout\n  grep '>' ${binmaxbin}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 > btc.txt\n  grep '>' ${binmaxbin40}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  grep '>' ${binmetabat}/*fa | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  $RSCRIPT /ifs/data/nfs_share/sukmb276/github/LaMeta/DAS_Tool_ripoff.Rscript ${id} btc.txt ${markergenes} \n  $PYTHON /ifs/data/nfs_share/sukmb276/github/LaMeta/sort_into_bins.py ${id}.refined.contig_to_bin.out ${spadescontigs}\n  mkdir bins\n  mkdir -p $refinedcontigsout/bins\n  mv ${id}_cleanbin_*.fasta bins\n  checkm lineage_wf -t ${task.cpus} -x fasta --nt --tab_table -f ${id}.checkm.out bins checkm\n  head -n 1 ${id}.checkm.out > $refinedcontigsout/${id}.checkm.out\n  for good in \\$(awk -F '\\t' '{if(\\$12 > 50 && \\$1!=\"Bin Id\") print \\$1}' ${id}.checkm.out); do mv bins/\\$good.fasta $refinedcontigsout/bins; grep -w \\$good ${id}.checkm.out >> ${refinedcontigsout}/${id}.checkm.out; done\n  mv ${id}.refined* $refinedcontigsout\n  \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "  refinedcontigsout = id + \"_refined\"\n\n  if( startfrom > 3 )\n  \"\"\"\n  cp -r ${OUTDIR}/Samples/${id}//ContigsRefined/$refinedcontigsout $refinedcontigsout\n  \"\"\"\n\n  else\n  \"\"\"\n  module load R/3.4.0\n  mkdir $refinedcontigsout\n  grep '>' ${binmaxbin}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 > btc.txt\n  grep '>' ${binmaxbin40}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  grep '>' ${binmetabat}/*fa | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  $RSCRIPT /ifs/data/nfs_share/sukmb276/github/LaMeta/DAS_Tool_ripoff.Rscript ${id} btc.txt ${markergenes} \n  $PYTHON /ifs/data/nfs_share/sukmb276/github/LaMeta/sort_into_bins.py ${id}.refined.contig_to_bin.out ${spadescontigs}\n  mkdir bins\n  mkdir -p $refinedcontigsout/bins\n  mv ${id}_cleanbin_*.fasta bins\n  checkm lineage_wf -t ${task.cpus} -x fasta --nt --tab_table -f ${id}.checkm.out bins checkm\n  head -n 1 ${id}.checkm.out > $refinedcontigsout/${id}.checkm.out\n  for good in \\$(awk -F '\\t' '{if(\\$12 > 50 && \\$1!=\"Bin Id\") print \\$1}' ${id}.checkm.out); do mv bins/\\$good.fasta $refinedcontigsout/bins; grep -w \\$good ${id}.checkm.out >> ${refinedcontigsout}/${id}.checkm.out; done\n  mv ${id}.refined* $refinedcontigsout\n  \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "SamplesAllbins"
        ],
        "nb_inputs": 1,
        "outputs": [
            "SampleRefinedContigs"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${id}\"",
            "publishDir \"${OUTDIR}/Samples/${id}/ContigsRefined\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runCoassemblyBackmap": {
        "name_process": "runCoassemblyBackmap",
        "string_process": "\nprocess runCoassemblyBackmap {\n\n  tag \"${group}-${id}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}\", mode: 'copy'\n\n  input:\n  set group, id, file(left_clean), file(right_clean), file(unpaired_clean), file(megahitcontigs), file(megahitlog) from inputBackmapCoassemblyT\n\n  output:\n  set group, file(bamout) into outMegahitBackmap\n\n  script:\n  bamout = id + \".megahit.final.bam\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp ${OUTDIR}/CoAssembly/${group}/Backmap/$bamout $bamout\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Java/1.8.0\n  module load BBMap/37.88\n  module load Samtools/1.5\n  ${BBWRAP} -Xmx60g in=$left_clean,$unpaired_clean in2=$right_clean,NULL ref=$megahitcontigs t=${task.cpus} out=tmp_sam.gz kfilter=22 subfilter=15 maxindel=80\n  $SAMTOOLS view -u tmp_sam.gz | $SAMTOOLS sort -m 54G -@ 3 -o $bamout\n  rm tmp*\n  rm -r ref\n  \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "  bamout = id + \".megahit.final.bam\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp ${OUTDIR}/CoAssembly/${group}/Backmap/$bamout $bamout\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Java/1.8.0\n  module load BBMap/37.88\n  module load Samtools/1.5\n  ${BBWRAP} -Xmx60g in=$left_clean,$unpaired_clean in2=$right_clean,NULL ref=$megahitcontigs t=${task.cpus} out=tmp_sam.gz kfilter=22 subfilter=15 maxindel=80\n  $SAMTOOLS view -u tmp_sam.gz | $SAMTOOLS sort -m 54G -@ 3 -o $bamout\n  rm tmp*\n  rm -r ref\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputBackmapCoassemblyT"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outMegahitBackmap"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${group}-${id}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runCollapseBams": {
        "name_process": "runCollapseBams",
        "string_process": "\nprocess runCollapseBams {\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}/Backmap\", mode: 'copy'\n\n  input:\n  set group, file(bams) from inputCollapseBams\n\n  output:\n  set group, file(depthfile) into coassemblyDepth\n  set group, file(abufolder) into coassemblyAbufolder\n\n  script:\n  depthfile = group + \"depth.txt\"\n  abufolder = group + \"_abufiles\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp ${OUTDIR}/CoAssembly/${group}/Backmap/$depthfile $depthfile\n  cp -r ${OUTDIR}/CoAssembly/${group}/Backmap/$abufolder $abufolder\n  \"\"\"\n\n  else\n  \"\"\"\n  $JGISUM --outputDepth $depthfile $bams\n  ncol=\\$(head -n 1 $depthfile | awk '{print NF}')\n  mkdir $abufolder\n  for i in \\$(seq 4 2 \\$ncol); do\n  name=\\$(head -n 1 $depthfile | cut -f \\$i | cut -d \".\" -f 1)\n  cut -f  1,\\$i $depthfile | tail -n+2 > $abufolder/\\${name}.out\n  done\n  \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "  depthfile = group + \"depth.txt\"\n  abufolder = group + \"_abufiles\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp ${OUTDIR}/CoAssembly/${group}/Backmap/$depthfile $depthfile\n  cp -r ${OUTDIR}/CoAssembly/${group}/Backmap/$abufolder $abufolder\n  \"\"\"\n\n  else\n  \"\"\"\n  $JGISUM --outputDepth $depthfile $bams\n  ncol=\\$(head -n 1 $depthfile | awk '{print NF}')\n  mkdir $abufolder\n  for i in \\$(seq 4 2 \\$ncol); do\n  name=\\$(head -n 1 $depthfile | cut -f \\$i | cut -d \".\" -f 1)\n  cut -f  1,\\$i $depthfile | tail -n+2 > $abufolder/\\${name}.out\n  done\n  \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputCollapseBams"
        ],
        "nb_inputs": 1,
        "outputs": [
            "coassemblyDepth",
            "coassemblyAbufolder"
        ],
        "nb_outputs": 2,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}/Backmap\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMegahitMaxbin": {
        "name_process": "runMegahitMaxbin",
        "string_process": "\nprocess runMegahitMaxbin {\n  cpus 20\n  memory 240.GB\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}/Maxbin\", mode: 'copy'\n\n  input:\n  set group, file(inputfolder), file(megahitcontigs) from inputMegahitMaxbin\n\n  output:\n  set group, file(binfolder) into outputMegahitMaxbin\n\n  script:\n  binfolder = group + \"_maxbin_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}/Maxbin/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  ls ${inputfolder}/*.out > abufiles.txt\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n  $MAXBIN -contig $megahitcontigs -abund_list abufiles.txt -out workfolder/${group}.maxbin.bin -thread ${task.cpus}\n\n  for bin in \\$(ls workfolder/${group}.maxbin.*.fasta | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu ${task.cpus} $MARKERS107 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu ${task.cpus} $MARKERS40 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar\n  done > summary.txt\n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  \"\"\"\n}",
        "nb_lignes_process": 48,
        "string_script": "  binfolder = group + \"_maxbin_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}/Maxbin/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  ls ${inputfolder}/*.out > abufiles.txt\n  mkdir $binfolder\n  mkdir workfolder\n  mkdir tmp_workfolder\n  $MAXBIN -contig $megahitcontigs -abund_list abufiles.txt -out workfolder/${group}.maxbin.bin -thread ${task.cpus}\n\n  for bin in \\$(ls workfolder/${group}.maxbin.*.fasta | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu ${task.cpus} $MARKERS107 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu ${task.cpus} $MARKERS40 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar\n  done > summary.txt\n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "inputMegahitMaxbin"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputMegahitMaxbin"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "cpus 20",
            "memory 240.GB",
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}/Maxbin\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMegahitMaxbin40": {
        "name_process": "runMegahitMaxbin40",
        "string_process": "\nprocess runMegahitMaxbin40 {\n\n  scratch true  \n\n  cpus 20\n  memory 240.GB\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}/Maxbin40\", mode: 'copy'\n\n  input:\n  set group, file(inputfolder), file(megahitcontigs), file(megahitlog)  from inputMegahitMaxbin40\n\n  output:\n  set group, file(binfolder) into outputMegahitMaxbin40\n\n  script:\n  binfolder = group + \"_maxbin40_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}/Maxbin40/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  ls ${inputfolder}/*.out > abufiles.txt\n  mkdir $binfolder\n  $MAXBIN -contig $megahitcontigs -abund_list abufiles.txt -out $binfolder/${group}.maxbin.bin40 -thread ${task.cpus} -markerset 40\n\n  \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "  binfolder = group + \"_maxbin40_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}/Maxbin40/$binfolder $binfolder\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n\n  ls ${inputfolder}/*.out > abufiles.txt\n  mkdir $binfolder\n  $MAXBIN -contig $megahitcontigs -abund_list abufiles.txt -out $binfolder/${group}.maxbin.bin40 -thread ${task.cpus} -markerset 40\n\n  \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputMegahitMaxbin40"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputMegahitMaxbin40"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "scratch true",
            "cpus 20",
            "memory 240.GB",
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}/Maxbin40\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMegahitMetabat": {
        "name_process": "runMegahitMetabat",
        "string_process": "\nprocess runMegahitMetabat {\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}/Metabat\", mode: 'copy'\n\n  input:\n  set group, file(inputdepth), file(megahitcontigs) from inputMegahitMetabat\n\n  output:\n  set group, file(binfolder) into outputMegahitMetabat\n\n  script:\n  binfolder = group + \"_metabat_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}/Metabat/$binfolder $binfolder\n  \"\"\"\n\n  else\n\n  \"\"\"\n  module load Prokka/1.11\n\n  mkdir $binfolder\n  mkdir tmp_workfolder\n  mkdir workfolder\n  $METABAT -i $megahitcontigs -a $inputdepth -o workfolder/${group}.metabat.bin -t ${task.cpus}\n\n  for bin in \\$(ls workfolder/${group}.metabat.bin.*.fa | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu 1 $MARKERS107 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu 1 $MARKERS40 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar\n  done > summary.txt\n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  \"\"\"\n}",
        "nb_lignes_process": 46,
        "string_script": "  binfolder = group + \"_metabat_bins\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}/Metabat/$binfolder $binfolder\n  \"\"\"\n\n  else\n\n  \"\"\"\n  module load Prokka/1.11\n\n  mkdir $binfolder\n  mkdir tmp_workfolder\n  mkdir workfolder\n  $METABAT -i $megahitcontigs -a $inputdepth -o workfolder/${group}.metabat.bin -t ${task.cpus}\n\n  for bin in \\$(ls workfolder/${group}.metabat.bin.*.fa | awk -F'/' '{print \\$NF}'); do\n  cat workfolder/\\$bin | $PARALLEL -j ${task.cpus} --block 100k --recstart '>' --pipe $PRODIGAL -p meta -a tmp_workfolder/\\$bin.{#}.faa 1>/dev/null 2>/dev/null\n  cat tmp_workfolder/\\$bin.*.faa > tmp_workfolder/\\$bin.faa\n  rm tmp_workfolder/\\$bin.*.faa\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker107.hmm --cut_tc --cpu 1 $MARKERS107 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  $HMMSEARCH --domtblout tmp_workfolder/\\$bin.marker40.hmm --cut_tc --cpu 1 $MARKERS40 tmp_workfolder/\\$bin.faa 1>/dev/null 2>/dev/null\n  bac=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker107.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/107}')\n  bacar=\\$(grep -v \"^#\" tmp_workfolder/\\$bin.marker40.hmm | awk '{print \\$4}' | sort | uniq | wc -l | awk '{printf \"%0.1f\", (100*\\$1)/40}')\n  echo \\$bin \\$bac \\$bacar\n  done > summary.txt\n\n  for goodbin in \\$(cat summary.txt | awk '{if(\\$2>40 || \\$3>40) print \\$1}'); do\n  cp workfolder/\\$goodbin $binfolder\n  done\n  rm -r tmp_workfolder\n  rm -r workfolder\n  \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "inputMegahitMetabat"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputMegahitMetabat"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}/Metabat\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMegahitMarkergenes": {
        "name_process": "runMegahitMarkergenes",
        "string_process": "\nprocess runMegahitMarkergenes {\n\n  scratch true\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}/MegahitMarkergenes\", mode: 'copy'\n\n  input:\n  set group, file(megahitcontigs), file(megahitlog) from inputMegahitMarkergenes\n\n  output:\n  set group, file(markergenes) into outputMegahitMarkergenes\n\n  script:\n  markergenes = group + \"_markergenes.txt\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}//MegahitMarkergenes/$markergenes $markergenes\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n  mkdir tmp\n  cp $megahitcontigs tmp\n  perlbrew exec --with perl-5.12.3 $GTDBTK identify --genome_dir tmp -x fasta --cpus ${task.cpus} --out_dir markers\n  cat markers/marker_genes/*/*tophit.tsv | grep -v hits | tr \",\" \"\\t\" | cut -d ';' -f 1 > $markergenes\n  rm -r tmp\n  \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "  markergenes = group + \"_markergenes.txt\"\n\n  if( startfrom > 2 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}//MegahitMarkergenes/$markergenes $markergenes\n  \"\"\"\n\n  else\n  \"\"\"\n  module load Prokka/1.11\n  mkdir tmp\n  cp $megahitcontigs tmp\n  perlbrew exec --with perl-5.12.3 $GTDBTK identify --genome_dir tmp -x fasta --cpus ${task.cpus} --out_dir markers\n  cat markers/marker_genes/*/*tophit.tsv | grep -v hits | tr \",\" \"\\t\" | cut -d ';' -f 1 > $markergenes\n  rm -r tmp\n  \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputMegahitMarkergenes"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputMegahitMarkergenes"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "scratch true",
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}/MegahitMarkergenes\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runMegahitRefine": {
        "name_process": "runMegahitRefine",
        "string_process": "\nprocess runMegahitRefine {\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}/ContigsRefined\", mode: 'copy'\n\n  input:\n  set group, file(megahitcontigs), file(megahitlog), file(markergenes), file(binmaxbin), file(binmaxbin40), file(binmetabat) from MegahitAllbins\n\n  output:\n  set group, file(refinedcontigsout) into MegahitRefinedContigs\n\n  script:\n  refinedcontigsout = group + \"_refined\"\n\n  if( startfrom > 3 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}//ContigsRefined/$refinedcontigsout $refinedcontigsout\n  \"\"\"\n\n  else\n  \"\"\"\n  module load R/3.4.0\n  mkdir $refinedcontigsout\n  grep '>' ${binmaxbin}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 > btc.txt\n  grep '>' ${binmaxbin40}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  grep '>' ${binmetabat}/*fa | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  $RSCRIPT /ifs/data/nfs_share/sukmb276/github/LaMeta/DAS_Tool_ripoff.Rscript ${group} btc.txt ${markergenes}\n  $PYTHON /ifs/data/nfs_share/sukmb276/github/LaMeta/sort_into_bins.py ${group}.refined.contig_to_bin.out ${megahitcontigs} \n  mkdir bins\n  mkdir -p $refinedcontigsout/bins\n  mv ${group}_cleanbin_*.fasta bins\n  checkm lineage_wf -t ${task.cpus} -x fasta --nt --tab_table -f ${group}.checkm.out bins checkm\n  head -n 1 ${group}.checkm.out > $refinedcontigsout/${group}.checkm.out\n  for good in \\$(awk -F '\\t' '{if(\\$12 > 50 && \\$1!=\"Bin Id\") print \\$1}' ${group}.checkm.out); do mv bins/\\$good.fasta $refinedcontigsout/bins; grep -w \\$good ${group}.checkm.out >> $refinedcontigsout/${group}.checkm.out; done \n  mv ${group}.refined* $refinedcontigsout\n  \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "  refinedcontigsout = group + \"_refined\"\n\n  if( startfrom > 3 )\n  \"\"\"\n  cp -r ${OUTDIR}/CoAssembly/${group}//ContigsRefined/$refinedcontigsout $refinedcontigsout\n  \"\"\"\n\n  else\n  \"\"\"\n  module load R/3.4.0\n  mkdir $refinedcontigsout\n  grep '>' ${binmaxbin}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 > btc.txt\n  grep '>' ${binmaxbin40}/*fasta | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  grep '>' ${binmetabat}/*fa | tr ':' ' ' | tr -d '>'  | cut -d '/' -f 2 >> btc.txt\n  $RSCRIPT /ifs/data/nfs_share/sukmb276/github/LaMeta/DAS_Tool_ripoff.Rscript ${group} btc.txt ${markergenes}\n  $PYTHON /ifs/data/nfs_share/sukmb276/github/LaMeta/sort_into_bins.py ${group}.refined.contig_to_bin.out ${megahitcontigs} \n  mkdir bins\n  mkdir -p $refinedcontigsout/bins\n  mv ${group}_cleanbin_*.fasta bins\n  checkm lineage_wf -t ${task.cpus} -x fasta --nt --tab_table -f ${group}.checkm.out bins checkm\n  head -n 1 ${group}.checkm.out > $refinedcontigsout/${group}.checkm.out\n  for good in \\$(awk -F '\\t' '{if(\\$12 > 50 && \\$1!=\"Bin Id\") print \\$1}' ${group}.checkm.out); do mv bins/\\$good.fasta $refinedcontigsout/bins; grep -w \\$good ${group}.checkm.out >> $refinedcontigsout/${group}.checkm.out; done \n  mv ${group}.refined* $refinedcontigsout\n  \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "MegahitAllbins"
        ],
        "nb_inputs": 1,
        "outputs": [
            "MegahitRefinedContigs"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}/ContigsRefined\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runDrepGroups": {
        "name_process": "runDrepGroups",
        "string_process": "\nprocess runDrepGroups {\n\n  tag \"${group}\"\n  publishDir \"${OUTDIR}/CoAssembly/${group}\", mode: 'copy'\n\n  input:\n  set group, file(binfolder) from groupbinfolder\n\n  output:\n  file outfolder into outputDrepGroup\n\n  script:\n  outfolder = group + \"_dRep_out\"\n\n\n  \"\"\"\n  mkdir allbins\n  cp \\$(ls *_bins/*.fa*) allbins\n  pyenv local $PYENV3 $PYENV2\n  $DREP bonus testDir --check_dependencies\n  $DREP dereplicate $outfolder -g allbins/*.fa* -p ${task.cpus} -comp ${MINCOMP}\n#  rm -r testDir\n  rm -r allbins\n  rm -r $outfolder/data\n  \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "  outfolder = group + \"_dRep_out\"\n\n\n  \"\"\"\n  mkdir allbins\n  cp \\$(ls *_bins/*.fa*) allbins\n  pyenv local $PYENV3 $PYENV2\n  $DREP bonus testDir --check_dependencies\n  $DREP dereplicate $outfolder -g allbins/*.fa* -p ${task.cpus} -comp ${MINCOMP}\n#  rm -r testDir\n  rm -r allbins\n  rm -r $outfolder/data\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "groupbinfolder"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputDrepGroup"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"${group}\"",
            "publishDir \"${OUTDIR}/CoAssembly/${group}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "runDrepAll": {
        "name_process": "runDrepAll",
        "string_process": "\nprocess runDrepAll {\n\n  tag \"allbins\"\n  publishDir \"${OUTDIR}/Final\", mode: 'copy'\n\n  input:\n  file binfolder from outputDrepGroup.collect()\n\n  output:\n  file outfolder into outputDrep\n\n  script:\n  outfolder = \"dRep_out\"\n\n\n  \"\"\"\n  mkdir allbins\n  for binf in ${binfolder}; do\n  cp \\$binf/dereplicated_genomes/*.fa* allbins\n  done\n\n  pyenv local $PYENV3 $PYENV2\n  $DREP bonus testDir --check_dependencies\n  $DREP dereplicate $outfolder -g allbins/*.fa* -p ${task.cpus} -comp ${MINCOMP}\n  rm -r testDir\n  rm -r allbins\n  \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "  outfolder = \"dRep_out\"\n\n\n  \"\"\"\n  mkdir allbins\n  for binf in ${binfolder}; do\n  cp \\$binf/dereplicated_genomes/*.fa* allbins\n  done\n\n  pyenv local $PYENV3 $PYENV2\n  $DREP bonus testDir --check_dependencies\n  $DREP dereplicate $outfolder -g allbins/*.fa* -p ${task.cpus} -comp ${MINCOMP}\n  rm -r testDir\n  rm -r allbins\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "outputDrepGroup"
        ],
        "nb_inputs": 1,
        "outputs": [
            "outputDrep"
        ],
        "nb_outputs": 1,
        "name_workflow": "mruehlemann__LaMeta",
        "directive": [
            "tag \"allbins\"",
            "publishDir \"${OUTDIR}/Final\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}