{
    "OPERATION_1": {
        "string": "fileinfo = Channel\n    .from(fq_file.collect { it.tokenize(\"\\t\") })\n    .map { strain, SM, reads_1, reads_2, pol -> [ strain, SM, file(\"${reads_1}\"), file(\"${reads_2}\"), pol ] }\n    .into { fq_file_1;fq_file_2 }",
        "origin": [],
        "gives": [
            [
                "fileinfo",
                "P"
            ],
            [
                "fq_file_1",
                "P"
            ],
            [
                "fq_file_2",
                "P"
            ]
        ]
    },
    "OPERATION_2": {
        "string": "Channel\n    .from(fq_file.collect { it.tokenize(\"\\t\") })\n    .map { ST, SM, reads_1, reads_2, pol -> ST  }\n    .unique()\n    .into { Strains; \n            Strains2}",
        "origin": [],
        "gives": [
            [
                "Strains",
                "P"
            ],
            [
                "Strains2",
                "P"
            ]
        ]
    },
    "OPERATION_3": {
        "string": "fq_file_trim1\n\t.combine(transcriptome_index, by: 0)\n\t.into{mapping_data_set;\n             print_mapping}",
        "origin": [
            [
                "fq_file_trim1",
                "P"
            ]
        ],
        "gives": [
            [
                "mapping_data_set",
                "P"
            ],
            [
                "print_mapping",
                "P"
            ]
        ]
    },
    "OPERATION_4": {
        "string": "fastqc_ch\n    .mix(kallisto_log)\n    .collect()\n    .into{qc_data;\n    qc_data_2 }",
        "origin": [
            [
                "fastqc_ch",
                "P"
            ],
            [
                "kallisto_log",
                "P"
            ]
        ],
        "gives": [
            [
                "qc_data",
                "P"
            ],
            [
                "qc_data_2",
                "P"
            ]
        ]
    }
}