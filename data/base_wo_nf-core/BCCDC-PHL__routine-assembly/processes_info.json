{
    "prokka": {
        "name_process": "prokka",
        "string_process": "process prokka {\n\n    tag { sample_id }\n\n    publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_${assembler}_prokka.{gbk,gff}\", mode: 'copy'\n\n    input:\n      tuple val(sample_id), path(assembly), val(assembler)\n\n    output:\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_prokka.gbk\"), emit: gbk\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_prokka.gff\"), emit: gff\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_prokka_provenance.yml\"), emit: provenance\n\n    script:\n      \"\"\"\n      printf -- \"- process_name: prokka\\\\n\" > ${sample_id}_prokka_provenance.yml\n      printf -- \"  tool_name: prokka\\\\n  tool_version: \\$(prokka --version 2>&1 | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_${assembler}_prokka_provenance.yml\n      prokka --cpus ${task.cpus} --compliant --locustag ${sample_id} --centre \"BCCDC-PHL\" --prefix \"${sample_id}\" ${assembly}\n      cp ${sample_id}/${sample_id}.gbk ${sample_id}_${assembler}_prokka.gbk\n      cp ${sample_id}/${sample_id}.gff ${sample_id}_${assembler}_prokka.gff\n      \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "      \"\"\"\n      printf -- \"- process_name: prokka\\\\n\" > ${sample_id}_prokka_provenance.yml\n      printf -- \"  tool_name: prokka\\\\n  tool_version: \\$(prokka --version 2>&1 | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_${assembler}_prokka_provenance.yml\n      prokka --cpus ${task.cpus} --compliant --locustag ${sample_id} --centre \"BCCDC-PHL\" --prefix \"${sample_id}\" ${assembly}\n      cp ${sample_id}/${sample_id}.gbk ${sample_id}_${assembler}_prokka.gbk\n      cp ${sample_id}/${sample_id}.gff ${sample_id}_${assembler}_prokka.gff\n      \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "Prokka"
        ],
        "tools_url": [
            "https://bio.tools/prokka"
        ],
        "tools_dico": [
            {
                "name": "Prokka",
                "uri": "https://bio.tools/prokka",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0781",
                            "term": "Virology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.",
                "homepage": "https://github.com/tseemann/prokka"
            }
        ],
        "inputs": [
            "sample_id",
            "assembler",
            "assembly"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_${assembler}_prokka.{gbk,gff}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "unicycler": {
        "name_process": "unicycler",
        "string_process": "process unicycler {\n\n    tag { sample_id }\n\n    publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_unicycler.{fa,gfa,log}\", mode: 'copy'\n\n    input:\n      tuple val(sample_id), path(reads_1), path(reads_2)\n\n    output:\n      tuple val(sample_id), path(\"${sample_id}_unicycler.fa\"), val(\"unicycler\"), emit: assembly\n      tuple val(sample_id), path(\"${sample_id}_unicycler.gfa\"), emit: assembly_graph\n      tuple val(sample_id), path(\"${sample_id}_unicycler.log\"), emit: log\n      tuple val(sample_id), path(\"${sample_id}_unicycler_provenance.yml\"), emit: provenance\n\n    script:\n      \"\"\"\n      printf -- \"- process_name: unicycler\\\\n\" > ${sample_id}_unicycler_provenance.yml\n      printf -- \"  tool_name: unicycler\\\\n  tool_version: \\$(unicycler --version | cut -d ' ' -f 2 | tr -d 'v')\\\\n\" >> ${sample_id}_unicycler_provenance.yml\n      unicycler --threads ${task.cpus} -1 ${reads_1} -2 ${reads_2} -o ${sample_id}_assembly\n      sed 's/^>/>${sample_id}_/' ${sample_id}_assembly/assembly.fasta > ${sample_id}_unicycler.fa\n      cp ${sample_id}_assembly/assembly.gfa ${sample_id}_unicycler.gfa\n      cp ${sample_id}_assembly/unicycler.log ${sample_id}_unicycler.log\n      \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "      \"\"\"\n      printf -- \"- process_name: unicycler\\\\n\" > ${sample_id}_unicycler_provenance.yml\n      printf -- \"  tool_name: unicycler\\\\n  tool_version: \\$(unicycler --version | cut -d ' ' -f 2 | tr -d 'v')\\\\n\" >> ${sample_id}_unicycler_provenance.yml\n      unicycler --threads ${task.cpus} -1 ${reads_1} -2 ${reads_2} -o ${sample_id}_assembly\n      sed 's/^>/>${sample_id}_/' ${sample_id}_assembly/assembly.fasta > ${sample_id}_unicycler.fa\n      cp ${sample_id}_assembly/assembly.gfa ${sample_id}_unicycler.gfa\n      cp ${sample_id}_assembly/unicycler.log ${sample_id}_unicycler.log\n      \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Unicycler"
        ],
        "tools_url": [
            "https://bio.tools/unicycler"
        ],
        "tools_dico": [
            {
                "name": "Unicycler",
                "uri": "https://bio.tools/unicycler",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3301",
                            "term": "Microbiology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0925",
                                "term": "Sequence assembly"
                            }
                        ]
                    }
                ],
                "description": "A tool for assembling bacterial genomes from a combination of short (2nd generation) and long (3rd generation) sequencing reads.",
                "homepage": "https://github.com/rrwick/Unicycler"
            }
        ],
        "inputs": [
            "sample_id",
            "reads_1",
            "reads_2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_unicycler.{fa,gfa,log}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "hash_files": {
        "name_process": "hash_files",
        "string_process": "process hash_files {\n\n    tag { sample_id + \" / \" + file_type }\n\n    input:\n    tuple  val(sample_id), path(files_to_hash), val(file_type)\n\n    output:\n    tuple  val(sample_id), path(\"${sample_id}_${file_type}.sha256.csv\"), emit: csv\n    tuple  val(sample_id), path(\"${sample_id}_${file_type}_provenance.yml\"), emit: provenance\n\n    script:\n    \"\"\"\n    shasum -a 256 ${files_to_hash} | tr -s ' ' ',' > ${sample_id}_${file_type}.sha256.csv\n    while IFS=',' read -r hash filename; do\n      printf -- \"- input_filename: \\$filename\\\\n  sha256: \\$hash\\\\n\" >> ${sample_id}_${file_type}_provenance.yml\n    done < ${sample_id}_${file_type}.sha256.csv\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    shasum -a 256 ${files_to_hash} | tr -s ' ' ',' > ${sample_id}_${file_type}.sha256.csv\n    while IFS=',' read -r hash filename; do\n      printf -- \"- input_filename: \\$filename\\\\n  sha256: \\$hash\\\\n\" >> ${sample_id}_${file_type}_provenance.yml\n    done < ${sample_id}_${file_type}.sha256.csv\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "file_type",
            "files_to_hash"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id + \" / \" + file_type }"
        ],
        "when": "",
        "stub": ""
    },
    "collect_provenance": {
        "name_process": "collect_provenance",
        "string_process": "process collect_provenance {\n\n  tag { sample_id }\n\n  executor 'local'\n\n  publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_*_provenance.yml\", mode: 'copy'\n\n  input:\n  tuple val(sample_id), path(provenance_files)\n\n  output:\n  tuple val(sample_id), file(\"${sample_id}_*_provenance.yml\")\n\n  script:\n  \"\"\"\n  cat ${provenance_files} > ${sample_id}_\\$(date +%Y%m%d%H%M%S)_provenance.yml\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  cat ${provenance_files} > ${sample_id}_\\$(date +%Y%m%d%H%M%S)_provenance.yml\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "provenance_files"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample_id"
        ],
        "nb_outputs": 1,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "executor 'local'",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_*_provenance.yml\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "pipeline_provenance": {
        "name_process": "pipeline_provenance",
        "string_process": "\nprocess pipeline_provenance {\n\n  tag { pipeline_name + \" / \" + pipeline_version }\n\n  executor 'local'\n\n  input:\n  tuple val(pipeline_name), val(pipeline_version), val(analysis_start)\n\n  output:\n  file(\"pipeline_provenance.yml\")\n\n  script:\n  \"\"\"\n  printf -- \"- pipeline_name: ${pipeline_name}\\\\n  pipeline_version: ${pipeline_version}\\\\n- timestamp_analysis_start: ${analysis_start}\\\\n\" > pipeline_provenance.yml\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  printf -- \"- pipeline_name: ${pipeline_name}\\\\n  pipeline_version: ${pipeline_version}\\\\n- timestamp_analysis_start: ${analysis_start}\\\\n\" > pipeline_provenance.yml\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pipeline_name",
            "pipeline_version",
            "analysis_start"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { pipeline_name + \" / \" + pipeline_version }",
            "executor 'local'"
        ],
        "when": "",
        "stub": ""
    },
    "fastp": {
        "name_process": "fastp",
        "string_process": "process fastp {\n\n    tag { sample_id }\n\n    publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_fastp.json\", mode: 'copy'\n\n    input:\n    tuple val(sample_id), path(reads_1), path(reads_2)\n\n    output:\n    tuple val(sample_id), path(\"${sample_id}_R1.trim.fastq.gz\"), path(\"${sample_id}_R2.trim.fastq.gz\"), emit: trimmed_reads\n    tuple val(sample_id), path(\"${sample_id}_fastp.json\"), emit: json\n    tuple val(sample_id), path(\"${sample_id}_fastp_provenance.yml\"), emit: provenance\n    \n\n    script:\n    \"\"\"\n    printf -- \"- process_name: fastp\\\\n\" > ${sample_id}_fastp_provenance.yml\n    printf -- \"  tool_name: fastp\\\\n  tool_version: \\$(fastp --version 2>&1 | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_fastp_provenance.yml\n    fastp \\\n      -t ${task.cpus} \\\n      -i ${reads_1} \\\n      -I ${reads_2} \\\n      --cut_tail \\\n      -o ${sample_id}_R1.trim.fastq.gz \\\n      -O ${sample_id}_R2.trim.fastq.gz \\\n      -j ${sample_id}_fastp.json\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    printf -- \"- process_name: fastp\\\\n\" > ${sample_id}_fastp_provenance.yml\n    printf -- \"  tool_name: fastp\\\\n  tool_version: \\$(fastp --version 2>&1 | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_fastp_provenance.yml\n    fastp \\\n      -t ${task.cpus} \\\n      -i ${reads_1} \\\n      -I ${reads_2} \\\n      --cut_tail \\\n      -o ${sample_id}_R1.trim.fastq.gz \\\n      -O ${sample_id}_R2.trim.fastq.gz \\\n      -j ${sample_id}_fastp.json\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "sample_id",
            "reads_1",
            "reads_2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_fastp.json\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "fastp_json_to_csv": {
        "name_process": "fastp_json_to_csv",
        "string_process": "\nprocess fastp_json_to_csv {\n\n  tag { sample_id }\n\n  executor 'local'\n\n  publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_fastp.csv\", mode: 'copy'\n\n  input:\n  tuple val(sample_id), path(fastp_json)\n\n  output:\n  tuple val(sample_id), path(\"${sample_id}_fastp.csv\")\n\n  script:\n  \"\"\"\n  fastp_json_to_csv.py -s ${sample_id} ${fastp_json} > ${sample_id}_fastp.csv\n  \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "  \"\"\"\n  fastp_json_to_csv.py -s ${sample_id} ${fastp_json} > ${sample_id}_fastp.csv\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "fastp_json"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample_id"
        ],
        "nb_outputs": 1,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "executor 'local'",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_fastp.csv\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "quast": {
        "name_process": "quast",
        "string_process": "process quast {\n\n    tag { sample_id }\n\n    input:\n      tuple val(sample_id), path(assembly), val(assembler)\n\n    output:\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_quast.tsv\"), val(assembler), emit: tsv\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_quast_provenance.yml\"), emit: provenance\n\n    script:\n      \"\"\"\n      printf -- \"- process_name: quast\\\\n\" > ${sample_id}_quast_provenance.yml\n      printf -- \"  tool_name: quast\\\\n  tool_version: \\$(quast --version | cut -d ' ' -f 2 | tr -d 'v')\\\\n\" >> ${sample_id}_${assembler}_quast_provenance.yml\n      quast --threads ${task.cpus} ${assembly} --space-efficient --fast --output-dir ${sample_id}\n      mv ${sample_id}/transposed_report.tsv ${sample_id}_${assembler}_quast.tsv\n      \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "      \"\"\"\n      printf -- \"- process_name: quast\\\\n\" > ${sample_id}_quast_provenance.yml\n      printf -- \"  tool_name: quast\\\\n  tool_version: \\$(quast --version | cut -d ' ' -f 2 | tr -d 'v')\\\\n\" >> ${sample_id}_${assembler}_quast_provenance.yml\n      quast --threads ${task.cpus} ${assembly} --space-efficient --fast --output-dir ${sample_id}\n      mv ${sample_id}/transposed_report.tsv ${sample_id}_${assembler}_quast.tsv\n      \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "QUAST"
        ],
        "tools_url": [
            "https://bio.tools/quast"
        ],
        "tools_dico": [
            {
                "name": "QUAST",
                "uri": "https://bio.tools/quast",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly validation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "QUAST stands for QUality ASsessment Tool.  \nIt evaluates a quality of genome assemblies by computing various metrics and providing nice reports.",
                "homepage": "http://quast.sourceforge.net/quast"
            }
        ],
        "inputs": [
            "sample_id",
            "assembler",
            "assembly"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }"
        ],
        "when": "",
        "stub": ""
    },
    "parse_quast_report": {
        "name_process": "parse_quast_report",
        "string_process": "\nprocess parse_quast_report {\n\n    tag { sample_id }\n\n    executor 'local'\n\n    publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_${assembler}_quast.csv\", mode: 'copy'\n\n    input:\n      tuple val(sample_id), path(quast_report), val(assembler)\n\n    output:\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_quast.csv\")\n\n    script:\n      \"\"\"\n      parse_quast_report.py ${quast_report} > ${sample_id}_${assembler}_quast.csv\n      \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "      \"\"\"\n      parse_quast_report.py ${quast_report} > ${sample_id}_${assembler}_quast.csv\n      \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "assembler",
            "quast_report"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample_id"
        ],
        "nb_outputs": 1,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "executor 'local'",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_${assembler}_quast.csv\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "bakta": {
        "name_process": "bakta",
        "string_process": "process bakta {\n\n    tag { sample_id }\n\n    publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}*.{gbk,gff,json,log}\", mode: 'copy'\n\n    input:\n      tuple val(sample_id), path(assembly), val(assembler)\n\n    output:\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_bakta.gbk\"), emit: gbk\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_bakta.gff\"), emit: gff\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_bakta.json\"), emit: json\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_bakta.log\"), emit: log\n      tuple val(sample_id), path(\"${sample_id}_${assembler}_bakta_provenance.yml\"), emit: provenance\n\n    script:\n      \"\"\"\n      printf -- \"- process_name: bakta\\\\n\" > ${sample_id}_bakta_provenance.yml\n      printf -- \"  tool_name: bakta\\\\n  tool_version: \\$(bakta --version | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_${assembler}_bakta_provenance.yml\n      bakta --db ${params.bakta_db} --threads ${task.cpus} --compliant --keep-contig-headers --locus-tag ${sample_id} --prefix \"${sample_id}\" ${assembly}\n      cp ${sample_id}.gff3 ${sample_id}_${assembler}_bakta.gff\n      cp ${sample_id}.gbff ${sample_id}_${assembler}_bakta.gbk\n      cp ${sample_id}.json ${sample_id}_${assembler}_bakta.json\n      cp ${sample_id}.log ${sample_id}_${assembler}_bakta.log\n      \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "      \"\"\"\n      printf -- \"- process_name: bakta\\\\n\" > ${sample_id}_bakta_provenance.yml\n      printf -- \"  tool_name: bakta\\\\n  tool_version: \\$(bakta --version | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_${assembler}_bakta_provenance.yml\n      bakta --db ${params.bakta_db} --threads ${task.cpus} --compliant --keep-contig-headers --locus-tag ${sample_id} --prefix \"${sample_id}\" ${assembly}\n      cp ${sample_id}.gff3 ${sample_id}_${assembler}_bakta.gff\n      cp ${sample_id}.gbff ${sample_id}_${assembler}_bakta.gbk\n      cp ${sample_id}.json ${sample_id}_${assembler}_bakta.json\n      cp ${sample_id}.log ${sample_id}_${assembler}_bakta.log\n      \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "assembler",
            "assembly"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}*.{gbk,gff,json,log}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "shovill": {
        "name_process": "shovill",
        "string_process": "process shovill {\n\n    tag { sample_id }\n\n    publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_shovill.{fa,log}\", mode: 'copy'\n\n\n    input:\n      tuple val(sample_id), path(reads_1), path(reads_2)\n\n    output:\n      tuple val(sample_id), path(\"${sample_id}_shovill.fa\"), val(\"shovill\"), emit: assembly\n      tuple val(sample_id), path(\"${sample_id}_shovill.log\"), emit: log\n      tuple val(sample_id), path(\"${sample_id}_shovill_provenance.yml\"), emit: provenance\n\n    script:\n      \"\"\"\n      printf -- \"- process_name: shovill\\\\n\" > ${sample_id}_shovill_provenance.yml\n      printf -- \"  tool_name: shovill\\\\n  tool_version: \\$(shovill --version | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_shovill_provenance.yml\n      shovill --cpus ${task.cpus} --trim --namefmt \\\"${sample_id}_contig%0d\\\" --outdir ${sample_id}_assembly --R1 ${reads_1} --R2 ${reads_2}\n      cp ${sample_id}_assembly/contigs.fa ${sample_id}_shovill.fa\n      cp ${sample_id}_assembly/shovill.log ${sample_id}_shovill.log\n      \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "      \"\"\"\n      printf -- \"- process_name: shovill\\\\n\" > ${sample_id}_shovill_provenance.yml\n      printf -- \"  tool_name: shovill\\\\n  tool_version: \\$(shovill --version | cut -d ' ' -f 2)\\\\n\" >> ${sample_id}_shovill_provenance.yml\n      shovill --cpus ${task.cpus} --trim --namefmt \\\"${sample_id}_contig%0d\\\" --outdir ${sample_id}_assembly --R1 ${reads_1} --R2 ${reads_2}\n      cp ${sample_id}_assembly/contigs.fa ${sample_id}_shovill.fa\n      cp ${sample_id}_assembly/shovill.log ${sample_id}_shovill.log\n      \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "shovill"
        ],
        "tools_url": [
            "https://bio.tools/shovill"
        ],
        "tools_dico": [
            {
                "name": "shovill",
                "uri": "https://bio.tools/shovill",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3301",
                            "term": "Microbiology"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ]
                    }
                ],
                "description": "Shovill is a pipeline for assembly of bacterial isolate genomes from Illumina paired-end reads.  Shovill uses SPAdes at its core, but alters the steps before and after the primary assembly step to get similar results in less time. Shovill also supports other assemblers like SKESA, Velvet and Megahit, so you can take advantage of the pre- and post-processing the Shovill provides with those too.",
                "homepage": "https://github.com/tseemann/shovill"
            }
        ],
        "inputs": [
            "sample_id",
            "reads_1",
            "reads_2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "BCCDC-PHL__routine-assembly",
        "directive": [
            "tag { sample_id }",
            "publishDir params.versioned_outdir ? \"${params.outdir}/${sample_id}/${params.pipeline_short_name}-v${params.pipeline_minor_version}-output\" : \"${params.outdir}/${sample_id}\", pattern: \"${sample_id}_shovill.{fa,log}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}