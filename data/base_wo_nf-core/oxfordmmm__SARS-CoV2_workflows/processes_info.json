{
    "viridianPrimers": {
        "name_process": "viridianPrimers",
        "string_process": "process viridianPrimers {\n       \n                                                                               \n            \n             \n      \n\n    tag { prefix }\n    label 'viridian'\n    publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}\n    publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}\n    publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null}\n    if (params.TESToutputMODE){\n        publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null}\n    }\n\n    input:\n        tuple val(prefix), path(\"${prefix}_1.fastq.gz\"), path(\"${prefix}_2.fastq.gz\"),path('primers'), path('ref.fa')\n\n    output:\n        tuple val(prefix), path(\"${prefix}_outdir/consensus.fa\"), emit: consensus\n        tuple val(prefix), path(\"${prefix}_outdir/log.json\"), emit: coverage\n        tuple val(prefix), path(\"${prefix}_outdir/variants.vcf\"), emit: vcfs\n        tuple val(prefix), path(\"${prefix}_outdir/reference_mapped.bam\"), emit: bam\n\n\n    script:\n    \"\"\"\n    viridian_workflow run_one_sample \\\n            --tech illumina \\\n            --ref_fasta ref.fa \\\n            --amplicon_json primers \\\n            --reads1 ${prefix}_1.fastq.gz \\\n            --reads2 ${prefix}_2.fastq.gz \\\n            --outdir ${prefix}_outdir/ \\\n            --sample_name ${prefix} \\\n            --keep_bam\n    \"\"\" \n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n    viridian_workflow run_one_sample \\\n            --tech illumina \\\n            --ref_fasta ref.fa \\\n            --amplicon_json primers \\\n            --reads1 ${prefix}_1.fastq.gz \\\n            --reads2 ${prefix}_2.fastq.gz \\\n            --outdir ${prefix}_outdir/ \\\n            --sample_name ${prefix} \\\n            --keep_bam\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'viridian'",
            "publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}",
            "publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}",
            "publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null} if (params.TESToutputMODE){ publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null} }"
        ],
        "when": "",
        "stub": ""
    },
    "viridianAuto": {
        "name_process": "viridianAuto",
        "string_process": "\nprocess viridianAuto {\n        \n                                                                               \n            \n             \n      \n\n    tag { prefix }\n    label 'viridian'\n    publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}\n    publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}\n    publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null}\n    if (params.TESToutputMODE){\n        publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null}\n    }\n\n    input:\n        tuple val(prefix), path(\"${prefix}_1.fastq.gz\"), path(\"${prefix}_2.fastq.gz\"), path('ref.fa')\n\n\n    output:\n        tuple val(prefix), path(\"${prefix}_outdir/consensus.fa\"), emit: consensus\n        tuple val(prefix), path(\"${prefix}_outdir/log.json\"), emit: coverage\n        tuple val(prefix), path(\"${prefix}_outdir/variants.vcf\"), emit: vcfs\n        tuple val(prefix), path(\"${prefix}_outdir/reference_mapped.bam\"), emit: bam\n\n    script:\n    \"\"\"\n    viridian_workflow run_one_sample \\\n            --tech illumina \\\n            --ref_fasta ref.fa \\\n            --reads1 ${prefix}_1.fastq.gz \\\n            --reads2 ${prefix}_2.fastq.gz \\\n            --outdir ${prefix}_outdir/ \\\n            --sample_name ${prefix} \\\n            --keep_bam\n    \"\"\" \n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n    viridian_workflow run_one_sample \\\n            --tech illumina \\\n            --ref_fasta ref.fa \\\n            --reads1 ${prefix}_1.fastq.gz \\\n            --reads2 ${prefix}_2.fastq.gz \\\n            --outdir ${prefix}_outdir/ \\\n            --sample_name ${prefix} \\\n            --keep_bam\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'viridian'",
            "publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}",
            "publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}",
            "publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null} if (params.TESToutputMODE){ publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null} }"
        ],
        "when": "",
        "stub": ""
    },
    "viridianONTPrimers": {
        "name_process": "viridianONTPrimers",
        "string_process": "\nprocess viridianONTPrimers {\n       \n                                                                               \n            \n             \n      \n\n    tag { prefix }\n    label 'viridian'\n    publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}\n    publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}\n    publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null}\n    if (params.TESToutputMODE){\n        publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null}\n    }\n\n    input:\n        tuple val(prefix), path(\"${prefix}.fastq.gz\"), path('primers'), path('ref.fa')\n    \n    output:\n        tuple val(prefix), path(\"${prefix}_outdir/consensus.fa\"), emit: consensus\n        tuple val(prefix), path(\"${prefix}_outdir/log.json\"), emit: coverage\n        tuple val(prefix), path(\"${prefix}_outdir/variants.vcf\"), emit: vcfs\n        tuple val(prefix), path(\"${prefix}_outdir/reference_mapped.bam\"), emit: bam\n\n    script:\n        \"\"\"\n        viridian_workflow run_one_sample \\\n\t\t--tech ont \\\n                --ref_fasta ref.fa \\\n\t\t--amplicon_json primers \\\n\t\t--reads ${prefix}.fastq.gz \\\n\t\t--outdir ${prefix}_outdir/ \\\n\t\t--sample_name ${prefix} \\\n\t\t--keep_bam\n        \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "        \"\"\"\n        viridian_workflow run_one_sample \\\n\t\t--tech ont \\\n                --ref_fasta ref.fa \\\n\t\t--amplicon_json primers \\\n\t\t--reads ${prefix}.fastq.gz \\\n\t\t--outdir ${prefix}_outdir/ \\\n\t\t--sample_name ${prefix} \\\n\t\t--keep_bam\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'viridian'",
            "publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}",
            "publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}",
            "publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null} if (params.TESToutputMODE){ publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null} }"
        ],
        "when": "",
        "stub": ""
    },
    "viridianONTAuto": {
        "name_process": "viridianONTAuto",
        "string_process": "\nprocess viridianONTAuto {\n       \n                                                                               \n            \n             \n      \n\n    tag { prefix }\n    label 'viridian'\n    publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}\n    publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}\n    publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null}\n    if (params.TESToutputMODE){\n        publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null}\n    }\n\n\n    input:\n        tuple val(prefix), path(\"${prefix}.fastq.gz\"),path('ref.fa')\n\n    output:\n        tuple val(prefix), path(\"${prefix}_outdir/consensus.fa\"), emit: consensus\n        tuple val(prefix), path(\"${prefix}_outdir/log.json\"), emit: coverage\n        tuple val(prefix), path(\"${prefix}_outdir/variants.vcf\"), emit: vcfs\n        tuple val(prefix), path(\"${prefix}_outdir/reference_mapped.bam\"), emit: bam\n\n    script:\n        \"\"\"\n        viridian_workflow run_one_sample \\\n\t\t--tech ont \\\n                --ref_fasta ref.fa \\\n\t\t--reads ${prefix}.fastq.gz \\\n\t\t--outdir ${prefix}_outdir/ \\\n\t\t--sample_name ${prefix} \\\n\t\t--keep_bam\n        \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "        \"\"\"\n        viridian_workflow run_one_sample \\\n\t\t--tech ont \\\n                --ref_fasta ref.fa \\\n\t\t--reads ${prefix}.fastq.gz \\\n\t\t--outdir ${prefix}_outdir/ \\\n\t\t--sample_name ${prefix} \\\n\t\t--keep_bam\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'viridian'",
            "publishDir \"${params.outdir}/consensus_seqs/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".fa\") ? \"${prefix}.fasta\":null}",
            "publishDir \"${params.outdir}/VCF/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".vcf\") ? \"${prefix}.vcf\":null}",
            "publishDir \"${params.outdir}/qc/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".json\") ? \"${prefix}.json\":null} if (params.TESToutputMODE){ publishDir \"${params.outdir}/bam/\", mode: 'copy', saveAs: { filename -> filename.endsWith(\".bam\") ? \"${prefix}.bam\":null} }"
        ],
        "when": "",
        "stub": ""
    },
    "getObjFiles": {
        "name_process": "getObjFiles",
        "string_process": "process getObjFiles {\n       \n                                                                                                                                                                              \n            \n             \n      \n\n    tag { prefix }\n    label 'oci_pipe'\n\n    input:\n        tuple val(bucket), val(filePrefix), val(prefix)\n\n    output:\n        tuple val(prefix), path(\"${prefix}*1.fastq.gz\"), path(\"${prefix}*2.fastq.gz\"), emit: fqs\n\n    script:\n        \"\"\"\n\toci os object bulk-download \\\n\t\t-bn $bucket \\\n\t\t--download-dir ./ \\\n\t\t--overwrite \\\n\t\t--auth instance_principal \\\n\t\t--prefix $filePrefix \n    \n    if [ \\$(find * -type d | wc -l) -gt 0 ]\n    then \n        mv */*.fastq.gz .\n    fi\n\t\"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "        \"\"\"\n\toci os object bulk-download \\\n\t\t-bn $bucket \\\n\t\t--download-dir ./ \\\n\t\t--overwrite \\\n\t\t--auth instance_principal \\\n\t\t--prefix $filePrefix \n    \n    if [ \\$(find * -type d | wc -l) -gt 0 ]\n    then \n        mv */*.fastq.gz .\n    fi\n\t\"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "Roci"
        ],
        "tools_url": [
            "https://bio.tools/roci"
        ],
        "tools_dico": [
            {
                "name": "Roci",
                "uri": "https://bio.tools/roci",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0797",
                            "term": "Comparative genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0325",
                                    "term": "Phylogenetic tree comparison"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0872",
                                "term": "Phylogenetic tree"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2523",
                                "term": "Phylogenetic data"
                            }
                        ]
                    }
                ],
                "description": "Reconstruct ancestral gene orders of a phylogenetic tree. Given the topology of a phylogenetic tree and the gene orders of the leaf nodes, it calculates sets of gene orders for the inner nodes, represented by conserved intervals.",
                "homepage": "https://bibiserv.cebitec.uni-bielefeld.de/roci"
            }
        ],
        "inputs": [
            "bucket",
            "filePrefix",
            "prefix"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'oci_pipe'"
        ],
        "when": "",
        "stub": ""
    },
    "checkSizeSubsample": {
        "name_process": "checkSizeSubsample",
        "string_process": "\nprocess checkSizeSubsample {\n       \n                                                        \n            \n             \n      \n\n    tag { prefix }\n    label 'oci_pipe'\n\n    input:\n        tuple val(prefix), path(\"${prefix}_1.fastq.gz\"), path(\"${prefix}_2.fastq.gz\")\n\n    output:\n        tuple val(prefix), path(\"${prefix}_1.fastq.gz\"), path(\"${prefix}_2.fastq.gz\"), emit: checked_fqs\n\n    script:\n        maxReadsIll=params.maxReadsIll\n        \"\"\"\n        lines=\\$(zcat ${prefix}_1.fastq.gz | wc -l);reads=\\$((\\$lines / 4))\n        if (( \\$reads > $maxReadsIll ))\n        then\n            echo \"${prefix} has \\$reads reads which is more than maximum of $maxReadsIll. Subsampling down to this value.\"\n            gunzip -c ${prefix}_1.fastq.gz | seqtk sample -s 100 - $maxReadsIll | gzip > ${prefix}_1_sub.fastq.gz\n            mv ${prefix}_1_sub.fastq.gz ${prefix}_1.fastq.gz\n\n            gunzip -c ${prefix}_2.fastq.gz | seqtk sample -s 100 - $maxReadsIll | gzip > ${prefix}_2_sub.fastq.gz\n            mv ${prefix}_2_sub.fastq.gz ${prefix}_2.fastq.gz\n        else\n            echo \"${prefix} has \\$reads reads, no subsampling is needed\"\n        fi\n        \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "        maxReadsIll=params.maxReadsIll\n        \"\"\"\n        lines=\\$(zcat ${prefix}_1.fastq.gz | wc -l);reads=\\$((\\$lines / 4))\n        if (( \\$reads > $maxReadsIll ))\n        then\n            echo \"${prefix} has \\$reads reads which is more than maximum of $maxReadsIll. Subsampling down to this value.\"\n            gunzip -c ${prefix}_1.fastq.gz | seqtk sample -s 100 - $maxReadsIll | gzip > ${prefix}_1_sub.fastq.gz\n            mv ${prefix}_1_sub.fastq.gz ${prefix}_1.fastq.gz\n\n            gunzip -c ${prefix}_2.fastq.gz | seqtk sample -s 100 - $maxReadsIll | gzip > ${prefix}_2_sub.fastq.gz\n            mv ${prefix}_2_sub.fastq.gz ${prefix}_2.fastq.gz\n        else\n            echo \"${prefix} has \\$reads reads, no subsampling is needed\"\n        fi\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'oci_pipe'"
        ],
        "when": "",
        "stub": ""
    },
    "getObjFilesONT": {
        "name_process": "getObjFilesONT",
        "string_process": "\nprocess getObjFilesONT {\n       \n                                                                                                                                                                              \n            \n             \n      \n\n    tag { prefix }\n    label 'oci_pipe'\n\n    input:\n        tuple val(bucket), val(filePrefix), val(prefix)\n\n    output:\n        tuple val(prefix), path(\"*.fastq.gz\"), emit: fqs\n\n    script:\n        \"\"\"\n\toci os object bulk-download \\\n\t\t-bn $bucket \\\n\t\t--download-dir ./ \\\n\t\t--overwrite \\\n\t\t--auth instance_principal \\\n\t\t--prefix $filePrefix\n    \n    if [ \\$(find * -type d | wc -l) -gt 0 ]\n    then \n        mv */*.fastq.gz .\n    fi\n\t\"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        \"\"\"\n\toci os object bulk-download \\\n\t\t-bn $bucket \\\n\t\t--download-dir ./ \\\n\t\t--overwrite \\\n\t\t--auth instance_principal \\\n\t\t--prefix $filePrefix\n    \n    if [ \\$(find * -type d | wc -l) -gt 0 ]\n    then \n        mv */*.fastq.gz .\n    fi\n\t\"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "Roci"
        ],
        "tools_url": [
            "https://bio.tools/roci"
        ],
        "tools_dico": [
            {
                "name": "Roci",
                "uri": "https://bio.tools/roci",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0797",
                            "term": "Comparative genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0325",
                                    "term": "Phylogenetic tree comparison"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0872",
                                "term": "Phylogenetic tree"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2523",
                                "term": "Phylogenetic data"
                            }
                        ]
                    }
                ],
                "description": "Reconstruct ancestral gene orders of a phylogenetic tree. Given the topology of a phylogenetic tree and the gene orders of the leaf nodes, it calculates sets of gene orders for the inner nodes, represented by conserved intervals.",
                "homepage": "https://bibiserv.cebitec.uni-bielefeld.de/roci"
            }
        ],
        "inputs": [
            "bucket",
            "filePrefix",
            "prefix"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'oci_pipe'"
        ],
        "when": "",
        "stub": ""
    },
    "checkSizeSubsampleONT": {
        "name_process": "checkSizeSubsampleONT",
        "string_process": "\nprocess checkSizeSubsampleONT {\n       \n                                                        \n            \n             \n      \n\n    tag { prefix }\n    label 'oci_pipe'\n\n    input:\n        tuple val(prefix), path(\"${prefix}.fastq.gz\")\n\n    output:\n        tuple val(prefix), path(\"${prefix}.fastq.gz\"), emit: checked_fqs\n\n    script:\n        maxReadsONT=params.maxReadsONT\n        \"\"\"\n        lines=\\$(zcat ${prefix}.fastq.gz | wc -l);reads=\\$((\\$lines / 4))\n        if (( \\$reads > $maxReadsONT ))\n        then\n            echo \"${prefix} has \\$reads reads which is more than maximum of $maxReadsONT. Subsampling down to this value.\"\n            gunzip -c ${prefix}.fastq.gz | seqtk sample -s 100 - $maxReadsONT | gzip > ${prefix}_sub.fastq.gz\n            mv ${prefix}_sub.fastq.gz ${prefix}.fastq.gz\n        else\n            echo \"${prefix} has \\$reads reads, no subsampling is needed\"\n        fi\n        \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "        maxReadsONT=params.maxReadsONT\n        \"\"\"\n        lines=\\$(zcat ${prefix}.fastq.gz | wc -l);reads=\\$((\\$lines / 4))\n        if (( \\$reads > $maxReadsONT ))\n        then\n            echo \"${prefix} has \\$reads reads which is more than maximum of $maxReadsONT. Subsampling down to this value.\"\n            gunzip -c ${prefix}.fastq.gz | seqtk sample -s 100 - $maxReadsONT | gzip > ${prefix}_sub.fastq.gz\n            mv ${prefix}_sub.fastq.gz ${prefix}.fastq.gz\n        else\n            echo \"${prefix} has \\$reads reads, no subsampling is needed\"\n        fi\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { prefix }",
            "label 'oci_pipe'"
        ],
        "when": "",
        "stub": ""
    },
    "getRefFiles": {
        "name_process": "getRefFiles",
        "string_process": "\nprocess getRefFiles {\n       \n                                  \n      \n\n    output:\n    path(\"ref.fasta\"), emit: fasta\n    path(\"ref.bed\"), emit: bed\n\n    script:\n    refURL=params.refURL\n    bedURL=params.bedURL\n    \"\"\"\n    wget $refURL -O ref.fasta\n    wget $bedURL -O ref.bed\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    refURL=params.refURL\n    bedURL=params.bedURL\n    \"\"\"\n    wget $refURL -O ref.fasta\n    wget $bedURL -O ref.bed\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "uploadToBucket": {
        "name_process": "uploadToBucket",
        "string_process": "\nprocess uploadToBucket {\n    tag {prefix}\n    label 'oci_pipe'\n\n    input:\n    tuple(val(prefix), path(\"${prefix}.fasta\"), path(\"${prefix}.bam\"),path(\"${prefix}.vcf\"),path(\"${prefix}.json\"))\n\n    script:\n    bucketName=params.uploadBucket\n    \"\"\"\n    mkdir ${prefix}\n    cp ${prefix}.fasta ${prefix}/\n    cp ${prefix}.bam ${prefix}/\n    cp ${prefix}.vcf ${prefix}/\n    cp ${prefix}.json ${prefix}/\n    gzip ${prefix}/${prefix}.fasta\n\n    oci os object bulk-upload \\\n    --overwrite \\\n    --src-dir ./${prefix}/ \\\n    -bn $bucketName \\\n    --auth instance_principal \\\n    --prefix ${prefix}/ \n\n    \"\"\" \n}",
        "nb_lignes_process": 25,
        "string_script": "    bucketName=params.uploadBucket\n    \"\"\"\n    mkdir ${prefix}\n    cp ${prefix}.fasta ${prefix}/\n    cp ${prefix}.bam ${prefix}/\n    cp ${prefix}.vcf ${prefix}/\n    cp ${prefix}.json ${prefix}/\n    gzip ${prefix}/${prefix}.fasta\n\n    oci os object bulk-upload \\\n    --overwrite \\\n    --src-dir ./${prefix}/ \\\n    -bn $bucketName \\\n    --auth instance_principal \\\n    --prefix ${prefix}/ \n\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "Roci"
        ],
        "tools_url": [
            "https://bio.tools/roci"
        ],
        "tools_dico": [
            {
                "name": "Roci",
                "uri": "https://bio.tools/roci",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0797",
                            "term": "Comparative genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0325",
                                    "term": "Phylogenetic tree comparison"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0872",
                                "term": "Phylogenetic tree"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2523",
                                "term": "Phylogenetic data"
                            }
                        ]
                    }
                ],
                "description": "Reconstruct ancestral gene orders of a phylogenetic tree. Given the topology of a phylogenetic tree and the gene orders of the leaf nodes, it calculates sets of gene orders for the inner nodes, represented by conserved intervals.",
                "homepage": "https://bibiserv.cebitec.uni-bielefeld.de/roci"
            }
        ],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag {prefix}",
            "label 'oci_pipe'"
        ],
        "when": "",
        "stub": ""
    },
    "getObjCsv": {
        "name_process": "getObjCsv",
        "string_process": "\nprocess getObjCsv {\n       \n                                                                                                                                                                                         \n            \n             \n      \n\n                    \n\n    label 'oci_pipe'\n\n    input:\n        tuple val(bucket), val(path)\n\n    output:\n        path(\"*.csv\")\n\n    script:\n    \"\"\"\n    oci os object get \\\n        -bn $bucket \\\n        --auth instance_principal \\\n        --file sp3data.csv \\\n        --name $path\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    oci os object get \\\n        -bn $bucket \\\n        --auth instance_principal \\\n        --file sp3data.csv \\\n        --name $path\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "Roci"
        ],
        "tools_url": [
            "https://bio.tools/roci"
        ],
        "tools_dico": [
            {
                "name": "Roci",
                "uri": "https://bio.tools/roci",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0797",
                            "term": "Comparative genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0325",
                                    "term": "Phylogenetic tree comparison"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0872",
                                "term": "Phylogenetic tree"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2523",
                                "term": "Phylogenetic data"
                            }
                        ]
                    }
                ],
                "description": "Reconstruct ancestral gene orders of a phylogenetic tree. Given the topology of a phylogenetic tree and the gene orders of the leaf nodes, it calculates sets of gene orders for the inner nodes, represented by conserved intervals.",
                "homepage": "https://bibiserv.cebitec.uni-bielefeld.de/roci"
            }
        ],
        "inputs": [
            "bucket"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "label 'oci_pipe'"
        ],
        "when": "",
        "stub": ""
    },
    "pango": {
        "name_process": "pango",
        "string_process": "process pango {\n    tag { sampleName }\n    label 'pango'\n\n    publishDir \"${params.outdir}/analysis/pango/${params.prefix}\", mode: 'copy'\n\n    input:\n    tuple(val(sampleName),  path(fasta))\n\n    output:\n    tuple(val(sampleName), path(\"${sampleName}_lineage_report.csv\"))\n\n    script:\n    \"\"\"\n    pangolin ${fasta}\n    mv lineage_report.csv ${sampleName}_lineage_report.csv\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    pangolin ${fasta}\n    mv lineage_report.csv ${sampleName}_lineage_report.csv\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleName",
            "fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleName"
        ],
        "nb_outputs": 1,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { sampleName }",
            "label 'pango'",
            "publishDir \"${params.outdir}/analysis/pango/${params.prefix}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "download_primers": {
        "name_process": "download_primers",
        "string_process": "\nprocess  download_primers {\n    input:\n        val(primers) \n\n    output:\n        path('primers.txt')\n\n    script:\n        \"\"\"\n        wget https://raw.githubusercontent.com/iqbal-lab-org/viridian_workflow/master/data/covid-artic-v3.json -O primers.txt\n        \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "        \"\"\"\n        wget https://raw.githubusercontent.com/iqbal-lab-org/viridian_workflow/master/data/covid-artic-v3.json -O primers.txt\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "primers"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "download_nextclade_files": {
        "name_process": "download_nextclade_files",
        "string_process": "\nprocess download_nextclade_files {\n    label 'nextclade'\n\n    publishDir \"${params.outdir}/analysis/nextclade/${params.prefix}\", mode: 'copy'\n    output:\n    file('nextclade_files')\n\n    script:\n    \"\"\"\n    home=PWD\n    nextclade_ver=`(nextclade -v)`\n    nextclade dataset get --name 'sars-cov-2' --output-dir nextclade_files\n    echo \\$nextclade_ver > nextclade_files/version.txt\n\n    \"\"\"\n\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    home=PWD\n    nextclade_ver=`(nextclade -v)`\n    nextclade dataset get --name 'sars-cov-2' --output-dir nextclade_files\n    echo \\$nextclade_ver > nextclade_files/version.txt\n\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "label 'nextclade'",
            "publishDir \"${params.outdir}/analysis/nextclade/${params.prefix}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "nextclade": {
        "name_process": "nextclade",
        "string_process": "\nprocess nextclade {\n    tag { sampleName }\n    label 'nextclade'\n\n    publishDir \"${params.outdir}/analysis/nextclade/${params.prefix}\", mode: 'copy'\n\n    input:\n    tuple(val(sampleName),  path(fasta), path(reffasta), path(nextclade_files)) \n\n    output:\n    tuple val(sampleName), path(\"${sampleName}.tsv\"), emit: tsv\n    tuple val(sampleName), path(\"${sampleName}.json\"), emit: json\n\n    script:\n    \"\"\"\n    nextclade --input-fasta ${fasta} \\\n\t--input-root-seq ${reffasta} \\\n\t--input-dataset=nextclade_files \\\n\t--output-json=${sampleName}.json \\\n\t--output-tsv=${sampleName}.tsv \\\n\t--output-basename=${sampleName}\n    nextclade_ver=`(nextclade -v)`\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    nextclade --input-fasta ${fasta} \\\n\t--input-root-seq ${reffasta} \\\n\t--input-dataset=nextclade_files \\\n\t--output-json=${sampleName}.json \\\n\t--output-tsv=${sampleName}.tsv \\\n\t--output-basename=${sampleName}\n    nextclade_ver=`(nextclade -v)`\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleName",
            "fasta",
            "reffasta",
            "nextclade_files"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { sampleName }",
            "label 'nextclade'",
            "publishDir \"${params.outdir}/analysis/nextclade/${params.prefix}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "getVariantDefinitions": {
        "name_process": "getVariantDefinitions",
        "string_process": "\nprocess getVariantDefinitions {\n    label 'aln2type'\n\n    publishDir \"${params.outdir}/analysis/aln2type/${params.prefix}\", mode: 'copy'\n\n    output:\n    path \"variant_definitions\", emit: defs\n                                                          \n\n    script:\n    \"\"\"\n    git clone https://github.com/phe-genomics/variant_definitions\n    cd variant_definitions\n    git log -1 --pretty=format:\"%h\" > aln2type_variant_git_commit.txt\n    git describe --tags > aln2type_variant_version.txt\n    git config --global --add safe.directory /aln2type\n    git -C /aln2type log -1 --pretty=format:\"%h\" > aln2type_commit.txt\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    git clone https://github.com/phe-genomics/variant_definitions\n    cd variant_definitions\n    git log -1 --pretty=format:\"%h\" > aln2type_variant_git_commit.txt\n    git describe --tags > aln2type_variant_version.txt\n    git config --global --add safe.directory /aln2type\n    git -C /aln2type log -1 --pretty=format:\"%h\" > aln2type_commit.txt\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "label 'aln2type'",
            "publishDir \"${params.outdir}/analysis/aln2type/${params.prefix}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "getWorkflowCommit": {
        "name_process": "getWorkflowCommit",
        "string_process": "\nprocess getWorkflowCommit {\n    label 'sars_cov2_workflows'\n\n    output:\n    path \"workflowcommit.txt\", emit: commit\n\n    script:\n    \"\"\"\n    git config --global --add safe.directory $projectDir\n    git -C $projectDir log -1 --pretty=format:\"%h\" > workflowcommit.txt\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    git config --global --add safe.directory $projectDir\n    git -C $projectDir log -1 --pretty=format:\"%h\" > workflowcommit.txt\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "label 'sars_cov2_workflows'"
        ],
        "when": "",
        "stub": ""
    },
    "aln2type": {
        "name_process": "aln2type",
        "string_process": "\nprocess aln2type {\n    tag { sampleName }\n    label 'aln2type'\n\n    publishDir \"${params.outdir}/analysis/aln2type/${params.prefix}\", mode: 'copy'\n\n    input:\n    tuple(val(sampleName),  path(fasta),path(variant_definitions), path(reffasta), path(\"*\"))\n\n    output:\n    tuple(val(sampleName), path(\"${sampleName}.csv\")) optional true\n\n    script:\n    \"\"\"\n    cat $reffasta  ${fasta} > unaligned.fasta\n    mafft --auto unaligned.fasta > aln.fasta\n    aln2type sample_json_out \\\n\tsample_csv_out \\\n\t--output_unclassified \\\n\t${sampleName}.csv \\\n\tMN908947.3 \\\n\taln.fasta \\\n\tvariant_definitions/variant_yaml/*.yml\n\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    cat $reffasta  ${fasta} > unaligned.fasta\n    mafft --auto unaligned.fasta > aln.fasta\n    aln2type sample_json_out \\\n\tsample_csv_out \\\n\t--output_unclassified \\\n\t${sampleName}.csv \\\n\tMN908947.3 \\\n\taln.fasta \\\n\tvariant_definitions/variant_yaml/*.yml\n\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "MAFFT"
        ],
        "tools_url": [
            "https://bio.tools/MAFFT"
        ],
        "tools_dico": [
            {
                "name": "MAFFT",
                "uri": "https://bio.tools/MAFFT",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "MAFFT (Multiple Alignment using Fast Fourier Transform) is a high speed multiple sequence alignment program.",
                "homepage": "http://mafft.cbrc.jp/alignment/server/index.html"
            }
        ],
        "inputs": [
            "sampleName",
            "fasta",
            "variant_definitions",
            "reffasta"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleName"
        ],
        "nb_outputs": 1,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { sampleName }",
            "label 'aln2type'",
            "publishDir \"${params.outdir}/analysis/aln2type/${params.prefix}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "makeReport": {
        "name_process": "makeReport",
        "string_process": "\nprocess makeReport {\n    tag { sampleName }\n    label 'sars_cov2_workflows'\n\n    publishDir \"${params.outdir}/analysis/report/${params.prefix}\", mode: 'copy'\n\n    input:\n    tuple(val(sampleName), path('pango.csv'), path('aln2type.csv'), path('nextclade.tsv'), path('nextclade.json'),\n\tpath('workflow_commit.txt'), val(manifest_ver), path(nextclade_files),\n\tpath(variant_definitions), path('consensus.fasta'),path('ref.fasta'))\n\n    output:\n    tuple val(sampleName),path(\"${sampleName}_report.tsv\"), emit: tsv\n    tuple val(sampleName),path(\"${sampleName}_report.json\"), emit: json\n\n    script:\n    \"\"\"\n    makeReport.py ${sampleName} ${manifest_ver}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    makeReport.py ${sampleName} ${manifest_ver}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleName",
            "manifest_ver",
            "nextclade_files",
            "variant_definitions"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { sampleName }",
            "label 'sars_cov2_workflows'",
            "publishDir \"${params.outdir}/analysis/report/${params.prefix}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "FN4_upload": {
        "name_process": "FN4_upload",
        "string_process": "\nprocess FN4_upload {\n    tag { sampleName }\n    label 'fn4'\n\n    input:\n    tuple(val(sampleName),  file('consensus.fasta'), path(variant_definitions), path(reffasta), path(\"*\"))\n\n    script:\n    \"\"\"\n    mafft --auto \\\n        --thread 1 \\\n        --addfull 'consensus.fasta' \\\n        --keeplength $reffasta \\\n        > ${sampleName}_wuhan.fa\n\n    FN4ormater.py -i ${sampleName}_wuhan.fa -r MN908947.3 -s ${sampleName} -o ${sampleName}.fasta\n\n    oci os object put \\\n\t-bn ${params.bucketNameFN4} \\\n\t--force \\\n    --auth instance_principal \\\n\t--file ${sampleName}.fasta \\\n\t--metadata \"{\\\\\"sampleID\\\\\":\\\\\"$sampleName\\\\\"}\"\n\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    mafft --auto \\\n        --thread 1 \\\n        --addfull 'consensus.fasta' \\\n        --keeplength $reffasta \\\n        > ${sampleName}_wuhan.fa\n\n    FN4ormater.py -i ${sampleName}_wuhan.fa -r MN908947.3 -s ${sampleName} -o ${sampleName}.fasta\n\n    oci os object put \\\n\t-bn ${params.bucketNameFN4} \\\n\t--force \\\n    --auth instance_principal \\\n\t--file ${sampleName}.fasta \\\n\t--metadata \"{\\\\\"sampleID\\\\\":\\\\\"$sampleName\\\\\"}\"\n\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "MAFFT",
            "Roci"
        ],
        "tools_url": [
            "https://bio.tools/MAFFT",
            "https://bio.tools/roci"
        ],
        "tools_dico": [
            {
                "name": "MAFFT",
                "uri": "https://bio.tools/MAFFT",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "MAFFT (Multiple Alignment using Fast Fourier Transform) is a high speed multiple sequence alignment program.",
                "homepage": "http://mafft.cbrc.jp/alignment/server/index.html"
            },
            {
                "name": "Roci",
                "uri": "https://bio.tools/roci",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0797",
                            "term": "Comparative genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0325",
                                    "term": "Phylogenetic tree comparison"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0872",
                                "term": "Phylogenetic tree"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2523",
                                "term": "Phylogenetic data"
                            }
                        ]
                    }
                ],
                "description": "Reconstruct ancestral gene orders of a phylogenetic tree. Given the topology of a phylogenetic tree and the gene orders of the leaf nodes, it calculates sets of gene orders for the inner nodes, represented by conserved intervals.",
                "homepage": "https://bibiserv.cebitec.uni-bielefeld.de/roci"
            }
        ],
        "inputs": [
            "sampleName",
            "variant_definitions",
            "reffasta"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { sampleName }",
            "label 'fn4'"
        ],
        "when": "",
        "stub": ""
    },
    "getGFF3": {
        "name_process": "getGFF3",
        "string_process": "\nprocess getGFF3 {\n    label 'bcftools'\n\n    output:\n    path \"MN908947.3.gff3\"\n\n    script:\n    \"\"\"\n    esearch -db nucleotide -query \"MN908947.3\" | efetch -format gb > MN908947.3.gb\n\n    cat MN908947.3.gb | gbk2gff3.py > MN908947.3.gff3\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n    esearch -db nucleotide -query \"MN908947.3\" | efetch -format gb > MN908947.3.gb\n\n    cat MN908947.3.gb | gbk2gff3.py > MN908947.3.gff3\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "QResearch",
            "eFetch Snp"
        ],
        "tools_url": [
            "https://bio.tools/QResearch",
            "https://bio.tools/efetch_snp"
        ],
        "tools_dico": [
            {
                "name": "QResearch",
                "uri": "https://bio.tools/QResearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatric medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "https://en.wikipedia.org/wiki/Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3283",
                                    "term": "Anonymisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3283",
                                    "term": "Data anonymisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "General practice database for research.",
                "homepage": "http://www.qresearch.org"
            },
            {
                "name": "eFetch Snp",
                "uri": "https://bio.tools/efetch_snp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Get SNPs information given SNP ID list.",
                "homepage": "http://www.ncbi.nlm.nih.gov/corehtml/query/static/efetchseq_help.html"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "label 'bcftools'"
        ],
        "when": "",
        "stub": ""
    },
    "bcftools_csq": {
        "name_process": "bcftools_csq",
        "string_process": "\nprocess bcftools_csq {\n    tag { sampleName }\n    label 'bcftools'\n\n    publishDir \"${params.outdir}/analysis/bcftools/${params.prefix}\", mode: 'copy'\n\n    input:\n    tuple(val(sampleName), path('vcf'), path('reffasta'), path('GFF3'))\n\n    output:\n    tuple(val(sampleName), path(\"${sampleName}.vcf\")) optional true\n\n    script:\n    \"\"\"\n    bcftools csq \\\n\t-f reffasta \\\n\t-g GFF3 \\\n\tvcf \\\n\t-Ot -o ${sampleName}.vcf \\\n\t--force\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    bcftools csq \\\n\t-f reffasta \\\n\t-g GFF3 \\\n\tvcf \\\n\t-Ot -o ${sampleName}.vcf \\\n\t--force\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "BCFtools",
            "vcfR"
        ],
        "tools_url": [
            "https://bio.tools/bcftools",
            "https://bio.tools/vcfr"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "vcfR",
                "uri": "https://bio.tools/vcfr",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Facilitates easy manipulation of variant call format (VCF) data. Functions are provided to rapidly read from and write to VCF files. Once VCF data is read into R a parser function extracts matrices of data. This information can then be used for quality control or other purposes.",
                "homepage": "https://cran.r-project.org/web/packages/vcfR/index.html"
            }
        ],
        "inputs": [
            "sampleName"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleName"
        ],
        "nb_outputs": 1,
        "name_workflow": "oxfordmmm__SARS-CoV2_workflows",
        "directive": [
            "tag { sampleName }",
            "label 'bcftools'",
            "publishDir \"${params.outdir}/analysis/bcftools/${params.prefix}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}