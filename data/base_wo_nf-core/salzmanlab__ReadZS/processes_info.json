{
    "GET_SOFTWARE_VERSIONS": {
        "name_process": "GET_SOFTWARE_VERSIONS",
        "string_process": "\nprocess GET_SOFTWARE_VERSIONS {\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/python:3.8.3\"\n    } else {\n        container \"quay.io/biocontainers/python:3.8.3\"\n    }\n\n    cache false\n\n    input:\n    path versions\n\n    output:\n    path \"software_versions.tsv\"     , emit: tsv\n    path 'software_versions_mqc.yaml', emit: yaml\n\n    script:                                                                    \n    \"\"\"\n    echo $workflow.manifest.version > pipeline.version.txt\n    echo $workflow.nextflow.version > nextflow.version.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > pipeline.version.txt\n    echo $workflow.nextflow.version > nextflow.version.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "versions"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/python:3.8.3\" } else { container \"quay.io/biocontainers/python:3.8.3\" }",
            "cache false"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE": {
        "name_process": "MERGE",
        "string_process": "process MERGE {\n  tag \"${basename}\"\n  label 'process_low'\n\n  publishDir \"${params.outdir}/${subDir}\",\n    mode: 'copy'\n\n  input:\n  path chr_merge_list\n  val runName\n  val subDir\n  val removeHeader\n\n  output:\n  path \"*.txt\", emit: merged\n\n  script:\n  basename = chr_merge_list.baseName\n  outputFile = \"${runName}_${basename}.txt\"\n\n  if (removeHeader == true)\n    \"\"\"\n    rm -f ${outputFile}\n    cat ${chr_merge_list} |\n        while read f; do\n        tail -n +2 \\$f\n        done >> ${outputFile}\n    \"\"\"\n  else\n    \"\"\"\n    rm -f ${outputFile}\n    cat ${chr_merge_list} |\n        while read f; do\n        cat \\$f\n        done >> ${outputFile}\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "  basename = chr_merge_list.baseName\n  outputFile = \"${runName}_${basename}.txt\"\n\n  if (removeHeader == true)\n    \"\"\"\n    rm -f ${outputFile}\n    cat ${chr_merge_list} |\n        while read f; do\n        tail -n +2 \\$f\n        done >> ${outputFile}\n    \"\"\"\n  else\n    \"\"\"\n    rm -f ${outputFile}\n    cat ${chr_merge_list} |\n        while read f; do\n        cat \\$f\n        done >> ${outputFile}\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "chr_merge_list",
            "runName",
            "subDir",
            "removeHeader"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${basename}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/${subDir}\" , mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_ZSCORE": {
        "name_process": "CALC_ZSCORE",
        "string_process": "process CALC_ZSCORE {\n  tag \"${basename}\"\n  publishDir \"${params.outdir}/zscore\",\n    mode: 'copy'\n  label 'process_high'\n\n  input:\n  path count\n  val zscores_only\n  path metadata\n\n  output:\n  path \"*.zscore\", emit: zscore\n\n  script:\n  basename = count.baseName\n  outputFile = \"${basename}.zscore\"\n  \"\"\"\n  calc_zscore.R \\\\\n    ${count} \\\\\n    ${outputFile} \\\\\n    ${metadata} \\\\\n    ${zscores_only}\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "  basename = count.baseName\n  outputFile = \"${basename}.zscore\"\n  \"\"\"\n  calc_zscore.R \\\\\n    ${count} \\\\\n    ${outputFile} \\\\\n    ${metadata} \\\\\n    ${zscores_only}\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "count",
            "zscores_only",
            "metadata"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${basename}\"",
            "publishDir \"${params.outdir}/zscore\" , mode: 'copy'",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "SAMPLESHEET_CHECK": {
        "name_process": "SAMPLESHEET_CHECK",
        "string_process": "\nprocess SAMPLESHEET_CHECK {\n    tag \"$samplesheet\"\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/python:3.8.3\"\n    } else {\n        container \"quay.io/biocontainers/python:3.8.3\"\n    }\n\n    input:\n    path samplesheet\n\n    output:\n    path '*.csv'\n\n    script:                                                                    \n    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplesheet"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"$samplesheet\"",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/python:3.8.3\" } else { container \"quay.io/biocontainers/python:3.8.3\" }"
        ],
        "when": "",
        "stub": ""
    },
    "FILTER_BAM_SS2": {
        "name_process": "FILTER_BAM_SS2",
        "string_process": "process FILTER_BAM_SS2 {\n  tag \"${bamFileID}\"\n  label 'process_medium'\n\n  conda 'bioconda::pysam=0.17.0 conda-forge::python=3.9.5'\n\n  input:\n  tuple val(inputChannel), val(bamFileID), path(bam), path(bai)\n  val isSICILIAN\n  val isCellranger\n  val libType\n\n  output:\n  path \"*.filter\", emit: filter\n\n  script:\n  \"\"\"\n  filter.py \\\\\n    --input_bam ${bam} \\\\\n    --isSICILIAN ${isSICILIAN} \\\\\n    --isCellranger ${isCellranger} \\\\\n    --libType ${libType} \\\\\n    --bamName ${bamFileID} \\\\\n    --inputChannel ${inputChannel}\n  \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "  \"\"\"\n  filter.py \\\\\n    --input_bam ${bam} \\\\\n    --isSICILIAN ${isSICILIAN} \\\\\n    --isCellranger ${isCellranger} \\\\\n    --libType ${libType} \\\\\n    --bamName ${bamFileID} \\\\\n    --inputChannel ${inputChannel}\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputChannel",
            "bamFileID",
            "bam",
            "bai",
            "isSICILIAN",
            "isCellranger",
            "libType"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${bamFileID}\"",
            "label 'process_medium'",
            "conda 'bioconda::pysam=0.17.0 conda-forge::python=3.9.5'"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_MEDIAN": {
        "name_process": "CALC_MEDIAN",
        "string_process": "process CALC_MEDIAN {\n  tag \"${basename}\"\n\n  label 'process_medium'\n\n  publishDir \"${params.outdir}/medians\",\n    pattern: \"*medians*\",\n    mode: 'copy'\n  publishDir \"${params.outdir}/signif_medians\",\n    pattern: \"*signifPvalues*\",\n        mode: 'copy'\n\n  input:\n  path zscore\n  val ontologyCols\n  val minCellsPerWindowOnt\n  val minCtsPerCell\n  val nPermutations\n\n  output:\n  path \"${output_medians}\"  , emit: medians\n  path \"${output_pvals}\"    , emit: signif_medians\n\n  script:\n  basename = zscore.baseName\n  output_medians = \"${basename}_medians_${nPermutations}_permutations_min_${minCellsPerWindowOnt}_cellsPerGeneOnt_${minCtsPerCell}_ctsPerCell.txt\"\n  output_pvals = \"${basename}_signif_medians_${nPermutations}_permutations_min_${minCellsPerWindowOnt}_cellsPerGeneOnt_${minCtsPerCell}_ctsPerCell.txt\"\n  \"\"\"\n  calc_median.R \\\\\n    ${zscore} \\\\\n    ${ontologyCols} \\\\\n    ${minCellsPerWindowOnt} \\\\\n    ${minCtsPerCell} \\\\\n    ${nPermutations} \\\\\n    ${output_medians} \\\\\n    ${output_pvals}\n  \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "  basename = zscore.baseName\n  output_medians = \"${basename}_medians_${nPermutations}_permutations_min_${minCellsPerWindowOnt}_cellsPerGeneOnt_${minCtsPerCell}_ctsPerCell.txt\"\n  output_pvals = \"${basename}_signif_medians_${nPermutations}_permutations_min_${minCellsPerWindowOnt}_cellsPerGeneOnt_${minCtsPerCell}_ctsPerCell.txt\"\n  \"\"\"\n  calc_median.R \\\\\n    ${zscore} \\\\\n    ${ontologyCols} \\\\\n    ${minCellsPerWindowOnt} \\\\\n    ${minCtsPerCell} \\\\\n    ${nPermutations} \\\\\n    ${output_medians} \\\\\n    ${output_pvals}\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "zscore",
            "ontologyCols",
            "minCellsPerWindowOnt",
            "minCtsPerCell",
            "nPermutations"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${basename}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/medians\" , pattern: \"*medians*\" , mode: 'copy'",
            "publishDir \"${params.outdir}/signif_medians\" , pattern: \"*signifPvalues*\" , mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "CALL_PEAKS": {
        "name_process": "CALL_PEAKS",
        "string_process": "process CALL_PEAKS {\n  publishDir \"${params.outdir}/peaks\",\n    mode: 'copy'\n\n  label 'process_medium'\n  conda 'conda-forge::r-mclust=5.4.9'\n\n  input:\n  path all_counts\n  path ann_pvals\n  val peak_method\n  val runName\n\n  output:\n  path \"*.tsv\", optional: true, emit: peaks\n\n  script:\n  output = \"${runName}_peaks_${peak_method}.tsv\"\n  \"\"\"\n  GMM_based_peak_finder.R \\\\\n    ${all_counts} \\\\\n    ${ann_pvals} \\\\\n    ${peak_method} \\\\\n    ${output}\n  \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "  output = \"${runName}_peaks_${peak_method}.tsv\"\n  \"\"\"\n  GMM_based_peak_finder.R \\\\\n    ${all_counts} \\\\\n    ${ann_pvals} \\\\\n    ${peak_method} \\\\\n    ${output}\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "wossoutput"
        ],
        "tools_url": [
            "https://bio.tools/wossoutput"
        ],
        "tools_dico": [
            {
                "name": "wossoutput",
                "uri": "https://bio.tools/wossoutput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM output data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossoutput.html"
            }
        ],
        "inputs": [
            "all_counts",
            "ann_pvals",
            "peak_method",
            "runName"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "publishDir \"${params.outdir}/peaks\" , mode: 'copy'",
            "label 'process_medium'",
            "conda 'conda-forge::r-mclust=5.4.9'"
        ],
        "when": "",
        "stub": ""
    },
    "PLOTTERPNG": {
        "name_process": "PLOTTERPNG",
        "string_process": "process PLOTTERPNG {\n  publishDir \"${params.outdir}/plots\",\n    mode: 'copy'\n  label 'process_low'\n\n  input:\n  path plotterFile\n  val ontologyCols\n  path gff\n\n  output:\n  path \"*png\"\n\n  script:\n  \"\"\"\n  make_plot.R \\\\\n    ${plotterFile} \\\\\n    ${ontologyCols} \\\\\n    ${gff}\n  \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  make_plot.R \\\\\n    ${plotterFile} \\\\\n    ${ontologyCols} \\\\\n    ${gff}\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plotterFile",
            "ontologyCols",
            "gff"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "publishDir \"${params.outdir}/plots\" , mode: 'copy'",
            "label 'process_low'"
        ],
        "when": "",
        "stub": ""
    },
    "ANNOTATE_WINDOWS": {
        "name_process": "ANNOTATE_WINDOWS",
        "string_process": "process ANNOTATE_WINDOWS {\n  label 'process_medium'\n  publishDir \"${params.outdir}/annotated_files\",\n    mode: 'copy'\n\n  conda 'bioconda::bedtools=2.30.0'\n  input:\n  val libType\n  path chr_lengths\n  path annotation_bed\n  val binSize\n\n  output:\n  path \"annotated_windows.file\",   emit: annotated_windows\n\n  script:\n  if (params.libType == 'SS2')\n    \"\"\"\n    bedtools makewindows -g ${chr_lengths} -w ${binSize} -i srcwinnum |\n      awk -v OFS='\\t' '{print \\$0, \".\", \"+\"}' |\n      sort -k1,1 -k2,2n > windows.file\n    bedtools intersect -a windows.file -b ${annotation_bed} -loj -wa |\n      awk -v OFS='\\t' '{print \\$1,\\$2,\\$3,\\$4,\\$10}' |\n      bedtools groupby -g 1,2,3,4 -c 5 -o collapse |\n      sed '1i chr\\tstart\\tend\\twindow\\tgene' > annotated_windows.file\n    \"\"\"\n  else if (params.libType == '10X')\n    \"\"\"\n    bedtools makewindows -g ${chr_lengths} -w ${binSize} -i srcwinnum > unstranded_windows.file\n    cat unstranded_windows.file | awk -v OFS='\\t' '{print \\$0, \"plus\", \".\", \"+\"}' | \n      sed 's/\\t/_/4' > pos_windows.file\n    cat unstranded_windows.file | awk -v OFS='\\t' '{print \\$0, \"minus\", \".\", \"-\"}' | \n      sed 's/\\t/_/4' > minus_windows.file\n    cat pos_windows.file minus_windows.file | sort -k1,1 -k2,2n > windows.file\n    bedtools intersect -a windows.file -b ${annotation_bed} -loj -wa -s |\n      awk -v OFS='\\t' '{print \\$1,\\$2,\\$3,\\$4,\\$6,\\$10}' |\n      bedtools groupby -g 1,2,3,4,5 -c 6 -o collapse |\n      sed '1i chr\\tstart\\tend\\twindow\\tstrand\\tgene' > annotated_windows.file\n    \"\"\"\n  }",
        "nb_lignes_process": 38,
        "string_script": "  if (params.libType == 'SS2')\n    \"\"\"\n    bedtools makewindows -g ${chr_lengths} -w ${binSize} -i srcwinnum |\n      awk -v OFS='\\t' '{print \\$0, \".\", \"+\"}' |\n      sort -k1,1 -k2,2n > windows.file\n    bedtools intersect -a windows.file -b ${annotation_bed} -loj -wa |\n      awk -v OFS='\\t' '{print \\$1,\\$2,\\$3,\\$4,\\$10}' |\n      bedtools groupby -g 1,2,3,4 -c 5 -o collapse |\n      sed '1i chr\\tstart\\tend\\twindow\\tgene' > annotated_windows.file\n    \"\"\"\n  else if (params.libType == '10X')\n    \"\"\"\n    bedtools makewindows -g ${chr_lengths} -w ${binSize} -i srcwinnum > unstranded_windows.file\n    cat unstranded_windows.file | awk -v OFS='\\t' '{print \\$0, \"plus\", \".\", \"+\"}' | \n      sed 's/\\t/_/4' > pos_windows.file\n    cat unstranded_windows.file | awk -v OFS='\\t' '{print \\$0, \"minus\", \".\", \"-\"}' | \n      sed 's/\\t/_/4' > minus_windows.file\n    cat pos_windows.file minus_windows.file | sort -k1,1 -k2,2n > windows.file\n    bedtools intersect -a windows.file -b ${annotation_bed} -loj -wa -s |\n      awk -v OFS='\\t' '{print \\$1,\\$2,\\$3,\\$4,\\$6,\\$10}' |\n      bedtools groupby -g 1,2,3,4,5 -c 6 -o collapse |\n      sed '1i chr\\tstart\\tend\\twindow\\tstrand\\tgene' > annotated_windows.file\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "libType",
            "chr_lengths",
            "annotation_bed",
            "binSize"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/annotated_files\" , mode: 'copy'",
            "conda 'bioconda::bedtools=2.30.0'"
        ],
        "when": "",
        "stub": ""
    },
    "MULTIQC": {
        "name_process": "MULTIQC",
        "string_process": "\nprocess MULTIQC {\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"bioconda::multiqc=1.10.1\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/multiqc:1.10.1--py_0\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.10.1--py_0\"\n    }\n\n    input:\n    path multiqc_files\n\n    output:\n    path \"*multiqc_report.html\", emit: report\n    path \"*_data\"              , emit: data\n    path \"*_plots\"             , optional:true, emit: plots\n    path \"*.version.txt\"       , emit: version\n\n    script:\n    def software = getSoftwareName(task.process)\n    \"\"\"\n    multiqc -f $options.args .\n    multiqc --version | sed -e \"s/multiqc, version //g\" > ${software}.version.txt\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    def software = getSoftwareName(task.process)\n    \"\"\"\n    multiqc -f $options.args .\n    multiqc --version | sed -e \"s/multiqc, version //g\" > ${software}.version.txt\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "multiqc_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"bioconda::multiqc=1.10.1\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/multiqc:1.10.1--py_0\" } else { container \"quay.io/biocontainers/multiqc:1.10.1--py_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "COUNT": {
        "name_process": "COUNT",
        "string_process": "process COUNT {\n  tag \"${basename}\"\n  label 'process_medium'\n\n  input:\n  path filtered\n  val libType\n  val binSize\n\n  output:\n  path \"*.count\", optional: true, emit: count\n\n  script:\n  basename = filtered.baseName\n  \"\"\"\n  count.R \\\\\n    ${filtered} \\\\\n    ${basename} \\\\\n    ${libType} \\\\\n    ${binSize}\n  \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "  basename = filtered.baseName\n  \"\"\"\n  count.R \\\\\n    ${filtered} \\\\\n    ${basename} \\\\\n    ${libType} \\\\\n    ${binSize}\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filtered",
            "libType",
            "binSize"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${basename}\"",
            "label 'process_medium'"
        ],
        "when": "",
        "stub": ""
    },
    "PVAL_LIST": {
        "name_process": "PVAL_LIST",
        "string_process": "process PVAL_LIST {\n  publishDir \"${params.outdir}/annotated_files\",\n    mode: 'copy'\n  label 'process_low'\n\n  input:\n  path allPval_file\n  val runName\n  path annotated_windows\n\n  output:\n  path \"${runName}_all_pvals.txt\",   emit: all_pvals,   optional: true\n  path \"${runName}_ann_pvals.txt\",   emit: ann_pvals,   optional: true\n\n  script:\n  outfile_allPvals = \"${runName}_all_pvals.txt\"\n  outfile_annPvals = \"${runName}_ann_pvals.txt\"\n  \"\"\"\n  make_pval_list.R \\\\\n    ${allPval_file} \\\\\n    ${annotated_windows} \\\\\n    ${outfile_allPvals} \\\\\n    ${outfile_annPvals}\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "  outfile_allPvals = \"${runName}_all_pvals.txt\"\n  outfile_annPvals = \"${runName}_ann_pvals.txt\"\n  \"\"\"\n  make_pval_list.R \\\\\n    ${allPval_file} \\\\\n    ${annotated_windows} \\\\\n    ${outfile_allPvals} \\\\\n    ${outfile_annPvals}\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "allPval_file",
            "runName",
            "annotated_windows"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "publishDir \"${params.outdir}/annotated_files\" , mode: 'copy'",
            "label 'process_low'"
        ],
        "when": "",
        "stub": ""
    },
    "FASTQC": {
        "name_process": "FASTQC",
        "string_process": "\nprocess FASTQC {\n    tag \"$meta.id\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\"\n    } else {\n        container \"quay.io/biocontainers/fastqc:0.11.9--0\"\n    }\n\n    input:\n    tuple val(meta), path(reads)\n\n    output:\n    tuple val(meta), path(\"*.html\"), emit: html\n    tuple val(meta), path(\"*.zip\") , emit: zip\n    path  \"versions.yml\"           , emit: version\n\n    script:\n                                                                          \n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 47,
        "string_script": "    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    }",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\" } else { container \"quay.io/biocontainers/fastqc:0.11.9--0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMTOOLS_INDEX": {
        "name_process": "SAMTOOLS_INDEX",
        "string_process": "\nprocess SAMTOOLS_INDEX {\n    tag \"${bam}\"\n    label 'process_low'\n    publishDir \"${params.outdir}/bams\",\n        mode: params.publish_dir_mode\n\n    conda 'bioconda::samtools=1.13'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\"\n    }\n\n    input:\n    tuple val(inputChannel), val(bamFileID), path(bam)\n\n    output:\n    tuple val(inputChannel), val(bamFileID), path(bam), path(\"*bai\")     , emit: bam_tuple\n    path  \"versions.yml\"                                            , emit: version\n\n    script:\n    def software = getSoftwareName(task.process)\n    \"\"\"\n    samtools index $options.args $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    def software = getSoftwareName(task.process)\n    \"\"\"\n    samtools index $options.args $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "inputChannel",
            "bamFileID",
            "bam"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${bam}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/bams\" , mode: params.publish_dir_mode",
            "conda 'bioconda::samtools=1.13' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\" } else { container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "PLOTTERFILE": {
        "name_process": "PLOTTERFILE",
        "string_process": "\nprocess PLOTTERFILE {\n  publishDir \"${params.outdir}/plotter_files\",\n    mode: 'copy'\n  label 'process_high_memory'\n\n  input:\n  path all_pvals\n  val binSize\n  val ontologyCols\n  val numPlots\n  val runName\n  val outdir\n\n  output:\n  path \"*.plotterFile\"\n\n  script:\n  \"\"\"\n  make_plotter_files.R \\\\\n    ${all_pvals} \\\\\n    ${binSize} \\\\\n    ${ontologyCols} \\\\\n    ${numPlots} \\\\\n    ${outdir} \\\\\n    ${runName}\n  \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "  \"\"\"\n  make_plotter_files.R \\\\\n    ${all_pvals} \\\\\n    ${binSize} \\\\\n    ${ontologyCols} \\\\\n    ${numPlots} \\\\\n    ${outdir} \\\\\n    ${runName}\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_pvals",
            "binSize",
            "ontologyCols",
            "numPlots",
            "runName",
            "outdir"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "publishDir \"${params.outdir}/plotter_files\" , mode: 'copy'",
            "label 'process_high_memory'"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_SPLIT": {
        "name_process": "MERGE_SPLIT",
        "string_process": "process MERGE_SPLIT {\n  tag \"${basename}\"\n  label 'process_low'\n\n  publishDir \"${params.outdir}/${subDir}\",\n    mode: 'copy'\n\n  input:\n  path chr_merge_list\n  val runName\n  val subDir\n  val removeHeader\n\n  output:\n  path \"*.txt\", emit: merged\n\n  script:\n  basename = chr_merge_list.baseName\n  outputFile = \"${runName}_${basename}.txt\"\n  \"\"\"\n  rm -f ${outputFile}\n  cat ${chr_merge_list} |\n      while read f; do\n      awk -v var=${runName} '{if(\\$2 ~ /chr/) print >> var\"_\"\\$2\".txt\"}' \\$f\n      done\n  \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "  basename = chr_merge_list.baseName\n  outputFile = \"${runName}_${basename}.txt\"\n  \"\"\"\n  rm -f ${outputFile}\n  cat ${chr_merge_list} |\n      while read f; do\n      awk -v var=${runName} '{if(\\$2 ~ /chr/) print >> var\"_\"\\$2\".txt\"}' \\$f\n      done\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "chr_merge_list",
            "runName",
            "subDir",
            "removeHeader"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${basename}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/${subDir}\" , mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD_MARKDUPLICATES": {
        "name_process": "PICARD_MARKDUPLICATES",
        "string_process": "\nprocess PICARD_MARKDUPLICATES {\n    tag \"${bamFileID}\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode\n\n\n    input:\n    tuple val(inputChannel), val(bamFileID), path(bam)\n    path picard\n\n    output:\n    tuple val(inputChannel), val(bamFileID), path(\"dedup*bam\")          , emit: bam_tuple\n    path \"*.metrics.txt\"                                                , emit: metrics\n    path  \"*.version.txt\"                                               , emit: version\n    \n    script:\n    def software  = getSoftwareName(task.process)\n    def prefix    = \"dedup.${bamFileID}\"\n    \"\"\"\n    java -jar ${picard} MarkDuplicates -I ${bam} -O ${prefix}.bam -M ${bamFileID}.metrics.txt --QUIET true \n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    def software  = getSoftwareName(task.process)\n    def prefix    = \"dedup.${bamFileID}\"\n    \"\"\"\n    java -jar ${picard} MarkDuplicates -I ${bam} -O ${prefix}.bam -M ${bamFileID}.metrics.txt --QUIET true \n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputChannel",
            "bamFileID",
            "bam",
            "picard"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${bamFileID}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD": {
        "name_process": "PICARD",
        "string_process": "process PICARD {\n    tag \"${bamName}\"\n    label 'process_medium'\n\n    conda 'bioconda::picard=2.26.2'\n\n    input:\n    tuple val(inputChannel), val(bamFileID), path(bam)\n\n    output:\n    tuple val(inputChannel), val(bamFileID), path(\"*dedup*\"), emit: bam_tuple\n\n    script:\n    outputFile = \"${bamFileID}.dedup\"\n    metrics = \"${bamFileID}.metrics\"\n    \"\"\"\n    picard MarkDuplicates -I ${bam} -O ${outputFile} -M ${metrics} --QUIET true\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    outputFile = \"${bamFileID}.dedup\"\n    metrics = \"${bamFileID}.metrics\"\n    \"\"\"\n    picard MarkDuplicates -I ${bam} -O ${outputFile} -M ${metrics} --QUIET true\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "GRmetrics",
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/grmetrics",
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "GRmetrics",
                "uri": "https://bio.tools/grmetrics",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3336",
                            "term": "Drug discovery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3438",
                                    "term": "Calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Functions for calculating and visualizing growth-rate inhibition (GR) metrics.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/GRmetrics.html"
            },
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "inputChannel",
            "bamFileID",
            "bam"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${bamName}\"",
            "label 'process_medium'",
            "conda 'bioconda::picard=2.26.2'"
        ],
        "when": "",
        "stub": ""
    },
    "FILTER_BAM_10X": {
        "name_process": "FILTER_BAM_10X",
        "string_process": "process FILTER_BAM_10X {\n  tag \"${chr}, ${bamFileID}\"\n  label 'process_medium'\n\n  conda 'bioconda::pysam=0.17.0 conda-forge::python=3.9.5'\n\n  input:\n  tuple val(inputChannel), val(bamFileID), path(bam), path(bai)\n  val isSICILIAN\n  val isCellranger\n  val libType\n  each chr\n\n  output:\n  path \"*.filter\", emit: filter\n\n  script:\n  \"\"\"\n  filter.py \\\\\n    --input_bam <(samtools view -b ${bam} ${chr} ) \\\\\n    --isSICILIAN ${isSICILIAN} \\\\\n    --isCellranger ${isCellranger} \\\\\n    --libType ${libType} \\\\\n    --bamName ${bamFileID} \\\\\n    --inputChannel ${inputChannel} \\\\\n    --chr ${chr}\n  \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "  \"\"\"\n  filter.py \\\\\n    --input_bam <(samtools view -b ${bam} ${chr} ) \\\\\n    --isSICILIAN ${isSICILIAN} \\\\\n    --isCellranger ${isCellranger} \\\\\n    --libType ${libType} \\\\\n    --bamName ${bamFileID} \\\\\n    --inputChannel ${inputChannel} \\\\\n    --chr ${chr}\n  \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputChannel",
            "bamFileID",
            "bam",
            "bai",
            "isSICILIAN",
            "isCellranger",
            "libType",
            "chr"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${chr}, ${bamFileID}\"",
            "label 'process_medium'",
            "conda 'bioconda::pysam=0.17.0 conda-forge::python=3.9.5'"
        ],
        "when": "",
        "stub": ""
    },
    "SAMTOOLS_SORT": {
        "name_process": "SAMTOOLS_SORT",
        "string_process": "\nprocess SAMTOOLS_SORT {\n    tag \"${bamFileID}\"\n    label 'process_medium'\n\n    conda 'bioconda::samtools=1.13'\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\"\n    }\n\n    input:\n    tuple val(inputChannel), val(bamFileID), path(bam)\n\n    output:\n    tuple val(inputChannel), val(bamFileID), path(\"sorted*.bam\")   , emit: bam\n    path  \"versions.yml\"                                , emit: version\n\n    script:\n    def software = getSoftwareName(task.process)\n    def prefix   = \"sorted.${bamFileID}\"\n    \"\"\"\n    samtools sort $options.args -@ $task.cpus -o ${prefix}.bam -T $prefix $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    def software = getSoftwareName(task.process)\n    def prefix   = \"sorted.${bamFileID}\"\n    \"\"\"\n    samtools sort $options.args -@ $task.cpus -o ${prefix}.bam -T $prefix $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "inputChannel",
            "bamFileID",
            "bam"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${bamFileID}\"",
            "label 'process_medium'",
            "conda 'bioconda::samtools=1.13' if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\" } else { container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_FILTERED": {
        "name_process": "MERGE_FILTERED",
        "string_process": "process MERGE_FILTERED {\n  tag \"${basename}\"\n  label 'process_low'\n  input:\n  path channel_merge_list\n\n  output:\n  path \"*.mergeFilter\", emit: filter\n\n  script:\n  basename = channel_merge_list.baseName\n  outputFile = \"${basename}.mergeFilter\"\n  \"\"\"\n  rm -f ${outputFile}\n  cat ${channel_merge_list} |\n    while read f; do\n      cat \\$f\n    done >> ${outputFile}\n  \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "  basename = channel_merge_list.baseName\n  outputFile = \"${basename}.mergeFilter\"\n  \"\"\"\n  rm -f ${outputFile}\n  cat ${channel_merge_list} |\n    while read f; do\n      cat \\$f\n    done >> ${outputFile}\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "channel_merge_list"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "salzmanlab__ReadZS",
        "directive": [
            "tag \"${basename}\"",
            "label 'process_low'"
        ],
        "when": "",
        "stub": ""
    }
}