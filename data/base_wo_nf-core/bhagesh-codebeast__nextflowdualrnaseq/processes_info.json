{
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n    publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.indexOf(\".csv\") > 0) filename\n                      else null\n                }\n\n    output:\n    file 'software_versions_mqc.yaml' into ch_software_versions_yaml\n    file \"software_versions.csv\"\n\n    script:\n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    python --version > v_python.txt\n    R --version > v_r.txt\n    cutadapt --version > v_cutadapt.txt\n    fastqc --version > v_fastqc.txt\n    multiqc --version > v_multiqc.txt\n    STAR --version > v_star.txt\n    htseq-count . . --version > v_htseq.txt\n    samtools --version > v_samtools.txt\n    gffread --version > v_gffread.txt\n    salmon --version > v_salmon.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    python --version > v_python.txt\n    R --version > v_r.txt\n    cutadapt --version > v_cutadapt.txt\n    fastqc --version > v_fastqc.txt\n    multiqc --version > v_multiqc.txt\n    STAR --version > v_star.txt\n    htseq-count . . --version > v_htseq.txt\n    samtools --version > v_samtools.txt\n    gffread --version > v_gffread.txt\n    salmon --version > v_salmon.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "Cutadapt",
            "FastQC",
            "MultiQC",
            "STAR",
            "htseqcount",
            "SAMtools",
            "gffread",
            "Salmon"
        ],
        "tools_url": [
            "https://bio.tools/cutadapt",
            "https://bio.tools/fastqc",
            "https://bio.tools/multiqc",
            "https://bio.tools/star",
            "https://bio.tools/htseqcount",
            "https://bio.tools/samtools",
            "https://bio.tools/gffread",
            "https://bio.tools/salmon"
        ],
        "tools_dico": [
            {
                "name": "Cutadapt",
                "uri": "https://bio.tools/cutadapt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ]
                    }
                ],
                "description": "Find and remove adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads.",
                "homepage": "https://pypi.python.org/pypi/cutadapt"
            },
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            },
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            },
            {
                "name": "htseqcount",
                "uri": "https://bio.tools/htseqcount",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "This script takes an alignment file in SAM format and a feature file in GFF format and calculates for each feature the number of reads mapping to it.",
                "homepage": "https://htseq.readthedocs.io/en/release_0.9.1/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "gffread",
                "uri": "https://bio.tools/gffread",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0361",
                                    "term": "Sequence annotation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "program for filtering, converting and manipulating GFF files",
                "homepage": "https://ccb.jhu.edu/software/stringtie/gff.shtml"
            },
            {
                "name": "Salmon",
                "uri": "https://bio.tools/salmon",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3496",
                                "term": "RNA sequence (raw)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2093",
                                "term": "Data reference"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "A tool for transcript expression quantification from RNA-seq data",
                "homepage": "https://github.com/COMBINE-lab/salmon"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "ch_software_versions_yaml"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.indexOf(\".csv\") > 0) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "check_replicates": {
        "name_process": "check_replicates",
        "string_process": "\tprocess check_replicates {\n\t    tag \"check_replicates\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    val(sample_name) from scatter_plots.collect()\n\t    \n\t    output:\n\t    stdout repl_scatter_plots_salmon_pathogen\n\t    stdout repl_scatter_plots_salmon_host\n\t    stdout repl_scatter_plots_salmon_alignment_host\n\t    stdout repl_scatter_plots_salmon_alignment_pathogen\n\t    stdout repl_scatter_plots_htseq_pathogen\n\t    stdout repl_scatter_plots_htseq_host\n\n\t    shell:\n\t    '''\n\t    python !{workflow.projectDir}/bin/check_replicates.py -s !{sample_name} 2>&1\n\t    '''\n\t}",
        "nb_lignes_process": 19,
        "string_script": "\t    '''\n\t    python !{workflow.projectDir}/bin/check_replicates.py -s !{sample_name} 2>&1\n\t    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scatter_plots"
        ],
        "nb_inputs": 1,
        "outputs": [
            "repl_scatter_plots_salmon_pathogen",
            "repl_scatter_plots_salmon_host",
            "repl_scatter_plots_salmon_alignment_host",
            "repl_scatter_plots_salmon_alignment_pathogen",
            "repl_scatter_plots_htseq_pathogen",
            "repl_scatter_plots_htseq_host"
        ],
        "nb_outputs": 6,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"check_replicates\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "uncompress_pathogen_fasta_genome": {
        "name_process": "uncompress_pathogen_fasta_genome",
        "string_process": "\nprocess uncompress_pathogen_fasta_genome {\n    tag \"uncompress_pathogen_genome\"\n    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\n    label 'process_high'\n\n    input:\n    each file(f_ext) from genome_fasta_pathogen_to_unzip.collect()\n\n    output:\n    file \"${base_name_file}.fasta\" into genome_fasta_pathogen_to_combine\n    file \"${base_name_file}.fasta\" into genome_fasta_pathogen_ref_names\n    file \"${base_name_file}.fasta\" into genome_fasta_pathogen_to_transcriptome\n\n    shell:\n    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n    if (ext_file == \"fasta\" | ext_file == \"fa\"){\n\t    '''\n\t    cp -n !{f_ext} !{base_name_file}.fasta\n\t    '''\n    }else if(ext_file == \"zip\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n\t    '''\n      gunzip -f -S .zip !{f_ext}\n\t    cp -n !{old_base_name_file} !{base_name_file}.fasta\n\t    '''\n    }else if(ext_file == \"gz\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n\t    '''\n\t    gunzip -f !{f_ext}\n\t    cp -n !{old_base_name_file} !{base_name_file}.fasta\n\t    '''\n    }else {\n      '''\n      echo \"Your pathogen genome files appear to have the wrong extension. \\n Currently, the pipeline only supports .fasta or .fa, or compressed files with .zip or .gz extensions.\"\n      '''\n    }\n}",
        "nb_lignes_process": 40,
        "string_script": "    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n    if (ext_file == \"fasta\" | ext_file == \"fa\"){\n\t    '''\n\t    cp -n !{f_ext} !{base_name_file}.fasta\n\t    '''\n    }else if(ext_file == \"zip\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n\t    '''\n      gunzip -f -S .zip !{f_ext}\n\t    cp -n !{old_base_name_file} !{base_name_file}.fasta\n\t    '''\n    }else if(ext_file == \"gz\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n\t    '''\n\t    gunzip -f !{f_ext}\n\t    cp -n !{old_base_name_file} !{base_name_file}.fasta\n\t    '''\n    }else {\n      '''\n      echo \"Your pathogen genome files appear to have the wrong extension. \\n Currently, the pipeline only supports .fasta or .fa, or compressed files with .zip or .gz extensions.\"\n      '''\n    }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_fasta_pathogen_to_unzip"
        ],
        "nb_inputs": 1,
        "outputs": [
            "genome_fasta_pathogen_to_combine",
            "genome_fasta_pathogen_ref_names",
            "genome_fasta_pathogen_to_transcriptome"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"uncompress_pathogen_genome\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "uncompress_host_fasta_genome": {
        "name_process": "uncompress_host_fasta_genome",
        "string_process": "\nprocess uncompress_host_fasta_genome {\n    tag \"uncompress_host_genome\"\n    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\n    label 'process_high'\n\n    input:\n    file(f_ext) from genome_fasta_host_to_unzip\n\n    output:\n    file \"${base_name_file}.fasta\" into genome_fasta_host_to_combine\n    file \"${base_name_file}.fasta\" into genome_fasta_host_to_decoys\n    file \"${base_name_file}.fasta\" into genome_fasta_host_ref_names\n    file \"${base_name_file}.fasta\" into genome_fasta_host_to_transcriptome\n    file \"${base_name_file}.fasta\" into genome_fasta_host_to_transcriptome_tRNA\n\n    shell:\n                                                      \n                                                                                  \n    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n    if (ext_file == \"fasta\" | ext_file == \"fa\"){\n    \t'''\n    \tcp -n !{f_ext} !{base_name_file}.fasta\n    \t'''\n    }else if(ext_file == \"zip\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n  \t  '''\n  \t  gunzip -f -S .zip !{f_ext}\n  \t  cp -n !{old_base_name_file} !{base_name_file}.fasta\n  \t  '''\n    }else if(ext_file == \"gz\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n\t    '''\n\t    gunzip -f !{f_ext}\n\t    cp -n !{old_base_name_file} !{base_name_file}.fasta\n\t    '''\n    }else {\n      '''\n      echo \"Your host genome files appear to have the wrong extension. \\n Currently, the pipeline only supports .fasta or .fa, or compressed files with .zip or .gz extensions.\"\n      '''\n    }\n}",
        "nb_lignes_process": 44,
        "string_script": "    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n    if (ext_file == \"fasta\" | ext_file == \"fa\"){\n    \t'''\n    \tcp -n !{f_ext} !{base_name_file}.fasta\n    \t'''\n    }else if(ext_file == \"zip\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n  \t  '''\n  \t  gunzip -f -S .zip !{f_ext}\n  \t  cp -n !{old_base_name_file} !{base_name_file}.fasta\n  \t  '''\n    }else if(ext_file == \"gz\"){\n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.fasta|.fa/,\"\")\n\t    '''\n\t    gunzip -f !{f_ext}\n\t    cp -n !{old_base_name_file} !{base_name_file}.fasta\n\t    '''\n    }else {\n      '''\n      echo \"Your host genome files appear to have the wrong extension. \\n Currently, the pipeline only supports .fasta or .fa, or compressed files with .zip or .gz extensions.\"\n      '''\n    }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_fasta_host_to_unzip"
        ],
        "nb_inputs": 1,
        "outputs": [
            "genome_fasta_host_to_combine",
            "genome_fasta_host_to_decoys",
            "genome_fasta_host_ref_names",
            "genome_fasta_host_to_transcriptome",
            "genome_fasta_host_to_transcriptome_tRNA"
        ],
        "nb_outputs": 5,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"uncompress_host_genome\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "uncompress_pathogen_gff": {
        "name_process": "uncompress_pathogen_gff",
        "string_process": "\nprocess uncompress_pathogen_gff {\n    tag \"uncompress_pathogen_GFF\"\n    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\n    label 'process_high'\n\n    input:\n    file(f_ext) from pathogen_gff_to_unzip\n\n    output:\n    file \"${base_name_file}.gff3\" into gff_feature_quant_pathogen_salmon_alignment\n    file \"${base_name_file}.gff3\" into gff_pathogen_create_transcriptome\n    file \"${base_name_file}.gff3\" into gff_feature_quant_pathogen_htseq\n    file \"${base_name_file}.gff3\" into extract_annotations_pathogen_gff_htseq\n\n    shell:\n                                                      \n                                                                                \n    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n\n    if (ext_file == \"gff\" | ext_file == \"gff3\"){\n      '''\n      cp -n !{f_ext} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"zip\"){\n      '''\n      gunzip -f -S .zip !{f_ext}\n      cp -n !{base_name_file} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"gz\"){\n                                             \n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n      '''\n      gunzip -f !{f_ext}\n      cp -n !{old_base_name_file} !{base_name_file}.gff3\n      '''\n    }else {\n      '''\n      echo \"Your pathogen GFF file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n      '''\n    }\n}",
        "nb_lignes_process": 43,
        "string_script": "    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n\n    if (ext_file == \"gff\" | ext_file == \"gff3\"){\n      '''\n      cp -n !{f_ext} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"zip\"){\n      '''\n      gunzip -f -S .zip !{f_ext}\n      cp -n !{base_name_file} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"gz\"){\n                                             \n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n      '''\n      gunzip -f !{f_ext}\n      cp -n !{old_base_name_file} !{base_name_file}.gff3\n      '''\n    }else {\n      '''\n      echo \"Your pathogen GFF file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n      '''\n    }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pathogen_gff_to_unzip"
        ],
        "nb_inputs": 1,
        "outputs": [
            "gff_feature_quant_pathogen_salmon_alignment",
            "gff_pathogen_create_transcriptome",
            "gff_feature_quant_pathogen_htseq",
            "extract_annotations_pathogen_gff_htseq"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"uncompress_pathogen_GFF\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "uncompress_host_gff": {
        "name_process": "uncompress_host_gff",
        "string_process": "\nprocess uncompress_host_gff {\n    tag \"uncompress_host_GFF\"\n    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\n    label 'process_high'\n\n    input:\n    file(f_ext) from host_gff_to_unzip\n\n    output:\n    file \"${base_name_file}.gff3\" into gff_host_genome_star_salmon_change_atr\n    file \"${base_name_file}.gff3\" into gff_host_create_transcriptome\n    file \"${base_name_file}.gff3\" into gff_host_genome_htseq\n    file \"${base_name_file}.gff3\" into extract_annotations_host_gff_htseq\n    file \"${base_name_file}.gff3\" into gff_host_star_alignment_gff\n    file \"${base_name_file}.gff3\" into gff_host_star_htseq_alignment_gff\n    file \"${base_name_file}.gff3\" into genome_gff_star_index\n\n    shell:\n                                                      \n                                                                                \n    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n\n    if (ext_file == \"gff\" | ext_file == \"gff3\"){\n      '''\n      cp -n !{f_ext} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"zip\"){\n      '''\n      gunzip -f -S .zip !{f_ext}\n      cp -n !{base_name_file} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"gz\"){\n                                             \n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n      '''\n      gunzip -f !{f_ext}\n      cp -n !{old_base_name_file} !{base_name_file}.gff3\n      '''\n    }else {\n      '''\n      echo \"Your host GFF file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n      '''\n    }\n}",
        "nb_lignes_process": 46,
        "string_script": "    ext_file = f_ext.getExtension()\n    base_name_file = f_ext.getBaseName()\n\n    if (ext_file == \"gff\" | ext_file == \"gff3\"){\n      '''\n      cp -n !{f_ext} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"zip\"){\n      '''\n      gunzip -f -S .zip !{f_ext}\n      cp -n !{base_name_file} !{base_name_file}.gff3\n      '''\n    }else if(ext_file == \"gz\"){\n                                             \n      old_base_name_file = base_name_file\n      base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n      '''\n      gunzip -f !{f_ext}\n      cp -n !{old_base_name_file} !{base_name_file}.gff3\n      '''\n    }else {\n      '''\n      echo \"Your host GFF file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n      '''\n    }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_gff_to_unzip"
        ],
        "nb_inputs": 1,
        "outputs": [
            "gff_host_genome_star_salmon_change_atr",
            "gff_host_create_transcriptome",
            "gff_host_genome_htseq",
            "extract_annotations_host_gff_htseq",
            "gff_host_star_alignment_gff",
            "gff_host_star_htseq_alignment_gff",
            "genome_gff_star_index"
        ],
        "nb_outputs": 7,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"uncompress_host_GFF\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "uncompress_host_gff_trna": {
        "name_process": "uncompress_host_gff_trna",
        "string_process": " process uncompress_host_gff_trna {\n      tag \"uncompress_host_GFF_trna\"\n      publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\n      label 'process_high'\n\n      input:\n      file(f_ext) from host_gff_trna_to_unzip\n\n      output:\n      file \"${base_name_file}.gff3\" into gff_host_genome_star_salmon_change_atr\n      file \"${base_name_file}.gff3\" into gff_host_create_transcriptome\n      file \"${base_name_file}.gff3\" into combine_gff_host_genome_htseq\n      file \"${base_name_file}.gff3\" into gff_host_star_alignment_gff\n      file \"${base_name_file}.gff3\" into gff_host_star_htseq_alignment_gff\n      file \"${base_name_file}.gff3\" into genome_gff_star_index\n\n      shell:\n                                                        \n                                                                                  \n      ext_file = f_ext.getExtension()\n      base_name_file = f_ext.getBaseName()\n\n      if (ext_file == \"gff\" | ext_file == \"gff3\"){\n        '''\n        cp -n !{f_ext} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"zip\"){\n        '''\n        gunzip -f -S .zip !{f_ext}\n        cp -n !{base_name_file} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"gz\"){\n                                               \n        old_base_name_file = base_name_file\n        base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n        '''\n        gunzip -f !{f_ext}\n        cp -n !{old_base_name_file} !{base_name_file}.gff3\n        '''\n      }else {\n        '''\n        echo \"Your host GFF file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n        '''\n      }\n  }",
        "nb_lignes_process": 44,
        "string_script": "      ext_file = f_ext.getExtension()\n      base_name_file = f_ext.getBaseName()\n\n      if (ext_file == \"gff\" | ext_file == \"gff3\"){\n        '''\n        cp -n !{f_ext} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"zip\"){\n        '''\n        gunzip -f -S .zip !{f_ext}\n        cp -n !{base_name_file} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"gz\"){\n                                               \n        old_base_name_file = base_name_file\n        base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n        '''\n        gunzip -f !{f_ext}\n        cp -n !{old_base_name_file} !{base_name_file}.gff3\n        '''\n      }else {\n        '''\n        echo \"Your host GFF file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n        '''\n      }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_gff_trna_to_unzip"
        ],
        "nb_inputs": 1,
        "outputs": [
            "gff_host_genome_star_salmon_change_atr",
            "gff_host_create_transcriptome",
            "combine_gff_host_genome_htseq",
            "gff_host_star_alignment_gff",
            "gff_host_star_htseq_alignment_gff",
            "genome_gff_star_index"
        ],
        "nb_outputs": 6,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"uncompress_host_GFF_trna\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "uncompress_host_gff_trna_file": {
        "name_process": "uncompress_host_gff_trna_file",
        "string_process": " process uncompress_host_gff_trna_file {\n      tag \"uncompress_host_GFF_trna_file\"\n      publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\n      label 'process_high'\n\n      input:\n      file(f_ext) from host_gff_trna_file_to_unzip\n\n      output:\n      file \"${base_name_file}.gff3\" into change_attrubute_gff_host_tRNA_salmon_alignment\n      file \"${base_name_file}.gff3\" into gff_host_create_transcriptome_tRNA\n      file \"${base_name_file}.gff3\" into combine_gff_host_tRNA_htseq\n\n      shell:\n                                                        \n                                                                                  \n      ext_file = f_ext.getExtension()\n      base_name_file = f_ext.getBaseName()\n\n      if (ext_file == \"gff\" | ext_file == \"gff3\"){\n        '''\n        cp -n !{f_ext} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"zip\"){\n        '''\n        gunzip -f -S .zip !{f_ext}\n        cp -n !{base_name_file} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"gz\"){\n                                               \n        old_base_name_file = base_name_file\n        base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n        '''\n        gunzip -f !{f_ext}\n        cp -n !{old_base_name_file} !{base_name_file}.gff3\n        '''\n      }else {\n        '''\n        echo \"Your host GFF tRNA file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n        '''\n      }\n  }",
        "nb_lignes_process": 41,
        "string_script": "      ext_file = f_ext.getExtension()\n      base_name_file = f_ext.getBaseName()\n\n      if (ext_file == \"gff\" | ext_file == \"gff3\"){\n        '''\n        cp -n !{f_ext} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"zip\"){\n        '''\n        gunzip -f -S .zip !{f_ext}\n        cp -n !{base_name_file} !{base_name_file}.gff3\n        '''\n      }else if(ext_file == \"gz\"){\n                                               \n        old_base_name_file = base_name_file\n        base_name_file = old_base_name_file.replaceAll(/.gff|.gff3/,\"\")\n        '''\n        gunzip -f !{f_ext}\n        cp -n !{old_base_name_file} !{base_name_file}.gff3\n        '''\n      }else {\n        '''\n        echo \"Your host GFF tRNA file appears to be in the wrong format or has the wrong extension. \\n Currently, the pipeline only supports .gff or .gff3, or compressed files with .zip or .gz extensions.\"\n        '''\n      }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_gff_trna_file_to_unzip"
        ],
        "nb_inputs": 1,
        "outputs": [
            "change_attrubute_gff_host_tRNA_salmon_alignment",
            "gff_host_create_transcriptome_tRNA",
            "combine_gff_host_tRNA_htseq"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"uncompress_host_GFF_trna_file\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_pathogen_host_fasta_genome": {
        "name_process": "combine_pathogen_host_fasta_genome",
        "string_process": "\nprocess combine_pathogen_host_fasta_genome {\n    tag \"combine_genome_fa_files\"\n    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n    storeDir \"${params.outdir}/references\"\n\n    label 'process_high'\n\n    input:\n    file(host_fa) from genome_fasta_host_to_combine\n    file(pathogen_fa) from genome_fasta_pathogen_to_combine.collect()\n\n    output:\n    file \"host_pathogen.fasta\" into host_pathogen_fasta_index\n    file \"host_pathogen.fasta\" into host_pathogen_fasta_star_index\n    file \"host_pathogen.fasta\" into genome_fasta_file_host_pathogen_to_decoy_transcriptome\n\n    script:\n    \"\"\"\n    cat $pathogen_fa $host_fa > host_pathogen.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    cat $pathogen_fa $host_fa > host_pathogen.fasta\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_fasta_host_to_combine",
            "genome_fasta_pathogen_to_combine"
        ],
        "nb_inputs": 2,
        "outputs": [
            "host_pathogen_fasta_index",
            "host_pathogen_fasta_star_index",
            "genome_fasta_file_host_pathogen_to_decoy_transcriptome"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"combine_genome_fa_files\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_host_genome_tRNA_gff_files_htseq": {
        "name_process": "combine_host_genome_tRNA_gff_files_htseq",
        "string_process": "\tprocess combine_host_genome_tRNA_gff_files_htseq {\n\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/references\"\n\t\t    tag \"comb_host_genome_tRNA_gff\"\n\t\t    \n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(host_gff_genome) from combine_gff_host_genome_htseq\n\t\t    file(host_gff_tRNA) from combine_gff_host_tRNA_htseq\n\n\t\t    output:\n\t\t    file \"${outfile_name}\" into gff_host_genome_htseq\n\t\t    file \"${outfile_name}\" into extract_annotations_host_gff_htseq\n\n\t\t    script:\n\t\t    outfile_name = host_gff_genome[0].toString().replaceAll(/.gff3|.gff/,\"_with_tRNA.gff3\")\n\t\t    \"\"\"\n\t\t    cat $host_gff_genome $host_gff_tRNA > ${outfile_name}\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 19,
        "string_script": "\t\t    outfile_name = host_gff_genome[0].toString().replaceAll(/.gff3|.gff/,\"_with_tRNA.gff3\")\n\t\t    \"\"\"\n\t\t    cat $host_gff_genome $host_gff_tRNA > ${outfile_name}\n\t\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "combine_gff_host_genome_htseq",
            "combine_gff_host_tRNA_htseq"
        ],
        "nb_inputs": 2,
        "outputs": [
            "gff_host_genome_htseq",
            "extract_annotations_host_gff_htseq"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"comb_host_genome_tRNA_gff\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_gene_feature_gff_host_htseq": {
        "name_process": "replace_gene_feature_gff_host_htseq",
        "string_process": "\tprocess replace_gene_feature_gff_host_htseq {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"repl_gene_feature_gff_host\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(gff) from gff_host_genome_htseq\n\t    val(features) from gene_feature_to_quantify_host\n\n\t    output:\n\t    file \"${outfile_name}\" into combine_gff_host \n\t    file \"${outfile_name}\" into gff_host_to_TPM \n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 19,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_host_genome_htseq",
            "gene_feature_to_quantify_host"
        ],
        "nb_inputs": 2,
        "outputs": [
            "combine_gff_host",
            "gff_host_to_TPM"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"repl_gene_feature_gff_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_gene_feature_gff_pathogen_htseq": {
        "name_process": "replace_gene_feature_gff_pathogen_htseq",
        "string_process": "\tprocess replace_gene_feature_gff_pathogen_htseq {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"repl_gene_feature_gff_pathogen\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(gff) from gff_feature_quant_pathogen_htseq\n\t    val(features) from gene_feature_to_quantify_pathogen\n\n\t    output:\n\t    file \"${outfile_name}\" into to_replace_gff_attribute\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_feature_quant_pathogen_htseq",
            "gene_feature_to_quantify_pathogen"
        ],
        "nb_inputs": 2,
        "outputs": [
            "to_replace_gff_attribute"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"repl_gene_feature_gff_pathogen\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_attribute_pathogen_gff_htseq": {
        "name_process": "replace_attribute_pathogen_gff_htseq",
        "string_process": "\tprocess replace_attribute_pathogen_gff_htseq {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"repl_attribute_pathogen_gff\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(gff) from to_replace_gff_attribute\n\t    val(host_attribute) from host_gff_attribute_to_pathogen\n\t    val(pathogen_attribute) from pathogen_gff_attribute\n\n\t    output:\n\t    file \"${outfile_name}\" into combine_gff_pathogen\n\t    file \"${outfile_name}\" into gff_pathogen_to_TPM\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_new_attribute.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} $host_attribute $pathogen_attribute\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 20,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_new_attribute.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} $host_attribute $pathogen_attribute\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "to_replace_gff_attribute",
            "host_gff_attribute_to_pathogen",
            "pathogen_gff_attribute"
        ],
        "nb_inputs": 3,
        "outputs": [
            "combine_gff_pathogen",
            "gff_pathogen_to_TPM"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"repl_attribute_pathogen_gff\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_pathogen_host_gff_files_htseq": {
        "name_process": "combine_pathogen_host_gff_files_htseq",
        "string_process": "\tprocess combine_pathogen_host_gff_files_htseq {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode \n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"comb_pathogen_host_gff_files\"\n\n\t    label 'process_high'\n\t \n\t    input:\n\t    file(host_gff) from combine_gff_host\n\t    file(pathogen_gff_genome) from combine_gff_pathogen\n\n\t    output:\n\t    file \"host_pathogen_htseq.gff\" into quantification_gff_u_m\n\n\t    script:\n\t    \"\"\"\n\t    cat $pathogen_gff_genome $host_gff > host_pathogen_htseq.gff\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    cat $pathogen_gff_genome $host_gff > host_pathogen_htseq.gff\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "combine_gff_host",
            "combine_gff_pathogen"
        ],
        "nb_inputs": 2,
        "outputs": [
            "quantification_gff_u_m"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"comb_pathogen_host_gff_files\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_annotations_pathogen_htseq": {
        "name_process": "extract_annotations_pathogen_htseq",
        "string_process": "\tprocess extract_annotations_pathogen_htseq {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"extract_annotations_pathogen\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file gff from extract_annotations_pathogen_gff_htseq\n\t    val(features) from gene_feature_to_extract_annotations_pathongen_htseq\n\t    val(pathogen_attribute) from pathogen_gff_attribute_to_extract_annotations_htseq\n\n\t    output:\n\t    file \"${outfile_name}*_htseq.tsv\" into pathogen_annotations_RNA_class_stats_htseq\n\t    file \"${outfile_name}*_htseq.tsv\" into annotation_pathogen_combine_quant_htseq_u_m\n\t    file \"${outfile_name}*_htseq.tsv\" into annotation_pathogen_split_quant_htseq\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"\")\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f $features -a $pathogen_attribute -org pathogen -q_tool htseq -o ${outfile_name}\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 21,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"\")\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f $features -a $pathogen_attribute -org pathogen -q_tool htseq -o ${outfile_name}\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "extract_annotations_pathogen_gff_htseq",
            "gene_feature_to_extract_annotations_pathongen_htseq",
            "pathogen_gff_attribute_to_extract_annotations_htseq"
        ],
        "nb_inputs": 3,
        "outputs": [
            "pathogen_annotations_RNA_class_stats_htseq",
            "annotation_pathogen_combine_quant_htseq_u_m",
            "annotation_pathogen_split_quant_htseq"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"extract_annotations_pathogen\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_annotations_host_htseq": {
        "name_process": "extract_annotations_host_htseq",
        "string_process": "\tprocess extract_annotations_host_htseq {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"extract_annotations_host\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file gff from extract_annotations_host_gff_htseq\n\t    val(features) from gene_feature_to_extract_annotations_host_htseq\n\t    val(host_attribute) from host_gff_attribute_to_extract_annotations_htseq\n\n\t    output:\n\t    file \"${outfile_name}*_htseq.tsv\" into host_annotations_RNA_class_stats_htseq\n\t    file \"${outfile_name}*_htseq.tsv\" into annotation_host_combine_quant_htseq\n\t    file \"${outfile_name}*_htseq.tsv\" into annotation_host_split_quant_htseq\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"\")\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f $features -a $host_attribute -org host -q_tool htseq -o ${outfile_name}\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 21,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"\")\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f $features -a $host_attribute -org host -q_tool htseq -o ${outfile_name}\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "extract_annotations_host_gff_htseq",
            "gene_feature_to_extract_annotations_host_htseq",
            "host_gff_attribute_to_extract_annotations_htseq"
        ],
        "nb_inputs": 3,
        "outputs": [
            "host_annotations_RNA_class_stats_htseq",
            "annotation_host_combine_quant_htseq",
            "annotation_host_split_quant_htseq"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"extract_annotations_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_reference_names_host_star": {
        "name_process": "extract_reference_names_host_star",
        "string_process": "\tprocess extract_reference_names_host_star {\n\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode \n\t\t    storeDir \"${params.outdir}/references\"\n\t\t    tag \"extract_ref_names_host_star\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(host_fa) from genome_fasta_host_ref_names\n\n\t\t    output:\n\t\t    file \"reference_host_names.txt\" into reference_host_names_uniquelymapped \n\t\t    file \"reference_host_names.txt\" into reference_host_names_crossmapped_find\n\t\t    file \"reference_host_names.txt\" into reference_host_names_multimapped\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_reference_names_from_fasta_files.sh reference_host_names.txt $host_fa\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 18,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_reference_names_from_fasta_files.sh reference_host_names.txt $host_fa\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_fasta_host_ref_names"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reference_host_names_uniquelymapped",
            "reference_host_names_crossmapped_find",
            "reference_host_names_multimapped"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"extract_ref_names_host_star\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_reference_names_pathogen_star": {
        "name_process": "extract_reference_names_pathogen_star",
        "string_process": "\tprocess extract_reference_names_pathogen_star {\n\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode \n\t\t    storeDir \"${params.outdir}/references\"\n\t\t    tag \"extract_ref_names_pathgn_star\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(pathogen_fa) from genome_fasta_pathogen_ref_names.collect()\n\n\t\t    output:\n\t\t    file \"reference_pathogen_names.txt\" into reference_pathogen_names_uniquelymapped\n\t\t    file \"reference_pathogen_names.txt\" into reference_pathogen_crossmapped_find\n\t\t    file \"reference_pathogen_names.txt\" into reference_pathogen_names_multimapped\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_reference_names_from_fasta_files.sh reference_pathogen_names.txt $pathogen_fa\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 18,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_reference_names_from_fasta_files.sh reference_pathogen_names.txt $pathogen_fa\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_fasta_pathogen_ref_names"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reference_pathogen_names_uniquelymapped",
            "reference_pathogen_crossmapped_find",
            "reference_pathogen_names_multimapped"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"extract_ref_names_pathgn_star\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_attribute_host_genome_gff_star_salmon": {
        "name_process": "replace_attribute_host_genome_gff_star_salmon",
        "string_process": "\tprocess replace_attribute_host_genome_gff_star_salmon {\n\t    tag \"repl_attribute_host_genome_gff\"\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(gff) from gff_host_genome_star_salmon_change_atr\n\n\t    output:\n\t    file \"${outfile_name}\" into combine_gff_host_genome_star_salmon\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_parent_attribute.gff3\")\n\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} parent Parent\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_parent_attribute.gff3\")\n\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} parent Parent\n\t    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_host_genome_star_salmon_change_atr"
        ],
        "nb_inputs": 1,
        "outputs": [
            "combine_gff_host_genome_star_salmon"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"repl_attribute_host_genome_gff\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_attribute_host_tRNA_gff_star_salmon": {
        "name_process": "replace_attribute_host_tRNA_gff_star_salmon",
        "string_process": "\tprocess replace_attribute_host_tRNA_gff_star_salmon {\n\t\t    tag \"repl_attribute_host_tRNA_gff\"\n\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/references\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(gff) from change_attrubute_gff_host_tRNA_salmon_alignment\n\t\t    val(host_attribute) from host_gff_attribute_salmon_alignment_tRNA\n\n\t\t    output:\n\t\t    file \"${outfile_name}\" into combine_host_gffs\n\n\t\t    script:\n\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_parent_attribute.gff3\")\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} parent $host_attribute\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 18,
        "string_script": "\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_parent_attribute.gff3\")\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} parent $host_attribute\n\t\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "change_attrubute_gff_host_tRNA_salmon_alignment",
            "host_gff_attribute_salmon_alignment_tRNA"
        ],
        "nb_inputs": 2,
        "outputs": [
            "combine_host_gffs"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"repl_attribute_host_tRNA_gff\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_host_genome_tRNA_gff_star_salmon": {
        "name_process": "combine_host_genome_tRNA_gff_star_salmon",
        "string_process": "\tprocess combine_host_genome_tRNA_gff_star_salmon {\n\t\t    tag \"comb_host_genome_tRNA_gff\"\n\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/references\"\n\t\t    \n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(host_gff_genome) from combine_gff_host_genome_star_salmon\n\t\t    file(host_gff_tRNA) from combine_host_gffs\n\n\t\t    output:\n\t\t    file \"${outfile_name}\" into gff_host_tRNA_genome_salmon_alignment\n\n\t\t    script:\n\t\t    outfile_name = host_gff_genome[0].toString().replaceAll(/.gff3|.gff/,\"_with_tRNA_STAR_salmon.gff3\")\n\t\t    \"\"\"\n\t\t    cat $host_gff_genome $host_gff_tRNA > ${outfile_name}\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 18,
        "string_script": "\t\t    outfile_name = host_gff_genome[0].toString().replaceAll(/.gff3|.gff/,\"_with_tRNA_STAR_salmon.gff3\")\n\t\t    \"\"\"\n\t\t    cat $host_gff_genome $host_gff_tRNA > ${outfile_name}\n\t\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "combine_gff_host_genome_star_salmon",
            "combine_host_gffs"
        ],
        "nb_inputs": 2,
        "outputs": [
            "gff_host_tRNA_genome_salmon_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"comb_host_genome_tRNA_gff\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_gene_feature_gff_host_salmon": {
        "name_process": "replace_gene_feature_gff_host_salmon",
        "string_process": "\tprocess replace_gene_feature_gff_host_salmon {\n\t    tag \"repl_gene_feature_gff_host\"\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(gff) from gff_host_genome_salmon_alignment\n\t    val(features) from gene_feature_gff_host_salmon_alignment\n\n\t    output:\n\t    file \"${outfile_name}\" into combine_gff_host_salmon_alignment\n\t    file \"${outfile_name}\" into extract_annotations_host_gff_salmon\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature_salmon_alignment.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 19,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature_salmon_alignment.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_host_genome_salmon_alignment",
            "gene_feature_gff_host_salmon_alignment"
        ],
        "nb_inputs": 2,
        "outputs": [
            "combine_gff_host_salmon_alignment",
            "extract_annotations_host_gff_salmon"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"repl_gene_feature_gff_host\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_attribute_pathogen_gff_star_salmon": {
        "name_process": "replace_attribute_pathogen_gff_star_salmon",
        "string_process": "\tprocess replace_attribute_pathogen_gff_star_salmon {\n\t    tag \"repl_attribute_pathogen_gff\"\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(gff) from gff_feature_quant_pathogen_salmon_alignment\n\t    val(pathogen_attribute) from pathogen_gff_attribute_salmon_alignment\n\n\t    output:\n\t    file \"${outfile_name}\" into to_replace_gff_feature_salmon_alignment\n\t    file \"${outfile_name}\" into extract_annotations_pathogen_gff_salmon\n\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_parent_attribute.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} parent $pathogen_attribute\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 20,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_parent_attribute.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_attribute_gff.sh $gff ${outfile_name} parent $pathogen_attribute\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_feature_quant_pathogen_salmon_alignment",
            "pathogen_gff_attribute_salmon_alignment"
        ],
        "nb_inputs": 2,
        "outputs": [
            "to_replace_gff_feature_salmon_alignment",
            "extract_annotations_pathogen_gff_salmon"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"repl_attribute_pathogen_gff\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_annotations_pathogen_salmon": {
        "name_process": "extract_annotations_pathogen_salmon",
        "string_process": "\tprocess extract_annotations_pathogen_salmon {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"extract_gff_annots_pathogen\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file gff from extract_annotations_pathogen_gff_salmon\n\t    val(features) from gene_feature_to_extract_annotations_pathogen\n\n\t    output:\n\t    file \"${outfile_name}*_salmon.tsv\" into pathogen_annotations_RNA_class_stats\n\t    file \"${outfile_name}*_salmon.tsv\" into pathogen_annotations_RNA_class_stats_salmon_alignment\n\t    file \"${outfile_name}*_salmon.tsv\" into annotation_pathogen_combine_quant\n\t    file \"${outfile_name}*_salmon.tsv\" into annotation_pathogen_combine_quant_salmon_alignment_based\n\n\t    script:\n\t    outfile_name = \"pathogen_gff_annotations\"\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f $features -a parent -org pathogen -q_tool salmon -o ${outfile_name}\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 21,
        "string_script": "\t    outfile_name = \"pathogen_gff_annotations\"\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f $features -a parent -org pathogen -q_tool salmon -o ${outfile_name}\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "extract_annotations_pathogen_gff_salmon",
            "gene_feature_to_extract_annotations_pathogen"
        ],
        "nb_inputs": 2,
        "outputs": [
            "pathogen_annotations_RNA_class_stats",
            "pathogen_annotations_RNA_class_stats_salmon_alignment",
            "annotation_pathogen_combine_quant",
            "annotation_pathogen_combine_quant_salmon_alignment_based"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"extract_gff_annots_pathogen\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_annotations_host_salmon": {
        "name_process": "extract_annotations_host_salmon",
        "string_process": "\tprocess extract_annotations_host_salmon {\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\t    tag \"extract_gff_annots_host\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file gff from extract_annotations_host_gff_salmon\n\n\t    output:\n\t    file \"${outfile_name}*_salmon.tsv\" into host_annotations_RNA_class_stats\n\t    file \"${outfile_name}*_salmon.tsv\" into host_annotations_RNA_class_stats_salmon_alignment\n\t    file \"${outfile_name}*_salmon.tsv\" into tximport_annotations\n\t    file \"${outfile_name}*_salmon.tsv\" into host_annotations_uniq_ambig\n            file \"${outfile_name}*_salmon.tsv\" into tximport_annotations_salmon_alignment\n\t    file \"${outfile_name}*_salmon.tsv\" into host_annotations_uniq_ambig_AB\n\t    file \"${outfile_name}*_salmon.tsv\" into annotation_host_combine_quant\n\t    file \"${outfile_name}*_salmon.tsv\" into annotation_host_combine_quant_salmon_alignment_based\n\t    file \"${outfile_name}*_salmon.tsv\" into annotation_host_combine_quant_gene_level_salmon\n\t    file \"${outfile_name}*_salmon.tsv\" into annotation_host_combine_quant_gene_level_salmon_alignment\n\n\t    script:\n\t    outfile_name = \"host_gff_annotations\"\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f quant -a parent -org host -q_tool salmon -o ${outfile_name}\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 26,
        "string_script": "\t    outfile_name = \"host_gff_annotations\"\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/extract_annotations_from_gff.py -gff $gff -f quant -a parent -org host -q_tool salmon -o ${outfile_name}\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "extract_annotations_host_gff_salmon"
        ],
        "nb_inputs": 1,
        "outputs": [
            "host_annotations_RNA_class_stats",
            "host_annotations_RNA_class_stats_salmon_alignment",
            "tximport_annotations",
            "host_annotations_uniq_ambig",
            "tximport_annotations_salmon_alignment",
            "host_annotations_uniq_ambig_AB",
            "annotation_host_combine_quant",
            "annotation_host_combine_quant_salmon_alignment_based",
            "annotation_host_combine_quant_gene_level_salmon",
            "annotation_host_combine_quant_gene_level_salmon_alignment"
        ],
        "nb_outputs": 10,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "tag \"extract_gff_annots_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "create_transcriptome_fasta_host": {
        "name_process": "create_transcriptome_fasta_host",
        "string_process": "\tprocess create_transcriptome_fasta_host {\n\t\t    tag \"create_transcripts_host\"\n\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/references\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(gff) from gff_host_create_transcriptome\n\t\t    file(host_fa) from genome_fasta_host_to_transcriptome\n\n\t\t    output:\n\t\t    file \"${outfile_name}\" into host_transcriptome\n\t\t    file \"${outfile_name}\" into transcriptome_host_to_split_table_salmon_without_tRNA\n\t\t    file \"${outfile_name}\" into transcriptome_host_to_split_table_salmon_alignment_without_tRNA\n\t\t    file \"${outfile_name}\" into transcriptome_host_to_split_q_table_salmon_without_tRNA\n\t\t    file \"${outfile_name}\" into transcriptome_host_to_split_q_table_salmon_alignment_based_without_tRNA\n\t\t    file \"${outfile_name}\" into host_transcriptome_to_combine_host\n\t\t    file \"${outfile_name}\" into transcriptome_fasta_host_ref_names_without_tRNA\n\n\t\t    script:\n\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_transcriptome.fasta\")\n\t\t    \"\"\"\n\t\t    gffread -w $outfile_name -g $host_fa $gff\n\t\t    \"\"\"\n\t}",
        "nb_lignes_process": 24,
        "string_script": "\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_transcriptome.fasta\")\n\t\t    \"\"\"\n\t\t    gffread -w $outfile_name -g $host_fa $gff\n\t\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_host_create_transcriptome",
            "genome_fasta_host_to_transcriptome"
        ],
        "nb_inputs": 2,
        "outputs": [
            "host_transcriptome",
            "transcriptome_host_to_split_table_salmon_without_tRNA",
            "transcriptome_host_to_split_table_salmon_alignment_without_tRNA",
            "transcriptome_host_to_split_q_table_salmon_without_tRNA",
            "transcriptome_host_to_split_q_table_salmon_alignment_based_without_tRNA",
            "host_transcriptome_to_combine_host",
            "transcriptome_fasta_host_ref_names_without_tRNA"
        ],
        "nb_outputs": 7,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"create_transcripts_host\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "create_transcriptome_fasta_host_tRNA": {
        "name_process": "create_transcriptome_fasta_host_tRNA",
        "string_process": "\tprocess create_transcriptome_fasta_host_tRNA {\n\t\t\t    tag \"create_transcripts_tRNA_host\"\n\t\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t\t\t    storeDir \"${params.outdir}/references\"\n\n\t\t\t    label 'process_high'\n\n\t\t\t    input:\n\t\t\t    file(gff) from gff_host_create_transcriptome_tRNA\n\t\t\t    file(host_fa) from genome_fasta_host_to_transcriptome_tRNA\n\t\t\t    val(features) from gene_feature_gff_to_create_transcriptome_host_salmon\n\t\t\t    val(attribute) from gene_attribute_gff_to_create_transcriptome_host_salmon\n\n\t\t\t    output:\n\t\t\t    file \"${outfile_name}\" into host_transcriptome_to_combine_tRNA\n\n\t\t\t    script:\n\t\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_transcriptome.fasta\")\n\t\t\t    \"\"\"\n\t\t\t    python $workflow.projectDir/bin/gff_to_fasta_transcriptome.py -fasta $host_fa -gff $gff  -f $features -a $attribute -o $outfile_name\n\t\t\t    \"\"\"\n\t\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_transcriptome.fasta\")\n\t\t\t    \"\"\"\n\t\t\t    python $workflow.projectDir/bin/gff_to_fasta_transcriptome.py -fasta $host_fa -gff $gff  -f $features -a $attribute -o $outfile_name\n\t\t\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_host_create_transcriptome_tRNA",
            "genome_fasta_host_to_transcriptome_tRNA",
            "gene_feature_gff_to_create_transcriptome_host_salmon",
            "gene_attribute_gff_to_create_transcriptome_host_salmon"
        ],
        "nb_inputs": 4,
        "outputs": [
            "host_transcriptome_to_combine_tRNA"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"create_transcripts_tRNA_host\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_host_fasta_transcriptomes": {
        "name_process": "combine_host_fasta_transcriptomes",
        "string_process": "\tprocess combine_host_fasta_transcriptomes {\n\t\t\t    tag \"comb_host_fa_tRNA_transcripts\"\n\t\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t\t\t    storeDir \"${params.outdir}/references\"\n\n\t\t\t    label 'process_high'\n\n\t\t\t    input:\n\t\t\t    file(host_tr_fa) from host_transcriptome_to_combine_host\n\t\t\t    file(host_tRNA_tr_fa) from host_transcriptome_to_combine_tRNA\n\n\t\t\t    output:\n\t\t\t    file \"host_transcriptome.fasta\" into host_transcriptome_genome_tRNA\n                            file \"host_transcriptome.fasta\" into transcriptome_host_to_split_table_salmon_with_tRNA\n                            file \"host_transcriptome.fasta\" into transcriptome_host_to_split_table_salmon_alignment_with_tRNA\n                            file \"host_transcriptome.fasta\" into transcriptome_host_to_split_q_table_salmon_with_tRNA\n                            file \"host_transcriptome.fasta\" into transcriptome_host_to_split_q_table_salmon_alignment_based_with_tRNA\n                            file \"host_transcriptome.fasta\" into transcriptome_fasta_host_ref_names_with_tRNA\n\n \t\t\t    script:\n\t\t\t    \"\"\"\n\t\t\t    cat $host_tr_fa $host_tRNA_tr_fa > host_transcriptome.fasta\n\t\t\t    \"\"\"\n\t\t\t}",
        "nb_lignes_process": 22,
        "string_script": "\t\t\t    \"\"\"\n\t\t\t    cat $host_tr_fa $host_tRNA_tr_fa > host_transcriptome.fasta\n\t\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_transcriptome_to_combine_host",
            "host_transcriptome_to_combine_tRNA"
        ],
        "nb_inputs": 2,
        "outputs": [
            "host_transcriptome_genome_tRNA",
            "transcriptome_host_to_split_table_salmon_with_tRNA",
            "transcriptome_host_to_split_table_salmon_alignment_with_tRNA",
            "transcriptome_host_to_split_q_table_salmon_with_tRNA",
            "transcriptome_host_to_split_q_table_salmon_alignment_based_with_tRNA",
            "transcriptome_fasta_host_ref_names_with_tRNA"
        ],
        "nb_outputs": 6,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"comb_host_fa_tRNA_transcripts\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "create_transcriptome_fasta_pathogen": {
        "name_process": "create_transcriptome_fasta_pathogen",
        "string_process": "\tprocess create_transcriptome_fasta_pathogen {\n\t\t    tag \"create_transcripts_fa_pathogen\"\n\t\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/references\"\n\n\t\t    label 'main'\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(gff) from gff_pathogen_create_transcriptome\n\t\t    file(pathogen_fa) from genome_fasta_pathogen_to_transcriptome.collect()\n\t\t    val(features) from gene_feature_gff_to_create_transcriptome_pathogen_salmon\n\t\t    val(attribute) from gene_attribute_gff_to_create_transcriptome_pathogen_salmon\n\n\t\t    output:\n\t\t    file \"${outfile_name}\" into pathogen_transcriptome_to_combine\n\t\t    file \"${outfile_name}\" into transcriptome_pathogen_to_split_table_salmon\n\t\t    file \"${outfile_name}\" into transcriptome_pathogen_to_split_table_salmon_alignment\n\t\t    file \"${outfile_name}\" into transcriptome_pathogen_to_split_q_table_salmon\n\t\t    file \"${outfile_name}\" into transcriptome_pathogen_to_split_q_table_salmon_alignment_based\n\t\t    file \"${outfile_name}\" into transcriptome_fasta_pathogen_ref_names\n\n\t\t    script:\n\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_transcriptome.fasta\")\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/gff_to_fasta_transcriptome.py -fasta $pathogen_fa -gff $gff -f $features -a $attribute  -o $outfile_name\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 26,
        "string_script": "\t\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_transcriptome.fasta\")\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/gff_to_fasta_transcriptome.py -fasta $pathogen_fa -gff $gff -f $features -a $attribute  -o $outfile_name\n\t\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff_pathogen_create_transcriptome",
            "genome_fasta_pathogen_to_transcriptome",
            "gene_feature_gff_to_create_transcriptome_pathogen_salmon",
            "gene_attribute_gff_to_create_transcriptome_pathogen_salmon"
        ],
        "nb_inputs": 4,
        "outputs": [
            "pathogen_transcriptome_to_combine",
            "transcriptome_pathogen_to_split_table_salmon",
            "transcriptome_pathogen_to_split_table_salmon_alignment",
            "transcriptome_pathogen_to_split_q_table_salmon",
            "transcriptome_pathogen_to_split_q_table_salmon_alignment_based",
            "transcriptome_fasta_pathogen_ref_names"
        ],
        "nb_outputs": 6,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"create_transcripts_fa_pathogen\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'main'",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_pathogen_host_fasta_transcriptome": {
        "name_process": "combine_pathogen_host_fasta_transcriptome",
        "string_process": "\tprocess combine_pathogen_host_fasta_transcriptome {\n\t    tag \"comb_pathogen_host_transcripts\"\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(host_tr_fa) from host_transcriptome_to_combine\n\t    file(pathogen_tr_fa) from pathogen_transcriptome_to_combine\n\n\t    output:\n\t    file \"host_pathogen_transcriptome.fasta\" into transcriptome_fasta_file_host_pathogen_to_decoy_transcriptome\n\t    file \"host_pathogen_transcriptome.fasta\" into transcriptome_salmon_alignment_based_mode\n\n\t    script:\n\t    \"\"\"\n\t    cat $pathogen_tr_fa $host_tr_fa > host_pathogen_transcriptome.fasta\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    \"\"\"\n\t    cat $pathogen_tr_fa $host_tr_fa > host_pathogen_transcriptome.fasta\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_transcriptome_to_combine",
            "pathogen_transcriptome_to_combine"
        ],
        "nb_inputs": 2,
        "outputs": [
            "transcriptome_fasta_file_host_pathogen_to_decoy_transcriptome",
            "transcriptome_salmon_alignment_based_mode"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"comb_pathogen_host_transcripts\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "replace_gene_feature_gff_pathogen_salmon": {
        "name_process": "replace_gene_feature_gff_pathogen_salmon",
        "string_process": "\tprocess replace_gene_feature_gff_pathogen_salmon {\n\t    tag \"repl_gene_feature_gff_pathogen\"\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(gff) from to_replace_gff_feature_salmon_alignment\n\t    val(features) from gene_feature_to_quantify_pathogen_salmon_alignment\n\n\t    output:\n\t    file \"${outfile_name}\" into combine_gff_pathogen_salmon_alignment\n\n\t    script:\n\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature_salmon_alignment.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    outfile_name = gff[0].toString().replaceAll(/.gff3|.gff/,\"_quant_feature_salmon_alignment.gff3\")\n\t    \"\"\"\n\t    $workflow.projectDir/bin/replace_feature_gff.sh $gff ${outfile_name} $features\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "to_replace_gff_feature_salmon_alignment",
            "gene_feature_to_quantify_pathogen_salmon_alignment"
        ],
        "nb_inputs": 2,
        "outputs": [
            "combine_gff_pathogen_salmon_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"repl_gene_feature_gff_pathogen\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_pathogen_host_gff_files_salmon": {
        "name_process": "combine_pathogen_host_gff_files_salmon",
        "string_process": "\tprocess combine_pathogen_host_gff_files_salmon {\n\t    tag \"combine_pathogen_host_gff\"\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode \n\t    storeDir \"${params.outdir}/references\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(host_gff) from combine_gff_host_salmon_alignment\n\t    file(pathogen_gff_genome) from combine_gff_pathogen_salmon_alignment\n\n\t    output:\n\t    file \"host_pathogen_star_alignment_mode.gff\" into gff_host_pathogen_star_salmon_alignment_gff\n\n\t    script:\n\t    \"\"\"\n\t    cat $pathogen_gff_genome $host_gff > host_pathogen_star_alignment_mode.gff\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    cat $pathogen_gff_genome $host_gff > host_pathogen_star_alignment_mode.gff\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "combine_gff_host_salmon_alignment",
            "combine_gff_pathogen_salmon_alignment"
        ],
        "nb_inputs": 2,
        "outputs": [
            "gff_host_pathogen_star_salmon_alignment_gff"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"combine_pathogen_host_gff\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\tprocess fastqc {\n\t    tag \"$name\"\n\t    label 'process_medium'\n\n\t    publishDir \"${params.outdir}/fastqc\", mode: params.publish_dir_mode\n                                                                                            \n\t    storeDir \"${params.outdir}/fastqc\"\n\n\t    input:\n\t    set val(name), file(reads) from ch_read_files_fastqc\n\n\t    output:\n\t    file \"*_fastqc.{zip,html}\" into ch_fastqc_results\n\n\t    script:\n\t    fastqc_params = params.fastqc_params\n\t    \"\"\"\n\t    fastqc --quiet --threads $task.cpus --noextract $reads $fastqc_params\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    fastqc_params = params.fastqc_params\n\t    \"\"\"\n\t    fastqc --quiet --threads $task.cpus --noextract $reads $fastqc_params\n\t    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_read_files_fastqc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_fastqc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/fastqc\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/fastqc\""
        ],
        "when": "",
        "stub": ""
    },
    "trimming": {
        "name_process": "trimming",
        "string_process": "\tprocess trimming {\n\t\t    tag \"$name_reads\"\n\t\t    publishDir \"${params.outdir}/trimming_cutadapt\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/trimming_cutadapt\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    set val(name), file(reads) from trimming_reads\n\t\t    val adapter_seq_3 from adapter_sequence_3\n\t\t    val q_value from quality_cutoff\n\n\t\t    output:\n\t\t    set val(name_sample), file(\"${name_sample}{_1,_2,}_trimmed.fastq.gz\") into trimming_results_star_htseq, trimming_results_to_salmon, trimming_results_to_qc, trimming_results_star_salmon\n\n\t\t    script:\n\t\t    cutadapt_params = params.cutadapt_params\n\t\t\tif (params.single_end){\n\t\t    \t\tname_reads = reads.toString().replaceAll(/:/,\"_\")\n\t\t    \t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t    \t\tname_out = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t    \t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\t\n\t\t    \t\t\"\"\"\n\t\t    \t\tcutadapt -j ${task.cpus} -q $q_value -a $adapter_seq_3 -m 1 -o ${name_out} $reads $cutadapt_params\n\t\t    \t\t\"\"\"\n\t\t\t} else{\n\t\t\t\tname_reads = name.replaceAll(/:/,\"_\")\n\t\t\t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t\t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\tname_1 = reads[0][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/-/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t\t\tname_2 = reads[1][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/-/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\") \n\t\t\t\t\"\"\"\n\t\t\t\tcutadapt -j ${task.cpus} -q $q_value -a ${adapter_seq_3[0]} -A ${adapter_seq_3[1]} -o ${name_1} -p ${name_2} -m 1 ${reads[0]} ${reads[1]} $cutadapt_params\n\t\t\t\t\"\"\"\n\t\t\t}\n\t\t}",
        "nb_lignes_process": 39,
        "string_script": "\t\t    cutadapt_params = params.cutadapt_params\n\t\t\tif (params.single_end){\n\t\t    \t\tname_reads = reads.toString().replaceAll(/:/,\"_\")\n\t\t    \t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t    \t\tname_out = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t    \t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\t\n\t\t    \t\t\"\"\"\n\t\t    \t\tcutadapt -j ${task.cpus} -q $q_value -a $adapter_seq_3 -m 1 -o ${name_out} $reads $cutadapt_params\n\t\t    \t\t\"\"\"\n\t\t\t} else{\n\t\t\t\tname_reads = name.replaceAll(/:/,\"_\")\n\t\t\t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t\t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\tname_1 = reads[0][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/-/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t\t\tname_2 = reads[1][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/-/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\") \n\t\t\t\t\"\"\"\n\t\t\t\tcutadapt -j ${task.cpus} -q $q_value -a ${adapter_seq_3[0]} -A ${adapter_seq_3[1]} -o ${name_1} -p ${name_2} -m 1 ${reads[0]} ${reads[1]} $cutadapt_params\n\t\t\t\t\"\"\"\n\t\t\t}",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "Cutadapt"
        ],
        "tools_url": [
            "https://bio.tools/cutadapt"
        ],
        "tools_dico": [
            {
                "name": "Cutadapt",
                "uri": "https://bio.tools/cutadapt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ]
                    }
                ],
                "description": "Find and remove adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads.",
                "homepage": "https://pypi.python.org/pypi/cutadapt"
            }
        ],
        "inputs": [
            "trimming_reads",
            "adapter_sequence_3",
            "quality_cutoff"
        ],
        "nb_inputs": 3,
        "outputs": [
            "trimming_results_star_htseq",
            "trimming_results_to_salmon",
            "trimming_results_to_qc",
            "trimming_results_star_salmon"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$name_reads\"",
            "publishDir \"${params.outdir}/trimming_cutadapt\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/trimming_cutadapt\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "bbduk": {
        "name_process": "bbduk",
        "string_process": "\tprocess bbduk {\n\t\t    tag \"$name_reads\"\n\t\t    publishDir \"${params.outdir}/trimming_bbduk\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/trimming_bbduk\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    set val(name), file(reads) from trimming_reads\n\t\t    file adapters from adapter_database\n\n\t\t    output:\n\t\t    set val(name_sample), file(\"${name_sample}{_1,_2,}_trimmed.fastq.gz\") into trimming_results_star_htseq, trimming_results_to_salmon, trimming_results_to_qc, trimming_results_star_salmon\n\t\t    file \"*.log\"\n\n\t\t    script:\n\t\t    minlen = params.minlen\n\t\t    qtrim = params.qtrim\n\t\t    trimq = params.trimq\n\t\t    ktrim = params.ktrim\n\t\t    k = params.k\n\t\t    mink = params.mink\n\t\t    hdist = params.hdist\n\t\t    bbduk_params = params.bbduk_params\n\t\t    if (params.single_end){\n\t\t    \t\tname_reads = reads.toString().replaceAll(/:/,\"_\")\n\t\t    \t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t    \t\tname_out = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t    \t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\tfileoutput = name_sample + '.log'\n\t\t    \t\t\"\"\"\n\t\t    \t\tbbduk.sh -Xmx1g in=$reads out=${name_out} ref=$adapters minlen=$minlen qtrim=$qtrim trimq=$trimq ktrim=$ktrim k=$k mink=$mink hdist=$hdist &> $fileoutput $bbduk_params\n\t\t    \t\t\"\"\"\n\t\t    } else{\n\t\t\t\tname_reads = name.replaceAll(/:/,\"_\")\n\t\t\t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t\t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\tname_1 = reads[0][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/-/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t\t\tname_2 = reads[1][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/-/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\") \n\t\t\t\tfileoutput = name_sample + '.log'\n\t\t\t\t\"\"\"\n\t\t\t\tbbduk.sh -Xmx1g in1=${reads[0]} in2=${reads[1]} out1=${name_1} out2=${name_2} ref=$adapters minlen=$minlen qtrim=$qtrim trimq=$trimq ktrim=$ktrim k=$k mink=$mink hdist=$hdist $bbduk_params tpe tbo &> $fileoutput\n\t\t\t\t\"\"\"\n\t\t\t}\n\t\t}",
        "nb_lignes_process": 47,
        "string_script": "\t\t    minlen = params.minlen\n\t\t    qtrim = params.qtrim\n\t\t    trimq = params.trimq\n\t\t    ktrim = params.ktrim\n\t\t    k = params.k\n\t\t    mink = params.mink\n\t\t    hdist = params.hdist\n\t\t    bbduk_params = params.bbduk_params\n\t\t    if (params.single_end){\n\t\t    \t\tname_reads = reads.toString().replaceAll(/:/,\"_\")\n\t\t    \t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t    \t\tname_out = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t    \t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\tfileoutput = name_sample + '.log'\n\t\t    \t\t\"\"\"\n\t\t    \t\tbbduk.sh -Xmx1g in=$reads out=${name_out} ref=$adapters minlen=$minlen qtrim=$qtrim trimq=$trimq ktrim=$ktrim k=$k mink=$mink hdist=$hdist &> $fileoutput $bbduk_params\n\t\t    \t\t\"\"\"\n\t\t    } else{\n\t\t\t\tname_reads = name.replaceAll(/:/,\"_\")\n\t\t\t\tname_reads = name_reads.replaceAll(/-/,\"_\")\n\t\t\t\tname_sample = name_reads.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"\")\n\t\t\t\tname_1 = reads[0][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/-/,\"_\")\n\t\t\t\tname_1 = name_1.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\")\n\t\t\t\tname_2 = reads[1][0].toString().replaceAll(/:/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/-/,\"_\")\n\t\t\t\tname_2 = name_2.replaceAll(/.fastq.gz|.fq.gz|.fastq|.fq/,\"_trimmed.fastq.gz\") \n\t\t\t\tfileoutput = name_sample + '.log'\n\t\t\t\t\"\"\"\n\t\t\t\tbbduk.sh -Xmx1g in1=${reads[0]} in2=${reads[1]} out1=${name_1} out2=${name_2} ref=$adapters minlen=$minlen qtrim=$qtrim trimq=$trimq ktrim=$ktrim k=$k mink=$mink hdist=$hdist $bbduk_params tpe tbo &> $fileoutput\n\t\t\t\t\"\"\"\n\t\t\t}",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimming_reads",
            "adapter_database"
        ],
        "nb_inputs": 2,
        "outputs": [
            "trimming_results_star_htseq",
            "trimming_results_to_salmon",
            "trimming_results_to_qc",
            "trimming_results_star_salmon"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$name_reads\"",
            "publishDir \"${params.outdir}/trimming_bbduk\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/trimming_bbduk\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "fastqc_after_trimming": {
        "name_process": "fastqc_after_trimming",
        "string_process": "\tprocess fastqc_after_trimming {\n\t    tag \"$sample_name\"\n\t    publishDir \"${params.outdir}/fastqc_after_trimming\", mode: params.publish_dir_mode\n                                                                                           \n\t    storeDir \"${params.outdir}/fastqc_after_trimming\"\n\n\t    label 'process_medium'\n\n\t    input:\n\t    set val(name),file(reads) from trimming_results_to_qc\n\n\t    output:\n\t    file \"*_trimmed_fastqc.{zip,html}\" into ch_fastqc_trimmed_results\n\n\t    script:\n\t    sample_name = name.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t    fastqc_params = params.fastqc_params\n\t    \"\"\"\n\t    fastqc --threads ${task.cpus} --quiet --noextract $reads $fastqc_params\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 19,
        "string_script": "\t    sample_name = name.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t    fastqc_params = params.fastqc_params\n\t    \"\"\"\n\t    fastqc --threads ${task.cpus} --quiet --noextract $reads $fastqc_params\n\t    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimming_results_to_qc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_fastqc_trimmed_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/fastqc_after_trimming\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/fastqc_after_trimming\"",
            "label 'process_medium'"
        ],
        "when": "",
        "stub": ""
    },
    "count_total_reads": {
        "name_process": "count_total_reads",
        "string_process": " process count_total_reads {\n\t    tag \"count_total_reads\"\n\t    publishDir \"${params.outdir}/mapping_statistics\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/mapping_statistics\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(fastq) from raw_read_count_file.collect()\n\t    output:\n\t    file \"total_raw_reads_fastq.tsv\" into to_collect_total_reads\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/count_total_reads.sh $fastq >> total_raw_reads_fastq.tsv\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 15,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/count_total_reads.sh $fastq >> total_raw_reads_fastq.tsv\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "raw_read_count_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "to_collect_total_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"count_total_reads\"",
            "publishDir \"${params.outdir}/mapping_statistics\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "count_total_read_pairs": {
        "name_process": "count_total_read_pairs",
        "string_process": "\tprocess count_total_read_pairs {\n\t\t    tag \"count_total_reads\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(tsv) from to_collect_total_reads.collect()\n\t\t    output:\n\t\t    file \"total_raw_read_pairs_fastq.tsv\" into collect_total_reads_raw_salmon\n\t\t    file \"total_raw_read_pairs_fastq.tsv\" into collect_total_reads_raw_salmon_alignment\n\t\t    file \"total_raw_read_pairs_fastq.tsv\" into collect_total_reads_raw_star\n\t\t    file \"total_raw_read_pairs_fastq.tsv\" into collect_total_reads_raw_star_for_salmon\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/collect_total_raw_read_pairs.py -i $tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 18,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/collect_total_raw_read_pairs.py -i $tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "to_collect_total_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collect_total_reads_raw_salmon",
            "collect_total_reads_raw_salmon_alignment",
            "collect_total_reads_raw_star",
            "collect_total_reads_raw_star_for_salmon"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"count_total_reads\"",
            "publishDir \"${params.outdir}/mapping_statistics\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "create_decoy_transcriptome_file": {
        "name_process": "create_decoy_transcriptome_file",
        "string_process": "\tprocess create_decoy_transcriptome_file {\n\t    tag \"create_decoy_transcripts_file\"\n\t    publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/references\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(host_fa) from genome_fasta_host_to_decoys\n      \t                                                         \n            file(host_pathogen_genome_fasta) from genome_fasta_file_host_pathogen_to_decoy_transcriptome\n\t    file(host_pathogen_transcriptome_fasta) from transcriptome_fasta_file_host_pathogen_to_decoy_transcriptome\n\n\t    output:\n\t    file \"gentrome.fasta\" into salmon_index_gentrome\n\t    file \"decoys.txt\" into salmon_index_decoys\n\n\t    shell:\n\t    '''\n\t    grep \">\" !{host_fa} | cut -d \" \" -f 1 > decoys.txt\n\t    sed -i -e 's/>//g' decoys.txt\n\t    cat !{host_pathogen_transcriptome_fasta} !{host_fa} > gentrome.fasta\n\t    '''\n\t}",
        "nb_lignes_process": 22,
        "string_script": "\t    '''\n\t    grep \">\" !{host_fa} | cut -d \" \" -f 1 > decoys.txt\n\t    sed -i -e 's/>//g' decoys.txt\n\t    cat !{host_pathogen_transcriptome_fasta} !{host_fa} > gentrome.fasta\n\t    '''",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_fasta_host_to_decoys",
            "genome_fasta_file_host_pathogen_to_decoy_transcriptome",
            "transcriptome_fasta_file_host_pathogen_to_decoy_transcriptome"
        ],
        "nb_inputs": 3,
        "outputs": [
            "salmon_index_gentrome",
            "salmon_index_decoys"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"create_decoy_transcripts_file\"",
            "publishDir \"${params.outdir}/references\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/references\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "salmon_index": {
        "name_process": "salmon_index",
        "string_process": "\tprocess salmon_index {\n\t    tag \"salmon_index\"\n            storeDir \"${params.outdir}/salmon\"\n\n            label 'process_high'\n\n\t    input:\n\t    file(gentrome) from salmon_index_gentrome\n\t    file(decoys) from salmon_index_decoys\n\t    val(kmer_length) from kmer_length_salmon_index\n\n\t    output:\n\t    file \"transcripts_index\" into salmon_index\n\n\t    script:\n\t    salmon_sa_params_index = params.salmon_sa_params_index\n\t    keepDuplicates = params.keepDuplicates ? \"--keepDuplicates\" : ''\n\t    \"\"\"\n\t    salmon index -t $gentrome -i transcripts_index --decoys $decoys -k $kmer_length -p ${task.cpus} $keepDuplicates $salmon_sa_params_index\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 19,
        "string_script": "\t    salmon_sa_params_index = params.salmon_sa_params_index\n\t    keepDuplicates = params.keepDuplicates ? \"--keepDuplicates\" : ''\n\t    \"\"\"\n\t    salmon index -t $gentrome -i transcripts_index --decoys $decoys -k $kmer_length -p ${task.cpus} $keepDuplicates $salmon_sa_params_index\n\t    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_index_gentrome",
            "salmon_index_decoys",
            "kmer_length_salmon_index"
        ],
        "nb_inputs": 3,
        "outputs": [
            "salmon_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"salmon_index\"",
            "storeDir \"${params.outdir}/salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "salmon_quantification": {
        "name_process": "salmon_quantification",
        "string_process": "\tprocess salmon_quantification {\n\t    storeDir \"${params.outdir}/salmon\"\n\t    tag \"${sample}\"\n\n            label 'process_high'\n\n\t    input:\n\t    file(index) from salmon_index.collect()\n\t    set val(sample), file(reads) from trimming_results_to_salmon\n\t    val(libtype) from libtype_salmon\n\n\t    output:\n\t    set val(sample_name), file(\"${sample_name}\") into split_table\n\t    set val(sample_name), file(\"${sample_name}\") into split_table_uniq_ambig\n\t    file(\"${sample_name}\") into salmon_files_to_combine\n\t    file(\"${sample_name}\") into multiqc_salmon_quant\n\t    set val(sample_name), file(\"${sample_name}\") into collect_processed_read_counts\n\n\t    script:\n\t    UnmappedNames = params.writeUnmappedNames ? \"--writeUnmappedNames\" : ''\n\t    softclip = params.softclipOverhangs ? \"--softclipOverhangs\" : ''\n\t    incompatPrior = params.incompatPrior\n\t    dumpEq = params.dumpEq ? \"--dumpEq\" : ''\n\t    salmon_sa_params_mapping = params.salmon_sa_params_mapping \n\t    if (params.single_end){\n\t    \tsample_name = sample.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t\twriteMappings = params.writeMappings ? \"--writeMappings=$sample_name/mapping.sam\" : ''\n\t\t\"\"\"\n\t\tsalmon quant -p ${task.cpus} -i $index -l $libtype -r $reads $softclip --incompatPrior $incompatPrior $UnmappedNames --validateMappings $dumpEq $writeMappings -o $sample_name $salmon_sa_params_mapping\n\t\t\"\"\"\n\t    } else{\n\t\tsample_name = sample.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t\twriteMappings = params.writeMappings ? \"--writeMappings=$sample_name/mapping.sam\" : ''\n\t\t\"\"\"\n\t\tsalmon quant -p ${task.cpus} -i $index -l $libtype -1 ${reads[0]} -2 ${reads[1]} $softclip --incompatPrior $incompatPrior $UnmappedNames --validateMappings $dumpEq $writeMappings -o $sample_name $salmon_sa_params_mapping\n \t\t\"\"\"\n\t    }\n\t}",
        "nb_lignes_process": 36,
        "string_script": "\t    UnmappedNames = params.writeUnmappedNames ? \"--writeUnmappedNames\" : ''\n\t    softclip = params.softclipOverhangs ? \"--softclipOverhangs\" : ''\n\t    incompatPrior = params.incompatPrior\n\t    dumpEq = params.dumpEq ? \"--dumpEq\" : ''\n\t    salmon_sa_params_mapping = params.salmon_sa_params_mapping \n\t    if (params.single_end){\n\t    \tsample_name = sample.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t\twriteMappings = params.writeMappings ? \"--writeMappings=$sample_name/mapping.sam\" : ''\n\t\t\"\"\"\n\t\tsalmon quant -p ${task.cpus} -i $index -l $libtype -r $reads $softclip --incompatPrior $incompatPrior $UnmappedNames --validateMappings $dumpEq $writeMappings -o $sample_name $salmon_sa_params_mapping\n\t\t\"\"\"\n\t    } else{\n\t\tsample_name = sample.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t\twriteMappings = params.writeMappings ? \"--writeMappings=$sample_name/mapping.sam\" : ''\n\t\t\"\"\"\n\t\tsalmon quant -p ${task.cpus} -i $index -l $libtype -1 ${reads[0]} -2 ${reads[1]} $softclip --incompatPrior $incompatPrior $UnmappedNames --validateMappings $dumpEq $writeMappings -o $sample_name $salmon_sa_params_mapping\n \t\t\"\"\"\n\t    }",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "Salmon"
        ],
        "tools_url": [
            "https://bio.tools/salmon"
        ],
        "tools_dico": [
            {
                "name": "Salmon",
                "uri": "https://bio.tools/salmon",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3496",
                                "term": "RNA sequence (raw)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2093",
                                "term": "Data reference"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "A tool for transcript expression quantification from RNA-seq data",
                "homepage": "https://github.com/COMBINE-lab/salmon"
            }
        ],
        "inputs": [
            "salmon_index",
            "trimming_results_to_salmon",
            "libtype_salmon"
        ],
        "nb_inputs": 3,
        "outputs": [
            "split_table",
            "split_table_uniq_ambig",
            "salmon_files_to_combine",
            "multiqc_salmon_quant",
            "collect_processed_read_counts"
        ],
        "nb_outputs": 5,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"${sample}\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "split_table_salmon_each": {
        "name_process": "split_table_salmon_each",
        "string_process": "\tprocess split_table_salmon_each {\n            publishDir \"${params.outdir}/salmon/${sample_name}\", mode: params.publish_dir_mode\n            storeDir \"${params.outdir}/salmon/${sample_name}\"\n            tag \"split_quantification ${sample_name}\"\n\n            label 'process_high'\n\n            input:\n            set val(sample_name), file (\"salmon/*\") from split_table\n            file transcriptome_pathogen from transcriptome_pathogen_to_split_q_table_salmon\n            file transcriptome_host from transcriptome_host_to_split_q_table_salmon\n\n            output:\n            set val(sample_name), file(\"host_quant.sf\") into salmon_host_tximport\n\n            script:\n            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host  salmon/*/quant.sf \"quant.sf\"\n            \"\"\"\n        }",
        "nb_lignes_process": 18,
        "string_script": "            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host  salmon/*/quant.sf \"quant.sf\"\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_table",
            "transcriptome_pathogen_to_split_q_table_salmon",
            "transcriptome_host_to_split_q_table_salmon"
        ],
        "nb_inputs": 3,
        "outputs": [
            "salmon_host_tximport"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon/${sample_name}\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon/${sample_name}\"",
            "tag \"split_quantification ${sample_name}\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_ambig_uniq_transcripts_genes": {
        "name_process": "extract_ambig_uniq_transcripts_genes",
        "string_process": "\tprocess extract_ambig_uniq_transcripts_genes {\n\t\t    publishDir \"${params.outdir}/salmon/${sample_name}/aux_info\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/salmon/${sample_name}/aux_info\"\n\t\t    tag \"extract_ambig_uniq_transcripts_genes ${sample_name}\"\n\n\t\t    label 'process_high'\n\n\t\t    input: \n\t\t    set val(sample_name), file(\"salmon/*\") from split_table_uniq_ambig\n\t\t    file (annotations) from host_annotations_uniq_ambig\n\n\n\t\t    output:\n\t\t    file \"${sample_name}_host_quant_ambig_uniq.sf\"\n\t\t    file \"${sample_name}_pathogen_quant_ambig_uniq.sf\"\n\t\t    file \"${sample_name}_host_quant_ambig_uniq_gene_level.sf\"\n\t\t    set val(sample_name), file(\"${sample_name}_host_quant_ambig_uniq.sf\") into host_files_comb\n\t\t    set val(sample_name), file(\"${sample_name}_pathogen_quant_ambig_uniq.sf\") into path_files_comb\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_extract_ambig_uniq_transcripts_genes.R salmon/*/quant.sf salmon/*/aux_info/ambig_info.tsv $sample_name $annotations\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 22,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_extract_ambig_uniq_transcripts_genes.R salmon/*/quant.sf salmon/*/aux_info/ambig_info.tsv $sample_name $annotations\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_table_uniq_ambig",
            "host_annotations_uniq_ambig"
        ],
        "nb_inputs": 2,
        "outputs": [
            "host_files_comb",
            "path_files_comb"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon/${sample_name}/aux_info\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon/${sample_name}/aux_info\"",
            "tag \"extract_ambig_uniq_transcripts_genes ${sample_name}\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "host_comb_ambig_uniq": {
        "name_process": "host_comb_ambig_uniq",
        "string_process": "\tprocess host_comb_ambig_uniq {\n\t\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/salmon\"\n\t\t    tag \"host_comb_ambig_uniq\"\n\n\t\t    label 'process_high'\n\n\t\t    input: \n\t\t    file(\"salmon/*\") from host_files_comb.collect()\n\n\t\t    output:\n\t\t    file \"host_quant_combined_ambig_uniq.tsv\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_host_comb_ambig_uniq.R salmon/*/aux_info/*_host_quant_ambig_uniq.sf\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_host_comb_ambig_uniq.R salmon/*/aux_info/*_host_quant_ambig_uniq.sf\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_files_comb"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"host_comb_ambig_uniq\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "pathogen_comb_ambig_uniq": {
        "name_process": "pathogen_comb_ambig_uniq",
        "string_process": "\tprocess pathogen_comb_ambig_uniq {\n\t\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/salmon\"\n\t\t    tag \"pathogen_comb_ambig_uniq\"\n\n\t\t    label 'process_high'\n\n\t\t    input: \n\t\t    file(\"salmon/*\") from path_files_comb.collect()\n\n\t\t    output:\n\t\t    file \"pathogen_quant_combined_ambig_uniq.tsv\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_pathogen_comb_ambig_uniq.R salmon/*/aux_info/*_pathogen_quant_ambig_uniq.sf\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_pathogen_comb_ambig_uniq.R salmon/*/aux_info/*_pathogen_quant_ambig_uniq.sf\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "path_files_comb"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"pathogen_comb_ambig_uniq\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_quantification_tables_salmon": {
        "name_process": "combine_quantification_tables_salmon",
        "string_process": "\tprocess combine_quantification_tables_salmon {\n\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon\"\n\t    tag \"combine_quantification_salmon\"\n\t    label 'process_high'\n\n\t    input: \n\t    file input_quantification from salmon_files_to_combine.collect()\n\t    val gene_attribute from host_atr_collect_data_salmon\n\n\t    output:\n\t    file \"combined_quant.tsv\" into split_table_salmon \n\n\t    script:\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a $gene_attribute -org both\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 16,
        "string_script": "\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a $gene_attribute -org both\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_files_to_combine",
            "host_atr_collect_data_salmon"
        ],
        "nb_inputs": 2,
        "outputs": [
            "split_table_salmon"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"combine_quantification_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "split_quantification_tables_salmon": {
        "name_process": "split_quantification_tables_salmon",
        "string_process": "\tprocess split_quantification_tables_salmon {\n\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n            tag \"split_quant_table_salmon\"\n\n            label 'process_high'\n\n            input:\n            file quant_table from split_table_salmon\n            file transcriptome_pathogen from transcriptome_pathogen_to_split_table_salmon\n            file transcriptome_host from transcriptome_host_to_split_table_salmon\n\n            output:\n            file 'host_quant_salmon.tsv' into host_quantification_mapping_stats_salmon \n            file 'pathogen_quant_salmon.tsv' into pathogen_quantification_mapping_stats_salmon\n            file 'host_quant_salmon.tsv' into host_quantification_RNA_stats_salmon \n            file 'pathogen_quant_salmon.tsv' into pathogen_quantification_RNA_stats_salmon\n            file 'host_quant_salmon.tsv' into quant_host_add_annotations \n            file 'pathogen_quant_salmon.tsv' into quant_pathogen_add_annotations\n            file 'host_quant_salmon.tsv' into quant_scatter_plot_host\n            file 'pathogen_quant_salmon.tsv' into quant_scatter_plot_pathogen\n\t    env pathonen_tab into pathonen_tab into scatterplots_pathogen_salmon\n\t    env host_tab into host_tab into scatterplots_host_salmon\n\n            script:\n            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host $quant_table \"quant_salmon.tsv\"\n            pathonen_tab=\\$(if [ \\$(cat pathogen_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            host_tab=\\$(if [ \\$(cat host_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            \"\"\"\n        }",
        "nb_lignes_process": 28,
        "string_script": "            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host $quant_table \"quant_salmon.tsv\"\n            pathonen_tab=\\$(if [ \\$(cat pathogen_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            host_tab=\\$(if [ \\$(cat host_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_table_salmon",
            "transcriptome_pathogen_to_split_table_salmon",
            "transcriptome_host_to_split_table_salmon"
        ],
        "nb_inputs": 3,
        "outputs": [
            "host_quantification_mapping_stats_salmon",
            "pathogen_quantification_mapping_stats_salmon",
            "host_quantification_RNA_stats_salmon",
            "pathogen_quantification_RNA_stats_salmon",
            "quant_host_add_annotations",
            "quant_pathogen_add_annotations",
            "quant_scatter_plot_host",
            "quant_scatter_plot_pathogen",
            "pathonen_tab",
            "host_tab"
        ],
        "nb_outputs": 10,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "tag \"split_quant_table_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_pathogen": {
        "name_process": "combine_annotations_quant_pathogen",
        "string_process": "\tprocess combine_annotations_quant_pathogen {\n\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon\"\n\t    tag \"comb_annots_quant_pathgn_salmon\"\n\n   \t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_pathogen_add_annotations\n\t    file annotation_table from annotation_pathogen_combine_quant\n\t    val attribute from combine_annot_quant_pathogen\n\n\t    output:\n\t    file \"pathogen_combined_quant_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org pathogen\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org pathogen\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_pathogen_add_annotations",
            "annotation_pathogen_combine_quant",
            "combine_annot_quant_pathogen"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"comb_annots_quant_pathgn_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_host_salmon": {
        "name_process": "combine_annotations_quant_host_salmon",
        "string_process": "\tprocess combine_annotations_quant_host_salmon {\n\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon\"\n\t    tag \"comb_annots_quant_host_salmon\"\n\n   \t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_host_add_annotations\n\t    file annotation_table from annotation_host_combine_quant\n\t    val attribute from combine_annot_quant_host\n\n\t    output:\n\t    file \"host_combined_quant_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org host\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org host\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_host_add_annotations",
            "annotation_host_combine_quant",
            "combine_annot_quant_host"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"comb_annots_quant_host_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "tximport_host": {
        "name_process": "tximport_host",
        "string_process": "\tprocess tximport_host {\n\t    publishDir \"${params.outdir}/salmon/${sample_name}\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon/${sample_name}\"\n\t    tag \"tximport_host\"\n\n   \t    label 'process_high'\n\n\t    input: \n\t    set val(sample_name), file(\"salmon/${sample_name}/*\") from salmon_host_tximport\n\t    file (annotations) from tximport_annotations\n\n\t    output:\n\t    file \"${sample_name}_host_quant_gene_level.sf\" into salmon_files_to_combine_gene_level\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/tximport.R salmon $annotations $sample_name\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/tximport.R salmon $annotations $sample_name\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_host_tximport",
            "tximport_annotations"
        ],
        "nb_inputs": 2,
        "outputs": [
            "salmon_files_to_combine_gene_level"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon/${sample_name}\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon/${sample_name}\"",
            "tag \"tximport_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_host_quant_gene_level_salmon": {
        "name_process": "combine_host_quant_gene_level_salmon",
        "string_process": "\tprocess combine_host_quant_gene_level_salmon {\n\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon\"\n\t    tag \"comb_host_quant_genes_salmon\"\n \n\t    label 'process_high'\n\n\t    input: \n\t    file input_quantification from salmon_files_to_combine_gene_level.collect()\n\n\t    output:\n\t    file \"host_combined_gene_level.tsv\" into quant_gene_level_host_add_annotations_salmon\n\n\t    script:\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a gene_id -org host_gene_level\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 16,
        "string_script": "\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a gene_id -org host_gene_level\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_files_to_combine_gene_level"
        ],
        "nb_inputs": 1,
        "outputs": [
            "quant_gene_level_host_add_annotations_salmon"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"comb_host_quant_genes_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_gene_level_salmon": {
        "name_process": "combine_annotations_quant_gene_level_salmon",
        "string_process": "\tprocess combine_annotations_quant_gene_level_salmon {\n\t    publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon\"\n\t    tag \"comb_annots_gene_host_salmon\"\n\n\t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_gene_level_host_add_annotations_salmon\n\t    file annotation_table from annotation_host_combine_quant_gene_level_salmon\n\n\t    output:\n\t    file \"host_combined_quant_gene_level_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_annotations_salmon_gene_level.py -q $quantification_table -annotations $annotation_table -a gene_id -org host\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_annotations_salmon_gene_level.py -q $quantification_table -annotations $annotation_table -a gene_id -org host\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_gene_level_host_add_annotations_salmon",
            "annotation_host_combine_quant_gene_level_salmon"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon\"",
            "tag \"comb_annots_gene_host_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "scatter_plot_pathogen_salmon": {
        "name_process": "scatter_plot_pathogen_salmon",
        "string_process": "\tprocess scatter_plot_pathogen_salmon {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\"\n\t\t    tag \"scatter_plot_salmon_pathogen\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from quant_scatter_plot_pathogen\n\t\t    val attribute from atr_scatter_plot_pathogen\n\t\t    val replicates from repl_scatter_plots_salmon_pathogen\n\t\t    val pathogen_table_non_empty from scatterplots_pathogen_salmon \n\n\t\t    output:\n\t\t    file ('*.pdf')\n\n\t\t    when:\n\t\t    replicates.toBoolean()\n\t\t    pathogen_table_non_empty.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org pathogen \n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org pathogen \n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_scatter_plot_pathogen",
            "atr_scatter_plot_pathogen",
            "repl_scatter_plots_salmon_pathogen",
            "scatterplots_pathogen_salmon"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\"",
            "tag \"scatter_plot_salmon_pathogen\"",
            "label 'process_high'"
        ],
        "when": "replicates.toBoolean()\n\t\t    pathogen_table_non_empty.toBoolean()",
        "stub": ""
    },
    "scatter_plot_host_salmon": {
        "name_process": "scatter_plot_host_salmon",
        "string_process": "\tprocess scatter_plot_host_salmon {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\"\n\t\t    tag \"scatter_plot_salmon_host\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from quant_scatter_plot_host\n\t\t    val attribute from atr_scatter_plot_host\n\t\t    val replicates from repl_scatter_plots_salmon_host\n\t\t    val host_table_non_empty from scatterplots_host_salmon \n\n\t\t    output:\n\t\t    file ('*.pdf')\n\n\t\t    when:\n\t\t    replicates.toBoolean()\n\t\t    host_table_non_empty.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org host\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org host\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_scatter_plot_host",
            "atr_scatter_plot_host",
            "repl_scatter_plots_salmon_host",
            "scatterplots_host_salmon"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon/scatter_plots\"",
            "tag \"scatter_plot_salmon_host\"",
            "label 'process_high'"
        ],
        "when": "replicates.toBoolean()\n\t\t    host_table_non_empty.toBoolean()",
        "stub": ""
    },
    "extract_processed_reads": {
        "name_process": "extract_processed_reads",
        "string_process": "\tprocess extract_processed_reads {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon\"\n\t\t    tag \"extract_processed_reads\"\n\n\t\t    label 'process_high'\n\t\t   \n\t\t    input: \n\t\t    set val(sample_name), file (\"salmon/*\") from collect_processed_read_counts\n\n\t\t    output:\n\t\t    file \"${sample_name}.txt\" into collect_results\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh salmon/*/aux_info/meta_info.json $sample_name salmon\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh salmon/*/aux_info/meta_info.json $sample_name salmon\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_processed_read_counts"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collect_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon\"",
            "tag \"extract_processed_reads\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_processed_reads": {
        "name_process": "collect_processed_reads",
        "string_process": "\tprocess collect_processed_reads {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon\"\n\t\t    tag \"collect_processed_reads\"\n\n\t\t    label 'process_high' \n\t\t    \n\t\t    input: \n\t\t    file process_reads from collect_results.collect()\n\n\t\t    output:\n\t\t    file \"processed_reads_salmon.tsv\" into mapping_stats_total_reads\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_salmon.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_salmon.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_results"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mapping_stats_total_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon\"",
            "tag \"collect_processed_reads\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "salmon_quantification_stats": {
        "name_process": "salmon_quantification_stats",
        "string_process": "\tprocess salmon_quantification_stats {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon\"\n\t\t    tag \"quantification_stats_salmon\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table_host from host_quantification_mapping_stats_salmon\n\t\t    file quant_table_pathogen from pathogen_quantification_mapping_stats_salmon\n\t\t    val attribute from attribute_quant_stats_salmon\n\t\t    file total_processed_reads from mapping_stats_total_reads\n\t\t    file total_raw_reads from collect_total_reads_raw_salmon.ifEmpty('.')\n\n\t\t    output:\n\t\t    file ('salmon_host_pathogen_total_reads.tsv') into salmon_mapped_stats_to_plot\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -q_p $quant_table_pathogen -q_h $quant_table_host -total_processed $total_processed_reads -total_raw $total_raw_reads -a $attribute -t salmon -o salmon_host_pathogen_total_reads.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -q_p $quant_table_pathogen -q_h $quant_table_host -total_processed $total_processed_reads -total_raw $total_raw_reads -a $attribute -t salmon -o salmon_host_pathogen_total_reads.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_quantification_mapping_stats_salmon",
            "pathogen_quantification_mapping_stats_salmon",
            "attribute_quant_stats_salmon",
            "mapping_stats_total_reads",
            "collect_total_reads_raw_salmon"
        ],
        "nb_inputs": 5,
        "outputs": [
            "salmon_mapped_stats_to_plot"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon\"",
            "tag \"quantification_stats_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_salmon_mapping_stats_host_pathogen": {
        "name_process": "plot_salmon_mapping_stats_host_pathogen",
        "string_process": "\tprocess plot_salmon_mapping_stats_host_pathogen {\n\t\t    tag \"$name2\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(stats) from salmon_mapped_stats_to_plot\n\n\t\t    output:\n\t\t    file \"*.tsv\"\n\t\t    file \"*.pdf\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_statistics_salmon.py -i $stats\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 17,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_statistics_salmon.py -i $stats\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_mapped_stats_to_plot"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$name2\"",
            "publishDir \"${params.outdir}/mapping_statistics/salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "RNA_class_statistics_salmon_pathogen": {
        "name_process": "RNA_class_statistics_salmon_pathogen",
        "string_process": "\tprocess RNA_class_statistics_salmon_pathogen {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    tag \"rna_class_stats_pathgn_salmon\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from pathogen_quantification_RNA_stats_salmon\n\t\t    val attribute from host_annotations_RNA_class_stats_pathogen\n\t\t    file gene_annotations from pathogen_annotations_RNA_class_stats\n\n\t\t    output:\n\t\t    file \"pathogen_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_pathogen\n\t\t    file \"pathogen_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_pathogen_combined\n\t\t    file \"pathogen_RNA_classes_sum_counts_*.tsv\"\n\t\t    stdout plot_RNA_stats_pathogen_boolean\n\t\t    stdout plot_RNA_stats_pathogen_combined_boolean\n\n\t\t    shell:\n\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -q_tool salmon -org pathogen 2>&1\n\t\t    '''\n\t\t}",
        "nb_lignes_process": 21,
        "string_script": "\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -q_tool salmon -org pathogen 2>&1\n\t\t    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pathogen_quantification_RNA_stats_salmon",
            "host_annotations_RNA_class_stats_pathogen",
            "pathogen_annotations_RNA_class_stats"
        ],
        "nb_inputs": 3,
        "outputs": [
            "plot_RNA_stats_pathogen",
            "plot_RNA_stats_pathogen_combined",
            "plot_RNA_stats_pathogen_boolean",
            "plot_RNA_stats_pathogen_combined_boolean"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "tag \"rna_class_stats_pathgn_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "RNA_class_statistics_salmon_host": {
        "name_process": "RNA_class_statistics_salmon_host",
        "string_process": "\tprocess RNA_class_statistics_salmon_host {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    tag \"rna_class_stats_host_salmon\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from host_quantification_RNA_stats_salmon\n\t\t    val attribute from attribute_host_RNA_class_stats\n\t\t    file gene_annotations from host_annotations_RNA_class_stats\n\t\t    file rna_classes_to_replace from RNA_classes_to_replace\n\n\t\t    output:\n\t\t    file \"host_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_host\n\t\t    file \"host_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_host_combined\n\t\t    file \"host_RNA_classes_sum_counts_*.tsv\"\n\t\t    file \"host_gene_types_groups_*\"\n\t\t    stdout plot_RNA_stats_host_combined_boolean\n\t\t    stdout plot_RNA_stats_host_boolean\n\n\t\t    shell:\n\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -rna !{rna_classes_to_replace} -q_tool salmon -org host 2>&1\n\t\t    '''\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -rna !{rna_classes_to_replace} -q_tool salmon -org host 2>&1\n\t\t    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_quantification_RNA_stats_salmon",
            "attribute_host_RNA_class_stats",
            "host_annotations_RNA_class_stats",
            "RNA_classes_to_replace"
        ],
        "nb_inputs": 4,
        "outputs": [
            "plot_RNA_stats_host",
            "plot_RNA_stats_host_combined",
            "plot_RNA_stats_host_combined_boolean",
            "plot_RNA_stats_host_boolean"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\", mode: params.publish_dir_mode",
            "tag \"rna_class_stats_host_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_RNA_class_salmon_pathogen_each": {
        "name_process": "plot_RNA_class_salmon_pathogen_each",
        "string_process": "\tprocess plot_RNA_class_salmon_pathogen_each {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\"\n\t\t    tag \"plot_RNA_stats_pathogen_salmon\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_pathogen\n\t\t    val plot_rna from plot_RNA_stats_pathogen_boolean\n\n\t\t    output:\n\t\t    file \"*.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_pathogen",
            "plot_RNA_stats_pathogen_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\"",
            "tag \"plot_RNA_stats_pathogen_salmon\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_salmon_pathogen_combined": {
        "name_process": "plot_RNA_class_salmon_pathogen_combined",
        "string_process": "\tprocess plot_RNA_class_salmon_pathogen_combined {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\"\n\t\t    tag \"plot_RNA_stats_comb_pathogen\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_pathogen_combined\n\t\t    val plot_rna from plot_RNA_stats_pathogen_combined_boolean\n\n\t\t    output:\n\t\t    file \"RNA_class_stats_combined_pathogen.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org pathogen\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org pathogen\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_pathogen_combined",
            "plot_RNA_stats_pathogen_combined_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_pathogen\"",
            "tag \"plot_RNA_stats_comb_pathogen\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_salmon_host_each": {
        "name_process": "plot_RNA_class_salmon_host_each",
        "string_process": "\tprocess plot_RNA_class_salmon_host_each {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\"\n\t\t    tag \"plot_RNA_stats_host_salmon\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_host\n\t\t    val plot_rna from plot_RNA_stats_host_boolean\n\n\t\t    output:\n\t\t    file \"*.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_host",
            "plot_RNA_stats_host_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\"",
            "tag \"plot_RNA_stats_host_salmon\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_salmon_host_combined": {
        "name_process": "plot_RNA_class_salmon_host_combined",
        "string_process": "\tprocess plot_RNA_class_salmon_host_combined {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\"\n\t\t    tag \"plot_RNA_stats_comb_host\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_host_combined\n\t\t    val plot_rna from plot_RNA_stats_host_combined_boolean\n\n\t\t    output:\n\t\t    file \"RNA_class_stats_combined_host.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org host\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org host\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_host_combined",
            "plot_RNA_stats_host_combined_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon/RNA_classes_host\"",
            "tag \"plot_RNA_stats_comb_host\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "STARindex_salmon_alignment": {
        "name_process": "STARindex_salmon_alignment",
        "string_process": "\tprocess STARindex_salmon_alignment {\n\t\tpublishDir \"${params.outdir}/STAR_for_salmon\", mode: params.publish_dir_mode\n\t\tstoreDir \"${params.outdir}/STAR_for_salmon\" \n\t\ttag \"STAR_index\"\n\n         \tlabel 'process_high'\n\n\t\tinput:\n\t\tfile(fasta) from host_pathogen_fasta_index\n\t\tfile(gff) from genome_gff_star_index\n\n\t\toutput:\n\t\tfile \"index/*\" into star_index_transcriptome_alignment\n\n\t\tscript:\n\t\tsjdbOverhang = params.sjdbOverhang\n\t\tstar_salmon_index_params = params.star_salmon_index_params\n\t\t\"\"\"\n\t\tmkdir index\n\t\tSTAR --runThreadN ${task.cpus} --runMode genomeGenerate --genomeDir index/ --genomeFastaFiles $fasta --sjdbGTFfile $gff --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --sjdbOverhang $sjdbOverhang $star_salmon_index_params\n\t\t\"\"\"\n\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\tsjdbOverhang = params.sjdbOverhang\n\t\tstar_salmon_index_params = params.star_salmon_index_params\n\t\t\"\"\"\n\t\tmkdir index\n\t\tSTAR --runThreadN ${task.cpus} --runMode genomeGenerate --genomeDir index/ --genomeFastaFiles $fasta --sjdbGTFfile $gff --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --sjdbOverhang $sjdbOverhang $star_salmon_index_params\n\t\t\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "host_pathogen_fasta_index",
            "genome_gff_star_index"
        ],
        "nb_inputs": 2,
        "outputs": [
            "star_index_transcriptome_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/STAR_for_salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/STAR_for_salmon\"",
            "tag \"STAR_index\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "ALIGNMENTstar_for_salmon": {
        "name_process": "ALIGNMENTstar_for_salmon",
        "string_process": "\tprocess ALIGNMENTstar_for_salmon {\n\t    tag \"$sample_name\"\n\t    publishDir \"${params.outdir}/STAR_for_salmon\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/STAR_for_salmon\" \n\n\t    label 'process_medium'\n\t\n\t    input:\n\t    set val(sample_name),file(reads) from  trimming_results_star_salmon\n\t    file(gff) from gff_host_pathogen_star_salmon_alignment_gff.collect()\n\t    file(index) from star_index_transcriptome_alignment.collect()\n\n\t    output:\n\t    file \"${sample_name}/*\" into multiqc_star_for_salmon_alignment\n\t    set val(sample_name), file(\"${sample_name}/${sample_name}Aligned.toTranscriptome.out.bam\") into salmon_quantify_alignment_based_mode\n\t    file \"${sample_name}/*\"\n\t    set val(sample_name), file(\"${sample_name}/${sample_name}Log.final.out\") into collect_processed_read_counts_STAR_for_salmon\n\n\t    script:\n\t    outSAMunmapped = params.outSAMunmapped\n\t    outSAMattributes = params.outSAMattributes\n\t    quantTranscriptomeBan = params.quantTranscriptomeBan\n\t    outFilterMultimapNmax = params.outFilterMultimapNmax\n\t    outFilterType = params.outFilterType\n\t    alignSJoverhangMin = params.alignSJoverhangMin\n\t    alignSJDBoverhangMin = params.alignSJDBoverhangMin\n\t    outFilterMismatchNmax = params.outFilterMismatchNmax\n\t    outFilterMismatchNoverReadLmax = params.outFilterMismatchNoverReadLmax\n\t    alignIntronMin = params.alignIntronMin\n\t    alignIntronMax = params.alignIntronMax\n\t    alignMatesGapMax = params.alignMatesGapMax\n\t    limitBAMsortRAM = params.limitBAMsortRAM\n\t    readFilesCommand = reads[0].toString().endsWith('.gz') ? \"--readFilesCommand zcat\" : ''\n\t    winAnchorMultimapNmax = params.winAnchorMultimapNmax\n\t    star_salmon_alignment_params = params.star_salmon_alignment_params\n\n\t    if (params.single_end){\n\t    \t\"\"\"\n\t    \tmkdir $sample_name\n\t    \tSTAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn $reads --outSAMtype BAM Unsorted --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon quant --sjdbGTFtagExonParentTranscript parent --quantMode TranscriptomeSAM --quantTranscriptomeBan $quantTranscriptomeBan --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_salmon_alignment_params\n\t    \t\"\"\"\n\t    } else {\n\t    \t\"\"\"\n\t    \tmkdir $sample_name\n\t    \tSTAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn ${reads[0]} ${reads[1]} --outSAMtype BAM Unsorted --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon quant --sjdbGTFtagExonParentTranscript parent --quantMode TranscriptomeSAM --quantTranscriptomeBan $quantTranscriptomeBan --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_salmon_alignment_params\n\t    \t\"\"\"\n\t    }\n\t}",
        "nb_lignes_process": 46,
        "string_script": "\t    outSAMunmapped = params.outSAMunmapped\n\t    outSAMattributes = params.outSAMattributes\n\t    quantTranscriptomeBan = params.quantTranscriptomeBan\n\t    outFilterMultimapNmax = params.outFilterMultimapNmax\n\t    outFilterType = params.outFilterType\n\t    alignSJoverhangMin = params.alignSJoverhangMin\n\t    alignSJDBoverhangMin = params.alignSJDBoverhangMin\n\t    outFilterMismatchNmax = params.outFilterMismatchNmax\n\t    outFilterMismatchNoverReadLmax = params.outFilterMismatchNoverReadLmax\n\t    alignIntronMin = params.alignIntronMin\n\t    alignIntronMax = params.alignIntronMax\n\t    alignMatesGapMax = params.alignMatesGapMax\n\t    limitBAMsortRAM = params.limitBAMsortRAM\n\t    readFilesCommand = reads[0].toString().endsWith('.gz') ? \"--readFilesCommand zcat\" : ''\n\t    winAnchorMultimapNmax = params.winAnchorMultimapNmax\n\t    star_salmon_alignment_params = params.star_salmon_alignment_params\n\n\t    if (params.single_end){\n\t    \t\"\"\"\n\t    \tmkdir $sample_name\n\t    \tSTAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn $reads --outSAMtype BAM Unsorted --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon quant --sjdbGTFtagExonParentTranscript parent --quantMode TranscriptomeSAM --quantTranscriptomeBan $quantTranscriptomeBan --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_salmon_alignment_params\n\t    \t\"\"\"\n\t    } else {\n\t    \t\"\"\"\n\t    \tmkdir $sample_name\n\t    \tSTAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn ${reads[0]} ${reads[1]} --outSAMtype BAM Unsorted --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon quant --sjdbGTFtagExonParentTranscript parent --quantMode TranscriptomeSAM --quantTranscriptomeBan $quantTranscriptomeBan --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_salmon_alignment_params\n\t    \t\"\"\"\n\t    }",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimming_results_star_salmon",
            "gff_host_pathogen_star_salmon_alignment_gff",
            "star_index_transcriptome_alignment"
        ],
        "nb_inputs": 3,
        "outputs": [
            "multiqc_star_for_salmon_alignment",
            "salmon_quantify_alignment_based_mode",
            "collect_processed_read_counts_STAR_for_salmon"
        ],
        "nb_outputs": 3,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/STAR_for_salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/STAR_for_salmon\"",
            "label 'process_medium'"
        ],
        "when": "",
        "stub": ""
    },
    "salmon_quantification_alignment_based_mode": {
        "name_process": "salmon_quantification_alignment_based_mode",
        "string_process": "\tprocess salmon_quantification_alignment_based_mode {\n\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t    tag \"${sample}\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file(transcriptome) from transcriptome_salmon_alignment_based_mode.collect()\n\t    set val(sample), file(bam_file) from salmon_quantify_alignment_based_mode\n\t    val(libtype) from libtype_salmon_alignment_mode\n\n\t    output:\n\t    set val(sample_name), file(\"${sample_name}\") into split_table_alignment_based\n\t    set val(sample_name), file(\"${sample_name}\") into split_table_uniq_ambig_ab\n\t    file(\"${sample_name}\") into salmon_files_to_combine_alignment_mode\n\t    file(\"${sample_name}\") into multiqc_salmon_alignment_quant\n\t    set val(sample_name), file(\"${sample_name}\") into collect_processed_read_counts_alignment_based\n\n\t    script:\n\t    incompatPrior = params.incompatPrior\n\t    salmon_alignment_based_params = params.salmon_alignment_based_params\n\t    sample_name = sample.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t    \"\"\"\n\t    salmon quant -p ${task.cpus} -t $transcriptome -l $libtype -a $bam_file --incompatPrior $incompatPrior -o $sample_name $salmon_alignment_based_params\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 24,
        "string_script": "\t    incompatPrior = params.incompatPrior\n\t    salmon_alignment_based_params = params.salmon_alignment_based_params\n\t    sample_name = sample.replaceFirst(/.fastq.gz|.fq.gz|.fastq|.fq/, \"\")\n\t    \"\"\"\n\t    salmon quant -p ${task.cpus} -t $transcriptome -l $libtype -a $bam_file --incompatPrior $incompatPrior -o $sample_name $salmon_alignment_based_params\n\t    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "transcriptome_salmon_alignment_based_mode",
            "salmon_quantify_alignment_based_mode",
            "libtype_salmon_alignment_mode"
        ],
        "nb_inputs": 3,
        "outputs": [
            "split_table_alignment_based",
            "split_table_uniq_ambig_ab",
            "salmon_files_to_combine_alignment_mode",
            "multiqc_salmon_alignment_quant",
            "collect_processed_read_counts_alignment_based"
        ],
        "nb_outputs": 5,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"${sample}\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "split_table_salmon_each_salmon_alignment_mode": {
        "name_process": "split_table_salmon_each_salmon_alignment_mode",
        "string_process": "\tprocess split_table_salmon_each_salmon_alignment_mode {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\"\n\t    tag \"split_quant_tbl_for_sal_modes\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    set val(sample_name), file (\"salmon/*\") from split_table_alignment_based\n\t                                  \"salmon/*\"                                             \n\t    file transcriptome_pathogen from transcriptome_pathogen_to_split_q_table_salmon_alignment_based\n\t    file transcriptome_host from transcriptome_host_to_split_q_table_salmon_alignment_based\n\n\t    output:\n\t    set val(sample_name), file(\"host_quant.sf\") into salmon_alignment_host_tximport\n\t    set val(sample_name), file(\"pathogen_quant.sf\")\n\n            script:\n            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host salmon/*/quant.sf \"quant.sf\"\n            \"\"\"\n\t}",
        "nb_lignes_process": 20,
        "string_script": "            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host salmon/*/quant.sf \"quant.sf\"\n            \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_table_alignment_based",
            "transcriptome_pathogen_to_split_q_table_salmon_alignment_based",
            "transcriptome_host_to_split_q_table_salmon_alignment_based"
        ],
        "nb_inputs": 3,
        "outputs": [
            "salmon_alignment_host_tximport",
            "sample_name"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\"",
            "tag \"split_quant_tbl_for_sal_modes\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_ambig_uniq_transcripts_genes_alignment_based": {
        "name_process": "extract_ambig_uniq_transcripts_genes_alignment_based",
        "string_process": " process extract_ambig_uniq_transcripts_genes_alignment_based {\n\t\t    publishDir \"${params.outdir}/salmon_alignment_mode/${sample_name}/aux_info\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/salmon_alignment_mode/${sample_name}/aux_info\"\n\t\t    tag \"extract_ambig_uniq_transcripts_genes_AB ${sample_name}\"\n\n\t\t    label 'process_high'\n\n\t\t    input: \n\t\t    set val(sample_name), file(\"salmon/*\") from split_table_uniq_ambig_ab\n\t\t    file (annotations) from host_annotations_uniq_ambig_AB\n\n\n\t\t    output:\n\t\t    file \"${sample_name}_host_quant_ambig_uniq.sf\"\n\t\t    file \"${sample_name}_pathogen_quant_ambig_uniq.sf\"\n\t\t    file \"${sample_name}_host_quant_ambig_uniq_gene_level.sf\"\n\t\t    set val(sample_name), file(\"${sample_name}_host_quant_ambig_uniq.sf\") into host_files_comb_uniq_ambig_AB\n\t\t    set val(sample_name), file(\"${sample_name}_pathogen_quant_ambig_uniq.sf\") into path_files_comb_uniq_ambig_AB\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_extract_ambig_uniq_transcripts_genes.R salmon/*/quant.sf salmon/*/aux_info/ambig_info.tsv $sample_name $annotations\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 22,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_extract_ambig_uniq_transcripts_genes.R salmon/*/quant.sf salmon/*/aux_info/ambig_info.tsv $sample_name $annotations\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_table_uniq_ambig_ab",
            "host_annotations_uniq_ambig_AB"
        ],
        "nb_inputs": 2,
        "outputs": [
            "host_files_comb_uniq_ambig_AB",
            "path_files_comb_uniq_ambig_AB"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode/${sample_name}/aux_info\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode/${sample_name}/aux_info\"",
            "tag \"extract_ambig_uniq_transcripts_genes_AB ${sample_name}\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "host_comb_ambig_uniq_alignment_based": {
        "name_process": "host_comb_ambig_uniq_alignment_based",
        "string_process": "\tprocess host_comb_ambig_uniq_alignment_based {\n\t\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t\t    tag \"host_comb_ambig_uniq_AB\"\n\n\t\t    label 'process_high'\n\n\t\t    input: \n\t\t    file(\"salmon/*\") from host_files_comb_uniq_ambig_AB.collect()\n\n\t\t    output:\n\t\t    file \"host_quant_combined_ambig_uniq.tsv\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_host_comb_ambig_uniq.R salmon/*/aux_info/*_host_quant_ambig_uniq.sf\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_host_comb_ambig_uniq.R salmon/*/aux_info/*_host_quant_ambig_uniq.sf\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_files_comb_uniq_ambig_AB"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"host_comb_ambig_uniq_AB\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "pathogen_comb_ambig_uniq_alignment_based": {
        "name_process": "pathogen_comb_ambig_uniq_alignment_based",
        "string_process": "\tprocess pathogen_comb_ambig_uniq_alignment_based {\n\t\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t\t    tag \"pathogen_comb_ambig_uniq_AB\"\n\n\t\t    label 'process_high'\n\n\t\t    input: \n\t\t    file(\"salmon/*\") from path_files_comb_uniq_ambig_AB.collect()\n\n\t\t    output:\n\t\t    file \"pathogen_quant_combined_ambig_uniq.tsv\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_pathogen_comb_ambig_uniq.R salmon/*/aux_info/*_pathogen_quant_ambig_uniq.sf\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/salmon_pathogen_comb_ambig_uniq.R salmon/*/aux_info/*_pathogen_quant_ambig_uniq.sf\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "path_files_comb_uniq_ambig_AB"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"pathogen_comb_ambig_uniq_AB\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "tximport_host_salmon_alignment": {
        "name_process": "tximport_host_salmon_alignment",
        "string_process": "\tprocess tximport_host_salmon_alignment {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\"\n\t    tag \"tximport_host\"\n\n   \t    label 'process_high'\n\n\t    input: \n\t    set val(sample_name), file(\"salmon/${sample_name}/*\") from salmon_alignment_host_tximport\n\t    file (annotations) from tximport_annotations_salmon_alignment\n\n\t    output:\n\t    file \"${sample_name}_host_quant_gene_level.sf\" into salmon_files_to_combine_gene_level_alignment\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/tximport.R salmon $annotations $sample_name\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/tximport.R salmon $annotations $sample_name\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_alignment_host_tximport",
            "tximport_annotations_salmon_alignment"
        ],
        "nb_inputs": 2,
        "outputs": [
            "salmon_files_to_combine_gene_level_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode/${sample_name}\"",
            "tag \"tximport_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_host_quant_gene_level_salmon_alignment": {
        "name_process": "combine_host_quant_gene_level_salmon_alignment",
        "string_process": "\tprocess combine_host_quant_gene_level_salmon_alignment {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t    tag \"comb_host_quant_genes_sal_alig\"\n\n\t    label 'process_high'\n\n\t    input: \n\t    file input_quantification from salmon_files_to_combine_gene_level_alignment.collect()\n\n\t    output:\n\t    file \"host_combined_gene_level.tsv\" into quant_gene_level_host_add_annotations_salmon_alignment\n\n\t    script:\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a gene_id -org host_gene_level\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 16,
        "string_script": "\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a gene_id -org host_gene_level\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_files_to_combine_gene_level_alignment"
        ],
        "nb_inputs": 1,
        "outputs": [
            "quant_gene_level_host_add_annotations_salmon_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"comb_host_quant_genes_sal_alig\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_quantification_tables_salmon_alignment_mode": {
        "name_process": "combine_quantification_tables_salmon_alignment_mode",
        "string_process": "\tprocess combine_quantification_tables_salmon_alignment_mode {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t    tag \"combine_quantification_salmon\"\n\n\t    label 'process_high'\n\n\t    input: \n\t    file input_quantification from salmon_files_to_combine_alignment_mode.collect()\n\t    val gene_attribute from host_atr_collect_data_salmon_alignment_mode\n\n\t    output:\n\t    file \"combined_quant.tsv\" into split_table_salmon_salmon_alignment\n\n\t    script:\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a $gene_attribute -org both\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q salmon -a $gene_attribute -org both\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_files_to_combine_alignment_mode",
            "host_atr_collect_data_salmon_alignment_mode"
        ],
        "nb_inputs": 2,
        "outputs": [
            "split_table_salmon_salmon_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"combine_quantification_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "split_quantification_tables_salmon_salmon_alignment_mode": {
        "name_process": "split_quantification_tables_salmon_salmon_alignment_mode",
        "string_process": "\tprocess split_quantification_tables_salmon_salmon_alignment_mode {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t    tag \"split_quantification\"\n\n\t    label 'process_high'\n\n\t    input:\n\t    file quant_table from split_table_salmon_salmon_alignment\n\t    file transcriptome_pathogen from transcriptome_pathogen_to_split_table_salmon_alignment\n\t    file transcriptome_host from transcriptome_host_to_split_table_salmon_alignment\n\n\t    output:\n\t    file 'host_quant_salmon.tsv' into host_quantification_mapping_stats_salmon_alignment_based\n\t    file 'pathogen_quant_salmon.tsv' into pathogen_quantification_mapping_stats_salmon_alignment_based\n\t    file 'host_quant_salmon.tsv' into host_quantification_RNA_stats_salmon_alignment_based\n\t    file 'pathogen_quant_salmon.tsv' into pathogen_quantification_RNA_stats_salmon_alignment_based\n\t    file 'host_quant_salmon.tsv' into quant_host_add_annotations_salmon_alignment_based\n\t    file 'pathogen_quant_salmon.tsv' into quant_pathogen_add_annotations_alignment_based\n\t    file 'host_quant_salmon.tsv' into quant_scatter_plot_host_salmon_alignment_based\n\t    file 'pathogen_quant_salmon.tsv' into quant_scatter_plot_pathogen_salmon_alignment_based\n\t    env pathonen_tab into pathonen_tab into scatterplots_pathogen_salmon_alignment_based\n\t    env host_tab into host_tab into scatterplots_host_salmon_alignment_based\n\n            script:\n            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host $quant_table \"quant_salmon.tsv\"\n            pathonen_tab=\\$(if [ \\$(cat pathogen_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            host_tab=\\$(if [ \\$(cat host_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            \"\"\"\n\t}",
        "nb_lignes_process": 28,
        "string_script": "            \"\"\"\n            $workflow.projectDir/bin/split_quant_tables_salmon.sh $transcriptome_pathogen $transcriptome_host $quant_table \"quant_salmon.tsv\"\n            pathonen_tab=\\$(if [ \\$(cat pathogen_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            host_tab=\\$(if [ \\$(cat host_quant_salmon.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_table_salmon_salmon_alignment",
            "transcriptome_pathogen_to_split_table_salmon_alignment",
            "transcriptome_host_to_split_table_salmon_alignment"
        ],
        "nb_inputs": 3,
        "outputs": [
            "host_quantification_mapping_stats_salmon_alignment_based",
            "pathogen_quantification_mapping_stats_salmon_alignment_based",
            "host_quantification_RNA_stats_salmon_alignment_based",
            "pathogen_quantification_RNA_stats_salmon_alignment_based",
            "quant_host_add_annotations_salmon_alignment_based",
            "quant_pathogen_add_annotations_alignment_based",
            "quant_scatter_plot_host_salmon_alignment_based",
            "quant_scatter_plot_pathogen_salmon_alignment_based",
            "pathonen_tab",
            "host_tab"
        ],
        "nb_outputs": 10,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "tag \"split_quantification\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_pathogen_salmon_alignment_mode": {
        "name_process": "combine_annotations_quant_pathogen_salmon_alignment_mode",
        "string_process": "\tprocess combine_annotations_quant_pathogen_salmon_alignment_mode {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t    tag \"comb_annots_quant_pathgn_salmn\"\n\t    \n\t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_pathogen_add_annotations_alignment_based\n\t    file annotation_table from annotation_pathogen_combine_quant_salmon_alignment_based\n\t    val attribute from combine_annot_quant_pathogen_salmon_alignment_based\n\n\t    output:\n\t    file \"pathogen_combined_quant_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org pathogen\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org pathogen\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_pathogen_add_annotations_alignment_based",
            "annotation_pathogen_combine_quant_salmon_alignment_based",
            "combine_annot_quant_pathogen_salmon_alignment_based"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"comb_annots_quant_pathgn_salmn\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_host_salmon_alignment_mode": {
        "name_process": "combine_annotations_quant_host_salmon_alignment_mode",
        "string_process": "\tprocess combine_annotations_quant_host_salmon_alignment_mode {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t    tag \"comb_annots_quant_host_salmn\"\n\n\t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_host_add_annotations_salmon_alignment_based\n\t    file annotation_table from annotation_host_combine_quant_salmon_alignment_based\n\t    val attribute from combine_annot_quant_host_salmon_alignment_based\n\n\t    output:\n\t    file \"host_combined_quant_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org host\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org host\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_host_add_annotations_salmon_alignment_based",
            "annotation_host_combine_quant_salmon_alignment_based",
            "combine_annot_quant_host_salmon_alignment_based"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"comb_annots_quant_host_salmn\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_gene_level_salmon_alignment_mode": {
        "name_process": "combine_annotations_quant_gene_level_salmon_alignment_mode",
        "string_process": "\tprocess combine_annotations_quant_gene_level_salmon_alignment_mode {\n\t    publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/salmon_alignment_mode\"\n\t    tag \"comb_annots_gene_host_salmn\"\n\n\t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_gene_level_host_add_annotations_salmon_alignment\n\t    file annotation_table from annotation_host_combine_quant_gene_level_salmon_alignment\n\n\t    output:\n\t    file \"host_combined_quant_gene_level_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_annotations_salmon_gene_level.py -q $quantification_table -annotations $annotation_table -a gene_id -org host\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_annotations_salmon_gene_level.py -q $quantification_table -annotations $annotation_table -a gene_id -org host\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_gene_level_host_add_annotations_salmon_alignment",
            "annotation_host_combine_quant_gene_level_salmon_alignment"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/salmon_alignment_mode\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/salmon_alignment_mode\"",
            "tag \"comb_annots_gene_host_salmn\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_processed_reads_STAR_for_salmon": {
        "name_process": "extract_processed_reads_STAR_for_salmon",
        "string_process": "\tprocess extract_processed_reads_STAR_for_salmon {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR_for_salmon/processed_reads\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR_for_salmon/processed_reads\"\n\t\t    tag \"extract_processed_reads_STAR\"\n\n\t\t    label 'process_high'\n\t\t   \n\t\t    input: \n\t\t    set val(sample_name), file (Log_final_out) from collect_processed_read_counts_STAR_for_salmon\n\n\t\t    output:\n\t\t    file \"${sample_name}.txt\" into collect_results_star_for_salmon\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh $Log_final_out $sample_name star\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh $Log_final_out $sample_name star\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_processed_read_counts_STAR_for_salmon"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collect_results_star_for_salmon"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/STAR_for_salmon/processed_reads\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR_for_salmon/processed_reads\"",
            "tag \"extract_processed_reads_STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_processed_reads_STAR_for_salmon": {
        "name_process": "collect_processed_reads_STAR_for_salmon",
        "string_process": "\tprocess collect_processed_reads_STAR_for_salmon {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR_for_salmon\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR_for_salmon\"\n\t\t    tag \"collect_processed_reads_STAR\"\n\n\t\t    label 'process_high' \n\t\t    \n\t\t    input: \n\t\t    file process_reads from collect_results_star_for_salmon.collect()\n\n\t\t    output:\n\t\t    file \"processed_reads_star.tsv\" into mapping_stats_total_processed_reads_alignment_for_salmon\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_star.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_star.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_results_star_for_salmon"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mapping_stats_total_processed_reads_alignment_for_salmon"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/STAR_for_salmon\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR_for_salmon\"",
            "tag \"collect_processed_reads_STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "scatter_plot_pathogen_salmon_alignment_based": {
        "name_process": "scatter_plot_pathogen_salmon_alignment_based",
        "string_process": "\tprocess scatter_plot_pathogen_salmon_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\"\n\t\t    tag \"scatter_plots_salmon_pathogen\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from quant_scatter_plot_pathogen_salmon_alignment_based\n\t\t    val attribute from atr_scatter_plot_pathogen_alignment\n\t\t    val replicates from repl_scatter_plots_salmon_alignment_pathogen\n\t\t    val pathogen_table_non_empty from scatterplots_pathogen_salmon_alignment_based\n\n\t\t    output:\n\t\t    file ('*.pdf')\n\n\t\t    when:\n\t\t    replicates.toBoolean()\n\t\t    pathogen_table_non_empty.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org pathogen\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org pathogen\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_scatter_plot_pathogen_salmon_alignment_based",
            "atr_scatter_plot_pathogen_alignment",
            "repl_scatter_plots_salmon_alignment_pathogen",
            "scatterplots_pathogen_salmon_alignment_based"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\"",
            "tag \"scatter_plots_salmon_pathogen\"",
            "label 'process_high'"
        ],
        "when": "replicates.toBoolean()\n\t\t    pathogen_table_non_empty.toBoolean()",
        "stub": ""
    },
    "scatter_plot_host_salmon_alignment_based": {
        "name_process": "scatter_plot_host_salmon_alignment_based",
        "string_process": "\tprocess scatter_plot_host_salmon_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\"\n\t\t    tag \"scatter_plots_salmon_host\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from quant_scatter_plot_host_salmon_alignment_based\n\t\t    val attribute from atr_scatter_plot_host_alignment\n\t\t    val replicates from repl_scatter_plots_salmon_alignment_host\n\t\t    val host_table_non_empty from scatterplots_host_salmon_alignment_based\n\n\t\t    output:\n\t\t    file ('*.pdf')\n\n\t\t    when:\n\t\t    replicates.toBoolean()\n\t\t    host_table_non_empty.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org host \n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org host \n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_scatter_plot_host_salmon_alignment_based",
            "atr_scatter_plot_host_alignment",
            "repl_scatter_plots_salmon_alignment_host",
            "scatterplots_host_salmon_alignment_based"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/scatter_plots\"",
            "tag \"scatter_plots_salmon_host\"",
            "label 'process_high'"
        ],
        "when": "replicates.toBoolean()\n\t\t    host_table_non_empty.toBoolean()",
        "stub": ""
    },
    "extract_processed_reads_salmon_alignment_based": {
        "name_process": "extract_processed_reads_salmon_alignment_based",
        "string_process": "\tprocess extract_processed_reads_salmon_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"\n\t\t    tag \"extract_processed_reads\"\n\n\t\t    label 'process_high'\n\t\t   \n\t\t    input: \n\t\t    set val(sample_name), file (\"salmon_alignment_mode/*\") from collect_processed_read_counts_alignment_based\n\n\t\t    output:\n\t\t    file \"${sample_name}.txt\" into collect_results_alignment_based\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh salmon_alignment_mode/*/aux_info/meta_info.json $sample_name salmon_alignment\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh salmon_alignment_mode/*/aux_info/meta_info.json $sample_name salmon_alignment\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_processed_read_counts_alignment_based"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collect_results_alignment_based"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"",
            "tag \"extract_processed_reads\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_processed_reads_salmon_alignment_based": {
        "name_process": "collect_processed_reads_salmon_alignment_based",
        "string_process": "\tprocess collect_processed_reads_salmon_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"\n\t\t    tag \"collect_processed_reads\"\n\n\t\t    label 'process_high' \n\t\t    \n\t\t    input: \n\t\t    file process_reads from collect_results_alignment_based.collect()\n\n\t\t    output:\n\t\t    file \"processed_reads_salmon_alignment.tsv\" into mapping_stats_total_reads_alignment\n\t\t    script:\n\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_salmon_alignment.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 15,
        "string_script": "\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_salmon_alignment.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_results_alignment_based"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mapping_stats_total_reads_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"",
            "tag \"collect_processed_reads\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "salmon_quantification_stats_salmon_alignment_based": {
        "name_process": "salmon_quantification_stats_salmon_alignment_based",
        "string_process": "\tprocess salmon_quantification_stats_salmon_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"\n\t\t    tag \"quantification_stats_salmon\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table_host from host_quantification_mapping_stats_salmon_alignment_based\n\t\t    file quant_table_pathogen from pathogen_quantification_mapping_stats_salmon_alignment_based\n\t\t    val attribute from attribute_quant_stats_salmon_alignment\n\t\t    file total_processed_reads from mapping_stats_total_reads_alignment\n\t\t    file total_processed_reads_star from mapping_stats_total_processed_reads_alignment_for_salmon\n\t\t    file total_raw_reads from collect_total_reads_raw_salmon_alignment.ifEmpty('.')\n\n\t\t    output:\n\t\t    file ('salmon_alignment_host_pathogen_total_reads.tsv') into salmon_mapped_stats_to_plot_alignment\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -q_p $quant_table_pathogen -q_h $quant_table_host -total_processed $total_processed_reads -total_raw $total_raw_reads -a $attribute --star_processed $total_processed_reads_star -t salmon_alignment -o salmon_alignment_host_pathogen_total_reads.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 21,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -q_p $quant_table_pathogen -q_h $quant_table_host -total_processed $total_processed_reads -total_raw $total_raw_reads -a $attribute --star_processed $total_processed_reads_star -t salmon_alignment -o salmon_alignment_host_pathogen_total_reads.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_quantification_mapping_stats_salmon_alignment_based",
            "pathogen_quantification_mapping_stats_salmon_alignment_based",
            "attribute_quant_stats_salmon_alignment",
            "mapping_stats_total_reads_alignment",
            "mapping_stats_total_processed_reads_alignment_for_salmon",
            "collect_total_reads_raw_salmon_alignment"
        ],
        "nb_inputs": 6,
        "outputs": [
            "salmon_mapped_stats_to_plot_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"",
            "tag \"quantification_stats_salmon\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_salmon_mapping_stats_host_pathogen_salmon_alignment_based": {
        "name_process": "plot_salmon_mapping_stats_host_pathogen_salmon_alignment_based",
        "string_process": "\tprocess plot_salmon_mapping_stats_host_pathogen_salmon_alignment_based {\n\t\t    tag \"$name2\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(stats) from salmon_mapped_stats_to_plot_alignment\n\n\t\t    output:\n\t\t    file \"*.tsv\"\n\t\t    file \"*.pdf\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_statistics_salmon_alignment.py -i $stats\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 17,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_statistics_salmon_alignment.py -i $stats\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "salmon_mapped_stats_to_plot_alignment"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$name2\"",
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "RNA_class_statistics_salmon_pathogen_alignment_based": {
        "name_process": "RNA_class_statistics_salmon_pathogen_alignment_based",
        "string_process": "\tprocess RNA_class_statistics_salmon_pathogen_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    tag \"rna_class_stats_pathogen\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from pathogen_quantification_RNA_stats_salmon_alignment_based\n\t\t    val attribute from host_annotations_RNA_class_stats_pathogen_alignment\n\t\t    file gene_annotations from pathogen_annotations_RNA_class_stats_salmon_alignment\n\n\t\t    output:\n\t\t    file \"pathogen_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_pathogen_alignment\n\t\t    file \"pathogen_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_pathogen_combined_alignment\n\t\t    file \"pathogen_RNA_classes_sum_counts_*.tsv\"\n\t\t    stdout plot_RNA_stats_pathogen_alignment_boolean\n\t\t    stdout plot_RNA_stats_pathogen_combined_alignment_boolean\n\n\t\t    shell:\n\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -q_tool salmon -org pathogen 2>&1\n\t\t    '''\n\t\t}",
        "nb_lignes_process": 21,
        "string_script": "\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -q_tool salmon -org pathogen 2>&1\n\t\t    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pathogen_quantification_RNA_stats_salmon_alignment_based",
            "host_annotations_RNA_class_stats_pathogen_alignment",
            "pathogen_annotations_RNA_class_stats_salmon_alignment"
        ],
        "nb_inputs": 3,
        "outputs": [
            "plot_RNA_stats_pathogen_alignment",
            "plot_RNA_stats_pathogen_combined_alignment",
            "plot_RNA_stats_pathogen_alignment_boolean",
            "plot_RNA_stats_pathogen_combined_alignment_boolean"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "tag \"rna_class_stats_pathogen\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "RNA_class_statistics_salmon_host_alignment_based": {
        "name_process": "RNA_class_statistics_salmon_host_alignment_based",
        "string_process": "\tprocess RNA_class_statistics_salmon_host_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    tag \"rna_class_stats_host\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from host_quantification_RNA_stats_salmon_alignment_based\n\t\t    val attribute from attribute_host_RNA_class_stats_alignment\n\t\t    file gene_annotations from host_annotations_RNA_class_stats_salmon_alignment\n\t\t    file rna_classes_to_replace from RNA_classes_to_replace_alignment\n\n\t\t    output:\n\t\t    file \"host_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_host_alignment\n\t\t    file \"host_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_host_combined_alignment\n\t\t    file \"host_RNA_classes_sum_counts_*.tsv\"\n\t\t    file \"host_gene_types_groups_*\"\n\t\t    stdout plot_RNA_stats_host_alignment_boolean\n\t\t    stdout plot_RNA_stats_host_combined_alignment_boolean\n\n\t\t    shell:\n\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -rna !{rna_classes_to_replace} -q_tool salmon -org host 2>&1\n\t\t    '''\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -rna !{rna_classes_to_replace} -q_tool salmon -org host 2>&1\n\t\t    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_quantification_RNA_stats_salmon_alignment_based",
            "attribute_host_RNA_class_stats_alignment",
            "host_annotations_RNA_class_stats_salmon_alignment",
            "RNA_classes_to_replace_alignment"
        ],
        "nb_inputs": 4,
        "outputs": [
            "plot_RNA_stats_host_alignment",
            "plot_RNA_stats_host_combined_alignment",
            "plot_RNA_stats_host_alignment_boolean",
            "plot_RNA_stats_host_combined_alignment_boolean"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\", mode: params.publish_dir_mode",
            "tag \"rna_class_stats_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_RNA_class_salmon_pathogen_each_alignment_based": {
        "name_process": "plot_RNA_class_salmon_pathogen_each_alignment_based",
        "string_process": "\tprocess plot_RNA_class_salmon_pathogen_each_alignment_based{\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\"\n\t\t    tag \"plot_rna_class_stats_path_sal\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_pathogen_alignment\n\t\t    val plot_rna from plot_RNA_stats_pathogen_alignment_boolean\n\n\t\t    output:\n\t\t    file \"*.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_pathogen_alignment",
            "plot_RNA_stats_pathogen_alignment_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\"",
            "tag \"plot_rna_class_stats_path_sal\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_salmon_host_each_alignment_based": {
        "name_process": "plot_RNA_class_salmon_host_each_alignment_based",
        "string_process": "\tprocess plot_RNA_class_salmon_host_each_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\"\n\t\t    tag \"plot_rna_class_stats_host_sal\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_host_alignment\n\t\t    val plot_rna from plot_RNA_stats_host_alignment_boolean\n\n\t\t    output:\n\t\t    file \"*.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_host_alignment",
            "plot_RNA_stats_host_alignment_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\"",
            "tag \"plot_rna_class_stats_host_sal\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_salmon_pathogen_combined_alignment_based": {
        "name_process": "plot_RNA_class_salmon_pathogen_combined_alignment_based",
        "string_process": "\tprocess plot_RNA_class_salmon_pathogen_combined_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\"\n\t\t    tag \"plot_rna_class_stats_path_all\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_pathogen_combined_alignment\n\t\t    val plot_rna from plot_RNA_stats_pathogen_combined_alignment_boolean\n\n\t\t    output:\n\t\t    file \"RNA_class_stats_combined_pathogen.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org pathogen\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org pathogen\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_pathogen_combined_alignment",
            "plot_RNA_stats_pathogen_combined_alignment_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_pathogen\"",
            "tag \"plot_rna_class_stats_path_all\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_salmon_host_combined_alignment_based": {
        "name_process": "plot_RNA_class_salmon_host_combined_alignment_based",
        "string_process": "\tprocess plot_RNA_class_salmon_host_combined_alignment_based {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\"\n\t\t    tag \"plot_rna_class_stats_host_all\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_host_combined_alignment\n\t\t    val plot_rna from plot_RNA_stats_host_combined_alignment_boolean\n\n\t\t    output:\n\t\t    file \"RNA_class_stats_combined_host.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org host\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org host\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_host_combined_alignment",
            "plot_RNA_stats_host_combined_alignment_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/salmon_alignment_based/RNA_classes_host\"",
            "tag \"plot_rna_class_stats_host_all\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "STARindex": {
        "name_process": "STARindex",
        "string_process": "\tprocess STARindex {\n      publishDir \"${params.outdir}/STAR\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/STAR\" \n\t    tag \"build_star_index\"\n\n \n\t    label 'process_high'\n\n\t    input:\n\t    file(fasta) from host_pathogen_fasta_star_index\n\t    file(gff) from gff_host_star_alignment_gff\n\n\t    output:\n      file \"index/*\" into star_index_genome_alignment\n\n\t    script:\n\t    sjdbOverhang = params.sjdbOverhang\n\t    star_index_params = params.star_index_params\n\t    \"\"\"\n\t    mkdir index\n\t    STAR --runThreadN ${task.cpus} --runMode genomeGenerate --genomeDir index/ --genomeFastaFiles $fasta --sjdbGTFfile $gff --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --sjdbOverhang $sjdbOverhang $star_index_params\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 21,
        "string_script": "\t    sjdbOverhang = params.sjdbOverhang\n\t    star_index_params = params.star_index_params\n\t    \"\"\"\n\t    mkdir index\n\t    STAR --runThreadN ${task.cpus} --runMode genomeGenerate --genomeDir index/ --genomeFastaFiles $fasta --sjdbGTFfile $gff --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --sjdbOverhang $sjdbOverhang $star_index_params\n\t    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_pathogen_fasta_star_index",
            "gff_host_star_alignment_gff"
        ],
        "nb_inputs": 2,
        "outputs": [
            "star_index_genome_alignment"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/STAR\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/STAR\"",
            "tag \"build_star_index\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "ALIGNMENTstar": {
        "name_process": "ALIGNMENTstar",
        "string_process": "\tprocess ALIGNMENTstar {\n\t    tag \"${sample_name}\"\n      publishDir \"${params.outdir}/STAR\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/STAR\" \n\n      label 'process_high'\n\t\n\t    input:\n\t    set val(sample_name),file(reads) from  trimming_results_star_htseq\n\t    file(gff) from gff_host_star_htseq_alignment_gff.collect()\n\t    file(index) from star_index_genome_alignment.collect()\n\n\t    output:\n\t    set val(sample_name), file(\"${sample_name}/${sample_name}Aligned*.out.bam\") into star_aligned_u_m\n\t    set val(sample_name), file(\"${sample_name}/${sample_name}Aligned*.out.bam\") into alignment_unique_mapping_stats\n\t    set val(sample_name), file(\"${sample_name}/${sample_name}Aligned*.out.bam\") into alignment_crossmapped_extract\n\t    file \"${sample_name}/*\" into multiqc_star_alignment\n\t    set val(sample_name), file(\"${sample_name}/${sample_name}Log.final.out\") into collect_processed_read_counts_STAR\n\n\t    script:\n\t    outSAMunmapped = params.outSAMunmapped\n\t    outSAMattributes = params.outSAMattributes\n\t    outFilterMultimapNmax = params.outFilterMultimapNmax\n\t    outFilterType = params.outFilterType\n\t    alignSJoverhangMin = params.alignSJoverhangMin\n\t    alignSJDBoverhangMin = params.alignSJDBoverhangMin\n\t    outFilterMismatchNmax = params.outFilterMismatchNmax\n\t    outFilterMismatchNoverReadLmax = params.outFilterMismatchNoverReadLmax\n\t    alignIntronMin = params.alignIntronMin\n\t    alignIntronMax = params.alignIntronMax\n\t    alignMatesGapMax = params.alignMatesGapMax\n\t    outWigType = params.outWigType\n\t    outWigStrand = params.outWigStrand\n\t    limitBAMsortRAM = params.limitBAMsortRAM\n\t    readFilesCommand = reads[0].toString().endsWith('.gz') ? \"--readFilesCommand zcat\" : ''\n\t    winAnchorMultimapNmax = params.winAnchorMultimapNmax\n\t    star_alignment_params = params.star_alignment_params\n\n\t    if (params.single_end){\n\t    \"\"\"\n\t    \tmkdir $sample_name\n\t    \tSTAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn $reads --outSAMtype BAM SortedByCoordinate --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outWigType $outWigType --outWigStrand $outWigStrand --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_alignment_params\n\t    \"\"\"\n\t    } else {\n\t    \"\"\"\n\t    mkdir $sample_name\n\t    STAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn ${reads[0]} ${reads[1]} --outSAMtype BAM SortedByCoordinate --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outWigType $outWigType --outWigStrand $outWigStrand --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_alignment_params\n\t    \"\"\"\n\t    }\n\t}",
        "nb_lignes_process": 48,
        "string_script": "\t    outSAMunmapped = params.outSAMunmapped\n\t    outSAMattributes = params.outSAMattributes\n\t    outFilterMultimapNmax = params.outFilterMultimapNmax\n\t    outFilterType = params.outFilterType\n\t    alignSJoverhangMin = params.alignSJoverhangMin\n\t    alignSJDBoverhangMin = params.alignSJDBoverhangMin\n\t    outFilterMismatchNmax = params.outFilterMismatchNmax\n\t    outFilterMismatchNoverReadLmax = params.outFilterMismatchNoverReadLmax\n\t    alignIntronMin = params.alignIntronMin\n\t    alignIntronMax = params.alignIntronMax\n\t    alignMatesGapMax = params.alignMatesGapMax\n\t    outWigType = params.outWigType\n\t    outWigStrand = params.outWigStrand\n\t    limitBAMsortRAM = params.limitBAMsortRAM\n\t    readFilesCommand = reads[0].toString().endsWith('.gz') ? \"--readFilesCommand zcat\" : ''\n\t    winAnchorMultimapNmax = params.winAnchorMultimapNmax\n\t    star_alignment_params = params.star_alignment_params\n\n\t    if (params.single_end){\n\t    \"\"\"\n\t    \tmkdir $sample_name\n\t    \tSTAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn $reads --outSAMtype BAM SortedByCoordinate --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outWigType $outWigType --outWigStrand $outWigStrand --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_alignment_params\n\t    \"\"\"\n\t    } else {\n\t    \"\"\"\n\t    mkdir $sample_name\n\t    STAR --runThreadN ${task.cpus} --genomeDir . --sjdbGTFfile $gff $readFilesCommand --readFilesIn ${reads[0]} ${reads[1]} --outSAMtype BAM SortedByCoordinate --outSAMunmapped $outSAMunmapped --outSAMattributes $outSAMattributes --outWigType $outWigType --outWigStrand $outWigStrand --outFileNamePrefix $sample_name/$sample_name --sjdbGTFfeatureExon exon --sjdbGTFtagExonParentTranscript Parent --outFilterMultimapNmax $outFilterMultimapNmax --outFilterType $outFilterType --limitBAMsortRAM $limitBAMsortRAM --alignSJoverhangMin $alignSJoverhangMin --alignSJDBoverhangMin $alignSJDBoverhangMin --outFilterMismatchNmax $outFilterMismatchNmax --outFilterMismatchNoverReadLmax $outFilterMismatchNoverReadLmax --alignIntronMin $alignIntronMin --alignIntronMax $alignIntronMax --alignMatesGapMax $alignMatesGapMax --winAnchorMultimapNmax $winAnchorMultimapNmax $star_alignment_params\n\t    \"\"\"\n\t    }",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimming_results_star_htseq",
            "gff_host_star_htseq_alignment_gff",
            "star_index_genome_alignment"
        ],
        "nb_inputs": 3,
        "outputs": [
            "star_aligned_u_m",
            "alignment_unique_mapping_stats",
            "alignment_crossmapped_extract",
            "multiqc_star_alignment",
            "collect_processed_read_counts_STAR"
        ],
        "nb_outputs": 5,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"${sample_name}\"",
            "publishDir \"${params.outdir}/STAR\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "remove_crossmapped_reads": {
        "name_process": "remove_crossmapped_reads",
        "string_process": "\tprocess remove_crossmapped_reads {\n\t\t    tag \"$sample_name\"\n\t\t    publishDir \"${params.outdir}/STAR/multimapped_reads\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/STAR/multimapped_reads\"\n\n                    label 'process_high'\n\n\t\t    input:\n\t\t    set val(sample_name), file(alignment) from alignment_crossmapped_extract\n\t\t    file(host_reference) from reference_host_names_crossmapped_find.collect()\n\t\t    file(pathogen_reference) from reference_pathogen_crossmapped_find.collect()\n\n\n\t\t    output:\n\t\t    set val(sample_name), file(\"${bam_file_without_crossmapped}\") into alignment_multi_mapping_stats\n\t\t    file \"${cross_mapped_reads}\" into count_crossmapped_reads\n\n\t\t    script:\n\t\t    bam_file_without_crossmapped = sample_name + \"_no_crossmapped.bam\"\n\t\t    cross_mapped_reads = sample_name + \"_cross_mapped_reads.txt\"\n\t\t    \n\t\t    if (params.single_end){\n\t\t    \t\"\"\"\n\t\t    \t$workflow.projectDir/bin/remove_crossmapped_reads_BAM.sh $alignment $workflow.projectDir/bin $host_reference $pathogen_reference $cross_mapped_reads $bam_file_without_crossmapped\n\t\t    \t\"\"\"\n\t\t    } else {\n\t\t    \t\"\"\"\n\t\t    \t$workflow.projectDir/bin/remove_crossmapped_read_pairs_BAM.sh $alignment $workflow.projectDir/bin $host_reference $pathogen_reference $cross_mapped_reads $bam_file_without_crossmapped\n\t\t    \t\"\"\"\n\t\t    }\n\t\t}",
        "nb_lignes_process": 29,
        "string_script": "\t\t    bam_file_without_crossmapped = sample_name + \"_no_crossmapped.bam\"\n\t\t    cross_mapped_reads = sample_name + \"_cross_mapped_reads.txt\"\n\t\t    \n\t\t    if (params.single_end){\n\t\t    \t\"\"\"\n\t\t    \t$workflow.projectDir/bin/remove_crossmapped_reads_BAM.sh $alignment $workflow.projectDir/bin $host_reference $pathogen_reference $cross_mapped_reads $bam_file_without_crossmapped\n\t\t    \t\"\"\"\n\t\t    } else {\n\t\t    \t\"\"\"\n\t\t    \t$workflow.projectDir/bin/remove_crossmapped_read_pairs_BAM.sh $alignment $workflow.projectDir/bin $host_reference $pathogen_reference $cross_mapped_reads $bam_file_without_crossmapped\n\t\t    \t\"\"\"\n\t\t    }",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alignment_crossmapped_extract",
            "reference_host_names_crossmapped_find",
            "reference_pathogen_crossmapped_find"
        ],
        "nb_inputs": 3,
        "outputs": [
            "alignment_multi_mapping_stats",
            "count_crossmapped_reads"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/STAR/multimapped_reads\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/STAR/multimapped_reads\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_processed_reads_STAR": {
        "name_process": "extract_processed_reads_STAR",
        "string_process": "\tprocess extract_processed_reads_STAR {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR/processed_reads\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR/processed_reads\"\n\t\t    tag \"extract_processed_reads_STAR\"\n\n\t   \t    label 'process_high'\n\t\t   \n\t\t    input: \n\t\t    set val(sample_name), file (Log_final_out) from collect_processed_read_counts_STAR\n\n\t\t    output:\n\t\t    file \"${sample_name}.txt\" into collect_results_star\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh $Log_final_out $sample_name star\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/extract_processed_reads.sh $Log_final_out $sample_name star\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_processed_read_counts_STAR"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collect_results_star"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/STAR/processed_reads\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR/processed_reads\"",
            "tag \"extract_processed_reads_STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_processed_reads_STAR": {
        "name_process": "collect_processed_reads_STAR",
        "string_process": "\tprocess collect_processed_reads_STAR {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR\"\n\t\t    tag \"collect_processed_reads_STAR\"\n\n\t\t    label 'process_high' \n\t\t    \n\t\t    input: \n\t\t    file process_reads from collect_results_star.collect()\n\n\t\t    output:\n\t\t    file \"processed_reads_star.tsv\" into mapping_stats_total_processed_reads_alignment\n\t\t    file \"processed_reads_star.tsv\" into mapping_stats_htseq_total_processed_reads_alignment\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_star.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 17,
        "string_script": "\t\t    \"\"\"\n\t\t    cat $process_reads > processed_reads_star.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_results_star"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mapping_stats_total_processed_reads_alignment",
            "mapping_stats_htseq_total_processed_reads_alignment"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR\"",
            "tag \"collect_processed_reads_STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "unique_mapping_stats_STAR": {
        "name_process": "unique_mapping_stats_STAR",
        "string_process": "\tprocess unique_mapping_stats_STAR {\n\t\t    tag \"$sample_name\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR/uniquely_mapped\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR/uniquely_mapped\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    set val(sample_name), file(alignment) from alignment_unique_mapping_stats\n\t\t    file(host_reference_names) from reference_host_names_uniquelymapped.collect()\n\t\t    file(pathogen_reference_names) from reference_pathogen_names_uniquelymapped.collect()\n\n\t\t    output:\n\t\t    file(\"${name}\") into STAR_mapping_stats_unique\n\t\t   \n\t\t    shell: \n\t\t    name = sample_name + '_uniquely_mapped.txt'\n\t\t    if (params.single_end){\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_uniquely_mapped_reads.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    } else {\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_uniquely_mapped_read_pairs.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    }\n\t\t}",
        "nb_lignes_process": 25,
        "string_script": "\t\t    name = sample_name + '_uniquely_mapped.txt'\n\t\t    if (params.single_end){\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_uniquely_mapped_reads.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    } else {\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_uniquely_mapped_read_pairs.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    }",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alignment_unique_mapping_stats",
            "reference_host_names_uniquelymapped",
            "reference_pathogen_names_uniquelymapped"
        ],
        "nb_inputs": 3,
        "outputs": [
            "STAR_mapping_stats_unique"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/mapping_statistics/STAR/uniquely_mapped\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR/uniquely_mapped\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_stats_STAR_uniquely_mapped": {
        "name_process": "collect_stats_STAR_uniquely_mapped",
        "string_process": "\tprocess collect_stats_STAR_uniquely_mapped {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR\"\n\t\t    tag \"collect_uniq_mapped_reads_STAR\"\n\n\t\t    label 'process_high' \n\t\t    \n\t\t    input: \n\t\t    file stats from STAR_mapping_stats_unique.collect()\n\n\t\t    output:\n\t\t    file \"uniquely_mapped_reads_star.tsv\" into mapping_stats_uniquely_mapped_star\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/combine_tables.py -i $stats -o uniquely_mapped_reads_star.tsv -s uniquely_mapped_reads\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/combine_tables.py -i $stats -o uniquely_mapped_reads_star.tsv -s uniquely_mapped_reads\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "STAR_mapping_stats_unique"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mapping_stats_uniquely_mapped_star"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR\"",
            "tag \"collect_uniq_mapped_reads_STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "count_crossmapped_reads": {
        "name_process": "count_crossmapped_reads",
        "string_process": "\tprocess count_crossmapped_reads {\n\t\t    tag \"count_crossmapped_reads\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(cross_mapped_reads) from count_crossmapped_reads.collect()\n\n\t\t    output:\n                    file \"cross_mapped_reads_sum.txt\" into STAR_mapping_stats_cross_mapped\n\t\t    \n\t\t    script:\n\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/count_cross_mapped_reads.sh $cross_mapped_reads\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t    \"\"\"\n\t\t    $workflow.projectDir/bin/count_cross_mapped_reads.sh $cross_mapped_reads\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "count_crossmapped_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "STAR_mapping_stats_cross_mapped"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"count_crossmapped_reads\"",
            "publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "multi_mapping_stats": {
        "name_process": "multi_mapping_stats",
        "string_process": "\tprocess multi_mapping_stats {\n\t\t    tag \"$sample_name\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR/multi_mapped\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR/multi_mapped\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    set val(sample_name),file(alignment) from alignment_multi_mapping_stats\n\t\t    file(host_reference_names) from reference_host_names_multimapped.collect()\n\t\t    file(pathogen_reference_names) from reference_pathogen_names_multimapped.collect()\n\n\t\t    output:\n\t\t    file(\"${name}\") into STAR_mapping_stats_multi\n\n\t\t    shell: \n\t\t    name = sample_name + '_multi_mapped.txt'\n\t\t    if (params.single_end){\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_multi_mapped_reads.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    } else {\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_multi_mapped_read_pairs.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    }\n\t\t}",
        "nb_lignes_process": 25,
        "string_script": "\t\t    name = sample_name + '_multi_mapped.txt'\n\t\t    if (params.single_end){\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_multi_mapped_reads.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    } else {\n\t\t    '''\n\t\t    !{workflow.projectDir}/bin/count_multi_mapped_read_pairs.sh !{alignment} !{host_reference_names} !{pathogen_reference_names} !{sample_name} !{name}\n\t\t    '''\n\t\t    }",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alignment_multi_mapping_stats",
            "reference_host_names_multimapped",
            "reference_pathogen_names_multimapped"
        ],
        "nb_inputs": 3,
        "outputs": [
            "STAR_mapping_stats_multi"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/mapping_statistics/STAR/multi_mapped\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR/multi_mapped\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "collect_stats_STAR_multi_mapped": {
        "name_process": "collect_stats_STAR_multi_mapped",
        "string_process": "\tprocess collect_stats_STAR_multi_mapped {\n\t\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode\n\t\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR\"\n\t\t\t    tag \"collect_multi_mapped_reads_STAR\"\n\n\t\t\t    label 'process_high' \n\t\t\t    \n\t\t\t    input: \n\t\t\t    file stats from STAR_mapping_stats_multi.collect()\n\n\t\t\t    output:\n\t\t\t    file \"multi_mapped_reads_star.tsv\" into mapping_stats_multi_mapped_star\n\n\t\t\t    script:\n\t\t\t    \"\"\"\n\t\t\t    python $workflow.projectDir/bin/combine_tables.py -i $stats -o multi_mapped_reads_star.tsv -s multi_mapped_reads\n\t\t\t    \"\"\"\n\t\t\t}",
        "nb_lignes_process": 16,
        "string_script": "\t\t\t    \"\"\"\n\t\t\t    python $workflow.projectDir/bin/combine_tables.py -i $stats -o multi_mapped_reads_star.tsv -s multi_mapped_reads\n\t\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "STAR_mapping_stats_multi"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mapping_stats_multi_mapped_star"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR\"",
            "tag \"collect_multi_mapped_reads_STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "star_mapping_stats": {
        "name_process": "star_mapping_stats",
        "string_process": "\tprocess star_mapping_stats {\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode\n\t\t    tag \"star_mapping_stats\"\n\n\t\t    label 'process_high' \n\n\t\t    input:\n\t\t    file total_raw_reads from collect_total_reads_raw_star.ifEmpty('.')\n\t\t    file total_processed_reads from mapping_stats_total_processed_reads_alignment\n\t\t    file uniquely_mapped_reads from mapping_stats_uniquely_mapped_star\n\t\t    file multi_mapped_reads from mapping_stats_multi_mapped_star\n\t\t    file cross_mapped_reads from STAR_mapping_stats_cross_mapped\n\n\t\t    output:\n\t\t    file ('star_mapping_stats.tsv') into star_mapped_stats_to_plot\n\t\t    file ('star_mapping_stats.tsv') into mapping_stats_star_htseq_stats\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -total_raw $total_raw_reads -total_processed $total_processed_reads -m_u $uniquely_mapped_reads -m_m $multi_mapped_reads -c_m $cross_mapped_reads -t star -o star_mapping_stats.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 21,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -total_raw $total_raw_reads -total_processed $total_processed_reads -m_u $uniquely_mapped_reads -m_m $multi_mapped_reads -c_m $cross_mapped_reads -t star -o star_mapping_stats.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collect_total_reads_raw_star",
            "mapping_stats_total_processed_reads_alignment",
            "mapping_stats_uniquely_mapped_star",
            "mapping_stats_multi_mapped_star",
            "STAR_mapping_stats_cross_mapped"
        ],
        "nb_inputs": 5,
        "outputs": [
            "star_mapped_stats_to_plot",
            "mapping_stats_star_htseq_stats"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "storeDir \"${params.outdir}/mapping_statistics/STAR\"",
            "publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode",
            "tag \"star_mapping_stats\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_star_mapping_stats": {
        "name_process": "plot_star_mapping_stats",
        "string_process": "\tprocess plot_star_mapping_stats {\n\t\t    tag \"plot_star_mapping_stats\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/STAR\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(stats) from star_mapped_stats_to_plot\n\n\t\t    output:\n\t\t    file \"*.tsv\"\n\t\t    file \"*.pdf\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_stats_star.py -i $stats\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 17,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_stats_star.py -i $stats\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "star_mapped_stats_to_plot"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"plot_star_mapping_stats\"",
            "publishDir \"${params.outdir}/mapping_statistics/STAR\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/STAR\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "HTseq_unique_mapping": {
        "name_process": "HTseq_unique_mapping",
        "string_process": "\tprocess HTseq_unique_mapping {\n\t    publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/HTSeq\"\n\t    tag \"$sample_name\"\n\n            label 'process_high'\n\n\t    input:\n\t    file(gff) from quantification_gff_u_m.collect()\n\t    set val(sample_name), file(st) from star_aligned_u_m\n\t    val(host_attribute) from host_gff_attribute_htseq\n\t    val(stranded) from stranded_htseq_unique\n\n\n\t    output:\n\t    file (\"$name_file2\") into htseq_files_to_combine\n\t    file (\"$name_file2\") into multiqc_htseq_unique\n\n\t    script:\n\t    name_file2 = sample_name + \"_count_u_m.txt\"\n\t    host_attr = host_attribute\n\t    max_reads_in_buffer = params.max_reads_in_buffer\n\t    minaqual = params.minaqual\n\t    htseq_params = params.htseq_params\n\t    \"\"\"\n\t    htseq-count -n $task.cpus -t quant -f bam -r pos $st $gff -i $host_attr -s $stranded --max-reads-in-buffer=$max_reads_in_buffer -a $minaqual $htseq_params > $name_file2\n\t    sed -i '1{h;s/.*/'\"$sample_name\"'/;G}' \"$name_file2\"\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 27,
        "string_script": "\t    name_file2 = sample_name + \"_count_u_m.txt\"\n\t    host_attr = host_attribute\n\t    max_reads_in_buffer = params.max_reads_in_buffer\n\t    minaqual = params.minaqual\n\t    htseq_params = params.htseq_params\n\t    \"\"\"\n\t    htseq-count -n $task.cpus -t quant -f bam -r pos $st $gff -i $host_attr -s $stranded --max-reads-in-buffer=$max_reads_in_buffer -a $minaqual $htseq_params > $name_file2\n\t    sed -i '1{h;s/.*/'\"$sample_name\"'/;G}' \"$name_file2\"\n\t    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quantification_gff_u_m",
            "star_aligned_u_m",
            "host_gff_attribute_htseq",
            "stranded_htseq_unique"
        ],
        "nb_inputs": 4,
        "outputs": [
            "htseq_files_to_combine",
            "multiqc_htseq_unique"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/HTSeq\"",
            "tag \"$sample_name\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_quantification_tables_htseq_uniquely_mapped": {
        "name_process": "combine_quantification_tables_htseq_uniquely_mapped",
        "string_process": "\tprocess combine_quantification_tables_htseq_uniquely_mapped {\n\t    publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/HTSeq\"\n\t    tag \"comb_quants_htseq_uniq_mapped\"\n\n            label 'process_high'\n\n\t    input: \n\t    file input_quantification from htseq_result_quantification\n\t    val(host_attribute) from host_gff_attribute_htseq_combine\n\n\t    output:\n\t    file \"quantification_results_*.tsv\" into htseq_result_quantification_TPM\n\n\t    script:\n\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q htseq -a $host_attribute \n\t    \"\"\"\n\t}",
        "nb_lignes_process": 17,
        "string_script": "\t    \"\"\"\n\t    python $workflow.projectDir/bin/collect_quantification_data.py -i $input_quantification -q htseq -a $host_attribute \n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "htseq_result_quantification",
            "host_gff_attribute_htseq_combine"
        ],
        "nb_inputs": 2,
        "outputs": [
            "htseq_result_quantification_TPM"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/HTSeq\"",
            "tag \"comb_quants_htseq_uniq_mapped\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "htseq_uniquely_mapped_TPM": {
        "name_process": "htseq_uniquely_mapped_TPM",
        "string_process": "\tprocess htseq_uniquely_mapped_TPM {\n\t    publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/HTSeq\"\n\t    tag \"htseq_uniquely_mapped_TPM\"\n\n            label 'process_high'\n\n\t    input: \n\t    file input_quantification from htseq_result_quantification_TPM\n\t    val(host_attribute) from host_gff_attribute_htseq_TPM\n\t    file gff_host from gff_host_to_TPM\n\t    file gff_pathogen from gff_pathogen_to_TPM\n\n\t    output:\n\t    file \"quantification_results_uniquely_mapped_NumReads_TPM.tsv\" into split_table_htseq_host\n\t    file \"quantification_results_uniquely_mapped_NumReads_TPM.tsv\" into split_table_htseq_pathogen\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/calculate_TPM_HTSeq.R $input_quantification $host_attribute $gff_pathogen $gff_host\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 20,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/calculate_TPM_HTSeq.R $input_quantification $host_attribute $gff_pathogen $gff_host\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "htseq_result_quantification_TPM",
            "host_gff_attribute_htseq_TPM",
            "gff_host_to_TPM",
            "gff_pathogen_to_TPM"
        ],
        "nb_inputs": 4,
        "outputs": [
            "split_table_htseq_host",
            "split_table_htseq_pathogen"
        ],
        "nb_outputs": 2,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/HTSeq\"",
            "tag \"htseq_uniquely_mapped_TPM\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "split_quantification_tables_htseq_uniquely_mapped": {
        "name_process": "split_quantification_tables_htseq_uniquely_mapped",
        "string_process": "\tprocess split_quantification_tables_htseq_uniquely_mapped {\n\t    publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode\n\t    tag \"split_quants_uniq_mapped_host\"\n\n            label 'process_high'\n\n\t    input:\n\t    file quant_table from split_table_htseq_host\n\t    file host_annotations from annotation_host_split_quant_htseq\n\t    file pathogen_annotations from annotation_pathogen_split_quant_htseq\n\n\t    output:\n\t    file 'host_quantification_uniquely_mapped_htseq.tsv' into host_quantification_stats_htseq\n\t    file 'host_quantification_uniquely_mapped_htseq.tsv' into host_quantification_stats_htseq_total\n\t    file 'host_quantification_uniquely_mapped_htseq.tsv' into host_htseq_quantification_RNA_stats\n\t    file 'host_quantification_uniquely_mapped_htseq.tsv' into quant_host_add_annotations_htseq_u_m\n\t    file 'host_quantification_uniquely_mapped_htseq.tsv' into quant_scatter_plot_host_htseq_u_m\n\t    file 'pathogen_quantification_uniquely_mapped_htseq.tsv' into pathogen_quantification_stats_htseq\n\t    file 'pathogen_quantification_uniquely_mapped_htseq.tsv' into pathogen_quantification_stats_htseq_total\n\t    file 'pathogen_quantification_uniquely_mapped_htseq.tsv' into pathogen_htseq_quantification_RNA_stats\n\t    file 'pathogen_quantification_uniquely_mapped_htseq.tsv' into quant_pathogen_add_annotations_htseq_u_m\n\t    file 'pathogen_quantification_uniquely_mapped_htseq.tsv' into quant_scatter_plot_pathogen_htseq_u_m\n\t    env pathonen_tab into pathonen_tab into scatterplots_pathogen_htseq\n\t    env host_tab into host_tab into scatterplots_host_htseq\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/split_quant_tables.sh $quant_table $host_annotations $pathogen_annotations quantification_uniquely_mapped_htseq.tsv\n            pathonen_tab=\\$(if [ \\$(cat pathogen_quantification_uniquely_mapped_htseq.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            host_tab=\\$(if [ \\$(cat host_quantification_uniquely_mapped_htseq.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 30,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/split_quant_tables.sh $quant_table $host_annotations $pathogen_annotations quantification_uniquely_mapped_htseq.tsv\n            pathonen_tab=\\$(if [ \\$(cat pathogen_quantification_uniquely_mapped_htseq.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n            host_tab=\\$(if [ \\$(cat host_quantification_uniquely_mapped_htseq.tsv | wc -l) -gt 1  ]; then echo \"true\"; else echo \"false\"; fi)\n\t    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_table_htseq_host",
            "annotation_host_split_quant_htseq",
            "annotation_pathogen_split_quant_htseq"
        ],
        "nb_inputs": 3,
        "outputs": [
            "host_quantification_stats_htseq",
            "host_quantification_stats_htseq_total",
            "host_htseq_quantification_RNA_stats",
            "quant_host_add_annotations_htseq_u_m",
            "quant_scatter_plot_host_htseq_u_m",
            "pathogen_quantification_stats_htseq",
            "pathogen_quantification_stats_htseq_total",
            "pathogen_htseq_quantification_RNA_stats",
            "quant_pathogen_add_annotations_htseq_u_m",
            "quant_scatter_plot_pathogen_htseq_u_m",
            "pathonen_tab",
            "host_tab"
        ],
        "nb_outputs": 12,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode",
            "tag \"split_quants_uniq_mapped_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_pathogen_uniquely_mapped_host": {
        "name_process": "combine_annotations_quant_pathogen_uniquely_mapped_host",
        "string_process": "\tprocess combine_annotations_quant_pathogen_uniquely_mapped_host {\n\t    publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/HTSeq\"\n\t    tag \"comb_annots_quant_pathogen\"\n\t    \n\t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_pathogen_add_annotations_htseq_u_m\n\t    file annotation_table from annotation_pathogen_combine_quant_htseq_u_m\n\t    val attribute from combine_annot_quant_pathogen_host_gff_attribute\n\n\t    output:\n\t    file \"pathogen_combined_quant_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org pathogen\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org pathogen\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_pathogen_add_annotations_htseq_u_m",
            "annotation_pathogen_combine_quant_htseq_u_m",
            "combine_annot_quant_pathogen_host_gff_attribute"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/HTSeq\"",
            "tag \"comb_annots_quant_pathogen\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "combine_annotations_quant_host_uniquely_mapped_host": {
        "name_process": "combine_annotations_quant_host_uniquely_mapped_host",
        "string_process": "\tprocess combine_annotations_quant_host_uniquely_mapped_host {\n\t    publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode\n\t    storeDir \"${params.outdir}/HTSeq\"\n\t    tag \"comb_annots_quant_host\"\n\n\t    label 'process_high'\n\t   \n\t    input: \n\t    file quantification_table from quant_host_add_annotations_htseq_u_m\n\t    file annotation_table from annotation_host_combine_quant_htseq\n\t    val attribute from combine_annot_quant_pathogen_host_gff_attribute\n\n\t    output:\n\t    file \"host_combined_quant_annotations.tsv\"\n\n\t    script:\n\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org host\n\t    \"\"\"\n\t}",
        "nb_lignes_process": 18,
        "string_script": "\t    \"\"\"\n\t    $workflow.projectDir/bin/combine_quant_annotations.py -q $quantification_table -annotations $annotation_table -a $attribute -org host\n\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_host_add_annotations_htseq_u_m",
            "annotation_host_combine_quant_htseq",
            "combine_annot_quant_pathogen_host_gff_attribute"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/HTSeq\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/HTSeq\"",
            "tag \"comb_annots_quant_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "scatter_plot_pathogen_htseq": {
        "name_process": "scatter_plot_pathogen_htseq",
        "string_process": "\tprocess scatter_plot_pathogen_htseq {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\"\n\t\t    tag \"scatter_plot_pathogen_htseq\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from quant_scatter_plot_pathogen_htseq_u_m\n\t\t    val attribute from atr_scatter_plot_pathogen_htseq_u_m\n\t\t    val replicates from repl_scatter_plots_htseq_pathogen\n\t\t    val pathogen_table_non_empty from scatterplots_pathogen_htseq\n\n\t\t    output:\n\t\t    file ('*.pdf')\n\n\t\t    when:\n\t\t    replicates.toBoolean()\n\t\t    pathogen_table_non_empty.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org pathogen\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org pathogen\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_scatter_plot_pathogen_htseq_u_m",
            "atr_scatter_plot_pathogen_htseq_u_m",
            "repl_scatter_plots_htseq_pathogen",
            "scatterplots_pathogen_htseq"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\"",
            "tag \"scatter_plot_pathogen_htseq\"",
            "label 'process_high'"
        ],
        "when": "replicates.toBoolean()\n\t\t    pathogen_table_non_empty.toBoolean()",
        "stub": ""
    },
    "scatter_plot_host_htseq": {
        "name_process": "scatter_plot_host_htseq",
        "string_process": "\tprocess scatter_plot_host_htseq {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\"\n\t\t    tag \"scatter_plot_host_htseq\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from quant_scatter_plot_host_htseq_u_m\n\t\t    val attribute from atr_scatter_plot_host_htseq_u_m\n\t\t    val replicates from repl_scatter_plots_htseq_host\n\t\t    val host_table_non_empty from scatterplots_host_htseq\n\n\t\t    output:\n\t\t    file ('*.pdf')\n\n\t\t    when:\n\t\t    replicates.toBoolean()\n\t\t    host_table_non_empty.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org host \n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/scatter_plots.py -q $quant_table -a $attribute -org host \n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_scatter_plot_host_htseq_u_m",
            "atr_scatter_plot_host_htseq_u_m",
            "repl_scatter_plots_htseq_host",
            "scatterplots_host_htseq"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq/scatter_plots\"",
            "tag \"scatter_plot_host_htseq\"",
            "label 'process_high'"
        ],
        "when": "replicates.toBoolean()\n\t\t    host_table_non_empty.toBoolean()",
        "stub": ""
    },
    "htseq_quantification_stats_uniquely_mapped": {
        "name_process": "htseq_quantification_stats_uniquely_mapped",
        "string_process": "\tprocess htseq_quantification_stats_uniquely_mapped {\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq\", mode: params.publish_dir_mode\n\t\t    tag \"quantification_stats_htseq\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table_host from host_quantification_stats_htseq_total\n\t\t    file quant_table_pathogen from pathogen_quantification_stats_htseq_total\n\t\t    val attribute from host_gff_attribute_mapping_stats_htseq\n\t\t    file star_stats from mapping_stats_star_htseq_stats\n\n\t\t    output:\n\t\t    file ('htseq_uniquely_mapped_reads_stats.tsv') into htseq_mapped_stats_to_plot\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -q_p $quant_table_pathogen -q_h $quant_table_host -a $attribute  -star $star_stats -t htseq -o htseq_uniquely_mapped_reads_stats.tsv\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 19,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/mapping_stats.py -q_p $quant_table_pathogen -q_h $quant_table_host -a $attribute  -star $star_stats -t htseq -o htseq_uniquely_mapped_reads_stats.tsv\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_quantification_stats_htseq_total",
            "pathogen_quantification_stats_htseq_total",
            "host_gff_attribute_mapping_stats_htseq",
            "mapping_stats_star_htseq_stats"
        ],
        "nb_inputs": 4,
        "outputs": [
            "htseq_mapped_stats_to_plot"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq\"",
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq\", mode: params.publish_dir_mode",
            "tag \"quantification_stats_htseq\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_mapping_stats_host_pathogen_htseq_uniquely_mapped": {
        "name_process": "plot_mapping_stats_host_pathogen_htseq_uniquely_mapped",
        "string_process": "\tprocess plot_mapping_stats_host_pathogen_htseq_uniquely_mapped{\n\t\t    tag \"$name2\"\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file(stats) from htseq_mapped_stats_to_plot\n\n\t\t    output:\n\t\t    file \"*.tsv\"\n\t\t    file \"*.pdf\"\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_stats_htseq.py -i $stats\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 17,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_mapping_stats_htseq.py -i $stats\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "htseq_mapped_stats_to_plot"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "tag \"$name2\"",
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "RNA_class_statistics_htseq_uniquely_mapped_pathogen": {
        "name_process": "RNA_class_statistics_htseq_uniquely_mapped_pathogen",
        "string_process": "\tprocess RNA_class_statistics_htseq_uniquely_mapped_pathogen {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    tag \"rna_class_stats_htseq_pathogen\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from pathogen_htseq_quantification_RNA_stats\n\t\t    val attribute from host_gff_attribute_RNA_class_pathogen_htseq\n\t\t    file gene_annotations from pathogen_annotations_RNA_class_stats_htseq\n\n\n\t\t    output:\n\t\t    file \"pathogen_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_pathogen_htseq_u_m\n\t\t    file \"pathogen_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_pathogen_combined_htseq_u_m\n\t\t    file \"pathogen_RNA_classes_sum_counts_*.tsv\"\n\t\t    stdout plot_RNA_stats_pathogen_htseq_u_m_boolean\n\t\t    stdout plot_RNA_stats_pathogen_combined_htseq_u_m_boolean\n\n\t\t    shell:\n\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -q_tool htseq -org pathogen 2>&1\n\t\t    '''\n\t\t}",
        "nb_lignes_process": 22,
        "string_script": "\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -q_tool htseq -org pathogen 2>&1\n\t\t    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pathogen_htseq_quantification_RNA_stats",
            "host_gff_attribute_RNA_class_pathogen_htseq",
            "pathogen_annotations_RNA_class_stats_htseq"
        ],
        "nb_inputs": 3,
        "outputs": [
            "plot_RNA_stats_pathogen_htseq_u_m",
            "plot_RNA_stats_pathogen_combined_htseq_u_m",
            "plot_RNA_stats_pathogen_htseq_u_m_boolean",
            "plot_RNA_stats_pathogen_combined_htseq_u_m_boolean"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "tag \"rna_class_stats_htseq_pathogen\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "RNA_class_statistics_htseq_uniquely_mapped_host": {
        "name_process": "RNA_class_statistics_htseq_uniquely_mapped_host",
        "string_process": "\tprocess RNA_class_statistics_htseq_uniquely_mapped_host {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    tag \"rna_class_stats_htseq_host\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file quant_table from host_htseq_quantification_RNA_stats\n\t\t    val attribute from host_gff_attribute_RNA_class_host_htseq\n\t\t    file gene_annotations from host_annotations_RNA_class_stats_htseq\n\t\t    file rna_classes_to_replace from RNA_classes_to_replace_htseq_uniquely_mapped\n\n\t\t    output:\n\t\t    file \"host_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_host_htseq_u_m\n\t\t    file \"host_RNA_classes_percentage_*.tsv\" into plot_RNA_stats_host_combined_htseq_u_m\n\t\t    file \"host_RNA_classes_sum_counts_*.tsv\"\n\t\t    file \"host_gene_types_groups_*\"\n\t\t    stdout plot_RNA_stats_host_htseq_u_m_boolean\n\t\t    stdout plot_RNA_stats_host_combined_htseq_u_m_boolean\n\n\t\t    shell:\n\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -rna !{rna_classes_to_replace} -q_tool htseq -org host 2>&1\n\t\t    '''\n\t\t}",
        "nb_lignes_process": 23,
        "string_script": "\t\t    '''\n\t\t    python !{workflow.projectDir}/bin/RNA_class_content.py -q !{quant_table} -a !{attribute} -annotations !{gene_annotations} -rna !{rna_classes_to_replace} -q_tool htseq -org host 2>&1\n\t\t    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "host_htseq_quantification_RNA_stats",
            "host_gff_attribute_RNA_class_host_htseq",
            "host_annotations_RNA_class_stats_htseq",
            "RNA_classes_to_replace_htseq_uniquely_mapped"
        ],
        "nb_inputs": 4,
        "outputs": [
            "plot_RNA_stats_host_htseq_u_m",
            "plot_RNA_stats_host_combined_htseq_u_m",
            "plot_RNA_stats_host_htseq_u_m_boolean",
            "plot_RNA_stats_host_combined_htseq_u_m_boolean"
        ],
        "nb_outputs": 4,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\", mode: params.publish_dir_mode",
            "tag \"rna_class_stats_htseq_host\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_RNA_class_htseq_uniquely_mapped_pathogen_each": {
        "name_process": "plot_RNA_class_htseq_uniquely_mapped_pathogen_each",
        "string_process": "\tprocess plot_RNA_class_htseq_uniquely_mapped_pathogen_each{\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\"\n\t\t    tag \"plot_rna_stats_htseq_pathogen\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_pathogen_htseq_u_m\n\t\t    val plot_rna from plot_RNA_stats_pathogen_htseq_u_m_boolean\n\n\t\t    output:\n\t\t    file \"*.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_pathogen_htseq_u_m",
            "plot_RNA_stats_pathogen_htseq_u_m_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\"",
            "tag \"plot_rna_stats_htseq_pathogen\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_htseq_uniquely_mapped_host_each": {
        "name_process": "plot_RNA_class_htseq_uniquely_mapped_host_each",
        "string_process": "\tprocess plot_RNA_class_htseq_uniquely_mapped_host_each {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\"\n\t\t    tag \"plot_rna_stats_htseq_host\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_host_htseq_u_m\n\t\t    val plot_rna from plot_RNA_stats_host_htseq_u_m_boolean\n\n\t\t    output:\n\t\t    file \"*.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_each.py -i $stats_table\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_host_htseq_u_m",
            "plot_RNA_stats_host_htseq_u_m_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\"",
            "tag \"plot_rna_stats_htseq_host\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_htseq_uniquely_mapped_pathogen_combined": {
        "name_process": "plot_RNA_class_htseq_uniquely_mapped_pathogen_combined",
        "string_process": "\tprocess plot_RNA_class_htseq_uniquely_mapped_pathogen_combined {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\"\n\t\t    tag \"plt_rna_stats_htseq_pathgn_all\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_pathogen_combined_htseq_u_m\n\t\t    val plot_rna from plot_RNA_stats_pathogen_combined_htseq_u_m_boolean\n\n\t\t    output:\n\t\t    file \"RNA_class_stats_combined_pathogen.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org pathogen\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org pathogen\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_pathogen_combined_htseq_u_m",
            "plot_RNA_stats_pathogen_combined_htseq_u_m_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_pathogen\"",
            "tag \"plt_rna_stats_htseq_pathgn_all\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "plot_RNA_class_htseq_uniquely_host_combined": {
        "name_process": "plot_RNA_class_htseq_uniquely_host_combined",
        "string_process": "\tprocess plot_RNA_class_htseq_uniquely_host_combined {\n\t\t    publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\", mode: params.publish_dir_mode\n\t\t    storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\"\n\t\t    tag \"plt_rna_stats_htseq_host_all\"\n\n\t\t    label 'process_high'\n\n\t\t    input:\n\t\t    file stats_table from plot_RNA_stats_host_combined_htseq_u_m\n\t\t    val plot_rna from plot_RNA_stats_host_combined_htseq_u_m_boolean\n\n\t\t    output:\n\t\t    file \"RNA_class_stats_combined_host.pdf\"\n\n\t\t    when:\n\t\t    plot_rna.toBoolean()\n\n\t\t    script:\n\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org host\n\t\t    \"\"\"\n\t\t}",
        "nb_lignes_process": 20,
        "string_script": "\t\t    \"\"\"\n\t\t    python $workflow.projectDir/bin/plot_RNA_class_stats_combined.py -i $stats_table -org host\n\t\t    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plot_RNA_stats_host_combined_htseq_u_m",
            "plot_RNA_stats_host_combined_htseq_u_m_boolean"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\", mode: params.publish_dir_mode",
            "storeDir \"${params.outdir}/mapping_statistics/HTSeq/RNA_classes_host\"",
            "tag \"plt_rna_stats_htseq_host_all\"",
            "label 'process_high'"
        ],
        "when": "plot_rna.toBoolean()",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc {\n    publishDir \"${params.outdir}/MultiQC\", mode: params.publish_dir_mode\n    \n    input:\n    file (multiqc_config) from ch_multiqc_config\n    file (mqc_custom_config) from ch_multiqc_custom_config.collect().ifEmpty([])\n    file ('fastqc/*') from ch_fastqc_results.last().collect().ifEmpty([]) \n    file ('fastqc_after_trimming/*') from ch_fastqc_trimmed_results.last().collect().ifEmpty([])\n    file ('salmon/*') from multiqc_salmon_quant.collect().ifEmpty([])\n    file ('salmon_alignment_mode/*') from multiqc_salmon_alignment_quant.collect().ifEmpty([])\n    file ('STAR/*') from multiqc_star_alignment.collect().ifEmpty([])\n    file ('STAR_for_salmon/*') from multiqc_star_for_salmon_alignment.collect().ifEmpty([])\n    file ('uniquely_mapped/*') from multiqc_htseq_unique.collect().ifEmpty([])\n    file ('software_versions/*') from ch_software_versions_yaml.collect()\n    file workflow_summary from ch_workflow_summary.collectFile(name: \"workflow_summary_mqc.yaml\")\n\n    output:\n    file \"*multiqc_report.html\" into ch_multiqc_report\n    file \"*_data\"\n    file \"multiqc_plots\"\n\n    script:\n    rtitle = custom_runName ? \"--title \\\"$custom_runName\\\"\" : ''\n    rfilename = custom_runName ? \"--filename \" + custom_runName.replaceAll('\\\\W','_').replaceAll('_+','_') + \"_multiqc_report\" : ''\n    custom_config_file = params.multiqc_config ? \"--config $mqc_custom_config\" : ''\n    \"\"\"\n    multiqc -d --export -f $rtitle $rfilename $custom_config_file . \n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    rtitle = custom_runName ? \"--title \\\"$custom_runName\\\"\" : ''\n    rfilename = custom_runName ? \"--filename \" + custom_runName.replaceAll('\\\\W','_').replaceAll('_+','_') + \"_multiqc_report\" : ''\n    custom_config_file = params.multiqc_config ? \"--config $mqc_custom_config\" : ''\n    \"\"\"\n    multiqc -d --export -f $rtitle $rfilename $custom_config_file . \n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "ch_multiqc_config",
            "ch_multiqc_custom_config",
            "ch_fastqc_results",
            "ch_fastqc_trimmed_results",
            "multiqc_salmon_quant",
            "multiqc_salmon_alignment_quant",
            "multiqc_star_alignment",
            "multiqc_star_for_salmon_alignment",
            "multiqc_htseq_unique",
            "ch_software_versions_yaml",
            "ch_workflow_summary"
        ],
        "nb_inputs": 11,
        "outputs": [
            "ch_multiqc_report"
        ],
        "nb_outputs": 1,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/MultiQC\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "output_documentation": {
        "name_process": "output_documentation",
        "string_process": "\nprocess output_documentation {\n    publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode\n\n    input:\n    file output_docs from ch_output_docs\n\n    output:\n    file \"results_description.html\"\n                                            \n\n    script:\n    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_output_docs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "bhagesh-codebeast__nextflowdualrnaseq",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    }
}