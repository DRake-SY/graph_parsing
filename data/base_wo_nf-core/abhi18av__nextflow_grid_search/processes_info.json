{
    "H2O_NAIVE_BAYES": {
        "name_process": "H2O_NAIVE_BAYES",
        "string_process": "\nprocess H2O_NAIVE_BAYES {\n    container \"quay.io/abhi18av/nextflow_grid_search\"\n    memory '4 GB'\n    cpus 4\n\n    input:\n    tuple val(train_frame), val(test_frame)\n\n    output:\n    path('NaiveBayes_model_*')\n\n    script:\n    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators import H2ONaiveBayesEstimator\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${params.train_frame}\")\ntest = h2o.import_file(\"${params.test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"response\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = 5\n\n# Build and train the model:\nnb_model = H2ONaiveBayesEstimator(laplace=0,\n                                 nfolds=5,\n                                 seed=1234)\n\n# Train the model grid\nnb_model.train(x=x,\n              y=y,\n              training_frame=train)\n\n# Eval performance:\ntest_perf = nb_model.model_performance(test)\n\n# Save the model\nh2o.save_model(nb_model, \"./\", force=True)\n\n# Explicitly print out the  the model's AUC on test data\nprint('AUC on Test data: ', test_perf.auc())\n    \"\"\"\n}",
        "nb_lignes_process": 54,
        "string_script": "    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators import H2ONaiveBayesEstimator\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${params.train_frame}\")\ntest = h2o.import_file(\"${params.test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"response\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = 5\n\n# Build and train the model:\nnb_model = H2ONaiveBayesEstimator(laplace=0,\n                                 nfolds=5,\n                                 seed=1234)\n\n# Train the model grid\nnb_model.train(x=x,\n              y=y,\n              training_frame=train)\n\n# Eval performance:\ntest_perf = nb_model.model_performance(test)\n\n# Save the model\nh2o.save_model(nb_model, \"./\", force=True)\n\n# Explicitly print out the  the model's AUC on test data\nprint('AUC on Test data: ', test_perf.auc())\n    \"\"\"",
        "nb_lignes_script": 41,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "train_frame",
            "test_frame"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "abhi18av__nextflow_grid_search",
        "directive": [
            "container \"quay.io/abhi18av/nextflow_grid_search\"",
            "memory '4 GB'",
            "cpus 4"
        ],
        "when": "",
        "stub": ""
    },
    "H2O_GRID_NAIVE_BAYES_MODELS": {
        "name_process": "H2O_GRID_NAIVE_BAYES_MODELS",
        "string_process": "\nprocess H2O_GRID_NAIVE_BAYES_MODELS {\n    container \"quay.io/abhi18av/nextflow_grid_search\"\n    memory '8 GB'\n    cpus 4\n\n    input:\n    tuple val(train_frame), val(test_frame)\n\n    output:\n    tuple path('nb_grid_id.txt'), path('nb_grid')\n\n    script:\n    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators import H2ONaiveBayesEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${train_frame}\")\ntest = h2o.import_file(\"${test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"${params.independent_variable}\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = ${params.nfolds}\n\n\nsearch_criteria = {\n'strategy' : \"${params.strategy}\",\n'stopping_metric' : \"${params.stopping_metric}\",\n'max_models' : ${params.max_models},\n'max_runtime_secs' : ${params.max_runtime_secs},\n'stopping_metric' : \"${params.stopping_metric}\",\n'stopping_tolerance' : ${params.stopping_tolerance},\n'stopping_rounds' : ${params.stopping_rounds},\n'seed' : ${params.grid_seed},\n}\n\n\nnb_hyperparams = {\n'laplace': ${params.laplace},\n'min_sdev': ${params.min_sdev},\n'min_prob': ${params.min_prob},\n'eps_prob': ${params.eps_prob},\n'eps_sdev': ${params.eps_sdev},\n'compute_metrics': ${params.compute_metrics}\n}\n\n# Build and train the model:\nnb_base_model = H2ONaiveBayesEstimator(\n                                        nfolds=nfolds,\n                                        seed=${params.model_seed})\n\n\nnb_grid = H2OGridSearch(model=nb_base_model,\n                        hyper_params=nb_hyperparams,\n                        parallelism= ${params.parallelism})\n\n\nnb_grid.train(x=x, \n             y=y,\n             training_frame=train,\n             validation_frame=test)\n\n\nprint(\"Saving the grid\")\nh2o.save_grid(\"./nb_grid\", nb_grid.grid_id)\n\nprint(\"Saving the grid ID\")\nwith open(\"nb_grid_id.txt\", \"w\") as grid_id_file: \n    grid_id_file.write(nb_grid.grid_id) \n    \"\"\"\n}",
        "nb_lignes_process": 82,
        "string_script": "    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators import H2ONaiveBayesEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${train_frame}\")\ntest = h2o.import_file(\"${test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"${params.independent_variable}\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = ${params.nfolds}\n\n\nsearch_criteria = {\n'strategy' : \"${params.strategy}\",\n'stopping_metric' : \"${params.stopping_metric}\",\n'max_models' : ${params.max_models},\n'max_runtime_secs' : ${params.max_runtime_secs},\n'stopping_metric' : \"${params.stopping_metric}\",\n'stopping_tolerance' : ${params.stopping_tolerance},\n'stopping_rounds' : ${params.stopping_rounds},\n'seed' : ${params.grid_seed},\n}\n\n\nnb_hyperparams = {\n'laplace': ${params.laplace},\n'min_sdev': ${params.min_sdev},\n'min_prob': ${params.min_prob},\n'eps_prob': ${params.eps_prob},\n'eps_sdev': ${params.eps_sdev},\n'compute_metrics': ${params.compute_metrics}\n}\n\n# Build and train the model:\nnb_base_model = H2ONaiveBayesEstimator(\n                                        nfolds=nfolds,\n                                        seed=${params.model_seed})\n\n\nnb_grid = H2OGridSearch(model=nb_base_model,\n                        hyper_params=nb_hyperparams,\n                        parallelism= ${params.parallelism})\n\n\nnb_grid.train(x=x, \n             y=y,\n             training_frame=train,\n             validation_frame=test)\n\n\nprint(\"Saving the grid\")\nh2o.save_grid(\"./nb_grid\", nb_grid.grid_id)\n\nprint(\"Saving the grid ID\")\nwith open(\"nb_grid_id.txt\", \"w\") as grid_id_file: \n    grid_id_file.write(nb_grid.grid_id) \n    \"\"\"",
        "nb_lignes_script": 69,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "train_frame",
            "test_frame"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "abhi18av__nextflow_grid_search",
        "directive": [
            "container \"quay.io/abhi18av/nextflow_grid_search\"",
            "memory '8 GB'",
            "cpus 4"
        ],
        "when": "",
        "stub": ""
    },
    "H2O_Stacked_Ensemble": {
        "name_process": "H2O_Stacked_Ensemble",
        "string_process": "\nprocess H2O_Stacked_Ensemble {\n    container \"quay.io/abhi18av/nextflow_grid_search\"\n    memory '4 GB'\n    cpus 4\n\n    input:\n    tuple file(params.train_frame), file(params.test_frame)\n    val base_learner_models_list\n\n\n    script:\n    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${params.train_frame}\")\ntest = h2o.import_file(\"${params.test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"response\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = 5\n\n# Build and train the model:\nnb_model = H2ONaiveBayesEstimator(laplace=0,\n                                 nfolds=5,\n                                 seed=1234)\n\n# Train the model grid\nnb_model.train(x=x,\n              y=y,\n              training_frame=train)\n\n# Train a stacked ensemble using the GBM grid\nensemble = H2OStackedEnsembleEstimator( base_models=grid.model_ids)\nensemble.train(x=x, y=y, training_frame=train)\n\n\n\n# Eval performance:\ntest_perf = nb_model.model_performance(test)\n\n# Save the model\nh2o.save_model(nb_model, \"./\", force=True)\n\n# Explicitly print out the  the model's AUC on test data\nprint('AUC on Test data: ', test_perf.auc())\n    \"\"\"\n}",
        "nb_lignes_process": 59,
        "string_script": "    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${params.train_frame}\")\ntest = h2o.import_file(\"${params.test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"response\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = 5\n\n# Build and train the model:\nnb_model = H2ONaiveBayesEstimator(laplace=0,\n                                 nfolds=5,\n                                 seed=1234)\n\n# Train the model grid\nnb_model.train(x=x,\n              y=y,\n              training_frame=train)\n\n# Train a stacked ensemble using the GBM grid\nensemble = H2OStackedEnsembleEstimator( base_models=grid.model_ids)\nensemble.train(x=x, y=y, training_frame=train)\n\n\n\n# Eval performance:\ntest_perf = nb_model.model_performance(test)\n\n# Save the model\nh2o.save_model(nb_model, \"./\", force=True)\n\n# Explicitly print out the  the model's AUC on test data\nprint('AUC on Test data: ', test_perf.auc())\n    \"\"\"",
        "nb_lignes_script": 47,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "params",
            "params",
            "base_learner_models_list"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "abhi18av__nextflow_grid_search",
        "directive": [
            "container \"quay.io/abhi18av/nextflow_grid_search\"",
            "memory '4 GB'",
            "cpus 4"
        ],
        "when": "",
        "stub": ""
    },
    "H2O_GRID_GENERALIZED_LINEAR_MODELS": {
        "name_process": "H2O_GRID_GENERALIZED_LINEAR_MODELS",
        "string_process": "\nprocess H2O_GRID_GENERALIZED_LINEAR_MODELS {\n    container \"quay.io/abhi18av/nextflow_grid_search\"\n    memory '8 GB'\n    cpus 4\n\n    input:\n    tuple val(train_frame), val(test_frame)\n\n    output:\n    tuple path('glm_grid_id.txt'), path('glm_grid')\n\n    script:\n    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${train_frame}\")\ntest = h2o.import_file(\"${test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"${params.independent_variable}\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = ${params.nfolds}\n\n\nsearch_criteria = {\n'strategy' : \"${params.strategy}\",\n'stopping_metric' : \"${params.stopping_metric}\",\n'max_models' : ${params.max_models},\n'max_runtime_secs' : ${params.max_runtime_secs},\n'stopping_metric' : \"${params.stopping_metric}\",\n'stopping_tolerance' : ${params.stopping_tolerance},\n'stopping_rounds' : ${params.stopping_rounds},\n'seed' : ${params.grid_seed},\n}\n\nglm_hyperparams = {\n'alpha' : ${params.alpha},\n# lambda' : {params.lambda},\n'missing_values_handling' : [${params.missing_values_handling}],\n'theta' : ${params.theta},\n'tweedie_link_power' : ${params.tweedie_link_power},\n'tweedie_variance_power' : ${params.tweedie_variance_power}\n}\n\n# Build and train the model:\nglm_base_model = H2OGeneralizedLinearEstimator(\n                                        family= \"${params.family}\",\n                                        nfolds=nfolds,\n                                        seed=${params.model_seed},\n                                        standardize= ${params.standardize}\n)\n\n\nglm_grid = H2OGridSearch(model=glm_base_model,\n                        hyper_params=glm_hyperparams,\n                        parallelism= ${params.parallelism})\n\n\nglm_grid.train(x=x, \n             y=y,\n             training_frame=train,\n             validation_frame=test)\n\nprint(\"Saving the grid\")\nh2o.save_grid(\"./glm_grid\", glm_grid.grid_id)\n\nprint(\"Saving the grid ID\")\nwith open(\"glm_grid_id.txt\", \"w\") as grid_id_file: \n    grid_id_file.write(glm_grid.grid_id) \n\n\n    \"\"\"\n}",
        "nb_lignes_process": 85,
        "string_script": "    \"\"\"\n#!/usr/bin/env python3\n\nimport h2o\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\nh2o.init()\n\n# Import a sample binary outcome train/test set into H2O\ntrain = h2o.import_file(\"${train_frame}\")\ntest = h2o.import_file(\"${test_frame}\")\n\n# Identify predictors and response\nx = train.columns\ny = \"${params.independent_variable}\"\nx.remove(y)\n\n# For binary classification, response should be a factor\ntrain[y] = train[y].asfactor()\ntest[y] = test[y].asfactor()\n\n# Number of CV folds (to generate level-one data for stacking)\nnfolds = ${params.nfolds}\n\n\nsearch_criteria = {\n'strategy' : \"${params.strategy}\",\n'stopping_metric' : \"${params.stopping_metric}\",\n'max_models' : ${params.max_models},\n'max_runtime_secs' : ${params.max_runtime_secs},\n'stopping_metric' : \"${params.stopping_metric}\",\n'stopping_tolerance' : ${params.stopping_tolerance},\n'stopping_rounds' : ${params.stopping_rounds},\n'seed' : ${params.grid_seed},\n}\n\nglm_hyperparams = {\n'alpha' : ${params.alpha},\n# lambda' : {params.lambda},\n'missing_values_handling' : [${params.missing_values_handling}],\n'theta' : ${params.theta},\n'tweedie_link_power' : ${params.tweedie_link_power},\n'tweedie_variance_power' : ${params.tweedie_variance_power}\n}\n\n# Build and train the model:\nglm_base_model = H2OGeneralizedLinearEstimator(\n                                        family= \"${params.family}\",\n                                        nfolds=nfolds,\n                                        seed=${params.model_seed},\n                                        standardize= ${params.standardize}\n)\n\n\nglm_grid = H2OGridSearch(model=glm_base_model,\n                        hyper_params=glm_hyperparams,\n                        parallelism= ${params.parallelism})\n\n\nglm_grid.train(x=x, \n             y=y,\n             training_frame=train,\n             validation_frame=test)\n\nprint(\"Saving the grid\")\nh2o.save_grid(\"./glm_grid\", glm_grid.grid_id)\n\nprint(\"Saving the grid ID\")\nwith open(\"glm_grid_id.txt\", \"w\") as grid_id_file: \n    grid_id_file.write(glm_grid.grid_id) \n\n\n    \"\"\"",
        "nb_lignes_script": 72,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "train_frame",
            "test_frame"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "abhi18av__nextflow_grid_search",
        "directive": [
            "container \"quay.io/abhi18av/nextflow_grid_search\"",
            "memory '8 GB'",
            "cpus 4"
        ],
        "when": "",
        "stub": ""
    },
    "UTILS_GRID_TOP_PERFORMER": {
        "name_process": "UTILS_GRID_TOP_PERFORMER",
        "string_process": "\nprocess UTILS_GRID_TOP_PERFORMER {\n    container \"quay.io/abhi18av/nextflow_grid_search\"\n    memory '4 GB'\n    cpus 4\n\n\n    input:\n    tuple path(grid_id_file), path(grid_folder)\n\n    output:\n    path(\"Grid_*\")\n\n    script:\n    \"\"\"\n#!/usr/bin/env python3\nimport h2o\n\nh2o.init()\n\n# Save the model grid ID\nwith open(\"${grid_id_file}\", \"r\") as grid_id_txt: \n    grid_id= grid_id_txt.read() \n\ngrid = h2o.load_grid(\"${grid_folder}/\" + grid_id)\nprint(grid)\n\n\n# If nfolds is used then the accuracy on CV datasets is used.\n# For more info, http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=get_grid#h2o.grid.H2OGridSearch.get_grid\ntop_grid_performer = grid.get_grid(sort_by='auc', decreasing=True)[0]\n\nh2o.save_model(top_grid_performer, \"./\", force=True)\n\n# Explicitly print out the  the model's AUC on test data\nprint('AUC of Top-performer on Test data: ', top_grid_performer.auc())\n\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n#!/usr/bin/env python3\nimport h2o\n\nh2o.init()\n\n# Save the model grid ID\nwith open(\"${grid_id_file}\", \"r\") as grid_id_txt: \n    grid_id= grid_id_txt.read() \n\ngrid = h2o.load_grid(\"${grid_folder}/\" + grid_id)\nprint(grid)\n\n\n# If nfolds is used then the accuracy on CV datasets is used.\n# For more info, http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=get_grid#h2o.grid.H2OGridSearch.get_grid\ntop_grid_performer = grid.get_grid(sort_by='auc', decreasing=True)[0]\n\nh2o.save_model(top_grid_performer, \"./\", force=True)\n\n# Explicitly print out the  the model's AUC on test data\nprint('AUC of Top-performer on Test data: ', top_grid_performer.auc())\n\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "grid_id_file",
            "grid_folder"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "abhi18av__nextflow_grid_search",
        "directive": [
            "container \"quay.io/abhi18av/nextflow_grid_search\"",
            "memory '4 GB'",
            "cpus 4"
        ],
        "when": "",
        "stub": ""
    }
}