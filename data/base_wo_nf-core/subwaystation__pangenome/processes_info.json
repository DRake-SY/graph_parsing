{
    "wfmashMap": {
        "name_process": "wfmashMap",
        "string_process": "\nprocess wfmashMap {\n  publishDir \"${params.outdir}/wfmash_map\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    tuple val(f), path(fasta)\n\n  output:\n    tuple val(f), path(\"${f}.${wfmash_prefix}.map.paf\")\n\n  \"\"\"\n  wfmash ${wfmash_exclude_cmd} \\\n     -s ${params.wfmash_segment_length} \\\n     -l ${params.wfmash_block_length} \\\n     ${wfmash_merge_cmd} \\\n     ${wfmash_split_cmd} \\\n     -p ${params.wfmash_map_pct_id} \\\n     -n ${params.wfmash_n_mappings} \\\n     -k ${params.wfmash_mash_kmer} \\\n     -t ${task.cpus} \\\n     -m \\\n     $fasta $fasta \\\n     >${f}.${wfmash_prefix}.map.paf\n  \"\"\"  \n}",
        "nb_lignes_process": 23,
        "string_script": "\"\"\"\n  wfmash ${wfmash_exclude_cmd} \\\n     -s ${params.wfmash_segment_length} \\\n     -l ${params.wfmash_block_length} \\\n     ${wfmash_merge_cmd} \\\n     ${wfmash_split_cmd} \\\n     -p ${params.wfmash_map_pct_id} \\\n     -n ${params.wfmash_n_mappings} \\\n     -k ${params.wfmash_mash_kmer} \\\n     -t ${task.cpus} \\\n     -m \\\n     $fasta $fasta \\\n     >${f}.${wfmash_prefix}.map.paf\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "f",
            "fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "f"
        ],
        "nb_outputs": 1,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/wfmash_map\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "splitApproxMappingsInChunks": {
        "name_process": "splitApproxMappingsInChunks",
        "string_process": "\nprocess splitApproxMappingsInChunks {\n  publishDir \"${params.outdir}/wfmash_chunks\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    tuple val(f), path(paf)\n  output:\n    path(\"${f}*.chunk_*.paf\")\n  \"\"\"\n  python3 /split_approx_mappings_in_chunks.py $paf ${params.wfmash_chunks}\n  \"\"\"\n}",
        "nb_lignes_process": 10,
        "string_script": "\"\"\"\n  python3 /split_approx_mappings_in_chunks.py $paf ${params.wfmash_chunks}\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "f",
            "paf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/wfmash_chunks\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "wfmashAlign": {
        "name_process": "wfmashAlign",
        "string_process": "\nprocess wfmashAlign {\n  publishDir \"${params.outdir}/wfmash_align\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    tuple val(f), path(fasta), path(paf)\n\n  output:\n    path(\"${paf}.align.paf\")\n\n  \"\"\"\n  wfmash ${wfmash_exclude_cmd} \\\n     -s ${params.wfmash_segment_length} \\\n     -l ${params.wfmash_block_length} \\\n     ${wfmash_merge_cmd} \\\n     ${wfmash_split_cmd} \\\n     -p ${params.wfmash_map_pct_id} \\\n     -n ${params.wfmash_n_mappings} \\\n     -k ${params.wfmash_mash_kmer} \\\n     -t ${task.cpus} \\\n     -i $paf \\\n     $fasta $fasta \\\n     >${paf}.align.paf\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "\"\"\"\n  wfmash ${wfmash_exclude_cmd} \\\n     -s ${params.wfmash_segment_length} \\\n     -l ${params.wfmash_block_length} \\\n     ${wfmash_merge_cmd} \\\n     ${wfmash_split_cmd} \\\n     -p ${params.wfmash_map_pct_id} \\\n     -n ${params.wfmash_n_mappings} \\\n     -k ${params.wfmash_mash_kmer} \\\n     -t ${task.cpus} \\\n     -i $paf \\\n     $fasta $fasta \\\n     >${paf}.align.paf\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "f",
            "fasta",
            "paf"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/wfmash_align\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "wfmash": {
        "name_process": "wfmash",
        "string_process": "\nprocess wfmash {\n  publishDir \"${params.outdir}/wfmash\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    tuple val(f), path(fasta)\n\n  output:\n    tuple val(f), path(\"${f}${wfmash_prefix}.paf\")\n\n  \"\"\"\n  wfmash ${wfmash_exclude_cmd} \\\n     -s ${params.wfmash_segment_length} \\\n     -l ${params.wfmash_block_length} \\\n     ${wfmash_merge_cmd} \\\n     ${wfmash_split_cmd} \\\n     -p ${params.wfmash_map_pct_id} \\\n     -n ${params.wfmash_n_mappings} \\\n     -k ${params.wfmash_mash_kmer} \\\n     -t ${task.cpus} \\\n     $fasta $fasta \\\n     >${f}${wfmash_prefix}.paf\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "\"\"\"\n  wfmash ${wfmash_exclude_cmd} \\\n     -s ${params.wfmash_segment_length} \\\n     -l ${params.wfmash_block_length} \\\n     ${wfmash_merge_cmd} \\\n     ${wfmash_split_cmd} \\\n     -p ${params.wfmash_map_pct_id} \\\n     -n ${params.wfmash_n_mappings} \\\n     -k ${params.wfmash_mash_kmer} \\\n     -t ${task.cpus} \\\n     $fasta $fasta \\\n     >${f}${wfmash_prefix}.paf\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "f",
            "fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "f"
        ],
        "nb_outputs": 1,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/wfmash\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "seqwish": {
        "name_process": "seqwish",
        "string_process": "\nprocess seqwish {\n  publishDir \"${params.outdir}/seqwish\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    tuple val(f), path(fasta)\n    path(pafs)\n\n  output:\n    tuple val(f), path(\"${f}${seqwish_prefix}.gfa\")\n\n  script:\n    \"\"\"\n    if [[ \\$(ls *.paf | wc -l) == 1 ]]; then\n      input=$pafs\n    else \n      input=\\$(ls *.paf | tr '\\\\\\n' ',')\n      input=\\${input::-1}\n    fi  \n    seqwish \\\n      -t ${task.cpus} \\\n      -s $fasta \\\n      -p \\$input \\\n      -k ${params.seqwish_min_match_length} \\\n      -g ${f}${seqwish_prefix}.gfa -P \\\n      -B ${params.seqwish_transclose_batch} \\\n      -P\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    if [[ \\$(ls *.paf | wc -l) == 1 ]]; then\n      input=$pafs\n    else \n      input=\\$(ls *.paf | tr '\\\\\\n' ',')\n      input=\\${input::-1}\n    fi  \n    seqwish \\\n      -t ${task.cpus} \\\n      -s $fasta \\\n      -p \\$input \\\n      -k ${params.seqwish_min_match_length} \\\n      -g ${f}${seqwish_prefix}.gfa -P \\\n      -B ${params.seqwish_transclose_batch} \\\n      -P\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "f",
            "fasta",
            "pafs"
        ],
        "nb_inputs": 3,
        "outputs": [
            "f"
        ],
        "nb_outputs": 1,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/seqwish\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "smoothxg": {
        "name_process": "smoothxg",
        "string_process": "\nprocess smoothxg {\n  publishDir \"${params.outdir}/smoothxg\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    tuple val(f), path(graph)\n\n  output:\n    path(\"${f}${smoothxg_prefix}.gfa\"), emit: gfa_smooth\n    path(\"${f}*.cons*.gfa\"), optional: true, emit: consensus_smooth\n    path(\"${f}.${smoothxg_prefix}.maf\"), optional: true, emit: maf_smooth\n\n  script:\n    \"\"\"\n    smooth_iterations=\\$(echo ${params.smoothxg_poa_length} | tr ',' '\\\\\\n' | wc -l)\n    echo \\$smooth_iterations > smooth_iterations\n    maf_params=\"\"\n    if [[ ${params.smoothxg_write_maf} != false ]]; then\n      maf_params=\"-m ${f}.${smoothxg_prefix}.maf\"\n    fi\n    for i in \\$(seq 1 \\$smooth_iterations);\n    do\n      input_gfa=${graph}\n      if [[ \\$i != 1 ]]; then\n        input_gfa=smooth.\\$(echo \\$i - 1 | bc).gfa \n      fi\n      if [[ \\$i != \\$smooth_iterations ]]; then\n        poa_length=\\$(echo ${params.smoothxg_poa_length} | cut -f \\$i -d,)\n        smoothxg \\\n          -t ${task.cpus} \\\n          -T ${task.cpus} \\\n          -g \\$input_gfa \\\n          -w \\$(echo \"\\$poa_length * ${n_haps}\" | bc) \\\n          -K \\\n          -X 100 \\\n          -I ${params.smoothxg_block_id_min} \\\n          -R ${params.smoothxg_block_ratio_min} \\\n          -j ${params.smoothxg_max_path_jump} \\\n          -e ${params.smoothxg_max_edge_jump} \\\n          -l \\$poa_length \\\n          -p ${params.smoothxg_poa_params} \\\n          -O ${params.smoothxg_poa_padding} \\\n          -Y \\$(echo \"${params.smoothxg_pad_max_depth} * ${n_haps}\" | bc) \\\n          -d 0 -D 0 \\\n          -V \\\n          -o smooth.\\$i.gfa\n      else\n        poa_length=\\$(echo ${params.smoothxg_poa_length} | cut -f \\$i -d,)\n        consensus_params=\"-V\"\n        if [[ ${params.smoothxg_consensus_spec} != false ]]; then\n          consensus_params=\"-C ${f}.cons,${params.smoothxg_consensus_spec}\"  \n        fi  \n        smoothxg \\\n          -t ${task.cpus} \\\n          -T ${task.cpus} \\\n          -g \\$input_gfa \\\n          -w \\$(echo \"\\$poa_length * ${n_haps}\" | bc) \\\n          -K \\\n          -X 100 \\\n          -I ${params.smoothxg_block_id_min} \\\n          -R ${params.smoothxg_block_ratio_min} \\\n          -j ${params.smoothxg_max_path_jump} \\\n          -e ${params.smoothxg_max_edge_jump} \\\n          -l \\$poa_length \\\n          -p ${params.smoothxg_poa_params} \\\n          -O ${params.smoothxg_poa_padding} \\\n          -Y \\$(echo \"${params.smoothxg_pad_max_depth} * ${n_haps}\" | bc) \\\n          -d 0 -D 0 \\\n          \\$maf_params \\\n          -Q ${params.smoothxg_consensus_prefix} \\\n          \\$consensus_params \\\n          -o ${f}${smoothxg_prefix}.gfa\n      fi\n    done  \n    \"\"\"\n}",
        "nb_lignes_process": 74,
        "string_script": "    \"\"\"\n    smooth_iterations=\\$(echo ${params.smoothxg_poa_length} | tr ',' '\\\\\\n' | wc -l)\n    echo \\$smooth_iterations > smooth_iterations\n    maf_params=\"\"\n    if [[ ${params.smoothxg_write_maf} != false ]]; then\n      maf_params=\"-m ${f}.${smoothxg_prefix}.maf\"\n    fi\n    for i in \\$(seq 1 \\$smooth_iterations);\n    do\n      input_gfa=${graph}\n      if [[ \\$i != 1 ]]; then\n        input_gfa=smooth.\\$(echo \\$i - 1 | bc).gfa \n      fi\n      if [[ \\$i != \\$smooth_iterations ]]; then\n        poa_length=\\$(echo ${params.smoothxg_poa_length} | cut -f \\$i -d,)\n        smoothxg \\\n          -t ${task.cpus} \\\n          -T ${task.cpus} \\\n          -g \\$input_gfa \\\n          -w \\$(echo \"\\$poa_length * ${n_haps}\" | bc) \\\n          -K \\\n          -X 100 \\\n          -I ${params.smoothxg_block_id_min} \\\n          -R ${params.smoothxg_block_ratio_min} \\\n          -j ${params.smoothxg_max_path_jump} \\\n          -e ${params.smoothxg_max_edge_jump} \\\n          -l \\$poa_length \\\n          -p ${params.smoothxg_poa_params} \\\n          -O ${params.smoothxg_poa_padding} \\\n          -Y \\$(echo \"${params.smoothxg_pad_max_depth} * ${n_haps}\" | bc) \\\n          -d 0 -D 0 \\\n          -V \\\n          -o smooth.\\$i.gfa\n      else\n        poa_length=\\$(echo ${params.smoothxg_poa_length} | cut -f \\$i -d,)\n        consensus_params=\"-V\"\n        if [[ ${params.smoothxg_consensus_spec} != false ]]; then\n          consensus_params=\"-C ${f}.cons,${params.smoothxg_consensus_spec}\"  \n        fi  \n        smoothxg \\\n          -t ${task.cpus} \\\n          -T ${task.cpus} \\\n          -g \\$input_gfa \\\n          -w \\$(echo \"\\$poa_length * ${n_haps}\" | bc) \\\n          -K \\\n          -X 100 \\\n          -I ${params.smoothxg_block_id_min} \\\n          -R ${params.smoothxg_block_ratio_min} \\\n          -j ${params.smoothxg_max_path_jump} \\\n          -e ${params.smoothxg_max_edge_jump} \\\n          -l \\$poa_length \\\n          -p ${params.smoothxg_poa_params} \\\n          -O ${params.smoothxg_poa_padding} \\\n          -Y \\$(echo \"${params.smoothxg_pad_max_depth} * ${n_haps}\" | bc) \\\n          -d 0 -D 0 \\\n          \\$maf_params \\\n          -Q ${params.smoothxg_consensus_prefix} \\\n          \\$consensus_params \\\n          -o ${f}${smoothxg_prefix}.gfa\n      fi\n    done  \n    \"\"\"",
        "nb_lignes_script": 61,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "f",
            "graph"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/smoothxg\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "gfaffix": {
        "name_process": "gfaffix",
        "string_process": "\nprocess gfaffix {\n  publishDir \"${params.outdir}/gfaffix\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    path(graph)\n\n  output:\n    path(\"${graph}.norm.og\"), emit: og_norm\n    path(\"${graph}.norm.gfa\"), emit: gfa_norm\n    path(\"${graph}.norm.affixes.tsv.gz\"), emit: tsv_norm\n\n  \"\"\"\n  gfaffix $graph -o ${graph}.norm.gfa | gzip > ${graph}.norm.affixes.tsv.gz \n  odgi build -g ${graph}.norm.gfa -o ${graph}.norm.gfa.og -P -t ${task.cpus} -O -o - \\\n  | odgi sort -i - -o ${graph}.norm.og -t ${task.cpus} -p Ygs \n  odgi view -i ${graph}.norm.og -g > ${graph}.norm.gfa\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n  gfaffix $graph -o ${graph}.norm.gfa | gzip > ${graph}.norm.affixes.tsv.gz \n  odgi build -g ${graph}.norm.gfa -o ${graph}.norm.gfa.og -P -t ${task.cpus} -O -o - \\\n  | odgi sort -i - -o ${graph}.norm.og -t ${task.cpus} -p Ygs \n  odgi view -i ${graph}.norm.og -g > ${graph}.norm.gfa\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "graph"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/gfaffix\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "odgiBuild": {
        "name_process": "odgiBuild",
        "string_process": "\nprocess odgiBuild {\n  publishDir \"${params.outdir}/odgi_build\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    path(graph)\n\n  output:\n    path(\"${graph}.og\")\n\n  \"\"\"\n  odgi build -g $graph -o ${graph}.og -P -t ${task.cpus}\n  \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n  odgi build -g $graph -o ${graph}.og -P -t ${task.cpus}\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "graph"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/odgi_build\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "odgiStats": {
        "name_process": "odgiStats",
        "string_process": "\nprocess odgiStats {\n  publishDir \"${params.outdir}/odgi_stats\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    path(graph)\n\n  output:\n    path(\"${graph}.stats.yaml\")\n\n  \"\"\"\n  odgi stats -i \"${graph}\" -m > \"${graph}.stats.yaml\" 2>&1\n  \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n  odgi stats -i \"${graph}\" -m > \"${graph}.stats.yaml\" 2>&1\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "graph"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/odgi_stats\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "odgiViz": {
        "name_process": "odgiViz",
        "string_process": "\nprocess odgiViz {\n  publishDir \"${params.outdir}/odgi_viz\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n    path(graph)\n\n  output:\n    path(\"${graph}.viz*.png\")\n\n  script:\n    \"\"\"\n    odgi viz -i $graph -o ${graph}.viz_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix}\n    odgi viz -i $graph -o ${graph}.viz_pos_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix} -u -d\n    odgi viz -i $graph -o ${graph}.viz_depth_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix} -m\n    odgi viz -i $graph -o ${graph}.viz_inv_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix} -z\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    odgi viz -i $graph -o ${graph}.viz_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix}\n    odgi viz -i $graph -o ${graph}.viz_pos_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix} -u -d\n    odgi viz -i $graph -o ${graph}.viz_depth_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix} -m\n    odgi viz -i $graph -o ${graph}.viz_inv_multiqc.png -x 1500 -y 500 -a 10 -I ${params.smoothxg_consensus_prefix} -z\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "graph"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/odgi_viz\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "odgiLayout": {
        "name_process": "odgiLayout",
        "string_process": "\nprocess odgiLayout {\n  input:\n  path(graph)\n\n  output:\n  tuple path(graph), path(\"${graph}.lay\")\n\n  \"\"\"\n  odgi layout \\\n    -i $graph \\\n    -o ${graph}.lay \\\n    -t ${task.cpus} -P\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n  odgi layout \\\n    -i $graph \\\n    -o ${graph}.lay \\\n    -t ${task.cpus} -P\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "graph"
        ],
        "nb_inputs": 1,
        "outputs": [
            "graph"
        ],
        "nb_outputs": 1,
        "name_workflow": "subwaystation__pangenome",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "odgiDraw": {
        "name_process": "odgiDraw",
        "string_process": "\nprocess odgiDraw {\n  publishDir \"${params.outdir}/odgi_draw\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n  tuple path(graph), path(layoutGraph)\n\n  output:\n  path(\"${graph}.draw_multiqc.png\")\n\n  \"\"\"\n  odgi draw \\\n    -i $graph \\\n    -c $layoutGraph \\\n    -p ${graph}.draw_multiqc.png \\\n    -C \\\n    -w 20 \\\n    -H 1000 -t ${task.cpus}\n  odgi draw \\\n    -i $graph \\\n    -c $layoutGraph \\\n    -p ${graph}.draw.png \\\n    -H 100 -t ${task.cpus}\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "\"\"\"\n  odgi draw \\\n    -i $graph \\\n    -c $layoutGraph \\\n    -p ${graph}.draw_multiqc.png \\\n    -C \\\n    -w 20 \\\n    -H 1000 -t ${task.cpus}\n  odgi draw \\\n    -i $graph \\\n    -c $layoutGraph \\\n    -p ${graph}.draw.png \\\n    -H 100 -t ${task.cpus}\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "graph",
            "layoutGraph"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/odgi_draw\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "vg_deconstruct": {
        "name_process": "vg_deconstruct",
        "string_process": "\nprocess vg_deconstruct {\n  publishDir \"${params.outdir}/vg_deconstruct\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n  path(graph)\n\n  output:\n  path(\"${graph}.*.vcf\")\n\n  \"\"\"\n  for s in \\$(echo \"${params.vcf_spec}\" | tr ',' ' ');\n  do\n    ref=\\$(echo \"\\$s\" | cut -f 1 -d:)\n    delim=\\$(echo \"\\$s\" | cut -f 2 -d:)\n    vcf=\"${graph}\".\\$(echo \\$ref | tr '/|' '_').vcf\n    vg deconstruct -P \\$ref -H \\$delim -e -a -t \"${task.cpus}\" \"${graph}\" > \\$vcf\n  done\n  \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "\"\"\"\n  for s in \\$(echo \"${params.vcf_spec}\" | tr ',' ' ');\n  do\n    ref=\\$(echo \"\\$s\" | cut -f 1 -d:)\n    delim=\\$(echo \"\\$s\" | cut -f 2 -d:)\n    vcf=\"${graph}\".\\$(echo \\$ref | tr '/|' '_').vcf\n    vg deconstruct -P \\$ref -H \\$delim -e -a -t \"${task.cpus}\" \"${graph}\" > \\$vcf\n  done\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "VGE"
        ],
        "tools_url": [
            "https://bio.tools/VGE"
        ],
        "tools_dico": [
            {
                "name": "VGE",
                "uri": "https://bio.tools/VGE",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "Splitting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "File splitting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Virtual Grid Engine (VGE) is a kind of middleware for running bioinformatics software pipelines on large-scale supercomputers which do not support any grid engine survices. VGE employs master-worker model. It first reserves processors and/or cores by running the job which is parallelized by MPI, then asign divided small tasks onto its worker processes. VGE is written in python.",
                "homepage": "https://github.com/SatoshiITO/VGE"
            }
        ],
        "inputs": [
            "graph"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/vg_deconstruct\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "multiQC": {
        "name_process": "multiQC",
        "string_process": "\nprocess multiQC {\n  publishDir \"${params.outdir}\", mode: \"${params.publish_dir_mode}\"\n\n  input:\n  path odgi_stats\n  path odgi_viz\n  path odgi_draw\n  path(multiqc_config)\n\n  output:\n  path \"*multiqc_report.html\", emit: report\n  path \"*_data\"              , emit: data\n  path \"*_plots\"             , optional:true, emit: plots\n\n  \"\"\"\n  multiqc -s . -c ${multiqc_config}\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n  multiqc -s . -c ${multiqc_config}\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "odgi_stats",
            "odgi_viz",
            "odgi_draw",
            "multiqc_config"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}\", mode: \"${params.publish_dir_mode}\""
        ],
        "when": "",
        "stub": ""
    },
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n    publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.indexOf('.csv') > 0) filename\n                      else null\n        }\n\n    output:\n    file 'software_versions_mqc.yaml' into ch_software_versions_yaml\n    file 'software_versions.csv'\n\n    script:\n                                                                     \n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "FastQC",
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc",
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "ch_software_versions_yaml"
        ],
        "nb_outputs": 1,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.indexOf('.csv') > 0) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "output_documentation": {
        "name_process": "output_documentation",
        "string_process": "\nprocess output_documentation {\n    publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode\n\n    input:\n      file output_docs from ch_output_docs\n      file images from ch_output_docs_images\n\n    output:\n      file 'results_description.html'\n\n    script:\n    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_output_docs",
            "ch_output_docs_images"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "subwaystation__pangenome",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    }
}