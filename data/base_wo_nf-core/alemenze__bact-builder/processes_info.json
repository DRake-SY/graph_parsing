{
    "quast": {
        "name_process": "quast",
        "string_process": "\nprocess quast {\n    tag \"${meta}\"\n    label 'process_low'\n\n    publishDir \"${params.outdir}/quast/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"staphb/quast:5.0.2\"\n\n    input:\n        tuple val(meta), path(ont_assembly), path(ont_reads), path(illumina_r1), path(illumina_r2)\n    \n    output:\n        path(\"${meta}*\"), emit: qc\n\n    script:\n        \"\"\"\n        quast.py -o $meta -b --circos $ont_assembly\n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        quast.py -o $meta -b --circos $ont_assembly\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "ont_assembly",
            "ont_reads",
            "illumina_r1",
            "illumina_r2"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/quast/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"staphb/quast:5.0.2\""
        ],
        "when": "",
        "stub": ""
    },
    "random_subset": {
        "name_process": "random_subset",
        "string_process": "\nprocess random_subset {\n    tag \"${meta}\"\n    label 'process_medium'\n\n    publishDir \"${params.outdir}/rasusa/${replicate}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container 'mbhall88/rasusa:0.3.0'\n\n    input:\n        tuple val(meta), path(reads)\n        val(replicate)\n\n    output:\n        tuple val(meta), path(\"*.subsamp.fastq.gz\"), emit: fastq\n\n    script:\n\n        \"\"\"\n        rasusa --input $reads \\\\\n            --coverage $params.subset_cov --genome-size $params.genome_size \\\\\n            --output ${meta}.subsamp.fastq.gz\n        \"\"\"\n\n\n}",
        "nb_lignes_process": 27,
        "string_script": "        \"\"\"\n        rasusa --input $reads \\\\\n            --coverage $params.subset_cov --genome-size $params.genome_size \\\\\n            --output ${meta}.subsamp.fastq.gz\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "reads",
            "replicate"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/rasusa/${replicate}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container 'mbhall88/rasusa:0.3.0'"
        ],
        "when": "",
        "stub": ""
    },
    "canu_assembly": {
        "name_process": "canu_assembly",
        "string_process": "\nprocess canu_assembly {\n    tag \"${meta}\"\n    label 'process_overkill'\n\n    publishDir \"${params.outdir}/${meta}/canu/${replicate}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    container \"staphb/canu-racon\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(replicate)\n    \n    output:\n        tuple val(meta), path(\"${meta}_canu/*.contigs.fasta\"), emit: assembly\n        tuple val(meta), path(\"${meta}_canu/*.gfa\"), emit: gfa\n\n    script:\n        \"\"\"\n        canu -p ${meta}${replicate} -d ${meta}_canu genomeSize=${params.assembly_genome_size} useGrid=false -nanopore $reads\n        \"\"\"\n\n}",
        "nb_lignes_process": 27,
        "string_script": "        \"\"\"\n        canu -p ${meta}${replicate} -d ${meta}_canu genomeSize=${params.assembly_genome_size} useGrid=false -nanopore $reads\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "CANU"
        ],
        "tools_url": [
            "https://bio.tools/canu"
        ],
        "tools_dico": [
            {
                "name": "CANU",
                "uri": "https://bio.tools/canu",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De-novo assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De Bruijn graph"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "Sequence assembly (de-novo assembly)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "De-novo assembly tool for long read chemistry like Nanopore data and PacBio data.",
                "homepage": "https://github.com/marbl/canu"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "replicate"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_overkill'",
            "publishDir \"${params.outdir}/${meta}/canu/${replicate}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename } if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "container \"staphb/canu-racon\""
        ],
        "when": "",
        "stub": ""
    },
    "guppy_basecaller": {
        "name_process": "guppy_basecaller",
        "string_process": "\nprocess guppy_basecaller {\n    tag \"${reads}\"\n    \n    publishDir \"${params.outdir}/guppy/${reads}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    if (params.gpu_active){\n        container 'genomicpariscentre/guppy-gpu:4.2.2'\n    } else {\n        container 'genomicpariscentre/guppy:4.2.2'\n    }\n\n    input:\n        path(reads)\n\n    output:\n        path(\"fastq/*.fastq.gz\"), emit: fastq\n        path \"*.log\", emit: log\n        tuple path(\"*.txt\"),val(\"${reads}\"), emit: sequencing_summary\n        path \"*.js\", emit: telemetry\n\n    script:\n        flowcell=params.flowcell ? \"--flowcell $params.flowcell --kit $params.kit\": \"\"\n        barcode_kit=params.barcode_kit ? \"--barcode_kits '$params.barcode_kit'\": \"\"\n        cpu_opts=\"--num_callers 1 --cpu_threads_per_caller $task.cpus\"\n        if (params.gpu_active){\n            gpu_opts = \"--gpu_runners_per_device $params.gpus -x cuda:all:100% --chunk_size 1000 --chunks_per_runner 256\"\n        } else {\n            gpu_opts = \"\"\n        }\n        \"\"\"\n        guppy_basecaller --input_path $reads \\\\\n            -r \\\\\n            --save_path . \\\\\n            --records_per_fastq 0 \\\\\n            --compress_fastq \\\\\n            $flowcell \\\\\n            $barcode_kit \\\\\n            $cpu_opts \\\\\n            $gpu_opts\n            \n        # have to combine fastqs\n        mkdir fastq\n        if [ \"\\$(find . -type d -name \"barcode*\" )\" != \"\" ]\n        then\n            for dir in barcode*/\n            do\n                dir=\\${dir%*/}\n                cat \\$dir/*.fastq.gz > ./fastq/${reads}--\\$dir.fastq.gz\n            done\n        else\n            cat *.fastq.gz > ./fastq/output.fastq.gz\n        fi\n        \"\"\"\n}",
        "nb_lignes_process": 56,
        "string_script": "        flowcell=params.flowcell ? \"--flowcell $params.flowcell --kit $params.kit\": \"\"\n        barcode_kit=params.barcode_kit ? \"--barcode_kits '$params.barcode_kit'\": \"\"\n        cpu_opts=\"--num_callers 1 --cpu_threads_per_caller $task.cpus\"\n        if (params.gpu_active){\n            gpu_opts = \"--gpu_runners_per_device $params.gpus -x cuda:all:100% --chunk_size 1000 --chunks_per_runner 256\"\n        } else {\n            gpu_opts = \"\"\n        }\n        \"\"\"\n        guppy_basecaller --input_path $reads \\\\\n            -r \\\\\n            --save_path . \\\\\n            --records_per_fastq 0 \\\\\n            --compress_fastq \\\\\n            $flowcell \\\\\n            $barcode_kit \\\\\n            $cpu_opts \\\\\n            $gpu_opts\n            \n        # have to combine fastqs\n        mkdir fastq\n        if [ \"\\$(find . -type d -name \"barcode*\" )\" != \"\" ]\n        then\n            for dir in barcode*/\n            do\n                dir=\\${dir%*/}\n                cat \\$dir/*.fastq.gz > ./fastq/${reads}--\\$dir.fastq.gz\n            done\n        else\n            cat *.fastq.gz > ./fastq/output.fastq.gz\n        fi\n        \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${reads}\"",
            "publishDir \"${params.outdir}/guppy/${reads}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename } if (params.gpu_active){ container 'genomicpariscentre/guppy-gpu:4.2.2' } else { container 'genomicpariscentre/guppy:4.2.2' }"
        ],
        "when": "",
        "stub": ""
    },
    "Kraken2": {
        "name_process": "Kraken2",
        "string_process": "\nprocess Kraken2 {\n    tag \"${reads}\"\n    label 'process_high'\n\n    publishDir \"${params.outdir}/kraken2/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"alemenze/kraken2-docker\"\n\n    input:\n        tuple val(meta), path(reads)\n        path(db)\n        val(read_type)\n\n    output:\n        tuple val(meta), path(\"*kraken2.krona\"), emit: kraken2krona\n        path(\"*_kraken2.report\")\n        path(\"*_bracken.tsv\")\n\n    script:\n        if (read_type=='single') {\n            input=\"$reads\"\n            read_len='250'\n        }\n        if (read_type=='paired') {\n            input=\"--paired ${reads[0]} ${reads[1]}\"\n            read_len='150'\n        }\n        \"\"\"\n        kraken2 -db $db --report ${meta}_kraken2.report $input > ${meta}_kraken2.output\n        cut -f 2,3 ${meta}_kraken2.output > ${meta}_kraken2.krona\n\n        bracken -d $db -r $read_len -i ${meta}_kraken2.report -l $params.kraken_tax_level -o ${meta}_bracken.tsv\n        \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "        if (read_type=='single') {\n            input=\"$reads\"\n            read_len='250'\n        }\n        if (read_type=='paired') {\n            input=\"--paired ${reads[0]} ${reads[1]}\"\n            read_len='150'\n        }\n        \"\"\"\n        kraken2 -db $db --report ${meta}_kraken2.report $input > ${meta}_kraken2.output\n        cut -f 2,3 ${meta}_kraken2.output > ${meta}_kraken2.krona\n\n        bracken -d $db -r $read_len -i ${meta}_kraken2.report -l $params.kraken_tax_level -o ${meta}_bracken.tsv\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "kraken2",
            "Bracken"
        ],
        "tools_url": [
            "https://bio.tools/kraken2",
            "https://bio.tools/bracken"
        ],
        "tools_dico": [
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            },
            {
                "name": "Bracken",
                "uri": "https://bio.tools/bracken",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Microbial ecology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Environmental microbiology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Statistical method that computes the abundance of species in DNA sequences from a metagenomics sample.",
                "homepage": "https://ccb.jhu.edu/software/bracken/"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "db",
            "read_type"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${reads}\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}/kraken2/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"alemenze/kraken2-docker\""
        ],
        "when": "",
        "stub": ""
    },
    "Kraken2_db_build": {
        "name_process": "Kraken2_db_build",
        "string_process": "\nprocess Kraken2_db_build {\n\n    container \"alemenze/kraken2-docker\"\n    label 'process_medium'\n\n    input:\n        path(kraken)\n        val(kraken_name)\n\n    output:\n        path(\"./${kraken_name}/\", type:'dir', emit: kraken2_ch)\n    \n    script:\n        \"\"\"\n        mkdir -p $kraken_name && tar -xvzf $kraken -C $kraken_name\n        \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "        \"\"\"\n        mkdir -p $kraken_name && tar -xvzf $kraken -C $kraken_name\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "kraken",
            "kraken_name"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "container \"alemenze/kraken2-docker\"",
            "label 'process_medium'"
        ],
        "when": "",
        "stub": ""
    },
    "Krona": {
        "name_process": "Krona",
        "string_process": "\nprocess Krona {\n\n    container \"alemenze/kraken2-docker\"\n    label 'process_low'\n\n    publishDir \"${params.outdir}/kraken2_krona/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n    \n    input:\n        tuple val(meta), path(krona_in)\n    \n    output:\n        path(\"*_taxonomy_krona.html\")\n\n    script:\n        \"\"\"\n        ktImportTaxonomy -o ${meta}_kraken2_taxonomy_krona.html $krona_in\n        \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "        \"\"\"\n        ktImportTaxonomy -o ${meta}_kraken2_taxonomy_krona.html $krona_in\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "krona_in"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "container \"alemenze/kraken2-docker\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/kraken2_krona/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }"
        ],
        "when": "",
        "stub": ""
    },
    "nanoplot": {
        "name_process": "nanoplot",
        "string_process": "\nprocess nanoplot {\n    tag \"${sequencing_summary}\"\n    label 'process_low'\n\n    publishDir \"${params.outdir}/nanoplot/${type}/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n    \n    container \"staphb/nanoplot:1.33.0\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(type)\n    \n    output:\n        path \"*.{png, html, txt, log}\", emit: report\n    \n    script:\n        \"\"\"\n        NanoPlot --fastq $reads\n        \"\"\"\n \n}",
        "nb_lignes_process": 23,
        "string_script": "        \"\"\"\n        NanoPlot --fastq $reads\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "reads",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${sequencing_summary}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/nanoplot/${type}/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"staphb/nanoplot:1.33.0\""
        ],
        "when": "",
        "stub": ""
    },
    "make_cogs": {
        "name_process": "make_cogs",
        "string_process": "\nprocess make_cogs{\n    tag \"${meta}\"\n    label 'process_medium'\n\n    container \"quay.io/fhcrc-microbiome/anvio:7\"\n\n    output:\n        path(\"cog_dir.tar\"), emit: cog_index\n    \n                                                                                       \n    script:\n        \"\"\"\n        anvi-setup-ncbi-cogs --num-threads ${task.cpus} --cog-data-dir cog_dir --just-do-it --reset\n        tar cvf cog_dir.tar cog_dir\n        \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "        \"\"\"\n        anvi-setup-ncbi-cogs --num-threads ${task.cpus} --cog-data-dir cog_dir --just-do-it --reset\n        tar cvf cog_dir.tar cog_dir\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_medium'",
            "container \"quay.io/fhcrc-microbiome/anvio:7\""
        ],
        "when": "",
        "stub": ""
    },
    "make_genome_db": {
        "name_process": "make_genome_db",
        "string_process": "\nprocess make_genome_db{\n    tag \"${meta}\"\n    label 'process_low'\n\n    publishDir \"${params.outdir}/anvio/dbs/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/fhcrc-microbiome/anvio:7\"\n\n    input:\n        tuple val(meta), path(assembly)\n    \n    output:\n        tuple val(meta), path(\"*.db\"), emit: db\n    \n    script:\n        \"\"\"\n        anvi-gen-contigs-database -f $assembly -n ${meta} -o ${meta}.db\n        \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        anvi-gen-contigs-database -f $assembly -n ${meta} -o ${meta}.db\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "assembly"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/anvio/dbs/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/fhcrc-microbiome/anvio:7\""
        ],
        "when": "",
        "stub": ""
    },
    "annotate_cogs": {
        "name_process": "annotate_cogs",
        "string_process": "\nprocess annotate_cogs{\n    tag \"${meta}\"\n    label 'process_medium'\n\n    publishDir \"${params.outdir}/anvio/db_cogs/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/fhcrc-microbiome/anvio:7\"\n\n    input:\n        tuple val(meta), path(db)\n        path(cogs)\n\n    output:\n        tuple val(meta), path('$db'), emit: db_cog\n        path('*.txt'), emit: db_txt\n    \n    script:\n        \"\"\"\n        tar xvf $cogs\n        anvi-run-ncbi-cogs -c $db --num-threads ${task.cpus} --cog-data-dir cog_dir\n        echo -e ${meta},${meta}.db | tr ',' '\\\\t' > ${meta}.txt\n        \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "        \"\"\"\n        tar xvf $cogs\n        anvi-run-ncbi-cogs -c $db --num-threads ${task.cpus} --cog-data-dir cog_dir\n        echo -e ${meta},${meta}.db | tr ',' '\\\\t' > ${meta}.txt\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "db",
            "cogs"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/anvio/db_cogs/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/fhcrc-microbiome/anvio:7\""
        ],
        "when": "",
        "stub": ""
    },
    "combine": {
        "name_process": "combine",
        "string_process": "\nprocess combine{\n    label 'process_medium'\n\n    publishDir \"${params.outdir}/anvio/db_combine/\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/fhcrc-microbiome/anvio:7\"\n\n    input:\n        tuple val(meta), path(db)\n        path db_txt\n    \n    output:\n        path('SAMPLES-GENOMES.db'), emit: combined\n        path('external_genomes.txt'), emit: external\n        \n    script:\n        \"\"\"\n        echo -e \"name\\\\tcontigs_db_path\" > external-genomes.txt\n        for txt in $db_txt; do cat \\$txt; done >> external_genomes.txt\n        anvi-gen-genomes-storage -e external-genomes -o SAMPLES-GENOMES.db\n        \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "        \"\"\"\n        echo -e \"name\\\\tcontigs_db_path\" > external-genomes.txt\n        for txt in $db_txt; do cat \\$txt; done >> external_genomes.txt\n        anvi-gen-genomes-storage -e external-genomes -o SAMPLES-GENOMES.db\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "db",
            "db_txt"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/anvio/db_combine/\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/fhcrc-microbiome/anvio:7\""
        ],
        "when": "",
        "stub": ""
    },
    "pangenome": {
        "name_process": "pangenome",
        "string_process": "\nprocess pangenome{\n    label 'process_high'\n\n    publishDir \"${params.outdir}/anvio/pangenome/\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/fhcrc-microbiome/anvio:7\"\n\n    input:\n        path(combined)\n    \n    output:\n        path('*-PAN.db'), emit: pan_db\n        \n    script:\n        \"\"\"\n        anvi-pan-genome -g $combined \\\n            --project-name $params.project_name \\\n            --output-dir ./ \\\n            --num-threads ${task.cpus} \\\n            --use-ncbi-blast \\\n            --min-occurence $params.min_occurence \\\n            --minbit $params.minbit \\\n            --distance $params.distance \\\n            --linkage $params.linkage \\\n            --mcl-inflation $params.mcl\n        \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "        \"\"\"\n        anvi-pan-genome -g $combined \\\n            --project-name $params.project_name \\\n            --output-dir ./ \\\n            --num-threads ${task.cpus} \\\n            --use-ncbi-blast \\\n            --min-occurence $params.min_occurence \\\n            --minbit $params.minbit \\\n            --distance $params.distance \\\n            --linkage $params.linkage \\\n            --mcl-inflation $params.mcl\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "combined"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "label 'process_high'",
            "publishDir \"${params.outdir}/anvio/pangenome/\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/fhcrc-microbiome/anvio:7\""
        ],
        "when": "",
        "stub": ""
    },
    "summarize": {
        "name_process": "summarize",
        "string_process": "\nprocess summarize{\n    label 'process_medium'\n\n    publishDir \"${params.outdir}/anvio/pangenome/\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/fhcrc-microbiome/anvio:7\"\n\n    input:\n        path(pan_db)\n        path(combined)\n\n    output:\n        path(\"PROJECT_SUMMARY\"), emit: summary\n\n    script:\n        \"\"\"\n        anvi-script-add-default-collection \\\n            -p $pan_db \\\n            -c $combined \\\n            -b $params.bin_name \\\n            -C $params.collection_name \n\n        anvi-summarize -p $pan_db \\\n            -g $combined \\\n            -C $params.collection_name \\\n            -o PROJECT_SUMMARY\n        \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        \"\"\"\n        anvi-script-add-default-collection \\\n            -p $pan_db \\\n            -c $combined \\\n            -b $params.bin_name \\\n            -C $params.collection_name \n\n        anvi-summarize -p $pan_db \\\n            -g $combined \\\n            -C $params.collection_name \\\n            -o PROJECT_SUMMARY\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pan_db",
            "combined"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/anvio/pangenome/\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/fhcrc-microbiome/anvio:7\""
        ],
        "when": "",
        "stub": ""
    },
    "raven_assembly": {
        "name_process": "raven_assembly",
        "string_process": "\nprocess raven_assembly {\n    tag \"${meta}\"\n    label 'process_overkill'\n\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    publishDir \"${params.outdir}/${meta}/raven/${replicate}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/biocontainers/raven-assembler:1.3.0--h8b12597_0\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(replicate)\n    \n    output:\n        tuple val(meta), path(\"*.fasta\"), emit: assembly\n\n    script:\n        \"\"\"\n        raven -t $task.cpus $reads > raven_${meta}${replicate}.fasta\n        \"\"\"\n\n}",
        "nb_lignes_process": 27,
        "string_script": "        \"\"\"\n        raven -t $task.cpus $reads > raven_${meta}${replicate}.fasta\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "reads",
            "replicate"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_overkill' if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "publishDir \"${params.outdir}/${meta}/raven/${replicate}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/biocontainers/raven-assembler:1.3.0--h8b12597_0\""
        ],
        "when": "",
        "stub": ""
    },
    "bwa_align": {
        "name_process": "bwa_align",
        "string_process": "\nprocess bwa_align {\n    tag \"${meta}\"\n    label 'process_high'\n\n    container \"alemenze/bwa-tools\"\n\n    input:\n        tuple val(meta), path(ont_assembly), path(ont_reads), path(illumina_r1), path(illumina_r2)\n        tuple val(meta), path(reads)\n    \n    output:\n        tuple val(meta), path(\"*.sam\"),     emit: aligned_sam\n        tuple val(meta), path('*.sorted.{bam,bam.bai}'), emit: aligned_bams\n        tuple val(meta), path('*.sorted.bam'), emit: aligned_bam\n        tuple val(meta), path(\"*{flagstat,idxstats,stats}\"),   emit: logs\n\n    script:\n        \"\"\"\n        mkdir bwa_index\n        bwa index $ont_assembly -p bwa_index/${ont_assembly.baseName}\n\n        INDEX=`find -L ./bwa_index/ -name \"*.amb\" | sed 's/.amb//'`\n        bwa mem -t $task.cpus \\$INDEX $reads > ${meta}.sam\n\n        samtools view -hSbo ${meta}.bam ${meta}.sam\n        samtools sort ${meta}.bam -o ${meta}.sorted.bam\n        samtools index ${meta}.sorted.bam\n        samtools flagstat ${meta}.sorted.bam > ${meta}.sorted.bam.flagstat\n        samtools idxstats ${meta}.sorted.bam > ${meta}.sorted.bam.idxstats\n        samtools stats ${meta}.sorted.bam > ${meta}.sorted.bam.stats\n        \"\"\"\n\n}",
        "nb_lignes_process": 32,
        "string_script": "        \"\"\"\n        mkdir bwa_index\n        bwa index $ont_assembly -p bwa_index/${ont_assembly.baseName}\n\n        INDEX=`find -L ./bwa_index/ -name \"*.amb\" | sed 's/.amb//'`\n        bwa mem -t $task.cpus \\$INDEX $reads > ${meta}.sam\n\n        samtools view -hSbo ${meta}.bam ${meta}.sam\n        samtools sort ${meta}.bam -o ${meta}.sorted.bam\n        samtools index ${meta}.sorted.bam\n        samtools flagstat ${meta}.sorted.bam > ${meta}.sorted.bam.flagstat\n        samtools idxstats ${meta}.sorted.bam > ${meta}.sorted.bam.idxstats\n        samtools stats ${meta}.sorted.bam > ${meta}.sorted.bam.stats\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "meta",
            "ont_assembly",
            "ont_reads",
            "illumina_r1",
            "illumina_r2",
            "meta",
            "reads"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_high'",
            "container \"alemenze/bwa-tools\""
        ],
        "when": "",
        "stub": ""
    },
    "minimap2": {
        "name_process": "minimap2",
        "string_process": "\nprocess minimap2 {\n    tag \"${meta}\"\n    label 'process_high'\n\n    container \"staphb/minimap2:2.21\"\n\n    input:\n        tuple val(meta), path(ont_assembly), path(ont_reads)\n        val(iteration)\n    \n    output:\n        tuple val(meta), path(\"${meta}_${iteration}.sam\"),     emit: aligned_sam\n\n    script:\n        \"\"\"\n        minimap2 -ax map-ont -t $task.cpus $ont_assembly $ont_reads > ${meta}_${iteration}.sam\n        \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "        \"\"\"\n        minimap2 -ax map-ont -t $task.cpus $ont_assembly $ont_reads > ${meta}_${iteration}.sam\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Minimap2"
        ],
        "tools_url": [
            "https://bio.tools/minimap2"
        ],
        "tools_dico": [
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            }
        ],
        "inputs": [
            "meta",
            "ont_assembly",
            "ont_reads",
            "iteration"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_high'",
            "container \"staphb/minimap2:2.21\""
        ],
        "when": "",
        "stub": ""
    },
    "racon": {
        "name_process": "racon",
        "string_process": "\nprocess racon {\n    tag \"${meta}\"\n    label 'process_high'\n\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    publishDir \"${params.outdir}/racon/${meta}/${iteration}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"staphb/racon:1.4.20\"\n\n    input:\n        tuple val(meta), path(ont_assembly), path(ont_reads), path(aligned_sam)\n        val(iteration)\n    \n    output:\n        tuple val(meta), path(\"*.fasta\"), emit: racon_alignment\n    \n    script:\n        \"\"\"\n        racon -m 8 -x -6 -g -8 -w 500 -t $task.cpus $ont_reads $aligned_sam $ont_assembly > ${meta}_${iteration}_racon.fasta\n        \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "        \"\"\"\n        racon -m 8 -x -6 -g -8 -w 500 -t $task.cpus $ont_reads $aligned_sam $ont_assembly > ${meta}_${iteration}_racon.fasta\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Racon"
        ],
        "tools_url": [
            "https://bio.tools/Racon"
        ],
        "tools_dico": [
            {
                "name": "Racon",
                "uri": "https://bio.tools/Racon",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plants"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Botany"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Mapping assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Sequence assembly (mapping assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Possibility to Use Oxford Nanopore Technology | Ultrafast consensus module for raw de novo genome assembly of long uncorrected reads. http://genome.cshlp.org/content/early/2017/01/18/gr.214270.116 Note: This was the original repository which will no longer be officially maintained. Please use the new official repository here: | Racon is intended as a standalone consensus module to correct raw contigs generated by rapid assembly methods which do not include a consensus step | Consensus module for raw de novo DNA assembly of long uncorrected reads",
                "homepage": "https://github.com/isovic/racon"
            }
        ],
        "inputs": [
            "meta",
            "ont_assembly",
            "ont_reads",
            "aligned_sam",
            "iteration"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_high' if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "publishDir \"${params.outdir}/racon/${meta}/${iteration}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"staphb/racon:1.4.20\""
        ],
        "when": "",
        "stub": ""
    },
    "pilon": {
        "name_process": "pilon",
        "string_process": "\nprocess pilon {\n    tag \"${meta}\"\n    label 'process_high'\n\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    publishDir \"${params.outdir}/pilon/${meta}/${iteration}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"staphb/pilon:1.23.0\"\n\n    input:\n        tuple val(meta), path(ont_assembly), path(ont_reads), path(illumina_r1), path(illumina_r2)\n        tuple val(meta), path(aligned_bam)\n        val(iteration)\n    \n    output:\n        tuple val(meta), path(\"*.fasta\"), emit: pilon_alignment\n    \n    script:\n        \"\"\"\n        pilon --genome $ont_assembly --threads $task.cpus --frags $aligned_bam --changes --output ${meta}_${iteration}_pilon --fix all\n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        \"\"\"\n        pilon --genome $ont_assembly --threads $task.cpus --frags $aligned_bam --changes --output ${meta}_${iteration}_pilon --fix all\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "pilon"
        ],
        "tools_url": [
            "https://bio.tools/pilon"
        ],
        "tools_dico": [
            {
                "name": "pilon",
                "uri": "https://bio.tools/pilon",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Read alignment analysis to diagnose, report, and automatically improve de novo genome assemblies.",
                "homepage": "http://www.broadinstitute.org/software/pilon/"
            }
        ],
        "inputs": [
            "meta",
            "ont_assembly",
            "ont_reads",
            "illumina_r1",
            "illumina_r2",
            "meta",
            "aligned_bam",
            "iteration"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_high' if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "publishDir \"${params.outdir}/pilon/${meta}/${iteration}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"staphb/pilon:1.23.0\""
        ],
        "when": "",
        "stub": ""
    },
    "filtlong": {
        "name_process": "filtlong",
        "string_process": "\nprocess filtlong{\n    tag \"${meta}\"\n    label 'process_medium'\n\n    publishDir \"${params.outdir}/filtlong/\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"nanozoo/filtlong:0.2.0--0c4cbe3\"\n\n    input:\n        tuple val(meta), path(reads)\n    \n    output:\n        tuple val(meta), path(\"*.trim.fastq.gz\"), emit: fastq\n    \n    script:\n        \"\"\"\n        filtlong --min_length $params.min_length --min_mean_q $params.min_mean_q $reads | gzip > ${meta}.trim.fastq.gz\n        \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        filtlong --min_length $params.min_length --min_mean_q $params.min_mean_q $reads | gzip > ${meta}.trim.fastq.gz\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Filtlong"
        ],
        "tools_url": [
            "https://bio.tools/Filtlong"
        ],
        "tools_dico": [
            {
                "name": "Filtlong",
                "uri": "https://bio.tools/Filtlong",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0798",
                            "term": "Mobile genetic elements"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3482",
                                    "term": "Antimicrobial resistance prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3472",
                                    "term": "k-mer counting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "Splitting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "File splitting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Complete hybrid genome assembly of clinical multidrug-resistant Bacteroides fragilis isolates enables comprehensive identification of antimicrobial-resistance genes and plasmids.\n\nquality filtering tool for long reads.\n\nFiltlong is a tool for filtering long reads by quality. It can take a set of long reads and produce a smaller, better subset. It uses both read length (longer is better) and read identity (higher is better) when choosing which reads pass the filter.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Unicycler' (bio.tools/unicycler), 'Canu-corrected ONT', 'AMR', 'fragilis'",
                "homepage": "https://github.com/rrwick/Filtlong"
            }
        ],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/filtlong/\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"nanozoo/filtlong:0.2.0--0c4cbe3\""
        ],
        "when": "",
        "stub": ""
    },
    "trycycler": {
        "name_process": "trycycler",
        "string_process": "\nprocess trycycler{\n    tag \"${meta}\"\n    label 'process_overkill_long'\n\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    publishDir \"${params.outdir}/trycycler/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"alemenze/trycycler-docker\"\n\n    input:\n        tuple val(meta), path(input_reads), path(assemblies)\n        \n    output:\n        tuple val(meta), path(\"trycycler/cluster_001\", type:'dir'), emit: cluster_dirs\n        path(\"trycycler/**/**/*.fasta\"), emit: out_files\n        path(\"trycycler/*newick\"), emit: out_trees\n        tuple val(meta), path(\"${meta}_consensus.fasta\"), emit: consensus\n    \n    script:\n        \"\"\"\n        trycycler cluster --assemblies $assemblies --reads $input_reads --min_contig_depth $params.min_contig_depth --out_dir ./trycycler\n        trycycler reconcile --reads $input_reads --cluster_dir ./trycycler/cluster_001/ --max_length_diff $params.max_length_diff --min_identity $params.min_identity --max_add_seq $params.max_add_seq --max_indel_size $params.max_indel_size\n        trycycler msa --cluster_dir ./trycycler/cluster_001/\n        trycycler partition --reads $input_reads --cluster_dirs ./trycycler/cluster_001/\n        trycycler consensus --cluster_dir ./trycycler/cluster_001/\n        cat ./trycycler/cluster_001//7_final_consensus.fasta > ${meta}_consensus.fasta\n        \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "        \"\"\"\n        trycycler cluster --assemblies $assemblies --reads $input_reads --min_contig_depth $params.min_contig_depth --out_dir ./trycycler\n        trycycler reconcile --reads $input_reads --cluster_dir ./trycycler/cluster_001/ --max_length_diff $params.max_length_diff --min_identity $params.min_identity --max_add_seq $params.max_add_seq --max_indel_size $params.max_indel_size\n        trycycler msa --cluster_dir ./trycycler/cluster_001/\n        trycycler partition --reads $input_reads --cluster_dirs ./trycycler/cluster_001/\n        trycycler consensus --cluster_dir ./trycycler/cluster_001/\n        cat ./trycycler/cluster_001//7_final_consensus.fasta > ${meta}_consensus.fasta\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "input_reads",
            "assemblies"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_overkill_long' if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "publishDir \"${params.outdir}/trycycler/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"alemenze/trycycler-docker\""
        ],
        "when": "",
        "stub": ""
    },
    "medaka": {
        "name_process": "medaka",
        "string_process": "\nprocess medaka {\n    tag \"${meta}\"\n    label 'process_high'\n\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    publishDir \"${params.outdir}/medaka/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"staphb/medaka:1.2.0\"\n\n    input:\n        tuple val(meta), path(ont_assembly), path(ont_reads)\n    \n    output:\n        tuple val(meta), path(\"${meta}/*consensus.fasta\"), emit: consensus\n    \n    script:\n        \"\"\"\n        medaka_consensus -i $ont_reads -d $ont_assembly -o ${meta} -t $task.cpus -m r941_min_high_g360\n        \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "        \"\"\"\n        medaka_consensus -i $ont_reads -d $ont_assembly -o ${meta} -t $task.cpus -m r941_min_high_g360\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "ont_assembly",
            "ont_reads"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_high' if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "publishDir \"${params.outdir}/medaka/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"staphb/medaka:1.2.0\""
        ],
        "when": "",
        "stub": ""
    },
    "trimgalore": {
        "name_process": "trimgalore",
        "string_process": "\nprocess trimgalore {\n    tag \"${meta}\"\n    label 'process_medium'\n\n    container \"quay.io/biocontainers/trim-galore:0.6.6--0\"\n\n    input:\n        tuple val(meta), path(ont_assembly), path(ont_reads), path(illumina_r1), path(illumina_r2)\n\n    output:\n        tuple val(meta), path(\"*.fq.gz\"),       emit: reads\n        tuple val(meta), path(\"*report.txt\"),   emit: log\n        tuple val(meta), path(\"*.html\"),        emit: html \n        tuple val(meta), path(\"*.zip\") ,        emit: zip\n\n    script:\n        \"\"\"\n        trim_galore \\\\\n            --cores ${task.cpus} \\\\\n            --fastqc \\\\\n            --paired \\\\\n            --gzip \\\\\n            $illumina_r1 $illumina_r2\n        \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "        \"\"\"\n        trim_galore \\\\\n            --cores ${task.cpus} \\\\\n            --fastqc \\\\\n            --paired \\\\\n            --gzip \\\\\n            $illumina_r1 $illumina_r2\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "ont_assembly",
            "ont_reads",
            "illumina_r1",
            "illumina_r2"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_medium'",
            "container \"quay.io/biocontainers/trim-galore:0.6.6--0\""
        ],
        "when": "",
        "stub": ""
    },
    "pycoqc": {
        "name_process": "pycoqc",
        "string_process": "\nprocess pycoqc {\n    tag \"${sequencing_summary}\"\n    label 'process_low'\n\n    publishDir \"${params.outdir}/pycoqc/${run}/${type}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/biocontainers/pycoqc:2.5.0.23--py_0\"\n\n    input:\n        tuple path(sequencing_summary), val(run)\n        val(type)\n\n    output:\n        path '*.html', emit: report\n\n    script:    \n        \"\"\"\n        pycoQC --summary_file $sequencing_summary --html_outfile pycoqc_report.html\n        \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        pycoQC --summary_file $sequencing_summary --html_outfile pycoqc_report.html\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "run",
            "sequencing_summary",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${sequencing_summary}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/pycoqc/${run}/${type}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/biocontainers/pycoqc:2.5.0.23--py_0\""
        ],
        "when": "",
        "stub": ""
    },
    "flye_assembly": {
        "name_process": "flye_assembly",
        "string_process": "\nprocess flye_assembly {\n    tag \"${meta}\"\n    label 'process_overkill'\n\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    publishDir \"${params.outdir}/${meta}/flye/${replicate}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"staphb/flye:2.8\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(replicate)\n    \n    output:\n        tuple val(meta), path(\"*.fasta\"), emit: assembly\n        tuple val(meta), path(\"${meta}_flye/*.gfa\"), emit: gfa\n    \n    script:\n        \"\"\"\n        flye --nano-raw $reads --genome-size $params.assembly_genome_size --plasmids --o ${meta}_flye --threads $task.cpus\n        mv ${meta}_flye/assembly.fasta flye_${meta}${replicate}.fasta\n        \"\"\"\n\n}",
        "nb_lignes_process": 29,
        "string_script": "        \"\"\"\n        flye --nano-raw $reads --genome-size $params.assembly_genome_size --plasmids --o ${meta}_flye --threads $task.cpus\n        mv ${meta}_flye/assembly.fasta flye_${meta}${replicate}.fasta\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "Flye"
        ],
        "tools_url": [
            "https://bio.tools/Flye"
        ],
        "tools_dico": [
            {
                "name": "Flye",
                "uri": "https://bio.tools/Flye",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Mapping assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De-novo assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Sequence assembly (mapping assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De Bruijn graph"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "Sequence assembly (de-novo assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PB / ONT reads as input and outputs polished contigs.",
                "homepage": "https://github.com/fenderglass/Flye"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "replicate"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_overkill' if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "publishDir \"${params.outdir}/${meta}/flye/${replicate}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"staphb/flye:2.8\""
        ],
        "when": "",
        "stub": ""
    },
    "miniasm_assembly": {
        "name_process": "miniasm_assembly",
        "string_process": "\nprocess miniasm_assembly {\n    tag \"${meta}\"\n    label 'process_overkill'\n\n    if (!workflow.profile=='google' && !workflow.profile=='slurm'){\n        maxForks 1\n    }\n\n    publishDir \"${params.outdir}/${meta}/miniasm/${replicate}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"alemenze/ont_minis\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(replicate)\n\n    output:\n        tuple val(meta), path('*.fasta'), emit: assembly\n        tuple val(meta), path('*.assembly.gfa'), emit: gfa\n    \n    script:\n        \"\"\"\n        minimap2 -x ava-ont -t $task.cpus $reads $reads > overlaps.paf\n        miniasm -f $reads overlaps.paf > unpolished.gfa\n        minipolish --threads $task.cpus $reads unpolished.gfa > miniasm_${meta}${replicate}.assembly.gfa\n        awk '/^S/{print \">\"\\$2\"\\\\n\"\\$3}' miniasm_${meta}${replicate}.assembly.gfa > miniasm_${meta}${replicate}.assembly.fasta\n        \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        \"\"\"\n        minimap2 -x ava-ont -t $task.cpus $reads $reads > overlaps.paf\n        miniasm -f $reads overlaps.paf > unpolished.gfa\n        minipolish --threads $task.cpus $reads unpolished.gfa > miniasm_${meta}${replicate}.assembly.gfa\n        awk '/^S/{print \">\"\\$2\"\\\\n\"\\$3}' miniasm_${meta}${replicate}.assembly.gfa > miniasm_${meta}${replicate}.assembly.fasta\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "Minimap2"
        ],
        "tools_url": [
            "https://bio.tools/minimap2"
        ],
        "tools_dico": [
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "replicate"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_overkill' if (!workflow.profile=='google' && !workflow.profile=='slurm'){ maxForks 1 }",
            "publishDir \"${params.outdir}/${meta}/miniasm/${replicate}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"alemenze/ont_minis\""
        ],
        "when": "",
        "stub": ""
    },
    "fastp": {
        "name_process": "fastp",
        "string_process": "\nprocess fastp {\n    tag \"${meta}\"\n    label 'process_low'\n\n    publishDir \"${params.outdir}/fastp/${type}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"biocontainers/fastp:v0.20.1_cv1\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(type)\n    \n    output:\n        tuple val(meta), path(\"*.html\"), emit: html\n\n    script:\n        \"\"\"\n        fastp -i $reads -h ${meta}.html -A -L -Q \n        \"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "        \"\"\"\n        fastp -i $reads -h ${meta}.html -A -L -Q \n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__bact-builder",
        "directive": [
            "tag \"${meta}\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/fastp/${type}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"biocontainers/fastp:v0.20.1_cv1\""
        ],
        "when": "",
        "stub": ""
    }
}