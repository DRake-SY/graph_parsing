{
    "sort_compress": {
        "name_process": "sort_compress",
        "string_process": "\nprocess sort_compress {\n    publishDir \"${params.outdir}/bcftools_site_metrics_subcols/\", mode: params.publish_dir_mode\n\n    input:\n    set val(region), file(bcftools_site_metrics_subcols) from ch_bcftools_site_metrics_subcols\n\n\n    output:\n    set val(region),file (\"BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz\"), file(\"BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz.tbi\") into ch_sort_compress\n\n    script:\n\n    \"\"\"\n    sort -k2 -n ${bcftools_site_metrics_subcols} > BCFtools_site_metrics_SUBCOLS${region}_sorted.txt\n    bgzip -f BCFtools_site_metrics_SUBCOLS${region}_sorted.txt && \\\n    tabix -s1 -b2 -e2 BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    sort -k2 -n ${bcftools_site_metrics_subcols} > BCFtools_site_metrics_SUBCOLS${region}_sorted.txt\n    bgzip -f BCFtools_site_metrics_SUBCOLS${region}_sorted.txt && \\\n    tabix -s1 -b2 -e2 BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_bcftools_site_metrics_subcols"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_sort_compress"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/bcftools_site_metrics_subcols/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "filter_regions": {
        "name_process": "filter_regions",
        "string_process": "\nprocess filter_regions {\n    publishDir \"${params.outdir}/regionsFiltered/\", mode: params.publish_dir_mode\n\n    input:\n    set val(region), file(bcf), file(index) from ch_bcfs\n    set val(region2),file (\"BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz\"), file(\"BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz.tbi\") from ch_sort_compress\n\n\n    output:\n    set val(region), file (\"${region}_regionsFiltered.bcf\") into ch_regions_filtered\n\n    script:\n    \"\"\"\n    bcftools view ${bcf} \\\n    -T BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz  \\\n    -Ob \\\n    -o ${region}_regionsFiltered.bcf\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    bcftools view ${bcf} \\\n    -T BCFtools_site_metrics_SUBCOLS${region}_sorted.txt.gz  \\\n    -Ob \\\n    -o ${region}_regionsFiltered.bcf\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_bcfs",
            "ch_sort_compress"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_regions_filtered"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/regionsFiltered/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "further_filtering": {
        "name_process": "further_filtering",
        "string_process": "\nprocess further_filtering {\n    publishDir \"${params.outdir}/further_filtering/\", mode: params.publish_dir_mode\n\n    input:\n    set val(region), file(bcf_filtered) from ch_regions_filtered\n\n    output:\n    set val(region), file(\"MichiganLD_regionsFiltered_${region}.bcf\"), file(\"MAF_filtered_1kp3intersect_${region}.txt\") into ch_further_filtering\n\n    script:\n    \"\"\"\n    bcftools view ${bcf_filtered} \\\n    -i 'INFO/OLD_MULTIALLELIC=\".\" & INFO/OLD_CLUMPED=\".\"' \\\n    -v snps  | \\\n    bcftools annotate \\\n    --set-id '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC' | \\\n    bcftools +fill-tags -Ob \\\n    -o MichiganLD_regionsFiltered_${region}.bcf \\\n    -- -t MAF\n    #Produce filtered txt file\n    bcftools query MichiganLD_regionsFiltered_${region}.bcf \\\n    -i 'MAF[0]>0.01' -f '%CHROM\\\\t%POS\\\\t%REF\\\\t%ALT\\\\t%MAF\\\\n' | \\\n    awk -F \"\\t\" '{ if((\\$5 == \"G\" && \\$6 == \"C\") || (\\$6 == \"G\" && \\$5 == \"C\") || (\\$5 == \"A\" && \\$6 == \"T\") || (\\$6 == \"A\" && \\$5 == \"T\")) {next} { print \\$0} }' \\\n    > MAF_filtered_1kp3intersect_${region}.txt\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    bcftools view ${bcf_filtered} \\\n    -i 'INFO/OLD_MULTIALLELIC=\".\" & INFO/OLD_CLUMPED=\".\"' \\\n    -v snps  | \\\n    bcftools annotate \\\n    --set-id '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC' | \\\n    bcftools +fill-tags -Ob \\\n    -o MichiganLD_regionsFiltered_${region}.bcf \\\n    -- -t MAF\n    #Produce filtered txt file\n    bcftools query MichiganLD_regionsFiltered_${region}.bcf \\\n    -i 'MAF[0]>0.01' -f '%CHROM\\\\t%POS\\\\t%REF\\\\t%ALT\\\\t%MAF\\\\n' | \\\n    awk -F \"\\t\" '{ if((\\$5 == \"G\" && \\$6 == \"C\") || (\\$6 == \"G\" && \\$5 == \"C\") || (\\$5 == \"A\" && \\$6 == \"T\") || (\\$6 == \"A\" && \\$5 == \"T\")) {next} { print \\$0} }' \\\n    > MAF_filtered_1kp3intersect_${region}.txt\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_regions_filtered"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_further_filtering"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/further_filtering/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "create_final_king_vcf": {
        "name_process": "create_final_king_vcf",
        "string_process": "\nprocess create_final_king_vcf {\n    publishDir \"${params.outdir}/create_final_king_vcf/\", mode: params.publish_dir_mode\n\n    input:\n    set val(region), file(\"MichiganLD_regionsFiltered_${region}.bcf\"), file(\"MAF_filtered_1kp3intersect_${region}.txt\") from ch_further_filtering\n    file agg_samples_txt from ch_inputFinalPlatekeys\n\n    output:\n    set val(region), file(\"${region}_filtered.vcf.gz\"), file(\"${region}_filtered.vcf.gz.tbi\") into ch_create_final_king_vcf\n    file \"${region}_filtered.vcf.gz\" into ch_vcfs_create_final_king_vcf\n    file \"${region}_filtered.vcf.gz.tbi\" into ch_tbi_create_final_king_vcf\n    script:\n    \"\"\"\n    #Now filter down our file to just samples we want in our GRM. This removes any withdrawals that we learned of during the process of aggregation\n    #Store the header\n    bcftools view \\\n    -S ${agg_samples_txt} \\\n    --force-samples \\\n    -h MichiganLD_regionsFiltered_${region}.bcf \\\n    > ${region}_filtered.vcf\n\n    #Then match against all variant cols in our subsetted bcf to our maf filtered, intersected sites and only print those that are in the variant file.\n    #Then append this to the stored header, SNPRelate needs vcfs so leave as is\n    bcftools view \\\n    -H MichiganLD_regionsFiltered_${region}.bcf \\\n    -S ${agg_samples_txt} \\\n    --force-samples \\\n    | awk -F '\\t' '${awk_expr_create_final_king_vcf_1}' MAF_filtered_1kp3intersect_${region}.txt - >> ${region}_filtered.vcf\n    bgzip ${region}_filtered.vcf\n    tabix ${region}_filtered.vcf.gz\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    #Now filter down our file to just samples we want in our GRM. This removes any withdrawals that we learned of during the process of aggregation\n    #Store the header\n    bcftools view \\\n    -S ${agg_samples_txt} \\\n    --force-samples \\\n    -h MichiganLD_regionsFiltered_${region}.bcf \\\n    > ${region}_filtered.vcf\n\n    #Then match against all variant cols in our subsetted bcf to our maf filtered, intersected sites and only print those that are in the variant file.\n    #Then append this to the stored header, SNPRelate needs vcfs so leave as is\n    bcftools view \\\n    -H MichiganLD_regionsFiltered_${region}.bcf \\\n    -S ${agg_samples_txt} \\\n    --force-samples \\\n    | awk -F '\\t' '${awk_expr_create_final_king_vcf_1}' MAF_filtered_1kp3intersect_${region}.txt - >> ${region}_filtered.vcf\n    bgzip ${region}_filtered.vcf\n    tabix ${region}_filtered.vcf.gz\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_further_filtering",
            "ch_inputFinalPlatekeys"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_create_final_king_vcf",
            "ch_vcfs_create_final_king_vcf",
            "ch_tbi_create_final_king_vcf"
        ],
        "nb_outputs": 3,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/create_final_king_vcf/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "concat_king_vcf": {
        "name_process": "concat_king_vcf",
        "string_process": "\nprocess concat_king_vcf {\n    publishDir \"${params.outdir}/concat_king_vcf/\", mode: params.publish_dir_mode\n\n    input:\n    set val(region), file(\"${region}_filtered.vcf.gz\"), file(\"${region}_filtered.vcf.gz.tbi\") from ch_create_final_king_vcf\n    file \"*.vcf.gz\" from ch_vcfs_create_final_king_vcf.collect()\n    file \"*.tbi\" from ch_tbi_create_final_king_vcf.collect()\n    each chr from chrs\n    output:\n    set val(chr),file(\"chrom${chr}_merged_filtered.vcf.gz\"),file(\"chrom${chr}_merged_filtered.vcf.gz.tbi\") into ch_vcfs_per_chromosome\n\n    script:\n    \"\"\"\n    find -L . -type f -name chr${chr}_*.vcf.gz > tmp.files_chrom${chr}.txt\n    bcftools concat \\\n    -f tmp.files_chrom${chr}.txt \\\n    -Oz \\\n    -o chrom${chr}_merged_filtered.vcf.gz && \\\n    tabix chrom${chr}_merged_filtered.vcf.gz && \\\n    rm tmp.files_chrom${chr}.txt\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    find -L . -type f -name chr${chr}_*.vcf.gz > tmp.files_chrom${chr}.txt\n    bcftools concat \\\n    -f tmp.files_chrom${chr}.txt \\\n    -Oz \\\n    -o chrom${chr}_merged_filtered.vcf.gz && \\\n    tabix chrom${chr}_merged_filtered.vcf.gz && \\\n    rm tmp.files_chrom${chr}.txt\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_create_final_king_vcf",
            "ch_vcfs_create_final_king_vcf",
            "ch_tbi_create_final_king_vcf",
            "chrs"
        ],
        "nb_inputs": 4,
        "outputs": [
            "ch_vcfs_per_chromosome"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/concat_king_vcf/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "make_bed_all": {
        "name_process": "make_bed_all",
        "string_process": "\nprocess make_bed_all {\n    publishDir \"${params.outdir}/make_bed_all/\", mode: params.publish_dir_mode\n\n    input:\n    set val(chr),file(\"chrom${chr}_merged_filtered.vcf.gz\"),file(\"chrom${chr}_merged_filtered.vcf.gz.tbi\") from ch_vcfs_per_chromosome\n    file(michiganld_exclude_regions_file) from ch_inputMichiganLDfileExclude\n    output:\n    set val(chr),file(\"BED_${chr}.bed\"),file(\"BED_${chr}.bim\"),file(\"BED_${chr}.fam\") into ch_make_bed_all\n\n    script:\n\n    \"\"\"\n    stringQuery='#-\\$r/\\$a-.-.'\n    plink2 --vcf chrom${chr}_merged_filtered.vcf.gz \\\n    --make-bed \\\n    --vcf-half-call m \\\n    --set-missing-var-ids chr@:\\$stringQuery \\\n    --new-id-max-allele-len 60 missing \\\n    --exclude range ${michiganld_exclude_regions_file} \\\n    --double-id \\\n    --real-ref-alleles \\\n    --allow-extra-chr \\\n    --threads 30 \\\n    --out BED_${chr}\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    stringQuery='#-\\$r/\\$a-.-.'\n    plink2 --vcf chrom${chr}_merged_filtered.vcf.gz \\\n    --make-bed \\\n    --vcf-half-call m \\\n    --set-missing-var-ids chr@:\\$stringQuery \\\n    --new-id-max-allele-len 60 missing \\\n    --exclude range ${michiganld_exclude_regions_file} \\\n    --double-id \\\n    --real-ref-alleles \\\n    --allow-extra-chr \\\n    --threads 30 \\\n    --out BED_${chr}\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_vcfs_per_chromosome",
            "ch_inputMichiganLDfileExclude"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_make_bed_all"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/make_bed_all/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "ld_bed": {
        "name_process": "ld_bed",
        "string_process": " process ld_bed {\n    publishDir \"${params.outdir}/ld_bed/\", mode: params.publish_dir_mode\n\n    input:\n    set val(chr),file(\"BED_${chr}.bed\"),file(\"BED_${chr}.bim\"),file(\"BED_${chr}.fam\") from ch_make_bed_all\n\n    output:\n    file \"BED_LDpruned_${chr}*\" into ch_ld_bed\n\n    script:\n    \"\"\"\n    #Not considering founders in this as all of our SNPs are common\n    plink  \\\n    --keep-allele-order \\\n    --bfile BED_${chr} \\\n    --indep-pairwise 500kb 1 0.1 \\\n    --threads 30 \\\n    --out BED_LD_${chr}\n\n    #Now that we have our correct list of SNPs (prune.in), filter the original\n    #bed file to just these sites\n    plink \\\n    --make-bed \\\n    --bfile BED_${chr} \\\n    --keep-allele-order \\\n    --extract BED_LD_${chr}.prune.in \\\n    --double-id \\\n    --allow-extra-chr \\\n    --threads 30 \\\n    --out BED_LDpruned_${chr}\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    #Not considering founders in this as all of our SNPs are common\n    plink  \\\n    --keep-allele-order \\\n    --bfile BED_${chr} \\\n    --indep-pairwise 500kb 1 0.1 \\\n    --threads 30 \\\n    --out BED_LD_${chr}\n\n    #Now that we have our correct list of SNPs (prune.in), filter the original\n    #bed file to just these sites\n    plink \\\n    --make-bed \\\n    --bfile BED_${chr} \\\n    --keep-allele-order \\\n    --extract BED_LD_${chr}.prune.in \\\n    --double-id \\\n    --allow-extra-chr \\\n    --threads 30 \\\n    --out BED_LDpruned_${chr}\n    \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "pLink"
        ],
        "tools_url": [
            "https://bio.tools/pLink-2"
        ],
        "tools_dico": [
            {
                "name": "pLink",
                "uri": "https://bio.tools/pLink-2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3649",
                                    "term": "Target-Decoy"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fragment weight comparison"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "PMF"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Peptide mass fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fingerprinting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A high-speed search engine pLink 2 with systematic evaluation for proteome-scale identification of cross-linked peptides.",
                "homepage": "http://pfind.ict.ac.cn/software/pLink/index.html"
            }
        ],
        "inputs": [
            "ch_make_bed_all"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_ld_bed"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/ld_bed/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "merge_autosomes": {
        "name_process": "merge_autosomes",
        "string_process": "\nprocess merge_autosomes {\n    publishDir \"${params.outdir}/merge_autosomes/\", mode: params.publish_dir_mode\n\n    input:\n    file chr_ld_pruned_bed from ch_ld_bed.collect()\n\n    output:\n    set file(\"autosomes_LD_pruned_1kgp3Intersect.bed\"), file(\"autosomes_LD_pruned_1kgp3Intersect.bim\"), file(\"autosomes_LD_pruned_1kgp3Intersect.fam\"),file(\"autosomes_LD_pruned_1kgp3Intersect.nosex\") into (ch_merge_autosomes , ch_merge_autosomes2, ch_merge_autosomes3, ch_merge_autosomes4)\n\n    script:\n    \"\"\"\n    for i in {1..22}; do if [ -f \"BED_LDpruned_\\$i.bed\" ]; then echo BED_LDpruned_\\$i >> mergelist.txt; fi ;done\n    plink --merge-list mergelist.txt \\\n    --make-bed \\\n    --out autosomes_LD_pruned_1kgp3Intersect\n    rm mergelist.txt\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    for i in {1..22}; do if [ -f \"BED_LDpruned_\\$i.bed\" ]; then echo BED_LDpruned_\\$i >> mergelist.txt; fi ;done\n    plink --merge-list mergelist.txt \\\n    --make-bed \\\n    --out autosomes_LD_pruned_1kgp3Intersect\n    rm mergelist.txt\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "pLink"
        ],
        "tools_url": [
            "https://bio.tools/pLink-2"
        ],
        "tools_dico": [
            {
                "name": "pLink",
                "uri": "https://bio.tools/pLink-2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3649",
                                    "term": "Target-Decoy"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fragment weight comparison"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "PMF"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Peptide mass fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fingerprinting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A high-speed search engine pLink 2 with systematic evaluation for proteome-scale identification of cross-linked peptides.",
                "homepage": "http://pfind.ict.ac.cn/software/pLink/index.html"
            }
        ],
        "inputs": [
            "ch_ld_bed"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/merge_autosomes/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "hwe_pruning_30k_snps": {
        "name_process": "hwe_pruning_30k_snps",
        "string_process": "\nprocess hwe_pruning_30k_snps {\n    publishDir \"${params.outdir}/hwe_pruning_30k_snps/\", mode: params.publish_dir_mode\n    input:\n    set file(\"autosomes_LD_pruned_1kgp3Intersect.bed\"), file(\"autosomes_LD_pruned_1kgp3Intersect.bim\"), file(\"autosomes_LD_pruned_1kgp3Intersect.fam\"),file(\"autosomes_LD_pruned_1kgp3Intersect.nosex\") from ch_merge_autosomes\n    file (ancestry_assignment_probs) from ch_inputAncestryAssignmentProbs\n    file (pc_sancestry_related) from ch_inputPCsancestryrelated\n\n    output:\n    file \"hwe1e-5_superpops_195ksnps\" into hwe_pruning_30k_snps\n\n    script:\n    \"\"\"\n    R -e 'library(data.table);\n    library(dplyr);\n    dat <- fread(\"${ancestry_assignment_probs}\") %>% as_tibble();\n    unrels <- fread(\"${pc_sancestry_related}\") %>% as_tibble() %>% filter(unrelated_set == 1);\n    dat <- dat %>% filter(plate_key %in% unrels\\$plate_key);\n    for(col in c(\"AFR\",\"EUR\",\"SAS\",\"EAS\")){dat[dat[col]>0.8,c(\"plate_key\",col)] %>% write.table(paste0(col,\"pop.txt\"), quote = F, row.names=F)}\n    '\n\n    bedmain=\"autosomes_LD_pruned_1kgp3Intersect\"\n    for pop in AFR EUR SAS EAS; do\n        echo \\${pop}\n        awk '{print \\$1\"\\t\"\\$1}' \\${pop}pop.txt > \\${pop}keep\n        plink \\\n        --keep-allele-order \\\n        --make-bed \\\n        --bfile \\${bedmain} \\\n        --out \\${pop}\n\n        plink --bfile \\${pop} --hardy midp --out \\${pop} --nonfounders\n    done\n\n    #Combine the HWE and produce a list of pass\n    R -e 'library(data.table);\n    library(dplyr);\n    dat <- lapply(c(\"EUR.hwe\",\"AFR.hwe\", \"SAS.hwe\", \"EAS.hwe\"),fread);\n    names(dat) <- c(\"EUR.hwe\",\"AFR.hwe\", \"SAS.hwe\", \"EAS.hwe\");\n    dat <- dat %>% bind_rows(.id=\"id\");\n    write.table(dat, \"combinedHWE.txt\", row.names = F, quote = F)\n    #Create set that is just SNPS that are >1e-5 in all pops\n    dat %>% filter(P >1e-5) %>% group_by(SNP) %>% count() %>% filter(n==4) %>% select(SNP) %>% distinct() %>%\n    write.table(\"hwe1e-5_superpops_195ksnps\", row.names = F, quote = F)\n    '\n    \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "    \"\"\"\n    R -e 'library(data.table);\n    library(dplyr);\n    dat <- fread(\"${ancestry_assignment_probs}\") %>% as_tibble();\n    unrels <- fread(\"${pc_sancestry_related}\") %>% as_tibble() %>% filter(unrelated_set == 1);\n    dat <- dat %>% filter(plate_key %in% unrels\\$plate_key);\n    for(col in c(\"AFR\",\"EUR\",\"SAS\",\"EAS\")){dat[dat[col]>0.8,c(\"plate_key\",col)] %>% write.table(paste0(col,\"pop.txt\"), quote = F, row.names=F)}\n    '\n\n    bedmain=\"autosomes_LD_pruned_1kgp3Intersect\"\n    for pop in AFR EUR SAS EAS; do\n        echo \\${pop}\n        awk '{print \\$1\"\\t\"\\$1}' \\${pop}pop.txt > \\${pop}keep\n        plink \\\n        --keep-allele-order \\\n        --make-bed \\\n        --bfile \\${bedmain} \\\n        --out \\${pop}\n\n        plink --bfile \\${pop} --hardy midp --out \\${pop} --nonfounders\n    done\n\n    #Combine the HWE and produce a list of pass\n    R -e 'library(data.table);\n    library(dplyr);\n    dat <- lapply(c(\"EUR.hwe\",\"AFR.hwe\", \"SAS.hwe\", \"EAS.hwe\"),fread);\n    names(dat) <- c(\"EUR.hwe\",\"AFR.hwe\", \"SAS.hwe\", \"EAS.hwe\");\n    dat <- dat %>% bind_rows(.id=\"id\");\n    write.table(dat, \"combinedHWE.txt\", row.names = F, quote = F)\n    #Create set that is just SNPS that are >1e-5 in all pops\n    dat %>% filter(P >1e-5) %>% group_by(SNP) %>% count() %>% filter(n==4) %>% select(SNP) %>% distinct() %>%\n    write.table(\"hwe1e-5_superpops_195ksnps\", row.names = F, quote = F)\n    '\n    \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "ADAT",
            "pLink"
        ],
        "tools_url": [
            "https://bio.tools/adat",
            "https://bio.tools/pLink-2"
        ],
        "tools_dico": [
            {
                "name": "ADAT",
                "uri": "https://bio.tools/adat",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "PCA plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Web Tool for Navigating and Plotting SomaLogic ADAT Files.",
                "homepage": "https://foocheung.shinyapps.io/adat/"
            },
            {
                "name": "pLink",
                "uri": "https://bio.tools/pLink-2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3649",
                                    "term": "Target-Decoy"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fragment weight comparison"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "PMF"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Peptide mass fingerprinting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2929",
                                    "term": "Protein fingerprinting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A high-speed search engine pLink 2 with systematic evaluation for proteome-scale identification of cross-linked peptides.",
                "homepage": "http://pfind.ict.ac.cn/software/pLink/index.html"
            }
        ],
        "inputs": [
            "ch_merge_autosomes",
            "ch_inputAncestryAssignmentProbs",
            "ch_inputPCsancestryrelated"
        ],
        "nb_inputs": 3,
        "outputs": [
            "hwe_pruning_30k_snps"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/hwe_pruning_30k_snps/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "king_coefficients": {
        "name_process": "king_coefficients",
        "string_process": "\nprocess king_coefficients{\n       publishDir \"${params.outdir}/king_coefficients/\", mode: params.publish_dir_mode\n\n\n\n       input:\n       set file(\"autosomes_LD_pruned_1kgp3Intersect.bed\"), file(\"autosomes_LD_pruned_1kgp3Intersect.bim\"), file(\"autosomes_LD_pruned_1kgp3Intersect.fam\"),file(\"autosomes_LD_pruned_1kgp3Intersect.nosex\") from ch_merge_autosomes2\n       file \"hwe1e-5_superpops_195ksnps\" from hwe_pruning_30k_snps\n\n       output:\n       set file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.bed\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.bim\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.fam\"), file(\"autosomes_LD_pruned_1kgp3Intersect_related.bed\"),file(\"autosomes_LD_pruned_1kgp3Intersect_related.bim\"), file(\"autosomes_LD_pruned_1kgp3Intersect_related.fam\") into king_coefficients\n  \t   file(\"autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.in.id\") into ch_unrelatedlist\n\n       script:\n    \"\"\"\n    plink2 \\\n    --bfile autosomes_LD_pruned_1kgp3Intersect \\\n    --extract hwe1e-5_superpops_195ksnps \\\n    --make-king triangle bin \\\n    --out autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1e_5 \\\n    --thread-num 30\n    echo \"done1\"\n\n    plink2 --bfile autosomes_LD_pruned_1kgp3Intersect \\\n       --king-cutoff autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1e_5 0.0442 && \\\n       mv plink2.king.cutoff.in.id  autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.in.id && \\\n       mv plink2.king.cutoff.out.id  autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.out.id\n\n    plink2 --bfile autosomes_LD_pruned_1kgp3Intersect \\\n    --make-bed \\\n    --keep autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.in.id \\\n    --out autosomes_LD_pruned_1kgp3Intersect_unrelated\n    echo \"done2\"\n    plink2 --bfile autosomes_LD_pruned_1kgp3Intersect \\\n    --make-bed \\\n    --remove autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.in.id \\\n    --out autosomes_LD_pruned_1kgp3Intersect_related\n    echo \"done3\"\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    \"\"\"\n    plink2 \\\n    --bfile autosomes_LD_pruned_1kgp3Intersect \\\n    --extract hwe1e-5_superpops_195ksnps \\\n    --make-king triangle bin \\\n    --out autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1e_5 \\\n    --thread-num 30\n    echo \"done1\"\n\n    plink2 --bfile autosomes_LD_pruned_1kgp3Intersect \\\n       --king-cutoff autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1e_5 0.0442 && \\\n       mv plink2.king.cutoff.in.id  autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.in.id && \\\n       mv plink2.king.cutoff.out.id  autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.out.id\n\n    plink2 --bfile autosomes_LD_pruned_1kgp3Intersect \\\n    --make-bed \\\n    --keep autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.in.id \\\n    --out autosomes_LD_pruned_1kgp3Intersect_unrelated\n    echo \"done2\"\n    plink2 --bfile autosomes_LD_pruned_1kgp3Intersect \\\n    --make-bed \\\n    --remove autosomes_LD_pruned_1kgp3Intersect_triangle_HWE1_5.king.cutoff.in.id \\\n    --out autosomes_LD_pruned_1kgp3Intersect_related\n    echo \"done3\"\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_merge_autosomes2",
            "hwe_pruning_30k_snps"
        ],
        "nb_inputs": 2,
        "outputs": [
            "king_coefficients",
            "ch_unrelatedlist"
        ],
        "nb_outputs": 2,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/king_coefficients/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "gcta": {
        "name_process": "gcta",
        "string_process": "\nprocess gcta{\n    publishDir \"${params.outdir}/gcta/\", mode: params.publish_dir_mode\n\n    input:\n    set file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.bed\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.bim\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.fam\"), file(\"autosomes_LD_pruned_1kgp3Intersect_related.bed\"),file(\"autosomes_LD_pruned_1kgp3Intersect_related.bim\"), file(\"autosomes_LD_pruned_1kgp3Intersect_related.fam\") from king_coefficients\n\n    output:\n\n    set file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenval\") , file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec.PROJ.eigenvec\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.grm.N.bin\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.grm.bin\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.grm.id\") into ch_gcta\n\n    script:\n    \"\"\"\n    gcta64 --bfile \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --make-grm-bin --thread-num 30 --out \"autosomes_LD_pruned_1kgp3Intersect_unrelated\"\n    gcta64 --grm \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --pca ${n_pca}  --out \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --thread-num 30\n    gcta64 --bfile \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --pc-loading \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --out \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --thread-num 30\n    awk 'BEGIN{OFS=\"    \"}{print \\$0, \"NA\"}' \"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec\" > \"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec.PROJ.eigenvec\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    gcta64 --bfile \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --make-grm-bin --thread-num 30 --out \"autosomes_LD_pruned_1kgp3Intersect_unrelated\"\n    gcta64 --grm \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --pca ${n_pca}  --out \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --thread-num 30\n    gcta64 --bfile \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --pc-loading \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --out \"autosomes_LD_pruned_1kgp3Intersect_unrelated\" --thread-num 30\n    awk 'BEGIN{OFS=\"    \"}{print \\$0, \"NA\"}' \"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec\" > \"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec.PROJ.eigenvec\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "king_coefficients"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_gcta"
        ],
        "nb_outputs": 1,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/gcta/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "infer_ancestry": {
        "name_process": "infer_ancestry",
        "string_process": "\nprocess infer_ancestry{\n    publishDir \"${params.outdir}/infer_ancestry/\", mode: params.publish_dir_mode\n\n    input:\n    file (kgp3_sample_table) from ch_input1KGP3\n    file (super_pop_codes) from ch_inputSuper_pop_codes\n    file (kgp3_unrel) from ch_inputUNRELATED_1KGP3\n    file \"1KGP3_intersectGEL_200Kset_perpopHWE1e-6_unrel_maf0.05both1K100K.eigenvec\" from ch_input05both1K100K_eigenvec\n    file \"1KGP3_intersectGEL_200Kset_perpopHWE1e-6_unrel_maf0.05both1K100K_GELprojection.proj.eigenvec\" from ch_GELprojection_proj_eigenvec\n    set file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenval\") , file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.eigenvec.PROJ.eigenvec\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.grm.N.bin\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.grm.bin\"), file(\"autosomes_LD_pruned_1kgp3Intersect_unrelated.grm.id\") from ch_gcta\n\n    output:\n    file \"predicted_ancestries.tsv\" into ch_infer_ancestry\n    file \"results.RDS\" into ch_infer_ancestry_2\n\n    script:\n    \"\"\"\n    mkdir Ancestries\n    infer_ancestry.R  \\\n    ${kgp3_sample_table} \\\n    ${super_pop_codes} \\\n    ${kgp3_unrel} \\\n    \"1KGP3_intersectGEL_200Kset_perpopHWE1e-6_unrel_maf0.05both1K100K.eigenvec\" \\\n    \"1KGP3_intersectGEL_200Kset_perpopHWE1e-6_unrel_maf0.05both1K100K_GELprojection.proj.eigenvec\" \\\n    \"Ancestries\"\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    mkdir Ancestries\n    infer_ancestry.R  \\\n    ${kgp3_sample_table} \\\n    ${super_pop_codes} \\\n    ${kgp3_unrel} \\\n    \"1KGP3_intersectGEL_200Kset_perpopHWE1e-6_unrel_maf0.05both1K100K.eigenvec\" \\\n    \"1KGP3_intersectGEL_200Kset_perpopHWE1e-6_unrel_maf0.05both1K100K_GELprojection.proj.eigenvec\" \\\n    \"Ancestries\"\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_input1KGP3",
            "ch_inputSuper_pop_codes",
            "ch_inputUNRELATED_1KGP3",
            "ch_input05both1K100K_eigenvec",
            "ch_GELprojection_proj_eigenvec",
            "ch_gcta"
        ],
        "nb_inputs": 6,
        "outputs": [
            "ch_infer_ancestry",
            "ch_infer_ancestry_2"
        ],
        "nb_outputs": 2,
        "name_workflow": "lifebit-ai__relate",
        "directive": [
            "publishDir \"${params.outdir}/infer_ancestry/\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    }
}