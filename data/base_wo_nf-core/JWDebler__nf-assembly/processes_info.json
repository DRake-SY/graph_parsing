{
    "combineReads": {
        "name_process": "combineReads",
        "string_process": "\nprocess combineReads {\n    tag {sampleID}\n\n    publishDir \"${params.outputdir}/${sampleID}/00-rawReads/\", mode: 'copy'\n\n    input:\n    set sampleID, \"fwd.*.fastq.gz\", \"rev.*.fastq.gz\" from rawReads\n\n    output:\n    set sampleID, \"${sampleID}.fwd.fastq.gz\", \"${sampleID}.rev.fastq.gz\" into rawCombinedReads\n\n    \"\"\"\n    cat fwd.*.fastq.gz > ${sampleID}.fwd.fastq.gz\n    cat rev.*.fastq.gz > ${sampleID}.rev.fastq.gz \\\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\"\n    cat fwd.*.fastq.gz > ${sampleID}.fwd.fastq.gz\n    cat rev.*.fastq.gz > ${sampleID}.rev.fastq.gz \\\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "rawReads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "rawCombinedReads"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/00-rawReads/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "trimReadsWithFastP": {
        "name_process": "trimReadsWithFastP",
        "string_process": "\nprocess trimReadsWithFastP {\n    tag {\"${sampleID} avg quality ${quality}\"}\n    cpus 5\n\n    publishDir \"${params.outputdir}/${sampleID}/fastp${quality}/01-trimmedReads/\", mode: 'copy'\n        \n    input:\n    set sampleID, \"fwd.fastq.gz\", \"rev.fastq.gz\", quality from trimInput\n\n    output:\n    set sampleID, quality, \"paired.fwd.fastq.gz\", \"paired.rev.fastq.gz\", \"singletons.fastq.gz\" into trimmedReads\n    set sampleID, \"report.${sampleID}.html\"\n\n    \"\"\"\n    fastp \\\n    -i fwd.fastq.gz \\\n    -I rev.fastq.gz \\\n    -o paired.fwd.fastq.gz \\\n    -O paired.rev.fastq.gz \\\n    --unpaired1 singletons.fastq.gz \\\n    --unpaired2 singletons.fastq.gz \\\n    --detect_adapter_for_pe \\\n    -l 50 \\\n    -e ${quality} \\\n    -x \\\n    -y \\\n    -c \\\n    -p \\\n    -h \"report.${sampleID}.html\"\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "\"\"\"\n    fastp \\\n    -i fwd.fastq.gz \\\n    -I rev.fastq.gz \\\n    -o paired.fwd.fastq.gz \\\n    -O paired.rev.fastq.gz \\\n    --unpaired1 singletons.fastq.gz \\\n    --unpaired2 singletons.fastq.gz \\\n    --detect_adapter_for_pe \\\n    -l 50 \\\n    -e ${quality} \\\n    -x \\\n    -y \\\n    -c \\\n    -p \\\n    -h \"report.${sampleID}.html\"\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "trimInput"
        ],
        "nb_inputs": 1,
        "outputs": [
            "trimmedReads",
            "sampleID"
        ],
        "nb_outputs": 2,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {\"${sampleID} avg quality ${quality}\"}",
            "cpus 5",
            "publishDir \"${params.outputdir}/${sampleID}/fastp${quality}/01-trimmedReads/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "fastQC": {
        "name_process": "fastQC",
        "string_process": "\nprocess fastQC {\n    tag {\"${sampleID} avg quality ${quality}\"}\n\n    publishDir \"${params.outputdir}/${sampleID}/comparisons/fastQC\", mode: 'copy'\n\n    input:\n    set sampleID, quality, \"${quality}.paired.fwd.fastq.gz\", \"${quality}.paired.rev.fastq.gz\", \"${quality}.singletons.fastq.gz\" from trimmedReads\n\n    output:\n    file('*fastqc*')\n\n    \"\"\"\n    ${params.fastqc} *.gz\n    \"\"\"\n\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\"\n    ${params.fastqc} *.gz\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimmedReads"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {\"${sampleID} avg quality ${quality}\"}",
            "publishDir \"${params.outputdir}/${sampleID}/comparisons/fastQC\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "versions": {
        "name_process": "versions",
        "string_process": "\nprocess versions {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${params.isolate}\", mode: 'copy'\n\n    output:\n    file('versions.txt')\n\n    \"\"\"\n    echo \"Programs and versions used in this pipeline:\" >> versions.txt\n    date >> versions.txt\n    echo \"============================================\" >> versions.txt\n    echo \"trimmomatic:\" >> versions.txt\n    java -jar ${params.trimmomatic} -version >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"spades:\" >> versions.txt\n    ${params.spades} -v >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"GeneMarkES:\" >> versions.txt\n    ${params.genemark} | grep 'GeneMark-ES Suite version' >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"infernal:\" >> versions.txt\n    ${params.infernal_cmpress} -h | grep INFERNAL >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"trnaScanSE:\" >> versions.txt\n    ${params.trnascan} -h 2>&1 | head -2 | grep tRNAscan >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"Quast:\" >> versions.txt\n    ${params.quast} -v >> versions.txt\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "\"\"\"\n    echo \"Programs and versions used in this pipeline:\" >> versions.txt\n    date >> versions.txt\n    echo \"============================================\" >> versions.txt\n    echo \"trimmomatic:\" >> versions.txt\n    java -jar ${params.trimmomatic} -version >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"spades:\" >> versions.txt\n    ${params.spades} -v >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"GeneMarkES:\" >> versions.txt\n    ${params.genemark} | grep 'GeneMark-ES Suite version' >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"infernal:\" >> versions.txt\n    ${params.infernal_cmpress} -h | grep INFERNAL >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"trnaScanSE:\" >> versions.txt\n    ${params.trnascan} -h 2>&1 | head -2 | grep tRNAscan >> versions.txt\n    echo \"--------------------------------------------\" >> versions.txt\n    echo \"Quast:\" >> versions.txt\n    ${params.quast} -v >> versions.txt\n    \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "datelife"
        ],
        "tools_url": [
            "https://bio.tools/datelife"
        ],
        "tools_dico": [
            {
                "name": "datelife",
                "uri": "https://bio.tools/datelife",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0194",
                            "term": "Phylogenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Query and retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0224",
                                    "term": "Database retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3478",
                                    "term": "Phylogenetic tree reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Leveraging databases and analytical tools to reveal the dated Tree of Life.\n\nR package containing datelife's core functionality.\n\nDashboard \u22c5 phylotastic/datelife.\n\nGet a phylogenetic tree with branch lengths proportional to geologic time (aka a chronogram) of any two or more lineages of interest to you: use this R package or go to www.datelife.org to make a query of chronograms available for your lineages in the Open Tree of Life\u2019s tree store.\n\nWelcome to the DateLife project.\n\nAn R package, datelife for doing the calculations.\n\nCode coverage done right",
                "homepage": "http://www.datelife.org/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${params.isolate}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "assembleFastP": {
        "name_process": "assembleFastP",
        "string_process": "\nprocess assembleFastP {\n    tag {\"${sampleID} avg quality ${quality}\"}\n    publishDir \"${params.outputdir}/${sampleID}/fastp${quality}/02-assembly/\", mode: 'copy'\n    memory '30G'\n    cpus 10\n\n    input:\n    set sampleID, quality, \"paired.fwd.fastq.gz\", \"paired.rev.fastq.gz\", \"singletons.fastq.gz\" from trimmedReads\n\n    output:\n    set sampleID, quality, \"${sampleID}.${quality}.contigs.fasta\" into contigsForCleanup\n    set sampleID, quality, \"${sampleID}.${quality}.scaffolds.fasta\" into scaffoldsForCleanup\n\n    \"\"\"\n    ${params.spades} \\\n    -k 21,33,55,77 \\\n    --memory ${task.memory.toGiga()} \\\n    --threads ${task.cpus} \\\n    --careful \\\n    --only-assembler \\\n    -1 paired.fwd.fastq.gz \\\n    -2 paired.rev.fastq.gz \\\n    -s singletons.fastq.gz \\\n    -o .\n    mv scaffolds.fasta ${sampleID}.${quality}.scaffolds.fasta\n    mv contigs.fasta ${sampleID}.${quality}.contigs.fasta\n\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "\"\"\"\n    ${params.spades} \\\n    -k 21,33,55,77 \\\n    --memory ${task.memory.toGiga()} \\\n    --threads ${task.cpus} \\\n    --careful \\\n    --only-assembler \\\n    -1 paired.fwd.fastq.gz \\\n    -2 paired.rev.fastq.gz \\\n    -s singletons.fastq.gz \\\n    -o .\n    mv scaffolds.fasta ${sampleID}.${quality}.scaffolds.fasta\n    mv contigs.fasta ${sampleID}.${quality}.contigs.fasta\n\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimmedReads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "contigsForCleanup",
            "scaffoldsForCleanup"
        ],
        "nb_outputs": 2,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {\"${sampleID} avg quality ${quality}\"}",
            "publishDir \"${params.outputdir}/${sampleID}/fastp${quality}/02-assembly/\", mode: 'copy'",
            "memory '30G'",
            "cpus 10"
        ],
        "when": "",
        "stub": ""
    },
    "cleanupSpadesOutputScaffolds": {
        "name_process": "cleanupSpadesOutputScaffolds",
        "string_process": "\nprocess cleanupSpadesOutputScaffolds {\n    tag {sampleID}\n    \n    input:\n\tset sampleID, \"${sampleID}.scaffolds.fasta\" from scaffoldsForCleanup\n\n    output:\n    set sampleID, \"${sampleID}.scaffolds.clean.fasta\" into scaffoldsForHeaderadjustment\n\n    \"\"\"\n    #!/usr/bin/env ruby\n\n    require 'optparse'\n    require 'bio'\n    require 'pp'\n\n    options = {:prefix => nil}\n    OptionParser.new do |opts|\n      opts.banner = \"Usage: fix_names.rb [options] input.fasta\"\n\n      opts.on(\"-p\", \"--prefix [NAME]\", \"Strain prefix to prepend to contig name\") do |p|\n        options[:prefix] = p + \"_\"\n      end\n    end.parse!\n    out = File.open(\"${sampleID}.scaffolds.clean.fasta\", 'w')\n    Bio::FlatFile\n    .open(\"${sampleID}.scaffolds.fasta\")\n    .sort_by{|entry| entry.length}\n    .reverse\n    .each\n    .with_index(1)\n    .map{|entry, i| [entry, \"%sscf%d\" % [options[:prefix], i]]}\n    .each{|entry, name| out.puts entry.seq.to_fasta(name, 80)}\n    out.close\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "\"\"\"\n    #!/usr/bin/env ruby\n\n    require 'optparse'\n    require 'bio'\n    require 'pp'\n\n    options = {:prefix => nil}\n    OptionParser.new do |opts|\n      opts.banner = \"Usage: fix_names.rb [options] input.fasta\"\n\n      opts.on(\"-p\", \"--prefix [NAME]\", \"Strain prefix to prepend to contig name\") do |p|\n        options[:prefix] = p + \"_\"\n      end\n    end.parse!\n    out = File.open(\"${sampleID}.scaffolds.clean.fasta\", 'w')\n    Bio::FlatFile\n    .open(\"${sampleID}.scaffolds.fasta\")\n    .sort_by{|entry| entry.length}\n    .reverse\n    .each\n    .with_index(1)\n    .map{|entry, i| [entry, \"%sscf%d\" % [options[:prefix], i]]}\n    .each{|entry, name| out.puts entry.seq.to_fasta(name, 80)}\n    out.close\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "ruby",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffoldsForCleanup"
        ],
        "nb_inputs": 1,
        "outputs": [
            "scaffoldsForHeaderadjustment"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}"
        ],
        "when": "",
        "stub": ""
    },
    "cleanupSpadesOutputContigs": {
        "name_process": "cleanupSpadesOutputContigs",
        "string_process": "\nprocess cleanupSpadesOutputContigs {\n    tag {sampleID}\n    \n    input:\n\tset sampleID, \"${sampleID}.contigs.fasta\" from contigsForCleanup\n\n    output:\n    set sampleID, \"${sampleID}.contigs.clean.fasta\" into contigsForHeaderadjustment\n\n    \"\"\"\n    #!/usr/bin/env ruby\n\n    require 'optparse'\n    require 'bio'\n    require 'pp'\n\n    options = {:prefix => nil}\n    OptionParser.new do |opts|\n      opts.banner = \"Usage: fix_names.rb [options] input.fasta\"\n\n      opts.on(\"-p\", \"--prefix [NAME]\", \"Strain prefix to prepend to contig name\") do |p|\n        options[:prefix] = p + \"_\"\n      end\n    end.parse!\n    out = File.open(\"${sampleID}.contigs.clean.fasta\", 'w')\n    Bio::FlatFile\n    .open(\"${sampleID}.contigs.fasta\")\n    .sort_by{|entry| entry.length}\n    .reverse\n    .each\n    .with_index(1)\n    .map{|entry, i| [entry, \"%sctg%d\" % [options[:prefix], i]]}\n    .each{|entry, name| out.puts entry.seq.to_fasta(name, 80)}\n    out.close\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "\"\"\"\n    #!/usr/bin/env ruby\n\n    require 'optparse'\n    require 'bio'\n    require 'pp'\n\n    options = {:prefix => nil}\n    OptionParser.new do |opts|\n      opts.banner = \"Usage: fix_names.rb [options] input.fasta\"\n\n      opts.on(\"-p\", \"--prefix [NAME]\", \"Strain prefix to prepend to contig name\") do |p|\n        options[:prefix] = p + \"_\"\n      end\n    end.parse!\n    out = File.open(\"${sampleID}.contigs.clean.fasta\", 'w')\n    Bio::FlatFile\n    .open(\"${sampleID}.contigs.fasta\")\n    .sort_by{|entry| entry.length}\n    .reverse\n    .each\n    .with_index(1)\n    .map{|entry, i| [entry, \"%sctg%d\" % [options[:prefix], i]]}\n    .each{|entry, name| out.puts entry.seq.to_fasta(name, 80)}\n    out.close\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "ruby",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigsForCleanup"
        ],
        "nb_inputs": 1,
        "outputs": [
            "contigsForHeaderadjustment"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}"
        ],
        "when": "",
        "stub": ""
    },
    "addSpeciesNameToFastaHeadersScaffolds": {
        "name_process": "addSpeciesNameToFastaHeadersScaffolds",
        "string_process": "\nprocess addSpeciesNameToFastaHeadersScaffolds {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/02-assembly/spades/\", mode: 'copy'\n\n    input:\n    set sampleID, \"${sampleID}.scaffolds.clean.fasta\" from scaffoldsForHeaderadjustment\n\n    output:\n    set sampleID, \"${sampleID}.scaffolds.clean.fasta\" into scaffoldsRawForGenemark\n    set sampleID, \"${sampleID}.scaffolds.clean.fasta\" into scaffoldsRawForTRNAscan\n    set sampleID, \"${sampleID}.scaffolds.clean.fasta\" into scaffoldsRawForInfernal\n    set sampleID, \"${sampleID}.scaffolds.clean.fasta\" into scaffoldsRawForQuast\n    set sampleID, \"${sampleID}.scaffolds.clean.fasta\" into scaffoldsRawForFastQC\n\n    \"\"\"\n    sed 's,>,&${sampleID}_,g' -i ${sampleID}.scaffolds.clean.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n    sed 's,>,&${sampleID}_,g' -i ${sampleID}.scaffolds.clean.fasta\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffoldsForHeaderadjustment"
        ],
        "nb_inputs": 1,
        "outputs": [
            "scaffoldsRawForGenemark",
            "scaffoldsRawForTRNAscan",
            "scaffoldsRawForInfernal",
            "scaffoldsRawForQuast",
            "scaffoldsRawForFastQC"
        ],
        "nb_outputs": 5,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/02-assembly/spades/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "addSpeciesNameToFastaHeadersContigs": {
        "name_process": "addSpeciesNameToFastaHeadersContigs",
        "string_process": "\nprocess addSpeciesNameToFastaHeadersContigs {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/02-assembly/spades/\", mode: 'copy'\n\n    input:\n    set sampleID, \"${sampleID}.contigs.clean.fasta\" from contigsForHeaderadjustment\n\n    output:\n    set sampleID, \"${sampleID}.contigs.clean.fasta\" into contigsRawForGenemark\n    set sampleID, \"${sampleID}.contigs.clean.fasta\" into contigsRawForTRNAscan\n    set sampleID, \"${sampleID}.contigs.clean.fasta\" into contigsRawForInfernal\n    set sampleID, \"${sampleID}.contigs.clean.fasta\" into contigsRawForFastQC\n    set sampleID, \"${sampleID}.contigs.clean.fasta\" into contigsRawForQuast\n\n    \"\"\"\n    sed 's,>,&${sampleID}_,g' -i ${sampleID}.contigs.clean.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n    sed 's,>,&${sampleID}_,g' -i ${sampleID}.contigs.clean.fasta\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigsForHeaderadjustment"
        ],
        "nb_inputs": 1,
        "outputs": [
            "contigsRawForGenemark",
            "contigsRawForTRNAscan",
            "contigsRawForInfernal",
            "contigsRawForFastQC",
            "contigsRawForQuast"
        ],
        "nb_outputs": 5,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/02-assembly/spades/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "annotation_genemark_scaffolds": {
        "name_process": "annotation_genemark_scaffolds",
        "string_process": "\nprocess annotation_genemark_scaffolds {\n    tag {sampleID}\n    cpus 10\n    publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'\n\n    input:\n\tset sampleID, \"${sampleID}.scaffolds.clean.fasta\" from scaffoldsRawForGenemark\n\n    output:\n\tset sampleID, \"${sampleID}.scaffolds.genemark.gtf\"\n\n    \"\"\"\n    ${params.genemark} --ES --fungus --cores ${task.cpus} --sequence ${sampleID}.scaffolds.clean.fasta\n    mv genemark.gtf ${sampleID}.scaffolds.genemark.gtf\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\"\n    ${params.genemark} --ES --fungus --cores ${task.cpus} --sequence ${sampleID}.scaffolds.clean.fasta\n    mv genemark.gtf ${sampleID}.scaffolds.genemark.gtf\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffoldsRawForGenemark"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleID"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "cpus 10",
            "publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "annotation_genemark_contigs": {
        "name_process": "annotation_genemark_contigs",
        "string_process": "\nprocess annotation_genemark_contigs {\n    tag {sampleID}\n    cpus 10\n    publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'\n\n    input:\n\tset sampleID, \"${sampleID}.contigs.clean.fasta\" from contigsRawForGenemark\n\n    output:\n\tset sampleID, \"${sampleID}.contigs.genemark.gtf\"\n\n    \"\"\"\n    /opt/genemark-ES/gmes_petap.pl --ES --fungus --cores ${task.cpus} --sequence ${sampleID}.contigs.clean.fasta\n    mv genemark.gtf ${sampleID}.contigs.genemark.gtf\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\"\n    /opt/genemark-ES/gmes_petap.pl --ES --fungus --cores ${task.cpus} --sequence ${sampleID}.contigs.clean.fasta\n    mv genemark.gtf ${sampleID}.contigs.genemark.gtf\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigsRawForGenemark"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleID"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "cpus 10",
            "publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "extractProteinsFromGenemarkContigs": {
        "name_process": "extractProteinsFromGenemarkContigs",
        "string_process": "\nprocess extractProteinsFromGenemarkContigs {\n  tag {\"${sampleID} avg quality ${quality}\"}\n\n  input:\n  set sampleID, quality, \"${sampleID}.genemark.gtf\", \"input.fasta\" from proteinsFromGenemarkContis\n\n  output:\n  set sampleID, quality, \"${sampleID}.genemark.proteins.fasta\" into proteinsFromGenemarkContigs\n\n  \"\"\"\n  /opt/genemark-ES/get_sequence_from_GTF.pl ${sampleID}.genemark.gtf input.fasta\n  mv prot_seq.faa ${sampleID}.genemark.proteins.fasta\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n  /opt/genemark-ES/get_sequence_from_GTF.pl ${sampleID}.genemark.gtf input.fasta\n  mv prot_seq.faa ${sampleID}.genemark.proteins.fasta\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proteinsFromGenemarkContis"
        ],
        "nb_inputs": 1,
        "outputs": [
            "proteinsFromGenemarkContigs"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {\"${sampleID} avg quality ${quality}\"}"
        ],
        "when": "",
        "stub": ""
    },
    "interproscan": {
        "name_process": "interproscan",
        "string_process": "\nprocess interproscan {\n  tag {\"${sampleID} avg quality ${quality}\"}\n  publishDir \"${params.outputdir}/${sampleID}/fastp${quality}/03-annotation/\", mode: 'copy'\n  cpus 12\n\n  input:\n  set sampleID, quality, \"proteins.fasta\" from proteinsFromGenemarkContigs\n\n  output:\n  file \"${sampleID}.interproscan.tsv\"\n\n  \"\"\"\n  ${params.interproscan} \\\n  --applications SignalP_EUK,Pfam,TMHMM,PANTHER,PRINTS,ProDom,ProSitePatterns,ProSiteProfiles,MobiDBLite\\\n  --cpu ${task.cpus} \\\n  --seqtype p \\\n  --disable-precalc \\\n  --goterms \\\n  --pathways \\\n  --iprlookup\\\n  --input proteins.fasta \\\n  --output-file-base ${sampleID}.interproscan \\\n  --format tsv\n  \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "\"\"\"\n  ${params.interproscan} \\\n  --applications SignalP_EUK,Pfam,TMHMM,PANTHER,PRINTS,ProDom,ProSitePatterns,ProSiteProfiles,MobiDBLite\\\n  --cpu ${task.cpus} \\\n  --seqtype p \\\n  --disable-precalc \\\n  --goterms \\\n  --pathways \\\n  --iprlookup\\\n  --input proteins.fasta \\\n  --output-file-base ${sampleID}.interproscan \\\n  --format tsv\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proteinsFromGenemarkContigs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {\"${sampleID} avg quality ${quality}\"}",
            "publishDir \"${params.outputdir}/${sampleID}/fastp${quality}/03-annotation/\", mode: 'copy'",
            "cpus 12"
        ],
        "when": "",
        "stub": ""
    },
    "annotation_trnascan_scaffolds": {
        "name_process": "annotation_trnascan_scaffolds",
        "string_process": "\nprocess annotation_trnascan_scaffolds {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'\n\n    input:\n\tset sampleID, \"${sampleID}.scaffolds.clean.fasta\" from scaffoldsRawForTRNAscan\n\n    output:\n\tset sampleID, \"${sampleID}.scaffolds.trnascanSE.gff3\"\n    \"\"\"\n    ${params.trnascan} -o trnascanoutput.out ${sampleID}.scaffolds.clean.fasta \n    ${params.scripts}/convert_tRNAScanSE_to_gff3.pl --input=trnascanoutput.out > ${sampleID}.scaffolds.trnascanSE.gff3\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n    ${params.trnascan} -o trnascanoutput.out ${sampleID}.scaffolds.clean.fasta \n    ${params.scripts}/convert_tRNAScanSE_to_gff3.pl --input=trnascanoutput.out > ${sampleID}.scaffolds.trnascanSE.gff3\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffoldsRawForTRNAscan"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleID"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "annotation_trnascan_contigs": {
        "name_process": "annotation_trnascan_contigs",
        "string_process": "\nprocess annotation_trnascan_contigs {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'\n\n    input:\n\tset sampleID, \"${sampleID}.contigs.clean.fasta\" from contigsRawForTRNAscan\n\n    output:\n\tset sampleID, \"${sampleID}.contigs.trnascanSE.gff3\"\n    \"\"\"\n    ${params.trnascan} -o trnascanoutput.out ${sampleID}.contigs.clean.fasta \n    ${params.scripts}/convert_tRNAScanSE_to_gff3.pl --input=trnascanoutput.out > ${sampleID}.contigs.trnascanSE.gff3\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n    ${params.trnascan} -o trnascanoutput.out ${sampleID}.contigs.clean.fasta \n    ${params.scripts}/convert_tRNAScanSE_to_gff3.pl --input=trnascanoutput.out > ${sampleID}.contigs.trnascanSE.gff3\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigsRawForTRNAscan"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleID"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "annotaton_infernal_scaffolds": {
        "name_process": "annotaton_infernal_scaffolds",
        "string_process": "\nprocess annotaton_infernal_scaffolds {\n    tag {sampleID}\n    cpus 10\n    \n    input:\n\tset sampleID, \"${sampleID}.scaffolds.clean.fasta\" from scaffoldsRawForInfernal\n\n    output:\n\tset sampleID, \"scaffolds.cmscan.tbl\" into infernalToGff3scaffolds\n    \"\"\"\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.clanin\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.cm.gz\n    gzip -d Rfam.cm.gz\n    ${params.infernal_cmpress} Rfam.cm\n    ${params.infernal_cmscan} --rfam --cpu ${task.cpus} --cut_ga --nohmmonly --tblout scaffolds.cmscan.tbl --fmt 2 --clanin Rfam.clanin Rfam.cm ${sampleID}.scaffolds.clean.fasta > infernal.cmscan\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.clanin\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.cm.gz\n    gzip -d Rfam.cm.gz\n    ${params.infernal_cmpress} Rfam.cm\n    ${params.infernal_cmscan} --rfam --cpu ${task.cpus} --cut_ga --nohmmonly --tblout scaffolds.cmscan.tbl --fmt 2 --clanin Rfam.clanin Rfam.cm ${sampleID}.scaffolds.clean.fasta > infernal.cmscan\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffoldsRawForInfernal"
        ],
        "nb_inputs": 1,
        "outputs": [
            "infernalToGff3scaffolds"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "cpus 10"
        ],
        "when": "",
        "stub": ""
    },
    "annotaton_infernal_contigs": {
        "name_process": "annotaton_infernal_contigs",
        "string_process": "\nprocess annotaton_infernal_contigs {\n    tag {sampleID}\n    cpus 10\n    \n    input:\n\tset sampleID, \"${sampleID}.contigs.clean.fasta\" from contigsRawForInfernal\n\n    output:\n\tset sampleID, \"contigs.cmscan.tbl\" into infernalToGff3contigs\n    \"\"\"\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/13.0/Rfam.clanin\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/13.0/Rfam.cm.gz\n    gzip -d Rfam.cm.gz\n    ${params.infernal_cmpress} Rfam.cm\n    ${params.infernal_cmscan} --rfam --cpu ${task.cpus} --cut_ga --nohmmonly --tblout contigs.cmscan.tbl --fmt 2 --clanin Rfam.clanin Rfam.cm ${sampleID}.contigs.clean.fasta > infernal.cmscan\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/13.0/Rfam.clanin\n    wget ftp://ftp.ebi.ac.uk/pub/databases/Rfam/13.0/Rfam.cm.gz\n    gzip -d Rfam.cm.gz\n    ${params.infernal_cmpress} Rfam.cm\n    ${params.infernal_cmscan} --rfam --cpu ${task.cpus} --cut_ga --nohmmonly --tblout contigs.cmscan.tbl --fmt 2 --clanin Rfam.clanin Rfam.cm ${sampleID}.contigs.clean.fasta > infernal.cmscan\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigsRawForInfernal"
        ],
        "nb_inputs": 1,
        "outputs": [
            "infernalToGff3contigs"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "cpus 10"
        ],
        "when": "",
        "stub": ""
    },
    "infernalToGff3scaffolds": {
        "name_process": "infernalToGff3scaffolds",
        "string_process": "\nprocess infernalToGff3scaffolds {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'\n\n    input:\n\tset sampleID, \"scaffolds.cmscan.tbl\" from infernalToGff3scaffolds\n\n    output:\n\tset sampleID, \"${sampleID}.scaffolds.infernal.gff3\"\n    \"\"\"\n    grep -v ^# scaffolds.cmscan.tbl > scaffolds.cmscan.clean.tbl && awk '{printf \"%s\\tinfernal\\t%s\\t%d\\t%d\\t%s\\t%s\\t.\\tNote=RfamID-%s\\\\n\" ,\\$4,\\$2,\\$10,\\$11,\\$17,\\$12,\\$3}'  scaffolds.cmscan.clean.tbl > ${sampleID}.scaffolds.infernal.gff3\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n    grep -v ^# scaffolds.cmscan.tbl > scaffolds.cmscan.clean.tbl && awk '{printf \"%s\\tinfernal\\t%s\\t%d\\t%d\\t%s\\t%s\\t.\\tNote=RfamID-%s\\\\n\" ,\\$4,\\$2,\\$10,\\$11,\\$17,\\$12,\\$3}'  scaffolds.cmscan.clean.tbl > ${sampleID}.scaffolds.infernal.gff3\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "infernalToGff3scaffolds"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleID"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "infernalToGff3contigs": {
        "name_process": "infernalToGff3contigs",
        "string_process": "\nprocess infernalToGff3contigs {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'\n\n    input:\n\tset sampleID, \"contigs.cmscan.tbl\" from infernalToGff3contigs\n\n    output:\n\tset sampleID, \"${sampleID}.contigs.infernal.gff3\"\n    \"\"\"\n    grep -v ^# contigs.cmscan.tbl > contigs.cmscan.clean.tbl && awk '{printf \"%s\\tinfernal\\t%s\\t%d\\t%d\\t%s\\t%s\\t.\\tNote=RfamID-%s\\\\n\" ,\\$4,\\$2,\\$10,\\$11,\\$17,\\$12,\\$3}'  contigs.cmscan.clean.tbl > ${sampleID}.contigs.infernal.gff3\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n    grep -v ^# contigs.cmscan.tbl > contigs.cmscan.clean.tbl && awk '{printf \"%s\\tinfernal\\t%s\\t%d\\t%d\\t%s\\t%s\\t.\\tNote=RfamID-%s\\\\n\" ,\\$4,\\$2,\\$10,\\$11,\\$17,\\$12,\\$3}'  contigs.cmscan.clean.tbl > ${sampleID}.contigs.infernal.gff3\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "infernalToGff3contigs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleID"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/03-annotation/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "trimReadsWithTrimmomatic": {
        "name_process": "trimReadsWithTrimmomatic",
        "string_process": "\nprocess trimReadsWithTrimmomatic {\n    tag {sampleID}\n    cpus 5\n\n    publishDir \"${params.outputdir}/${sampleID}/01-trimmedReads/trimmomatic/\", mode: 'copy'\n        \n    input:\n    set sampleID, \"fwd.fastq.gz\", \"rev.fastq.gz\" from rawCombinedReads\n\n    output:\n    set sampleID, \"${sampleID}.trimmed.fwd.fastq.gz\", \"${sampleID}.trimmed.rev.fastq.gz\", \"${sampleID}.singletons.fastq.gz\" into trimmedReads\n\n    \"\"\"\n    cp /opt/trimmomatic/current/adapters/NexteraPE-PE.fa .\n\n    java -jar ${params.trimmomatic} PE \\\n    -threads ${task.cpus} \\\n    fwd.fastq.gz rev.fastq.gz \\\n    ${sampleID}.trimmed.fwd.fastq.gz singles.fwd.fastq.gz \\\n    ${sampleID}.trimmed.rev.fastq.gz singles.rev.fastq.gz \\\n    ILLUMINACLIP:NexteraPE-PE.fa:2:30:10 SLIDINGWINDOW:4:20 MINLEN:50\n\n    cat singles.*.fastq.gz > ${sampleID}.singletons.fastq.gz\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "\"\"\"\n    cp /opt/trimmomatic/current/adapters/NexteraPE-PE.fa .\n\n    java -jar ${params.trimmomatic} PE \\\n    -threads ${task.cpus} \\\n    fwd.fastq.gz rev.fastq.gz \\\n    ${sampleID}.trimmed.fwd.fastq.gz singles.fwd.fastq.gz \\\n    ${sampleID}.trimmed.rev.fastq.gz singles.rev.fastq.gz \\\n    ILLUMINACLIP:NexteraPE-PE.fa:2:30:10 SLIDINGWINDOW:4:20 MINLEN:50\n\n    cat singles.*.fastq.gz > ${sampleID}.singletons.fastq.gz\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "rawCombinedReads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "trimmedReads"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "cpus 5",
            "publishDir \"${params.outputdir}/${sampleID}/01-trimmedReads/trimmomatic/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "assemblySpades": {
        "name_process": "assemblySpades",
        "string_process": "\nprocess assemblySpades {\n    tag {sampleID}\n    \n    memory '25G'\n    cpus 10\n\n    input:\n    set sampleID, \"paired.fwd.fastq.gz\", \"paired.rev.fastq.gz\", \"singletons.fastq.gz\" from trimmedReads\n\n    output:\n    set sampleID, \"${sampleID}.contigs.fasta\" into contigsForCleanup\n    set sampleID, \"${sampleID}.scaffolds.fasta\" into scaffoldsForCleanup\n\n    \"\"\"\n    ${params.spades} \\\n    -k 21,33,55,77 \\\n    --memory ${task.memory.toGiga()} \\\n    --threads ${task.cpus} \\\n    --careful \\\n    -1 paired.fwd.fastq.gz \\\n    -2 paired.rev.fastq.gz \\\n    -s singletons.fastq.gz \\\n    -o .\n    mv scaffolds.fasta ${sampleID}.scaffolds.fasta\n    mv contigs.fasta ${sampleID}.contigs.fasta\n\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "\"\"\"\n    ${params.spades} \\\n    -k 21,33,55,77 \\\n    --memory ${task.memory.toGiga()} \\\n    --threads ${task.cpus} \\\n    --careful \\\n    -1 paired.fwd.fastq.gz \\\n    -2 paired.rev.fastq.gz \\\n    -s singletons.fastq.gz \\\n    -o .\n    mv scaffolds.fasta ${sampleID}.scaffolds.fasta\n    mv contigs.fasta ${sampleID}.contigs.fasta\n\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimmedReads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "contigsForCleanup",
            "scaffoldsForCleanup"
        ],
        "nb_outputs": 2,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "memory '25G'",
            "cpus 10"
        ],
        "when": "",
        "stub": ""
    },
    "quastScaffolds": {
        "name_process": "quastScaffolds",
        "string_process": "\nprocess quastScaffolds {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/04-QC/scaffolds/\", mode: 'copy'\n\n    input: \n    set sampleID, \"${sampleID}.fasta\" from scaffoldsRawForQuast\n\n    output:\n    file(\"quast_results/*\") into quastResultsScaffolds\n\n    \"\"\"\n    ${params.quast} --fungus --conserved-genes-finding --min-contig 0 --threads 10 --split-scaffolds ${sampleID}.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n    ${params.quast} --fungus --conserved-genes-finding --min-contig 0 --threads 10 --split-scaffolds ${sampleID}.fasta\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffoldsRawForQuast"
        ],
        "nb_inputs": 1,
        "outputs": [
            "quastResultsScaffolds"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/04-QC/scaffolds/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "quastContigs": {
        "name_process": "quastContigs",
        "string_process": "\nprocess quastContigs {\n    tag {sampleID}\n    publishDir \"${params.outputdir}/${sampleID}/04-QC/contigs/\", mode: 'copy'\n\n    input: \n    set sampleID, \"${sampleID}.fasta\" from contigsRawForQuast\n\n    output:\n    file(\"quast_results/*\") into quastResultsContigs\n\n    \"\"\"\n    ${params.quast} --fungus --conserved-genes-finding --min-contig 0 --threads 10 ${sampleID}.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n    ${params.quast} --fungus --conserved-genes-finding --min-contig 0 --threads 10 ${sampleID}.fasta\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigsRawForQuast"
        ],
        "nb_inputs": 1,
        "outputs": [
            "quastResultsContigs"
        ],
        "nb_outputs": 1,
        "name_workflow": "JWDebler__nf-assembly",
        "directive": [
            "tag {sampleID}",
            "publishDir \"${params.outputdir}/${sampleID}/04-QC/contigs/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}