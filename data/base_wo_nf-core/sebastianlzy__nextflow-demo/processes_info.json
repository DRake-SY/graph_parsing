{
    "fastqc_raw": {
        "name_process": "fastqc_raw",
        "string_process": "\nprocess fastqc_raw {\n\n    tag \"$sample_id\"\n    echo true\n    \n    publishDir \"${params.outdir}/fastqc_raw\", mode: 'copy', overwrite: true\n\n    input:\n    tuple val(sample_id),file(reads_r1),file(reads_r2) from read_pairs_ch\n\n\n    output:\n    tuple val(sample_id),file('*_fastqc.{zip,html}') \n    tuple val(sample_id),file('*_nbases.txt') \n\n    script:\n    \"\"\"\n #   module load python\n    fastqc --quiet ${\n    }\n    fastqc --quiet ${reads_r2}\n\n #   python3 docker_config/q30/q30.py ${reads_r1} > ${sample_id}_R1_nbases.txt;\n #   python3 docker_config/q30/q30.py ${reads_r2} > ${sample_id}_R2_nbases.txt\n\n     q30.py ${reads_r1} > ${sample_id}_R1_nbases.txt;\n     q30.py ${reads_r2} > ${sample_id}_R2_nbases.txt\n\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n #   module load python\n    fastqc --quiet ${\n    }\n    fastqc --quiet ${reads_r2}\n\n #   python3 docker_config/q30/q30.py ${reads_r1} > ${sample_id}_R1_nbases.txt;\n #   python3 docker_config/q30/q30.py ${reads_r2} > ${sample_id}_R2_nbases.txt\n\n     q30.py ${reads_r1} > ${sample_id}_R1_nbases.txt;\n     q30.py ${reads_r2} > ${sample_id}_R2_nbases.txt\n\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "read_pairs_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_id",
            "sample_id"
        ],
        "nb_outputs": 2,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/fastqc_raw\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "fastq_split": {
        "name_process": "fastq_split",
        "string_process": "\nprocess fastq_split {\n\n    tag \"$sample_id\"\n    echo true\n    \n    publishDir \"${params.outdir}/wgbs/${sample_id}\"\n\n    input:\n    tuple val(sample_id), file(reads_r1), file(reads_r2) from read_pairs_ch2\n\n    output:\n    tuple val(sample_id), file('*_1.*'), file('*_2.*') into ch_split_fastq\n\n    script:\n    \"\"\"\n    cat $reads_r1 | split -l 1000000 - ${sample_id}_1.\n    cat $reads_r2 | split -l 1000000 - ${sample_id}_2.\n    \n    \"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    cat $reads_r1 | split -l 1000000 - ${sample_id}_1.\n    cat $reads_r2 | split -l 1000000 - ${sample_id}_2.\n    \n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "read_pairs_ch2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_split_fastq"
        ],
        "nb_outputs": 1,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/wgbs/${sample_id}\""
        ],
        "when": "",
        "stub": ""
    },
    "trim_galore": {
        "name_process": "trim_galore",
        "string_process": "\nprocess trim_galore {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/wgbs/${sample_id}/trimmed_reads\", pattern:\"*.trimming_report.txt\", mode:'copy', overwrite: true\n\n    input:\n    tuple val(sample_id), val(sub_ID),file(split_reads_r1), file(split_reads_r2) from ch_fastq_for_trim\n\n    output:\n    tuple val(sample_id),val(sub_ID), file('*_1.*_val_1.fq'), file('*_2.*_val_2.fq') into ch_trimmed_reads_for_alignment,ch_trimmed_reads_for_align_lambda,ch_trimmed_reads_fastQC\n\n    tuple val(sample_id), file(\"*trimming_report.txt\")\n\n    script:\n    \"\"\"\n\n    trim_galore --dont_gzip --clip_R2 18 --three_prime_clip_R1 18 --phred33 --paired ${split_reads_r1} ${split_reads_r2}\n\n    ## remove splitted fastq files\n    rm $split_reads_r1 $split_reads_r2\n\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n\n    trim_galore --dont_gzip --clip_R2 18 --three_prime_clip_R1 18 --phred33 --paired ${split_reads_r1} ${split_reads_r2}\n\n    ## remove splitted fastq files\n    rm $split_reads_r1 $split_reads_r2\n\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_fastq_for_trim"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_trimmed_reads_for_alignment",
            "ch_trimmed_reads_for_align_lambda",
            "ch_trimmed_reads_fastQC",
            "sample_id"
        ],
        "nb_outputs": 4,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/wgbs/${sample_id}/trimmed_reads\", pattern:\"*.trimming_report.txt\", mode:'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "fastqc_aftertrim": {
        "name_process": "fastqc_aftertrim",
        "string_process": "\nprocess fastqc_aftertrim {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/fastqc_aftertrim\", mode: 'copy', overwrite: true\n\n    input:\n    tuple val(sample_id), file(trimmed_reads_r1), file(trimmed_reads_r2) from ch_trimmed_reads_fastQC2\n\n    output:\n    tuple val(sample_id), file('*_aftertrim_*nbases.txt'), file('*_fastqc.{zip,html}')\n\n\n    script:\n\n    \"\"\"\n   ## module load python\n\n    cat ${trimmed_reads_r1} >> ${sample_id}_aftertrim_R1.fq;\n    cat ${trimmed_reads_r2} >> ${sample_id}_aftertrim_R2.fq;\n\n  #  python2 /Users/mirmac2103lizhou/mirxes_project/WGBS_AWS/docker_config/q30/q30.py ${sample_id}_aftertrim_R1.fq > ${sample_id}_aftertrim_R1_nbases.txt;\n  #  python2 /Users/mirmac2103lizhou/mirxes_project/WGBS_AWS/docker_config/q30/q30.py ${sample_id}_aftertrim_R2.fq > ${sample_id}_aftertrim_R2_nbases.txt;\n\n    q30.py ${sample_id}_aftertrim_R1.fq > ${sample_id}_aftertrim_R1_nbases.txt;\n    q30.py ${sample_id}_aftertrim_R2.fq > ${sample_id}_aftertrim_R2_nbases.txt;\n\n    fastqc --quiet ${sample_id}_aftertrim_R1.fq;\n    fastqc --quiet ${sample_id}_aftertrim_R2.fq;\n\n    rm ${sample_id}_aftertrim_R1.fq ${sample_id}_aftertrim_R2.fq\n\n    rm ${trimmed_reads_r1} ${trimmed_reads_r2}\n\n\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n   ## module load python\n\n    cat ${trimmed_reads_r1} >> ${sample_id}_aftertrim_R1.fq;\n    cat ${trimmed_reads_r2} >> ${sample_id}_aftertrim_R2.fq;\n\n  #  python2 /Users/mirmac2103lizhou/mirxes_project/WGBS_AWS/docker_config/q30/q30.py ${sample_id}_aftertrim_R1.fq > ${sample_id}_aftertrim_R1_nbases.txt;\n  #  python2 /Users/mirmac2103lizhou/mirxes_project/WGBS_AWS/docker_config/q30/q30.py ${sample_id}_aftertrim_R2.fq > ${sample_id}_aftertrim_R2_nbases.txt;\n\n    q30.py ${sample_id}_aftertrim_R1.fq > ${sample_id}_aftertrim_R1_nbases.txt;\n    q30.py ${sample_id}_aftertrim_R2.fq > ${sample_id}_aftertrim_R2_nbases.txt;\n\n    fastqc --quiet ${sample_id}_aftertrim_R1.fq;\n    fastqc --quiet ${sample_id}_aftertrim_R2.fq;\n\n    rm ${sample_id}_aftertrim_R1.fq ${sample_id}_aftertrim_R2.fq\n\n    rm ${trimmed_reads_r1} ${trimmed_reads_r2}\n\n\n    \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "ch_trimmed_reads_fastQC2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_id"
        ],
        "nb_outputs": 1,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/fastqc_aftertrim\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "bismark_align_lambda": {
        "name_process": "bismark_align_lambda",
        "string_process": "\nprocess bismark_align_lambda {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/wgbs/$sample_id/bam_files_lambda\"\n\n    input:\n    tuple val(sample_id), val(sub_ID), file(trimmed_reads_r1),file(trimmed_reads_r2) from ch_trimmed_reads_for_align_lambda\n    file LAMBDA_PATH\n\n    output:\n\n    tuple val(sample_id),file(\"*_bismark_bt2_PE_report.txt\")\n\n    script:\n    \"\"\"\n    ## --path_to_bowtie2 /usr/local/bin\n    bismark --bowtie2 -p 2 --bam --score_min L,0,-0.2 lambda -1 ${trimmed_reads_r1} -2 ${trimmed_reads_r2}\n\n    ## remove the bam files\n    rm ${sample_id}*_bismark_bt2_pe.bam\n\n\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    ## --path_to_bowtie2 /usr/local/bin\n    bismark --bowtie2 -p 2 --bam --score_min L,0,-0.2 lambda -1 ${trimmed_reads_r1} -2 ${trimmed_reads_r2}\n\n    ## remove the bam files\n    rm ${sample_id}*_bismark_bt2_pe.bam\n\n\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "Bismark"
        ],
        "tools_url": [
            "https://bio.tools/bismark"
        ],
        "tools_dico": [
            {
                "name": "Bismark",
                "uri": "https://bio.tools/bismark",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3295",
                            "term": "Epigenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3173",
                            "term": "Epigenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3204",
                                    "term": "Methylation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite sequence mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3204",
                                    "term": "Methylation profile analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Bismark is a tool to map bisulfite treated sequencing reads and perform methylation calling in a quick and easy-to-use fashion.",
                "homepage": "https://github.com/FelixKrueger/Bismark"
            }
        ],
        "inputs": [
            "ch_trimmed_reads_for_align_lambda",
            "LAMBDA_PATH"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample_id"
        ],
        "nb_outputs": 1,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/wgbs/$sample_id/bam_files_lambda\""
        ],
        "when": "",
        "stub": ""
    },
    "bismark_align": {
        "name_process": "bismark_align",
        "string_process": "\nprocess bismark_align {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/wgbs/$sample_id/bam_files\",  pattern:\"*_bismark_bt2_PE_report.txt\", mode: \"copy\", overwrite: true\n\n    input:\n    tuple val(sample_id),val(sub_ID), file(trimmed_reads_r1),file(trimmed_reads_r2) from ch_trimmed_reads_for_alignment\n    file GENOME_PRIMARY\n    file GENOME_ALT\n\n    output:\n    tuple val(sample_id),val(sub_ID), file('*_val_1_bismark_bt2_pe.bam'), file('*_val_1.fq_unmapped_reads_1_bismark_bt2_pe.bam') into ch_bismark_bam\n\n                                                                \n\n    script:\n    \"\"\"\n    ## map the overall reads to the hg38 primary assembly\n    ## --path_to_bowtie2 /usr/local/bin\n    bismark --bowtie2 -p 2 --bam --un --ambiguous --score_min L,0,-0.2 GRCh38_primary -1 ${trimmed_reads_r1} -2 ${trimmed_reads_r2}\n\n    ## map the unmapped reads to hg38 alternate contigs\n\n    bismark --bowtie2 -p 2 --bam --score_min L,0,-0.2 GRCh38_alt -1 ${trimmed_reads_r1}_unmapped_reads_1.fq.gz -2 ${trimmed_reads_r2}_unmapped_reads_2.fq.gz\n\n    ## remove the unmapped reads and ambiguous reads\n    rm ${sample_id}*_unmapped_reads_2.fq.gz ${sample_id}*_unmapped_reads_1.fq.gz\n    rm ${sample_id}*_ambiguous_reads_2.fq.gz ${sample_id}*_ambiguous_reads_1.fq.gz\n\n\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n    ## map the overall reads to the hg38 primary assembly\n    ## --path_to_bowtie2 /usr/local/bin\n    bismark --bowtie2 -p 2 --bam --un --ambiguous --score_min L,0,-0.2 GRCh38_primary -1 ${trimmed_reads_r1} -2 ${trimmed_reads_r2}\n\n    ## map the unmapped reads to hg38 alternate contigs\n\n    bismark --bowtie2 -p 2 --bam --score_min L,0,-0.2 GRCh38_alt -1 ${trimmed_reads_r1}_unmapped_reads_1.fq.gz -2 ${trimmed_reads_r2}_unmapped_reads_2.fq.gz\n\n    ## remove the unmapped reads and ambiguous reads\n    rm ${sample_id}*_unmapped_reads_2.fq.gz ${sample_id}*_unmapped_reads_1.fq.gz\n    rm ${sample_id}*_ambiguous_reads_2.fq.gz ${sample_id}*_ambiguous_reads_1.fq.gz\n\n\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "Bismark"
        ],
        "tools_url": [
            "https://bio.tools/bismark"
        ],
        "tools_dico": [
            {
                "name": "Bismark",
                "uri": "https://bio.tools/bismark",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3295",
                            "term": "Epigenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3173",
                            "term": "Epigenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3204",
                                    "term": "Methylation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite sequence mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3186",
                                    "term": "Bisulfite read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3204",
                                    "term": "Methylation profile analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Bismark is a tool to map bisulfite treated sequencing reads and perform methylation calling in a quick and easy-to-use fashion.",
                "homepage": "https://github.com/FelixKrueger/Bismark"
            }
        ],
        "inputs": [
            "ch_trimmed_reads_for_alignment",
            "GENOME_PRIMARY",
            "GENOME_ALT"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_bismark_bam"
        ],
        "nb_outputs": 1,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/wgbs/$sample_id/bam_files\", pattern:\"*_bismark_bt2_PE_report.txt\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "merge_bam": {
        "name_process": "merge_bam",
        "string_process": "\nprocess merge_bam {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/wgbs/$sample_id/unsortedButMerged_ForBismark_file\", mode:\"copy\", overwrite: true\n\n    input:\n    tuple val(sample_id), file(bam_file1), file(bam_file2) from ch_bismark_bam2\n\n    output:\n    tuple val(sample_id), file(\"*_unsorted_merged.bam\") into ch_bismark_merged_bam\n\n\n    script:\n    \"\"\"\n    ## module load samtools/1.3\n\n    samtools merge -nf ${sample_id}_unsorted_merged.bam $bam_file1 $bam_file2\n\n    ## remove individual bamfiles\n   #  rm $bam_file1 $bam_file2\n\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    ## module load samtools/1.3\n\n    samtools merge -nf ${sample_id}_unsorted_merged.bam $bam_file1 $bam_file2\n\n    ## remove individual bamfiles\n   #  rm $bam_file1 $bam_file2\n\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_bismark_bam2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_bismark_merged_bam"
        ],
        "nb_outputs": 1,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/wgbs/$sample_id/unsortedButMerged_ForBismark_file\", mode:\"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "deduplication_bam": {
        "name_process": "deduplication_bam",
        "string_process": "\nprocess deduplication_bam {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/wgbs/$sample_id/unsortedButMerged_ForBismark_file\", pattern: \"*deduplication_report.txt\", mode:\"copy\", overwrite: true\n\n    input:\n    tuple val(sample_id), path(merged_bam) from ch_bismark_merged_bam\n\n    output:\n    tuple val(sample_id), file('*unsorted_merged.deduplicated.bam') into ch_deduplicated_bam_for_methylextract, ch_deduplicated_bam_for_sort\n\n    tuple val(sample_id), file(\"*_unsorted_merged.deduplication_report.txt\")\n\n    script:\n    \"\"\"\n    deduplicate_bismark -p --bam $merged_bam\n\n    ## remove the unsorted undeduplicated bam\n    rm $merged_bam\n\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    deduplicate_bismark -p --bam $merged_bam\n\n    ## remove the unsorted undeduplicated bam\n    rm $merged_bam\n\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_bismark_merged_bam"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_deduplicated_bam_for_methylextract",
            "ch_deduplicated_bam_for_sort",
            "sample_id"
        ],
        "nb_outputs": 3,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/wgbs/$sample_id/unsortedButMerged_ForBismark_file\", pattern: \"*deduplication_report.txt\", mode:\"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "methyl_extract": {
        "name_process": "methyl_extract",
        "string_process": "\nprocess methyl_extract {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/wgbs/$sample_id/unsortedButMerged_ForBismark_file/methylation_extraction\", mode:\"copy\", overwrite: true\n\n    input:\n    tuple val(sample_id), path(merged_deduplicated_bam) from ch_deduplicated_bam_for_methylextract\n    file filelist_genome_path\n\n    output:\n    file \"*\"\n\n\n    script:\n    \"\"\"\n\n    bismark_methylation_extractor -p --multicore 4 --gzip --no_overlap --comprehensive --merge_non_CpG --cutoff 1 --buffer_size 40G --zero_based --cytosine_report --genome_folder GRCh38 $merged_deduplicated_bam\n\n\n    \"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n\n    bismark_methylation_extractor -p --multicore 4 --gzip --no_overlap --comprehensive --merge_non_CpG --cutoff 1 --buffer_size 40G --zero_based --cytosine_report --genome_folder GRCh38 $merged_deduplicated_bam\n\n\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_deduplicated_bam_for_methylextract",
            "filelist_genome_path"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/wgbs/$sample_id/unsortedButMerged_ForBismark_file/methylation_extraction\", mode:\"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "sort_bam": {
        "name_process": "sort_bam",
        "string_process": "\nprocess sort_bam {\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/coverage_files_picard\", mode:\"copy\", overwrite: true\n\n    input:\n    tuple val(sample_id), path(merged_deduplicated_bam) from ch_deduplicated_bam_for_sort\n\n\n    output:\n    tuple val(sample_id), file('*_sorted_deduplicated.bam') into ch_bismark_sorted_deduplicated_bam1, ch_bismark_sorted_deduplicated_bam2\n\n    script:\n    \"\"\"\n   ## \t  module load java\n   ## \t  module load samtools/1.3\n\n    \t  samtools sort -@ 12 -m 4G -o ${sample_id}_sorted_deduplicated.bam $merged_deduplicated_bam\n\n    \"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n   ## \t  module load java\n   ## \t  module load samtools/1.3\n\n    \t  samtools sort -@ 12 -m 4G -o ${sample_id}_sorted_deduplicated.bam $merged_deduplicated_bam\n\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_deduplicated_bam_for_sort"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_bismark_sorted_deduplicated_bam1",
            "ch_bismark_sorted_deduplicated_bam2"
        ],
        "nb_outputs": 2,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/coverage_files_picard\", mode:\"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "coverage": {
        "name_process": "coverage",
        "string_process": "\nprocess coverage {\n\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/coverage_files_picard\", mode:\"copy\", overwrite: true\n\n    input:\n    tuple val(sample_id), path(sorted_deduplicated_bam) from ch_bismark_sorted_deduplicated_bam1\n    file GENOME_FASTA\n\n    output:\n\n    tuple val(sample_id),file(\"*_coverage_picard.txt\")\n\n    script:\n    \"\"\"\n   ## \t  module load java\n   ## \t  module load samtools/1.3\n\n\tpicard CollectWgsMetrics REFERENCE_SEQUENCE=hg38.fa \\\n\t    MINIMUM_MAPPING_QUALITY=0 \\\n\t\tINPUT=$sorted_deduplicated_bam \\\n\t\tOUTPUT=${sample_id}_coverage_picard.txt\n\n\n    \"\"\"\n\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n   ## \t  module load java\n   ## \t  module load samtools/1.3\n\n\tpicard CollectWgsMetrics REFERENCE_SEQUENCE=hg38.fa \\\n\t    MINIMUM_MAPPING_QUALITY=0 \\\n\t\tINPUT=$sorted_deduplicated_bam \\\n\t\tOUTPUT=${sample_id}_coverage_picard.txt\n\n\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "ch_bismark_sorted_deduplicated_bam1",
            "GENOME_FASTA"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample_id"
        ],
        "nb_outputs": 1,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/coverage_files_picard\", mode:\"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "insert_size": {
        "name_process": "insert_size",
        "string_process": "\nprocess insert_size {\n\n\n    tag \"$sample_id\"\n    echo true\n\n    publishDir \"${params.outdir}/insert_size_files\", mode:\"copy\", overwrite: true\n\n    input:\n    tuple val(sample_id), path(sorted_deduplicated_bam) from ch_bismark_sorted_deduplicated_bam2\n\n    output:\n\n    tuple val(sample_id),file(\"*_insert_size_metrics.txt\")\n\n    script:\n    \"\"\"\n  ##  module load java\n\n    picard CollectInsertSizeMetrics \\\n        I=$sorted_deduplicated_bam \\\n        O=${sample_id}_insert_size_metrics.txt \\\n        H=${sample_id}_insert_size_histogram.pdf \\\n        INCLUDE_DUPLICATES=false \\\n        ASSUME_SORTED=true\n\n    \"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "    \"\"\"\n  ##  module load java\n\n    picard CollectInsertSizeMetrics \\\n        I=$sorted_deduplicated_bam \\\n        O=${sample_id}_insert_size_metrics.txt \\\n        H=${sample_id}_insert_size_histogram.pdf \\\n        INCLUDE_DUPLICATES=false \\\n        ASSUME_SORTED=true\n\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "ch_bismark_sorted_deduplicated_bam2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_id"
        ],
        "nb_outputs": 1,
        "name_workflow": "sebastianlzy__nextflow-demo",
        "directive": [
            "tag \"$sample_id\"",
            "echo true",
            "publishDir \"${params.outdir}/insert_size_files\", mode:\"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    }
}