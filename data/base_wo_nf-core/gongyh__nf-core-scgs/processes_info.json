{
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n    output:\n    file 'software_versions_mqc.yaml' into software_versions_yaml1, software_versions_yaml2\n\n    script:\n                                                                     \n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    trim_galore --version &> v_trim_galore.txt\n    bowtie2 --version &> v_bowtie2.txt\n    minimap2 -V &> v_minimap2.txt\n    samtools --version &> v_samtools.txt\n    bedtools --version &> v_bedtools.txt\n    preseq &> v_preseq.txt\n    qualimap -h &> v_qualimap.txt\n    if [ x=`picard MarkDuplicates --version &> v_picard.txt` = 1 ]; then return 0; fi\n    #gatk3 -version &> v_gatk.txt\n    Rscript -e 'print(packageVersion(\"AneuFinder\"))' &> v_AneuFinder.txt\n    spades.py --version &> v_spades.txt\n    canu -version &> v_canu.txt\n    blastn -version &> v_blast.txt\n    quast.py --version &> v_quast.txt\n    multiqc --version &> v_multiqc.txt\n    diamond version &> v_diamond.txt\n    kraken --version | grep Kraken &> v_kraken.txt\n    head -n 1 /opt/conda/envs/nf-core-gongyh-scgs/lib/python3.6/site-packages/checkm/VERSION &> v_checkm.txt\n    prokka -v &> v_prokka.txt\n    emapper.py --version | grep emapper &> v_eggnogmapper.txt\n    echo 'v0.0.1' > v_monovar.txt\n    blobtools -v &> v_blobtools.txt\n    scrape_software_versions.py > software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    trim_galore --version &> v_trim_galore.txt\n    bowtie2 --version &> v_bowtie2.txt\n    minimap2 -V &> v_minimap2.txt\n    samtools --version &> v_samtools.txt\n    bedtools --version &> v_bedtools.txt\n    preseq &> v_preseq.txt\n    qualimap -h &> v_qualimap.txt\n    if [ x=`picard MarkDuplicates --version &> v_picard.txt` = 1 ]; then return 0; fi\n    #gatk3 -version &> v_gatk.txt\n    Rscript -e 'print(packageVersion(\"AneuFinder\"))' &> v_AneuFinder.txt\n    spades.py --version &> v_spades.txt\n    canu -version &> v_canu.txt\n    blastn -version &> v_blast.txt\n    quast.py --version &> v_quast.txt\n    multiqc --version &> v_multiqc.txt\n    diamond version &> v_diamond.txt\n    kraken --version | grep Kraken &> v_kraken.txt\n    head -n 1 /opt/conda/envs/nf-core-gongyh-scgs/lib/python3.6/site-packages/checkm/VERSION &> v_checkm.txt\n    prokka -v &> v_prokka.txt\n    emapper.py --version | grep emapper &> v_eggnogmapper.txt\n    echo 'v0.0.1' > v_monovar.txt\n    blobtools -v &> v_blobtools.txt\n    scrape_software_versions.py > software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [
            "FastQC",
            "Rbowtie2",
            "Minimap2",
            "SAMtools",
            "BEDTools",
            "preseq",
            "QualiMap",
            "CANU",
            "G-BLASTN",
            "MultiQC",
            "Diamond",
            "Kraken",
            "Prokka",
            "BlobTools"
        ],
        "tools_url": [
            "https://bio.tools/fastqc",
            "https://bio.tools/rbowtie2",
            "https://bio.tools/minimap2",
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools",
            "https://bio.tools/preseq",
            "https://bio.tools/qualimap",
            "https://bio.tools/canu",
            "https://bio.tools/g-blastn",
            "https://bio.tools/multiqc",
            "https://bio.tools/diamond",
            "https://bio.tools/kraken",
            "https://bio.tools/prokka",
            "https://bio.tools/blobtools"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            },
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "preseq",
                "uri": "https://bio.tools/preseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package is aimed at predicting and number of distinct reads and how many will be expected from additional sequencing using an initial sequencing experiment. The estimates can then be used to examine the utility of further sequencing, optimize the sequencing depth, or to screen multiple libraries to avoid low complexity samples.",
                "homepage": "http://smithlabresearch.org/software/preseq/"
            },
            {
                "name": "QualiMap",
                "uri": "https://bio.tools/qualimap",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Platform-independent application written in Java and R that provides both a Graphical User Inteface (GUI) and a command-line interface to facilitate the quality control of alignment sequencing data.",
                "homepage": "http://qualimap.bioinfo.cipf.es/"
            },
            {
                "name": "CANU",
                "uri": "https://bio.tools/canu",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De-novo assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De Bruijn graph"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "Sequence assembly (de-novo assembly)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "De-novo assembly tool for long read chemistry like Nanopore data and PacBio data.",
                "homepage": "https://github.com/marbl/canu"
            },
            {
                "name": "G-BLASTN",
                "uri": "https://bio.tools/g-blastn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0346",
                                    "term": "Sequence similarity search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2976",
                                "term": "Protein sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0857",
                                "term": "Sequence search results"
                            }
                        ]
                    }
                ],
                "description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "homepage": "http://www.comp.hkbu.edu.hk/~chxw/software/G-BLASTN.html"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            },
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            },
            {
                "name": "Kraken",
                "uri": "https://bio.tools/kraken",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "System for assigning taxonomic labels to short DNA sequences, usually obtained through metagenomic studies. Previous attempts by other bioinformatics software to accomplish this task have often used sequence alignment or machine learning techniques that were quite slow, leading to the development of less sensitive but much faster abundance estimation programs. It aims to achieve high sensitivity and high speed by utilizing exact alignments of k-mers and a novel classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken/"
            },
            {
                "name": "Prokka",
                "uri": "https://bio.tools/prokka",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0781",
                            "term": "Virology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.",
                "homepage": "https://github.com/tseemann/prokka"
            },
            {
                "name": "BlobTools",
                "uri": "https://bio.tools/blobtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly validation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly QC"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Visualisation, quality control and taxonomic partitioning of genome datasets.",
                "homepage": "https://github.com/DRL/blobtools"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "software_versions_yaml1",
            "software_versions_yaml2"
        ],
        "nb_outputs": 2,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "save_reference": {
        "name_process": "save_reference",
        "string_process": "\nprocess save_reference {\n    publishDir path: \"${params.outdir}/reference_genome\", mode: 'copy'\n\n    input:\n    file fasta from fasta\n    file gff from gff\n\n    output:\n    file \"genome.fa\"\n    file \"genome.gff\"\n    file \"*.bed\"\n    file \"genome.bed\" into genome_circlize, genome_samtools\n\n    when:\n    params.fasta && params.gff\n\n    script:\n    \"\"\"\n    ln -s ${fasta} genome.fa\n    ln -s ${gff} genome.gff\n    fa2bed.py genome.fa\n    cat genome.gff | grep \\$'\\tgene\\t' | bedtools sort | cut -f1,4,5,7 > genes.bed\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    ln -s ${fasta} genome.fa\n    ln -s ${gff} genome.gff\n    fa2bed.py genome.fa\n    cat genome.gff | grep \\$'\\tgene\\t' | bedtools sort | cut -f1,4,5,7 > genes.bed\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "fasta",
            "gff"
        ],
        "nb_inputs": 2,
        "outputs": [
            "genome_circlize",
            "genome_samtools"
        ],
        "nb_outputs": 2,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir path: \"${params.outdir}/reference_genome\", mode: 'copy'"
        ],
        "when": "params.fasta && params.gff",
        "stub": ""
    },
    "prepare_bowtie2": {
        "name_process": "prepare_bowtie2",
        "string_process": "\nprocess prepare_bowtie2 {\n    publishDir path: \"${params.outdir}/reference_genome\", mode: 'copy'\n\n    input:\n    file fasta from fasta\n\n    output:\n    file \"Bowtie2Index\" into bowtie2_index\n\n    when:\n    params.fasta\n\n    script:\n    \"\"\"\n    mkdir -p Bowtie2Index; cd Bowtie2Index\n    ln -s ../${fasta} genome.fa\n    bowtie2-build genome.fa genome\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    mkdir -p Bowtie2Index; cd Bowtie2Index\n    ln -s ../${fasta} genome.fa\n    bowtie2-build genome.fa genome\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [
            "bowtie2_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir path: \"${params.outdir}/reference_genome\", mode: 'copy'"
        ],
        "when": "params.fasta",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n    tag \"$name\"\n    publishDir \"${params.outdir}/fastqc\", mode: 'copy',\n        saveAs: {filename -> filename.indexOf(\".zip\") > 0 ? \"zips/$filename\" : \"$filename\"}\n\n    input:\n    set val(name), file(reads) from read_files_fastqc\n\n    output:\n    file \"*_fastqc.{zip,html}\" into fastqc_results1, fastqc_results2\n\n    script:\n    \"\"\"\n    fastqc -q $reads\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    fastqc -q $reads\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "read_files_fastqc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_results1",
            "fastqc_results2"
        ],
        "nb_outputs": 2,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$name\"",
            "publishDir \"${params.outdir}/fastqc\", mode: 'copy' , saveAs: {filename -> filename.indexOf(\".zip\") > 0 ? \"zips/$filename\" : \"$filename\"}"
        ],
        "when": "",
        "stub": ""
    },
    "trim_galore": {
        "name_process": "trim_galore",
        "string_process": " process trim_galore {\n        tag \"$name\"\n        publishDir \"${params.outdir}/trim_galore\", mode: 'copy',\n            saveAs: {filename ->\n                if (filename.indexOf(\"_fastqc\") > 0) \"FastQC/$filename\"\n                else if (filename.indexOf(\"trimming_report.txt\") > 0) \"logs/$filename\"\n                else params.saveTrimmed ? filename : null\n            }\n\n        input:\n        set val(name), file(reads) from read_files_trimming\n\n        output:\n        file '*.fq.gz' into trimmed_reads, trimmed_reads_for_spades, trimmed_reads_for_kraken, trimmed_reads_for_kmer\n        file '*trimming_report.txt' into trimgalore_results1, trimgalore_results2\n        file \"*_fastqc.{zip,html}\" into trimgalore_fastqc_reports1, trimgalore_fastqc_reports2\n\n        script:\n        c_r1 = params.clip_r1 > 0 ? \"--clip_r1 ${params.clip_r1}\" : ''\n        c_r2 = params.clip_r2 > 0 ? \"--clip_r2 ${params.clip_r2}\" : ''\n        tpc_r1 = params.three_prime_clip_r1 > 0 ? \"--three_prime_clip_r1 ${params.three_prime_clip_r1}\" : ''\n        tpc_r2 = params.three_prime_clip_r2 > 0 ? \"--three_prime_clip_r2 ${params.three_prime_clip_r2}\" : ''\n        if (single_end) {\n            \"\"\"\n            trim_galore --fastqc --gzip $c_r1 $tpc_r1 $reads\n            \"\"\"\n        } else {\n            \"\"\"\n            trim_galore --paired --fastqc --gzip $c_r1 $c_r2 $tpc_r1 $tpc_r2 $reads\n            \"\"\"\n        }\n    }",
        "nb_lignes_process": 30,
        "string_script": "        c_r1 = params.clip_r1 > 0 ? \"--clip_r1 ${params.clip_r1}\" : ''\n        c_r2 = params.clip_r2 > 0 ? \"--clip_r2 ${params.clip_r2}\" : ''\n        tpc_r1 = params.three_prime_clip_r1 > 0 ? \"--three_prime_clip_r1 ${params.three_prime_clip_r1}\" : ''\n        tpc_r2 = params.three_prime_clip_r2 > 0 ? \"--three_prime_clip_r2 ${params.three_prime_clip_r2}\" : ''\n        if (single_end) {\n            \"\"\"\n            trim_galore --fastqc --gzip $c_r1 $tpc_r1 $reads\n            \"\"\"\n        } else {\n            \"\"\"\n            trim_galore --paired --fastqc --gzip $c_r1 $c_r2 $tpc_r1 $tpc_r2 $reads\n            \"\"\"\n        }",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "read_files_trimming"
        ],
        "nb_inputs": 1,
        "outputs": [
            "trimmed_reads",
            "trimmed_reads_for_spades",
            "trimmed_reads_for_kraken",
            "trimmed_reads_for_kmer",
            "trimgalore_results1",
            "trimgalore_results2",
            "trimgalore_fastqc_reports1",
            "trimgalore_fastqc_reports2"
        ],
        "nb_outputs": 8,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$name\"",
            "publishDir \"${params.outdir}/trim_galore\", mode: 'copy' , saveAs: {filename -> if (filename.indexOf(\"_fastqc\") > 0) \"FastQC/$filename\" else if (filename.indexOf(\"trimming_report.txt\") > 0) \"logs/$filename\" else params.saveTrimmed ? filename : null }"
        ],
        "when": "",
        "stub": ""
    },
    "kraken": {
        "name_process": "kraken",
        "string_process": "\nprocess kraken {\n    tag \"$prefix\"\n    publishDir path: \"${params.outdir}/kraken\", mode: 'copy'\n\n    input:\n    file reads from trimmed_reads_for_kraken\n    file db from kraken_db\n\n    output:\n    file \"${prefix}.report\" into kraken_for_mqc1, kraken_for_mqc2\n    file \"${prefix}.krona.html\"\n\n    when:\n    params.kraken_db\n\n    script:\n    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    mode = single_end ? \"\" : \"--paired\"\n    \"\"\"\n    kraken -db $db --threads ${task.cpus} --fastq-input --gzip-compressed ${mode} --check-names --output ${prefix}.krk $reads\n    kraken-report -db $db ${prefix}.krk > ${prefix}.report\n    cut -f2,3 ${prefix}.krk > ${prefix}.f23\n    ktImportTaxonomy -o ${prefix}.krona.html ${prefix}.f23\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    mode = single_end ? \"\" : \"--paired\"\n    \"\"\"\n    kraken -db $db --threads ${task.cpus} --fastq-input --gzip-compressed ${mode} --check-names --output ${prefix}.krk $reads\n    kraken-report -db $db ${prefix}.krk > ${prefix}.report\n    cut -f2,3 ${prefix}.krk > ${prefix}.f23\n    ktImportTaxonomy -o ${prefix}.krona.html ${prefix}.f23\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "MoDEL",
            "Kraken"
        ],
        "tools_url": [
            "https://bio.tools/model",
            "https://bio.tools/kraken"
        ],
        "tools_dico": [
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            },
            {
                "name": "Kraken",
                "uri": "https://bio.tools/kraken",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "System for assigning taxonomic labels to short DNA sequences, usually obtained through metagenomic studies. Previous attempts by other bioinformatics software to accomplish this task have often used sequence alignment or machine learning techniques that were quite slow, leading to the development of less sensitive but much faster abundance estimation programs. It aims to achieve high sensitivity and high speed by utilizing exact alignments of k-mers and a novel classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken/"
            }
        ],
        "inputs": [
            "trimmed_reads_for_kraken",
            "kraken_db"
        ],
        "nb_inputs": 2,
        "outputs": [
            "kraken_for_mqc1",
            "kraken_for_mqc2"
        ],
        "nb_outputs": 2,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir path: \"${params.outdir}/kraken\", mode: 'copy'"
        ],
        "when": "params.kraken_db",
        "stub": ""
    },
    "saturation": {
        "name_process": "saturation",
        "string_process": "\nprocess saturation {\n    tag \"$prefix\"\n    publishDir path: \"${params.outdir}/saturation\", mode: 'copy'\n\n    input:\n    file reads from trimmed_reads_for_kmer\n\n    output:\n    file \"${prefix}_kmer.pdf\"\n    file \"${prefix}_cov31_*.csv\"\n\n    when:\n    params.saturation\n\n    script:\n    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    R1 = reads[0].toString()\n    if (single_end) {\n    \"\"\"\n    fastp -i $R1 -A -G -Q -L -s 10 -d 0 -o ${prefix}_split.fq.gz\n    for i in {1..10}; do\n      mccortex31 build --kmer 31 --sample \\$i -t ${task.cpus} -Q 20 -m 8G \\\n        --seq \\${i}.${prefix}_split.fq.gz \\${i}.k31.ctx\n      if [ \\$i == 1 ]; then\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:\\${i}.k31.ctx\n        cp -f 1.k31.ctx tmp_clean31.ctx\n      else\n        mccortex31 join -m 8G --out merged_clean31.ctx 0:\\${i}.k31.ctx 0:tmp_clean31.ctx\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:merged_clean31.ctx\n        mv -f merged_clean31.ctx tmp_clean31.ctx\n      fi\n    done\n    KmerDensity.R \\$PWD ${prefix}\n    \"\"\"\n    } else {\n    R2 = reads[1].toString()\n    \"\"\"\n    fastp -i $R1 -I $R2 -A -G -Q -L -s 10 -d 0 -o ${prefix}_split_R1.fq.gz -O ${prefix}_split_R2.fq.gz\n    for i in {1..10}; do\n      mccortex31 build --kmer 31 --sample \\$i -t ${task.cpus} -Q 20 -m 8G \\\n        --seq2 \\${i}.${prefix}_split_R1.fq.gz:\\${i}.${prefix}_split_R2.fq.gz \\${i}.k31.ctx\n      if [ \\$i == 1 ]; then\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:\\${i}.k31.ctx\n        cp -f 1.k31.ctx tmp_clean31.ctx\n      else\n        mccortex31 join -m 8G --out merged_clean31.ctx 0:\\${i}.k31.ctx 0:tmp_clean31.ctx\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:merged_clean31.ctx\n        mv -f merged_clean31.ctx tmp_clean31.ctx\n      fi\n    done\n    KmerDensity.R \\$PWD ${prefix}\n    \"\"\"\n    }\n\n}",
        "nb_lignes_process": 54,
        "string_script": "    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    R1 = reads[0].toString()\n    if (single_end) {\n    \"\"\"\n    fastp -i $R1 -A -G -Q -L -s 10 -d 0 -o ${prefix}_split.fq.gz\n    for i in {1..10}; do\n      mccortex31 build --kmer 31 --sample \\$i -t ${task.cpus} -Q 20 -m 8G \\\n        --seq \\${i}.${prefix}_split.fq.gz \\${i}.k31.ctx\n      if [ \\$i == 1 ]; then\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:\\${i}.k31.ctx\n        cp -f 1.k31.ctx tmp_clean31.ctx\n      else\n        mccortex31 join -m 8G --out merged_clean31.ctx 0:\\${i}.k31.ctx 0:tmp_clean31.ctx\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:merged_clean31.ctx\n        mv -f merged_clean31.ctx tmp_clean31.ctx\n      fi\n    done\n    KmerDensity.R \\$PWD ${prefix}\n    \"\"\"\n    } else {\n    R2 = reads[1].toString()\n    \"\"\"\n    fastp -i $R1 -I $R2 -A -G -Q -L -s 10 -d 0 -o ${prefix}_split_R1.fq.gz -O ${prefix}_split_R2.fq.gz\n    for i in {1..10}; do\n      mccortex31 build --kmer 31 --sample \\$i -t ${task.cpus} -Q 20 -m 8G \\\n        --seq2 \\${i}.${prefix}_split_R1.fq.gz:\\${i}.${prefix}_split_R2.fq.gz \\${i}.k31.ctx\n      if [ \\$i == 1 ]; then\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:\\${i}.k31.ctx\n        cp -f 1.k31.ctx tmp_clean31.ctx\n      else\n        mccortex31 join -m 8G --out merged_clean31.ctx 0:\\${i}.k31.ctx 0:tmp_clean31.ctx\n        mccortex31 clean -t ${task.cpus} -m 8G -U10 -T16 -f -o null -C ${prefix}_cov31_p\\${i}.csv 0:merged_clean31.ctx\n        mv -f merged_clean31.ctx tmp_clean31.ctx\n      fi\n    done\n    KmerDensity.R \\$PWD ${prefix}\n    \"\"\"\n    }",
        "nb_lignes_script": 37,
        "language_script": "bash",
        "tools": [
            "CR10",
            "fastPHASE",
            "R2"
        ],
        "tools_url": [
            "https://bio.tools/CR10",
            "https://bio.tools/fastphase",
            "https://bio.tools/R2"
        ],
        "tools_dico": [
            {
                "name": "CR10",
                "uri": "https://bio.tools/CR10",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "PUBLIC DATABASE OF COSMIC RADIATION MEASUREMENTS AT AVIATION ALTITUDES OF ABOUT 10 KM.\n\nWhen using these data, please read this info",
                "homepage": "http://cr10.odz.ujf.cas.cz"
            },
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            },
            {
                "name": "R2",
                "uri": "https://bio.tools/R2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Expression correlation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set enrichment analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Co-expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "GSEA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Functional enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set over-represenation analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "R2 is a biologist friendly web based genomics analysis and visualization application",
                "homepage": "http://r2.amc.nl"
            }
        ],
        "inputs": [
            "trimmed_reads_for_kmer"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir path: \"${params.outdir}/saturation\", mode: 'copy'"
        ],
        "when": "params.saturation",
        "stub": ""
    },
    "minimap2": {
        "name_process": "minimap2",
        "string_process": "\nprocess minimap2 {\n    tag \"$prefix\"\n    publishDir path: { params.saveAlignedIntermediates ? \"${params.outdir}/bowtie2\" : params.outdir }, mode: 'copy',\n               saveAs: {filename -> params.saveAlignedIntermediates ? filename : null }\n    input:\n    file reads from trimmed_reads\n    file fasta from fasta\n    \n    output:\n    file '*.bam' into bb_bam\n    \n    when:\n    denovo == false\n    \n    script:\n    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    filtering = params.allow_multi_align ? '' : \"-F 256\"\n    R1 = reads[0].toString()\n    \"\"\"\n    minimap2 -x map-ont -a $fasta $R1 | samtools view -b -q 40 -F 4 $filtering - > ${prefix}.bam\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    filtering = params.allow_multi_align ? '' : \"-F 256\"\n    R1 = reads[0].toString()\n    \"\"\"\n    minimap2 -x map-ont -a $fasta $R1 | samtools view -b -q 40 -F 4 $filtering - > ${prefix}.bam\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "CR10",
            "Minimap2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/CR10",
            "https://bio.tools/minimap2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "CR10",
                "uri": "https://bio.tools/CR10",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "PUBLIC DATABASE OF COSMIC RADIATION MEASUREMENTS AT AVIATION ALTITUDES OF ABOUT 10 KM.\n\nWhen using these data, please read this info",
                "homepage": "http://cr10.odz.ujf.cas.cz"
            },
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "trimmed_reads",
            "fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bb_bam"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir path: { params.saveAlignedIntermediates ? \"${params.outdir}/bowtie2\" : params.outdir }, mode: 'copy' , saveAs: {filename -> params.saveAlignedIntermediates ? filename : null }"
        ],
        "when": "denovo == false",
        "stub": ""
    },
    "bowtie2": {
        "name_process": "bowtie2",
        "string_process": "\nprocess bowtie2 {\n    tag \"$prefix\"\n    publishDir path: { params.saveAlignedIntermediates ? \"${params.outdir}/bowtie2\" : params.outdir }, mode: 'copy',\n               saveAs: {filename -> params.saveAlignedIntermediates ? filename : null }\n\n    input:\n    file reads from trimmed_reads\n    file index from bowtie2_index\n\n    output:\n    file '*.bam' into bb_bam\n\n    when:\n    denovo == false\n\n    script:\n    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    filtering = params.allow_multi_align ? '' : \"| samtools view -b -q 40 -F 4 -F 256 -\"\n    R1 = reads[0].toString()\n    if (single_end) {\n    \"\"\"\n    bowtie2 -x ${index}/genome -p ${task.cpus} -U $R1 | samtools view -bT $index - $filtering > ${prefix}.bam\n    \"\"\"\n    } else {\n    R2 = reads[1].toString()\n    \"\"\"\n    bowtie2 --no-mixed --no-discordant -X 1000 -x ${index}/genome -p ${task.cpus} -1 $R1 -2 $R2 | samtools view -bT $index - $filtering > ${prefix}.bam\n    \"\"\"\n    }\n}",
        "nb_lignes_process": 29,
        "string_script": "    prefix = reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n    filtering = params.allow_multi_align ? '' : \"| samtools view -b -q 40 -F 4 -F 256 -\"\n    R1 = reads[0].toString()\n    if (single_end) {\n    \"\"\"\n    bowtie2 -x ${index}/genome -p ${task.cpus} -U $R1 | samtools view -bT $index - $filtering > ${prefix}.bam\n    \"\"\"\n    } else {\n    R2 = reads[1].toString()\n    \"\"\"\n    bowtie2 --no-mixed --no-discordant -X 1000 -x ${index}/genome -p ${task.cpus} -1 $R1 -2 $R2 | samtools view -bT $index - $filtering > ${prefix}.bam\n    \"\"\"\n    }",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "CR10",
            "Rbowtie2",
            "R2"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/CR10",
            "https://bio.tools/rbowtie2",
            "https://bio.tools/R2"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "CR10",
                "uri": "https://bio.tools/CR10",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "PUBLIC DATABASE OF COSMIC RADIATION MEASUREMENTS AT AVIATION ALTITUDES OF ABOUT 10 KM.\n\nWhen using these data, please read this info",
                "homepage": "http://cr10.odz.ujf.cas.cz"
            },
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "R2",
                "uri": "https://bio.tools/R2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Expression correlation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set enrichment analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Co-expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "GSEA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Functional enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set over-represenation analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "R2 is a biologist friendly web based genomics analysis and visualization application",
                "homepage": "http://r2.amc.nl"
            }
        ],
        "inputs": [
            "trimmed_reads",
            "bowtie2_index"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bb_bam"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir path: { params.saveAlignedIntermediates ? \"${params.outdir}/bowtie2\" : params.outdir }, mode: 'copy' , saveAs: {filename -> params.saveAlignedIntermediates ? filename : null }"
        ],
        "when": "denovo == false",
        "stub": ""
    },
    "samtools": {
        "name_process": "samtools",
        "string_process": "\nprocess samtools {\n    tag \"${prefix}\"\n    publishDir path: \"${pp_outdir}\", mode: 'copy',\n               saveAs: { filename ->\n                   if (filename.indexOf(\".stats.txt\") > 0) \"stats/$filename\"\n                   else if (filename.indexOf(\"_bins.txt\") > 0) filename\n                   else if (filename.indexOf(\"_pdrc.pdf\") > 0) filename\n                   else params.saveAlignedIntermediates ? filename : null\n               }\n\n    input:\n    file bam from bb_bam\n    file genome from genome_samtools\n\n    output:\n    file '*.markdup.bam' into bam_for_qualimap, bam_for_aneufinder, bam_for_realign, bam_for_quast\n    file '*.markdup.bam.bai' into bai_for_qualimap, bai_for_aneufinder, bai_for_realign, bai_for_quast\n    file '*.markdup.bed' into bed_for_circlize, bed_for_preseq\n    file '*.stats.txt' into samtools_stats\n    file \"${prefix}_1k_bins.txt\"\n    file \"${prefix}_pdrc.pdf\"\n\n    script:\n    pp_outdir = \"${params.outdir}/bowtie2\"\n    prefix = bam.baseName\n    \"\"\"\n    samtools sort -o ${prefix}.sorted.bam $bam\n    samtools index ${prefix}.sorted.bam\n    picard MarkDuplicates I=${prefix}.sorted.bam O=${prefix}.markdup.bam M=metrics.txt AS=true\n    samtools index ${prefix}.markdup.bam\n    bedtools bamtobed -i ${prefix}.markdup.bam | sort -T /tmp -k 1,1 -k 2,2n -k 3,3n -k 6,6 > ${prefix}.markdup.bed\n    samtools stats -t ${genome} ${prefix}.markdup.bam > ${prefix}.stats.txt\n    # uniformity\n    cut -f1,3 ${genome} > ref.genome\n    genomeCoverageBed -ibam ${prefix}.markdup.bam -d -g ref.genome > ${prefix}.raw.cov\n    meanCov=\\$(awk 'BEGIN{ total=0; base=0 } { total=total+\\$3; base=base+1 } END{ printf total/base }' ${prefix}.raw.cov)\n    awk -v mc=\\$meanCov -F'\\t' '{print \\$1\"\\t\"\\$2\"\\t\"\\$3/mc}' ${prefix}.raw.cov > ${prefix}.relative.cov\n    awk '{sum+=\\$3} (NR%1000)==0{print sum/1000; sum=0;}' ${prefix}.relative.cov > ${prefix}_1k_bins.txt\n    plotProp.R ${prefix}_1k_bins.txt ${prefix}\n    \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "    pp_outdir = \"${params.outdir}/bowtie2\"\n    prefix = bam.baseName\n    \"\"\"\n    samtools sort -o ${prefix}.sorted.bam $bam\n    samtools index ${prefix}.sorted.bam\n    picard MarkDuplicates I=${prefix}.sorted.bam O=${prefix}.markdup.bam M=metrics.txt AS=true\n    samtools index ${prefix}.markdup.bam\n    bedtools bamtobed -i ${prefix}.markdup.bam | sort -T /tmp -k 1,1 -k 2,2n -k 3,3n -k 6,6 > ${prefix}.markdup.bed\n    samtools stats -t ${genome} ${prefix}.markdup.bam > ${prefix}.stats.txt\n    # uniformity\n    cut -f1,3 ${genome} > ref.genome\n    genomeCoverageBed -ibam ${prefix}.markdup.bam -d -g ref.genome > ${prefix}.raw.cov\n    meanCov=\\$(awk 'BEGIN{ total=0; base=0 } { total=total+\\$3; base=base+1 } END{ printf total/base }' ${prefix}.raw.cov)\n    awk -v mc=\\$meanCov -F'\\t' '{print \\$1\"\\t\"\\$2\"\\t\"\\$3/mc}' ${prefix}.raw.cov > ${prefix}.relative.cov\n    awk '{sum+=\\$3} (NR%1000)==0{print sum/1000; sum=0;}' ${prefix}.relative.cov > ${prefix}_1k_bins.txt\n    plotProp.R ${prefix}_1k_bins.txt ${prefix}\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "Picard",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/picard_tools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "bb_bam",
            "genome_samtools"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bam_for_qualimap",
            "bam_for_aneufinder",
            "bam_for_realign",
            "bam_for_quast",
            "bai_for_qualimap",
            "bai_for_aneufinder",
            "bai_for_realign",
            "bai_for_quast",
            "bed_for_circlize",
            "bed_for_preseq",
            "samtools_stats"
        ],
        "nb_outputs": 11,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir path: \"${pp_outdir}\", mode: 'copy' , saveAs: { filename -> if (filename.indexOf(\".stats.txt\") > 0) \"stats/$filename\" else if (filename.indexOf(\"_bins.txt\") > 0) filename else if (filename.indexOf(\"_pdrc.pdf\") > 0) filename else params.saveAlignedIntermediates ? filename : null }"
        ],
        "when": "",
        "stub": ""
    },
    "preseq": {
        "name_process": "preseq",
        "string_process": "\nprocess preseq {\n    tag \"${prefix}\"\n    publishDir path: \"${pp_outdir}\", mode: 'copy',\n               saveAs: { filename ->\n                   if (filename.indexOf(\".txt\") > 0) filename\n                   else if (filename.indexOf(\".pdf\") > 0) filename\n                   else null }\n\n    input:\n    file sbed from bed_for_preseq\n\n    output:\n    file '*.txt' into preseq_for_multiqc\n    file '*.pdf'\n\n    when:\n    !params.nanopore\n\n    script:\n    pp_outdir = \"${params.outdir}/preseq\"\n    prefix = sbed.toString() - ~/(\\.markdup\\.bed)?(\\.markdup)?(\\.bed)?$/\n    mode = single_end ? \"\" : \"-P\"\n    if (params.bulk) {\n    \"\"\"\n    preseq c_curve ${mode} -s 1e+5 -o ${prefix}_c.txt $sbed\n    preseq lc_extrap ${mode} -s 1e+5 -D -o ${prefix}_lc.txt $sbed\n    plotPreSeq.R ${prefix}_lc.txt ${prefix}_lc\n    \"\"\"\n    } else {\n    \"\"\"\n    preseq c_curve ${mode} -s 1e+5 -o ${prefix}_c.txt $sbed\n    preseq lc_extrap ${mode} -s 1e+5 -D -o ${prefix}_lc.txt $sbed\n    plotPreSeq.R ${prefix}_lc.txt ${prefix}_lc\n    preseq gc_extrap -w 1000 -s 1e+7 -D -o ${prefix}_gc.txt $sbed\n    plotPreSeq.R ${prefix}_gc.txt ${prefix}_gc\n    \"\"\"\n    }\n}",
        "nb_lignes_process": 37,
        "string_script": "    pp_outdir = \"${params.outdir}/preseq\"\n    prefix = sbed.toString() - ~/(\\.markdup\\.bed)?(\\.markdup)?(\\.bed)?$/\n    mode = single_end ? \"\" : \"-P\"\n    if (params.bulk) {\n    \"\"\"\n    preseq c_curve ${mode} -s 1e+5 -o ${prefix}_c.txt $sbed\n    preseq lc_extrap ${mode} -s 1e+5 -D -o ${prefix}_lc.txt $sbed\n    plotPreSeq.R ${prefix}_lc.txt ${prefix}_lc\n    \"\"\"\n    } else {\n    \"\"\"\n    preseq c_curve ${mode} -s 1e+5 -o ${prefix}_c.txt $sbed\n    preseq lc_extrap ${mode} -s 1e+5 -D -o ${prefix}_lc.txt $sbed\n    plotPreSeq.R ${prefix}_lc.txt ${prefix}_lc\n    preseq gc_extrap -w 1000 -s 1e+7 -D -o ${prefix}_gc.txt $sbed\n    plotPreSeq.R ${prefix}_gc.txt ${prefix}_gc\n    \"\"\"\n    }",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "MoDEL",
            "preseq"
        ],
        "tools_url": [
            "https://bio.tools/model",
            "https://bio.tools/preseq"
        ],
        "tools_dico": [
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            },
            {
                "name": "preseq",
                "uri": "https://bio.tools/preseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package is aimed at predicting and number of distinct reads and how many will be expected from additional sequencing using an initial sequencing experiment. The estimates can then be used to examine the utility of further sequencing, optimize the sequencing depth, or to screen multiple libraries to avoid low complexity samples.",
                "homepage": "http://smithlabresearch.org/software/preseq/"
            }
        ],
        "inputs": [
            "bed_for_preseq"
        ],
        "nb_inputs": 1,
        "outputs": [
            "preseq_for_multiqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir path: \"${pp_outdir}\", mode: 'copy' , saveAs: { filename -> if (filename.indexOf(\".txt\") > 0) filename else if (filename.indexOf(\".pdf\") > 0) filename else null }"
        ],
        "when": "!params.nanopore",
        "stub": ""
    },
    "qualimap": {
        "name_process": "qualimap",
        "string_process": "\nprocess qualimap {\n    publishDir path: \"${pp_outdir}\", mode: 'copy'\n\n    input:\n    file (\"*\") from bam_for_qualimap.collect()\n    file (\"*\") from bai_for_qualimap.collect()\n    file gff from gff\n\n    output:\n    file '*.markdup_stats' into qualimap_for_multiqc\n    file 'multi-bamqc'\n\n    script:\n    pp_outdir = \"${params.outdir}/qualimap\"\n    \"\"\"\n    ls *.markdup.bam > bams.txt\n    let num=`ls *.bam | wc -l`\n    if [ \\$num == 1 ]; then\n      qualimap bamqc -c -bam *.markdup.bam -gff $gff -outdir multi-bamqc\n      ln -s multi-bamqc Sample.markdup_stats\n    else\n      cat bams.txt | awk '{split(\\$1,a,\".markdup.bam\"); print a[1]\"\\t\"\\$1}' > inputs.txt\n      JAVA_MEM_SIZE=${task.memory.toGiga()}G qualimap multi-bamqc -r -c -d inputs.txt -gff $gff -outdir multi-bamqc\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    pp_outdir = \"${params.outdir}/qualimap\"\n    \"\"\"\n    ls *.markdup.bam > bams.txt\n    let num=`ls *.bam | wc -l`\n    if [ \\$num == 1 ]; then\n      qualimap bamqc -c -bam *.markdup.bam -gff $gff -outdir multi-bamqc\n      ln -s multi-bamqc Sample.markdup_stats\n    else\n      cat bams.txt | awk '{split(\\$1,a,\".markdup.bam\"); print a[1]\"\\t\"\\$1}' > inputs.txt\n      JAVA_MEM_SIZE=${task.memory.toGiga()}G qualimap multi-bamqc -r -c -d inputs.txt -gff $gff -outdir multi-bamqc\n    fi\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "carlet",
            "QualiMap"
        ],
        "tools_url": [
            "https://bio.tools/carlet",
            "https://bio.tools/qualimap"
        ],
        "tools_dico": [
            {
                "name": "carlet",
                "uri": "https://bio.tools/carlet",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Targeted exome capture"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "WES"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Whole exome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome capture"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phlyogenetic tree construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic tree generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Single-cell tumor phylogeny inference with copy-number constrained mutation losses.\n\nSCARLET (Single-cell Algorithm for Reconstructing Loss-supported Evolution of Tumors) is an algorithm that reconstructs tumor phylogenies from single-cell DNA sequencing data. SCARLET uses a loss-supported model that constrains mutation losses based on observed copy-number data.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'S carlet', 'loss-supported'",
                "homepage": "http://github.com/raphael-group/scarlet"
            },
            {
                "name": "QualiMap",
                "uri": "https://bio.tools/qualimap",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Platform-independent application written in Java and R that provides both a Graphical User Inteface (GUI) and a command-line interface to facilitate the quality control of alignment sequencing data.",
                "homepage": "http://qualimap.bioinfo.cipf.es/"
            }
        ],
        "inputs": [
            "bam_for_qualimap",
            "bai_for_qualimap",
            "gff"
        ],
        "nb_inputs": 3,
        "outputs": [
            "qualimap_for_multiqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir path: \"${pp_outdir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "IndelRealign": {
        "name_process": "IndelRealign",
        "string_process": "\nprocess IndelRealign {\n    tag \"${prefix}\"\n    publishDir path: \"${pp_outdir}\", mode: 'copy'\n\n    input:\n    file bam from bam_for_realign\n    file fa from fasta\n\n    output:\n    file '*.realign.bam' into bam_for_monovar\n    file '*.realign.bam.bai' into bai_for_monovar\n\n    when:\n    params.snv && !params.nanopore\n\n    script:\n    pp_outdir = \"${params.outdir}/gatk\"\n    prefix = bam.toString() - ~/(\\.markdup\\.bam)?(\\.markdup)?(\\.bam)?$/\n    \"\"\"\n    samtools faidx $fa\n    picard CreateSequenceDictionary R=$fa\n    picard AddOrReplaceReadGroups I=$bam O=${prefix}_rg.bam RGLB=lib RGPL=illumina RGPU=run RGSM=${prefix}\n    samtools index ${prefix}_rg.bam\n    gatk3 -T RealignerTargetCreator -R $fa -I ${prefix}_rg.bam -o indels.intervals\n    gatk3 -T IndelRealigner -R $fa -I ${prefix}_rg.bam -targetIntervals indels.intervals -o ${prefix}.realign.bam\n    #java -Xmx4g -jar ${workflow.projectDir}/bin/srma-0.1.15.jar I=${prefix}_rg.bam O=${prefix}.realign.bam R=${fa}\n    samtools index ${prefix}.realign.bam\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    pp_outdir = \"${params.outdir}/gatk\"\n    prefix = bam.toString() - ~/(\\.markdup\\.bam)?(\\.markdup)?(\\.bam)?$/\n    \"\"\"\n    samtools faidx $fa\n    picard CreateSequenceDictionary R=$fa\n    picard AddOrReplaceReadGroups I=$bam O=${prefix}_rg.bam RGLB=lib RGPL=illumina RGPU=run RGSM=${prefix}\n    samtools index ${prefix}_rg.bam\n    gatk3 -T RealignerTargetCreator -R $fa -I ${prefix}_rg.bam -o indels.intervals\n    gatk3 -T IndelRealigner -R $fa -I ${prefix}_rg.bam -targetIntervals indels.intervals -o ${prefix}.realign.bam\n    #java -Xmx4g -jar ${workflow.projectDir}/bin/srma-0.1.15.jar I=${prefix}_rg.bam O=${prefix}.realign.bam R=${fa}\n    samtools index ${prefix}.realign.bam\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "bam_for_realign",
            "fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bam_for_monovar",
            "bai_for_monovar"
        ],
        "nb_outputs": 2,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir path: \"${pp_outdir}\", mode: 'copy'"
        ],
        "when": "params.snv && !params.nanopore",
        "stub": ""
    },
    "monovar": {
        "name_process": "monovar",
        "string_process": "\nprocess monovar {\n    publishDir path: \"${pp_outdir}\", mode: 'copy',\n               saveAs: { filename ->\n                   if (filename.indexOf(\".vcf\") > 0) \"$filename\" else null }\n\n    input:\n    file (\"*\") from bam_for_monovar.collect()\n    file (\"*\") from bai_for_monovar.collect()\n    file fa from fasta\n\n    output:\n    file 'monovar.vcf' into monovar_vcf\n\n    when:\n    !params.bulk && params.snv && !params.nanopore\n\n    script:\n    pp_outdir = \"${params.outdir}/monovar\"\n    \"\"\"\n    ls *.bam > bams.txt\n    samtools mpileup -B -d 10000 -q 40 -f $fa -b bams.txt | /opt/MonoVar/src/monovar.py -f $fa -o monovar.vcf -m ${task.cpus} -b bams.txt\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    pp_outdir = \"${params.outdir}/monovar\"\n    \"\"\"\n    ls *.bam > bams.txt\n    samtools mpileup -B -d 10000 -q 40 -f $fa -b bams.txt | /opt/MonoVar/src/monovar.py -f $fa -o monovar.vcf -m ${task.cpus} -b bams.txt\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bam_for_monovar",
            "bai_for_monovar",
            "fasta"
        ],
        "nb_inputs": 3,
        "outputs": [
            "monovar_vcf"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir path: \"${pp_outdir}\", mode: 'copy' , saveAs: { filename -> if (filename.indexOf(\".vcf\") > 0) \"$filename\" else null }"
        ],
        "when": "!params.bulk && params.snv && !params.nanopore",
        "stub": ""
    },
    "aneufinder": {
        "name_process": "aneufinder",
        "string_process": "\nprocess aneufinder {\n    publishDir path: \"${pp_outdir}\", mode: 'copy'\n\n    input:\n    file (\"bams/*\") from bam_for_aneufinder.collect()\n    file (\"bams/*\") from bai_for_aneufinder.collect()\n\n    output:\n    file 'CNV_output' into cnv_output\n\n    when:\n    !params.bulk && params.cnv && !single_end && !params.nanopore\n\n    script:\n    pp_outdir = \"${params.outdir}/aneufinder\"\n    \"\"\"\n    aneuf.R ./bams CNV_output ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    pp_outdir = \"${params.outdir}/aneufinder\"\n    \"\"\"\n    aneuf.R ./bams CNV_output ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bam_for_aneufinder",
            "bai_for_aneufinder"
        ],
        "nb_inputs": 2,
        "outputs": [
            "cnv_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir path: \"${pp_outdir}\", mode: 'copy'"
        ],
        "when": "!params.bulk && params.cnv && !single_end && !params.nanopore",
        "stub": ""
    },
    "circlize": {
        "name_process": "circlize",
        "string_process": "\nprocess circlize {\n    tag \"${prefix}\"\n    publishDir \"${params.outdir}/circlize\", mode: 'copy',\n            saveAs: {filename ->\n                if (filename.indexOf(\".bed\") > 0) \"$filename\" else null\n            }\n\n    input:\n    file sbed from bed_for_circlize\n    file refbed from genome_circlize\n\n    output:\n    file \"${prefix}-cov200.bed\"\n\n    shell:\n    prefix = sbed.toString() - ~/(\\.markdup\\.bed)?(\\.markdup)?(\\.bed)?$/\n    \"\"\"\n    bedtools makewindows -b $refbed -w 200 > genome.200.bed\n    bedtools coverage -mean -b $sbed -a genome.200.bed | sort -k 1V,1 -k 2n,2 -k 3n,3 > ${prefix}-cov200.bed\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    prefix = sbed.toString() - ~/(\\.markdup\\.bed)?(\\.markdup)?(\\.bed)?$/\n    \"\"\"\n    bedtools makewindows -b $refbed -w 200 > genome.200.bed\n    bedtools coverage -mean -b $sbed -a genome.200.bed | sort -k 1V,1 -k 2n,2 -k 3n,3 > ${prefix}-cov200.bed\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "bed_for_circlize",
            "genome_circlize"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir \"${params.outdir}/circlize\", mode: 'copy' , saveAs: {filename -> if (filename.indexOf(\".bed\") > 0) \"$filename\" else null }"
        ],
        "when": "",
        "stub": ""
    },
    "normalize": {
        "name_process": "normalize",
        "string_process": "\nprocess normalize {\n    tag \"${prefix}\"\n\n    input:\n    file clean_reads from trimmed_reads_for_spades\n\n    output:\n    file \"*_norm*.fastq.gz\" into normalized_reads_for_assembly\n\n    when:\n    params.ass\n\n    script:\n    prefix = clean_reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?(\\.bz2)?$/\n    R1 = clean_reads[0].toString()\n    mode = params.bulk ? \"bulk\" : \"mda\"\n    if (single_end) {\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      ln -s $R1 ${prefix}_norm.fastq.gz\n    else\n      normalize-by-median.py -k 31 -C 40 --gzip -M 4e+9 -R ${prefix}_norm.report -o ${prefix}_norm.fastq.gz $R1\n    fi\n    \"\"\"\n    } else {\n    R2 = clean_reads[1].toString()\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      ln -s $R1 ${prefix}_norm_R1.fastq.gz\n      ln -s $R2 ${prefix}_norm_R2.fastq.gz\n    else\n      gzip -cd $R1 | fastx_renamer -n COUNT -i /dev/stdin -Q33 -z -o ${prefix}_rename_R1_fq.gz\n      gzip -cd $R2 | fastx_renamer -n COUNT -i /dev/stdin -Q33 -z -o ${prefix}_rename_R2_fq.gz\n      interleave-reads.py ${prefix}_rename_R1_fq.gz ${prefix}_rename_R2_fq.gz | normalize-by-median.py -k 31 -C 40 -M 4e+9 -p --gzip -R ${prefix}_norm.report -o ${prefix}_norm.fastq.gz /dev/stdin\n    fi\n    \"\"\"\n    }\n}",
        "nb_lignes_process": 37,
        "string_script": "    prefix = clean_reads[0].toString() - ~/(\\.R1)?(_1)?(_R1)?(_trimmed)?(_combined)?(\\.1_val_1)?(_1_val_1)?(_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?(\\.bz2)?$/\n    R1 = clean_reads[0].toString()\n    mode = params.bulk ? \"bulk\" : \"mda\"\n    if (single_end) {\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      ln -s $R1 ${prefix}_norm.fastq.gz\n    else\n      normalize-by-median.py -k 31 -C 40 --gzip -M 4e+9 -R ${prefix}_norm.report -o ${prefix}_norm.fastq.gz $R1\n    fi\n    \"\"\"\n    } else {\n    R2 = clean_reads[1].toString()\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      ln -s $R1 ${prefix}_norm_R1.fastq.gz\n      ln -s $R2 ${prefix}_norm_R2.fastq.gz\n    else\n      gzip -cd $R1 | fastx_renamer -n COUNT -i /dev/stdin -Q33 -z -o ${prefix}_rename_R1_fq.gz\n      gzip -cd $R2 | fastx_renamer -n COUNT -i /dev/stdin -Q33 -z -o ${prefix}_rename_R2_fq.gz\n      interleave-reads.py ${prefix}_rename_R1_fq.gz ${prefix}_rename_R2_fq.gz | normalize-by-median.py -k 31 -C 40 -M 4e+9 -p --gzip -R ${prefix}_norm.report -o ${prefix}_norm.fastq.gz /dev/stdin\n    fi\n    \"\"\"\n    }",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "CR10",
            "MoDEL",
            "R2",
            "cshl_fastx_renamer"
        ],
        "tools_url": [
            "https://bio.tools/CR10",
            "https://bio.tools/model",
            "https://bio.tools/R2",
            "https://bio.tools/cshl_fastx_renamer"
        ],
        "tools_dico": [
            {
                "name": "CR10",
                "uri": "https://bio.tools/CR10",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "PUBLIC DATABASE OF COSMIC RADIATION MEASUREMENTS AT AVIATION ALTITUDES OF ABOUT 10 KM.\n\nWhen using these data, please read this info",
                "homepage": "http://cr10.odz.ujf.cas.cz"
            },
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            },
            {
                "name": "R2",
                "uri": "https://bio.tools/R2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Expression correlation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set enrichment analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Co-expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "GSEA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Functional enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set over-represenation analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "R2 is a biologist friendly web based genomics analysis and visualization application",
                "homepage": "http://r2.amc.nl"
            },
            {
                "name": "cshl_fastx_renamer",
                "uri": "https://bio.tools/cshl_fastx_renamer",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3282",
                                    "term": "ID mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3282",
                                    "term": "Accession mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3282",
                                    "term": "Identifier mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "Rename the sequence identifiers in a FASTQ/A file.",
                "homepage": "http://hannonlab.cshl.edu/fastx_toolkit/"
            }
        ],
        "inputs": [
            "trimmed_reads_for_spades"
        ],
        "nb_inputs": 1,
        "outputs": [
            "normalized_reads_for_assembly"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\""
        ],
        "when": "params.ass",
        "stub": ""
    },
    "canu": {
        "name_process": "canu",
        "string_process": "\nprocess canu {\n    tag \"${prefix}\"\n    publishDir path: \"${params.outdir}/spades\", mode: 'copy'\n\n    input:\n    file clean_reads from normalized_reads_for_assembly\n\n    output:\n    file \"${prefix}.ctg200.fasta\" into contigs_for_nt, contigs_for_split\n    file \"${prefix}.ctgs.fasta\" into contigs_for_quast1, contigs_for_quast2, contigs_for_checkm, contigs_for_prokka, contigs_for_prodigal, contigs_for_resfinder, contigs_for_pointfinder, contigs_for_tsne, contigs_for_augustus, contigs_for_eukcc\n\n    when:\n    params.ass\n\n    script:\n    prefix = clean_reads[0].toString() - ~/(_trimmed)?(_norm)?(_combined)?(\\.R1)?(_1)?(_R1)?(\\.1_val_1)?(_1_val_1)?(_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?(\\.bz2)?$/\n    R1 = clean_reads[0].toString()\n    mode = params.bulk ? \"bulk\" : \"mda\"\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      #canu -d ${prefix}.spades_out -p ${prefix} genomeSize=4m useGrid=false maxThreads=${task.cpus} maxMemory=${task.memory.toGiga()}g -nanopore $R1\n      flye --nano-raw $R1 --out-dir ${prefix}.spades_out --threads ${task.cpus} --scaffold\n    else\n      #canu -d ${prefix}.spades_out -p ${prefix} genomeSize=4m corOutCoverage=999 corMhapSensitivity=high useGrid=false maxThreads=${task.cpus} maxMemory=${task.memory.toGiga()}g -nanopore $R1\n      flye --nano-raw $R1 --out-dir ${prefix}.spades_out --threads ${task.cpus} --scaffold --meta\n    fi\n    #ln -s ${prefix}.spades_out/${prefix}.contigs.fasta ${prefix}.contigs.fasta # for canu\n    cut -f1,2,3 ${prefix}.spades_out/assembly_info.txt | awk -F'\\t' 'NR>1{print \\$1\"\\t\"\\$1\"_length_\"\\$2\"_cov_\"\\$3}' > flyeID_spadesID.txt\n    fasta_tool --swap_ids flyeID_spadesID.txt ${prefix}.spades_out/assembly.fasta > ${prefix}.contigs.fasta\n    ##ln -s ${prefix}.spades_out/assembly.fasta ${prefix}.contigs.fasta # for flye\n    faFilterByLen.pl ${prefix}.contigs.fasta 200 > ${prefix}.ctg200.fasta\n    cat ${prefix}.ctg200.fasta | sed 's/ len=.*\\$//g' > ${prefix}.ctgs.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    prefix = clean_reads[0].toString() - ~/(_trimmed)?(_norm)?(_combined)?(\\.R1)?(_1)?(_R1)?(\\.1_val_1)?(_1_val_1)?(_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?(\\.bz2)?$/\n    R1 = clean_reads[0].toString()\n    mode = params.bulk ? \"bulk\" : \"mda\"\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      #canu -d ${prefix}.spades_out -p ${prefix} genomeSize=4m useGrid=false maxThreads=${task.cpus} maxMemory=${task.memory.toGiga()}g -nanopore $R1\n      flye --nano-raw $R1 --out-dir ${prefix}.spades_out --threads ${task.cpus} --scaffold\n    else\n      #canu -d ${prefix}.spades_out -p ${prefix} genomeSize=4m corOutCoverage=999 corMhapSensitivity=high useGrid=false maxThreads=${task.cpus} maxMemory=${task.memory.toGiga()}g -nanopore $R1\n      flye --nano-raw $R1 --out-dir ${prefix}.spades_out --threads ${task.cpus} --scaffold --meta\n    fi\n    #ln -s ${prefix}.spades_out/${prefix}.contigs.fasta ${prefix}.contigs.fasta # for canu\n    cut -f1,2,3 ${prefix}.spades_out/assembly_info.txt | awk -F'\\t' 'NR>1{print \\$1\"\\t\"\\$1\"_length_\"\\$2\"_cov_\"\\$3}' > flyeID_spadesID.txt\n    fasta_tool --swap_ids flyeID_spadesID.txt ${prefix}.spades_out/assembly.fasta > ${prefix}.contigs.fasta\n    ##ln -s ${prefix}.spades_out/assembly.fasta ${prefix}.contigs.fasta # for flye\n    faFilterByLen.pl ${prefix}.contigs.fasta 200 > ${prefix}.ctg200.fasta\n    cat ${prefix}.ctg200.fasta | sed 's/ len=.*\\$//g' > ${prefix}.ctgs.fasta\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "CR10",
            "MoDEL",
            "Flye"
        ],
        "tools_url": [
            "https://bio.tools/CR10",
            "https://bio.tools/model",
            "https://bio.tools/Flye"
        ],
        "tools_dico": [
            {
                "name": "CR10",
                "uri": "https://bio.tools/CR10",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "PUBLIC DATABASE OF COSMIC RADIATION MEASUREMENTS AT AVIATION ALTITUDES OF ABOUT 10 KM.\n\nWhen using these data, please read this info",
                "homepage": "http://cr10.odz.ujf.cas.cz"
            },
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            },
            {
                "name": "Flye",
                "uri": "https://bio.tools/Flye",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Mapping assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De-novo assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Sequence assembly (mapping assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De Bruijn graph"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "Sequence assembly (de-novo assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PB / ONT reads as input and outputs polished contigs.",
                "homepage": "https://github.com/fenderglass/Flye"
            }
        ],
        "inputs": [
            "normalized_reads_for_assembly"
        ],
        "nb_inputs": 1,
        "outputs": [
            "contigs_for_nt",
            "contigs_for_split",
            "contigs_for_quast1",
            "contigs_for_quast2",
            "contigs_for_checkm",
            "contigs_for_prokka",
            "contigs_for_prodigal",
            "contigs_for_resfinder",
            "contigs_for_pointfinder",
            "contigs_for_tsne",
            "contigs_for_augustus",
            "contigs_for_eukcc"
        ],
        "nb_outputs": 12,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir path: \"${params.outdir}/spades\", mode: 'copy'"
        ],
        "when": "params.ass",
        "stub": ""
    },
    "spades": {
        "name_process": "spades",
        "string_process": "\nprocess spades {\n    tag \"${prefix}\"\n    publishDir path: \"${params.outdir}/spades\", mode: 'copy'\n\n    input:\n    file clean_reads from normalized_reads_for_assembly\n\n    output:\n    file \"${prefix}.ctg200.fasta\" into contigs_for_nt, contigs_for_split\n    file \"${prefix}.ctgs.fasta\" into contigs_for_quast1, contigs_for_quast2, contigs_for_checkm, contigs_for_prokka, contigs_for_prodigal, contigs_for_resfinder, contigs_for_pointfinder, contigs_for_tsne, contigs_for_augustus, contigs_for_eukcc\n\n    when:\n    params.ass\n\n    script:\n    prefix = clean_reads[0].toString() - ~/(_trimmed)?(_norm)?(_combined)?(\\.R1)?(_1)?(_R1)?(\\.1_val_1)?(_1_val_1)?(_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?(\\.bz2)?$/\n    R1 = clean_reads[0].toString()\n    mode = params.bulk ? \"bulk\" : \"mda\"\n    if (single_end) {\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      spades.py -s $R1 --careful --cov-cutoff auto -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    else\n      spades.py --sc -s $R1 --careful -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    fi\n    ln -s ${prefix}.spades_out/contigs.fasta ${prefix}.contigs.fasta\n    faFilterByLen.pl ${prefix}.contigs.fasta 200 > ${prefix}.ctg200.fasta\n    cat ${prefix}.ctg200.fasta | sed 's/_length.*\\$//g' > ${prefix}.ctgs.fasta\n    \"\"\"\n    } else {\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      spades.py -1 ${prefix}_norm_R1.fastq.gz -2 ${prefix}_norm_R2.fastq.gz --careful --cov-cutoff auto -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    else\n      spades.py --sc --12 $R1 --careful -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    fi\n    ln -s ${prefix}.spades_out/contigs.fasta ${prefix}.contigs.fasta\n    faFilterByLen.pl ${prefix}.contigs.fasta 200 > ${prefix}.ctg200.fasta\n    cat ${prefix}.ctg200.fasta | sed 's/_length.*\\$//g' > ${prefix}.ctgs.fasta\n    \"\"\"\n    }\n}",
        "nb_lignes_process": 41,
        "string_script": "    prefix = clean_reads[0].toString() - ~/(_trimmed)?(_norm)?(_combined)?(\\.R1)?(_1)?(_R1)?(\\.1_val_1)?(_1_val_1)?(_val_1)?(_R1_val_1)?(\\.fq)?(\\.fastq)?(\\.gz)?(\\.bz2)?$/\n    R1 = clean_reads[0].toString()\n    mode = params.bulk ? \"bulk\" : \"mda\"\n    if (single_end) {\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      spades.py -s $R1 --careful --cov-cutoff auto -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    else\n      spades.py --sc -s $R1 --careful -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    fi\n    ln -s ${prefix}.spades_out/contigs.fasta ${prefix}.contigs.fasta\n    faFilterByLen.pl ${prefix}.contigs.fasta 200 > ${prefix}.ctg200.fasta\n    cat ${prefix}.ctg200.fasta | sed 's/_length.*\\$//g' > ${prefix}.ctgs.fasta\n    \"\"\"\n    } else {\n    \"\"\"\n    if [ \\\"${mode}\\\" == \\\"bulk\\\" ]; then\n      spades.py -1 ${prefix}_norm_R1.fastq.gz -2 ${prefix}_norm_R2.fastq.gz --careful --cov-cutoff auto -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    else\n      spades.py --sc --12 $R1 --careful -t ${task.cpus} -m ${task.memory.toGiga()} -o ${prefix}.spades_out\n    fi\n    ln -s ${prefix}.spades_out/contigs.fasta ${prefix}.contigs.fasta\n    faFilterByLen.pl ${prefix}.contigs.fasta 200 > ${prefix}.ctg200.fasta\n    cat ${prefix}.ctg200.fasta | sed 's/_length.*\\$//g' > ${prefix}.ctgs.fasta\n    \"\"\"\n    }",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "CR10",
            "MoDEL"
        ],
        "tools_url": [
            "https://bio.tools/CR10",
            "https://bio.tools/model"
        ],
        "tools_dico": [
            {
                "name": "CR10",
                "uri": "https://bio.tools/CR10",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "PUBLIC DATABASE OF COSMIC RADIATION MEASUREMENTS AT AVIATION ALTITUDES OF ABOUT 10 KM.\n\nWhen using these data, please read this info",
                "homepage": "http://cr10.odz.ujf.cas.cz"
            },
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            }
        ],
        "inputs": [
            "normalized_reads_for_assembly"
        ],
        "nb_inputs": 1,
        "outputs": [
            "contigs_for_nt",
            "contigs_for_split",
            "contigs_for_quast1",
            "contigs_for_quast2",
            "contigs_for_checkm",
            "contigs_for_prokka",
            "contigs_for_prodigal",
            "contigs_for_resfinder",
            "contigs_for_pointfinder",
            "contigs_for_tsne",
            "contigs_for_augustus",
            "contigs_for_eukcc"
        ],
        "nb_outputs": 12,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir path: \"${params.outdir}/spades\", mode: 'copy'"
        ],
        "when": "params.ass",
        "stub": ""
    },
    "quast_ref": {
        "name_process": "quast_ref",
        "string_process": "\nprocess quast_ref {\n    label \"quast\"\n    publishDir path: \"${params.outdir}\", mode: 'copy'\n\n    input:\n    file fasta from fasta\n    file gff from gff\n    file (\"*\") from contigs_for_quast1.collect()\n    file (\"*\") from bam_for_quast.collect()\n    file (\"*\") from bai_for_quast.collect()\n\n    output:\n    file \"quast/report.tsv\" into quast_report1\n    file \"quast\"\n\n    when:\n    denovo == false\n\n    script:\n    euk_cmd = euk ? ( params.fungus ? \"--fungus\" : \"-e\") : \"\"\n    ref = fasta.exists() ? \"-r $fasta\" : \"\"\n    gene = gff.exists() ? \"--features gene:$gff\" : \"\"\n    \"\"\"\n    contigs=\\$(ls *.ctgs.fasta | paste -sd \" \" -)\n    labels=\\$(ls *.ctgs.fasta | paste -sd \",\" - | sed 's/.ctgs.fasta//g')\n    bams=\\$(ls *.markdup.bam | paste -sd \",\" -)\n    quast.py -o quast $ref $gene -m 200 -t ${task.cpus} $euk_cmd --rna-finding --bam \\$bams -l \\$labels --no-sv --no-read-stats \\$contigs\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    euk_cmd = euk ? ( params.fungus ? \"--fungus\" : \"-e\") : \"\"\n    ref = fasta.exists() ? \"-r $fasta\" : \"\"\n    gene = gff.exists() ? \"--features gene:$gff\" : \"\"\n    \"\"\"\n    contigs=\\$(ls *.ctgs.fasta | paste -sd \" \" -)\n    labels=\\$(ls *.ctgs.fasta | paste -sd \",\" - | sed 's/.ctgs.fasta//g')\n    bams=\\$(ls *.markdup.bam | paste -sd \",\" -)\n    quast.py -o quast $ref $gene -m 200 -t ${task.cpus} $euk_cmd --rna-finding --bam \\$bams -l \\$labels --no-sv --no-read-stats \\$contigs\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "KOREF",
            "Gene"
        ],
        "tools_url": [
            "https://bio.tools/KOREF",
            "https://bio.tools/Gene"
        ],
        "tools_dico": [
            {
                "name": "KOREF",
                "uri": "https://bio.tools/KOREF",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Mapping assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De-novo assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3216",
                                    "term": "Scaffolding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Sequence assembly (mapping assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De Bruijn graph"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "Sequence assembly (de-novo assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3216",
                                    "term": "Scaffold construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3216",
                                    "term": "Scaffold generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Chromosome-scale assembly comparison of the Korean Reference Genome KOREF from PromethION and PacBio with Hi-C mapping information.\n\nThe first Korean Reference Genome. KOREF_S means KOREF_Single.",
                "homepage": "http://koref.net"
            },
            {
                "name": "Gene",
                "uri": "https://bio.tools/Gene",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3400",
                            "term": "Allergy, clinical immunology and immunotherapeutics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> LOW CONFIDENCE! | A curated transcriptome dataset collection to investigate inborn errors of immunity | There was an error sending your bug report. Please fill out the form and try again | Your Email: (so we can get back to you when the bug has been fixed)",
                "homepage": "http://pid.gxbsidra.org/dm3/geneBrowser/list"
            }
        ],
        "inputs": [
            "fasta",
            "gff",
            "contigs_for_quast1",
            "bam_for_quast",
            "bai_for_quast"
        ],
        "nb_inputs": 5,
        "outputs": [
            "quast_report1"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "label \"quast\"",
            "publishDir path: \"${params.outdir}\", mode: 'copy'"
        ],
        "when": "denovo == false",
        "stub": ""
    },
    "quast_denovo": {
        "name_process": "quast_denovo",
        "string_process": "\nprocess quast_denovo {\n    label \"quast\"\n    publishDir path: \"${params.outdir}\", mode: 'copy'\n\n    input:\n    file (\"*\") from contigs_for_quast2.collect()\n\n    output:\n    file \"quast/report.tsv\" into quast_report2\n    file \"quast\"\n\n    when:\n    denovo == true\n\n    script:\n    euk_cmd = euk ? ( params.fungus ? \"--fungus\" : \"-e\") : \"\"\n    \"\"\"\n    contigs=\\$(ls *.ctgs.fasta | paste -sd \" \" -)\n    labels=\\$(ls *.ctgs.fasta | paste -sd \",\" - | sed 's/.ctgs.fasta//g')\n    quast.py -o quast -m 200 -t ${task.cpus} $euk_cmd --rna-finding -l \\$labels --no-sv --no-read-stats \\$contigs\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    euk_cmd = euk ? ( params.fungus ? \"--fungus\" : \"-e\") : \"\"\n    \"\"\"\n    contigs=\\$(ls *.ctgs.fasta | paste -sd \" \" -)\n    labels=\\$(ls *.ctgs.fasta | paste -sd \",\" - | sed 's/.ctgs.fasta//g')\n    quast.py -o quast -m 200 -t ${task.cpus} $euk_cmd --rna-finding -l \\$labels --no-sv --no-read-stats \\$contigs\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigs_for_quast2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "quast_report2"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "label \"quast\"",
            "publishDir path: \"${params.outdir}\", mode: 'copy'"
        ],
        "when": "denovo == true",
        "stub": ""
    },
    "checkm": {
        "name_process": "checkm",
        "string_process": "\nprocess checkm {\n   publishDir \"${params.outdir}/CheckM\", mode: 'copy'\n\n   input:\n   file ('spades/*') from contigs_for_checkm.collect()\n\n   output:\n   file 'spades_checkM.txt'\n\n   when:\n   !euk\n\n   script:\n   checkm_wf = params.genus ? \"taxonomy_wf\" : \"lineage_wf\"\n   \"\"\"\n   if [ \\\"${checkm_wf}\\\" == \\\"taxonomy_wf\\\" ]; then\n     checkm taxonomy_wf -t ${task.cpus} --tab_table -f spades_checkM.txt -x fasta genus ${params.genus} spades spades_checkM\n   else\n     checkm lineage_wf -t ${task.cpus} -r --tab_table -f spades_checkM.txt -x fasta spades spades_checkM\n   fi\n   \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "   checkm_wf = params.genus ? \"taxonomy_wf\" : \"lineage_wf\"\n   \"\"\"\n   if [ \\\"${checkm_wf}\\\" == \\\"taxonomy_wf\\\" ]; then\n     checkm taxonomy_wf -t ${task.cpus} --tab_table -f spades_checkM.txt -x fasta genus ${params.genus} spades spades_checkM\n   else\n     checkm lineage_wf -t ${task.cpus} -r --tab_table -f spades_checkM.txt -x fasta spades spades_checkM\n   fi\n   \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigs_for_checkm"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir \"${params.outdir}/CheckM\", mode: 'copy'"
        ],
        "when": "!euk",
        "stub": ""
    },
    "blast_nt": {
        "name_process": "blast_nt",
        "string_process": "\nprocess blast_nt {\n   tag \"${prefix}\"\n   publishDir \"${params.outdir}/blob\", mode: 'copy'\n\n   input:\n   file contigs from contigs_for_nt\n   file nt from nt_db\n\n   output:\n   file \"${prefix}_nt.out\" into nt_for_blobtools_original\n   file \"${contigs}\" into contigs_for_uniprot\n\n   when:\n   params.nt_db\n\n   script:\n   prefix = contigs.toString() - ~/(\\.ctg200\\.fasta)?(\\.ctg200)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   export BLASTDB=$nt\n   blastn -query $contigs -db $nt/nt -outfmt '6 qseqid staxids bitscore std' \\\n     -max_target_seqs 1 -max_hsps 1 -evalue ${params.evalue} \\\n     -num_threads ${task.cpus} -out ${prefix}_nt.out\n   \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "   prefix = contigs.toString() - ~/(\\.ctg200\\.fasta)?(\\.ctg200)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   export BLASTDB=$nt\n   blastn -query $contigs -db $nt/nt -outfmt '6 qseqid staxids bitscore std' \\\n     -max_target_seqs 1 -max_hsps 1 -evalue ${params.evalue} \\\n     -num_threads ${task.cpus} -out ${prefix}_nt.out\n   \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "G-BLASTN"
        ],
        "tools_url": [
            "https://bio.tools/g-blastn"
        ],
        "tools_dico": [
            {
                "name": "G-BLASTN",
                "uri": "https://bio.tools/g-blastn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0346",
                                    "term": "Sequence similarity search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2976",
                                "term": "Protein sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0857",
                                "term": "Sequence search results"
                            }
                        ]
                    }
                ],
                "description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "homepage": "http://www.comp.hkbu.edu.hk/~chxw/software/G-BLASTN.html"
            }
        ],
        "inputs": [
            "contigs_for_nt",
            "nt_db"
        ],
        "nb_inputs": 2,
        "outputs": [
            "nt_for_blobtools_original",
            "contigs_for_uniprot"
        ],
        "nb_outputs": 2,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir \"${params.outdir}/blob\", mode: 'copy'"
        ],
        "when": "params.nt_db",
        "stub": ""
    },
    "diamond_uniprot": {
        "name_process": "diamond_uniprot",
        "string_process": "\nprocess diamond_uniprot {\n   tag \"${prefix}\"\n   publishDir \"${params.outdir}/blob\", mode: 'copy'\n\n   input:\n   file contigs from contigs_for_uniprot\n   file nt_out from nt_for_blobtools_original\n   file uniprot from uniprot_db\n   file \"uniprot.taxids\" from uniprot_taxids\n\n   output:\n   file \"${prefix}_uniprot.taxified.out\" into uniprot_for_blobtools\n   file \"${contigs}\" into contigs_for_blob\n   file \"${nt_out}\" into nt_for_blobtools\n   val used into uniprot_real\n   file \"${prefix}_uniprot.*\"\n\n   script:\n   prefix = contigs.toString() - ~/(\\.ctg200\\.fasta)?(\\.ctg200)?(\\.fasta)?(\\.fa)?$/\n   if ( uniprot.toString().equals(\"/dev/null\") || uniprot.toString().equals(\"null\") ) {\n     used = false\n     \"\"\"\n     touch ${prefix}_uniprot.out\n     touch ${prefix}_uniprot.taxified.out\n     \"\"\"\n   } else {\n     used = true\n     \"\"\"\n     diamond blastx --query $contigs --db $uniprot -p ${task.cpus} -o ${prefix}_uniprot.out \\\n       --outfmt 6 --sensitive --max-target-seqs 1 --evalue ${params.evalue} -b ${params.blockSize}\n     blobtools taxify -f ${prefix}_uniprot.out -m uniprot.taxids -s 0 -t 2\n     \"\"\"\n   }\n}",
        "nb_lignes_process": 33,
        "string_script": "   prefix = contigs.toString() - ~/(\\.ctg200\\.fasta)?(\\.ctg200)?(\\.fasta)?(\\.fa)?$/\n   if ( uniprot.toString().equals(\"/dev/null\") || uniprot.toString().equals(\"null\") ) {\n     used = false\n     \"\"\"\n     touch ${prefix}_uniprot.out\n     touch ${prefix}_uniprot.taxified.out\n     \"\"\"\n   } else {\n     used = true\n     \"\"\"\n     diamond blastx --query $contigs --db $uniprot -p ${task.cpus} -o ${prefix}_uniprot.out \\\n       --outfmt 6 --sensitive --max-target-seqs 1 --evalue ${params.evalue} -b ${params.blockSize}\n     blobtools taxify -f ${prefix}_uniprot.out -m uniprot.taxids -s 0 -t 2\n     \"\"\"\n   }",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "Diamond",
            "BlobTools"
        ],
        "tools_url": [
            "https://bio.tools/diamond",
            "https://bio.tools/blobtools"
        ],
        "tools_dico": [
            {
                "name": "Diamond",
                "uri": "https://bio.tools/diamond",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sequence aligner for protein and translated DNA searches and functions as a drop-in replacement for the NCBI BLAST software tools. It is suitable for protein-protein search as well as DNA-protein search on short reads and longer sequences including contigs and assemblies, providing a speedup of BLAST ranging up to x20,000.",
                "homepage": "https://github.com/bbuchfink/diamond"
            },
            {
                "name": "BlobTools",
                "uri": "https://bio.tools/blobtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly validation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly QC"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Visualisation, quality control and taxonomic partitioning of genome datasets.",
                "homepage": "https://github.com/DRL/blobtools"
            }
        ],
        "inputs": [
            "contigs_for_uniprot",
            "nt_for_blobtools_original",
            "uniprot_db",
            "uniprot_taxids"
        ],
        "nb_inputs": 4,
        "outputs": [
            "uniprot_for_blobtools",
            "contigs_for_blob",
            "nt_for_blobtools",
            "uniprot_real"
        ],
        "nb_outputs": 4,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir \"${params.outdir}/blob\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "blobtools": {
        "name_process": "blobtools",
        "string_process": "\nprocess blobtools {\n   tag \"${prefix}\"\n   publishDir \"${params.outdir}/blob\", mode: 'copy'\n\n   input:\n   file contigs from contigs_for_blob\n   file anno from nt_for_blobtools\n   val has_uniprot from uniprot_real\n   file uniprot_anno from uniprot_for_blobtools\n\n   output:\n   file \"${prefix}/${prefix}.blobDB*table.txt\" into blob_tax\n   file \"${contigs}\" into contigs_for_acdc\n   file \"${prefix}\" into blob_tax_for_split\n\n   script:\n   prefix = contigs.toString() - ~/(\\.ctg200\\.fasta)?(\\.ctg200)?(\\.fasta)?(\\.fa)?$/\n   uniprot_anno_cmd = has_uniprot ? \"-t $uniprot_anno\" : \"\"\n   \"\"\"\n   mkdir -p ${prefix}\n   blobtools create -i $contigs -y spades -t $anno $uniprot_anno_cmd -o ${prefix}/${prefix} \\\n     --db /opt/conda/envs/nf-core-gongyh-scgs/lib/python3.6/site-packages/data/nodesDB.txt\n   blobtools view -i ${prefix}/${prefix}.blobDB.json -r all -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r phylum --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r order --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r family --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r genus --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r species --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r phylum --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r order --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r family --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r genus --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r species --format png -o ${prefix}/\n   \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "   prefix = contigs.toString() - ~/(\\.ctg200\\.fasta)?(\\.ctg200)?(\\.fasta)?(\\.fa)?$/\n   uniprot_anno_cmd = has_uniprot ? \"-t $uniprot_anno\" : \"\"\n   \"\"\"\n   mkdir -p ${prefix}\n   blobtools create -i $contigs -y spades -t $anno $uniprot_anno_cmd -o ${prefix}/${prefix} \\\n     --db /opt/conda/envs/nf-core-gongyh-scgs/lib/python3.6/site-packages/data/nodesDB.txt\n   blobtools view -i ${prefix}/${prefix}.blobDB.json -r all -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r phylum --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r order --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r family --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r genus --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r species --format pdf -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r phylum --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r order --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r family --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r genus --format png -o ${prefix}/\n   blobtools plot -i ${prefix}/${prefix}.blobDB.json --filelabel --notitle -l 200 -r species --format png -o ${prefix}/\n   \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "BlobTools"
        ],
        "tools_url": [
            "https://bio.tools/blobtools"
        ],
        "tools_dico": [
            {
                "name": "BlobTools",
                "uri": "https://bio.tools/blobtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly validation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Sequence assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3184",
                                    "term": "Assembly rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Assembly quality evaluation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3180",
                                    "term": "Sequence assembly QC"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Visualisation, quality control and taxonomic partitioning of genome datasets.",
                "homepage": "https://github.com/DRL/blobtools"
            }
        ],
        "inputs": [
            "contigs_for_blob",
            "nt_for_blobtools",
            "uniprot_real",
            "uniprot_for_blobtools"
        ],
        "nb_inputs": 4,
        "outputs": [
            "blob_tax",
            "contigs_for_acdc",
            "blob_tax_for_split"
        ],
        "nb_outputs": 3,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir \"${params.outdir}/blob\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "acdc": {
        "name_process": "acdc",
        "string_process": "\nprocess acdc {\n    tag \"${prefix}\"\n    publishDir \"${params.outdir}/acdc\", mode: 'copy'\n\n    input:\n    file contigs from contigs_for_acdc\n    file db from kraken_db\n    file tax from blob_tax\n\n    output:\n    file \"${prefix}\"\n\n    when:\n    false\n\n    script:\n    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    \"\"\"\n    cat $tax | grep -v '^#' | cut -f1,18 > genus.txt\n    /usr/local/bin/acdc -i $contigs -m 1000 -b 100 -o $prefix -K $db -x genus.txt -T ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    \"\"\"\n    cat $tax | grep -v '^#' | cut -f1,18 > genus.txt\n    /usr/local/bin/acdc -i $contigs -m 1000 -b 100 -o $prefix -K $db -x genus.txt -T ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "acdc"
        ],
        "tools_url": [
            "https://bio.tools/acdc_estimation"
        ],
        "tools_dico": [
            {
                "name": "acdc",
                "uri": "https://bio.tools/acdc_estimation",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0925",
                                "term": "Sequence assembly"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "A tool to test next-generation-sequencing (NGS) data from single-cell sequencing for contamination. By using sophisticated dimensionality reduction and clustering methods, it uses tetramer profiles to differentiate between different species in a given sample.",
                "homepage": "https://bibiserv.cebitec.uni-bielefeld.de/acdc/"
            }
        ],
        "inputs": [
            "contigs_for_acdc",
            "kraken_db",
            "blob_tax"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir \"${params.outdir}/acdc\", mode: 'copy'"
        ],
        "when": "false",
        "stub": ""
    },
    "tsne": {
        "name_process": "tsne",
        "string_process": "\nprocess tsne {\n    tag \"${prefix}\"\n    publishDir \"${params.outdir}/tsne\", mode: 'copy'\n\n    input:\n    file contigs from contigs_for_tsne\n\n    output:\n    file \"${prefix}_tsne.tsv\"\n\n    script:\n    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    \"\"\"\n    faFilterByLen.pl ${contigs} 1000 > ${prefix}.ctg1k.fasta\n    if [ -s ${prefix}.ctg1k.fasta ]\n    then\n      kpal count -k 4 -r ${prefix}.ctg1k.fasta ${prefix}.4mer\n      kmer_tsne.py ${prefix}.4mer ${prefix}_tsne.tsv ${task.cpus}\n    else\n      touch ${prefix}_tsne.tsv\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    \"\"\"\n    faFilterByLen.pl ${contigs} 1000 > ${prefix}.ctg1k.fasta\n    if [ -s ${prefix}.ctg1k.fasta ]\n    then\n      kpal count -k 4 -r ${prefix}.ctg1k.fasta ${prefix}.4mer\n      kmer_tsne.py ${prefix}.4mer ${prefix}_tsne.tsv ${task.cpus}\n    else\n      touch ${prefix}_tsne.tsv\n    fi\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigs_for_tsne"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir \"${params.outdir}/tsne\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "prokka": {
        "name_process": "prokka",
        "string_process": "\nprocess prokka {\n   tag \"$prefix\"\n   publishDir \"${params.outdir}/prokka\", mode: 'copy'\n\n   input:\n   file contigs from contigs_for_prokka\n\n   output:\n   file \"$prefix\" into prokka_for_mqc1, prokka_for_mqc2, prokka_for_split\n   file \"$prefix/${prefix}.faa\" into faa_eggnog, faa_kofam\n\n   when:\n   !euk\n\n   script:\n   prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   if [ \\$(id -u) -eq 0 ]; then\n     wget -c -q -t 1 -T 60 ftp://ftp.ncbi.nih.gov/toolbox/ncbi_tools/converters/by_program/tbl2asn/linux64.tbl2asn.gz -O linux64.tbl2asn.gz && gunzip linux64.tbl2asn.gz && chmod +x linux64.tbl2asn && mv linux64.tbl2asn /opt/conda/envs/nf-core-gongyh-scgs/bin/tbl2asn\n   fi\n   cat $contigs | sed 's/_length.*\\$//g' > ${prefix}_node.fa\n   prokka --outdir $prefix --prefix $prefix --addgenes --cpus ${task.cpus} ${prefix}_node.fa || echo \"Ignore minor errors of prokka!\"\n   sed '/^##FASTA/Q' ${prefix}/${prefix}.gff > ${prefix}/${prefix}_noseq.gff\n   gff2bed < ${prefix}/${prefix}_noseq.gff | cut -f1,4 | grep -v gene > ${prefix}/${prefix}_ctg_genes.tsv\n   prokka_postprocess.py ${prefix}/${prefix}_ctg_genes.tsv ${prefix}/${prefix}.tsv > ${prefix}/${prefix}_all.tsv\n   \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "   prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   if [ \\$(id -u) -eq 0 ]; then\n     wget -c -q -t 1 -T 60 ftp://ftp.ncbi.nih.gov/toolbox/ncbi_tools/converters/by_program/tbl2asn/linux64.tbl2asn.gz -O linux64.tbl2asn.gz && gunzip linux64.tbl2asn.gz && chmod +x linux64.tbl2asn && mv linux64.tbl2asn /opt/conda/envs/nf-core-gongyh-scgs/bin/tbl2asn\n   fi\n   cat $contigs | sed 's/_length.*\\$//g' > ${prefix}_node.fa\n   prokka --outdir $prefix --prefix $prefix --addgenes --cpus ${task.cpus} ${prefix}_node.fa || echo \"Ignore minor errors of prokka!\"\n   sed '/^##FASTA/Q' ${prefix}/${prefix}.gff > ${prefix}/${prefix}_noseq.gff\n   gff2bed < ${prefix}/${prefix}_noseq.gff | cut -f1,4 | grep -v gene > ${prefix}/${prefix}_ctg_genes.tsv\n   prokka_postprocess.py ${prefix}/${prefix}_ctg_genes.tsv ${prefix}/${prefix}.tsv > ${prefix}/${prefix}_all.tsv\n   \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "Prokka"
        ],
        "tools_url": [
            "https://bio.tools/prokka"
        ],
        "tools_dico": [
            {
                "name": "Prokka",
                "uri": "https://bio.tools/prokka",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0781",
                            "term": "Virology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.",
                "homepage": "https://github.com/tseemann/prokka"
            }
        ],
        "inputs": [
            "contigs_for_prokka"
        ],
        "nb_inputs": 1,
        "outputs": [
            "prokka_for_mqc1",
            "prokka_for_mqc2",
            "prokka_for_split",
            "faa_eggnog",
            "faa_kofam"
        ],
        "nb_outputs": 5,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir \"${params.outdir}/prokka\", mode: 'copy'"
        ],
        "when": "!euk",
        "stub": ""
    },
    "prodigal": {
        "name_process": "prodigal",
        "string_process": "\nprocess prodigal {\n   tag \"$prefix\"\n   publishDir \"${params.outdir}/prodigal\", mode: 'copy'\n\n   input:\n   file contigs from contigs_for_prodigal\n\n   output:\n   file \"$prefix\"\n\n   when:\n   !euk\n\n   script:\n   prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   mkdir -p ${prefix}\n   prodigal -i $contigs -o ${prefix}/${prefix}.gbk -a ${prefix}/${prefix}.proteins.faa -p meta\n   \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "   prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   mkdir -p ${prefix}\n   prodigal -i $contigs -o ${prefix}/${prefix}.gbk -a ${prefix}/${prefix}.proteins.faa -p meta\n   \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigs_for_prodigal"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir \"${params.outdir}/prodigal\", mode: 'copy'"
        ],
        "when": "!euk",
        "stub": ""
    },
    "augustus": {
        "name_process": "augustus",
        "string_process": "\nprocess augustus {\n   tag \"$prefix\"\n   publishDir \"${params.outdir}/augustus\", mode: 'copy'\n\n   input:\n   file contigs from contigs_for_augustus\n\n   output:\n   file \"${prefix}.aa\" into faa_eukcc, faa_eggnog, faa_kofam\n   file \"${prefix}*\"\n\n   when:\n   euk\n\n   script:\n   prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   # clean id\n   cat $contigs | sed 's/_length.*\\$//g' > ${prefix}_clean.fasta\n   # mask genome\n   tantan ${prefix}_clean.fasta > ${prefix}_mask.fasta\n   # gene prediction\n   augustus --species=${params.augustus_species} --gff3=on --uniqueGeneId=true --protein=on --codingseq=on ${prefix}_mask.fasta > ${prefix}.gff\n   # generate proteins\n   getAnnoFasta.pl ${prefix}.gff\n   \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "   prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   # clean id\n   cat $contigs | sed 's/_length.*\\$//g' > ${prefix}_clean.fasta\n   # mask genome\n   tantan ${prefix}_clean.fasta > ${prefix}_mask.fasta\n   # gene prediction\n   augustus --species=${params.augustus_species} --gff3=on --uniqueGeneId=true --protein=on --codingseq=on ${prefix}_mask.fasta > ${prefix}.gff\n   # generate proteins\n   getAnnoFasta.pl ${prefix}.gff\n   \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "AUGUSTUS"
        ],
        "tools_url": [
            "https://bio.tools/augustus"
        ],
        "tools_dico": [
            {
                "name": "AUGUSTUS",
                "uri": "https://bio.tools/augustus",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Gene and protein families"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Genes, gene family or system"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Homology-based gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3662",
                                    "term": "Ab-initio gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0004",
                                    "term": "Operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Evidence-based gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Gene prediction (homology-based)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Empirical gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Similarity-based gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Empirical gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3662",
                                    "term": "Gene prediction (ab-initio)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "AUGUSTUS is a eukaryotic gene prediction tool. It can integrate evidence, e.g. from RNA-Seq, ESTs, proteomics, but can also predict genes ab initio. The PPX extension to AUGUSTUS can take a protein sequence multiple sequence alignment as input to find new members of the family in a genome. It can be run through a web interface (see https://bio.tools/webaugustus), or downloaded and run locally.",
                "homepage": "http://bioinf.uni-greifswald.de/augustus"
            }
        ],
        "inputs": [
            "contigs_for_augustus"
        ],
        "nb_inputs": 1,
        "outputs": [
            "faa_eukcc",
            "faa_eggnog",
            "faa_kofam"
        ],
        "nb_outputs": 3,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir \"${params.outdir}/augustus\", mode: 'copy'"
        ],
        "when": "euk",
        "stub": ""
    },
    "eukcc": {
        "name_process": "eukcc",
        "string_process": "\nprocess eukcc {\n   publishDir \"${params.outdir}/EukCC\", mode: 'copy'\n\n   input:\n   file faa from faa_eukcc\n   file db from eukcc_db\n\n   output:\n   file \"${prefix}\"\n\n   when:\n   euk && eukcc_db\n\n   script:\n   prefix = faa.toString() - ~/(\\.faa)?(\\.aa)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   export HOME=/tmp/\n   if [ -f \"/tmp/.etetoolkit/taxa.sqlite\" ]; then\n     echo \"NCBI taxa database exist!\"\n   else\n     python -c \"from ete3 import NCBITaxa; ncbi = NCBITaxa(taxdump_file='/opt/nf-core-scgs/taxdump.tar.gz')\"\n   fi\n   eukcc --db ${db} --ncores ${task.cpus} --outdir ${prefix} --protein ${faa} || echo \"Ignore minor errors of eukcc!\"\n   \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "   prefix = faa.toString() - ~/(\\.faa)?(\\.aa)?(\\.fasta)?(\\.fa)?$/\n   \"\"\"\n   export HOME=/tmp/\n   if [ -f \"/tmp/.etetoolkit/taxa.sqlite\" ]; then\n     echo \"NCBI taxa database exist!\"\n   else\n     python -c \"from ete3 import NCBITaxa; ncbi = NCBITaxa(taxdump_file='/opt/nf-core-scgs/taxdump.tar.gz')\"\n   fi\n   eukcc --db ${db} --ncores ${task.cpus} --outdir ${prefix} --protein ${faa} || echo \"Ignore minor errors of eukcc!\"\n   \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "NCBI-SRA"
        ],
        "tools_url": [
            "https://bio.tools/NCBI-SRA"
        ],
        "tools_dico": [
            {
                "name": "NCBI-SRA",
                "uri": "https://bio.tools/NCBI-SRA",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Microbial ecology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0659",
                            "term": "Functional, regulatory and non-coding RNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Environmental microbiology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3695",
                                    "term": "Filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Experimental data from flesh quality assessment and shelf life monitoring of high pressure processed European sea bass (Dicentrarchus labrax) fillets.\n\nSequence Read Archive (SRA) makes biological sequence data available to the research community to enhance reproducibility and allow for new discoveries by comparing data sets.\n\nView results as an expanded interactive table using the RunSelector.\n\nShowing SRA Experiments for (projects.\n\n||| COMMON LINK WITH (PUB. & NAME DIFFERENT) bio.tools/ncbi_resources (NLM.NIH.GOV), bio.tools/sra (NLM.NIH.GOV/sra), bio.tools/genbank (NLM.NIH.GOV).\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'bass Dicentrarchus labrax fillets', 'HP-processed fillets', 'sea bass Dicentrarchus labrax fillets', 'Dicentrarchus labrax fillets'",
                "homepage": "https://www.ncbi.nlm.nih.gov/sra/(projects"
            }
        ],
        "inputs": [
            "faa_eukcc",
            "eukcc_db"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir \"${params.outdir}/EukCC\", mode: 'copy'"
        ],
        "when": "euk && eukcc_db",
        "stub": ""
    },
    "multiqc_ref": {
        "name_process": "multiqc_ref",
        "string_process": "\nprocess multiqc_ref {\n    label \"multiqc\"\n    publishDir \"${params.outdir}/MultiQC\", mode: 'copy'\n\n    input:\n    file multiqc_config from ch_multiqc_config1\n    file ('fastqc/*') from fastqc_results1.collect()\n    file ('software_versions/*') from software_versions_yaml1\n    file ('trimgalore/*') from trimgalore_results1.collect()\n    file ('fastqc2/*') from trimgalore_fastqc_reports1.collect()\n    file ('samtools/*') from samtools_stats.collect()\n    file ('preseq/*') from preseq_for_multiqc.collect()\n    file ('*') from qualimap_for_multiqc\n    file ('quast/*') from quast_report1\n    file ('prokka/*') from prokka_for_mqc1.collect()\n    file ('kraken/*') from kraken_for_mqc1.collect()\n    file workflow_summary from create_workflow_summary(summary)\n\n    output:\n    file \"*multiqc_report.html\" into multiqc_report1\n    file \"*_data\"\n\n    when:\n    denovo == false\n\n    script:\n    \"\"\"\n    multiqc -f --config $multiqc_config .\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    multiqc -f --config $multiqc_config .\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "ch_multiqc_config1",
            "fastqc_results1",
            "software_versions_yaml1",
            "trimgalore_results1",
            "trimgalore_fastqc_reports1",
            "samtools_stats",
            "preseq_for_multiqc",
            "qualimap_for_multiqc",
            "quast_report1",
            "prokka_for_mqc1",
            "kraken_for_mqc1",
            "summary"
        ],
        "nb_inputs": 12,
        "outputs": [
            "multiqc_report1"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "label \"multiqc\"",
            "publishDir \"${params.outdir}/MultiQC\", mode: 'copy'"
        ],
        "when": "denovo == false",
        "stub": ""
    },
    "multiqc_denovo": {
        "name_process": "multiqc_denovo",
        "string_process": "\nprocess multiqc_denovo {\n    label \"multiqc\"\n    publishDir \"${params.outdir}/MultiQC\", mode: 'copy'\n\n    input:\n    file multiqc_config from ch_multiqc_config2\n    file ('fastqc/*') from fastqc_results2.collect()\n    file ('software_versions/*') from software_versions_yaml2\n    file ('trimgalore/*') from trimgalore_results2.collect()\n    file ('fastqc2/*') from trimgalore_fastqc_reports2.collect()\n    file ('quast/*') from quast_report2.ifEmpty('/dev/null')\n    file ('prokka/*') from prokka_for_mqc2.collect()\n    file ('kraken/*') from kraken_for_mqc2.collect()\n    file workflow_summary from create_workflow_summary(summary)\n\n    output:\n    file \"*multiqc_report.html\" into multiqc_report2\n    file \"*_data\"\n\n    when:\n    denovo == true\n\n    script:\n    \"\"\"\n    multiqc -f --config $multiqc_config .\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    multiqc -f --config $multiqc_config .\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "ch_multiqc_config2",
            "fastqc_results2",
            "software_versions_yaml2",
            "trimgalore_results2",
            "trimgalore_fastqc_reports2",
            "quast_report2",
            "prokka_for_mqc2",
            "kraken_for_mqc2",
            "summary"
        ],
        "nb_inputs": 9,
        "outputs": [
            "multiqc_report2"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "label \"multiqc\"",
            "publishDir \"${params.outdir}/MultiQC\", mode: 'copy'"
        ],
        "when": "denovo == true",
        "stub": ""
    },
    "eggnog": {
        "name_process": "eggnog",
        "string_process": "\nprocess eggnog {\n   tag \"$prefix\"\n   publishDir \"${params.outdir}/eggnog\", mode: 'copy'\n\n   input:\n   file faa from faa_eggnog\n   file db from eggnog_db\n\n   output:\n   file \"${prefix}.emapper.annotations\"\n\n   when:\n   eggnog_db\n\n   script:\n   prefix = faa.toString() - ~/(\\.proteins\\.fa)?(\\.faa)?$/\n   \"\"\"\n   set +u\n   source activate base\n   emapper.py -i $faa -o $prefix --data_dir $db --dmnd_db $db/eggnog_proteins.dmnd -m diamond --cpu ${task.cpus}\n   \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "   prefix = faa.toString() - ~/(\\.proteins\\.fa)?(\\.faa)?$/\n   \"\"\"\n   set +u\n   source activate base\n   emapper.py -i $faa -o $prefix --data_dir $db --dmnd_db $db/eggnog_proteins.dmnd -m diamond --cpu ${task.cpus}\n   \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "faa_eggnog",
            "eggnog_db"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir \"${params.outdir}/eggnog\", mode: 'copy'"
        ],
        "when": "eggnog_db",
        "stub": ""
    },
    "kofam": {
        "name_process": "kofam",
        "string_process": "\nprocess kofam {\n   tag \"$prefix\"\n   publishDir \"${params.outdir}/kofam\", mode: 'copy'\n\n   input:\n   file faa from faa_kofam\n   file profile from kofam_profile\n   file ko_list from kofam_kolist\n\n   output:\n   file \"${prefix}_KOs_*.txt\" into kofam_for_split\n\n   when:\n   kofam_profile && kofam_kolist\n\n   script:\n   prefix = faa.toString() - ~/(\\.proteins\\.fa)?(\\.faa)?$/\n   \"\"\"\n   exec_annotation -p ${profile} -k ${ko_list} --cpu ${task.cpus} -T 0.8 --keep-tabular -o ${prefix}_KOs_detail.txt ${faa}\n   exec_annotation -p ${profile} -k ${ko_list} --cpu ${task.cpus} -T 0.8 --keep-tabular -r -f mapper -o ${prefix}_KOs_mapper.txt ${faa}\n   exec_annotation -p ${profile} -k ${ko_list} --cpu ${task.cpus} -T 0.8 --keep-tabular -r -f mapper-one-line -o ${prefix}_KOs_mapper2.txt ${faa}\n   kofam_postprocess.py /opt/nf-core-scgs/assets/ko_KO.txt ${prefix}_KOs_mapper.txt > ${prefix}_KOs_ko.txt\n   \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "   prefix = faa.toString() - ~/(\\.proteins\\.fa)?(\\.faa)?$/\n   \"\"\"\n   exec_annotation -p ${profile} -k ${ko_list} --cpu ${task.cpus} -T 0.8 --keep-tabular -o ${prefix}_KOs_detail.txt ${faa}\n   exec_annotation -p ${profile} -k ${ko_list} --cpu ${task.cpus} -T 0.8 --keep-tabular -r -f mapper -o ${prefix}_KOs_mapper.txt ${faa}\n   exec_annotation -p ${profile} -k ${ko_list} --cpu ${task.cpus} -T 0.8 --keep-tabular -r -f mapper-one-line -o ${prefix}_KOs_mapper2.txt ${faa}\n   kofam_postprocess.py /opt/nf-core-scgs/assets/ko_KO.txt ${prefix}_KOs_mapper.txt > ${prefix}_KOs_ko.txt\n   \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "faa_kofam",
            "kofam_profile",
            "kofam_kolist"
        ],
        "nb_inputs": 3,
        "outputs": [
            "kofam_for_split"
        ],
        "nb_outputs": 1,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir \"${params.outdir}/kofam\", mode: 'copy'"
        ],
        "when": "kofam_profile && kofam_kolist",
        "stub": ""
    },
    "resfinder": {
        "name_process": "resfinder",
        "string_process": "\nprocess resfinder {\n    tag \"$prefix\"\n    publishDir \"${params.outdir}/ARG\", mode: 'copy'\n\n    input:\n    file contigs from contigs_for_resfinder\n    file db from resfinder_db\n\n    output:\n    file \"${prefix}/*\"\n\n    when:\n    !euk && params.acquired && resfinder_db\n\n    script:\n    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    \"\"\"\n    mkdir -p $prefix\n    python /opt/resfinder/resfinder.py -i $contigs -o $prefix -p $db -mp blastn -x\n    rm -rf $prefix/tmp\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    \"\"\"\n    mkdir -p $prefix\n    python /opt/resfinder/resfinder.py -i $contigs -o $prefix -p $db -mp blastn -x\n    rm -rf $prefix/tmp\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigs_for_resfinder",
            "resfinder_db"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir \"${params.outdir}/ARG\", mode: 'copy'"
        ],
        "when": "!euk && params.acquired && resfinder_db",
        "stub": ""
    },
    "pointfinder": {
        "name_process": "pointfinder",
        "string_process": "\nprocess pointfinder {\n    tag \"$prefix\"\n    publishDir \"${params.outdir}/ARG\", mode: 'copy'\n\n    input:\n    file contigs from contigs_for_pointfinder\n    file db from pointfinder_db\n\n    output:\n    file \"${prefix}/*\"\n\n    when:\n    !euk && params.point && pointfinder_db\n\n    script:\n    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    species = params.pointfinder_species\n    known_snp = params.only_known ? \"\" : \"-l 0.4 -r all -u\"\n    \"\"\"\n    mkdir -p $prefix\n    python /opt/pointfinder/PointFinder.py -p $db \\\n      -m blastn -m_p /opt/conda/bin/blastn $known_snp \\\n      -i $contigs -o $prefix -s $species\n    rm -rf $prefix/tmp\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    prefix = contigs.toString() - ~/(\\.ctgs\\.fasta)?(\\.ctgs)?(\\.fasta)?(\\.fa)?$/\n    species = params.pointfinder_species\n    known_snp = params.only_known ? \"\" : \"-l 0.4 -r all -u\"\n    \"\"\"\n    mkdir -p $prefix\n    python /opt/pointfinder/PointFinder.py -p $db \\\n      -m blastn -m_p /opt/conda/bin/blastn $known_snp \\\n      -i $contigs -o $prefix -s $species\n    rm -rf $prefix/tmp\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "JSpecies"
        ],
        "tools_url": [
            "https://bio.tools/jspecies"
        ],
        "tools_dico": [
            {
                "name": "JSpecies",
                "uri": "https://bio.tools/jspecies",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3299",
                            "term": "Evolutionary biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0797",
                            "term": "Comparative genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3299",
                            "term": "Evolution"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3209",
                                    "term": "Genome comparison"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3209",
                                    "term": "Genomic region matching"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An easy to use, biologist-centric software designed to measure the probability if two genomes belonging to the same species or not.",
                "homepage": "http://www.imedea.uib-csic.es/jspecies/index.html"
            }
        ],
        "inputs": [
            "contigs_for_pointfinder",
            "pointfinder_db"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "tag \"$prefix\"",
            "publishDir \"${params.outdir}/ARG\", mode: 'copy'"
        ],
        "when": "!euk && params.point && pointfinder_db",
        "stub": ""
    },
    "split_checkm": {
        "name_process": "split_checkm",
        "string_process": "\nprocess split_checkm {\n    publishDir \"${params.outdir}/\", mode: 'copy'\n\n    input:\n    file \"results/spades/*\" from contigs_for_split.collect()\n    file \"results/blob/*\" from blob_tax_for_split.collect()\n    file \"results/prokka/*\" from prokka_for_split.collect()\n    file \"results/kofam/*\" from kofam_for_split.collect()\n\n    output:\n    file \"split/*\"\n\n    when:\n    params.split\n\n    script:\n    \"\"\"\n    cli.py tools scgs_split\n    cd split\n    samples=(`ls -d *_genus | sed 's/_genus//g'`)\n    for sample in \\${samples[*]}; do\n      mkdir -p \\${sample}_genus_checkM\n      checkm lineage_wf -t ${task.cpus} -f \\${sample}_genus_checkM.txt -x fasta \\${sample}_genus \\${sample}_genus_checkM || echo \"Ignore internal errors!\" \n    done\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    cli.py tools scgs_split\n    cd split\n    samples=(`ls -d *_genus | sed 's/_genus//g'`)\n    for sample in \\${samples[*]}; do\n      mkdir -p \\${sample}_genus_checkM\n      checkm lineage_wf -t ${task.cpus} -f \\${sample}_genus_checkM.txt -x fasta \\${sample}_genus \\${sample}_genus_checkM || echo \"Ignore internal errors!\" \n    done\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contigs_for_split",
            "blob_tax_for_split",
            "prokka_for_split",
            "kofam_for_split"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir \"${params.outdir}/\", mode: 'copy'"
        ],
        "when": "params.split",
        "stub": ""
    },
    "output_documentation": {
        "name_process": "output_documentation",
        "string_process": "\nprocess output_documentation {\n    publishDir \"${params.outdir}/pipeline_info\", mode: 'copy'\n\n    input:\n    file output_docs from ch_output_docs\n\n    output:\n    file \"results_description.html\"\n\n    script:\n    \"\"\"\n    markdown_to_html.py -o results_description.html $output_docs\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    markdown_to_html.py -o results_description.html $output_docs\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_output_docs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "gongyh__nf-core-scgs",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}