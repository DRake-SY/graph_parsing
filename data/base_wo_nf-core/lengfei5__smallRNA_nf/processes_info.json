{
    "cutadapt": {
        "name_process": "cutadapt",
        "string_process": "\nprocess cutadapt {\n    tag \"Channel: ${name}\"\n\n    publishDir \"${params.outdir}/cutadapt\", mode: 'copy', pattern: '*.err'\n\n    input:\n        set val(name), file(bam) from read_files\n\n    output:\n        set name, file(\"cutadapt.fastq\") into fastq_cutadapt\n\t      set name, file(\"cutadapt.${name}.err\") into stat_cutadapt\n\t      set name, file(\"cntTotal.txt\") into cnt_total\n\n    script:\n    \"\"\"\n        PYTHON_EGG_CACHE=`pwd` #cutadapt wants to write into home FIXME\n        export PYTHON_EGG_CACHE\n\n        samtools view -c ${bam} > cntTotal.txt\n        bamToFastq -i ${bam} -fq /dev/stdout |\\\n            cutadapt -e ${params.adapterER} -a ${params.adapter} -f fastq --overlap 5 --discard-untrimmed -o cutadapt.fastq - > cutadapt.${name}.err\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n        PYTHON_EGG_CACHE=`pwd` #cutadapt wants to write into home FIXME\n        export PYTHON_EGG_CACHE\n\n        samtools view -c ${bam} > cntTotal.txt\n        bamToFastq -i ${bam} -fq /dev/stdout |\\\n            cutadapt -e ${params.adapterER} -a ${params.adapter} -f fastq --overlap 5 --discard-untrimmed -o cutadapt.fastq - > cutadapt.${name}.err\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "Cutadapt"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/cutadapt"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "Cutadapt",
                "uri": "https://bio.tools/cutadapt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ]
                    }
                ],
                "description": "Find and remove adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads.",
                "homepage": "https://pypi.python.org/pypi/cutadapt"
            }
        ],
        "inputs": [
            "read_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastq_cutadapt",
            "stat_cutadapt",
            "cnt_total"
        ],
        "nb_outputs": 3,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/cutadapt\", mode: 'copy', pattern: '*.err'"
        ],
        "when": "",
        "stub": ""
    },
    "skip_sRBCdemultiplex": {
        "name_process": "skip_sRBCdemultiplex",
        "string_process": "\nprocess skip_sRBCdemultiplex {\n\n  tag \"Channel: ${name}\"\n\n  when:\n  ! params.demultiplexWithsRBC\n\n  input:\n    set name, file(fastq) from fastq_cutadapt2\n\n  output:\n    set name, file(\"cutadapt.fastq\") into fastq_skipDemultiplex\n\n  script:\n  \"\"\"\n  echo 'Hello world!' > test.txt\n\n  \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "  \"\"\"\n  echo 'Hello world!' > test.txt\n\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastq_cutadapt2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastq_skipDemultiplex"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "! params.demultiplexWithsRBC",
        "stub": ""
    },
    "fastq_sRBC_demultiplex": {
        "name_process": "fastq_sRBC_demultiplex",
        "string_process": "\nprocess fastq_sRBC_demultiplex {\n\n  tag \"Channel: ${name}\"\n  publishDir \"${params.outdir}/fastq_demultiplex_trim_sRBC\",  mode: 'copy'\n\n  when:\n  params.demultiplexWithsRBC\n\n  input:\n    file bc_file from bc_file\n    set name, file(fastq) from fastq_cutadapt\n\n  output:\n    set name, file(\"*.fastq\") into fastq_split\n                                      \n    set name, file(\"${name}.cnt_sRBC_demul.txt\") into cnt_sRBC_demul\n    set name, file(\"${name}.cnt_sRBC_unmatched.txt\") into cnt_sRBC_unmatched\n\n  shell:\n  '''\n    cat !{bc_file} |grep !{name} |cut -f2,3 > barcode_file.txt\n    cat !{fastq} | fastx_barcode_splitter.pl --bcfile barcode_file.txt --eol --exact --prefix !{name}_ --suffix .fastq\n    cat !{fastq} | paste - - - - | wc -l > !{name}.cnt_sRBC_demul.txt\n    cat $(ls *.fastq |grep unmatched) | paste - - - - | wc -l > !{name}.cnt_sRBC_unmatched.txt\n\n  '''\n}",
        "nb_lignes_process": 26,
        "string_script": "  '''\n    cat !{bc_file} |grep !{name} |cut -f2,3 > barcode_file.txt\n    cat !{fastq} | fastx_barcode_splitter.pl --bcfile barcode_file.txt --eol --exact --prefix !{name}_ --suffix .fastq\n    cat !{fastq} | paste - - - - | wc -l > !{name}.cnt_sRBC_demul.txt\n    cat $(ls *.fastq |grep unmatched) | paste - - - - | wc -l > !{name}.cnt_sRBC_unmatched.txt\n\n  '''",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bc_file",
            "fastq_cutadapt"
        ],
        "nb_inputs": 2,
        "outputs": [
            "fastq_split",
            "cnt_sRBC_demul",
            "cnt_sRBC_unmatched"
        ],
        "nb_outputs": 3,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/fastq_demultiplex_trim_sRBC\", mode: 'copy'"
        ],
        "when": "params.demultiplexWithsRBC",
        "stub": ""
    },
    "fastq_sRBC_trim": {
        "name_process": "fastq_sRBC_trim",
        "string_process": "\nprocess fastq_sRBC_trim {\n\n    tag \"Channel: ${name}\"\n    publishDir \"${params.outdir}/fastq_demultiplex_trim_sRBC\", mode: 'copy'\n\n    when:\n    params.demultiplexWithsRBC\n\n    input:\n    set name, file(fastq) from fastq_split_clean\n\n    output:\n    set name, file(\"${name}_srbcTrim.err\") into stat_srbcTrim\n    set name, file(\"${name}_srbc_trim.fastq\") into fastq_bc_splitTrimmed\n\n    script:\n    \"\"\"\n    PYTHON_EGG_CACHE=`pwd` #cutadapt wants to write into home FIXME\n    export PYTHON_EGG_CACHE\n\n    cutadapt -u -5 --minimum-length 28 -f fastq -o ${name}_srbc_trim.fastq ${fastq} > ${name}_srbcTrim.err\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    PYTHON_EGG_CACHE=`pwd` #cutadapt wants to write into home FIXME\n    export PYTHON_EGG_CACHE\n\n    cutadapt -u -5 --minimum-length 28 -f fastq -o ${name}_srbc_trim.fastq ${fastq} > ${name}_srbcTrim.err\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "Cutadapt"
        ],
        "tools_url": [
            "https://bio.tools/cutadapt"
        ],
        "tools_dico": [
            {
                "name": "Cutadapt",
                "uri": "https://bio.tools/cutadapt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ]
                    }
                ],
                "description": "Find and remove adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads.",
                "homepage": "https://pypi.python.org/pypi/cutadapt"
            }
        ],
        "inputs": [
            "fastq_split_clean"
        ],
        "nb_inputs": 1,
        "outputs": [
            "stat_srbcTrim",
            "fastq_bc_splitTrimmed"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/fastq_demultiplex_trim_sRBC\", mode: 'copy'"
        ],
        "when": "params.demultiplexWithsRBC",
        "stub": ""
    },
    "trimUMI": {
        "name_process": "trimUMI",
        "string_process": "\nprocess trimUMI {\n\n    tag \"Channel: ${name}\"\n\n    input:\n        set name, file(fastq) from fastq_cutadapt\n\n    output:\n        set name, file(\"trimmed.fastq\") into fastq_trimmed, fastq_trimmed2, fastq_for_spike\n        set name, file(\"cntTrimmed.txt\") into cnt_trimmed\n\n    script:\n    \"\"\"\n    cat ${fastq} |\\\n        paste - - - - |\\\n        perl ${baseDir}/scripts/trim.pl -m ${params.minLength} -M ${params.maxLength} > trimmed.fastq\n\n    cat trimmed.fastq | paste - - - - | wc -l > cntTrimmed.txt\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    cat ${fastq} |\\\n        paste - - - - |\\\n        perl ${baseDir}/scripts/trim.pl -m ${params.minLength} -M ${params.maxLength} > trimmed.fastq\n\n    cat trimmed.fastq | paste - - - - | wc -l > cntTrimmed.txt\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastq_cutadapt"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastq_trimmed",
            "fastq_trimmed2",
            "fastq_for_spike",
            "cnt_trimmed"
        ],
        "nb_outputs": 4,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "trimSpike": {
        "name_process": "trimSpike",
        "string_process": "\nprocess trimSpike {\n\n    tag \"Channel: ${name}\"\n\n    when:\n    spikeIn_file.exists()\n\n    input:\n        set name, file(fastq) from fastq_for_spike\n\n    output:\n        set name, file(\"spike.fastq\") into fastq_spike\n                                                           \n\n    script:\n    \"\"\"\n    cat ${fastq} |\\\n        paste - - - - |\\\n        perl ${baseDir}/scripts/trim.pl -m 13 -M 13 > spike.fastq\n\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    cat ${fastq} |\\\n        paste - - - - |\\\n        perl ${baseDir}/scripts/trim.pl -m 13 -M 13 > spike.fastq\n\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastq_for_spike"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastq_spike"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "spikeIn_file.exists()",
        "stub": ""
    },
    "buildTailorIndexSpikeIn": {
        "name_process": "buildTailorIndexSpikeIn",
        "string_process": "\nprocess buildTailorIndexSpikeIn {\n\n    when:\n    spikeIn_file.exists()\n\n    input:\n\t   file genome from spikeIn_file\n\n    output:\n     file \"index.tailor.spike*\" into index_tailor_spikeIn\n\n    script:\n    \"\"\"\n    tailor_v1.1_linux_static build -i ${genome} -p index.tailor.spike\n\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    tailor_v1.1_linux_static build -i ${genome} -p index.tailor.spike\n\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "spikeIn_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "index_tailor_spikeIn"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [],
        "when": "spikeIn_file.exists()",
        "stub": ""
    },
    "alignSpike": {
        "name_process": "alignSpike",
        "string_process": "\nprocess alignSpike {\n\n    tag \"Channel: ${name}\"\n    publishDir \"${params.outdir}/spikeIns\", mode: 'copy', pattern: '*.spike.bam'\n\n    when:\n    spikeIn_file.exists()\n\n    input:\n      file index from index_tailor_spikeIn\n      set name, file(fastq) from fastq_spike\n\n    output:\n      set name, file(\"spike.bam\") into bam_tailor_spike, bam_tailor_spike2\n      file \"${name}.spike.bam\"\n\n    script:\n    \"\"\"\n    if [ -e index.tailor.spike.t_bwt.bwt ]; then\n        tailor_v1.1_linux_static map -i ${fastq} -p index.tailor.spike -l 13 -n ${task.cpus} | samtools view -bS > spike.bam\n    else\n        touch spike.bam\n    fi\n    cp spike.bam ${name}.spike.bam\n\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    if [ -e index.tailor.spike.t_bwt.bwt ]; then\n        tailor_v1.1_linux_static map -i ${fastq} -p index.tailor.spike -l 13 -n ${task.cpus} | samtools view -bS > spike.bam\n    else\n        touch spike.bam\n    fi\n    cp spike.bam ${name}.spike.bam\n\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "index_tailor_spikeIn",
            "fastq_spike"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bam_tailor_spike",
            "bam_tailor_spike2"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/spikeIns\", mode: 'copy', pattern: '*.spike.bam'"
        ],
        "when": "spikeIn_file.exists()",
        "stub": ""
    },
    "countSpike": {
        "name_process": "countSpike",
        "string_process": " process countSpike {\n    tag \"Channel: ${name}\"\n    publishDir \"${params.outdir}/spikeIns\", mode: 'copy', pattern: '*spikeIn.txt'\n\n    when:\n    spikeIn_file.exists()\n\n    input:\n    set name, file(spike_bam) from bam_tailor_spike\n\n    output:\n    file \"${name}.spikeIn.txt\" into spike_count\n\n    script:\n    \"\"\"\n    bash ${baseDir}/scripts/countSpikeIn.sh ${spike_bam} > ${name}.spikeIn.txt\n    \"\"\"\n\n }",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    bash ${baseDir}/scripts/countSpikeIn.sh ${spike_bam} > ${name}.spikeIn.txt\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bam_tailor_spike"
        ],
        "nb_inputs": 1,
        "outputs": [
            "spike_count"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/spikeIns\", mode: 'copy', pattern: '*spikeIn.txt'"
        ],
        "when": "spikeIn_file.exists()",
        "stub": ""
    },
    "buildTailorIndex": {
        "name_process": "buildTailorIndex",
        "string_process": "\nprocess buildTailorIndex {\n\n    input:\n\t    file genome from genome_file\n\n    output:\n      file \"index.tailor*\" into index_tailor\n\n    script:\n    \"\"\"\n    tailor_v1.1_linux_static build -i ${genome} -p index.tailor\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n    tailor_v1.1_linux_static build -i ${genome} -p index.tailor\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "index_tailor"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "buildTailorIndexContamination": {
        "name_process": "buildTailorIndexContamination",
        "string_process": "\nprocess buildTailorIndexContamination {\n\n    input:\n\t   file genome from cont_file\n\n    output:\n     file \"index.tailor.cont*\" into index_tailor_cont\n\n    script:\n    \"\"\"\n    if [ ${genome} = \"none\" ]; then\n        touch index.tailor.cont\n    else\n        tailor_v1.1_linux_static build -i ${genome} -p index.tailor.cont\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    if [ ${genome} = \"none\" ]; then\n        touch index.tailor.cont\n    else\n        tailor_v1.1_linux_static build -i ${genome} -p index.tailor.cont\n    fi\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cont_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "index_tailor_cont"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "alignContamination": {
        "name_process": "alignContamination",
        "string_process": "\nprocess alignContamination {\n\n    tag \"Channel: ${name}\"\n\n    input:\n      file index from index_tailor_cont\n      set name, file(fastq) from fastq_trimmed\n\n    output:\n      set name, file(\"contamination.bam\") into bam_tailor_cont, bam_tailor_cont2\n\n    script:\n    \"\"\"\n    if [ -e index.tailor.cont.t_bwt.bwt ]; then\n        tailor_v1.1_linux_static map -i ${fastq} -p index.tailor.cont -l ${params.minAlign}  -n ${task.cpus} | samtools view -bS > contamination.bam\n    else\n        touch contamination.bam\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    if [ -e index.tailor.cont.t_bwt.bwt ]; then\n        tailor_v1.1_linux_static map -i ${fastq} -p index.tailor.cont -l ${params.minAlign}  -n ${task.cpus} | samtools view -bS > contamination.bam\n    else\n        touch contamination.bam\n    fi\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "index_tailor_cont",
            "fastq_trimmed"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bam_tailor_cont",
            "bam_tailor_cont2"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "cleanReads": {
        "name_process": "cleanReads",
        "string_process": "\nprocess cleanReads {\n\n    tag \"Channel: ${name}\"\n\n    input:\n        set name, file(fastq), file(bam) from fastq_bam\n\n    output:\n        set name, file(\"cleanReads.fastq\") into fastq_cleanReads\n\n    script:\n    \"\"\"\n    if [ -s ${bam} ]; then\n        perl ${baseDir}/scripts/extract.unaligned.pl -b ${bam} -f ${fastq} > cleanReads.fastq\n    else\n        cp ${fastq} cleanReads.fastq\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    if [ -s ${bam} ]; then\n        perl ${baseDir}/scripts/extract.unaligned.pl -b ${bam} -f ${fastq} > cleanReads.fastq\n    else\n        cp ${fastq} cleanReads.fastq\n    fi\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastq_bam"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastq_cleanReads"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "align": {
        "name_process": "align",
        "string_process": "\nprocess align {\n\n    tag \"Channel: ${name}\"\n\n    input:\n\t   file index from index_tailor\n     set name, file(fastq) from fastq_cleanReads\n\n    output:\n      set name, file(\"tailor.bam\") into bam_tailor, bam_tailor2\n\n    script:\n    \"\"\"\n    tailor_v1.1_linux_static map -i ${fastq} -p index.tailor -l ${params.minAlign} -n ${task.cpus} | perl $baseDir/scripts/bam.NH2fraction.pl -m ${params.maxMultialign} | samtools view -bS > tailor.bam\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    tailor_v1.1_linux_static map -i ${fastq} -p index.tailor -l ${params.minAlign} -n ${task.cpus} | perl $baseDir/scripts/bam.NH2fraction.pl -m ${params.maxMultialign} | samtools view -bS > tailor.bam\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "index_tailor",
            "fastq_cleanReads"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bam_tailor",
            "bam_tailor2"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "alignStat": {
        "name_process": "alignStat",
        "string_process": "\nprocess alignStat {\n\n  tag \"Channel: ${name}\"\n\n  input:\n  set name, file(bam) from bam_tailor2\n\n  output:\n  set name, file(\"tailorStat.txt\") into tailorStat\n\n  script:\n  \"\"\"\n  samtools sort -@ ${task.cpus} -n -m ${params.memPerCPUSort} -l 0 ${bam} | samtools view | cut -f 1  | uniq | wc -l > tailorStat.txt\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "  \"\"\"\n  samtools sort -@ ${task.cpus} -n -m ${params.memPerCPUSort} -l 0 ${bam} | samtools view | cut -f 1  | uniq | wc -l > tailorStat.txt\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bam_tailor2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tailorStat"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "splitAndMergeGTF": {
        "name_process": "splitAndMergeGTF",
        "string_process": "\nprocess splitAndMergeGTF {\n\n    input:\n        file gtf from gtf_file\n        file gtfNoSplit from gtfNoSplit_file\n\n    output:\n        file \"splitAndMerged.gtf\" into gtf_split\n\t      file \"splitAndMerged.as.gtf\" into gtf_split_as\n\n    shell:\n    '''\n    if [ \"!{gtf}\" != \"NA\" ]; then\n      perl !{baseDir}/scripts/GTF.splitInHalf.pl !{gtf} > split.gtf\n    else\n      touch split.gtf\n    fi\n\n    if [ \"!{gtfNoSplit}\" != \"NA\" ]; then\n      cat split.gtf !{gtfNoSplit} > splitAndMerged.gtf\n    else\n      mv split.gtf splitAndMerged.gtf\n    fi\n\n    perl -pe '@c = split \"\\t\"; $c[6] =~ tr/+-/-+/; $c[1].=\"_AS\"; $_=join \"\\t\", @c; s/\";/_AS\";/g' splitAndMerged.gtf > splitAndMerged.as.gtf\n    '''\n}",
        "nb_lignes_process": 26,
        "string_script": "    '''\n    if [ \"!{gtf}\" != \"NA\" ]; then\n      perl !{baseDir}/scripts/GTF.splitInHalf.pl !{gtf} > split.gtf\n    else\n      touch split.gtf\n    fi\n\n    if [ \"!{gtfNoSplit}\" != \"NA\" ]; then\n      cat split.gtf !{gtfNoSplit} > splitAndMerged.gtf\n    else\n      mv split.gtf splitAndMerged.gtf\n    fi\n\n    perl -pe '@c = split \"\\t\"; $c[6] =~ tr/+-/-+/; $c[1].=\"_AS\"; $_=join \"\\t\", @c; s/\";/_AS\";/g' splitAndMerged.gtf > splitAndMerged.as.gtf\n    '''",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gtf_file",
            "gtfNoSplit_file"
        ],
        "nb_inputs": 2,
        "outputs": [
            "gtf_split",
            "gtf_split_as"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "assignFeat": {
        "name_process": "assignFeat",
        "string_process": "\nprocess assignFeat {\n\n    tag \"Channel: ${name}\"\n\n    publishDir \"${params.outdir}/seqCnt\", mode: 'copy', pattern: '*.seqCnt.txt'\n\n    input:\n        set name, file(bam) from bam_tailor\n\t      file gtf from gtf_split\n    output:\n        set name, file(\"seqCnt.txt\") into seq_cnt\n        file \"${name}.seqCnt.txt\"\n\n    script:\n    \"\"\"\n    samtools view ${bam} |\\\n        htseq-count -s yes -m intersection-nonempty - ${gtf} -o assign.tmp\n\n    egrep -v no_feature assign.tmp > assign2feat.tmp\n    perl $baseDir/scripts/reduceBam.tailor.umi.pl -g ${gtf} -s assign2feat.tmp > seqCnt.txt\n    cp seqCnt.txt ${name}.seqCnt.txt\n\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    samtools view ${bam} |\\\n        htseq-count -s yes -m intersection-nonempty - ${gtf} -o assign.tmp\n\n    egrep -v no_feature assign.tmp > assign2feat.tmp\n    perl $baseDir/scripts/reduceBam.tailor.umi.pl -g ${gtf} -s assign2feat.tmp > seqCnt.txt\n    cp seqCnt.txt ${name}.seqCnt.txt\n\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "htseqcount"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/htseqcount"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "htseqcount",
                "uri": "https://bio.tools/htseqcount",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "This script takes an alignment file in SAM format and a feature file in GFF format and calculates for each feature the number of reads mapping to it.",
                "homepage": "https://htseq.readthedocs.io/en/release_0.9.1/"
            }
        ],
        "inputs": [
            "bam_tailor",
            "gtf_split"
        ],
        "nb_inputs": 2,
        "outputs": [
            "seq_cnt"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/seqCnt\", mode: 'copy', pattern: '*.seqCnt.txt'"
        ],
        "when": "",
        "stub": ""
    },
    "countSample": {
        "name_process": "countSample",
        "string_process": "\nprocess countSample {\n\n    tag \"Channel: ${name}\"\n\n    publishDir \"${params.outdir}/count\", mode: 'copy', pattern: '*count.txt'\n\n    input:\n\t      set name, file(seq_cnt) from seq_cnt\n\n    output:\n        file \"${name}.count.txt\" into count\n\t      set name, file(\"totalFeatCnt.txt\") into cnt_totalFeat\n\n    shell:\n    '''\n    tail -n +2 !{seq_cnt} |\\\n        awk -vFS=\"\\t\" -vOFS=\"\\t\" -v CONVFMT=\"%.17g\" -vTF=\"!{params.tailFraction}\" \\\n        'BEGIN{print \"Name\", \"GM\", \"PM\", \"Total\", \"GM.UMInum\", \"PM.UMInum\", \"Total.UMInum\", \"GM.UMIfr\", \"PM.UMIfr\", \"Total.UMIfr\"} \\\n        {if ((length($10) / length($8)) <= TF) \\\n          { if ($11 == 0) { GM[$6] = GM[$6] + $12; GMumiNum[$6] = GMumiNum[$6] + $13; GMumiFr[$6] = GMumiFr[$6] + $14; \\\n          ID[$6] = 1; } \\\n            else { PM[$6] = PM[$6] + $12 ; PMumiNum[$6] = PMumiNum[$6] + $13; PMumiFr[$6] = PMumiFr[$6] + $14; \\\n            ID[$6] = 1; } \\\n          } \\\n        } \\\n        END{ Total=0; TotalUmiNum=0; TotalUmiFr=0; for (name in ID) \\\n        { Total=Total+GM[name]+PM[name];\n        printf \"%s\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\n\", \\\n        name, GM[name], PM[name], GM[name]+PM[name], GMumiNum[name], PMumiNum[name], GMumiNum[name]+PMumiNum[name], GMumiFr[name], PMumiFr[name], GMumiFr[name]+PMumiFr[name]}; \\\n        print Total > \"totalFeatCnt.txt\"}' > !{name}.count.txt\n    '''\n}",
        "nb_lignes_process": 31,
        "string_script": "    '''\n    tail -n +2 !{seq_cnt} |\\\n        awk -vFS=\"\\t\" -vOFS=\"\\t\" -v CONVFMT=\"%.17g\" -vTF=\"!{params.tailFraction}\" \\\n        'BEGIN{print \"Name\", \"GM\", \"PM\", \"Total\", \"GM.UMInum\", \"PM.UMInum\", \"Total.UMInum\", \"GM.UMIfr\", \"PM.UMIfr\", \"Total.UMIfr\"} \\\n        {if ((length($10) / length($8)) <= TF) \\\n          { if ($11 == 0) { GM[$6] = GM[$6] + $12; GMumiNum[$6] = GMumiNum[$6] + $13; GMumiFr[$6] = GMumiFr[$6] + $14; \\\n          ID[$6] = 1; } \\\n            else { PM[$6] = PM[$6] + $12 ; PMumiNum[$6] = PMumiNum[$6] + $13; PMumiFr[$6] = PMumiFr[$6] + $14; \\\n            ID[$6] = 1; } \\\n          } \\\n        } \\\n        END{ Total=0; TotalUmiNum=0; TotalUmiFr=0; for (name in ID) \\\n        { Total=Total+GM[name]+PM[name];\n        printf \"%s\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\n\", \\\n        name, GM[name], PM[name], GM[name]+PM[name], GMumiNum[name], PMumiNum[name], GMumiNum[name]+PMumiNum[name], GMumiFr[name], PMumiFr[name], GMumiFr[name]+PMumiFr[name]}; \\\n        print Total > \"totalFeatCnt.txt\"}' > !{name}.count.txt\n    '''",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seq_cnt"
        ],
        "nb_inputs": 1,
        "outputs": [
            "count",
            "cnt_totalFeat"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/count\", mode: 'copy', pattern: '*count.txt'"
        ],
        "when": "",
        "stub": ""
    },
    "statTable_part1": {
        "name_process": "statTable_part1",
        "string_process": "\nprocess statTable_part1 {\n\n    tag \"Channel: ${name}\"\n    publishDir \"${params.outdir}/stat_allSteps\", mode: 'copy'\n\n    input:\n        set name, file(cnt_total), file(cnt_cutadapt), file(cnt_sRBC_unmatched) from cntStat_files_1\n\n    output:\n        file \"${name}.countStat.txt\" into cnt_stat_part1\n\n    script:\n    \"\"\"\n    echo -e \"Name\\tTotal\\tadaptorCutting\\tsRBCunmatched\" > ${name}.countStat.txt\n    TOTAL=`cat ${cnt_total}`\n    cntCutadapt=`cat ${cnt_cutadapt}`\n    sRBCunmatched=`cat ${cnt_sRBC_unmatched}`\n    echo -e \"${name}\\t\\$TOTAL\\t\\$cntCutadapt\\t\\$sRBCunmatched\" >> ${name}.countStat.txt\n\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    echo -e \"Name\\tTotal\\tadaptorCutting\\tsRBCunmatched\" > ${name}.countStat.txt\n    TOTAL=`cat ${cnt_total}`\n    cntCutadapt=`cat ${cnt_cutadapt}`\n    sRBCunmatched=`cat ${cnt_sRBC_unmatched}`\n    echo -e \"${name}\\t\\$TOTAL\\t\\$cntCutadapt\\t\\$sRBCunmatched\" >> ${name}.countStat.txt\n\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cntStat_files_1"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cnt_stat_part1"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/stat_allSteps\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "statTable_part2": {
        "name_process": "statTable_part2",
        "string_process": "\nprocess statTable_part2 {\n\n    tag \"Channel: ${name}\"\n    publishDir \"${params.outdir}/stat_allSteps\", mode: 'copy'\n\n    input:\n        set name, file(cnt_umi_trimmed), file(bam_tailor_cont), file(tailorStat), file(cnt_totalFeat), file(cnt_mapppedToSpike) from cntStat_files_2\n\n    output:\n        file \"${name}.countStat.txt\" into cnt_stat_part2\n\n    script:\n    \"\"\"\n    echo -e \"Name\\tcnt.umiTrimmed\\tContaminationAlign\\tGenomeAlign\\tTotalReadsInFeature\\tREADsInSpikeIns\" > ${name}.countStat.txt\n    cntUMItrimmed=`cat ${cnt_umi_trimmed}`\n    CONT=`samtools view ${bam_tailor_cont} | cut -f 1 | sort -u | wc -l`\n    TAILOR=`cat ${tailorStat}`\n    FEATURE=`cat ${cnt_totalFeat}`\n    spikeIns=`cat ${cnt_mapppedToSpike}`\n    echo -e \"${name}\\t\\$cntUMItrimmed\\t\\$CONT\\t\\$TAILOR\\t\\$FEATURE\\t\\$spikeIns\" >> ${name}.countStat.txt\n\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    echo -e \"Name\\tcnt.umiTrimmed\\tContaminationAlign\\tGenomeAlign\\tTotalReadsInFeature\\tREADsInSpikeIns\" > ${name}.countStat.txt\n    cntUMItrimmed=`cat ${cnt_umi_trimmed}`\n    CONT=`samtools view ${bam_tailor_cont} | cut -f 1 | sort -u | wc -l`\n    TAILOR=`cat ${tailorStat}`\n    FEATURE=`cat ${cnt_totalFeat}`\n    spikeIns=`cat ${cnt_mapppedToSpike}`\n    echo -e \"${name}\\t\\$cntUMItrimmed\\t\\$CONT\\t\\$TAILOR\\t\\$FEATURE\\t\\$spikeIns\" >> ${name}.countStat.txt\n\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cntStat_files_2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cnt_stat_part2"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/stat_allSteps\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "countTable": {
        "name_process": "countTable",
        "string_process": "\nprocess countTable {\n\n    publishDir \"${params.outdir}/result\", mode: 'copy'\n\n    input:\n        file \"count/*\" from count.collect()\n        file \"spikeIn/*\" from spike_count.collect()\n\t      file \"countStat/*\" from cnt_stat.collect()\n\n    output:\n        file \"countTable.txt\"\n        file \"spikeInTable.txt\"\n\t      file \"countTable.html\"\n\t      file \"countStatTable.txt\"\n\n    script:\n    \"\"\"\n    cp $baseDir/scripts/countTable_UMI.Rmd ./countTable.Rmd\n    R --slave -e \"rmarkdown::render('countTable.Rmd')\"\n\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    cp $baseDir/scripts/countTable_UMI.Rmd ./countTable.Rmd\n    R --slave -e \"rmarkdown::render('countTable.Rmd')\"\n\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "count",
            "spike_count",
            "cnt_stat"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "publishDir \"${params.outdir}/result\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "countSimple": {
        "name_process": "countSimple",
        "string_process": "\nprocess countSimple {\n\n    tag \"Channel: ${name}\"\n\n    publishDir \"${params.outdir}/count\", mode: 'copy', pattern: '*count.txt'\n\n    input:\n\t      set name, file(seq_cnt) from seq_cnt\n\n    output:\n        file \"${name}.count.txt\" into count\n\t      set name, file(\"totalFeatCnt.txt\") into cnt_totalFeat\n\n    shell:\n    '''\n    tail -n +2 !{seq_cnt} |\\\n        awk -vFS=\"\\t\" -vOFS=\"\\t\" -v CONVFMT=\"%.17g\" -vTF=\"!{params.tailFraction}\" \\\n        'BEGIN{print \"Name\", \"GM\", \"PM\", \"Total\", \"GM.UMInum\", \"PM.UMInum\", \"Total.UMInum\", \"GM.UMIfr\", \"PM.UMIfr\", \"Total.UMIfr\"} \\\n        {if ((length($10) / length($8)) <= TF) \\\n          { if ($11 == 0) { GM[$6] = GM[$6] + $12; GMumiNum[$6] = GMumiNum[$6] + $13; GMumiFr[$6] = GMumiFr[$6] + $14; \\\n          ID[$6] = 1; } \\\n            else { PM[$6] = PM[$6] + $12 ; PMumiNum[$6] = PMumiNum[$6] + $13; PMumiFr[$6] = PMumiFr[$6] + $14; \\\n            ID[$6] = 1; } \\\n          } \\\n        } \\\n        END{ Total=0; TotalUmiNum=0; TotalUmiFr=0; for (name in ID) \\\n        { Total=Total+GM[name]+PM[name];\n        printf \"%s\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\n\", \\\n        name, GM[name], PM[name], GM[name]+PM[name], GMumiNum[name], PMumiNum[name], GMumiNum[name]+PMumiNum[name], GMumiFr[name], PMumiFr[name], GMumiFr[name]+PMumiFr[name]}; \\\n        print Total > \"totalFeatCnt.txt\"}' > !{name}.count.txt\n    '''\n}",
        "nb_lignes_process": 31,
        "string_script": "    '''\n    tail -n +2 !{seq_cnt} |\\\n        awk -vFS=\"\\t\" -vOFS=\"\\t\" -v CONVFMT=\"%.17g\" -vTF=\"!{params.tailFraction}\" \\\n        'BEGIN{print \"Name\", \"GM\", \"PM\", \"Total\", \"GM.UMInum\", \"PM.UMInum\", \"Total.UMInum\", \"GM.UMIfr\", \"PM.UMIfr\", \"Total.UMIfr\"} \\\n        {if ((length($10) / length($8)) <= TF) \\\n          { if ($11 == 0) { GM[$6] = GM[$6] + $12; GMumiNum[$6] = GMumiNum[$6] + $13; GMumiFr[$6] = GMumiFr[$6] + $14; \\\n          ID[$6] = 1; } \\\n            else { PM[$6] = PM[$6] + $12 ; PMumiNum[$6] = PMumiNum[$6] + $13; PMumiFr[$6] = PMumiFr[$6] + $14; \\\n            ID[$6] = 1; } \\\n          } \\\n        } \\\n        END{ Total=0; TotalUmiNum=0; TotalUmiFr=0; for (name in ID) \\\n        { Total=Total+GM[name]+PM[name];\n        printf \"%s\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\t%.17g\\\\n\", \\\n        name, GM[name], PM[name], GM[name]+PM[name], GMumiNum[name], PMumiNum[name], GMumiNum[name]+PMumiNum[name], GMumiFr[name], PMumiFr[name], GMumiFr[name]+PMumiFr[name]}; \\\n        print Total > \"totalFeatCnt.txt\"}' > !{name}.count.txt\n    '''",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seq_cnt"
        ],
        "nb_inputs": 1,
        "outputs": [
            "count",
            "cnt_totalFeat"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/count\", mode: 'copy', pattern: '*count.txt'"
        ],
        "when": "",
        "stub": ""
    },
    "statTable": {
        "name_process": "statTable",
        "string_process": "\nprocess statTable {\n\n    tag \"Channel: ${name}\"\n\n    input:\n        set name, file(cnt_total), file(cnt_trimmed), file(bam_tailor_cont), file(tailorStat), file(cnt_totalFeat) from cntStat_files\n\n    output:\n        file \"${name}.countStat.txt\" into cnt_stat\n\n\n    script:\n    \"\"\"\n    echo -e \"Name\\tTotal\\tPassed trimming\\tContamination align\\tGenome align\\tTotal reads in feature\" > ${name}.countStat.txt\n    TOTAL=`cat ${cnt_total}`\n    TRIMMED=`cat ${cnt_trimmed}`\n    CONT=`samtools view ${bam_tailor_cont} | cut -f 1 | sort -u | wc -l`\n    TAILOR=`cat ${tailorStat}`\n    FEATURE=`cat ${cnt_totalFeat}`\n\n    echo -e \"${name}\\t\\$TOTAL\\t\\$TRIMMED\\t\\$CONT\\t\\$TAILOR\\t\\$FEATURE\" >> ${name}.countStat.txt\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    echo -e \"Name\\tTotal\\tPassed trimming\\tContamination align\\tGenome align\\tTotal reads in feature\" > ${name}.countStat.txt\n    TOTAL=`cat ${cnt_total}`\n    TRIMMED=`cat ${cnt_trimmed}`\n    CONT=`samtools view ${bam_tailor_cont} | cut -f 1 | sort -u | wc -l`\n    TAILOR=`cat ${tailorStat}`\n    FEATURE=`cat ${cnt_totalFeat}`\n\n    echo -e \"${name}\\t\\$TOTAL\\t\\$TRIMMED\\t\\$CONT\\t\\$TAILOR\\t\\$FEATURE\" >> ${name}.countStat.txt\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cntStat_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cnt_stat"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__smallRNA_nf",
        "directive": [
            "tag \"Channel: ${name}\""
        ],
        "when": "",
        "stub": ""
    }
}