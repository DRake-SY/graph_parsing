{
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: \"*_fastqc.*\"\n\n    conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\"\n    } else {\n        container \"quay.io/biocontainers/fastqc:0.11.9--0\"\n    }\n\n    input:\n    tuple val(sample_id), path(fastq_files)\n\n    output:\n    tuple path(\"*_fastqc.html\"), path(\"*_fastqc.zip\"), emit: REPORTS\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    fastqc ${fastq_files}\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    fastqc ${fastq_files}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "sample_id",
            "fastq_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: \"*_fastqc.*\"",
            "conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\" } else { container \"quay.io/biocontainers/fastqc:0.11.9--0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "stringtie_fpkm_tpm": {
        "name_process": "stringtie_fpkm_tpm",
        "string_process": "\nprocess stringtie_fpkm_tpm {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode\n                                                         \n    conda     (params.enable_conda ? \"bioconda::stringtie=2.1.7\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/stringtie:2.1.7--h978d192_0\"\n    } else {\n        container \"quay.io/biocontainers/stringtie:2.1.7--h978d192_0\"\n    }\n\n    input:\n    tuple val(sample_id), path(stringtie_files)\n\n    output:\n    path(\"*.stringtie.fpkm\"), optional: true, emit: FPKM_FILES\n    path(\"*.stringtie.tpm\"), optional: true, emit: TPM_FILES\n    path(\"*.stringtie.raw\"), optional: true, emit: RAW_FILES\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE publish_fpkm=${params.keep_fpkm}\"\n    echo \"#TRACE publish_tpm=${params.keep_tpm}\"\n    echo \"#TRACE publish_raw=${params.keep_counts}\"\n    echo \"#TRACE ga_lines=`cat *.ga | wc -l`\"\n    echo \"#TRACE gtf_lines=`cat *.gtf | wc -l`\"\n\n    if [[ ${params.keep_fpkm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$8}}' OFS='\\t' ${sample_id}.stringtie.ga > ${sample_id}.stringtie.fpkm\n    fi\n\n    if [[ ${params.keep_tpm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$9}}' OFS='\\t' ${sample_id}.stringtie.ga > ${sample_id}.stringtie.tpm\n    fi\n\n    if [[ ${params.keep_counts} == true ]]; then\n      # Run the prepDE.py script provided by stringtie to get the raw counts.\n      echo -e \"${sample_id}\\t./${sample_id}.stringtie.gtf\" > gtf_files\n      prepDE.py -i gtf_files -g ${sample_id}.raw.pre\n\n      # Reformat the raw file to be the same as the TPM/FKPM files.\n      cat ${sample_id}.raw.pre | \\\n        grep -v gene_id | \\\n        sed \"s/,/\\\\t/g\" > ${sample_id}.stringtie.raw\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 48,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE publish_fpkm=${params.keep_fpkm}\"\n    echo \"#TRACE publish_tpm=${params.keep_tpm}\"\n    echo \"#TRACE publish_raw=${params.keep_counts}\"\n    echo \"#TRACE ga_lines=`cat *.ga | wc -l`\"\n    echo \"#TRACE gtf_lines=`cat *.gtf | wc -l`\"\n\n    if [[ ${params.keep_fpkm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$8}}' OFS='\\t' ${sample_id}.stringtie.ga > ${sample_id}.stringtie.fpkm\n    fi\n\n    if [[ ${params.keep_tpm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$9}}' OFS='\\t' ${sample_id}.stringtie.ga > ${sample_id}.stringtie.tpm\n    fi\n\n    if [[ ${params.keep_counts} == true ]]; then\n      # Run the prepDE.py script provided by stringtie to get the raw counts.\n      echo -e \"${sample_id}\\t./${sample_id}.stringtie.gtf\" > gtf_files\n      prepDE.py -i gtf_files -g ${sample_id}.raw.pre\n\n      # Reformat the raw file to be the same as the TPM/FKPM files.\n      cat ${sample_id}.raw.pre | \\\n        grep -v gene_id | \\\n        sed \"s/,/\\\\t/g\" > ${sample_id}.stringtie.raw\n    fi\n    \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "stringtie_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode",
            "conda (params.enable_conda ? \"bioconda::stringtie=2.1.7\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/stringtie:2.1.7--h978d192_0\" } else { container \"quay.io/biocontainers/stringtie:2.1.7--h978d192_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "kallisto": {
        "name_process": "kallisto",
        "string_process": "\nprocess kallisto {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_kallisto_ga\n\n    conda (params.enable_conda ? \"bioconda::kallisto=0.46.2\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/kallisto:0.46.2--h4f7b962_1\"\n    } else {\n        container \"quay.io/biocontainers/kallisto:0.46.2--h4f7b962_1\"\n    }\n\n    input:\n    tuple val(sample_id), path(fastq_files)\n    path(kallisto_index)\n\n    output:\n    tuple val(sample_id), path(\"*.ga\", type: \"dir\"), emit: GA_FILES\n    tuple val(sample_id), path(\"*.kallisto.log\"), emit: LOGS\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    # Convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # Kallisto will generate an exit code of 1 if no alignments are made. This\n    # isn't an error and should be rewritten to 0 so that Nextflow doesn't end.\n    trap 'if [[ \\$? == 1 ]]; then echo OK; exit 0; fi' EXIT\n\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      echo \"#TRACE Paired End Files Detected\"\n      kallisto quant \\\n        -i ${kallisto_index} \\\n        -b ${params.kallisto_bootstrap_samples} \\\n        -o ${sample_id}.Kallisto.ga \\\n        -t ${task.cpus} \\\n        \\${fastq_files[0]} \\\n        \\${fastq_files[1]} > ${sample_id}.kallisto.log 2>&1\n    else\n      echo \"#TRACE Unpaired End Files Detected\"\n      kallisto quant \\\n        --single \\\n        -l 70 \\\n        -s .0000001 \\\n        -i ${kallisto_index} \\\n        -b ${params.kallisto_bootstrap_samples} \\\n        -o ${sample_id}.Kallisto.ga \\\n        -t ${task.cpus} \\\n        \\${fastq_files[0]} > ${sample_id}.kallisto.log 2>&1\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 54,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    # Convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # Kallisto will generate an exit code of 1 if no alignments are made. This\n    # isn't an error and should be rewritten to 0 so that Nextflow doesn't end.\n    trap 'if [[ \\$? == 1 ]]; then echo OK; exit 0; fi' EXIT\n\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      echo \"#TRACE Paired End Files Detected\"\n      kallisto quant \\\n        -i ${kallisto_index} \\\n        -b ${params.kallisto_bootstrap_samples} \\\n        -o ${sample_id}.Kallisto.ga \\\n        -t ${task.cpus} \\\n        \\${fastq_files[0]} \\\n        \\${fastq_files[1]} > ${sample_id}.kallisto.log 2>&1\n    else\n      echo \"#TRACE Unpaired End Files Detected\"\n      kallisto quant \\\n        --single \\\n        -l 70 \\\n        -s .0000001 \\\n        -i ${kallisto_index} \\\n        -b ${params.kallisto_bootstrap_samples} \\\n        -o ${sample_id}.Kallisto.ga \\\n        -t ${task.cpus} \\\n        \\${fastq_files[0]} > ${sample_id}.kallisto.log 2>&1\n    fi\n    \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "TRAP",
            "kallisto"
        ],
        "tools_url": [
            "https://bio.tools/trap",
            "https://bio.tools/kallisto"
        ],
        "tools_dico": [
            {
                "name": "TRAP",
                "uri": "https://bio.tools/trap",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0157",
                            "term": "Sequence composition, complexity and repeats"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0379",
                                    "term": "Repeat sequence detection"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Program that provides a unified set of analyses for the selection, classification, quantification and automated annotation of tandemly repeated sequences.",
                "homepage": "http://www.coccidia.icb.usp.br/trap/index.html"
            },
            {
                "name": "kallisto",
                "uri": "https://bio.tools/kallisto",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0314",
                                    "term": "Gene expression profiling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0314",
                                    "term": "Functional profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0314",
                                    "term": "Gene expression profile construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0314",
                                    "term": "Feature expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0314",
                                    "term": "Gene transcription profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0314",
                                    "term": "Gene expression quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0314",
                                    "term": "Gene expression profile generation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A program for quantifying abundances of transcripts from RNA-Seq data, or more generally of target sequences using high-throughput sequencing reads. It is based on the novel idea of pseudoalignment for rapidly determining the compatibility of reads with targets, without the need for alignment.",
                "homepage": "https://pachterlab.github.io/kallisto/about.html"
            }
        ],
        "inputs": [
            "sample_id",
            "fastq_files",
            "kallisto_index"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_kallisto_ga",
            "conda (params.enable_conda ? \"bioconda::kallisto=0.46.2\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/kallisto:0.46.2--h4f7b962_1\" } else { container \"quay.io/biocontainers/kallisto:0.46.2--h4f7b962_1\" }"
        ],
        "when": "",
        "stub": ""
    },
    "clean_work_files": {
        "name_process": "clean_work_files",
        "string_process": "\nprocess clean_work_files {\n    tag { sample_id }\n    label \"local\"\n\n    input:\n    tuple val(sample_id), val(files)\n\n    output:\n    val(1), emit: IS_CLEAN\n\n    script:\n    \"\"\"\n    clean_work_files.sh \"${files.join(\" \")}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    clean_work_files.sh \"${files.join(\" \")}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "label \"local\""
        ],
        "when": "",
        "stub": ""
    },
    "retrieve_sra_metadata": {
        "name_process": "retrieve_sra_metadata",
        "string_process": "\nprocess retrieve_sra_metadata {\n  publishDir \"${params.outdir}/reports\", mode: params.publish_dir_mode\n  container \"systemsgenetics/gemmaker:2.1.0\"\n\n  input:\n  file(sras)\n\n  output:\n  path(\"SRA_run2exp.tsv\"), emit: SRR2SRX\n  path(\"failed_runs.metadata.txt\"), emit: FAILED_RUNS\n\n  script:\n  \"\"\"\n  echo \"#TRACE n_remote_run_ids=`cat ${sras} | wc -l`\"\n\n  # Remove the 'path:' prefix. This was added to prevent\n  # Nextflow from recoginzing the path and noticing the work\n  # directory changed and trying to re-run this process even\n  # if it succeeded.\n  workdir=`echo ${params.workDirParent}/${params.workDirName}/GEMmaker | sed 's/path://'`\n\n  retrieve_sra_metadata.py \\\n      --run_id_file ${sras} \\\n      --meta_dir \"\\$workdir\" \\\n      --out_file SRA_run2exp.tsv \\\n       ${params.skip_samples ? \"--skip_file ${file(params.skip_samples)}\" : \"\"}\n  \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "  \"\"\"\n  echo \"#TRACE n_remote_run_ids=`cat ${sras} | wc -l`\"\n\n  # Remove the 'path:' prefix. This was added to prevent\n  # Nextflow from recoginzing the path and noticing the work\n  # directory changed and trying to re-run this process even\n  # if it succeeded.\n  workdir=`echo ${params.workDirParent}/${params.workDirName}/GEMmaker | sed 's/path://'`\n\n  retrieve_sra_metadata.py \\\n      --run_id_file ${sras} \\\n      --meta_dir \"\\$workdir\" \\\n      --out_file SRA_run2exp.tsv \\\n       ${params.skip_samples ? \"--skip_file ${file(params.skip_samples)}\" : \"\"}\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sras"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: params.publish_dir_mode",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "salmon": {
        "name_process": "salmon",
        "string_process": "\nprocess salmon {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_salmon_ga\n\n    conda (params.enable_conda ? 'bioconda::salmon=1.5.2' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/salmon:1.5.2--h84f40af_0\"\n    } else {\n        container \"quay.io/biocontainers/salmon:1.5.2--h84f40af_0\"\n    }\n\n    input:\n    tuple val(sample_id), path(fastq_files)\n    path(salmon_index)\n\n    output:\n    tuple val(sample_id), path(\"*.ga\", type: \"dir\"), emit: GA_FILES\n    tuple val(sample_id), path(\"${sample_id}.Salmon_multiqc\", type: \"dir\"), emit: LOGS\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      salmon quant \\\n        -i ${salmon_index} \\\n        -l A \\\n        -1 \\${fastq_files[0]} \\\n        -2 \\${fastq_files[1]} \\\n        -p ${task.cpus} \\\n        -o ${sample_id}.Salmon.ga \\\n        --minAssignedFrags 1 > ${sample_id}.salmon.log 2>&1\n    else\n      salmon quant \\\n        -i ${salmon_index} \\\n        -l A \\\n        -r \\${fastq_files[0]} \\\n        -p ${task.cpus} \\\n        -o ${sample_id}.Salmon.ga \\\n        --minAssignedFrags 1 > ${sample_id}.salmon.log 2>&1\n    fi\n\n    # Copy these files for MultiQC reporting\n    mkdir -p ./${sample_id}.Salmon_multiqc/aux_info\n    mkdir -p ./${sample_id}.Salmon_multiqc/libParams\n    cp ${sample_id}.Salmon.ga/aux_info/meta_info.json ${sample_id}.Salmon_multiqc/aux_info/meta_info.json\n    cp ${sample_id}.Salmon.ga/libParams/flenDist.txt ${sample_id}.Salmon_multiqc/libParams/flenDist.txt\n    \"\"\"\n}",
        "nb_lignes_process": 53,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      salmon quant \\\n        -i ${salmon_index} \\\n        -l A \\\n        -1 \\${fastq_files[0]} \\\n        -2 \\${fastq_files[1]} \\\n        -p ${task.cpus} \\\n        -o ${sample_id}.Salmon.ga \\\n        --minAssignedFrags 1 > ${sample_id}.salmon.log 2>&1\n    else\n      salmon quant \\\n        -i ${salmon_index} \\\n        -l A \\\n        -r \\${fastq_files[0]} \\\n        -p ${task.cpus} \\\n        -o ${sample_id}.Salmon.ga \\\n        --minAssignedFrags 1 > ${sample_id}.salmon.log 2>&1\n    fi\n\n    # Copy these files for MultiQC reporting\n    mkdir -p ./${sample_id}.Salmon_multiqc/aux_info\n    mkdir -p ./${sample_id}.Salmon_multiqc/libParams\n    cp ${sample_id}.Salmon.ga/aux_info/meta_info.json ${sample_id}.Salmon_multiqc/aux_info/meta_info.json\n    cp ${sample_id}.Salmon.ga/libParams/flenDist.txt ${sample_id}.Salmon_multiqc/libParams/flenDist.txt\n    \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "Salmon"
        ],
        "tools_url": [
            "https://bio.tools/salmon"
        ],
        "tools_dico": [
            {
                "name": "Salmon",
                "uri": "https://bio.tools/salmon",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3496",
                                "term": "RNA sequence (raw)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2093",
                                "term": "Data reference"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "A tool for transcript expression quantification from RNA-seq data",
                "homepage": "https://github.com/COMBINE-lab/salmon"
            }
        ],
        "inputs": [
            "sample_id",
            "fastq_files",
            "salmon_index"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_salmon_ga",
            "conda (params.enable_conda ? 'bioconda::salmon=1.5.2' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/salmon:1.5.2--h84f40af_0\" } else { container \"quay.io/biocontainers/salmon:1.5.2--h84f40af_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "fastq_dump": {
        "name_process": "fastq_dump",
        "string_process": "\nprocess fastq_dump {\n    tag { sample_id }\n    publishDir params.outdir, mode: params.publish_dir_mode, pattern: params.publish_pattern_fastq_dump, saveAs: { \"Samples/${sample_id}/${it}\" }\n    publishDir params.outdir, mode: params.publish_dir_mode, pattern: '*.failed_runs.fastq-dump.txt', saveAs: { \"Samples/${sample_id}/${it}\" }\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    tuple val(sample_id), path(sra_files)\n\n    output:\n    tuple val(sample_id), path(\"*.fastq\"), optional: true, emit: FASTQ_FILES\n    tuple val(sample_id), path(\"sample_failed\"), optional: true, emit: FAILED_SAMPLES\n    tuple val(sample_id), path(\"*.failed_runs.fastq-dump.txt\"), emit: FAILED_RUNS\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE sra_bytes=`stat -Lc '%s' *.sra | awk '{sum += \\$1} END {print sum}'`\"\n\n    sra2fastq.py --sample ${sample_id} --sra_files ${sra_files}\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE sra_bytes=`stat -Lc '%s' *.sra | awk '{sum += \\$1} END {print sum}'`\"\n\n    sra2fastq.py --sample ${sample_id} --sra_files ${sra_files}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "sra_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir params.outdir, mode: params.publish_dir_mode, pattern: params.publish_pattern_fastq_dump, saveAs: { \"Samples/${sample_id}/${it}\" }",
            "publishDir params.outdir, mode: params.publish_dir_mode, pattern: '*.failed_runs.fastq-dump.txt', saveAs: { \"Samples/${sample_id}/${it}\" }",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "clean_work_dirs": {
        "name_process": "clean_work_dirs",
        "string_process": "\nprocess clean_work_dirs {\n    tag { sample_id }\n    label \"local\"\n\n    input:\n    tuple val(sample_id), val(directory)\n\n    output:\n    val(1), emit: IS_CLEAN\n\n    script:\n    \"\"\"\n    for dir in ${directory}; do\n      if [ -e \\$dir ]; then\n        echo \"Cleaning: \\$dir\"\n        files=`find \\$dir -type  f `\n\n        echo \"Files to delete: \\$files\"\n        clean_work_files.sh \"\\$files\" \"null\"\n      fi\n    done\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    for dir in ${directory}; do\n      if [ -e \\$dir ]; then\n        echo \"Cleaning: \\$dir\"\n        files=`find \\$dir -type  f `\n\n        echo \"Files to delete: \\$files\"\n        clean_work_files.sh \"\\$files\" \"null\"\n      fi\n    done\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "directory"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "label \"local\""
        ],
        "when": "",
        "stub": ""
    },
    "samtools_sort": {
        "name_process": "samtools_sort",
        "string_process": "\nprocess samtools_sort {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_samtools_sort\n\n    conda (params.enable_conda ? \"bioconda::samtools=1.14\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.14--hb421002_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.14--hb421002_0\"\n    }\n\n    input:\n    tuple val(sample_id), path(sam_file)\n\n    output:\n    tuple val(sample_id), path(\"*sorted.bam\"), emit: BAM_FILES\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    # echo \"#TRACE sam_lines=`cat *.sam | wc -l`\"\n\n    samtools sort \\\n        -o ${sample_id}.sorted.bam \\\n        -O bam \\\n        -T temp \\\n        ${sam_file}\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    # echo \"#TRACE sam_lines=`cat *.sam | wc -l`\"\n\n    samtools sort \\\n        -o ${sample_id}.sorted.bam \\\n        -O bam \\\n        -T temp \\\n        ${sam_file}\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_id",
            "sam_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_samtools_sort",
            "conda (params.enable_conda ? \"bioconda::samtools=1.14\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.14--hb421002_0\" } else { container \"quay.io/biocontainers/samtools:1.14--hb421002_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "create_gem": {
        "name_process": "create_gem",
        "string_process": "\nprocess create_gem {\n    publishDir \"${params.outdir}/GEMs\", mode: params.publish_dir_mode\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    val(signal)\n    path(input_files)\n\n    output:\n    path(\"*.GEM.*.txt\"), emit: GEM_FILES\n\n    script:\n    \"\"\"\n    echo \"#TRACE publish_fpkm=${params.publish_fpkm}\"\n    echo \"#TRACE publish_tpm=${params.publish_tpm}\"\n    echo \"#TRACE publish_raw=${params.publish_raw}\"\n    #echo \"#TRACE fpkm_lines=`cat ${params.outdir}/*.fpkm 2> /dev/null  | wc -l`\"\n    #echo \"#TRACE tpm_lines=`cat ${params.outdir}/*.tpm 2> /dev/null | wc -l`\"\n    #echo \"#TRACE raw_lines=`cat ${params.outdir}/*.raw 2> /dev/null | wc -l`\"\n\n    # FPKM format is only generated if hisat2/star is used\n    if [[ ${params.publish_fpkm} == true ]]; then\n      create-gem.py \\\n        --sources . \\\n        --prefix GEMmaker \\\n        --type FPKM\n    fi;\n\n    if [[ ${params.publish_raw} == true ]]; then\n      create-gem.py \\\n        --sources . \\\n        --prefix GEMmaker \\\n        --type raw\n    fi\n\n    if [[ ${params.publish_tpm} == true ]]; then\n      create-gem.py \\\n        --sources . \\\n        --prefix GEMmaker \\\n        --type TPM\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 42,
        "string_script": "    \"\"\"\n    echo \"#TRACE publish_fpkm=${params.publish_fpkm}\"\n    echo \"#TRACE publish_tpm=${params.publish_tpm}\"\n    echo \"#TRACE publish_raw=${params.publish_raw}\"\n    #echo \"#TRACE fpkm_lines=`cat ${params.outdir}/*.fpkm 2> /dev/null  | wc -l`\"\n    #echo \"#TRACE tpm_lines=`cat ${params.outdir}/*.tpm 2> /dev/null | wc -l`\"\n    #echo \"#TRACE raw_lines=`cat ${params.outdir}/*.raw 2> /dev/null | wc -l`\"\n\n    # FPKM format is only generated if hisat2/star is used\n    if [[ ${params.publish_fpkm} == true ]]; then\n      create-gem.py \\\n        --sources . \\\n        --prefix GEMmaker \\\n        --type FPKM\n    fi;\n\n    if [[ ${params.publish_raw} == true ]]; then\n      create-gem.py \\\n        --sources . \\\n        --prefix GEMmaker \\\n        --type raw\n    fi\n\n    if [[ ${params.publish_tpm} == true ]]; then\n      create-gem.py \\\n        --sources . \\\n        --prefix GEMmaker \\\n        --type TPM\n    fi\n    \"\"\"",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "signal",
            "input_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "publishDir \"${params.outdir}/GEMs\", mode: params.publish_dir_mode",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "GET_SOFTWARE_VERSIONS": {
        "name_process": "GET_SOFTWARE_VERSIONS",
        "string_process": "\nprocess GET_SOFTWARE_VERSIONS {\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/python:3.8.3\"\n    } else {\n        container \"quay.io/biocontainers/python:3.8.3\"\n    }\n\n    cache false\n\n    input:\n    path versions\n\n    output:\n    path \"software_versions.tsv\"     , emit: tsv\n    path 'software_versions_mqc.yaml', emit: yaml\n\n    script:                                                                              \n    \"\"\"\n    echo $workflow.manifest.version > pipeline.version.txt\n    echo $workflow.nextflow.version > nextflow.version.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > pipeline.version.txt\n    echo $workflow.nextflow.version > nextflow.version.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "versions"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/python:3.8.3\" } else { container \"quay.io/biocontainers/python:3.8.3\" }",
            "cache false"
        ],
        "when": "",
        "stub": ""
    },
    "download_runs": {
        "name_process": "download_runs",
        "string_process": "\nprocess download_runs {\n    tag { sample_id }\n    publishDir params.outdir, mode: params.publish_dir_mode, pattern: '*.failed_runs.download.txt', saveAs: { \"Samples/${sample_id}/${it}\" }\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    tuple val(sample_id), val(run_ids), val(type)\n\n    output:\n    tuple val(sample_id), path(\"*.sra\"), optional: true, emit: SRA_FILES\n    tuple val(sample_id), path(\"sample_failed\"), optional: true, emit: FAILED_SAMPLES\n    tuple val(sample_id), path(\"*.failed_runs.download.txt\"), emit: FAILED_RUNS\n\n    script:\n    \"\"\"\n    # Remove the 'path:' prefix. This was added to prevent\n    # Nextflow from recoginzing the path and noticing the work\n    # directory changed and trying to re-run this process even\n    # if it succeeded.\n    workdir=`echo ${params.workDirParent}/${params.workDirName}/GEMmaker | sed 's/path://'`\n\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_remote_run_ids=${run_ids.tokenize(\" \").size()}\"\n    echo \"#TRACE n_spots=`retrieve_sra_spots.py \\$workdir ${sample_id}`\"\n\n    retrieve_sra.py --sample ${sample_id} --run_ids ${run_ids} --akey \\${ASPERA_KEY}\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    # Remove the 'path:' prefix. This was added to prevent\n    # Nextflow from recoginzing the path and noticing the work\n    # directory changed and trying to re-run this process even\n    # if it succeeded.\n    workdir=`echo ${params.workDirParent}/${params.workDirName}/GEMmaker | sed 's/path://'`\n\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_remote_run_ids=${run_ids.tokenize(\" \").size()}\"\n    echo \"#TRACE n_spots=`retrieve_sra_spots.py \\$workdir ${sample_id}`\"\n\n    retrieve_sra.py --sample ${sample_id} --run_ids ${run_ids} --akey \\${ASPERA_KEY}\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "run_ids",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir params.outdir, mode: params.publish_dir_mode, pattern: '*.failed_runs.download.txt', saveAs: { \"Samples/${sample_id}/${it}\" }",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "hisat2": {
        "name_process": "hisat2",
        "string_process": "\nprocess hisat2 {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: \"*.log\"\n\n    conda (params.enable_conda ? \"bioconda::hisat2=2.2.0 bioconda::samtools=1.10\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-a97e90b3b802d1da3d6958e0867610c718cb5eb1:2880dd9d8ad0a7b221d4eacda9a818e92983128d-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-a97e90b3b802d1da3d6958e0867610c718cb5eb1:2880dd9d8ad0a7b221d4eacda9a818e92983128d-0\"\n    }\n\n    input:\n    tuple val(sample_id), path(fastq_files)\n    path(indexes)\n\n    output:\n    tuple val(sample_id), path(\"*.sam\"), emit: SAM_FILES\n    tuple val(sample_id), path(\"*.sam.log\"), emit: LOGS\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_cpus=${task.cpus}\"\n    echo \"#TRACE trimmed_fastq_lines=`cat *.fastq | wc -l`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # we don't know the order the files will come so we have\n    # to find the paired and non paired files.\n    fq_1p=\"\"\n    fq_2p=\"\"\n    fq_1u=\"\"\n    fq_2u=\"\"\n    for f in \"\\${fastq_files[@]}\"; do\n        echo \\$f\n        if [[ \\$f =~ _1p_trim.fastq ]]; then\n            fq_1p=\\$f\n        elif [[ \\$f =~ _2p_trim.fastq ]]; then\n            fq_2p=\\$f\n        elif [[ \\$f =~ _1u_trim.fastq ]]; then\n            fq_1u=\\$f\n        elif [[ \\$f =~ _2u_trim.fastq ]]; then\n            fq_2u=\\$f\n        fi\n    done;\n\n    if [ \\${#fastq_files[@]} == 4 ]; then\n      hisat2 \\\n        -x ${params.hisat2_base_name} \\\n        --no-spliced-alignment \\\n        -q \\\n        -1 \\${fq_1p} \\\n        -2 \\${fq_2p} \\\n        -U \\${fq_1u},\\${fq_2u} \\\n        -S ${sample_id}.sam \\\n        -t \\\n        -p ${task.cpus} \\\n        --un ${sample_id}_un.fastq \\\n        --dta-cufflinks \\\n        --new-summary \\\n        --summary-file ${sample_id}.sam.log\n    else\n      hisat2 \\\n        -x ${params.hisat2_base_name} \\\n        --no-spliced-alignment \\\n        -q \\\n        -U \\${fq_1u} \\\n        -S ${sample_id}.sam \\\n        -t \\\n        -p ${task.cpus} \\\n        --un ${sample_id}_un.fastq \\\n        --dta-cufflinks \\\n        --new-summary \\\n        --summary-file ${sample_id}.sam.log\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 78,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_cpus=${task.cpus}\"\n    echo \"#TRACE trimmed_fastq_lines=`cat *.fastq | wc -l`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # we don't know the order the files will come so we have\n    # to find the paired and non paired files.\n    fq_1p=\"\"\n    fq_2p=\"\"\n    fq_1u=\"\"\n    fq_2u=\"\"\n    for f in \"\\${fastq_files[@]}\"; do\n        echo \\$f\n        if [[ \\$f =~ _1p_trim.fastq ]]; then\n            fq_1p=\\$f\n        elif [[ \\$f =~ _2p_trim.fastq ]]; then\n            fq_2p=\\$f\n        elif [[ \\$f =~ _1u_trim.fastq ]]; then\n            fq_1u=\\$f\n        elif [[ \\$f =~ _2u_trim.fastq ]]; then\n            fq_2u=\\$f\n        fi\n    done;\n\n    if [ \\${#fastq_files[@]} == 4 ]; then\n      hisat2 \\\n        -x ${params.hisat2_base_name} \\\n        --no-spliced-alignment \\\n        -q \\\n        -1 \\${fq_1p} \\\n        -2 \\${fq_2p} \\\n        -U \\${fq_1u},\\${fq_2u} \\\n        -S ${sample_id}.sam \\\n        -t \\\n        -p ${task.cpus} \\\n        --un ${sample_id}_un.fastq \\\n        --dta-cufflinks \\\n        --new-summary \\\n        --summary-file ${sample_id}.sam.log\n    else\n      hisat2 \\\n        -x ${params.hisat2_base_name} \\\n        --no-spliced-alignment \\\n        -q \\\n        -U \\${fq_1u} \\\n        -S ${sample_id}.sam \\\n        -t \\\n        -p ${task.cpus} \\\n        --un ${sample_id}_un.fastq \\\n        --dta-cufflinks \\\n        --new-summary \\\n        --summary-file ${sample_id}.sam.log\n    fi\n    \"\"\"",
        "nb_lignes_script": 56,
        "language_script": "bash",
        "tools": [
            "HISAT2"
        ],
        "tools_url": [
            "https://bio.tools/hisat2"
        ],
        "tools_dico": [
            {
                "name": "HISAT2",
                "uri": "https://bio.tools/hisat2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).",
                "homepage": "https://ccb.jhu.edu/software/hisat2/index.shtml"
            }
        ],
        "inputs": [
            "sample_id",
            "fastq_files",
            "indexes"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: \"*.log\"",
            "conda (params.enable_conda ? \"bioconda::hisat2=2.2.0 bioconda::samtools=1.10\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-a97e90b3b802d1da3d6958e0867610c718cb5eb1:2880dd9d8ad0a7b221d4eacda9a818e92983128d-0\" } else { container \"quay.io/biocontainers/mulled-v2-a97e90b3b802d1da3d6958e0867610c718cb5eb1:2880dd9d8ad0a7b221d4eacda9a818e92983128d-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "samtools_merge": {
        "name_process": "samtools_merge",
        "string_process": "\nprocess samtools_merge {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_samtools_merge\n\n    conda (params.enable_conda ? \"bioconda::samtools=1.14\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.14--hb421002_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.14--hb421002_0\"\n    }\n\n    input:\n    tuple val(sample_id), path(sam_files)\n\n    output:\n    tuple val(sample_id), path(\"*.bam\"), emit: BAM_FILES\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE sam_lines=`cat *.sam | wc -l`\"\n\n    samtools merge \\\n        -o ${sample_id}.bam \\\n        ${sam_files}\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE sam_lines=`cat *.sam | wc -l`\"\n\n    samtools merge \\\n        -o ${sample_id}.bam \\\n        ${sam_files}\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_id",
            "sam_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_samtools_merge",
            "conda (params.enable_conda ? \"bioconda::samtools=1.14\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.14--hb421002_0\" } else { container \"quay.io/biocontainers/samtools:1.14--hb421002_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "star": {
        "name_process": "star",
        "string_process": "\nprocess star {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: \"*.log\"\n\n    conda (params.enable_conda ? \"bioconda::star=2.7.9a\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n      container \"https://depot.galaxyproject.org/singularity/star:2.7.9a--h9ee0642_0\"\n    } else {\n      container \"quay.io/biocontainers/star:2.7.9a--h9ee0642_0\"\n    }\n\n    input:\n    tuple val(sample_id), path(fastq_files)\n    path(star_index)\n\n    output:\n    tuple val(sample_id), path(\"*.sam\"), emit: SAM_FILES\n    tuple val(sample_id), path(\"*Log.final.out\"), emit: LOGS\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_cpus=${task.cpus}\"\n    echo \"#TRACE trimmed_fastq_lines=`cat *.fastq | wc -l`\"\n    echo \"#TRACE index_bytes=`stat -Lc '%s' ${star_index} | awk '{sum += \\$1} END {print sum}'`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # we don't know the order the files will come so we have\n    # to find the paired and non paired files.\n    fq_1p=\"\"\n    fq_2p=\"\"\n    fq_1u=\"\"\n    fq_2u=\"\"\n    for f in \"\\${fastq_files[@]}\"; do\n        echo \\$f\n        if [[ \\$f =~ _1p_trim.fastq ]]; then\n            fq_1p=\\$f\n        elif [[ \\$f =~ _2p_trim.fastq ]]; then\n            fq_2p=\\$f\n        elif [[ \\$f =~ _1u_trim.fastq ]]; then\n            fq_1u=\\$f\n        elif [[ \\$f =~ _2u_trim.fastq ]]; then\n            fq_2u=\\$f\n        fi\n    done;\n\n    if [ \\${#fastq_files[@]} == 4 ]; then\n      # First align the paired.\n      STAR \\\n        --runThreadN ${task.cpus} \\\n        --genomeDir ${star_index} \\\n        --outFileNamePrefix ${sample_id}.trimmed_paired \\\n        --readFilesIn \\${fq_1p} \\${fq_2p} > ${sample_id}.trimmed_paired.star.log 2>&1\n\n      # Now aligned the non-paired\n      STAR \\\n        --runThreadN ${task.cpus} \\\n        --genomeDir ${star_index} \\\n        --outFileNamePrefix ${sample_id}.trimmed_single \\\n        --readFilesIn \\${fq_1u},\\${fq_2u} > ${sample_id}.trimmed_single.star.log 2>&1\n\n    else\n        STAR \\\n            --runThreadN ${task.cpus} \\\n            --genomeDir ${star_index} \\\n            --outFileNamePrefix ${sample_id}.trimmed \\\n            --readFilesIn \\${fq_1u} > ${sample_id}.trimmed.star.log 2>&1\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 72,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_cpus=${task.cpus}\"\n    echo \"#TRACE trimmed_fastq_lines=`cat *.fastq | wc -l`\"\n    echo \"#TRACE index_bytes=`stat -Lc '%s' ${star_index} | awk '{sum += \\$1} END {print sum}'`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # we don't know the order the files will come so we have\n    # to find the paired and non paired files.\n    fq_1p=\"\"\n    fq_2p=\"\"\n    fq_1u=\"\"\n    fq_2u=\"\"\n    for f in \"\\${fastq_files[@]}\"; do\n        echo \\$f\n        if [[ \\$f =~ _1p_trim.fastq ]]; then\n            fq_1p=\\$f\n        elif [[ \\$f =~ _2p_trim.fastq ]]; then\n            fq_2p=\\$f\n        elif [[ \\$f =~ _1u_trim.fastq ]]; then\n            fq_1u=\\$f\n        elif [[ \\$f =~ _2u_trim.fastq ]]; then\n            fq_2u=\\$f\n        fi\n    done;\n\n    if [ \\${#fastq_files[@]} == 4 ]; then\n      # First align the paired.\n      STAR \\\n        --runThreadN ${task.cpus} \\\n        --genomeDir ${star_index} \\\n        --outFileNamePrefix ${sample_id}.trimmed_paired \\\n        --readFilesIn \\${fq_1p} \\${fq_2p} > ${sample_id}.trimmed_paired.star.log 2>&1\n\n      # Now aligned the non-paired\n      STAR \\\n        --runThreadN ${task.cpus} \\\n        --genomeDir ${star_index} \\\n        --outFileNamePrefix ${sample_id}.trimmed_single \\\n        --readFilesIn \\${fq_1u},\\${fq_2u} > ${sample_id}.trimmed_single.star.log 2>&1\n\n    else\n        STAR \\\n            --runThreadN ${task.cpus} \\\n            --genomeDir ${star_index} \\\n            --outFileNamePrefix ${sample_id}.trimmed \\\n            --readFilesIn \\${fq_1u} > ${sample_id}.trimmed.star.log 2>&1\n    fi\n    \"\"\"",
        "nb_lignes_script": 50,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "sample_id",
            "fastq_files",
            "star_index"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: \"*.log\"",
            "conda (params.enable_conda ? \"bioconda::star=2.7.9a\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/star:2.7.9a--h9ee0642_0\" } else { container \"quay.io/biocontainers/star:2.7.9a--h9ee0642_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc {\n    publishDir \"${params.outdir}/reports\", mode: params.publish_dir_mode\n\n    conda (params.enable_conda ? 'bioconda::multiqc=1.11' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\"\n    }\n\n    input:\n    val(signal)\n    path(config_file)\n    path(custom_logo)\n    path(input_files)\n\n    output:\n    path(\"multiqc_data\"), emit: MULTIQC_DATA\n    path(\"multiqc_report.html\"), emit: MULTIQC_REPORT\n\n    script:\n    \"\"\"\n    multiqc --config ${config_file} ./\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    multiqc --config ${config_file} ./\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "signal",
            "config_file",
            "custom_logo",
            "input_files"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: params.publish_dir_mode",
            "conda (params.enable_conda ? 'bioconda::multiqc=1.11' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0\" } else { container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "fastq_merge": {
        "name_process": "fastq_merge",
        "string_process": "\nprocess fastq_merge {\n    tag { sample_id }\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    tuple val(sample_id), path(fastq_files)\n\n    output:\n    tuple val(sample_id), path(\"${sample_id}_?.fastq\"), emit: FASTQ_FILES\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    merge_fastq.py --fastq_files ${fastq_files.join(\" \")} --out_prefix ${sample_id}\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    merge_fastq.py --fastq_files ${fastq_files.join(\" \")} --out_prefix ${sample_id}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "fastq_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "salmon_tpm": {
        "name_process": "salmon_tpm",
        "string_process": "\nprocess salmon_tpm {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    tuple val(sample_id), path(ga_file)\n\n    output:\n    path(\"*.Salmon.tpm\"), optional: true, emit: TPM_FILES\n    path(\"*.Salmon.raw\"), optional: true, emit: RAW_FILES\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n\n    if [[ ${params.salmon_keep_tpm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$4}}' OFS='\\t' ${sample_id}.Salmon.ga/quant.sf > ${sample_id}.Salmon.tpm\n    fi\n\n    if [[ ${params.salmon_keep_counts} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$5}}' OFS='\\t' ${sample_id}.Salmon.ga/quant.sf > ${sample_id}.Salmon.raw\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n\n    if [[ ${params.salmon_keep_tpm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$4}}' OFS='\\t' ${sample_id}.Salmon.ga/quant.sf > ${sample_id}.Salmon.tpm\n    fi\n\n    if [[ ${params.salmon_keep_counts} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$5}}' OFS='\\t' ${sample_id}.Salmon.ga/quant.sf > ${sample_id}.Salmon.raw\n    fi\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "ga_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "trimmomatic": {
        "name_process": "trimmomatic",
        "string_process": "\nprocess trimmomatic {\n    tag { sample_id }\n    label \"process_medium\"\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_trimmomatic\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    tuple val(sample_id), path(fastq_files)\n    path(fasta_adapter)\n\n    output:\n    tuple val(sample_id), path(\"*_trim.fastq\"), emit: FASTQ_FILES\n    tuple val(sample_id), path(\"*.trim.log\"), emit: LOGS\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_cpus=${task.cpus}\"\n    echo \"#TRACE minlen=${params.trimmomatic_MINLEN}\"\n    echo \"#TRACE leading=${params.trimmomatic_LEADING}\"\n    echo \"#TRACE trailing=${params.trimmomatic_TRAILING}\"\n    echo \"#TRACE slidingwindow=${params.trimmomatic_SLIDINGWINDOW}\"\n    echo \"#TRACE fasta_lines=`cat ${fasta_adapter} | wc -l`\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # This script calculates average length of fastq files.\n    total=0\n    # This if statement checks if the data is single or paired data, and checks length accordingly\n    # This script returns 1 number, which can be used for the minlen in trimmomatic\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      for fastq in \"\\${fastq_files[@]}\"; do\n        cat=\"cat \\$fastq\"\n        if [[ \\$fastq =~ .gz\\$ ]]; then\n          cat=\"zcat \\$fastq\"\n        fi\n        a=`\\$cat | awk 'NR%4 == 2 {lengths[length(\\$0)]++} END {for (l in lengths) {print l, lengths[l]}}' \\\n        | sort \\\n        | awk '{ print \\$0, \\$1*\\$2}' \\\n        | awk -v var=\"${params.trimmomatic_MINLEN}\" '{ SUM += \\$3 } { SUM2 += \\$2 } END { printf(\"%.0f\", SUM / SUM2 * var)} '`\n      total=(\\$a + \\$total)\n      done\n      total=( \\$total / 2 )\n      minlen=\\$total\n    else\n      cat=\"cat \\${fastq_files[0]}\"\n      if [[ \\${fastq_files[0]} =~ .gz\\$ ]]; then\n        cat=\"zcat \\${fastq_files[0]}\"\n      fi\n      minlen=`\\$cat | awk 'NR%4 == 2 {lengths[length(\\$0)]++} END {for (l in lengths) {print l, lengths[l]}}'  \\\n        | sort \\\n        | awk '{ print \\$0, \\$1*\\$2}' \\\n        | awk -v var=\"${params.trimmomatic_MINLEN}\" '{ SUM += \\$3 } { SUM2 += \\$2 } END { printf(\"%.0f\", SUM / SUM2 * var)} '`\n    fi\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      trimmomatic \\\n        PE \\\n        -threads ${task.cpus} \\\n        \\${fastq_files[0]} \\\n        \\${fastq_files[1]} \\\n        ${sample_id}_1p_trim.fastq \\\n        ${sample_id}_1u_trim.fastq \\\n        ${sample_id}_2p_trim.fastq \\\n        ${sample_id}_2u_trim.fastq \\\n        ILLUMINACLIP:${fasta_adapter}:2:40:15 \\\n        LEADING:${params.trimmomatic_LEADING} \\\n        TRAILING:${params.trimmomatic_TRAILING} \\\n        SLIDINGWINDOW:${params.trimmomatic_SLIDINGWINDOW} \\\n        MINLEN:\"\\$minlen\" > ${sample_id}.trim.log 2>&1\n    else\n      trimmomatic \\\n        SE \\\n        -threads ${task.cpus} \\\n        \\${fastq_files[0]} \\\n        ${sample_id}_1u_trim.fastq \\\n        ILLUMINACLIP:${fasta_adapter}:2:40:15 \\\n        LEADING:${params.trimmomatic_LEADING} \\\n        TRAILING:${params.trimmomatic_TRAILING} \\\n        SLIDINGWINDOW:${params.trimmomatic_SLIDINGWINDOW} \\\n        MINLEN:\"\\$minlen\" > ${sample_id}.trim.log 2>&1\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 85,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE n_cpus=${task.cpus}\"\n    echo \"#TRACE minlen=${params.trimmomatic_MINLEN}\"\n    echo \"#TRACE leading=${params.trimmomatic_LEADING}\"\n    echo \"#TRACE trailing=${params.trimmomatic_TRAILING}\"\n    echo \"#TRACE slidingwindow=${params.trimmomatic_SLIDINGWINDOW}\"\n    echo \"#TRACE fasta_lines=`cat ${fasta_adapter} | wc -l`\"\n    echo \"#TRACE fastq_lines=`cat *.fastq | wc -l`\"\n\n    # convert the incoming FASTQ file list to an array\n    fastq_files=(${fastq_files})\n\n    # This script calculates average length of fastq files.\n    total=0\n    # This if statement checks if the data is single or paired data, and checks length accordingly\n    # This script returns 1 number, which can be used for the minlen in trimmomatic\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      for fastq in \"\\${fastq_files[@]}\"; do\n        cat=\"cat \\$fastq\"\n        if [[ \\$fastq =~ .gz\\$ ]]; then\n          cat=\"zcat \\$fastq\"\n        fi\n        a=`\\$cat | awk 'NR%4 == 2 {lengths[length(\\$0)]++} END {for (l in lengths) {print l, lengths[l]}}' \\\n        | sort \\\n        | awk '{ print \\$0, \\$1*\\$2}' \\\n        | awk -v var=\"${params.trimmomatic_MINLEN}\" '{ SUM += \\$3 } { SUM2 += \\$2 } END { printf(\"%.0f\", SUM / SUM2 * var)} '`\n      total=(\\$a + \\$total)\n      done\n      total=( \\$total / 2 )\n      minlen=\\$total\n    else\n      cat=\"cat \\${fastq_files[0]}\"\n      if [[ \\${fastq_files[0]} =~ .gz\\$ ]]; then\n        cat=\"zcat \\${fastq_files[0]}\"\n      fi\n      minlen=`\\$cat | awk 'NR%4 == 2 {lengths[length(\\$0)]++} END {for (l in lengths) {print l, lengths[l]}}'  \\\n        | sort \\\n        | awk '{ print \\$0, \\$1*\\$2}' \\\n        | awk -v var=\"${params.trimmomatic_MINLEN}\" '{ SUM += \\$3 } { SUM2 += \\$2 } END { printf(\"%.0f\", SUM / SUM2 * var)} '`\n    fi\n    if [ \\${#fastq_files[@]} == 2 ]; then\n      trimmomatic \\\n        PE \\\n        -threads ${task.cpus} \\\n        \\${fastq_files[0]} \\\n        \\${fastq_files[1]} \\\n        ${sample_id}_1p_trim.fastq \\\n        ${sample_id}_1u_trim.fastq \\\n        ${sample_id}_2p_trim.fastq \\\n        ${sample_id}_2u_trim.fastq \\\n        ILLUMINACLIP:${fasta_adapter}:2:40:15 \\\n        LEADING:${params.trimmomatic_LEADING} \\\n        TRAILING:${params.trimmomatic_TRAILING} \\\n        SLIDINGWINDOW:${params.trimmomatic_SLIDINGWINDOW} \\\n        MINLEN:\"\\$minlen\" > ${sample_id}.trim.log 2>&1\n    else\n      trimmomatic \\\n        SE \\\n        -threads ${task.cpus} \\\n        \\${fastq_files[0]} \\\n        ${sample_id}_1u_trim.fastq \\\n        ILLUMINACLIP:${fasta_adapter}:2:40:15 \\\n        LEADING:${params.trimmomatic_LEADING} \\\n        TRAILING:${params.trimmomatic_TRAILING} \\\n        SLIDINGWINDOW:${params.trimmomatic_SLIDINGWINDOW} \\\n        MINLEN:\"\\$minlen\" > ${sample_id}.trim.log 2>&1\n    fi\n    \"\"\"",
        "nb_lignes_script": 68,
        "language_script": "bash",
        "tools": [
            "Trimmomatic",
            "PEC",
            "GSE"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic",
            "https://bio.tools/PEC",
            "https://bio.tools/gse"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            },
            {
                "name": "PEC",
                "uri": "https://bio.tools/PEC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3384",
                            "term": "Medical imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Medicine"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Experimental medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Clinical medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Biomedical research"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A novel approach to the program evaluation committee.\n\nBACKGROUND:The Accreditation Council for Graduate Medical Education requires each residency program to have a Program Evaluation Committee (PEC) but does not specify how the PEC should be designed. We sought to develop a PEC that promotes resident leadership and provides actionable feedback. METHODS:Participants were residents and faculty in the Traditional Internal Medicine residency program at Yale School of Medicine (YSM). One resident and one faculty member facilitated a 1-h structured group discussion to obtain resident feedback on each rotation. PEC co-facilitators summarized the feedback in written form, then met with faculty Firm Chiefs overseeing each rotation and with residency program leadership to discuss feedback and generate action plans. This PEC process was implemented in all inpatient and outpatient rotations over a 4-year period.\n\n||| HOMEPAGE MISSING!",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31842868"
            },
            {
                "name": "GSE",
                "uri": "https://bio.tools/gse",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3321",
                            "term": "Molecular genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Database for storing, visualizing, and analyzing ChIP-based transcription factor binding data and gene expression data.",
                "homepage": "http://groups.csail.mit.edu/cgs/gse.html"
            }
        ],
        "inputs": [
            "sample_id",
            "fastq_files",
            "fasta_adapter"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "label \"process_medium\"",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_trimmomatic",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "stringtie": {
        "name_process": "stringtie",
        "string_process": "\nprocess stringtie {\n    tag { sample_id }\n    label \"process_medium\"\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_stringtie_ga_gtf\n\n                                                         \n    conda     (params.enable_conda ? \"bioconda::stringtie=2.1.7\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/stringtie:2.1.7--h978d192_0\"\n    } else {\n        container \"quay.io/biocontainers/stringtie:2.1.7--h978d192_0\"\n    }\n\n    input:\n    tuple val(sample_id), path(bam_file)\n    path(gtf_file)\n\n    output:\n    tuple val(sample_id), path(\"*.stringtie.*\"), emit: GA_GTF_FILES\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE bam_bytes=`stat -Lc '%s' *.bam`\"\n    echo \"#TRACE gtf_lines=`cat *.gtf | wc -l`\"\n\n    stringtie \\\n        -v \\\n        -p ${task.cpus} \\\n        -e \\\n        -o ${sample_id}.stringtie.gtf \\\n        -G ${gtf_file} \\\n        -A ${sample_id}.stringtie.ga \\\n        -l ${sample_id} \\\n        ${bam_file}\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE bam_bytes=`stat -Lc '%s' *.bam`\"\n    echo \"#TRACE gtf_lines=`cat *.gtf | wc -l`\"\n\n    stringtie \\\n        -v \\\n        -p ${task.cpus} \\\n        -e \\\n        -o ${sample_id}.stringtie.gtf \\\n        -G ${gtf_file} \\\n        -A ${sample_id}.stringtie.ga \\\n        -l ${sample_id} \\\n        ${bam_file}\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "StringTie"
        ],
        "tools_url": [
            "https://bio.tools/stringtie"
        ],
        "tools_dico": [
            {
                "name": "StringTie",
                "uri": "https://bio.tools/stringtie",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Fast and highly efficient assembler of RNA-Seq alignments into potential transcripts. It uses a novel network flow algorithm as well as an optional de novo assembly step to assemble and quantitate full-length transcripts representing multiple splice variants for each gene locus.",
                "homepage": "https://ccb.jhu.edu/software/stringtie/"
            }
        ],
        "inputs": [
            "sample_id",
            "bam_file",
            "gtf_file"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "label \"process_medium\"",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_stringtie_ga_gtf",
            "conda (params.enable_conda ? \"bioconda::stringtie=2.1.7\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/stringtie:2.1.7--h978d192_0\" } else { container \"quay.io/biocontainers/stringtie:2.1.7--h978d192_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "next_sample": {
        "name_process": "next_sample",
        "string_process": "\nprocess next_sample {\n    tag { sample_id }\n    label \"local\"\n    cache false\n    maxForks 1\n\n    input:\n    val(sample_id)\n\n    output:\n    val(1), emit: SAMPLE_READY\n\n    exec:\n                                                    \n    sample_file = file(\"${workflow.workDir}/GEMmaker/process/${sample_id}.sample.csv\")\n    sample_file.moveTo(\"${workflow.workDir}/GEMmaker/done\")\n\n                                                               \n    staged_files = file(\"${workflow.workDir}/GEMmaker/stage/*\")\n    if (staged_files.size() > 0) {\n        staged_files.first().moveTo(\"${workflow.workDir}/GEMmaker/process\")\n    }\n\n                                                                     \n    else {\n        done_file = file(\"${workflow.workDir}/GEMmaker/process/DONE\")\n        done_file << \"\"\n    }\n}",
        "nb_lignes_process": 28,
        "string_script": "    sample_file = file(\"${workflow.workDir}/GEMmaker/process/${sample_id}.sample.csv\")\n    sample_file.moveTo(\"${workflow.workDir}/GEMmaker/done\")\n\n                                                               \n    staged_files = file(\"${workflow.workDir}/GEMmaker/stage/*\")\n    if (staged_files.size() > 0) {\n        staged_files.first().moveTo(\"${workflow.workDir}/GEMmaker/process\")\n    }\n\n                                                                     \n    else {\n        done_file = file(\"${workflow.workDir}/GEMmaker/process/DONE\")\n        done_file << \"\"\n    }",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "label \"local\"",
            "cache false",
            "maxForks 1"
        ],
        "when": "",
        "stub": ""
    },
    "samtools_index": {
        "name_process": "samtools_index",
        "string_process": "\nprocess samtools_index {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_samtools_index\n    \n    conda (params.enable_conda ? \"bioconda::samtools=1.14\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.14--hb421002_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.14--hb421002_0\"\n    }\n\n    input:\n    tuple val(sample_id), path(bam_file)\n\n    output:\n    tuple val(sample_id), path(bam_file), emit: BAM_FILES\n    tuple val(sample_id), path(\"*.bam.bai\"), emit: BAI_FILES\n    tuple val(sample_id), path(\"*.bam.log\"), emit: LOGS\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE bam_bytes=`stat -Lc '%s' *.bam`\"\n\n    samtools index ${bam_file}\n    samtools stats ${bam_file} > ${sample_id}.bam.log\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n    echo \"#TRACE bam_bytes=`stat -Lc '%s' *.bam`\"\n\n    samtools index ${bam_file}\n    samtools stats ${bam_file} > ${sample_id}.bam.log\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_id",
            "bam_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode, pattern: params.publish_pattern_samtools_index",
            "conda (params.enable_conda ? \"bioconda::samtools=1.14\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.14--hb421002_0\" } else { container \"quay.io/biocontainers/samtools:1.14--hb421002_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "failed_run_report": {
        "name_process": "failed_run_report",
        "string_process": "\nprocess failed_run_report {\n    publishDir \"${params.outdir}/reports\", mode: params.publish_dir_mode\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    path(failed_runs)\n    path(failed_run_template)\n\n    output:\n    path(\"failed_SRA_run_report.html\"), emit: FAILED_RUN_REPORT\n\n    script:\n    \"\"\"\n    failed_runs_report.py --template ${failed_run_template}\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    failed_runs_report.py --template ${failed_run_template}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "failed_runs",
            "failed_run_template"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: params.publish_dir_mode",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "kallisto_tpm": {
        "name_process": "kallisto_tpm",
        "string_process": "\nprocess kallisto_tpm {\n    tag { sample_id }\n    publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode\n    container \"systemsgenetics/gemmaker:2.1.0\"\n\n    input:\n    tuple val(sample_id), path(ga_file)\n\n    output:\n    path(\"*.tpm\"), optional: true, emit: TPM_FILES\n    path(\"*.raw\"), optional: true, emit: RAW_FILES\n    tuple val(sample_id), val(params.DONE_SENTINEL), emit: DONE_SIGNAL\n\n    script:\n    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n\n    if [[ ${params.kallisto_keep_tpm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$5}}' OFS='\\t' ${sample_id}.Kallisto.ga/abundance.tsv > ${sample_id}.Kallisto.tpm\n    fi\n\n    if [[ ${params.kallisto_keep_counts} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$4}}' OFS='\\t' ${sample_id}.Kallisto.ga/abundance.tsv > ${sample_id}.Kallisto.raw\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    echo \"#TRACE sample_id=${sample_id}\"\n\n    if [[ ${params.kallisto_keep_tpm} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$5}}' OFS='\\t' ${sample_id}.Kallisto.ga/abundance.tsv > ${sample_id}.Kallisto.tpm\n    fi\n\n    if [[ ${params.kallisto_keep_counts} == true ]]; then\n      awk -F\"\\t\" '{if (NR!=1) {print \\$1, \\$4}}' OFS='\\t' ${sample_id}.Kallisto.ga/abundance.tsv > ${sample_id}.Kallisto.raw\n    fi\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_id",
            "ga_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "SystemsGenetics__GEMmaker",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${params.outdir}/Samples/${sample_id}\", mode: params.publish_dir_mode",
            "container \"systemsgenetics/gemmaker:2.1.0\""
        ],
        "when": "",
        "stub": ""
    }
}