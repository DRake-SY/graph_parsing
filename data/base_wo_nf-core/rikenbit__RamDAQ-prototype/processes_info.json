{
    "run_RSeQC_readDist": {
        "name_process": "run_RSeQC_readDist",
        "string_process": "\nprocess run_RSeQC_readDist  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/05_rseqc/read_distribution\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/rseqc:1.2\"\n\n    input:\n    val proj_id\n    set chrom_size, pipeline_class, run_id, bam_name, file(bam_file), file(bai_files), bed_name, file(bed_file) from RSeQC_conditions1\n\n    output:\n    set run_id, pipeline_class, file(\"*_readdist.txt\") into readdist_output\n    file \"*_readdist.txt\" into readDist_output_to_count\n\n    script:\n    fileName = bam_file.baseName\n    \"\"\"\n    read_distribution.py -i $bam_file -r $bed_file > ${fileName}_readdist.txt\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    fileName = bam_file.baseName\n    \"\"\"\n    read_distribution.py -i $bam_file -r $bed_file > ${fileName}_readdist.txt\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "RSeQC_conditions1"
        ],
        "nb_inputs": 2,
        "outputs": [
            "readdist_output",
            "readDist_output_to_count"
        ],
        "nb_outputs": 2,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/05_rseqc/read_distribution\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/rseqc:1.2\""
        ],
        "when": "",
        "stub": ""
    },
    "run_RSeQC_geneBC": {
        "name_process": "run_RSeQC_geneBC",
        "string_process": "\nprocess run_RSeQC_geneBC  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/05_rseqc/gene_bodycoverage\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/julia_genebodycoverage:1.2\"\n \n    input:\n    val proj_id\n    set run_id, bam_name, file(bam_file), file(bai_file), bed_name, file(bed_file), pipeline_class from RSeQC_conditions2\n\n    output:\n    set run_id, pipeline_class, file(\"${bam_name}.geneBodyCoverage.txt\") into genebc_output\n    file \"*.geneBodyCoverage.txt\" into geneBC_output_to_count\n\n    script:\n\n    \"\"\"\n    julia /opt/run.jl $bam_file $bed_file $bam_name\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    julia /opt/run.jl $bam_file $bed_file $bam_name\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "RSeQC_conditions2"
        ],
        "nb_inputs": 2,
        "outputs": [
            "genebc_output",
            "geneBC_output_to_count"
        ],
        "nb_outputs": 2,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/05_rseqc/gene_bodycoverage\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/julia_genebodycoverage:1.2\""
        ],
        "when": "",
        "stub": ""
    },
    "run_RSeQC_inferexp": {
        "name_process": "run_RSeQC_inferexp",
        "string_process": "\nprocess run_RSeQC_inferexp  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/05_rseqc/infer_experiment\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/rseqc:1.2\"\n\n    input:\n    val proj_id\n    set chrom_size, pipeline_class, run_id, bam_name, file(bam_file), file(bai_files), bed_name, file(bed_file) from RSeQC_conditions3\n\n    output:\n    set run_id, pipeline_class, file(\"*.inferexp.txt\") into inferexp_output\n    file \"*.inferexp.txt\" into inferexp_output_to_count\n\n    when:\n    bam_file =~ /.sort./\n\n    script:\n\n    \"\"\"\n    infer_experiment.py -i $bam_file -r $bed_file > ./${bam_name}.inferexp.txt\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    infer_experiment.py -i $bam_file -r $bed_file > ./${bam_name}.inferexp.txt\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "RSeQC_conditions3"
        ],
        "nb_inputs": 2,
        "outputs": [
            "inferexp_output",
            "inferexp_output_to_count"
        ],
        "nb_outputs": 2,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/05_rseqc/infer_experiment\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/rseqc:1.2\""
        ],
        "when": "bam_file =~ /.sort./",
        "stub": ""
    },
    "collect_RSeQC_summary_readDist": {
        "name_process": "collect_RSeQC_summary_readDist",
        "string_process": "\nprocess collect_RSeQC_summary_readDist {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n\n    input:\n    val proj_id\n    set run_id, pipeline_class, file(readdist_file) from readdist_output.groupTuple()\n    path readdist_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_RSeQC_ReadDist_summary.py\"\n\n    output:\n    set run_id, file(\"*.txt\") into rseqc_readdist_results\n\n    script:\n\n    if( pipeline_class[0] == 'stranded' )\n\n        \"\"\"\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution sort summary_RSeQC_ReadDist_results_PE_sort\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution forward summary_RSeQC_ReadDist_results_PE_forward\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution reverse summary_RSeQC_ReadDist_results_PE_reverse\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution R1 summary_RSeQC_ReadDist_results_PE_R1\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution R2 summary_RSeQC_ReadDist_results_PE_R2\n        \"\"\"\n    else if( pipeline_class[0] == 'unstranded' )\n\n        \"\"\"\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution sort summary_RSeQC_ReadDist_results_PE_sort\n        \"\"\"\n\n}",
        "nb_lignes_process": 32,
        "string_script": "    if( pipeline_class[0] == 'stranded' )\n\n        \"\"\"\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution sort summary_RSeQC_ReadDist_results_PE_sort\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution forward summary_RSeQC_ReadDist_results_PE_forward\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution reverse summary_RSeQC_ReadDist_results_PE_reverse\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution R1 summary_RSeQC_ReadDist_results_PE_R1\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution R2 summary_RSeQC_ReadDist_results_PE_R2\n        \"\"\"\n    else if( pipeline_class[0] == 'unstranded' )\n\n        \"\"\"\n        python $readdist_script_path $PWD/output_$proj_id/$run_id/05_rseqc/read_distribution sort summary_RSeQC_ReadDist_results_PE_sort\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "readdist_output",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [
            "rseqc_readdist_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_RSeQC_summary_geneBC": {
        "name_process": "collect_RSeQC_summary_geneBC",
        "string_process": "\nprocess collect_RSeQC_summary_geneBC {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n\n    input:\n    val proj_id\n    set run_id, pipeline_class, file(genebc_file) from genebc_output.groupTuple()\n    path genebc_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_RSeQC_geneBC_summary.py\"\n\n    output:\n    set run_id, file(\"*.txt\") into rseqc_genebc_results\n\n    script:\n\n    if( pipeline_class[0] == 'stranded' )\n\n        \"\"\"\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage sort summary_RSeQC_geneBC_results_PE_sort\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage forward summary_RSeQC_geneBC_results_PE_forward\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage reverse summary_RSeQC_geneBC_results_PE_reverse\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage R1 summary_RSeQC_geneBC_results_PE_R1\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage R2 summary_RSeQC_geneBC_results_PE_R2\n        \"\"\"\n    else if( pipeline_class[0] == 'unstranded' )\n\n        \"\"\"\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage sort summary_RSeQC_geneBC_results_PE_sort\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    if( pipeline_class[0] == 'stranded' )\n\n        \"\"\"\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage sort summary_RSeQC_geneBC_results_PE_sort\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage forward summary_RSeQC_geneBC_results_PE_forward\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage reverse summary_RSeQC_geneBC_results_PE_reverse\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage R1 summary_RSeQC_geneBC_results_PE_R1\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage R2 summary_RSeQC_geneBC_results_PE_R2\n        \"\"\"\n    else if( pipeline_class[0] == 'unstranded' )\n\n        \"\"\"\n        python $genebc_script_path $PWD/output_$proj_id/$run_id/05_rseqc/gene_bodycoverage sort summary_RSeQC_geneBC_results_PE_sort\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "genebc_output",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [
            "rseqc_genebc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_RSeQC_summary_inferexp": {
        "name_process": "collect_RSeQC_summary_inferexp",
        "string_process": "\nprocess collect_RSeQC_summary_inferexp {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n\n    input:\n    val proj_id\n    set run_id, pipeline_class, file(infer_file) from inferexp_output.groupTuple()\n    path infer_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_inferexperiment_summary.py\"\n\n    output:\n    set run_id, file(\"*.txt\") into rseqc_inferexp_results\n\n    script:\n        \"\"\"\n        python $infer_script_path $PWD/output_$proj_id/$run_id/05_rseqc/infer_experiment summary_RSeQC_inferexperiment_results_PE_sort PE\n        \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "        \"\"\"\n        python $infer_script_path $PWD/output_$proj_id/$run_id/05_rseqc/infer_experiment summary_RSeQC_inferexperiment_results_PE_sort PE\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "inferexp_output",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [
            "rseqc_inferexp_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "run_fastQC_bef": {
        "name_process": "run_fastQC_bef",
        "string_process": "\nprocess run_fastQC_bef {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/03_fastQC_beforeTrimming\", mode: 'copy', overwrite: true\n\n    container \"genomicpariscentre/fastqc:0.11.5\"\n\n    input:\n    val proj_id\n    set run_id, fastq_name, fastq_L_name, fastq_R_name, file(fastq_L), file(fastq_R), fastq_L_basename, fastq_R_basename, option_name, option, adapter_name, file(adapterfile) from fastqc_bef_conditions\n\n    output:\n    set run_id, file(\"${fastq_L_basename}_fastqc\"), file(\"${fastq_R_basename}_fastqc\") into fastqc_bef_output\n\n    script:\n    \"\"\"\n    fastqc -o . --nogroup $fastq_L\n    unzip ${fastq_L_basename}_fastqc.zip\n    fastqc -o . --nogroup $fastq_R\n    unzip ${fastq_R_basename}_fastqc.zip\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    fastqc -o . --nogroup $fastq_L\n    unzip ${fastq_L_basename}_fastqc.zip\n    fastqc -o . --nogroup $fastq_R\n    unzip ${fastq_R_basename}_fastqc.zip\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "proj_id",
            "fastqc_bef_conditions"
        ],
        "nb_inputs": 2,
        "outputs": [
            "fastqc_bef_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/03_fastQC_beforeTrimming\", mode: 'copy', overwrite: true",
            "container \"genomicpariscentre/fastqc:0.11.5\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_fastQC_bef_summary": {
        "name_process": "collect_fastQC_bef_summary",
        "string_process": "\nprocess collect_fastQC_bef_summary {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n    input:\n    val proj_id\n    set run_id, fastq_L_dir, fastq_R_dir from fastqc_bef_output.groupTuple()   \n    path script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_fastqc_summary.py\"\n\n    output:\n    file \"*.txt\"\n\n    script:\n\n    \"\"\"\n    python $script_path $PWD/output_$proj_id/$run_id/03_fastQC_beforeTrimming summary_beforetrim_fastQC_result\n    \"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    python $script_path $PWD/output_$proj_id/$run_id/03_fastQC_beforeTrimming summary_beforetrim_fastQC_result\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "fastqc_bef_output",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "run_fastqmcf": {
        "name_process": "run_fastqmcf",
        "string_process": "\nprocess run_fastqmcf  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/02_fastqmcf\", mode: 'copy', overwrite: true\n   \n    container \"docker.io/myoshimura080822/fastqmcf:1.0\"\n\n    input:\n    val proj_id\n    set run_id, fastq_name, fastq_L_name, fastq_R_name, file(fastq_L), file(fastq_R), fastq_L_basename, fastq_R_basename, option_name, option, adapter_name, file(adapterfile) from fastqmcf_conditions\n\n    output:\n    set run_id, fastq_L_name, fastq_R_name, file(\"${fastq_L_name}_trim.fastq.gz\"), file(\"${fastq_R_name}_trim.fastq.gz\") into fastqmcf_output_tofastqc\n    set run_id, fastq_name, file(\"${fastq_L_name}_trim.fastq.gz\"), file(\"${fastq_R_name}_trim.fastq.gz\") into fastqmcf_output_tohisat2\n\n    script:\n    \"\"\"\n    fastq-mcf $adapterfile $fastq_L $fastq_R -o ${fastq_L_name}_trim.fastq -o ${fastq_R_name}_trim.fastq $option && gzip ${fastq_L_name}_trim.fastq && gzip ${fastq_R_name}_trim.fastq\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    fastq-mcf $adapterfile $fastq_L $fastq_R -o ${fastq_L_name}_trim.fastq -o ${fastq_R_name}_trim.fastq $option && gzip ${fastq_L_name}_trim.fastq && gzip ${fastq_R_name}_trim.fastq\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "fastqmcf_conditions"
        ],
        "nb_inputs": 2,
        "outputs": [
            "fastqmcf_output_tofastqc",
            "fastqmcf_output_tohisat2"
        ],
        "nb_outputs": 2,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/02_fastqmcf\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/fastqmcf:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "run_fastQC": {
        "name_process": "run_fastQC",
        "string_process": "\nprocess run_fastQC {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/03_fastQC\", mode: 'copy', overwrite: true\n    \n    container \"genomicpariscentre/fastqc:0.11.5\"\n\n    input:\n    val proj_id\n    set run_id, fastq_L_name, fastq_R_name, file(fastq_L_trim), file(fastq_R_trim) from fastqmcf_output_tofastqc\n\n    output:\n    set run_id, file(\"${fastq_L_name}_trim_fastqc\"), file(\"${fastq_R_name}_trim_fastqc\") into fastqc_output\n\n    script:\n    \"\"\"\n    fastqc -o . --nogroup $fastq_L_trim\n    unzip ${fastq_L_name}_trim_fastqc.zip\n    fastqc -o . --nogroup $fastq_R_trim\n    unzip ${fastq_R_name}_trim_fastqc.zip\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    fastqc -o . --nogroup $fastq_L_trim\n    unzip ${fastq_L_name}_trim_fastqc.zip\n    fastqc -o . --nogroup $fastq_R_trim\n    unzip ${fastq_R_name}_trim_fastqc.zip\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "proj_id",
            "fastqmcf_output_tofastqc"
        ],
        "nb_inputs": 2,
        "outputs": [
            "fastqc_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/03_fastQC\", mode: 'copy', overwrite: true",
            "container \"genomicpariscentre/fastqc:0.11.5\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_fastQC_summary": {
        "name_process": "collect_fastQC_summary",
        "string_process": "\nprocess collect_fastQC_summary {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n\n    input:\n    val proj_id\n    set run_id, fastq_L_dir, fastq_R_dir from fastqc_output.groupTuple()\n    path script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_fastqc_summary.py\"    \n\n    output:\n    set run_id, file(\"*.txt\") into fastqc_results\n\n    script:\n    \"\"\"\n    python $script_path $PWD/output_$proj_id/$run_id/03_fastQC summary_fastQC_result\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    python $script_path $PWD/output_$proj_id/$run_id/03_fastQC summary_fastQC_result\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "fastqc_output",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [
            "fastqc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "run_hisat2": {
        "name_process": "run_hisat2",
        "string_process": "\nprocess run_hisat2  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/04_hisat2_rrna\", mode: 'copy', overwrite: true\n\n    clusterOptions = '-S /bin/bash -l nc=8'\n    container \"docker.io/myoshimura080822/hisat2_set:190611\"\n\n    input:\n    val proj_id\n    set run_id, fastq_name, file(fastq), option_name, option, strandedness_name, strandedness, index_name, index, file(index_files), pipeline_class from hisat2_conditions\n\n    output:\n    set run_id, pipeline_class, fastq_name, file(\"*.bam\") into hisat2_output, hisat2_output_forsummary\n    file \"*.bai\"\n    file \"*.command.err\"\n    file \"*.bam\" into hisat2_output_to_count\n\n    script:\n    def scripts_dir = workflow.scriptFile.parent.parent + \"/bamtools_scripts\"\n\n    \"\"\"\n    hisat2 $option -x $index -U $fastq $strandedness 2> ${fastq_name}.hisat2.command.err | samtools view -bS - | samtools sort - -o ${fastq_name}_rrna_trim.sort.bam \n    samtools index ${fastq_name}_rrna_trim.sort.bam \n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    def scripts_dir = workflow.scriptFile.parent.parent + \"/bamtools_scripts\"\n\n    \"\"\"\n    hisat2 $option -x $index -U $fastq $strandedness 2> ${fastq_name}.hisat2.command.err | samtools view -bS - | samtools sort - -o ${fastq_name}_rrna_trim.sort.bam \n    samtools index ${fastq_name}_rrna_trim.sort.bam \n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "HISAT2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/hisat2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "HISAT2",
                "uri": "https://bio.tools/hisat2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).",
                "homepage": "https://ccb.jhu.edu/software/hisat2/index.shtml"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "proj_id",
            "hisat2_conditions"
        ],
        "nb_inputs": 2,
        "outputs": [
            "hisat2_output",
            "hisat2_output_forsummary",
            "hisat2_output_to_count"
        ],
        "nb_outputs": 3,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/04_hisat2_rrna\", mode: 'copy', overwrite: true",
            "clusterOptions = '-S /bin/bash -l nc=8'",
            "container \"docker.io/myoshimura080822/hisat2_set:190611\""
        ],
        "when": "",
        "stub": ""
    },
    "run_bam2wig": {
        "name_process": "run_bam2wig",
        "string_process": "\nprocess run_bam2wig  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/04_hisat2_bigwig\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/rseqc:1.2\"\n\n    input:\n    val proj_id\n    set chrom_size, pipeline_class, run_id, fastq_name, file(bam_files), file(bai_files), file(chrom_size_file) from bam2wig_input\n\n    output:\n    file \"*.bw\" into bam2wig_output_to_count\n    file \"*.wig\"\n\n    script:\n    \n    if( pipeline_class == 'stranded' )\n        \"\"\"\n        bam2wig.py -i ${bam_files[0]} -s $chrom_size_file -u -o ${bam_files[0].baseName}\n        bam2wig.py -i ${bam_files[1]} -s $chrom_size_file -u -o ${bam_files[1].baseName}\n        bam2wig.py -i ${bam_files[2]} -s $chrom_size_file -u -o ${bam_files[2].baseName}\n        \"\"\"\n    else if( pipeline_class == 'unstranded' )\n        \"\"\"\n        bam2wig.py -i $bam_files -s $chrom_size_file -u -o ${bam_files.baseName}\n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    if( pipeline_class == 'stranded' )\n        \"\"\"\n        bam2wig.py -i ${bam_files[0]} -s $chrom_size_file -u -o ${bam_files[0].baseName}\n        bam2wig.py -i ${bam_files[1]} -s $chrom_size_file -u -o ${bam_files[1].baseName}\n        bam2wig.py -i ${bam_files[2]} -s $chrom_size_file -u -o ${bam_files[2].baseName}\n        \"\"\"\n    else if( pipeline_class == 'unstranded' )\n        \"\"\"\n        bam2wig.py -i $bam_files -s $chrom_size_file -u -o ${bam_files.baseName}\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "bam2wig_input"
        ],
        "nb_inputs": 2,
        "outputs": [
            "bam2wig_output_to_count"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/04_hisat2_bigwig\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/rseqc:1.2\""
        ],
        "when": "",
        "stub": ""
    },
    "run_featurecounts": {
        "name_process": "run_featurecounts",
        "string_process": "\nprocess run_featurecounts  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/07_featurecounts_rrna/${gtf_name}/\", mode: 'copy', overwrite: true\n    \n    container \"docker.io/myoshimura080822/hisat2_set:190611\"\n\n    input:\n    val proj_id\n    set run_id, pipeline_class, bam_name, file(bam_file), option_name, option, gtf_name, file(gtf) from featurecounts_conditions\n\n    output:\n    set run_id, gtf_name, pipeline_class, bam_name, file(\"fcounts_${bam_name}_rrna_trim.txt\"), file(\"fcounts_${bam_name}_rrna_trim.txt.summary\") into featurecounts_output\n    file \"fcounts_${bam_name}_rrna.log\"\n    file \"*_rrna_trim.txt\" into fcounts_output_to_count\n\n    script:\n\n    \"\"\"\n    featureCounts $option -g gene_id -a $gtf -o ./fcounts_${bam_name}_rrna_trim.txt $bam_file >& ./fcounts_${bam_name}_rrna.log\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    featureCounts $option -g gene_id -a $gtf -o ./fcounts_${bam_name}_rrna_trim.txt $bam_file >& ./fcounts_${bam_name}_rrna.log\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FeatureCounts"
        ],
        "tools_url": [
            "https://bio.tools/featurecounts"
        ],
        "tools_dico": [
            {
                "name": "FeatureCounts",
                "uri": "https://bio.tools/featurecounts",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3793",
                                    "term": "Read summarisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "featureCounts is a very efficient read quantifier. It can be used to summarize RNA-seq reads and gDNA-seq reads to a variety of genomic features such as genes, exons, promoters, gene bodies and genomic bins. It is included in the Bioconductor Rsubread package and also in the SourceForge Subread package.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rsubread.html"
            }
        ],
        "inputs": [
            "proj_id",
            "featurecounts_conditions"
        ],
        "nb_inputs": 2,
        "outputs": [
            "featurecounts_output",
            "fcounts_output_to_count"
        ],
        "nb_outputs": 2,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/07_featurecounts_rrna/${gtf_name}/\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/hisat2_set:190611\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_featurecounts_summary": {
        "name_process": "collect_featurecounts_summary",
        "string_process": "\nprocess collect_featurecounts_summary {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n\n    input:\n    val proj_id\n    set run_id, gtf_name, pipeline_class, bam_name, file(fcounts_file), file(fcounts_summary_file) from featurecounts_output.groupTuple(by: [0,1])\n    path collectcounts_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_featurecounts_counts.py\"\n\n    output:\n    set run_id, file(\"*.txt\") into collect_featurecounts_results_output\n\n    script:\n\n    \"\"\"\n    python $collectcounts_script_path $PWD/output_${proj_id}/${run_id}/07_featurecounts_rrna/${gtf_name}/ mergefcounts_${gtf_name}\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    python $collectcounts_script_path $PWD/output_${proj_id}/${run_id}/07_featurecounts_rrna/${gtf_name}/ mergefcounts_${gtf_name}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "featurecounts_output",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [
            "collect_featurecounts_results_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "run_genebodycoverage": {
        "name_process": "run_genebodycoverage",
        "string_process": "\nprocess run_genebodycoverage  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/05_rseqc/gene_bodycoverage\", mode: 'copy', overwrite: true\n\n    container \"yuifu/readcoverage.jl:0.1.2\"\n\n    input:\n    val proj_id\n    set chrom_size, pipeline_class, run_id, bam_name, file(bam_file), file(bai_files), bed_name, file(bed_file) from RSeQC_conditions2\n\n    output:\n    set run_id, pipeline_class, file(\"*.geneBodyCoverage.txt\") into genebc_output\n    file \"*.geneBodyCoverage.txt\" into geneBC_output_to_count\n\n    script:\n    \"\"\"\n    julia /opt/run.jl relcov $bam_file $bed_file ${bam_file.baseName}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    julia /opt/run.jl relcov $bam_file $bed_file ${bam_file.baseName}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "RSeQC_conditions2"
        ],
        "nb_inputs": 2,
        "outputs": [
            "genebc_output",
            "geneBC_output_to_count"
        ],
        "nb_outputs": 2,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/05_rseqc/gene_bodycoverage\", mode: 'copy', overwrite: true",
            "container \"yuifu/readcoverage.jl:0.1.2\""
        ],
        "when": "",
        "stub": ""
    },
    "execute_nbconvert": {
        "name_process": "execute_nbconvert",
        "string_process": "\nprocess execute_nbconvert {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n    \n    container \"docker.io/myoshimura080822/jupyternotebook:2.4\"\n    \n    input:\n    val proj_id\n    set run_id from run_ids\n    path proj_dir from workflow.workDir.parent + \"/output_${proj_id}\"\n    path notebook_path_unstranded from workflow.scriptFile.parent.parent + \"/R_QCplot/RamDA-SeqQC_template_SE_unstranded_nbconvert.ipynb\"\n    path function_file from workflow.scriptFile.parent.parent + \"/R_QCplot/00_sampleQC_function_nbconvert.R\"\n\n    output:\n    file \"*.html\"\n    file \"*.ipynb\"\n\n    script:\n    \"\"\"\n    ln -s $proj_dir/${run_id}/summary_* .\n    ln -s $proj_dir/${run_id}/mergefcounts_gencode_mrna_gene.txt .\n\n    jupyter nbconvert --to html --execute $notebook_path_unstranded --output ${run_id}_notebook_SE_unstranded.html --ExecutePreprocessor.timeout=2678400 --allow-errors --debug\n    \n    jupyter nbconvert --to notebook --execute $notebook_path_unstranded --output ${run_id}_notebook_SE_unstranded.ipynb --ExecutePreprocessor.timeout=2678400 --allow-errors --debug\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    ln -s $proj_dir/${run_id}/summary_* .\n    ln -s $proj_dir/${run_id}/mergefcounts_gencode_mrna_gene.txt .\n\n    jupyter nbconvert --to html --execute $notebook_path_unstranded --output ${run_id}_notebook_SE_unstranded.html --ExecutePreprocessor.timeout=2678400 --allow-errors --debug\n    \n    jupyter nbconvert --to notebook --execute $notebook_path_unstranded --output ${run_id}_notebook_SE_unstranded.ipynb --ExecutePreprocessor.timeout=2678400 --allow-errors --debug\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Jupyterhub"
        ],
        "tools_url": [
            "https://bio.tools/Jupyterhub"
        ],
        "tools_dico": [
            {
                "name": "Jupyterhub",
                "uri": "https://bio.tools/Jupyterhub",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Jupyter notebooks in science gateways.\n\nJupyter Notebooks empower scientists to create executable documents that include text, equations, code and figures. Notebooks are a simple way to create reproducible and shareable workflows. The Jupyter developers have also released a multi-user notebook environment: Jupyterhub. Jupyterhub provides an extensible platform for handling user authentication and spawning the Notebook application to each user. I developed a plugin for Jupyterhub to spawn notebooks on a Supercomputer and integrated the authentication with CILogon and XSEDE. Scientists can authenticate on their browser and connect to a Jupyter Notebook instance running on the computing node of a Supercomputer, in my test deployment SDSC Comet. Jupyterhub can benefit Science Gateways by providing an expressive interface to a centralized environment with many software tools pre-installed and allow scientists to access Gateway functionality via web API.\n\n||| HOMEPAGE MISSING!",
                "homepage": "https://doi.org/10.7287/PEERJ.PREPRINTS.2577V2"
            }
        ],
        "inputs": [
            "proj_id",
            "run_ids",
            "workflow",
            "workflow",
            "workflow"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/jupyternotebook:2.4\""
        ],
        "when": "",
        "stub": ""
    },
    "run_sailfish": {
        "name_process": "run_sailfish",
        "string_process": "\nprocess run_sailfish  {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/06_sailfish\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/sailfish:1.0\"\n\n    input:\n    val proj_id\n    set run_id, fastq_name, file(fastq), option_name, option, index_name, index, file(index_files) from sailfish_conditions\n\n    output:\n    set run_id, fastq_name, file(\"sailfish_${fastq_name}_trim\") into sailfish_output\n\n    script:\n\n    \"\"\"\n    sailfish quant -i ${index} ${option} -r <(gzip -dc ${fastq}) -o ./sailfish_${fastq_name}_trim\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    sailfish quant -i ${index} ${option} -r <(gzip -dc ${fastq}) -o ./sailfish_${fastq_name}_trim\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Sailfish"
        ],
        "tools_url": [
            "https://bio.tools/sailfish"
        ],
        "tools_dico": [
            {
                "name": "Sailfish",
                "uri": "https://bio.tools/sailfish",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0099",
                            "term": "RNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A software tool that implements a novel, is an alignment-free algorithm for the estimation of isoform abundances directly from a set of reference sequences and RNA-seq reads.",
                "homepage": "http://www.cs.cmu.edu/~ckingsf/software/sailfish/"
            }
        ],
        "inputs": [
            "proj_id",
            "sailfish_conditions"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sailfish_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/06_sailfish\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/sailfish:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_sailfish_summary": {
        "name_process": "collect_sailfish_summary",
        "string_process": "\nprocess collect_sailfish_summary {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n    \n    input:\n    val proj_id\n    set run_id, fastq_name, sailfish_outdir from sailfish_output.groupTuple()\n    path summary_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_sailfish_summary.py\"\n    path collectcounts_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_sailfish_counts.py\"\n\n    output:\n    file \"*.txt\"\n\n    script:\n    \"\"\"\n    python $summary_script_path $PWD/output_$proj_id/$run_id/06_sailfish summary_sailfish_results\n    python $collectcounts_script_path $PWD/output_$proj_id/$run_id/06_sailfish countdata_sailfish\n\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    python $summary_script_path $PWD/output_$proj_id/$run_id/06_sailfish summary_sailfish_results\n    python $collectcounts_script_path $PWD/output_$proj_id/$run_id/06_sailfish countdata_sailfish\n\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "sailfish_output",
            "workflow",
            "workflow"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "run_bcl2fastq": {
        "name_process": "run_bcl2fastq",
        "string_process": "\nprocess run_bcl2fastq  {\n    tag { \"${run_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/01_fastq_files\"\n\n    container \"docker.io/myoshimura080822/bcl2fastq2:2.0\"\n\n    input:\n    val proj_id\n    set run_id, path(run_basedir) from run_basedirs\n\n    script:\n    def output_dir = \"output_${proj_id}/${run_id}/01_fastq_files\" \n\n    \"\"\"\n    bcl2fastq --no-lane-splitting --runfolder-dir $run_basedir --interop-dir $run_basedir/InterOp --input-dir $run_basedir/Data/Intensities/BaseCalls --sample-sheet $run_basedir/SampleSheet.csv --output-dir $PWD/$output_dir --stats-dir $PWD/$output_dir/Stats --reports-dir $PWD/$output_dir/Reports && rm -rf $PWD/$output_dir/Undetermined*\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    def output_dir = \"output_${proj_id}/${run_id}/01_fastq_files\" \n\n    \"\"\"\n    bcl2fastq --no-lane-splitting --runfolder-dir $run_basedir --interop-dir $run_basedir/InterOp --input-dir $run_basedir/Data/Intensities/BaseCalls --sample-sheet $run_basedir/SampleSheet.csv --output-dir $PWD/$output_dir --stats-dir $PWD/$output_dir/Stats --reports-dir $PWD/$output_dir/Reports && rm -rf $PWD/$output_dir/Undetermined*\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "run_basedirs"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag { \"${run_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/01_fastq_files\"",
            "container \"docker.io/myoshimura080822/bcl2fastq2:2.0\""
        ],
        "when": "",
        "stub": ""
    },
    "download_fastq": {
        "name_process": "download_fastq",
        "string_process": "\nprocess download_fastq {\n    publishDir \"output_download_fastq\", mode: 'move'\n    errorStrategy 'ignore'\n\n    container \"yuifu/cwltool-with-bash:1.0.20180809224403\"\n\n    input:\n    val run_id from run_ids\n\n    output:\n    file \"*.fastq.gz\"\n\n    script:\n    \"\"\"\n    cwltool --debug \"https://raw.githubusercontent.com/pitagora-network/pitagora-cwl/master/workflows/download-fastq/download-fastq.cwl\" --run_ids ${run_id} --nthreads ${nthreads} --repo ${repo}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    cwltool --debug \"https://raw.githubusercontent.com/pitagora-network/pitagora-cwl/master/workflows/download-fastq/download-fastq.cwl\" --run_ids ${run_id} --nthreads ${nthreads} --repo ${repo}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "run_ids"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "publishDir \"output_download_fastq\", mode: 'move'",
            "errorStrategy 'ignore'",
            "container \"yuifu/cwltool-with-bash:1.0.20180809224403\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_hisat2_summary": {
        "name_process": "collect_hisat2_summary",
        "string_process": "\nprocess collect_hisat2_summary {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true\n    \n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n    \n    input:\n    val proj_id\n    set run_id, pipeline_class, bam_name, file(bam_file) from hisat2_output_forsummary.groupTuple()\n    path summary_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_hisat2_summary.py\"\n\n    output:\n    file \"*.txt\"\n\n    script:\n    \"\"\"\n    python $summary_script_path $PWD/output_${proj_id}/${run_id}/04_hisat2_rrna summary_hisat2_rrna_results SE\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    python $summary_script_path $PWD/output_${proj_id}/${run_id}/04_hisat2_rrna summary_hisat2_rrna_results SE\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "hisat2_output_forsummary",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_highsensitivity_rrnaQC_summary": {
        "name_process": "collect_highsensitivity_rrnaQC_summary",
        "string_process": "\nprocess collect_highsensitivity_rrnaQC_summary {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/highsensitivity_rrnaQC_summary/\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/r-devel:2.4\"\n\n    input:\n    val proj_id\n    val collect_rrnaQC_annot_ts\n    val collect_rrnaQC_annot_refseq\n    set run_id, file(merge_fcounts_file) from collect_featurecounts_results_output.groupTuple()\n\n    path collectcounts_script_mouse from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_highsensitivity_rrnaQC_summary_mouse.R\"\n    path collectcounts_script_human from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_highsensitivity_rrnaQC_summary_human.R\"\n    path collect_rrnaQC_annot_ts_file from collect_rrnaQC_annot_ts\n    path collect_rrnaQC_annot_refseq_file from collect_rrnaQC_annot_refseq\n\n    output:\n    file \"*.txt\"\n\n    script:\n\n    if( pipeline_species == 'mouse' )\n        \"\"\"\n        Rscript $collectcounts_script_mouse $PWD/output_${proj_id}/${run_id} ${collect_rrnaQC_annot_ts_file} ${collect_rrnaQC_annot_refseq_file}\n        \"\"\"\n    else if( pipeline_species == 'human' )\n        \"\"\"\n        Rscript $collectcounts_script_human $PWD/output_${proj_id}/${run_id} ${collect_rrnaQC_annot_refseq}\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    if( pipeline_species == 'mouse' )\n        \"\"\"\n        Rscript $collectcounts_script_mouse $PWD/output_${proj_id}/${run_id} ${collect_rrnaQC_annot_ts_file} ${collect_rrnaQC_annot_refseq_file}\n        \"\"\"\n    else if( pipeline_species == 'human' )\n        \"\"\"\n        Rscript $collectcounts_script_human $PWD/output_${proj_id}/${run_id} ${collect_rrnaQC_annot_refseq}\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "collect_rrnaQC_annot_ts",
            "collect_rrnaQC_annot_refseq",
            "collect_featurecounts_results_output",
            "workflow",
            "workflow",
            "collect_rrnaQC_annot_ts",
            "collect_rrnaQC_annot_refseq"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/highsensitivity_rrnaQC_summary/\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/r-devel:2.4\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_featurecounts_results": {
        "name_process": "collect_featurecounts_results",
        "string_process": "\nprocess collect_featurecounts_results {\n\n    tag {\"${proj_id}\"}\n    publishDir \"output_${proj_id}/${run_id}/\", mode: 'copy', overwrite: true\n\n    container \"docker.io/myoshimura080822/scientific_python2.7:1.0\"\n\n    input:\n    val proj_id\n    set run_id, gtf_name, pipeline_class, bam_name, file(fcounts_file), file(fcounts_summary_file) from featurecounts_output.groupTuple(by: [0,1])\n    path collectcounts_script_path from workflow.scriptFile.parent.parent + \"/collect_output_scripts/collect_featurecounts_counts.py\"\n\n    output:\n    set run_id, file(\"*.txt\") into collect_featurecounts_results_output\n\n    script:\n    \"\"\"\n    python $collectcounts_script_path $PWD/output_${proj_id}/${run_id}/07_featurecounts_rrna/${gtf_name}/ mergefcounts_${gtf_name}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    python $collectcounts_script_path $PWD/output_${proj_id}/${run_id}/07_featurecounts_rrna/${gtf_name}/ mergefcounts_${gtf_name}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "proj_id",
            "featurecounts_output",
            "workflow"
        ],
        "nb_inputs": 3,
        "outputs": [
            "collect_featurecounts_results_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "rikenbit__RamDAQ-prototype",
        "directive": [
            "tag {\"${proj_id}\"}",
            "publishDir \"output_${proj_id}/${run_id}/\", mode: 'copy', overwrite: true",
            "container \"docker.io/myoshimura080822/scientific_python2.7:1.0\""
        ],
        "when": "",
        "stub": ""
    }
}