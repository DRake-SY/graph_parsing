{
    "fasta_gs": {
        "name_process": "fasta_gs",
        "string_process": " process fasta_gs {\n\n    label 'gs'\n    errorStrategy 'retry'\n    maxRetries 3\n\n    output:\n    tuple val(faval), file('*.fasta.gz') into fasta\n\n    script:\n    def faval = params.assemblylc == 'grch37' ? 'human_g1k_v37' : 'GRCh38_Verily_v1.genome'\n    if( params.assemblylc == 'grch37' )\n      \"\"\"\n      ##http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use\n      gsutil -q cp ${params.gsurl37}/human_g1k_v37.fasta.gz .\n      \"\"\"\n    else\n      \"\"\"\n      ##moved to Verily as gs bucket more reliable\n      gsutil -q cp gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa .\n      gzip -c ./GRCh38_Verily_v1.genome.fa > ./GRCh38_Verily_v1.genome.fasta.gz\n      rm ./GRCh38_Verily_v1.genome.fa\n      \"\"\"\n  }",
        "nb_lignes_process": 22,
        "string_script": "    def faval = params.assemblylc == 'grch37' ? 'human_g1k_v37' : 'GRCh38_Verily_v1.genome'\n    if( params.assemblylc == 'grch37' )\n      \"\"\"\n      ##http://lh3.github.io/2017/11/13/which-human-reference-genome-to-use\n      gsutil -q cp ${params.gsurl37}/human_g1k_v37.fasta.gz .\n      \"\"\"\n    else\n      \"\"\"\n      ##moved to Verily as gs bucket more reliable\n      gsutil -q cp gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa .\n      gzip -c ./GRCh38_Verily_v1.genome.fa > ./GRCh38_Verily_v1.genome.fasta.gz\n      rm ./GRCh38_Verily_v1.genome.fa\n      \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "NGSUtils"
        ],
        "tools_url": [
            "https://bio.tools/ngsutils"
        ],
        "tools_dico": [
            {
                "name": "NGSUtils",
                "uri": "https://bio.tools/ngsutils",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3187",
                                    "term": "Sequence contamination filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NGSUtils is a suite of software tools for working with next-generation sequencing datasets",
                "homepage": "http://ngsutils.org"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "fasta"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'gs'",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "fasta_process": {
        "name_process": "fasta_process",
        "string_process": " process fasta_process {\n\n    echo true\n    label 'low_mem'\n\n    input:\n    tuple val(faval), file(fagz) from fasta\n\n    output:\n    tuple file('*.noChr.fasta'), file('*.noChr.fasta.fai') into (fasta_bwa, fasta_seqza, fasta_msi, fasta_dict, fasta_2bit, fasta_exome_biall, fasta_wgs_biall)\n\n    script:\n    def fa = \"${fagz}\".split(\"\\\\.gz\")[0]\n    \"\"\"\n    gunzip -c \\$(readlink ${fagz}) > ${fa}\n    cat ${fa} | sed 's/>chr/>/g' > ./${faval}.noChr.fasta\n    rm ${fa}\n    samtools faidx ./${faval}.noChr.fasta\n    \"\"\"\n  }",
        "nb_lignes_process": 18,
        "string_script": "    def fa = \"${fagz}\".split(\"\\\\.gz\")[0]\n    \"\"\"\n    gunzip -c \\$(readlink ${fagz}) > ${fa}\n    cat ${fa} | sed 's/>chr/>/g' > ./${faval}.noChr.fasta\n    rm ${fa}\n    samtools faidx ./${faval}.noChr.fasta\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SynChr",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/synchr",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SynChr",
                "uri": "https://bio.tools/synchr",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0283",
                                    "term": "Linkage analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A Fast and Easy Tool to Reconstruct and Visualize Synteny Blocks along Eukaryotic Chromosomes.",
                "homepage": "http://www.lcqb.upmc.fr/CHROnicle/SynChro.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "echo true",
            "label 'low_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "dict_pr": {
        "name_process": "dict_pr",
        "string_process": " process dict_pr {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}/bwa\", mode: \"copy\"\n\n    input:\n    tuple file(fa), file(fai) from fasta_dict\n\n    output:\n    file(dict) into dict_win\n    tuple file(fa), file(fai), file(dict) into ( fasta_dict_exome, fasta_dict_wgs, fasta_dict_gensiz )\n    file(fai) into fai_gridss\n\n    script:\n    def dict = \"${fa}\".replace('fasta', 'dict')\n    \"\"\"\n    picard CreateSequenceDictionary \\\n      R=${fa} \\\n      O=${dict}\n    \"\"\"\n  }",
        "nb_lignes_process": 19,
        "string_script": "    def dict = \"${fa}\".replace('fasta', 'dict')\n    \"\"\"\n    picard CreateSequenceDictionary \\\n      R=${fa} \\\n      O=${dict}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "fasta_dict"
        ],
        "nb_inputs": 1,
        "outputs": [
            "dict_win",
            "",
            "fai_gridss"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/bwa\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "bwa_index": {
        "name_process": "bwa_index",
        "string_process": " process bwa_index {\n\n    label 'med_mem'\n    publishDir path: \"${params.outDir}/bwa\", mode: \"copy\"\n\n    input:\n    tuple file(fa), file(fai) from fasta_bwa\n\n    output:\n    file('*') into complete_bwa\n\n    script:\n    \"\"\"\n    ##https://gatkforums.broadinstitute.org/gatk/discussion/2798/howto-prepare-a-reference-for-use-with-bwa-and-gatk\n    bwa index -a bwtsw ${fa}\n    \"\"\"\n  }",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    ##https://gatkforums.broadinstitute.org/gatk/discussion/2798/howto-prepare-a-reference-for-use-with-bwa-and-gatk\n    bwa index -a bwtsw ${fa}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "BWA"
        ],
        "tools_url": [
            "https://bio.tools/bwa"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            }
        ],
        "inputs": [
            "fasta_bwa"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_bwa"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir path: \"${params.outDir}/bwa\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "send_dict_pr": {
        "name_process": "send_dict_pr",
        "string_process": " process send_dict_pr {\n\n    label 'low_mem'\n\n    input:\n    file(bwa_dir) from bwa_chan\n\n    output:\n    file('bwa/*.dict') into dict_win\n    tuple file('bwa/*noChr.fasta'), file('bwa/*.fai'), file('bwa/*.dict') into (fasta_dict_exome, fasta_dict_wgs, fasta_dict_gensiz)\n    tuple file('bwa/*.noChr.fasta'), file('bwa/*.noChr.fasta.fai') into (fasta_bwa, fasta_seqza, fasta_msi, fasta_dict, fasta_2bit, fasta_exome_biall, fasta_wgs_biall)\n    file('bwa/*.noChr.fasta.fai') into fai_gridss\n\n    script:\n    \"\"\"\n    \"\"\"\n  }",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    \"\"\"",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bwa_chan"
        ],
        "nb_inputs": 1,
        "outputs": [
            "dict_win",
            "",
            "",
            "fai_gridss"
        ],
        "nb_outputs": 4,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "vcf_dl": {
        "name_process": "vcf_dl",
        "string_process": " process vcf_dl {\n\n    label 'gs'\n    errorStrategy 'retry'\n    maxRetries 3\n\n    output:\n    file('*.vcf') into vcf_tabix\n\n    script:\n    if( params.assemblylc == 'grch37' )\n      \"\"\"\n      gsutil -q cp ${params.gsurl37}/1000G_phase1.snps.high_confidence.b37.vcf.gz ./KG_phase1.snps.high_confidence.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/dbsnp_138.b37.vcf.gz ./dbsnp_138.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/hapmap_3.3.b37.vcf.gz ./hapmap_3.3.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/1000G_omni2.5.b37.vcf.gz ./KG_omni2.5.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/Mills_and_1000G_gold_standard.indels.b37.vcf.gz ./Mills_KG_gold.indels.b37.vcf.gz\n\n      gunzip -cd dbsnp_138.b37.vcf.gz | sed 's/chr//g' > dbsnp_138.b37.vcf\n      gunzip -cd hapmap_3.3.b37.vcf.gz | sed 's/chr//g' > hapmap_3.3.b37.sites.vcf\n      gunzip -cd KG_omni2.5.b37.vcf.gz | sed 's/chr//g' > KG_omni2.5.b37.vcf\n      gunzip -cd KG_phase1.snps.high_confidence.b37.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.b37.vcf\n      gunzip -cd Mills_KG_gold.indels.b37.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.b37.vcf\n      \"\"\"\n    else\n      \"\"\"\n      gsutil -q cp gs://genomics-public-data/cwl-examples/gdc-dnaseq-cwl/input/dbsnp_144.hg38.vcf.gz ./dbsnp_144.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/1000G_phase1.snps.high_confidence.hg38.vcf.gz ./KG_phase1.snps.high_confidence.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/Homo_sapiens_assembly38.dbsnp138.vcf ./Homo_sapiens_assembly38.dbsnp138.vcf\n      gsutil -q cp ${params.gsurl38}/hapmap_3.3.hg38.vcf.gz ./hapmap_3.3.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/1000G_omni2.5.hg38.vcf.gz ./KG_omni2.5.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz ./Mills_KG_gold.indels.hg38.vcf.gz\n\n      gunzip -cd dbsnp_144.hg38.vcf.gz | sed 's/chr//g' > dbsnp_144.hg38.vcf\n      gunzip -cd hapmap_3.3.hg38.vcf.gz | sed 's/chr//g' > hapmap_3.3.hg38.vcf\n      gunzip -cd KG_omni2.5.hg38.vcf.gz | sed 's/chr//g' > KG_omni2.5.hg38.vcf\n      gunzip -cd KG_phase1.snps.high_confidence.hg38.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.hg38.vcf\n      gunzip -cd Mills_KG_gold.indels.hg38.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.hg38.vcf\n      \"\"\"\n  }",
        "nb_lignes_process": 38,
        "string_script": "    if( params.assemblylc == 'grch37' )\n      \"\"\"\n      gsutil -q cp ${params.gsurl37}/1000G_phase1.snps.high_confidence.b37.vcf.gz ./KG_phase1.snps.high_confidence.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/dbsnp_138.b37.vcf.gz ./dbsnp_138.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/hapmap_3.3.b37.vcf.gz ./hapmap_3.3.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/1000G_omni2.5.b37.vcf.gz ./KG_omni2.5.b37.vcf.gz\n      gsutil -q cp ${params.gsurl37}/Mills_and_1000G_gold_standard.indels.b37.vcf.gz ./Mills_KG_gold.indels.b37.vcf.gz\n\n      gunzip -cd dbsnp_138.b37.vcf.gz | sed 's/chr//g' > dbsnp_138.b37.vcf\n      gunzip -cd hapmap_3.3.b37.vcf.gz | sed 's/chr//g' > hapmap_3.3.b37.sites.vcf\n      gunzip -cd KG_omni2.5.b37.vcf.gz | sed 's/chr//g' > KG_omni2.5.b37.vcf\n      gunzip -cd KG_phase1.snps.high_confidence.b37.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.b37.vcf\n      gunzip -cd Mills_KG_gold.indels.b37.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.b37.vcf\n      \"\"\"\n    else\n      \"\"\"\n      gsutil -q cp gs://genomics-public-data/cwl-examples/gdc-dnaseq-cwl/input/dbsnp_144.hg38.vcf.gz ./dbsnp_144.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/1000G_phase1.snps.high_confidence.hg38.vcf.gz ./KG_phase1.snps.high_confidence.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/Homo_sapiens_assembly38.dbsnp138.vcf ./Homo_sapiens_assembly38.dbsnp138.vcf\n      gsutil -q cp ${params.gsurl38}/hapmap_3.3.hg38.vcf.gz ./hapmap_3.3.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/1000G_omni2.5.hg38.vcf.gz ./KG_omni2.5.hg38.vcf.gz\n      gsutil -q cp ${params.gsurl38}/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz ./Mills_KG_gold.indels.hg38.vcf.gz\n\n      gunzip -cd dbsnp_144.hg38.vcf.gz | sed 's/chr//g' > dbsnp_144.hg38.vcf\n      gunzip -cd hapmap_3.3.hg38.vcf.gz | sed 's/chr//g' > hapmap_3.3.hg38.vcf\n      gunzip -cd KG_omni2.5.hg38.vcf.gz | sed 's/chr//g' > KG_omni2.5.hg38.vcf\n      gunzip -cd KG_phase1.snps.high_confidence.hg38.vcf.gz | sed 's/chr//g' > KG_phase1.snps.high_confidence.hg38.vcf\n      gunzip -cd Mills_KG_gold.indels.hg38.vcf.gz | sed 's/chr//g' > Mills_KG_gold.indels.hg38.vcf\n      \"\"\"",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [
            "NGSUtils"
        ],
        "tools_url": [
            "https://bio.tools/ngsutils"
        ],
        "tools_dico": [
            {
                "name": "NGSUtils",
                "uri": "https://bio.tools/ngsutils",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3187",
                                    "term": "Sequence contamination filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NGSUtils is a suite of software tools for working with next-generation sequencing datasets",
                "homepage": "http://ngsutils.org"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "vcf_tabix"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'gs'",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "index_feature_files": {
        "name_process": "index_feature_files",
        "string_process": " process index_feature_files {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}/hc_dbs\", mode: \"copy\", pattern: \"{KG,Mills,hapmap}*\"\n    publishDir path: \"${params.outDir}/dbsnp\", mode: \"copy\", pattern: \"dbsnp*\"\n\n    input:\n    file(tbtbx) from vcf_tabix.flatten()\n\n    output:\n    file('*') into indexfeatured\n\n    script:\n    \"\"\"\n    bgzip ${tbtbx}\n    gatk IndexFeatureFile --input ${tbtbx}\".gz\"\n    \"\"\"\n  }",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    bgzip ${tbtbx}\n    gatk IndexFeatureFile --input ${tbtbx}\".gz\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "vcf_tabix"
        ],
        "nb_inputs": 1,
        "outputs": [
            "indexfeatured"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/hc_dbs\", mode: \"copy\", pattern: \"{KG,Mills,hapmap}*\"",
            "publishDir path: \"${params.outDir}/dbsnp\", mode: \"copy\", pattern: \"dbsnp*\""
        ],
        "when": "",
        "stub": ""
    },
    "gnomad_dl": {
        "name_process": "gnomad_dl",
        "string_process": " process gnomad_dl {\n\n    label 'gs'\n    publishDir path: \"${params.outDir}/gnomad\", mode: \"copy\"\n\n    output:\n    file('af-only-gnomad.*') into ( exome_biall_gnomad, wgs_biall_gnomad )\n\n    script:\n    if( params.assembly == \"GRCh37\" )\n      \"\"\"\n      gsutil -q cp gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf ./\n      bgzip af-only-gnomad.raw.sites.vcf\n      tabix af-only-gnomad.raw.sites.vcf.gz\n      \"\"\"\n    else\n      \"\"\"\n      gsutil -q cp gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz ./\n      \"\"\"\n  }",
        "nb_lignes_process": 18,
        "string_script": "    if( params.assembly == \"GRCh37\" )\n      \"\"\"\n      gsutil -q cp gs://gatk-best-practices/somatic-b37/af-only-gnomad.raw.sites.vcf ./\n      bgzip af-only-gnomad.raw.sites.vcf\n      tabix af-only-gnomad.raw.sites.vcf.gz\n      \"\"\"\n    else\n      \"\"\"\n      gsutil -q cp gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz ./\n      \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "NGSUtils"
        ],
        "tools_url": [
            "https://bio.tools/ngsutils"
        ],
        "tools_dico": [
            {
                "name": "NGSUtils",
                "uri": "https://bio.tools/ngsutils",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3187",
                                    "term": "Sequence contamination filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NGSUtils is a suite of software tools for working with next-generation sequencing datasets",
                "homepage": "http://ngsutils.org"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'gs'",
            "publishDir path: \"${params.outDir}/gnomad\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "send_gnomads": {
        "name_process": "send_gnomads",
        "string_process": " process send_gnomads {\n\n    input:\n    file(gnomad_dir) from gnomad_chan\n\n    output:\n    file('gnomad/af-only-gnomad.*') into ( exome_biall_gnomad, wgs_biall_gnomad )\n\n    script:\n    \"\"\"\n    \"\"\"\n  }",
        "nb_lignes_process": 10,
        "string_script": "    \"\"\"\n    \"\"\"",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gnomad_chan"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "exome_url": {
        "name_process": "exome_url",
        "string_process": " process exome_url {\n\n      label 'low_mem'\n\n      output:\n      tuple file(\"${params.exomeTag}.url.bed\"), file(\"README.${params.exomeTag}.url.bed\") into exome_parse_bed\n\n      script:\n      \"\"\"\n      ##download URL\n      echo \"Exome bed used here is from:\" > README.${params.exomeTag}.url.bed\n      echo ${params.exomeBedURL} >> README.${params.exomeTag}.url.bed\n\n      wget ${params.exomeBedURL}\n      if [[ ${params.exomeBedURL} =~ zip\\$ ]]; then\n        7za x -so *.zip  > ${params.exomeTag}.url.bed\n      fi\n      if [[ ${params.exomeBedURL} =~ bed\\$ ]]; then\n        mv *.bed ${params.exomeTag}.url.bed\n      fi\n      if [[ ! ${params.exomeBedURL} =~ zip\\$ || ${params.exomeBedURL} =~ bed\\$ ]]; then\n        echo \"No ZIP or BED files resulting from ${params.exomeBedURL}\"\n        echo \"Please try another URL with ZIP or BED file resulting\"\n        exit 147\n      fi\n      \"\"\"\n    }",
        "nb_lignes_process": 25,
        "string_script": "      \"\"\"\n      ##download URL\n      echo \"Exome bed used here is from:\" > README.${params.exomeTag}.url.bed\n      echo ${params.exomeBedURL} >> README.${params.exomeTag}.url.bed\n\n      wget ${params.exomeBedURL}\n      if [[ ${params.exomeBedURL} =~ zip\\$ ]]; then\n        7za x -so *.zip  > ${params.exomeTag}.url.bed\n      fi\n      if [[ ${params.exomeBedURL} =~ bed\\$ ]]; then\n        mv *.bed ${params.exomeTag}.url.bed\n      fi\n      if [[ ! ${params.exomeBedURL} =~ zip\\$ || ${params.exomeBedURL} =~ bed\\$ ]]; then\n        echo \"No ZIP or BED files resulting from ${params.exomeBedURL}\"\n        echo \"Please try another URL with ZIP or BED file resulting\"\n        exit 147\n      fi\n      \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "exome_parse_bed"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "exome_file": {
        "name_process": "exome_file",
        "string_process": " process exome_file {\n\n      label 'low_mem'\n      publishDir path: \"${params.outDir}/exome/${params.exomeTag}\", mode: \"copy\"\n\n      input:\n      file(exome_bed_file) from exomebed_file\n\n      output:\n      tuple file(\"${params.exomeTag}.file.bed\"), file(\"README.${params.exomeTag}.file.bed\") into exome_parse_bed\n\n      script:\n      \"\"\"\n      ##use file as input\n      if [[ ${exome_bed_file} =~ bed\\$ ]]; then\n        echo \"Exome bed used here is from:\" > README.${params.exomeTag}.file.bed\n        echo ${exome_bed_file} >> README.${params.exomeTag}.file.bed\n        mv ${exome_bed_file} ${params.exomeTag}.file.bed\n      else\n        echo \"BED file ${exome_bed_file} is not a BED file, please retry\"\n        exit 147\n      fi\n      \"\"\"\n    }",
        "nb_lignes_process": 22,
        "string_script": "      \"\"\"\n      ##use file as input\n      if [[ ${exome_bed_file} =~ bed\\$ ]]; then\n        echo \"Exome bed used here is from:\" > README.${params.exomeTag}.file.bed\n        echo ${exome_bed_file} >> README.${params.exomeTag}.file.bed\n        mv ${exome_bed_file} ${params.exomeTag}.file.bed\n      else\n        echo \"BED file ${exome_bed_file} is not a BED file, please retry\"\n        exit 147\n      fi\n      \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "exomebed_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "exome_parse_bed"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/exome/${params.exomeTag}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "exome_parse": {
        "name_process": "exome_parse",
        "string_process": " process exome_parse {\n\n    input:\n    tuple file(exome_bed), file(readme) from exome_parse_bed\n\n    output:\n    tuple file(\"${params.exomeTag}.lo.bed\"), file(readme) into exome_liftover\n\n    script:\n    \"\"\"\n    ##remove any non-chr, coord lines in top of file\n    CHR=\\$(tail -n1 ${exome_bed} | perl -ane 'print \\$F[0];')\n    if [[ \\$CHR =~ \"chr\" ]]; then\n      perl -ane 'if(\\$F[0]=~m/^chr/){print \\$_;}' ${exome_bed} > ${params.exomeTag}.lo.bed\n    else\n      perl -ane 'if(\\$F[0]=~m/^[0-9MXY]/){print \\$_;}' ${exome_bed} > ${params.exomeTag}.lo.bed\n    fi\n    \"\"\"\n  }",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    ##remove any non-chr, coord lines in top of file\n    CHR=\\$(tail -n1 ${exome_bed} | perl -ane 'print \\$F[0];')\n    if [[ \\$CHR =~ \"chr\" ]]; then\n      perl -ane 'if(\\$F[0]=~m/^chr/){print \\$_;}' ${exome_bed} > ${params.exomeTag}.lo.bed\n    else\n      perl -ane 'if(\\$F[0]=~m/^[0-9MXY]/){print \\$_;}' ${exome_bed} > ${params.exomeTag}.lo.bed\n    fi\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "exome_parse_bed"
        ],
        "nb_inputs": 1,
        "outputs": [
            "exome_liftover"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "lift_over": {
        "name_process": "lift_over",
        "string_process": " process lift_over {\n\n    label 'low_mem'\n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n    tuple file(exome_bed), file(readme) from exome_liftover\n\n    output:\n    tuple file(\"${params.exomeTag}.lift.bed\"), file(readme) into exome_bed_liftd\n\n    script:\n    def hgTohg = params.exomeAssembly == \"GRCh38\" ? \"hg38ToHg19\" : \"hg19ToHg38\"\n    def hg = params.exomeAssembly == \"GRCh38\" ? \"hg38\" : \"hg19\"\n\n    if( params.assembly == params.exomeAssembly )\n      \"\"\"\n      cp ${exome_bed} ${params.exomeTag}.lift.bed\n      \"\"\"\n    else\n      \"\"\"\n      wget http://hgdownload.cse.ucsc.edu/goldenPath/${hg}/liftOver/${hgTohg}.over.chain.gz\n      liftOver ${exome_bed} ${hgTohg}.over.chain.gz ${params.exomeTag}.lift.bed unmapped\n\n      echo -r\"Liftover using:\\\\nwget http://hgdownload.cse.ucsc.edu/goldenPath/${hg}/liftOver/${hgTohg}.over.chain.gz\n      liftOver ${exome_bed} ${hgTohg}.over.chain.gz ${params.exomeTag}.lift.bed unmapped\" >> ${readme}\n      \"\"\"\n  }",
        "nb_lignes_process": 27,
        "string_script": "    def hgTohg = params.exomeAssembly == \"GRCh38\" ? \"hg38ToHg19\" : \"hg19ToHg38\"\n    def hg = params.exomeAssembly == \"GRCh38\" ? \"hg38\" : \"hg19\"\n\n    if( params.assembly == params.exomeAssembly )\n      \"\"\"\n      cp ${exome_bed} ${params.exomeTag}.lift.bed\n      \"\"\"\n    else\n      \"\"\"\n      wget http://hgdownload.cse.ucsc.edu/goldenPath/${hg}/liftOver/${hgTohg}.over.chain.gz\n      liftOver ${exome_bed} ${hgTohg}.over.chain.gz ${params.exomeTag}.lift.bed unmapped\n\n      echo -r\"Liftover using:\\\\nwget http://hgdownload.cse.ucsc.edu/goldenPath/${hg}/liftOver/${hgTohg}.over.chain.gz\n      liftOver ${exome_bed} ${hgTohg}.over.chain.gz ${params.exomeTag}.lift.bed unmapped\" >> ${readme}\n      \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "LiftOver"
        ],
        "tools_url": [
            "https://bio.tools/liftover"
        ],
        "tools_dico": [
            {
                "name": "LiftOver",
                "uri": "https://bio.tools/liftover",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This service converts genome coordinates and genome annotation files between assemblies.",
                "homepage": "http://api.bioinfo.no/wsdl/LiftOverService.wsdl"
            }
        ],
        "inputs": [
            "exome_liftover"
        ],
        "nb_inputs": 1,
        "outputs": [
            "exome_bed_liftd"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "exome_bed_pr": {
        "name_process": "exome_bed_pr",
        "string_process": " process exome_bed_pr {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}/exome/${params.exomeTag}\", mode: \"copy\", overwrite: \"true\"\n\n    input:\n    tuple file(fa), file(fai), file(dict) from fasta_dict_exome\n    tuple file(exome_lift), file(readme) from exome_bed_liftd\n\n    output:\n    file(\"${params.exomeTag}.bed.interval_list\") into complete_exome\n    file(\"${params.exomeTag}.bed\") into ( exome_biallgz, pcgrtoml_exome )\n    tuple file(\"${params.exomeTag}.bed.gz\"), file(\"${params.exomeTag}.bed.gz.tbi\") into gztbi_exome\n\n    script:\n    \"\"\"\n    ##must test if all chr in fasta are in exome, else manta cries\n    ##must test if all regions are greater than length zero or strelka cries\n    ##must test if all seq.dict chrs are in bed and only they or BedToIntervalList cries\n    perl -ane 'if(\\$F[1] == \\$F[2]){\\$F[2]++;} if(\\$F[0] !~m/^chrM/){print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";}' ${exome_lift} | grep -v chrM | sed 's/chr//g' > tmp.bed\n\n     grep @SQ ${dict} | cut -f2 | sed 's/SN://' | while read CHR; do\n     TESTCHR=\\$(awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed | wc -l)\n     if [[ \\$TESTCHR != 0 ]];then\n      awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed\n     fi\n    done >> tmp.dict.bed\n\n    ##always make interval list so we are in line with fasta\n    picard BedToIntervalList I=tmp.dict.bed O=${params.exomeTag}.interval_list SD=${dict}\n\n    ##BedToIntervalList (reason unknown) makes 1bp interval to 0bp interval, replace with original\n    perl -ane 'if(\\$F[0]=~m/^@/){print \\$_;next;} if(\\$F[1] == \\$F[2]){\\$f=\\$F[1]; \\$f--; \\$F[1]=\\$f; print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";} else{print \\$_;}' ${params.exomeTag}.interval_list > ${params.exomeTag}.bed.interval_list\n\n    ##output BED\n    grep -v \"@\" ${params.exomeTag}.bed.interval_list | cut -f 1,2,3,5 > ${params.exomeTag}.bed\n\n    ##tabix\n    bgzip -c ${params.exomeTag}.bed > ${params.exomeTag}.bed.gz\n    tabix ${params.exomeTag}.bed.gz\n    \"\"\"\n  }",
        "nb_lignes_process": 40,
        "string_script": "    \"\"\"\n    ##must test if all chr in fasta are in exome, else manta cries\n    ##must test if all regions are greater than length zero or strelka cries\n    ##must test if all seq.dict chrs are in bed and only they or BedToIntervalList cries\n    perl -ane 'if(\\$F[1] == \\$F[2]){\\$F[2]++;} if(\\$F[0] !~m/^chrM/){print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";}' ${exome_lift} | grep -v chrM | sed 's/chr//g' > tmp.bed\n\n     grep @SQ ${dict} | cut -f2 | sed 's/SN://' | while read CHR; do\n     TESTCHR=\\$(awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed | wc -l)\n     if [[ \\$TESTCHR != 0 ]];then\n      awk -v chrs=\\$CHR '\\$1 == chrs' tmp.bed\n     fi\n    done >> tmp.dict.bed\n\n    ##always make interval list so we are in line with fasta\n    picard BedToIntervalList I=tmp.dict.bed O=${params.exomeTag}.interval_list SD=${dict}\n\n    ##BedToIntervalList (reason unknown) makes 1bp interval to 0bp interval, replace with original\n    perl -ane 'if(\\$F[0]=~m/^@/){print \\$_;next;} if(\\$F[1] == \\$F[2]){\\$f=\\$F[1]; \\$f--; \\$F[1]=\\$f; print join(\"\\\\t\", @F[0..\\$#F]) . \"\\\\n\";} else{print \\$_;}' ${params.exomeTag}.interval_list > ${params.exomeTag}.bed.interval_list\n\n    ##output BED\n    grep -v \"@\" ${params.exomeTag}.bed.interval_list | cut -f 1,2,3,5 > ${params.exomeTag}.bed\n\n    ##tabix\n    bgzip -c ${params.exomeTag}.bed > ${params.exomeTag}.bed.gz\n    tabix ${params.exomeTag}.bed.gz\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "Picard",
            "NextSV"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools",
            "https://bio.tools/nextsv"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            }
        ],
        "inputs": [
            "fasta_dict_exome",
            "exome_bed_liftd"
        ],
        "nb_inputs": 2,
        "outputs": [
            "complete_exome",
            "",
            "gztbi_exome"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/exome/${params.exomeTag}\", mode: \"copy\", overwrite: \"true\""
        ],
        "when": "",
        "stub": ""
    },
    "exome_biall": {
        "name_process": "exome_biall",
        "string_process": " process exome_biall {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}/exome/${params.exomeTag}\", mode: \"copy\"\n\n    input:\n    file(exome_bed) from exome_biallgz\n    file(gnomad) from exome_biall_gnomad\n    tuple file(fasta), file(fai) from fasta_exome_biall\n\n    output:\n    tuple file(\"af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz\"), file(\"af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz.tbi\") into exome_biallelicgz\n\n    script:\n    hg = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n    if( params.assembly == \"GRCh37\" )\n      \"\"\"\n      cut -f 1,2,3 ${exome_bed} > exome.biall.bed\n      bgzip ${gnomad}\n      tabix ${gnomad}.gz\n      gunzip -c ${gnomad}.gz |\n      bcftools view -R exome.biall.bed ${gnomad}.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.${hg}.noChr.vcf\n      perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.hg19.noChr.vcf ${fai} > af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      bgzip af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      tabix af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz\n      \"\"\"\n    else\n      \"\"\"\n      cut -f 1,2,3 ${exome_bed} > exome.biall.bed\n      gunzip -c ${gnomad} | sed 's/chr//' | bgzip > af-only-gnomad.${hg}.noChr.vcf.gz\n      tabix af-only-gnomad.${hg}.noChr.vcf.gz\n      bcftools view -R exome.biall.bed af-only-gnomad.${hg}.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.${hg}.noChr.vcf\n      perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.${hg}.noChr.vcf ${fai} > af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      bgzip af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      tabix af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz\n      \"\"\"\n  }",
        "nb_lignes_process": 35,
        "string_script": "    hg = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n    if( params.assembly == \"GRCh37\" )\n      \"\"\"\n      cut -f 1,2,3 ${exome_bed} > exome.biall.bed\n      bgzip ${gnomad}\n      tabix ${gnomad}.gz\n      gunzip -c ${gnomad}.gz |\n      bcftools view -R exome.biall.bed ${gnomad}.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.${hg}.noChr.vcf\n      perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.hg19.noChr.vcf ${fai} > af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      bgzip af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      tabix af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz\n      \"\"\"\n    else\n      \"\"\"\n      cut -f 1,2,3 ${exome_bed} > exome.biall.bed\n      gunzip -c ${gnomad} | sed 's/chr//' | bgzip > af-only-gnomad.${hg}.noChr.vcf.gz\n      tabix af-only-gnomad.${hg}.noChr.vcf.gz\n      bcftools view -R exome.biall.bed af-only-gnomad.${hg}.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.exomerh.${hg}.noChr.vcf\n      perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.exomerh.${hg}.noChr.vcf ${fai} > af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      bgzip af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf\n      tabix af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz\n      \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "PHG",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/PHG",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "PHG",
                "uri": "https://bio.tools/PHG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3810",
                            "term": "Agricultural science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Practical Haplotype Graph (PHG) facilitates genome-wide imputation and cost-effective genomic prediction.\n\nSuccessful management and utilization of increasingly large genomic datasets are essential for breeding programs to increase genetic gain and accelerate cultivar development. To help with data management and storage, a sorghum Practical Haplotype Graph (PHG) pangenome database stores all identified haplotypes and variant information for a given set of individuals.",
                "homepage": "https://bitbucket.org/bucklerlab/p_sorghumphg/src/master"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "exome_biallgz",
            "exome_biall_gnomad",
            "fasta_exome_biall"
        ],
        "nb_inputs": 3,
        "outputs": [
            "exome_biallelicgz"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/exome/${params.exomeTag}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "send_pcgrtoml_exome": {
        "name_process": "send_pcgrtoml_exome",
        "string_process": " process send_pcgrtoml_exome {\n\n      label 'low_mem'\n\n      input:\n      file(exome_dir) from exome_chan\n\n      output:\n      file('exome.biall.bed') into pcgrtoml_exome\n\n      script:\n      \"\"\"\n      cut -f 1,2,3 ${exome_dir}/${params.exomeTag}.bed > exome.biall.bed\n      \"\"\"\n    }",
        "nb_lignes_process": 13,
        "string_script": "      \"\"\"\n      cut -f 1,2,3 ${exome_dir}/${params.exomeTag}.bed > exome.biall.bed\n      \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "exome_chan"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcgrtoml_exome"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "wgs_bed": {
        "name_process": "wgs_bed",
        "string_process": " process wgs_bed {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}/wgs\", mode: \"copy\"\n\n    input:\n    tuple file(fa), file(fai), file(dict) from fasta_dict_wgs\n\n    output:\n    file('wgs.bed.interval_list') into complete_wgs\n    file('wgs.bed') into (wgs_tabix, wgs_fasta_biallgz)\n    tuple file('wgs.bed.gz'), file('wgs.bed.gz.tbi') into gztbi_wgs\n\n    script:\n    \"\"\"\n    ##WGS intervals = 1-LN for each chr\n    grep @SQ ${dict} | cut -f 2,3 | perl -ane '\\$chr=\\$F[0];\\$chr=~s/SN://;\\$end=\\$F[1];\\$end=~s/LN://;print \"\\$chr\\\\t0\\\\t\\$end\\\\n\";' > tmp.wgs.dict.bed\n\n    ##always make interval list so we are in line with fasta\n    picard BedToIntervalList I=tmp.wgs.dict.bed O=wgs.bed.interval_list SD=${dict}\n\n    ##output BED\n    grep -v \"@\" wgs.bed.interval_list | cut -f 1,2,3,5 > wgs.bed\n\n    ##tabix\n    bgzip -c wgs.bed > wgs.bed.gz\n    tabix wgs.bed.gz\n    \"\"\"\n  }",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    ##WGS intervals = 1-LN for each chr\n    grep @SQ ${dict} | cut -f 2,3 | perl -ane '\\$chr=\\$F[0];\\$chr=~s/SN://;\\$end=\\$F[1];\\$end=~s/LN://;print \"\\$chr\\\\t0\\\\t\\$end\\\\n\";' > tmp.wgs.dict.bed\n\n    ##always make interval list so we are in line with fasta\n    picard BedToIntervalList I=tmp.wgs.dict.bed O=wgs.bed.interval_list SD=${dict}\n\n    ##output BED\n    grep -v \"@\" wgs.bed.interval_list | cut -f 1,2,3,5 > wgs.bed\n\n    ##tabix\n    bgzip -c wgs.bed > wgs.bed.gz\n    tabix wgs.bed.gz\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "fasta_dict_wgs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_wgs",
            "",
            "gztbi_wgs"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/wgs\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "wgs_biall": {
        "name_process": "wgs_biall",
        "string_process": " process wgs_biall {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}/wgs\", mode: \"copy\"\n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n    file(wgsbed) from wgs_fasta_biallgz\n    file(gnomadgz) from wgs_biall_gnomad\n    tuple file(fasta), file(fai) from fasta_wgs_biall\n\n    output:\n    tuple file(\"af-only-gnomad.wgs.${hg}.noChr.vcf.gz\"), file(\"af-only-gnomad.wgs.${hg}.noChr.vcf.gz.tbi\") into wgs_biallelicgz\n    file('wgs.biall.bed') into pcgrtoml_wgs\n\n    script:\n    hg = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n    \"\"\"\n    cut -f 1,2,3 ${wgsbed} > wgs.biall.bed\n    gunzip -c ${gnomadgz} | sed 's/chr//' | bgzip > af-only-gnomad.${hg}.noChr.vcf.gz\n    tabix af-only-gnomad.${hg}.noChr.vcf.gz\n\n    bcftools view -R wgs.biall.bed af-only-gnomad.${hg}.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.wgsh.${hg}.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.wgsh.${hg}.noChr.vcf ${fai} > af-only-gnomad.wgs.${hg}.noChr.vcf\n    bgzip af-only-gnomad.wgs.${hg}.noChr.vcf\n    tabix af-only-gnomad.wgs.${hg}.noChr.vcf.gz\n    \"\"\"\n  }",
        "nb_lignes_process": 27,
        "string_script": "    hg = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n    \"\"\"\n    cut -f 1,2,3 ${wgsbed} > wgs.biall.bed\n    gunzip -c ${gnomadgz} | sed 's/chr//' | bgzip > af-only-gnomad.${hg}.noChr.vcf.gz\n    tabix af-only-gnomad.${hg}.noChr.vcf.gz\n\n    bcftools view -R wgs.biall.bed af-only-gnomad.${hg}.noChr.vcf.gz | bcftools sort -T '.' > af-only-gnomad.wgsh.${hg}.noChr.vcf\n    perl ${workflow.projectDir}/bin/reheader_vcf_fai.pl af-only-gnomad.wgsh.${hg}.noChr.vcf ${fai} > af-only-gnomad.wgs.${hg}.noChr.vcf\n    bgzip af-only-gnomad.wgs.${hg}.noChr.vcf\n    tabix af-only-gnomad.wgs.${hg}.noChr.vcf.gz\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "PHG",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/PHG",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "PHG",
                "uri": "https://bio.tools/PHG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3810",
                            "term": "Agricultural science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Practical Haplotype Graph (PHG) facilitates genome-wide imputation and cost-effective genomic prediction.\n\nSuccessful management and utilization of increasingly large genomic datasets are essential for breeding programs to increase genetic gain and accelerate cultivar development. To help with data management and storage, a sorghum Practical Haplotype Graph (PHG) pangenome database stores all identified haplotypes and variant information for a given set of individuals.",
                "homepage": "https://bitbucket.org/bucklerlab/p_sorghumphg/src/master"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "wgs_fasta_biallgz",
            "wgs_biall_gnomad",
            "fasta_wgs_biall"
        ],
        "nb_inputs": 3,
        "outputs": [
            "wgs_biallelicgz",
            "pcgrtoml_wgs"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/wgs\", mode: \"copy\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "send_pcgrtoml_wgs": {
        "name_process": "send_pcgrtoml_wgs",
        "string_process": " process send_pcgrtoml_wgs {\n\n      label 'low_mem'\n\n      input:\n      file(wgs_dir) from wgs_chan\n\n      output:\n      file('wgs.biall.bed') into pcgrtoml_wgs\n\n      script:\n      \"\"\"\n      cut -f 1,2,3 wgs/wgs.bed > wgs.biall.bed\n      \"\"\"\n    }",
        "nb_lignes_process": 13,
        "string_script": "      \"\"\"\n      cut -f 1,2,3 wgs/wgs.bed > wgs.biall.bed\n      \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "wgs_chan"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcgrtoml_wgs"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "pcgr_data": {
        "name_process": "pcgr_data",
        "string_process": " process pcgr_data {\n\n      label 'low_mem'\n      errorStrategy 'retry'\n      maxRetries 3\n\n      output:\n      file(\"*tgz\") into pcgr_data\n\n      script:\n      downloadURL = params.assembly == \"GRCh37\" ? \"${params.pcgrURL37}\" : \"${params.pcgrURL38}\"\n      \"\"\"\n      wget ${downloadURL}\n      \"\"\"\n    }",
        "nb_lignes_process": 13,
        "string_script": "      downloadURL = params.assembly == \"GRCh37\" ? \"${params.pcgrURL37}\" : \"${params.pcgrURL38}\"\n      \"\"\"\n      wget ${downloadURL}\n      \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "pcgr_data"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "pcgr_vep": {
        "name_process": "pcgr_vep",
        "string_process": " process pcgr_vep {\n\n    label 'low_mem'\n    publishDir \"${params.outDir}/pcgr\", mode: \"copy\", pattern: \"data\"\n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n    file(exomebed) from pcgrtoml_exome\n    file(wgsbed) from pcgrtoml_wgs\n    file(tgz) from pcgr_data\n\n    output:\n    file('data') into pcgrdata\n\n    script:\n    exometag = params.exomeTag == null ? \"\" : \"${params.exomeTag}\"\n    \"\"\"\n    tar -xf ${tgz} -C ./\n\n    ##allows editting of TOML for WGS and exome if supplied\n    sh ${workflow.projectDir}/bin/pcgr_edit_toml.sh \\\n      data/${params.assemblylc}/pcgr_configuration_default.toml \\\n      ${exomebed} ${exometag}\n    mv pcgr_configuration*.toml data/${params.assemblylc}/\n\n    ##build VEP cache using Singularity container 'vep_install' script\n    ##however PCGR installs a version of vep cache, so test that matches required assembly, and only install if not\n    ##required version is the VEP_INSTALL version in container\n\n    ##variables for install and test\n    VEP_INSTALL=\\$(find /opt/miniconda/envs/somatic_n-of-1/share/*/vep_install)\n    VEP_INSTVER=\\$(echo \\$VEP_INSTALL | perl -ane '@s=split(/\\\\//, \\$F[0]); foreach \\$k (@s){ if(\\$k =~m/ensembl-vep/){@o=split(/[-.]/, \\$k); print \\$o[2];}}')\n    VEP_PCGRVER=\\$(cat data/${params.assemblylc}/RELEASE_NOTES | perl -ane 'if(\\$F[0] eq \"VEP\"){@s=split(/\\\\./,\\$F[5]); \\$v=\\$s[0]; \\$v=~s/v//; print \\$v;}')\n\n    if [[ \\$VEP_INSTVER != \\$VEP_PCGRVER ]];then\n\n      ##remove current and reinstall correct version\n      \\$VEP_INSTALL \\\n        --AUTO cf \\\n        --CACHE_VERSION \\$VEP_INSTVER \\\n        --CACHEDIR \"data/${params.assemblylc}/.vep/\" \\\n        --SPECIES \"homo_sapiens\" \\\n        --ASSEMBLY ${params.assembly} \\\n        --NO_UPDATE \\\n        --NO_HTSLIB \\\n        --NO_BIOPERL \\\n        --NO_TEST\n    fi\n    \"\"\"\n  }",
        "nb_lignes_process": 49,
        "string_script": "    exometag = params.exomeTag == null ? \"\" : \"${params.exomeTag}\"\n    \"\"\"\n    tar -xf ${tgz} -C ./\n\n    ##allows editting of TOML for WGS and exome if supplied\n    sh ${workflow.projectDir}/bin/pcgr_edit_toml.sh \\\n      data/${params.assemblylc}/pcgr_configuration_default.toml \\\n      ${exomebed} ${exometag}\n    mv pcgr_configuration*.toml data/${params.assemblylc}/\n\n    ##build VEP cache using Singularity container 'vep_install' script\n    ##however PCGR installs a version of vep cache, so test that matches required assembly, and only install if not\n    ##required version is the VEP_INSTALL version in container\n\n    ##variables for install and test\n    VEP_INSTALL=\\$(find /opt/miniconda/envs/somatic_n-of-1/share/*/vep_install)\n    VEP_INSTVER=\\$(echo \\$VEP_INSTALL | perl -ane '@s=split(/\\\\//, \\$F[0]); foreach \\$k (@s){ if(\\$k =~m/ensembl-vep/){@o=split(/[-.]/, \\$k); print \\$o[2];}}')\n    VEP_PCGRVER=\\$(cat data/${params.assemblylc}/RELEASE_NOTES | perl -ane 'if(\\$F[0] eq \"VEP\"){@s=split(/\\\\./,\\$F[5]); \\$v=\\$s[0]; \\$v=~s/v//; print \\$v;}')\n\n    if [[ \\$VEP_INSTVER != \\$VEP_PCGRVER ]];then\n\n      ##remove current and reinstall correct version\n      \\$VEP_INSTALL \\\n        --AUTO cf \\\n        --CACHE_VERSION \\$VEP_INSTVER \\\n        --CACHEDIR \"data/${params.assemblylc}/.vep/\" \\\n        --SPECIES \"homo_sapiens\" \\\n        --ASSEMBLY ${params.assembly} \\\n        --NO_UPDATE \\\n        --NO_HTSLIB \\\n        --NO_BIOPERL \\\n        --NO_TEST\n    fi\n    \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "RASH"
        ],
        "tools_url": [
            "https://bio.tools/RASH"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            }
        ],
        "inputs": [
            "pcgrtoml_exome",
            "pcgrtoml_wgs",
            "pcgr_data"
        ],
        "nb_inputs": 3,
        "outputs": [
            "pcgrdata"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/pcgr\", mode: \"copy\", pattern: \"data\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "hartwigmed": {
        "name_process": "hartwigmed",
        "string_process": " process hartwigmed {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}/gridss\", mode: \"copy\"\n\n    input:\n    file(fai) from fai_gridss\n\n    output:\n    file('dbs') into gridss_db\n    file('refgenomes/human_virus') into gridss_hv\n    file('gridss_blacklist.noChr.bed') into gridss_bl\n    file('dbs/gridss/gridss.properties') into gridss_pr\n\n    script:\n    if( params.assembly == \"GRCh37\" )\n      \"\"\"\n      wget --content-disposition https://nextcloud.hartwigmedicalfoundation.nl/s/LTiKTd8XxBqwaiC/download?path=%2FHMFTools-Resources%2FGRIDSS-Purple-Linx-Docker\n\n      7z x GRIDSS-Purple-Linx-Docker.zip\n      mv GRIDSS-Purple-Linx-Docker/gpl_ref_data_37.gz gpl_ref_data_hg37.tar.gz\n      tar -xf gpl_ref_data_hg37.tar.gz\n      rm -rf GRIDSS-Purple-Linx-Docker.zip GRIDSS-Purple-Linx-Docker gpl_ref_data_hg37.tar.gz\n\n      ##blacklist\n      sed 's/chr//g' dbs/gridss/ENCFF001TDO.bed > gridss_blacklist.noChr.bed\n\n      perl ${workflow.projectDir}/bin/exact_match_by_col.pl ${fai},0 gridss_blacklist.noChr.bed,0 > gridss_blacklist.noChr.1.bed\n      mv gridss_blacklist.noChr.1.bed gridss_blacklist.noChr.bed\n      \"\"\"\n    else\n      \"\"\"\n      wget --content-disposition https://nextcloud.hartwigmedicalfoundation.nl/s/LTiKTd8XxBqwaiC/download?path=%2FHMFTools-Resources%2FGRIDSS-Purple-Linx-Docker\n\n      7z x GRIDSS-Purple-Linx-Docker.zip\n      mv GRIDSS-Purple-Linx-Docker/gpl_ref_data_38.gz gpl_ref_data_hg38.tar.gz\n      tar -xf gpl_ref_data_hg38.tar.gz\n      rm -rf GRIDSS-Purple-Linx-Docker.zip GRIDSS-Purple-Linx-Docker gpl_ref_data_hg38.tar.gz\n\n      ##blacklist\n      sed 's/chr//g' dbs/gridss/ENCFF001TDO.bed > gridss_blacklist.noChr.bed\n      perl ${workflow.projectDir}/bin/exact_match_by_col.pl ${fai},0 gridss_blacklist.noChr.bed,0 > gridss_blacklist.noChr.1.bed\n      mv gridss_blacklist.noChr.1.bed gridss_blacklist.noChr.bed\n      \"\"\"\n  }",
        "nb_lignes_process": 43,
        "string_script": "    if( params.assembly == \"GRCh37\" )\n      \"\"\"\n      wget --content-disposition https://nextcloud.hartwigmedicalfoundation.nl/s/LTiKTd8XxBqwaiC/download?path=%2FHMFTools-Resources%2FGRIDSS-Purple-Linx-Docker\n\n      7z x GRIDSS-Purple-Linx-Docker.zip\n      mv GRIDSS-Purple-Linx-Docker/gpl_ref_data_37.gz gpl_ref_data_hg37.tar.gz\n      tar -xf gpl_ref_data_hg37.tar.gz\n      rm -rf GRIDSS-Purple-Linx-Docker.zip GRIDSS-Purple-Linx-Docker gpl_ref_data_hg37.tar.gz\n\n      ##blacklist\n      sed 's/chr//g' dbs/gridss/ENCFF001TDO.bed > gridss_blacklist.noChr.bed\n\n      perl ${workflow.projectDir}/bin/exact_match_by_col.pl ${fai},0 gridss_blacklist.noChr.bed,0 > gridss_blacklist.noChr.1.bed\n      mv gridss_blacklist.noChr.1.bed gridss_blacklist.noChr.bed\n      \"\"\"\n    else\n      \"\"\"\n      wget --content-disposition https://nextcloud.hartwigmedicalfoundation.nl/s/LTiKTd8XxBqwaiC/download?path=%2FHMFTools-Resources%2FGRIDSS-Purple-Linx-Docker\n\n      7z x GRIDSS-Purple-Linx-Docker.zip\n      mv GRIDSS-Purple-Linx-Docker/gpl_ref_data_38.gz gpl_ref_data_hg38.tar.gz\n      tar -xf gpl_ref_data_hg38.tar.gz\n      rm -rf GRIDSS-Purple-Linx-Docker.zip GRIDSS-Purple-Linx-Docker gpl_ref_data_hg38.tar.gz\n\n      ##blacklist\n      sed 's/chr//g' dbs/gridss/ENCFF001TDO.bed > gridss_blacklist.noChr.bed\n      perl ${workflow.projectDir}/bin/exact_match_by_col.pl ${fai},0 gridss_blacklist.noChr.bed,0 > gridss_blacklist.noChr.1.bed\n      mv gridss_blacklist.noChr.1.bed gridss_blacklist.noChr.bed\n      \"\"\"",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fai_gridss"
        ],
        "nb_inputs": 1,
        "outputs": [
            "gridss_db",
            "gridss_hv",
            "gridss_bl",
            "gridss_pr"
        ],
        "nb_outputs": 4,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/gridss\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "cosmic": {
        "name_process": "cosmic",
        "string_process": " process cosmic {\n\n    publishDir \"${params.outDir}/cosmic\", mode: 'copy'\n\n    when:\n    params.cosmicUser && params.cosmicPass\n\n    output:\n    file 'cancer_gene_census.*'\n\n    script:\n    \"\"\"\n    ##README to show date of download\n    echo \\$(date) > cosmic_cancer-gene-census_dl.README.txt\n\n    ##https://cancer.sanger.ac.uk/cosmic/help/file_download\n    curl -H \"Authorization: Basic \\$(echo ${params.cosmicUser}:${params.cosmicPass} | base64)\" https://cancer.sanger.ac.uk/cosmic/file_download/${params.assembly}/cosmic/${params.cosmicVers}/cancer_gene_census.csv > url.txt\n\n    URL=\\$(cut -d '\"' -f4 url.txt)\n    curl -o cancer_gene_census.csv \\$URL\n\n    ##parse into BED format (many thanks for comma in 'Name' field NOT)\n    tail -n+2 cancer_gene_census.csv | \\\\\n    perl -ane '@s=split(/\\\\,/);\n               foreach \\$k (@s){\n                 if(\\$k=~m/\\\\d+:\\\\d+-\\\\d+/){\n                     @p=split(/[:-]/, \\$k);\n                     if(\\$s[-2]=~/^ENS/){\n                       \\$ens=\\$s[-2];\n                     }\n                     if(\\$s[-3]=~/^ENS/){\n                       \\$ens=\\$s[-3];\n                     }\n                 print \"\\$p[0]\\\\t\\$p[1]\\\\t\\$p[2]\\\\t\\$s[0];\\$ens\\\\n\"; next;\n               }};' | sort -V > cancer_gene_census.bed\n\n    \"\"\"\n  }",
        "nb_lignes_process": 36,
        "string_script": "    \"\"\"\n    ##README to show date of download\n    echo \\$(date) > cosmic_cancer-gene-census_dl.README.txt\n\n    ##https://cancer.sanger.ac.uk/cosmic/help/file_download\n    curl -H \"Authorization: Basic \\$(echo ${params.cosmicUser}:${params.cosmicPass} | base64)\" https://cancer.sanger.ac.uk/cosmic/file_download/${params.assembly}/cosmic/${params.cosmicVers}/cancer_gene_census.csv > url.txt\n\n    URL=\\$(cut -d '\"' -f4 url.txt)\n    curl -o cancer_gene_census.csv \\$URL\n\n    ##parse into BED format (many thanks for comma in 'Name' field NOT)\n    tail -n+2 cancer_gene_census.csv | \\\\\n    perl -ane '@s=split(/\\\\,/);\n               foreach \\$k (@s){\n                 if(\\$k=~m/\\\\d+:\\\\d+-\\\\d+/){\n                     @p=split(/[:-]/, \\$k);\n                     if(\\$s[-2]=~/^ENS/){\n                       \\$ens=\\$s[-2];\n                     }\n                     if(\\$s[-3]=~/^ENS/){\n                       \\$ens=\\$s[-3];\n                     }\n                 print \"\\$p[0]\\\\t\\$p[1]\\\\t\\$p[2]\\\\t\\$s[0];\\$ens\\\\n\"; next;\n               }};' | sort -V > cancer_gene_census.bed\n\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "CURLS",
            "NextSV"
        ],
        "tools_url": [
            "https://bio.tools/CURLS",
            "https://bio.tools/nextsv"
        ],
        "tools_dico": [
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            },
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "publishDir \"${params.outDir}/cosmic\", mode: 'copy'"
        ],
        "when": "params.cosmicUser && params.cosmicPass",
        "stub": ""
    },
    "seqnza": {
        "name_process": "seqnza",
        "string_process": " process seqnza {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}\", mode: \"copy\"\n\n    input:\n    set file(fa), file(fai) from fasta_seqza\n\n    output:\n    file('*') into sequenzaout\n\n    script:\n    \"\"\"\n    GENOMEGC50GZ=\\$(echo ${fa} | sed -r 's/.fasta/.gc50Base.txt.gz/')\n    sequenza\u2212utils.py GC-windows \u2212w 50 ${fa} | gzip > \\$GENOMEGC50GZ\n    \"\"\"\n  }",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    GENOMEGC50GZ=\\$(echo ${fa} | sed -r 's/.fasta/.gc50Base.txt.gz/')\n    sequenza\u2212utils.py GC-windows \u2212w 50 ${fa} | gzip > \\$GENOMEGC50GZ\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_seqza"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sequenzaout"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "msisen": {
        "name_process": "msisen",
        "string_process": " process msisen {\n\n    label 'low_mem'\n    publishDir \"${params.outDir}\", mode: \"copy\"\n\n    input:\n    set file(fa), file(fai) from fasta_msi\n\n    output:\n    file('*') into completedmsisensor\n\n    script:\n    \"\"\"\n    msisensor scan -d $fa -o msisensor_microsatellites.list\n    \"\"\"\n  }",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    msisensor scan -d $fa -o msisensor_microsatellites.list\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MSIsensor"
        ],
        "tools_url": [
            "https://bio.tools/msisensor"
        ],
        "tools_dico": [
            {
                "name": "MSIsensor",
                "uri": "https://bio.tools/msisensor",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Nucleic acid feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Sequence feature detection (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "C++ program for automatically detecting somatic and germline variants at microsatellite regions. It computes length distributions of microsatellites per site in paired tumor and normal sequence data, subsequently using these to statistically compare observed distributions in both samples.",
                "homepage": "https://github.com/ding-lab/msisensor"
            }
        ],
        "inputs": [
            "fasta_msi"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completedmsisensor"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "gensizxml": {
        "name_process": "gensizxml",
        "string_process": " process gensizxml {\n\n    label 'low_mem'\n    publishDir \"${params.outDir}\", mode: \"copy\"\n\n    input:\n    set file(fa), file(fai), file(dict) from fasta_dict_gensiz\n\n    output:\n    file('*') into complete_gensiz\n\n    script:\n    \"\"\"\n    echo \"<sequenceSizes genomeName=\\\"${dict}\\\">\" > GenomeSize.xml\n    grep \"@SQ\" ${dict} | while read LINE; do\n      CONTIGNAME=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[1]);print \\$s[1];' | sed 's/chr//')\n      TOTALBASES=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[2]);print \\$s[1];')\n      MD5SUM=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[3]);print \\$s[1];')\n      echo -e \"\\\\t<chromosome fileName=\\\"${fa}\\\" contigName=\\\"\\$CONTIGNAME\\\" totalBases=\\\"\\$TOTALBASES\\\" isCircular=\\\"false\\\" md5=\\\"\\$MD5SUM\\\" ploidy=\\\"2\\\" knownBases=\\\"\\$TOTALBASES\\\" type=\\\"Chromosome\\\" />\" >> GenomeSize.xml\n    done\n    echo \"</sequenceSizes>\" >> GenomeSize.xml\n    \"\"\"\n  }",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    echo \"<sequenceSizes genomeName=\\\"${dict}\\\">\" > GenomeSize.xml\n    grep \"@SQ\" ${dict} | while read LINE; do\n      CONTIGNAME=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[1]);print \\$s[1];' | sed 's/chr//')\n      TOTALBASES=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[2]);print \\$s[1];')\n      MD5SUM=\\$(echo \\$LINE | perl -ane '@s=split(/:/,\\$F[3]);print \\$s[1];')\n      echo -e \"\\\\t<chromosome fileName=\\\"${fa}\\\" contigName=\\\"\\$CONTIGNAME\\\" totalBases=\\\"\\$TOTALBASES\\\" isCircular=\\\"false\\\" md5=\\\"\\$MD5SUM\\\" ploidy=\\\"2\\\" knownBases=\\\"\\$TOTALBASES\\\" type=\\\"Chromosome\\\" />\" >> GenomeSize.xml\n    done\n    echo \"</sequenceSizes>\" >> GenomeSize.xml\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_dict_gensiz"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_gensiz"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "dict_pr2": {
        "name_process": "dict_pr2",
        "string_process": " process dict_pr2 {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}\", mode: \"copy\"\n\n    input:\n    file(win_dict) from dict_win\n\n    output:\n    file('*') into complete_dict\n\n    script:\n    \"\"\"\n    perl -ane 'if(\\$F[0]=~m/SQ\\$/){@sc=split(/:/,\\$F[1]);@ss=split(/:/,\\$F[2]); if(\\$sc[1]!~m/[GLMT]/){ print \"\\$sc[1]\\\\t\\$ss[1]\\\\n\";}}' ${win_dict} > seq.dict.chr-size\n\n    bedtools makewindows -g seq.dict.chr-size -w 35000000 | perl -ane 'if(\\$F[1]==0){\\$F[1]++;};print \"\\$F[0]:\\$F[1]-\\$F[2]\\n\";' > 35MB-window.bed\n    \"\"\"\n  }",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    perl -ane 'if(\\$F[0]=~m/SQ\\$/){@sc=split(/:/,\\$F[1]);@ss=split(/:/,\\$F[2]); if(\\$sc[1]!~m/[GLMT]/){ print \"\\$sc[1]\\\\t\\$ss[1]\\\\n\";}}' ${win_dict} > seq.dict.chr-size\n\n    bedtools makewindows -g seq.dict.chr-size -w 35000000 | perl -ane 'if(\\$F[1]==0){\\$F[1]++;};print \"\\$F[0]:\\$F[1]-\\$F[2]\\n\";' > 35MB-window.bed\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "dict_win"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_dict"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "ascat_loci": {
        "name_process": "ascat_loci",
        "string_process": " process ascat_loci {\n\n    label 'low_mem'\n    publishDir path: \"${params.outDir}\", mode: \"copy\"\n\n    input:\n    file(vcf) from ascatloci\n\n    output:\n    file('*loci') into complete_ascat\n\n    script:\n    \"\"\"\n    LOCIFILE=\\$(echo ${vcf} | sed 's/vcf/maf0.3.loci/')\n    cat ${vcf} | \\\n    perl -ane '@s=split(/[=\\\\;]/,\\$F[7]);if(\\$s[3]>0.3){print \"\\$F[0]\\\\t\\$F[1]\\\\n\";}' > \\$LOCIFILE\n    \"\"\"\n  }",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    LOCIFILE=\\$(echo ${vcf} | sed 's/vcf/maf0.3.loci/')\n    cat ${vcf} | \\\n    perl -ane '@s=split(/[=\\\\;]/,\\$F[7]);if(\\$s[3]>0.3){print \"\\$F[0]\\\\t\\$F[1]\\\\n\";}' > \\$LOCIFILE\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ascatloci"
        ],
        "nb_inputs": 1,
        "outputs": [
            "complete_ascat"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "samplecat": {
        "name_process": "samplecat",
        "string_process": " process samplecat {\n\n    label 'low_mem'\n    publishDir \"${params.outDir}/samples/${sampleID}/cat\", mode: \"copy\"\n\n    input:\n    tuple val(type), val(sampleID), val(meta), val(dir), val(ext) from samplecating\n\n    output:\n    tuple val(type), val(sampleID), val(meta), file(read1), file(read2) into bbduking\n\n    script:\n    rd1ext = \"${ext}\".split(';')[0]\n    rd2ext = \"${ext}\".split(';')[1]\n    read1 = \"${sampleID}.R1.fastq.gz\"\n    read2 = \"${sampleID}.R2.fastq.gz\"\n    \"\"\"\n    #! bash\n    cat \\$(find ${dir} | grep ${rd1ext} | sort) > ${read1}\n    cat \\$(find ${dir} | grep ${rd2ext} | sort) > ${read2}\n    \"\"\"\n  }",
        "nb_lignes_process": 20,
        "string_script": "    rd1ext = \"${ext}\".split(';')[0]\n    rd2ext = \"${ext}\".split(';')[1]\n    read1 = \"${sampleID}.R1.fastq.gz\"\n    read2 = \"${sampleID}.R2.fastq.gz\"\n    \"\"\"\n    #! bash\n    cat \\$(find ${dir} | grep ${rd1ext} | sort) > ${read1}\n    cat \\$(find ${dir} | grep ${rd2ext} | sort) > ${read2}\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplecating"
        ],
        "nb_inputs": 1,
        "outputs": [
            "bbduking"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/samples/${sampleID}/cat\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "bbduk": {
        "name_process": "bbduk",
        "string_process": "\nprocess bbduk {\n\n  label 'med_mem'\n  publishDir path: \"${params.outDir}/samples/${sampleID}/bbduk\", mode: \"copy\", pattern: \"*.txt\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) from bbduking\n\n  output:\n  file('*.txt') into log_bbduk\n  tuple val(type), val(sampleID), val(meta), file('*.bbduk.R1.fastq.gz'), file('*.bbduk.R2.fastq.gz') into bwa_memming\n  tuple val(type), val(sampleID), val(meta), file('*.bbduk.R1.fastq.gz'), file('*.bbduk.R2.fastq.gz'), file(read1), file(read2) into fastping\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) into fastqcing\n\n  script:\n  def taskmem = task.memory == null ? \"\" : \"-Xmx\" + javaTaskmem(\"${task.memory}\")\n  \"\"\"\n  {\n  sh bbduk.sh ${taskmem} \\\n    in1=${read1} \\\n    in2=${read2} \\\n    out1=${sampleID}\".bbduk.R1.fastq.gz\" \\\n    out2=${sampleID}\".bbduk.R2.fastq.gz\" \\\n    k=31 \\\n    mink=5 \\\n    hdist=1 \\\n    ktrim=r \\\n    trimq=20 \\\n    qtrim=rl \\\n    maq=20 \\\n    ref=/opt/miniconda/envs/somatic_n-of-1/opt/bbmap-adapters.fa \\\n    tpe \\\n    tbo \\\n    stats=${sampleID}\".bbduk.adapterstats.txt\" \\\n    overwrite=T\n  } 2>&1 | tee > ${sampleID}.bbduk.runstats.txt\n  \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "  def taskmem = task.memory == null ? \"\" : \"-Xmx\" + javaTaskmem(\"${task.memory}\")\n  \"\"\"\n  {\n  sh bbduk.sh ${taskmem} \\\n    in1=${read1} \\\n    in2=${read2} \\\n    out1=${sampleID}\".bbduk.R1.fastq.gz\" \\\n    out2=${sampleID}\".bbduk.R2.fastq.gz\" \\\n    k=31 \\\n    mink=5 \\\n    hdist=1 \\\n    ktrim=r \\\n    trimq=20 \\\n    qtrim=rl \\\n    maq=20 \\\n    ref=/opt/miniconda/envs/somatic_n-of-1/opt/bbmap-adapters.fa \\\n    tpe \\\n    tbo \\\n    stats=${sampleID}\".bbduk.adapterstats.txt\" \\\n    overwrite=T\n  } 2>&1 | tee > ${sampleID}.bbduk.runstats.txt\n  \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "RASH",
            "TPES",
            "NetBox"
        ],
        "tools_url": [
            "https://bio.tools/RASH",
            "https://bio.tools/TPES",
            "https://bio.tools/netbox"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            },
            {
                "name": "TPES",
                "uri": "https://bio.tools/TPES",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tumor Purity Estimation from SNVs.",
                "homepage": "https://bitbucket.org/l0ka/tpes.git"
            },
            {
                "name": "NetBox",
                "uri": "https://bio.tools/netbox",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2259",
                            "term": "Systems biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2497",
                                    "term": "Pathway or network analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NetBox is a Java-based software tool for performing network analysis on human interaction networks. It is pre-loaded with a Human Interaction Network (HIN) derived from four literature curated data sources, including the Human Protein Reference Database (HPRD), Reactome, NCI-Nature Pathway Interaction (PID) Database, and the MSKCC Cancer Cell Map.",
                "homepage": "http://cbio.mskcc.org/tools/netbox/index.html"
            }
        ],
        "inputs": [
            "bbduking"
        ],
        "nb_inputs": 1,
        "outputs": [
            "log_bbduk",
            "bwa_memming",
            "fastping",
            "fastqcing"
        ],
        "nb_outputs": 4,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/bbduk\", mode: \"copy\", pattern: \"*.txt\""
        ],
        "when": "",
        "stub": ""
    },
    "fastp": {
        "name_process": "fastp",
        "string_process": "\nprocess fastp {\n\n  label 'low_mem'\n  publishDir \"${params.outDir}/samples/${sampleID}/fastp\", mode: \"copy\", pattern: \"*.html\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(preread1), file(preread2), file(postread1), file(postread2) from fastping\n\n  output:\n  file('*.html') into fastp_html\n  file('*.json') into fastp_multiqc\n\n  script:\n  \"\"\"\n  fastp -w ${task.cpus} -h ${sampleID}\"_pre.fastp.html\" -j ${sampleID}\"_pre.fastp.json\" --in1 ${preread1} --in2 ${preread2}\n\n  fastp -w ${task.cpus} -h ${sampleID}\"_post.fastp.html\" -j ${sampleID}\"_post.fastp.json\" --in1 ${postread1} --in2 ${postread2}\n  \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "  \"\"\"\n  fastp -w ${task.cpus} -h ${sampleID}\"_pre.fastp.html\" -j ${sampleID}\"_pre.fastp.json\" --in1 ${preread1} --in2 ${preread2}\n\n  fastp -w ${task.cpus} -h ${sampleID}\"_post.fastp.html\" -j ${sampleID}\"_post.fastp.json\" --in1 ${postread1} --in2 ${postread2}\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "fastping"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastp_html",
            "fastp_multiqc"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/samples/${sampleID}/fastp\", mode: \"copy\", pattern: \"*.html\""
        ],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n\n  label 'low_mem'\n  publishDir \"${params.outDir}/samples/${sampleID}/fastqc\", mode: \"copy\", pattern: \"*.html\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) from fastqcing\n\n  output:\n  file('*.html') into fastqc_multiqc\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  fastqc -t ${task.cpus} --noextract -o ./ ${read1} ${read2}\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  fastqc -t ${task.cpus} --noextract -o ./ ${read1} ${read2}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "fastqcing"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_multiqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/samples/${sampleID}/fastqc\", mode: \"copy\", pattern: \"*.html\""
        ],
        "when": "",
        "stub": ""
    },
    "bwamem": {
        "name_process": "bwamem",
        "string_process": "\nprocess bwamem {\n\n  label 'high_mem'\n  errorStrategy 'retry'\n  maxRetries 3\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) from bwa_memming\n  file(bwa) from reference.bwa\n\n  output:\n  tuple val(type), val(sampleID), val(meta), file('*.bam'), file('*.bai') into (cramming, dup_marking)\n\n  script:\n  def fa = \"${bwa}/*fasta\"\n  \"\"\"\n  DATE=\\$(date +\"%Y-%m-%dT%T\")\n  RGLINE=\"@RG\\\\tID:${sampleID}\\\\tPL:ILLUMINA\\\\tSM:${sampleID}\\\\tDS:${type}\\\\tCN:UCD\\\\tLB:LANE_X\\\\tDT:\\$DATE\"\n\n  bwa mem \\\n    -t${task.cpus} \\\n    -M \\\n    -R \\$RGLINE \\\n    ${fa} \\\n    ${read1} ${read2} | \\\n    samtools sort -T \"tmp.\"${sampleID} -o ${sampleID}\".sort.bam\"\n  samtools index ${sampleID}\".sort.bam\"\n  \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "  def fa = \"${bwa}/*fasta\"\n  \"\"\"\n  DATE=\\$(date +\"%Y-%m-%dT%T\")\n  RGLINE=\"@RG\\\\tID:${sampleID}\\\\tPL:ILLUMINA\\\\tSM:${sampleID}\\\\tDS:${type}\\\\tCN:UCD\\\\tLB:LANE_X\\\\tDT:\\$DATE\"\n\n  bwa mem \\\n    -t${task.cpus} \\\n    -M \\\n    -R \\$RGLINE \\\n    ${fa} \\\n    ${read1} ${read2} | \\\n    samtools sort -T \"tmp.\"${sampleID} -o ${sampleID}\".sort.bam\"\n  samtools index ${sampleID}\".sort.bam\"\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bwa_memming",
            "reference"
        ],
        "nb_inputs": 2,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'high_mem'",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "cram": {
        "name_process": "cram",
        "string_process": "\nprocess cram {\n\n  label 'low_mem'\n  publishDir path: \"${params.outDir}/samples/${sampleID}/bwa\", mode: \"copy\", pattern: \"*.cra*\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai) from cramming\n  file(bwa) from reference.bwa\n\n  output:\n  tuple file('*.cram'), file('*.crai') into completedcram\n\n  script:\n  \"\"\"\n  samtools view -hC -T ${bwa}/*fasta ${sampleID}\".sort.bam\" > ${sampleID}\".sort.cram\"\n  samtools index ${sampleID}\".sort.cram\"\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  samtools view -hC -T ${bwa}/*fasta ${sampleID}\".sort.bam\" > ${sampleID}\".sort.cram\"\n  samtools index ${sampleID}\".sort.cram\"\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "cramming",
            "reference"
        ],
        "nb_inputs": 2,
        "outputs": [
            "completedcram"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/bwa\", mode: \"copy\", pattern: \"*.cra*\""
        ],
        "when": "",
        "stub": ""
    },
    "mrkdup": {
        "name_process": "mrkdup",
        "string_process": "\nprocess mrkdup {\n\n  label 'high_mem'\n  publishDir path: \"${params.outDir}/samples/${sampleID}/picard\", mode: \"copy\", pattern: \"*.txt\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai) from dup_marking\n\n  output:\n  file('*.txt') into mrkdup_multiqc\n  tuple val(type), val(sampleID), val(meta), file('*.md.bam'), file('*.md.bam.bai') into ( gatk4recaling, gridssing )\n\n  script:\n  def taskmem = task.memory == null ? \"\" : \"-Xmx\" + javaTaskmem(\"${task.memory}\")\n  \"\"\"\n  OUTBAM=\\$(echo ${bam} | sed 's/bam/md.bam/')\n  OUTMET=\\$(echo ${bam} | sed 's/bam/md.metrics.txt/')\n  {\n  picard ${taskmem} \\\n    MarkDuplicates \\\n    TMP_DIR=./ \\\n    INPUT=${bam} \\\n    OUTPUT=/dev/stdout \\\n    COMPRESSION_LEVEL=0 \\\n    QUIET=TRUE \\\n    METRICS_FILE=\\$OUTMET \\\n    REMOVE_DUPLICATES=FALSE \\\n    ASSUME_SORTED=TRUE \\\n    VALIDATION_STRINGENCY=LENIENT \\\n    VERBOSITY=ERROR | samtools view -Shb - > \\$OUTBAM\n\n  samtools index \\$OUTBAM\n  } 2>&1 | tee > ${sampleID}.picard_markDuplicates.log.txt\n  \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "  def taskmem = task.memory == null ? \"\" : \"-Xmx\" + javaTaskmem(\"${task.memory}\")\n  \"\"\"\n  OUTBAM=\\$(echo ${bam} | sed 's/bam/md.bam/')\n  OUTMET=\\$(echo ${bam} | sed 's/bam/md.metrics.txt/')\n  {\n  picard ${taskmem} \\\n    MarkDuplicates \\\n    TMP_DIR=./ \\\n    INPUT=${bam} \\\n    OUTPUT=/dev/stdout \\\n    COMPRESSION_LEVEL=0 \\\n    QUIET=TRUE \\\n    METRICS_FILE=\\$OUTMET \\\n    REMOVE_DUPLICATES=FALSE \\\n    ASSUME_SORTED=TRUE \\\n    VALIDATION_STRINGENCY=LENIENT \\\n    VERBOSITY=ERROR | samtools view -Shb - > \\$OUTBAM\n\n  samtools index \\$OUTBAM\n  } 2>&1 | tee > ${sampleID}.picard_markDuplicates.log.txt\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "Picard",
            "MarkDuplicates (IP)",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools",
            "https://bio.tools/markduplicates_ip",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "MarkDuplicates (IP)",
                "uri": "https://bio.tools/markduplicates_ip",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0253",
                                    "term": "Sequence feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0253",
                                    "term": "Sequence feature recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0253",
                                    "term": "Sequence feature prediction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "Marks all duplicate reads in a provided SAM or BAM file and either removes them or flags them.",
                "homepage": "https://galaxy.pasteur.fr/tool_runner?tool_id=toolshed.pasteur.fr/repos/fmareuil/picard_pasteur_wrapper/rgPicardMarkDups/1.56.0"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "dup_marking"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mrkdup_multiqc",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'high_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/picard\", mode: \"copy\", pattern: \"*.txt\""
        ],
        "when": "",
        "stub": ""
    },
    "gtkrcl": {
        "name_process": "gtkrcl",
        "string_process": "\nprocess gtkrcl {\n\n  label 'high_mem'\n  publishDir path: \"${params.outDir}/samples/${sampleID}/gatk4/bestpractice\", mode: \"copy\", pattern: \"*.GATK4_BQSR.log.txt \"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai) from gatk4recaling\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n  file(dbsnp_files) from reference.dbsnp\n  file(intlist) from reference.intlist\n\n  output:\n  file('*.table') into gtkrcl_multiqc\n  tuple val(type), val(sampleID), file('*.bqsr.bam'), file('*.bqsr.bam.bai') into ( germfiltering, gmultimetricing)\n  tuple val(type), val(sampleID), val(meta), file('*.bqsr.bam'), file('*.bqsr.bam.bai') into hc_germ\n  tuple val(sampleID), val(meta) into metas_pcgr\n  file(\"${sampleID}.GATK4_BQSR.log.txt\") into bqsr_log\n\n  script:\n  def dbsnp = \"${dbsnp_files}/*gz\"\n  \"\"\"\n  {\n  gatk BaseRecalibrator \\\n    -R ${fasta} \\\n    -I ${bam} \\\n    --known-sites \\$(echo ${dbsnp}) \\\n    --use-original-qualities \\\n    -O ${sampleID}.recal_data.table \\\n    --disable-sequence-dictionary-validation true \\\n    -L ${intlist}\n\n  #ApplyBQSR\n  OUTBAM=\\$(echo ${bam} | sed 's/bam/bqsr.bam/')\n  gatk ApplyBQSR \\\n    -R ${fasta} \\\n    -I ${bam} \\\n    --bqsr-recal-file ${sampleID}.recal_data.table \\\n    --add-output-sam-program-record \\\n    --use-original-qualities \\\n    -O \\$OUTBAM \\\n    -L ${intlist}\n\n  samtools index \\$OUTBAM \\$OUTBAM\".bai\"\n  } 2>&1 | tee >  ${sampleID}.GATK4_BQSR.log.txt\n  \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "  def dbsnp = \"${dbsnp_files}/*gz\"\n  \"\"\"\n  {\n  gatk BaseRecalibrator \\\n    -R ${fasta} \\\n    -I ${bam} \\\n    --known-sites \\$(echo ${dbsnp}) \\\n    --use-original-qualities \\\n    -O ${sampleID}.recal_data.table \\\n    --disable-sequence-dictionary-validation true \\\n    -L ${intlist}\n\n  #ApplyBQSR\n  OUTBAM=\\$(echo ${bam} | sed 's/bam/bqsr.bam/')\n  gatk ApplyBQSR \\\n    -R ${fasta} \\\n    -I ${bam} \\\n    --bqsr-recal-file ${sampleID}.recal_data.table \\\n    --add-output-sam-program-record \\\n    --use-original-qualities \\\n    -O \\$OUTBAM \\\n    -L ${intlist}\n\n  samtools index \\$OUTBAM \\$OUTBAM\".bai\"\n  } 2>&1 | tee >  ${sampleID}.GATK4_BQSR.log.txt\n  \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "GATK",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/gatk",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "gatk4recaling",
            "reference",
            "reference",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 6,
        "outputs": [
            "gtkrcl_multiqc",
            "",
            "hc_germ",
            "metas_pcgr",
            "bqsr_log"
        ],
        "nb_outputs": 5,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'high_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/gatk4/bestpractice\", mode: \"copy\", pattern: \"*.GATK4_BQSR.log.txt \""
        ],
        "when": "",
        "stub": ""
    },
    "scat_gath": {
        "name_process": "scat_gath",
        "string_process": "\nprocess scat_gath {\n\n  label 'low_mem'\n\n  input:\n  file(intlist) from reference.intlist\n\n  output:\n  file('lancet.scatgath.*.bed') into lancet_bedding\n  file('mutect2.scatgath.*.bed.interval_list') into mutect2_bedding\n  file('hc.scatgath.*.bed.interval_list') into hc_bedding\n\n  script:\n  def sgcount = params.scatGath\n  if (params.scatGath == null){\n    if (params.seqlevel == \"exome\"){\n      sgcount = 20\n    }\n    else {\n      sgcount = 100\n    }\n  }\n  \"\"\"\n  ##strip out all but chromosomes in the interval_list (no decoys etc)\n  CHRS=\\$(grep -v \"@\" ${intlist} | cut -f 1 | uniq)\n  for CHR in \\$CHRS; do\n    grep \"SN:\\$CHR\\\\s\" ${intlist} >> used.interval_list\n  done\n  grep -v \"@\" ${intlist} >> used.interval_list\n\n  ##generate scatters\n  picard IntervalListTools \\\n    I=used.interval_list \\\n    SCATTER_COUNT=${sgcount} \\\n    O=./\n\n  ##rename scatters and parse into appropriate format for tools\n  ls temp*/* | while read FILE; do\n    COUNTN=\\$(dirname \\$FILE | perl -ane '@s=split(/\\\\_/); print \\$s[1];');\n    mv \\$FILE mutect2.scatgath.\\${COUNTN}.bed.interval_list;\n    cp mutect2.scatgath.\\${COUNTN}.bed.interval_list hc.scatgath.\\${COUNTN}.bed.interval_list\n    grep -v @ mutect2.scatgath.\\${COUNTN}.bed.interval_list | \\\n      cut -f 1,2,3,5 > lancet.scatgath.\\${COUNTN}.bed\n  done\n  \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "  def sgcount = params.scatGath\n  if (params.scatGath == null){\n    if (params.seqlevel == \"exome\"){\n      sgcount = 20\n    }\n    else {\n      sgcount = 100\n    }\n  }\n  \"\"\"\n  ##strip out all but chromosomes in the interval_list (no decoys etc)\n  CHRS=\\$(grep -v \"@\" ${intlist} | cut -f 1 | uniq)\n  for CHR in \\$CHRS; do\n    grep \"SN:\\$CHR\\\\s\" ${intlist} >> used.interval_list\n  done\n  grep -v \"@\" ${intlist} >> used.interval_list\n\n  ##generate scatters\n  picard IntervalListTools \\\n    I=used.interval_list \\\n    SCATTER_COUNT=${sgcount} \\\n    O=./\n\n  ##rename scatters and parse into appropriate format for tools\n  ls temp*/* | while read FILE; do\n    COUNTN=\\$(dirname \\$FILE | perl -ane '@s=split(/\\\\_/); print \\$s[1];');\n    mv \\$FILE mutect2.scatgath.\\${COUNTN}.bed.interval_list;\n    cp mutect2.scatgath.\\${COUNTN}.bed.interval_list hc.scatgath.\\${COUNTN}.bed.interval_list\n    grep -v @ mutect2.scatgath.\\${COUNTN}.bed.interval_list | \\\n      cut -f 1,2,3,5 > lancet.scatgath.\\${COUNTN}.bed\n  done\n  \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "reference"
        ],
        "nb_inputs": 1,
        "outputs": [
            "lancet_bedding",
            "mutect2_bedding",
            "hc_bedding"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "haplotypecaller": {
        "name_process": "haplotypecaller",
        "string_process": "\nprocess haplotypecaller {\n\n  label 'med_mem'\n  errorStrategy 'retry'\n  maxRetries 3\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai), file(intlist) from hcgermbedding\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n  file(dbsnp_files) from reference.dbsnp\n  file(hc_dbs_files) from reference.hc_dbs\n\n  output:\n  tuple val(sampleID), file('*sort.hc.vcf') into hc_gt\n  tuple val(sampleID), val(meta) into hc_mv\n  val(sampleID) into ( gridssgermID, vcfGRaID )\n\n  when:\n  type == \"germline\" & params.germline != false\n\n  script:\n  def taskmem = task.memory == null ? \"\" : \"--java-options \\\"-Xmx\" + javaTaskmem(\"${task.memory}\") + \"\\\"\"\n  def dbsnp = \"${dbsnp_files}/*gz\"\n  def omni = \"${hc_dbs_files}/KG_omni*.gz\"\n  def kgp1 = \"${hc_dbs_files}/KG_phase1*.gz\"\n  def hpmp = \"${hc_dbs_files}/hapmap*.gz\"\n  \"\"\"\n  SCATGATHN=\\$(echo ${intlist} | perl -ane '@s=split(/\\\\./);print \\$s[2];')\n  gatk ${taskmem} HaplotypeCaller \\\n    -R ${fasta} \\\n    -I ${bam} \\\n    --dont-use-soft-clipped-bases \\\n    --standard-min-confidence-threshold-for-calling 20 \\\n    --dbsnp \\$(echo ${dbsnp}) \\\n    --native-pair-hmm-threads ${task.cpus} \\\n    -O ${sampleID}\".\\${SCATGATHN}.hc.vcf\" \\\n    --disable-sequence-dictionary-validation true \\\n    -L ${intlist}\n\n  picard SortVcf \\\n    I=${sampleID}\".\\${SCATGATHN}.hc.vcf\" \\\n    O=${sampleID}\".\\${SCATGATHN}.sort.hc.vcf\" \\\n    SD=${dict}\n  \"\"\"\n}",
        "nb_lignes_process": 46,
        "string_script": "  def taskmem = task.memory == null ? \"\" : \"--java-options \\\"-Xmx\" + javaTaskmem(\"${task.memory}\") + \"\\\"\"\n  def dbsnp = \"${dbsnp_files}/*gz\"\n  def omni = \"${hc_dbs_files}/KG_omni*.gz\"\n  def kgp1 = \"${hc_dbs_files}/KG_phase1*.gz\"\n  def hpmp = \"${hc_dbs_files}/hapmap*.gz\"\n  \"\"\"\n  SCATGATHN=\\$(echo ${intlist} | perl -ane '@s=split(/\\\\./);print \\$s[2];')\n  gatk ${taskmem} HaplotypeCaller \\\n    -R ${fasta} \\\n    -I ${bam} \\\n    --dont-use-soft-clipped-bases \\\n    --standard-min-confidence-threshold-for-calling 20 \\\n    --dbsnp \\$(echo ${dbsnp}) \\\n    --native-pair-hmm-threads ${task.cpus} \\\n    -O ${sampleID}\".\\${SCATGATHN}.hc.vcf\" \\\n    --disable-sequence-dictionary-validation true \\\n    -L ${intlist}\n\n  picard SortVcf \\\n    I=${sampleID}\".\\${SCATGATHN}.hc.vcf\" \\\n    O=${sampleID}\".\\${SCATGATHN}.sort.hc.vcf\" \\\n    SD=${dict}\n  \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "GATK",
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/gatk",
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            },
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "hcgermbedding",
            "reference",
            "reference",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 6,
        "outputs": [
            "hc_gt",
            "hc_mv",
            ""
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "type == \"germline\" & params.germline != false",
        "stub": ""
    },
    "gridss": {
        "name_process": "gridss",
        "string_process": "\nprocess gridss {\n\n  label 'max_mem'\n  publishDir path: \"${params.outDir}/combined/gridss\", mode: \"copy\", pattern: \"*.[!bam, vcf.gz]\"\n\n  input:\n  file(listbams) from gridssin\n  val(germlineID) from gridssgermID.collect().flatten().unique()\n  file(bwa) from reference.bwa\n  file(gridss_files) from reference.gridss\n\n  output:\n  file('*') into completegridss\n  tuple val(germlineID), file(\"tumords.txt\"), file(\"${params.runID}.output.vcf.gz\") into gridssfilter\n\n  when:\n  params.seqlevel == \"wgs\"\n\n  script:\n  def jvmheap_taskmem = task.memory == null ? \"\" : \"--jvmheap \" + javaTaskmem(\"${task.memory}\")\n  def fasta = \"${bwa}/*fasta\"\n  def gridss_blacklist = \"${gridss_files}/gridss_blacklist.noChr.bed\"\n  def gridss_props = \"${gridss_files}/dbs/gridss/gridss.properties\"\n  \"\"\"\n  GERMLINEBAM=\\$(ls | grep ${germlineID} | grep bam\\$ | grep -v bai)\n  BAMFILES=\\$(echo -n \\$GERMLINEBAM\" \"\\$(ls *.bam | grep -v \\$GERMLINEBAM))\n  LABELS=\\$(echo -n ${germlineID}\" \"\\$(ls *bam | grep -v ${germlineID} | grep -v assembly | cut -d \".\" -f1) | sed 's/\\\\s */,/g')\n  TUMORDS=\\$(echo \\$LABELS | perl -ane '@s=split(/\\\\,/);for(\\$i=2;\\$i<=@s;\\$i++){push(@o,\\$i);} print join(\",\",@o[0..\\$#o]) . \"\\\\n\";')\n  TASKCPUS=\\$(( ${task.cpus} / 4 )) ##\"preprocessing will use up to 200-300% CPU per thread\"\n  echo \\$TUMORDS > tumords.txt\n\n  gridss.sh \\\n    --reference \\$(echo ${fasta}) \\\n    --output ${params.runID}\".output.vcf.gz\" \\\n    --assembly ${params.runID}\".assembly.bam\" \\\n    --threads \\$TASKCPUS \\\n    --jar /opt/gridss/gridss-2.9.4-gridss-jar-with-dependencies.jar \\\n    --workingdir ./ ${jvmheap_taskmem} \\\n    --blacklist ${gridss_blacklist} \\\n    --steps All \\\n    --configuration ${gridss_props} \\\n    --maxcoverage 50000 \\\n    --labels \\$LABELS \\\n    \\$BAMFILES\n  \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "  def jvmheap_taskmem = task.memory == null ? \"\" : \"--jvmheap \" + javaTaskmem(\"${task.memory}\")\n  def fasta = \"${bwa}/*fasta\"\n  def gridss_blacklist = \"${gridss_files}/gridss_blacklist.noChr.bed\"\n  def gridss_props = \"${gridss_files}/dbs/gridss/gridss.properties\"\n  \"\"\"\n  GERMLINEBAM=\\$(ls | grep ${germlineID} | grep bam\\$ | grep -v bai)\n  BAMFILES=\\$(echo -n \\$GERMLINEBAM\" \"\\$(ls *.bam | grep -v \\$GERMLINEBAM))\n  LABELS=\\$(echo -n ${germlineID}\" \"\\$(ls *bam | grep -v ${germlineID} | grep -v assembly | cut -d \".\" -f1) | sed 's/\\\\s */,/g')\n  TUMORDS=\\$(echo \\$LABELS | perl -ane '@s=split(/\\\\,/);for(\\$i=2;\\$i<=@s;\\$i++){push(@o,\\$i);} print join(\",\",@o[0..\\$#o]) . \"\\\\n\";')\n  TASKCPUS=\\$(( ${task.cpus} / 4 )) ##\"preprocessing will use up to 200-300% CPU per thread\"\n  echo \\$TUMORDS > tumords.txt\n\n  gridss.sh \\\n    --reference \\$(echo ${fasta}) \\\n    --output ${params.runID}\".output.vcf.gz\" \\\n    --assembly ${params.runID}\".assembly.bam\" \\\n    --threads \\$TASKCPUS \\\n    --jar /opt/gridss/gridss-2.9.4-gridss-jar-with-dependencies.jar \\\n    --workingdir ./ ${jvmheap_taskmem} \\\n    --blacklist ${gridss_blacklist} \\\n    --steps All \\\n    --configuration ${gridss_props} \\\n    --maxcoverage 50000 \\\n    --labels \\$LABELS \\\n    \\$BAMFILES\n  \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gridssin",
            "gridssgermID",
            "reference",
            "reference"
        ],
        "nb_inputs": 4,
        "outputs": [
            "completegridss",
            "gridssfilter"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'max_mem'",
            "publishDir path: \"${params.outDir}/combined/gridss\", mode: \"copy\", pattern: \"*.[!bam, vcf.gz]\""
        ],
        "when": "params.seqlevel == \"wgs\"",
        "stub": ""
    },
    "gridss_filter": {
        "name_process": "gridss_filter",
        "string_process": "\nprocess gridss_filter {\n\n  label 'max_mem'\n  publishDir path: \"${params.outDir}/combined/gridss\", mode: \"copy\"\n\n  input:\n  tuple val(germlineID), file(tumords), file(\"${params.runID}.output.vcf.gz\") from gridssfilter\n\n  output:\n  file('*') into gridssfilterd\n  tuple val(germlineID), file(\"${params.runID}.somatic_filter.vcf.bgz\"), file(\"${params.runID}.somatic_filter.vcf.bgz.tbi\") into gridsspp\n\n  when:\n  params.seqlevel == \"wgs\"\n\n  script:\n  \"\"\"\n  Rscript --vanilla /opt/gridss/gridss_somatic_filter.R \\\n    --input ${params.runID}\".output.vcf.gz\" \\\n    --output ${params.runID}\".somatic_filter.vcf\" \\\n    --plotdir ./ \\\n    --scriptdir /opt/gridss \\\n    --normalordinal 1 \\\n    --tumourordinal \\$(cat $tumords)\n  \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "  \"\"\"\n  Rscript --vanilla /opt/gridss/gridss_somatic_filter.R \\\n    --input ${params.runID}\".output.vcf.gz\" \\\n    --output ${params.runID}\".somatic_filter.vcf\" \\\n    --plotdir ./ \\\n    --scriptdir /opt/gridss \\\n    --normalordinal 1 \\\n    --tumourordinal \\$(cat $tumords)\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gridssfilter"
        ],
        "nb_inputs": 1,
        "outputs": [
            "gridssfilterd",
            "gridsspp"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'max_mem'",
            "publishDir path: \"${params.outDir}/combined/gridss\", mode: \"copy\""
        ],
        "when": "params.seqlevel == \"wgs\"",
        "stub": ""
    },
    "gridss_vcf_pp": {
        "name_process": "gridss_vcf_pp",
        "string_process": "\nprocess gridss_vcf_pp {\n\n  label 'low_mem'\n  publishDir path: \"${params.outDir}/combined/gridss\", mode: \"copy\", pattern: \"*.[pdf, tsv, png, vcf.gz]\"\n\n  input:\n  tuple val(germlineID), file(vcf), file(tbi) from gridsspp\n  file(bwa) from reference.bwa\n\n  output:\n  file('*') into completegridsspp\n\n  when:\n  params.seqlevel == \"wgs\"\n\n  script:\n  def dict = \"${bwa}/*dict\"\n  def which_genome = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  \"\"\"\n  Rscript -e \"somenone::gridss_parse_plot(vcf = \\\\\"${params.runID}.somatic_filter.vcf.bgz\\\\\", germline_id = \\\\\"${germlineID}\\\\\", dict_file = \\$(echo \\\\\"${dict}\\\\\"), which_genome = \\\\\"${which_genome}\\\\\", output_path = NULL)\"\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  def dict = \"${bwa}/*dict\"\n  def which_genome = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  \"\"\"\n  Rscript -e \"somenone::gridss_parse_plot(vcf = \\\\\"${params.runID}.somatic_filter.vcf.bgz\\\\\", germline_id = \\\\\"${germlineID}\\\\\", dict_file = \\$(echo \\\\\"${dict}\\\\\"), which_genome = \\\\\"${which_genome}\\\\\", output_path = NULL)\"\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gridsspp",
            "reference"
        ],
        "nb_inputs": 2,
        "outputs": [
            "completegridsspp"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/combined/gridss\", mode: \"copy\", pattern: \"*.[pdf, tsv, png, vcf.gz]\""
        ],
        "when": "params.seqlevel == \"wgs\"",
        "stub": ""
    },
    "hc_merge": {
        "name_process": "hc_merge",
        "string_process": "\nprocess hc_merge {\n\n  label 'high_mem'\n  publishDir path: \"${params.outDir}/samples/${sampleID}/haplotypecaller\", mode: \"copy\", pattern: '*.vcf.*'\n\n  input:\n  tuple val(sampleID), file(rawvcfs) from hc_fm\n  tuple val(sampleID), val(meta) from hc_mv\n\n  output:\n  tuple val(sampleID), val(meta), file(\"${sampleID}.hc.merge.vcf.gz\"), file(\"${sampleID}.hc.merge.vcf.gz.tbi\") into cpsr_vcf\n\n  script:\n  \"\"\"\n  ls *.sort.hc.vcf > vcf.list\n  picard MergeVcfs I=vcf.list O=${sampleID}\".hc.merge.vcf\"\n  bgzip ${sampleID}\".hc.merge.vcf\"\n  tabix ${sampleID}\".hc.merge.vcf.gz\"\n  \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  ls *.sort.hc.vcf > vcf.list\n  picard MergeVcfs I=vcf.list O=${sampleID}\".hc.merge.vcf\"\n  bgzip ${sampleID}\".hc.merge.vcf\"\n  tabix ${sampleID}\".hc.merge.vcf.gz\"\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "hc_fm",
            "hc_mv"
        ],
        "nb_inputs": 2,
        "outputs": [
            "cpsr_vcf"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'high_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/haplotypecaller\", mode: \"copy\", pattern: '*.vcf.*'"
        ],
        "when": "",
        "stub": ""
    },
    "cpsrreport": {
        "name_process": "cpsrreport",
        "string_process": "\nprocess cpsrreport {\n\n  label 'med_mem'\n\n  publishDir \"${params.outDir}/reports/cpsr\", mode: \"copy\", pattern: \"*.html\"\n  publishDir \"${params.outDir}/samples/${sampleID}/cpsr\", mode: \"copy\", pattern: \"*[!.html]\"\n\n  input:\n  tuple val(sampleID), val(meta), file(vcf), file(tbi) from cpsr_vcf\n  file(grchver) from reference.grchvers\n  file(pcgrbase) from reference.pcgrbase\n\n  output:\n  file('*') into cpsr_vcfs\n  file(\"*.html\") into sendmail_cpsr\n\n  script:\n  def grchv = \"${grchver}\".split(\"\\\\/\")[-1]\n  \"\"\"\n  {\n  META=\\$(echo ${meta} | sed 's/\\\\s */_/g' | sed 's/[()]//g')\n\n  ##CPSR v0.6.1\n  cpsr.py \\\n    --no-docker \\\n    --no_vcf_validate \\\n    --panel_id 0 \\\n    --query_vcf ${vcf} \\\n    --pcgr_dir ${pcgrbase} \\\n    --output_dir ./ \\\n    --genome_assembly ${grchv} \\\n    --conf ${pcgrbase}/data/${grchv}/cpsr_configuration_default.toml \\\n    --sample_id \\$META\n  } 2>&1 | tee > ${sampleID}.cpsr.log.txt\n  \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "  def grchv = \"${grchver}\".split(\"\\\\/\")[-1]\n  \"\"\"\n  {\n  META=\\$(echo ${meta} | sed 's/\\\\s */_/g' | sed 's/[()]//g')\n\n  ##CPSR v0.6.1\n  cpsr.py \\\n    --no-docker \\\n    --no_vcf_validate \\\n    --panel_id 0 \\\n    --query_vcf ${vcf} \\\n    --pcgr_dir ${pcgrbase} \\\n    --output_dir ./ \\\n    --genome_assembly ${grchv} \\\n    --conf ${pcgrbase}/data/${grchv}/cpsr_configuration_default.toml \\\n    --sample_id \\$META\n  } 2>&1 | tee > ${sampleID}.cpsr.log.txt\n  \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cpsr_vcf",
            "reference",
            "reference"
        ],
        "nb_inputs": 3,
        "outputs": [
            "cpsr_vcfs",
            "sendmail_cpsr"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir \"${params.outDir}/reports/cpsr\", mode: \"copy\", pattern: \"*.html\"",
            "publishDir \"${params.outDir}/samples/${sampleID}/cpsr\", mode: \"copy\", pattern: \"*[!.html]\""
        ],
        "when": "",
        "stub": ""
    },
    "mltmet": {
        "name_process": "mltmet",
        "string_process": "\nprocess mltmet {\n\n  label 'med_mem'\n\n  publishDir \"${params.outDir}/samples/${sampleID}/metrics\", mode: \"copy\"\n\n  input:\n  tuple val(type), val(sampleID), file(bam), file(bai) from gmultimetricing\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n  file(intlist) from reference.intlist\n\n  output:\n  file('*.txt') into multimetrics_multiqc\n\n  script:\n  def taskmem = task.memory == null ? \"\" : \"-Xmx\" + javaTaskmem(\"${task.memory}\")\n  \"\"\"\n  {\n  if [[ ${params.seqlevel} == \"exome\" ]]; then\n  picard ${taskmem} CollectHsMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".hs_metrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta} \\\n    BAIT_INTERVALS=${intlist}  \\\n    TARGET_INTERVALS=${intlist}\n  fi\n  picard ${taskmem} CollectAlignmentSummaryMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".AlignmentSummaryMetrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta}\n\n  picard ${taskmem} CollectMultipleMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".CollectMultipleMetrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta}\n\n  picard ${taskmem} CollectSequencingArtifactMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".artifact_metrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta}\n\n  picard ${taskmem} CollectInsertSizeMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".insert_size_metrics.txt\" \\\n    H=${bam}\".histogram.pdf\" \\\n    TMP_DIR=./\n\n  } 2>&1 | tee > ${sampleID}.picard.metrics.log\n  \"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "  def taskmem = task.memory == null ? \"\" : \"-Xmx\" + javaTaskmem(\"${task.memory}\")\n  \"\"\"\n  {\n  if [[ ${params.seqlevel} == \"exome\" ]]; then\n  picard ${taskmem} CollectHsMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".hs_metrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta} \\\n    BAIT_INTERVALS=${intlist}  \\\n    TARGET_INTERVALS=${intlist}\n  fi\n  picard ${taskmem} CollectAlignmentSummaryMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".AlignmentSummaryMetrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta}\n\n  picard ${taskmem} CollectMultipleMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".CollectMultipleMetrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta}\n\n  picard ${taskmem} CollectSequencingArtifactMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".artifact_metrics.txt\" \\\n    TMP_DIR=./ \\\n    R=${fasta}\n\n  picard ${taskmem} CollectInsertSizeMetrics \\\n    I=${bam} \\\n    O=${sampleID}\".insert_size_metrics.txt\" \\\n    H=${bam}\".histogram.pdf\" \\\n    TMP_DIR=./\n\n  } 2>&1 | tee > ${sampleID}.picard.metrics.log\n  \"\"\"",
        "nb_lignes_script": 37,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "gmultimetricing",
            "reference",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 5,
        "outputs": [
            "multimetrics_multiqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir \"${params.outDir}/samples/${sampleID}/metrics\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "fctcsv": {
        "name_process": "fctcsv",
        "string_process": "\nprocess fctcsv {\n\n  label 'med_mem'\n\n  publishDir \"${params.outDir}/samples/${sampleID}/facets\", mode: \"copy\"\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai) from facetsomaing\n  file(dbsnp_files) from reference.dbsnp\n\n  output:\n  tuple file(\"${sampleID}.fit_cncf_jointsegs.tsv\"), file(\"${sampleID}.fit_ploidy_purity.tsv\") into ( facets_consensusing, facets_pyclone )\n  tuple val(sampleID), file(\"${sampleID}.cncf_jointsegs.pcgr.tsv\"), file(\"${sampleID}.fit_ploidy_purity.pcgr.tsv\") into facets_pcgr\n  file(\"${sampleID}.facets.log.txt\") into facets_log\n\n  script:\n  def dbsnp = \"${dbsnp_files}/*gz\"\n  \"\"\"\n  { snp-pileup \\\n      \\$(echo ${dbsnp}) \\\n      -r 10 \\\n      -p \\\n      ${sampleID}.facets.r10.csv \\\n      ${germlinebam} \\\n      ${tumourbam}\n\n    Rscript -e \"somenone::facets_cna_call(\\\\\"${sampleID}.facets.r10.csv\\\\\")\"\n\n    tail -n+2 ${sampleID}.fit_ploidy_purity.tsv > ${sampleID}.fit_ploidy_purity.pcgr.tsv\n  } 2>&1 | tee > ${sampleID}.facets.log.txt\n  \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "  def dbsnp = \"${dbsnp_files}/*gz\"\n  \"\"\"\n  { snp-pileup \\\n      \\$(echo ${dbsnp}) \\\n      -r 10 \\\n      -p \\\n      ${sampleID}.facets.r10.csv \\\n      ${germlinebam} \\\n      ${tumourbam}\n\n    Rscript -e \"somenone::facets_cna_call(\\\\\"${sampleID}.facets.r10.csv\\\\\")\"\n\n    tail -n+2 ${sampleID}.fit_ploidy_purity.tsv > ${sampleID}.fit_ploidy_purity.pcgr.tsv\n  } 2>&1 | tee > ${sampleID}.facets.log.txt\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "facetsomaing",
            "reference"
        ],
        "nb_inputs": 2,
        "outputs": [
            "",
            "facets_pcgr",
            "facets_log"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir \"${params.outDir}/samples/${sampleID}/facets\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "fctcon": {
        "name_process": "fctcon",
        "string_process": "\nprocess fctcon {\n  label 'med_mem'\n\n  publishDir \"${params.outDir}/combined/facets\", mode: \"copy\"\n\n  input:\n  file(filesn) from facets_consensusing.collect()\n  file(cosmicbed) from reference.cosmic\n  file(dict) from reference.dict\n\n  output:\n  file('*') into complete_facets\n  file(filesn) into pairtee_facets\n  file(\"${params.runID}.ENS.facets.CNA.master.tsv\") into pairtree_facet\n\n  script:\n  if( !params.cosmic )\n    \"\"\"\n    { Rscript -e \"somenone::facets_cna_consensus(\\\\\"fit_cncf_jointsegs.tsv\\\\\", \\\\\"${dict}\\\\\", \\\\\"${params.runID}\\\\\")\"\n    } 2>&1 | tee > facets_cons.log.txt\n    \"\"\"\n  else\n    \"\"\"\n    { Rscript -e \"somenone::facets_cna_consensus(\\\\\"fit_cncf_jointsegs.tsv\\\\\", \\\\\"${dict}\\\\\", \\\\\"${params.runID}\\\\\", \\\\\"${cosmicbed}\\\\\")\"\n    } 2>&1 | tee > facets_cons.log.txt\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "  if( !params.cosmic )\n    \"\"\"\n    { Rscript -e \"somenone::facets_cna_consensus(\\\\\"fit_cncf_jointsegs.tsv\\\\\", \\\\\"${dict}\\\\\", \\\\\"${params.runID}\\\\\")\"\n    } 2>&1 | tee > facets_cons.log.txt\n    \"\"\"\n  else\n    \"\"\"\n    { Rscript -e \"somenone::facets_cna_consensus(\\\\\"fit_cncf_jointsegs.tsv\\\\\", \\\\\"${dict}\\\\\", \\\\\"${params.runID}\\\\\", \\\\\"${cosmicbed}\\\\\")\"\n    } 2>&1 | tee > facets_cons.log.txt\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "facets_consensusing",
            "reference",
            "reference"
        ],
        "nb_inputs": 3,
        "outputs": [
            "complete_facets",
            "pairtee_facets",
            "pairtree_facet"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir \"${params.outDir}/combined/facets\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "mutct2_sg": {
        "name_process": "mutct2_sg",
        "string_process": "\nprocess mutct2_sg {\n\n  label 'med_mem'\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai), file(intlist) from mutect2somaticbedding\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n\n  output:\n  tuple val(sampleID), file('*sort.mutect2.vcf') into mutect2_gt\n  tuple val(sampleID), file('*.vcf.stats') into mutect2_st\n  tuple val(sampleID), file('*mutect2.f1r2.tar.gz') into mutect2_f1r2\n\n  script:\n  def taskmem = task.memory == null ? \"\" : \"--java-options \\\"-Xmx\" + javaTaskmem(\"${task.memory}\") + \"\\\"\"\n  \"\"\"\n  SCATGATHN=\\$(echo ${intlist} | perl -ane '@s=split(/\\\\./);print\\$s[2];')\n  gatk ${taskmem} \\\n    Mutect2 \\\n    --native-pair-hmm-threads ${task.cpus} \\\n    --reference ${fasta} \\\n    --input ${germlinebam} \\\n    --input ${tumourbam} \\\n    --normal-sample ${germlineID} \\\n    --tumor-sample ${sampleID} \\\n    --output ${sampleID}\".\"\\${SCATGATHN}\".mutect2.vcf\" \\\n    --disable-sequence-dictionary-validation true \\\n    --f1r2-tar-gz \\${SCATGATHN}\".mutect2.f1r2.tar.gz\" \\\n    -L ${intlist}\n\n  picard SortVcf \\\n    I=${sampleID}\".\"\\${SCATGATHN}\".mutect2.vcf\" \\\n    O=${sampleID}\".\"\\${SCATGATHN}\".sort.mutect2.vcf\" \\\n    SD=${dict}\n  \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "  def taskmem = task.memory == null ? \"\" : \"--java-options \\\"-Xmx\" + javaTaskmem(\"${task.memory}\") + \"\\\"\"\n  \"\"\"\n  SCATGATHN=\\$(echo ${intlist} | perl -ane '@s=split(/\\\\./);print\\$s[2];')\n  gatk ${taskmem} \\\n    Mutect2 \\\n    --native-pair-hmm-threads ${task.cpus} \\\n    --reference ${fasta} \\\n    --input ${germlinebam} \\\n    --input ${tumourbam} \\\n    --normal-sample ${germlineID} \\\n    --tumor-sample ${sampleID} \\\n    --output ${sampleID}\".\"\\${SCATGATHN}\".mutect2.vcf\" \\\n    --disable-sequence-dictionary-validation true \\\n    --f1r2-tar-gz \\${SCATGATHN}\".mutect2.f1r2.tar.gz\" \\\n    -L ${intlist}\n\n  picard SortVcf \\\n    I=${sampleID}\".\"\\${SCATGATHN}\".mutect2.vcf\" \\\n    O=${sampleID}\".\"\\${SCATGATHN}\".sort.mutect2.vcf\" \\\n    SD=${dict}\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "GATK",
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/gatk",
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            },
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "mutect2somaticbedding",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 4,
        "outputs": [
            "mutect2_gt",
            "mutect2_st",
            "mutect2_f1r2"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "mutct2_concat": {
        "name_process": "mutct2_concat",
        "string_process": "\nprocess mutct2_concat {\n\n  label 'med_mem'\n\n  input:\n  tuple val(sampleID), file(rawvcfs) from mutect2_fm\n\n  output:\n  tuple val(sampleID), file('*mutect2.merge.vcf') into mutect2_merge\n\n  script:\n  \"\"\"\n  ls *.sort.mutect2.vcf > vcf.list\n  picard MergeVcfs I=vcf.list O=${sampleID}\".mutect2.merge.vcf\"\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  ls *.sort.mutect2.vcf > vcf.list\n  picard MergeVcfs I=vcf.list O=${sampleID}\".mutect2.merge.vcf\"\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "mutect2_fm"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mutect2_merge"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "mutct2_concstat": {
        "name_process": "mutct2_concstat",
        "string_process": "\nprocess mutct2_concstat {\n\n  label 'med_mem'\n\n  input:\n  tuple val(sampleID), file(stats) from mutect2_sm\n\n  output:\n  tuple val(sampleID), file('*mutect2.merge.vcf.stats') into mutect2_stats\n\n  script:\n  \"\"\"\n  STATS=\\$(ls *stats | perl -ane 'foreach \\$k (@F){print \"--stats \\$k \";}')\n  gatk MergeMutectStats --output ${sampleID}\".mutect2.merge.vcf.stats\" \\$STATS\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  STATS=\\$(ls *stats | perl -ane 'foreach \\$k (@F){print \"--stats \\$k \";}')\n  gatk MergeMutectStats --output ${sampleID}\".mutect2.merge.vcf.stats\" \\$STATS\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "mutect2_sm"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mutect2_stats"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "mutct2_f1r2_comb": {
        "name_process": "mutct2_f1r2_comb",
        "string_process": "\nprocess mutct2_f1r2_comb {\n\n  label 'med_mem'\n\n  input:\n  tuple val(sampleID), file(mutect2_ro) from mutect2_f1r2_set\n\n  output:\n  tuple val(sampleID), file(\"${sampleID}.mutect2.f1r2.tar.gz\") into mutect2_f1r2_comb\n\n  script:\n  \"\"\"\n  ALL_F1R2_INPUT=\\$(for x in *.mutect2.f1r2.tar.gz; do echo -n \"-I \\$x \"; done)\n  gatk LearnReadOrientationModel \\$ALL_F1R2_INPUT -O ${sampleID}.mutect2.f1r2.tar.gz\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  ALL_F1R2_INPUT=\\$(for x in *.mutect2.f1r2.tar.gz; do echo -n \"-I \\$x \"; done)\n  gatk LearnReadOrientationModel \\$ALL_F1R2_INPUT -O ${sampleID}.mutect2.f1r2.tar.gz\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "mutect2_f1r2_set"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mutect2_f1r2_comb"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "mutct2_contam_filter": {
        "name_process": "mutct2_contam_filter",
        "string_process": "\nprocess mutct2_contam_filter {\n\n  label 'med_mem'\n\n  publishDir path: \"${params.outDir}/samples/${sampleID}/mutect2\", mode: \"copy\", overwrite: true\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai), file(mergevcf), file(statsvcf), file(readorient) from mutect2_contam_merge\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n  file(gps_files) from reference.seqlevel\n  file(intlist) from reference.intlist\n\n  output:\n  file('*snv_indel.pass.vcf') into mutect2_veping mode flatten\n  file('*.raw.vcf') into mutect2_rawVcf\n  file('*') into completedmutect2call\n\n  script:\n  def taskmem = task.memory == null ? \"\" : \"--java-options \\\"-Xmx\" + javaTaskmem(\"${task.memory}\") + \"\\\"\"\n  hg = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  gpsgz = params.seqlevel == \"exome\" ? \"${gps_files}/af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz\" : \"${gps_files}/af-only-gnomad.wgs.${hg}.noChr.vcf.gz\"\n  \"\"\"\n  gatk ${taskmem} \\\n    GetPileupSummaries \\\n    -I ${tumourbam} \\\n    -V ${gpsgz} \\\n    -O ${sampleID}\".getpileupsummaries.table\" \\\n    -L ${intlist}\n\n  gatk CalculateContamination \\\n    -I ${sampleID}\".getpileupsummaries.table\" \\\n    -O ${sampleID}\".calculatecontamination.table\"\n\n  CONTAM=\\$(tail -n+2 ${sampleID}.calculatecontamination.table | cut -f 2 | cut -d \".\" -f 1)\n  if [[ \\$CONTAM != 0 ]]; then\n    touch ${sampleID}\".CONTAMINATION.WARNING.txt\"\n  fi\n\n  gatk IndexFeatureFile \\\n    --input ${mergevcf}\n\n  gatk ${taskmem} \\\n    FilterMutectCalls \\\n    --reference ${fasta} \\\n    --contamination-table ${sampleID}\".calculatecontamination.table\" \\\n    --interval-padding 5 \\\n    --output ${sampleID}\".mutect2.FilterMutectCalls.vcf\" \\\n    --unique-alt-read-count 3 \\\n    --variant ${mergevcf} \\\n    --stats ${statsvcf} \\\n    --disable-sequence-dictionary-validation true \\\n    --ob-priors ${readorient} \\\n    -L ${intlist}\n\n  perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n    ID=${sampleID} \\\n    DP=14 \\\n    MD=2 \\\n    VCF=${sampleID}\".mutect2.FilterMutectCalls.vcf\"\n  \"\"\"\n}",
        "nb_lignes_process": 62,
        "string_script": "  def taskmem = task.memory == null ? \"\" : \"--java-options \\\"-Xmx\" + javaTaskmem(\"${task.memory}\") + \"\\\"\"\n  hg = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  gpsgz = params.seqlevel == \"exome\" ? \"${gps_files}/af-only-gnomad.${params.exomeTag}.${hg}.noChr.vcf.gz\" : \"${gps_files}/af-only-gnomad.wgs.${hg}.noChr.vcf.gz\"\n  \"\"\"\n  gatk ${taskmem} \\\n    GetPileupSummaries \\\n    -I ${tumourbam} \\\n    -V ${gpsgz} \\\n    -O ${sampleID}\".getpileupsummaries.table\" \\\n    -L ${intlist}\n\n  gatk CalculateContamination \\\n    -I ${sampleID}\".getpileupsummaries.table\" \\\n    -O ${sampleID}\".calculatecontamination.table\"\n\n  CONTAM=\\$(tail -n+2 ${sampleID}.calculatecontamination.table | cut -f 2 | cut -d \".\" -f 1)\n  if [[ \\$CONTAM != 0 ]]; then\n    touch ${sampleID}\".CONTAMINATION.WARNING.txt\"\n  fi\n\n  gatk IndexFeatureFile \\\n    --input ${mergevcf}\n\n  gatk ${taskmem} \\\n    FilterMutectCalls \\\n    --reference ${fasta} \\\n    --contamination-table ${sampleID}\".calculatecontamination.table\" \\\n    --interval-padding 5 \\\n    --output ${sampleID}\".mutect2.FilterMutectCalls.vcf\" \\\n    --unique-alt-read-count 3 \\\n    --variant ${mergevcf} \\\n    --stats ${statsvcf} \\\n    --disable-sequence-dictionary-validation true \\\n    --ob-priors ${readorient} \\\n    -L ${intlist}\n\n  perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n    ID=${sampleID} \\\n    DP=14 \\\n    MD=2 \\\n    VCF=${sampleID}\".mutect2.FilterMutectCalls.vcf\"\n  \"\"\"",
        "nb_lignes_script": 41,
        "language_script": "bash",
        "tools": [
            "PHG",
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/PHG",
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "PHG",
                "uri": "https://bio.tools/PHG",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3810",
                            "term": "Agricultural science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Practical Haplotype Graph (PHG) facilitates genome-wide imputation and cost-effective genomic prediction.\n\nSuccessful management and utilization of increasingly large genomic datasets are essential for breeding programs to increase genetic gain and accelerate cultivar development. To help with data management and storage, a sorghum Practical Haplotype Graph (PHG) pangenome database stores all identified haplotypes and variant information for a given set of individuals.",
                "homepage": "https://bitbucket.org/bucklerlab/p_sorghumphg/src/master"
            },
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "mutect2_contam_merge",
            "reference",
            "reference",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 6,
        "outputs": [
            "mutect2_veping",
            "mutect2_rawVcf",
            "completedmutect2call"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/mutect2\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "mntstr": {
        "name_process": "mntstr",
        "string_process": "\nprocess mntstr {\n\n  label 'high_mem'\n\n  publishDir path: \"${params.outDir}/samples/${sampleID}/manta-strelka2\", mode: \"copy\"\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai) from mantastrelka2ing\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n  file(bed_files) from reference.seqlevel\n\n  output:\n  file(\"${sampleID}.strelka2.snv_indel.pass.vcf\") into strelka2_veping\n  file(\"${sampleID}.strelka2.raw.vcf\") into strelka2_rawVcf\n  file('*.txt') into log_mantastrelka\n\n  script:\n  def bedgz = params.seqlevel == \"wgs\" ? \"${bed_files}/wgs.bed.gz\" : \"${bed_files}/${params.exomeTag}.bed.gz\"\n  def callRegions = params.seqlevel == \"exome\" ? \"--exome --callRegions ${bedgz}\" : \"--callRegions ${bedgz}\"\n  \"\"\"\n  {\n    configManta.py ${callRegions} --referenceFasta=${fasta} --normalBam=${germlinebam} --tumourBam=${tumourbam} --runDir=manta\n\n    manta/runWorkflow.py -m local -j ${task.cpus}\n\n    configureStrelkaSomaticWorkflow.py ${callRegions} --referenceFasta=${fasta} --indelCandidates=manta/results/variants/candidateSmallIndels.vcf.gz --normalBam=${germlinebam} --tumorBam=${tumourbam} --runDir=strelka2\n\n    strelka2/runWorkflow.py -m local -j ${task.cpus}\n\n    ##merge into raw snv_indel\n    gatk MergeVcfs -I strelka2/results/variants/somatic.snvs.vcf.gz -I strelka2/results/variants/somatic.indels.vcf.gz -O tmp.strelka2.snv_indel.vcf\n\n    ${workflow.projectDir}/bin/manta_strelka2_rename_filter.sh  tmp.strelka2.snv_indel.vcf tmp2.strelka2.snv_indel.vcf ${sampleID} ${germlineID}\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n        ID=${sampleID} \\\n        DP=14 \\\n        MD=2 \\\n        VCF=tmp2.strelka2.snv_indel.vcf\n\n  } 2>&1 | tee > ${sampleID}.manta-strelka2.log.txt\n  \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "  def bedgz = params.seqlevel == \"wgs\" ? \"${bed_files}/wgs.bed.gz\" : \"${bed_files}/${params.exomeTag}.bed.gz\"\n  def callRegions = params.seqlevel == \"exome\" ? \"--exome --callRegions ${bedgz}\" : \"--callRegions ${bedgz}\"\n  \"\"\"\n  {\n    configManta.py ${callRegions} --referenceFasta=${fasta} --normalBam=${germlinebam} --tumourBam=${tumourbam} --runDir=manta\n\n    manta/runWorkflow.py -m local -j ${task.cpus}\n\n    configureStrelkaSomaticWorkflow.py ${callRegions} --referenceFasta=${fasta} --indelCandidates=manta/results/variants/candidateSmallIndels.vcf.gz --normalBam=${germlinebam} --tumorBam=${tumourbam} --runDir=strelka2\n\n    strelka2/runWorkflow.py -m local -j ${task.cpus}\n\n    ##merge into raw snv_indel\n    gatk MergeVcfs -I strelka2/results/variants/somatic.snvs.vcf.gz -I strelka2/results/variants/somatic.indels.vcf.gz -O tmp.strelka2.snv_indel.vcf\n\n    ${workflow.projectDir}/bin/manta_strelka2_rename_filter.sh  tmp.strelka2.snv_indel.vcf tmp2.strelka2.snv_indel.vcf ${sampleID} ${germlineID}\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n        ID=${sampleID} \\\n        DP=14 \\\n        MD=2 \\\n        VCF=tmp2.strelka2.snv_indel.vcf\n\n  } 2>&1 | tee > ${sampleID}.manta-strelka2.log.txt\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "mantastrelka2ing",
            "reference",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 5,
        "outputs": [
            "strelka2_veping",
            "strelka2_rawVcf",
            "log_mantastrelka"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'high_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/manta-strelka2\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "lancet_sg": {
        "name_process": "lancet_sg",
        "string_process": "\nprocess lancet_sg {\n\n  label 'med_mem'\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai), file(bed) from lancetsbedding\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n\n  output:\n  tuple val(sampleID), file('*.sort.lancet.vcf') into lancet_gt\n\n  when:\n  params.seqlevel == \"exome\"\n\n  script:\n  scatgathn = \"${bed}\".split(\"\\\\.\")[2]\n  \"\"\"\n  lancet \\\n    --num-threads ${task.cpus} \\\n    --ref ${fasta} \\\n    --bed ${bed} \\\n    --tumor ${tumourbam} \\\n    --normal ${germlinebam} | \\\n    perl -ane 'if(\\$F[0]=~m/^\\\\#CHROM/){\n      \\$_=~s/TUMOR/${sampleID}/;\n      \\$_=~s/NORMAL/${germlineID}/;\n      print \\$_;}\n    else{print \\$_;}' > ${sampleID}\".\"${scatgathn}\".lancet.vcf\"\n\n  picard SortVcf \\\n    I=${sampleID}\".\"${scatgathn}\".lancet.vcf\" \\\n    O=${sampleID}\".\"${scatgathn}\".sort.lancet.vcf\" \\\n    SD=${dict}\n  \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "  scatgathn = \"${bed}\".split(\"\\\\.\")[2]\n  \"\"\"\n  lancet \\\n    --num-threads ${task.cpus} \\\n    --ref ${fasta} \\\n    --bed ${bed} \\\n    --tumor ${tumourbam} \\\n    --normal ${germlinebam} | \\\n    perl -ane 'if(\\$F[0]=~m/^\\\\#CHROM/){\n      \\$_=~s/TUMOR/${sampleID}/;\n      \\$_=~s/NORMAL/${germlineID}/;\n      print \\$_;}\n    else{print \\$_;}' > ${sampleID}\".\"${scatgathn}\".lancet.vcf\"\n\n  picard SortVcf \\\n    I=${sampleID}\".\"${scatgathn}\".lancet.vcf\" \\\n    O=${sampleID}\".\"${scatgathn}\".sort.lancet.vcf\" \\\n    SD=${dict}\n  \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "lancetsbedding",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 4,
        "outputs": [
            "lancet_gt"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'"
        ],
        "when": "params.seqlevel == \"exome\"",
        "stub": ""
    },
    "lancet_concat": {
        "name_process": "lancet_concat",
        "string_process": "\nprocess lancet_concat {\n\n  label 'med_mem'\n\n  input:\n  tuple val(sampleID), file(rawvcf) from lancet_fm\n\n  output:\n  tuple val(sampleID), file('*lancet.merge.vcf') into lancet_merge\n\n  script:\n  \"\"\"\n  ls *.sort.lancet.vcf > vcf.list\n  picard MergeVcfs I=vcf.list O=${sampleID}\".lancet.merge.vcf\"\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  ls *.sort.lancet.vcf > vcf.list\n  picard MergeVcfs I=vcf.list O=${sampleID}\".lancet.merge.vcf\"\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "lancet_fm"
        ],
        "nb_inputs": 1,
        "outputs": [
            "lancet_merge"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "lancet_filter": {
        "name_process": "lancet_filter",
        "string_process": "\nprocess lancet_filter {\n\n  label 'med_mem'\n\n  publishDir path: \"${params.outDir}/samples/${sampleID}/lancet\", mode: \"copy\"\n\n  input:\n  tuple val(sampleID), file(mergevcf) from lancet_merge\n\n  output:\n  file('*.pass.vcf') into lancet_veping mode flatten\n  file('*.raw.vcf') into lancet_rawVcf\n  file('*') into completedlancetcall\n\n  script:\n  \"\"\"\n  perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n    ID=${sampleID} \\\n    DP=14 \\\n    MD=2 \\\n    VCF=${mergevcf}\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "  \"\"\"\n  perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n    ID=${sampleID} \\\n    DP=14 \\\n    MD=2 \\\n    VCF=${mergevcf}\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "lancet_merge"
        ],
        "nb_inputs": 1,
        "outputs": [
            "lancet_veping",
            "lancet_rawVcf",
            "completedlancetcall"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/lancet\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "vepann": {
        "name_process": "vepann",
        "string_process": "\nprocess vepann {\n\n  label 'med_mem'\n\n  publishDir path: \"${params.outDir}/samples/${sampleID}/${caller}\", mode: \"copy\", pattern: \"${sampleID}.${caller}.snv_indel.pass.vep.vcf\"\n\n  input:\n  each file(vcf) from ALLVCFS\n  file(fasta) from reference.fa\n  file(fai) from reference.fai\n  file(dict) from reference.dict\n  file(grchver) from reference.grchvers\n  file(pcgrbase) from reference.pcgrbase\n\n  output:\n  file('*.vcf') into runGRanges\n\n  script:\n  def grch_vers = \"${grchver}\".split(\"\\\\/\")[-1]\n  def vcf_anno = \"${vcf}\".replaceAll(\".vcf\", \".vep.vcf\")\n  sampleID = \"${vcf}\".split(\"\\\\.\")[0]\n  caller = \"${vcf}\".split(\"\\\\.\")[1]\n  \"\"\"\n  vep --dir_cache ${pcgrbase}/data/${grch_vers}/.vep \\\n    --offline \\\n    --assembly ${params.assembly} \\\n    --vcf_info_field ANN \\\n    --symbol \\\n    --species homo_sapiens \\\n    --check_existing \\\n    --cache \\\n    --fork ${task.cpus} \\\n    --af_1kg \\\n    --af_gnomad \\\n    --vcf \\\n    --input_file ${vcf} \\\n    --output_file ${vcf_anno} \\\n    --format \"vcf\" \\\n    --fasta ${fasta} \\\n    --hgvs \\\n    --canonical \\\n    --ccds \\\n    --force_overwrite \\\n    --verbose\n  \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "  def grch_vers = \"${grchver}\".split(\"\\\\/\")[-1]\n  def vcf_anno = \"${vcf}\".replaceAll(\".vcf\", \".vep.vcf\")\n  sampleID = \"${vcf}\".split(\"\\\\.\")[0]\n  caller = \"${vcf}\".split(\"\\\\.\")[1]\n  \"\"\"\n  vep --dir_cache ${pcgrbase}/data/${grch_vers}/.vep \\\n    --offline \\\n    --assembly ${params.assembly} \\\n    --vcf_info_field ANN \\\n    --symbol \\\n    --species homo_sapiens \\\n    --check_existing \\\n    --cache \\\n    --fork ${task.cpus} \\\n    --af_1kg \\\n    --af_gnomad \\\n    --vcf \\\n    --input_file ${vcf} \\\n    --output_file ${vcf_anno} \\\n    --format \"vcf\" \\\n    --fasta ${fasta} \\\n    --hgvs \\\n    --canonical \\\n    --ccds \\\n    --force_overwrite \\\n    --verbose\n  \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "fivepseq"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/fivepseq"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "fivepseq",
                "uri": "https://bio.tools/fivepseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3563",
                                    "term": "RNA-seq read count analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Fivepseq is a software package for analysis of 5prime endpoints distribution in RNA sequencing datasets. This is particularly useful for techniques that capture 5prime  monophosphorylated RNAs, such as 5PSeq, PARE-seq or GMUC. It may also be useful for ribosome profiling datasets and alike.",
                "homepage": "http://pelechanolab.com/software/fivepseq"
            }
        ],
        "inputs": [
            "ALLVCFS",
            "reference",
            "reference",
            "reference",
            "reference",
            "reference"
        ],
        "nb_inputs": 6,
        "outputs": [
            "runGRanges"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'med_mem'",
            "publishDir path: \"${params.outDir}/samples/${sampleID}/${caller}\", mode: \"copy\", pattern: \"${sampleID}.${caller}.snv_indel.pass.vep.vcf\""
        ],
        "when": "",
        "stub": ""
    },
    "vcfGRa": {
        "name_process": "vcfGRa",
        "string_process": "\nprocess vcfGRa {\n\n  label 'max_mem'\n\n  publishDir \"${params.outDir}/combined/variant_consensus\", mode: \"copy\"\n\n  input:\n  file(grangesvcfs) from allvcfs\n  val(germlineID) from vcfGRaID.unique()\n  each impact from impacts\n\n  output:\n  file('*impacts.pcgr.tsv.vcf') into vcfs_pcgr\n  file('*') into completedvcfGRangesConsensus\n  file(\"${params.runID}.HMML_impacts.master_consensus_all.RData\") into pairtree_rdata\n\n  script:\n  def inc_ord = params.incOrder ? params.incOrder : \"noord\"\n  def which_genome = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  \"\"\"\n  Rscript -e \"somenone::variant_consensus(germline_id = \\\\\"${germlineID}\\\\\", vep_vcf_pattern = \\\\\"snv_indel.pass.vep.vcf\\\\\", raw_vcf_pattern = \\\\\"raw.vcf\\\\\", tag = \\\\\"${params.runID}\\\\\", which_genome = \\\\\"${which_genome}\\\\\", included_order = \\\\\"${inc_ord}\\\\\", impacts = \\\\\"${impact}\\\\\")\"\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "  def inc_ord = params.incOrder ? params.incOrder : \"noord\"\n  def which_genome = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  \"\"\"\n  Rscript -e \"somenone::variant_consensus(germline_id = \\\\\"${germlineID}\\\\\", vep_vcf_pattern = \\\\\"snv_indel.pass.vep.vcf\\\\\", raw_vcf_pattern = \\\\\"raw.vcf\\\\\", tag = \\\\\"${params.runID}\\\\\", which_genome = \\\\\"${which_genome}\\\\\", included_order = \\\\\"${inc_ord}\\\\\", impacts = \\\\\"${impact}\\\\\")\"\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "allvcfs",
            "vcfGRaID",
            "impacts"
        ],
        "nb_inputs": 3,
        "outputs": [
            "vcfs_pcgr",
            "completedvcfGRangesConsensus",
            "pairtree_rdata"
        ],
        "nb_outputs": 3,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'max_mem'",
            "publishDir \"${params.outDir}/combined/variant_consensus\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "pcgr_vcf": {
        "name_process": "pcgr_vcf",
        "string_process": "\nprocess pcgr_vcf {\n\n  label 'low_mem'\n\n  input:\n  file(vcf) from vcfs_pcgrd\n\n  output:\n  tuple val(sampleID), file(ovcf) into snvpass_pcgr\n\n  when:\n  vcf =~ \"HMML_impacts.pcgr.tsv.vcf\"\n\n  script:\n  sampleID = \"${vcf}\".split(\"\\\\.\")[0]\n  ovcf = \"${vcf}\".replace(\"pcgr.tsv.vcf\", \"snv_indel.pass.pcgr.vcf\")\n  \"\"\"\n  cat ${workflow.projectDir}/assets/vcf42.head.txt > $ovcf\n  head -n1 $vcf >> $ovcf\n  tail -n+2 $vcf | sort -V >> $ovcf\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  sampleID = \"${vcf}\".split(\"\\\\.\")[0]\n  ovcf = \"${vcf}\".replace(\"pcgr.tsv.vcf\", \"snv_indel.pass.pcgr.vcf\")\n  \"\"\"\n  cat ${workflow.projectDir}/assets/vcf42.head.txt > $ovcf\n  head -n1 $vcf >> $ovcf\n  tail -n+2 $vcf | sort -V >> $ovcf\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vcfs_pcgrd"
        ],
        "nb_inputs": 1,
        "outputs": [
            "snvpass_pcgr"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'"
        ],
        "when": "vcf =~ \"HMML_impacts.pcgr.tsv.vcf\"",
        "stub": ""
    },
    "pcgrreport": {
        "name_process": "pcgrreport",
        "string_process": "\nprocess pcgrreport {\n\n  label 'low_mem'\n  errorStrategy 'retry'\n  maxRetries 3\n\n  publishDir \"${params.outDir}/reports/pcgr\", mode: \"copy\", pattern: \"*html\"\n  publishDir \"${params.outDir}/samples/${sampleID}/pcgr\", mode: \"copy\", pattern: \"*[!.html]\"\n\n  input:\n  tuple val(sampleID), file(vcf), val(meta), file(jointsegs), file(ploidpur) from pcgr_inputs\n  file(grchver) from reference.grchvers\n  file(pcgrbase) from reference.pcgrbase\n\n  output:\n  file('*') into completed_pcgr\n  file(\"*.html\") into sendmail_pcgr\n\n  script:\n  grch_vers = \"${grchver}\".split(\"\\\\/\")[-1]\n  config = params.seqlevel == \"exome\" ? \"${pcgrbase}/data/${grch_vers}/pcgr_configuration_${params.exomeTag}.toml\" : \"${pcgrbase}/data/${grch_vers}/pcgr_configuration_wgs.toml\"\n  assay = params.seqlevel == \"exome\" ? \"WES\" : \"WGS\"\n  \"\"\"\n  {\n  ##want META to allow spaces, remove non-alphanum\n  META=\\$(echo ${meta} | perl -ane '\\$_=~s/[^a-zA-Z0-9_ \\\\n]//g; print \\$_;' | sed 's/\\\\s */_/g')\n\n  PLOIDY=\"\"; PURITY=\"\";\n  if [[ \\$(cut -f 1 ${ploidpur}) != \"NA\" ]]; then\n    PLOIDY=\"--tumor_ploidy \\$(cut -f 1 ${ploidpur})\"\n  fi\n  if [[ \\$(cut -f 2 ${ploidpur}) != \"NA\" ]]; then\n    PURITY=\"--tumor_purity \\$(cut -f 2 ${ploidpur})\"\n  fi\n\n  ##PCGR 0.9.1\n  pcgr.py \\\n    --pcgr_dir ${pcgrbase} \\\n    --output_dir ./ \\\n    --genome_assembly ${grch_vers} \\\n    --conf ${config} \\\n    --sample_id \\$META \\\n    --input_vcf ${vcf} \\\n    --input_cna ${jointsegs} \\$PLOIDY \\$PURITY \\\n    --no-docker \\\n    --force_overwrite \\\n    --no_vcf_validate \\\n    --estimate_tmb \\\n    --estimate_msi_status \\\n    --estimate_signatures \\\n    --include_trials \\\n    --assay ${assay}\n\n  } 2>&1 | tee > ${sampleID}.pcgr.log.txt\n  \"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "  grch_vers = \"${grchver}\".split(\"\\\\/\")[-1]\n  config = params.seqlevel == \"exome\" ? \"${pcgrbase}/data/${grch_vers}/pcgr_configuration_${params.exomeTag}.toml\" : \"${pcgrbase}/data/${grch_vers}/pcgr_configuration_wgs.toml\"\n  assay = params.seqlevel == \"exome\" ? \"WES\" : \"WGS\"\n  \"\"\"\n  {\n  ##want META to allow spaces, remove non-alphanum\n  META=\\$(echo ${meta} | perl -ane '\\$_=~s/[^a-zA-Z0-9_ \\\\n]//g; print \\$_;' | sed 's/\\\\s */_/g')\n\n  PLOIDY=\"\"; PURITY=\"\";\n  if [[ \\$(cut -f 1 ${ploidpur}) != \"NA\" ]]; then\n    PLOIDY=\"--tumor_ploidy \\$(cut -f 1 ${ploidpur})\"\n  fi\n  if [[ \\$(cut -f 2 ${ploidpur}) != \"NA\" ]]; then\n    PURITY=\"--tumor_purity \\$(cut -f 2 ${ploidpur})\"\n  fi\n\n  ##PCGR 0.9.1\n  pcgr.py \\\n    --pcgr_dir ${pcgrbase} \\\n    --output_dir ./ \\\n    --genome_assembly ${grch_vers} \\\n    --conf ${config} \\\n    --sample_id \\$META \\\n    --input_vcf ${vcf} \\\n    --input_cna ${jointsegs} \\$PLOIDY \\$PURITY \\\n    --no-docker \\\n    --force_overwrite \\\n    --no_vcf_validate \\\n    --estimate_tmb \\\n    --estimate_msi_status \\\n    --estimate_signatures \\\n    --include_trials \\\n    --assay ${assay}\n\n  } 2>&1 | tee > ${sampleID}.pcgr.log.txt\n  \"\"\"",
        "nb_lignes_script": 35,
        "language_script": "bash",
        "tools": [
            "haploconfig",
            "AssayR"
        ],
        "tools_url": [
            "https://bio.tools/haploconfig",
            "https://bio.tools/assayr"
        ],
        "tools_dico": [
            {
                "name": "haploconfig",
                "uri": "https://bio.tools/haploconfig",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Program that can be used to implement tests of neutrality based on the frequency distribution of haplotypes in a sample of DNA sequences (the \u201chaplotype configuration\u201d) and the number of segregating sites. The neutrality tests can be performed conditional on the standard neutral coalescent model with or without recombination, exponential population growth, or island migration.",
                "homepage": "http://www.stanford.edu/group/rosenberglab/haploconfig.html"
            },
            {
                "name": "AssayR",
                "uri": "https://bio.tools/assayr",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3214",
                                    "term": "Spectral analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3214",
                                    "term": "Spectrum analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3214",
                                    "term": "Mass spectrum analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Simple Mass Spectrometry Software Tool for Targeted Metabolic and Stable Isotope Tracer Analyses.",
                "homepage": "https://gitlab.com/jimiwills/assay.R/"
            }
        ],
        "inputs": [
            "pcgr_inputs",
            "reference",
            "reference"
        ],
        "nb_inputs": 3,
        "outputs": [
            "completed_pcgr",
            "sendmail_pcgr"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "errorStrategy 'retry'",
            "maxRetries 3",
            "publishDir \"${params.outDir}/reports/pcgr\", mode: \"copy\", pattern: \"*html\"",
            "publishDir \"${params.outDir}/samples/${sampleID}/pcgr\", mode: \"copy\", pattern: \"*[!.html]\""
        ],
        "when": "",
        "stub": ""
    },
    "pairtree_setup": {
        "name_process": "pairtree_setup",
        "string_process": "\nprocess pairtree_setup {\n\n  label 'low_mem'\n\n  publishDir \"${params.outDir}/combined/pylogeny\", mode: \"copy\"\n\n  input:\n  file(rdata) from pairtree_rdata\n  file(filesn) from pairtee_facets\n  file(cna_master) from pairtree_facet\n\n  output:\n  tuple file(\"${params.runID}.pairtree.psm\"), file(\"${params.runID}.in_params_fn.json\") into pairtree_in\n\n  script:\n  def which_genome = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  \"\"\"\n  Rscript -e \"somenone::make_pairtree_input(rdata_input = \\\\\"${rdata}\\\\\", cn_master = \\\\\"${cna_master}\\\\\", cn_pattern = \\\\\"fit_cncf_jointsegs.tsv\\\\\", pp_pattern = \\\\\"fit_ploidy_purity.tsv\\\\\", which_genome = \\\\\"${which_genome}\\\\\", tag = \\\\\"${params.runID}\\\\\")\"\n  \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "  def which_genome = params.assembly == \"GRCh37\" ? \"hg19\" : \"hg38\"\n  \"\"\"\n  Rscript -e \"somenone::make_pairtree_input(rdata_input = \\\\\"${rdata}\\\\\", cn_master = \\\\\"${cna_master}\\\\\", cn_pattern = \\\\\"fit_cncf_jointsegs.tsv\\\\\", pp_pattern = \\\\\"fit_ploidy_purity.tsv\\\\\", which_genome = \\\\\"${which_genome}\\\\\", tag = \\\\\"${params.runID}\\\\\")\"\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pairtree_rdata",
            "pairtee_facets",
            "pairtree_facet"
        ],
        "nb_inputs": 3,
        "outputs": [
            "pairtree_in"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/combined/pylogeny\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "pairtree_run": {
        "name_process": "pairtree_run",
        "string_process": "\nprocess pairtree_run {\n\n  label 'low_mem'\n\n  publishDir \"${params.outDir}/combined/phylogeny/pairtree/${model}_${concn}\", mode: \"copy\"\n\n  input:\n  tuple file(pairtree_psm), file(pairtree_json) from pairtree_in\n  each concn from Channel.from(\"-2\",\"-1\",\"0.5\",\"1.5\")\n  each model from Channel.from(\"pairwise\",\"linfreq\")\n\n  output:\n  file('*') into pairtree_res\n\n  script:\n  \"\"\"\n  cut -f 1,2,3,4,5 ${pairtree_psm} > ${params.runID}.pairtree.ssm\n\n  clustervars --model ${model} \\\n              --concentration ${concn} \\\n              ${params.runID}.pairtree.ssm \\\n              ${pairtree_json} \\\n              ${params.runID}.out_params_${model}_${concn}.json\n\n  python /opt/miniconda/envs/pairtree/share/pairtree/util/remove_high_vaf.py ${params.runID}.pairtree.ssm \\\n                            ${params.runID}.out_params_${model}_${concn}.json \\\n                            ${params.runID}.rmvaf_params_${model}_${concn}.json\n\n  pairtree --params ${params.runID}.rmvaf_params_${model}_${concn}.json \\\n           ${params.runID}.pairtree_${model}_${concn}.ssm \\\n           ${params.runID}.res_${model}_${concn}.npz\n\n  plottree ${params.runID}.pairtree_${model}_${concn}.ssm \\\n           ${params.runID}.rmvaf_params_${model}_${concn}.json \\\n           ${params.runID}.res_${model}_${concn}.npz \\\n           ${params.runID}.pairtree_${model}_${concn}.results.html\n  \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "  \"\"\"\n  cut -f 1,2,3,4,5 ${pairtree_psm} > ${params.runID}.pairtree.ssm\n\n  clustervars --model ${model} \\\n              --concentration ${concn} \\\n              ${params.runID}.pairtree.ssm \\\n              ${pairtree_json} \\\n              ${params.runID}.out_params_${model}_${concn}.json\n\n  python /opt/miniconda/envs/pairtree/share/pairtree/util/remove_high_vaf.py ${params.runID}.pairtree.ssm \\\n                            ${params.runID}.out_params_${model}_${concn}.json \\\n                            ${params.runID}.rmvaf_params_${model}_${concn}.json\n\n  pairtree --params ${params.runID}.rmvaf_params_${model}_${concn}.json \\\n           ${params.runID}.pairtree_${model}_${concn}.ssm \\\n           ${params.runID}.res_${model}_${concn}.npz\n\n  plottree ${params.runID}.pairtree_${model}_${concn}.ssm \\\n           ${params.runID}.rmvaf_params_${model}_${concn}.json \\\n           ${params.runID}.res_${model}_${concn}.npz \\\n           ${params.runID}.pairtree_${model}_${concn}.results.html\n  \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pairtree_in"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pairtree_res"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/combined/phylogeny/pairtree/${model}_${concn}\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "mltiQC": {
        "name_process": "mltiQC",
        "string_process": "\nprocess mltiQC {\n\n  label 'low_mem'\n  publishDir path: \"${params.outDir}/reports/multiQC\", mode: \"copy\"\n\n  input:\n  file(fastps) from fastp_multiqc.collect()\n  file(fastqcs) from fastqc_multiqc.collect()\n  file(gtkrcls) from gtkrcl_multiqc.collect()\n  file(multimetrics) from multimetrics_multiqc.collect()\n  file(mrkdups) from mrkdup_multiqc.collect()\n\n  output:\n  file('*') into completedmultiqc\n  file(\"*.html\") into sendmail_multiqc\n\n  script:\n  \"\"\"\n  multiqc . -i ${params.runID}\".somatic_n-of-1\" --tag DNA -f -c ${params.multiqcConfig}\n  \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "  \"\"\"\n  multiqc . -i ${params.runID}\".somatic_n-of-1\" --tag DNA -f -c ${params.multiqcConfig}\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastp_multiqc",
            "fastqc_multiqc",
            "gtkrcl_multiqc",
            "multimetrics_multiqc",
            "mrkdup_multiqc"
        ],
        "nb_inputs": 5,
        "outputs": [
            "completedmultiqc",
            "sendmail_multiqc"
        ],
        "nb_outputs": 2,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir path: \"${params.outDir}/reports/multiQC\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "somenone_software_vers": {
        "name_process": "somenone_software_vers",
        "string_process": "\nprocess somenone_software_vers {\n\n  label 'low_mem'\n  publishDir \"pipeline_info\", mode: 'copy'\n  publishDir path: \"${params.outDir}/reports/software_vers\", mode: \"copy\"\n\n  output:\n  file 'somenone_software_versions.yaml' into ch_somenone_software_vers\n\n  script:\n  \"\"\"\n  conda env export > somenone_software_versions.yaml\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  conda env export > somenone_software_versions.yaml\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "ANACONDA"
        ],
        "tools_url": [
            "https://bio.tools/anaconda"
        ],
        "tools_dico": [
            {
                "name": "ANACONDA",
                "uri": "https://bio.tools/anaconda",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software package specially developed for the study of genes\u2019 primary structure. It uses gene sequences downloaded from public databases, as FASTA and GenBank, and it applies a set of statistical and visualization methods in different ways, to reveal information about codon context, codon usage, nucleotide repeats within open reading frames (ORFeome) and others.",
                "homepage": "http://bioinformatics.ua.pt/software/anaconda/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "ch_somenone_software_vers"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"pipeline_info\", mode: 'copy'",
            "publishDir path: \"${params.outDir}/reports/software_vers\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "gridss_software_vers": {
        "name_process": "gridss_software_vers",
        "string_process": "\nprocess gridss_software_vers {\n\n  label 'low_mem'\n  publishDir \"${params.outDir}/pipeline_info\", mode: 'copy'\n\n  output:\n  file 'gridss_software_versions.txt' into ch_gridss_software_vers\n\n  when:\n  params.seqlevel == \"wgs\"\n\n  script:\n  \"\"\"\n  ls -l /opt/gridss > gridss_software_versions.txt\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  ls -l /opt/gridss > gridss_software_versions.txt\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "ch_gridss_software_vers"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/pipeline_info\", mode: 'copy'"
        ],
        "when": "params.seqlevel == \"wgs\"",
        "stub": ""
    },
    "pcgr_software_vers": {
        "name_process": "pcgr_software_vers",
        "string_process": "\nprocess pcgr_software_vers {\n\n  label 'low_mem'\n  publishDir \"${params.outDir}/pipeline_info\", mode: 'copy'\n\n  output:\n  file 'pcgr_software_versions.txt' into ch_pcgr_software_vers\n\n\n  script:\n  \"\"\"\n  pcgr.py --version > pcgr_software_versions.txt\n  cpsr.py --version >> pcgr_software_versions.txt\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "  \"\"\"\n  pcgr.py --version > pcgr_software_versions.txt\n  cpsr.py --version >> pcgr_software_versions.txt\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "ch_pcgr_software_vers"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'",
            "publishDir \"${params.outDir}/pipeline_info\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "zipup": {
        "name_process": "zipup",
        "string_process": "\nprocess zipup {\n\n  label 'low_mem'\n\n  input:\n  file(send_all) from sendmail_all.collect()\n\n  output:\n  file(\"${params.runID}.somatic_n-of-1.zip\") into send_zip\n\n  script:\n  \"\"\"\n  zip ${params.runID}.somatic_n-of-1.zip *.html\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "  \"\"\"\n  zip ${params.runID}.somatic_n-of-1.zip *.html\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sendmail_all"
        ],
        "nb_inputs": 1,
        "outputs": [
            "send_zip"
        ],
        "nb_outputs": 1,
        "name_workflow": "brucemoran__somatic_n-of-1",
        "directive": [
            "label 'low_mem'"
        ],
        "when": "",
        "stub": ""
    }
}