{
    "plotQual": {
        "name_process": "plotQual",
        "string_process": "\nprocess plotQual {\n    cpus 2\n    executor 'slurm'\n    queue myQueue\n    memory \"12 GB\"\n    module dada2Mod\n    publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"link\"\n\n    input:\n    file allReads from dada2ReadPairsToQual.flatMap({ it[1] }).collect()\n\n    output:\n    file \"R1.pdf\" into forQualPDF\n    file \"R2.pdf\" into revQualPDF\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2); packageVersion(\"dada2\")\n\n    # Forward Reads\n    pdf(\"R1.pdf\")\n    fnFs <- list.files('.', pattern=\"_R1_*.fastq*\", full.names = TRUE)\n    plotQualityProfile(fnFs, aggregate = TRUE)\n    dev.off()\n\n    # Reverse Reads\n    pdf(\"R2.pdf\")\n    fnRs <- list.files('.', pattern=\"_R2_*.fastq*\", full.names = TRUE)\n    plotQualityProfile(fnRs, aggregate = TRUE)\n    dev.off()\n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2); packageVersion(\"dada2\")\n\n    # Forward Reads\n    pdf(\"R1.pdf\")\n    fnFs <- list.files('.', pattern=\"_R1_*.fastq*\", full.names = TRUE)\n    plotQualityProfile(fnFs, aggregate = TRUE)\n    dev.off()\n\n    # Reverse Reads\n    pdf(\"R2.pdf\")\n    fnRs <- list.files('.', pattern=\"_R2_*.fastq*\", full.names = TRUE)\n    plotQualityProfile(fnRs, aggregate = TRUE)\n    dev.off()\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dada2ReadPairsToQual"
        ],
        "nb_inputs": 1,
        "outputs": [
            "forQualPDF",
            "revQualPDF"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "cpus 2",
            "executor 'slurm'",
            "queue myQueue",
            "memory \"12 GB\"",
            "module dada2Mod",
            "publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "filterAndTrim": {
        "name_process": "filterAndTrim",
        "string_process": " process filterAndTrim {\n        tag { \"16s_${pairId}\" }\n        publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"copy\", overwrite: true\n\n        input:\n        set pairId, file(reads) from dada2ReadPairs\n\n        output:\n        set val(pairId), \"*.R1.filtered.fastq.gz\", \"*.R2.filtered.fastq.gz\" optional true into filteredReadsforQC, filteredReads\n        file \"*.R1.filtered.fastq.gz\" optional true into forReads\n        file \"*.R2.filtered.fastq.gz\" optional true into revReads\n        file \"*.trimmed.txt\" into trimTracking\n\n        when:\n        params.precheck == false\n\n        script:\n        phix = params.rmPhiX ? '--rmPhiX TRUE' : '--rmPhiX FALSE'\n        \"\"\"\n        16S_FilterAndTrim.R ${phix} --id ${pairId} \\\\\n            --fwd ${reads[0]} \\\\\n            --rev ${reads[1]} \\\\\n            --cpus ${task.cpus} \\\\\n            --trimFor ${params.trimFor} \\\\\n            --trimRev ${params.trimRev} \\\\\n            --truncFor ${params.truncFor} \\\\\n            --truncRev ${params.truncRev} \\\\\n            --truncQ ${params.truncQ} \\\\\n            --maxEEFor ${params.maxEEFor} \\\\\n            --maxEERev ${params.maxEERev} \\\\\n            --maxN ${params.maxN} \\\\\n            --maxLen ${params.maxLen} \\\\\n            --minLen ${params.minLen}\n        \"\"\"\n    }",
        "nb_lignes_process": 33,
        "string_script": "        phix = params.rmPhiX ? '--rmPhiX TRUE' : '--rmPhiX FALSE'\n        \"\"\"\n        16S_FilterAndTrim.R ${phix} --id ${pairId} \\\\\n            --fwd ${reads[0]} \\\\\n            --rev ${reads[1]} \\\\\n            --cpus ${task.cpus} \\\\\n            --trimFor ${params.trimFor} \\\\\n            --trimRev ${params.trimRev} \\\\\n            --truncFor ${params.truncFor} \\\\\n            --truncRev ${params.truncRev} \\\\\n            --truncQ ${params.truncQ} \\\\\n            --maxEEFor ${params.maxEEFor} \\\\\n            --maxEERev ${params.maxEERev} \\\\\n            --maxN ${params.maxN} \\\\\n            --maxLen ${params.maxLen} \\\\\n            --minLen ${params.minLen}\n        \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dada2ReadPairs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "filteredReadsforQC",
            "filteredReads",
            "forReads",
            "revReads",
            "trimTracking"
        ],
        "nb_outputs": 5,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"16s_${pairId}\" }",
            "publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "mergeTrimmedTable": {
        "name_process": "mergeTrimmedTable",
        "string_process": "\nprocess mergeTrimmedTable {\n    tag { \"mergeTrimmedTable\" }\n    publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"copy\", overwrite: true\n\n    input:\n    file trimData from trimTracking.collect()\n\n    output:\n    file \"all.trimmed.csv\" into trimmedReadTracking\n\n    when:\n    params.precheck == false\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    trimmedFiles <- list.files(path = '.', pattern = '*.trimmed.txt')\n    sample.names <- sub('.trimmed.txt', '', trimmedFiles)\n    trimmed <- do.call(\"rbind\", lapply(trimmedFiles, function (x) as.data.frame(read.csv(x))))\n    colnames(trimmed)[1] <- \"Sequence\"\n    trimmed\\$SampleID <- sample.names\n    write.csv(trimmed, \"all.trimmed.csv\", row.names = FALSE)\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    trimmedFiles <- list.files(path = '.', pattern = '*.trimmed.txt')\n    sample.names <- sub('.trimmed.txt', '', trimmedFiles)\n    trimmed <- do.call(\"rbind\", lapply(trimmedFiles, function (x) as.data.frame(read.csv(x))))\n    colnames(trimmed)[1] <- \"Sequence\"\n    trimmed\\$SampleID <- sample.names\n    write.csv(trimmed, \"all.trimmed.csv\", row.names = FALSE)\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimTracking"
        ],
        "nb_inputs": 1,
        "outputs": [
            "trimmedReadTracking"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"mergeTrimmedTable\" }",
            "publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "LearnErrorsFor": {
        "name_process": "LearnErrorsFor",
        "string_process": "\nprocess LearnErrorsFor {\n    tag { \"LearnErrorsFor\" }\n    publishDir \"${params.outdir}/dada2-LearnErrors\", mode: \"copy\", overwrite: true\n\n    input:\n    file fReads from forReads.collect()\n\n    output:\n    file \"errorsF.RDS\" into errorsFor\n    file \"*.pdf\"\n\n    when:\n    params.precheck == false\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2);\n    packageVersion(\"dada2\")\n\n    # File parsing\n    filtFs <- list.files('.', pattern=\"R1.filtered.fastq.gz\", full.names = TRUE)\n    sample.namesF <- sapply(strsplit(basename(filtFs), \"_\"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz\n    set.seed(100)\n\n    # Learn forward error rates\n    errF <- learnErrors(filtFs, multithread=${task.cpus})\n    pdf(\"R1.err.pdf\")\n    plotErrors(errF, nominalQ=TRUE)\n    dev.off()\n    saveRDS(errF, \"errorsF.RDS\")\n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2);\n    packageVersion(\"dada2\")\n\n    # File parsing\n    filtFs <- list.files('.', pattern=\"R1.filtered.fastq.gz\", full.names = TRUE)\n    sample.namesF <- sapply(strsplit(basename(filtFs), \"_\"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz\n    set.seed(100)\n\n    # Learn forward error rates\n    errF <- learnErrors(filtFs, multithread=${task.cpus})\n    pdf(\"R1.err.pdf\")\n    plotErrors(errF, nominalQ=TRUE)\n    dev.off()\n    saveRDS(errF, \"errorsF.RDS\")\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "forReads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "errorsFor"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"LearnErrorsFor\" }",
            "publishDir \"${params.outdir}/dada2-LearnErrors\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "LearnErrorsRev": {
        "name_process": "LearnErrorsRev",
        "string_process": "\nprocess LearnErrorsRev {\n    tag { \"LearnErrorsRev\" }\n    publishDir \"${params.outdir}/dada2-LearnErrors\", mode: \"copy\", overwrite: true\n\n    input:\n    file rReads from revReads.collect()\n\n    output:\n    file \"errorsR.RDS\" into errorsRev\n    file \"*.pdf\"\n\n    when:\n    params.precheck == false\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2);\n    packageVersion(\"dada2\")\n\n    # load error profiles\n\n    # File parsing\n    filtRs <- list.files('.', pattern=\"R2.filtered.fastq.gz\", full.names = TRUE)\n    sample.namesR <- sapply(strsplit(basename(filtRs), \"_\"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz\n    set.seed(100)\n\n    # Learn forward error rates\n    errR <- learnErrors(filtRs, multithread=${task.cpus})\n    pdf(\"R2.err.pdf\")\n    plotErrors(errR, nominalQ=TRUE)\n    dev.off()\n    saveRDS(errR, \"errorsR.RDS\")\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2);\n    packageVersion(\"dada2\")\n\n    # load error profiles\n\n    # File parsing\n    filtRs <- list.files('.', pattern=\"R2.filtered.fastq.gz\", full.names = TRUE)\n    sample.namesR <- sapply(strsplit(basename(filtRs), \"_\"), `[`, 1) # Assumes filename = samplename_XXX.fastq.gz\n    set.seed(100)\n\n    # Learn forward error rates\n    errR <- learnErrors(filtRs, multithread=${task.cpus})\n    pdf(\"R2.err.pdf\")\n    plotErrors(errR, nominalQ=TRUE)\n    dev.off()\n    saveRDS(errR, \"errorsR.RDS\")\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "revReads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "errorsRev"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"LearnErrorsRev\" }",
            "publishDir \"${params.outdir}/dada2-LearnErrors\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "SampleInferDerepAndMerge": {
        "name_process": "SampleInferDerepAndMerge",
        "string_process": "\nprocess SampleInferDerepAndMerge {\n    tag                  { pairId }\n    cpus 4\n    executor 'slurm'\n    queue myQueue\n    memory \"8 GB\"\n    module dada2Mod\n    publishDir \"${params.outdir}/dada2-Derep\", mode: \"link\"\n\n    input:\n    set val(pairId), file(filtFor), file(filtRev) from filteredReads\n    file errFor from errorsFor\n    file errRev from errorsRev\n\n    output:\n    file \"*.merged.RDS\" into mergedReads\n    file \"*.ddF.RDS\" into dadaFor\n    file \"*.ddR.RDS\" into dadaRev\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    packageVersion(\"dada2\")\n\n    errF <- readRDS(\"${errFor}\")\n    errR <- readRDS(\"${errRev}\")\n    cat(\"Processing:\", \"${pairId}\", \"\\\\n\")\n\n    derepF <- derepFastq(\"${filtFor}\")\n    ddF <- dada(derepF, err=errF, multithread=${task.cpus})\n\n    derepR <- derepFastq(\"${filtRev}\")\n    ddR <- dada(derepR, err=errR, multithread=${task.cpus})\n\n    merger <- mergePairs(ddF, derepF, ddR, derepR,\n        minOverlap = ${params.minOverlap},\n        maxMismatch = ${params.maxMismatch},\n        trimOverhang = TRUE\n        )\n\n    # TODO: make this a single item list with ID as the name, this is lost\n    # further on\n    saveRDS(merger, paste(\"${pairId}\", \"merged\", \"RDS\", sep=\".\"))\n    saveRDS(ddF, paste(\"${pairId}\", \"ddF\", \"RDS\", sep=\".\"))\n    saveRDS(ddR, paste(\"${pairId}\", \"ddR\", \"RDS\", sep=\".\"))\n    \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    packageVersion(\"dada2\")\n\n    errF <- readRDS(\"${errFor}\")\n    errR <- readRDS(\"${errRev}\")\n    cat(\"Processing:\", \"${pairId}\", \"\\\\n\")\n\n    derepF <- derepFastq(\"${filtFor}\")\n    ddF <- dada(derepF, err=errF, multithread=${task.cpus})\n\n    derepR <- derepFastq(\"${filtRev}\")\n    ddR <- dada(derepR, err=errR, multithread=${task.cpus})\n\n    merger <- mergePairs(ddF, derepF, ddR, derepR,\n        minOverlap = ${params.minOverlap},\n        maxMismatch = ${params.maxMismatch},\n        trimOverhang = TRUE\n        )\n\n    # TODO: make this a single item list with ID as the name, this is lost\n    # further on\n    saveRDS(merger, paste(\"${pairId}\", \"merged\", \"RDS\", sep=\".\"))\n    saveRDS(ddF, paste(\"${pairId}\", \"ddF\", \"RDS\", sep=\".\"))\n    saveRDS(ddR, paste(\"${pairId}\", \"ddR\", \"RDS\", sep=\".\"))\n    \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filteredReads",
            "errorsFor",
            "errorsRev"
        ],
        "nb_inputs": 3,
        "outputs": [
            "mergedReads",
            "dadaFor",
            "dadaRev"
        ],
        "nb_outputs": 3,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { pairId }",
            "cpus 4",
            "executor 'slurm'",
            "queue myQueue",
            "memory \"8 GB\"",
            "module dada2Mod",
            "publishDir \"${params.outdir}/dada2-Derep\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "mergeDadaRDS": {
        "name_process": "mergeDadaRDS",
        "string_process": " process mergeDadaRDS {\n        tag { \"mergeDadaRDS\" }\n        publishDir \"${params.outdir}/dada2-Inference\", mode: \"copy\", overwrite: true\n\n        input:\n        file ddFs from dadaFor.collect()\n        file ddRs from dadaRev.collect()\n\n        output:\n        file \"all.ddF.RDS\" into dadaForReadTracking\n        file \"all.ddR.RDS\" into dadaRevReadTracking\n\n        when:\n        params.precheck == false\n\n        script:\n        '''\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        dadaFs <- lapply(list.files(path = '.', pattern = '.ddF.RDS$'), function (x) readRDS(x))\n        names(dadaFs) <- sub('.ddF.RDS', '', list.files('.', pattern = '.ddF.RDS'))\n        dadaRs <- lapply(list.files(path = '.', pattern = '.ddR.RDS$'), function (x) readRDS(x))\n        names(dadaRs) <- sub('.ddR.RDS', '', list.files('.', pattern = '.ddR.RDS'))\n        saveRDS(dadaFs, \"all.ddF.RDS\")\n        saveRDS(dadaRs, \"all.ddR.RDS\")\n        '''\n    }",
        "nb_lignes_process": 27,
        "string_script": "        '''\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        dadaFs <- lapply(list.files(path = '.', pattern = '.ddF.RDS$'), function (x) readRDS(x))\n        names(dadaFs) <- sub('.ddF.RDS', '', list.files('.', pattern = '.ddF.RDS'))\n        dadaRs <- lapply(list.files(path = '.', pattern = '.ddR.RDS$'), function (x) readRDS(x))\n        names(dadaRs) <- sub('.ddR.RDS', '', list.files('.', pattern = '.ddR.RDS'))\n        saveRDS(dadaFs, \"all.ddF.RDS\")\n        saveRDS(dadaRs, \"all.ddR.RDS\")\n        '''",
        "nb_lignes_script": 11,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dadaFor",
            "dadaRev"
        ],
        "nb_inputs": 2,
        "outputs": [
            "dadaForReadTracking",
            "dadaRevReadTracking"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"mergeDadaRDS\" }",
            "publishDir \"${params.outdir}/dada2-Inference\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "SequenceTable": {
        "name_process": "SequenceTable",
        "string_process": " process SequenceTable {\n        tag { \"SequenceTable\" }\n        publishDir \"${params.outdir}/dada2-SeqTable\", mode: \"copy\", overwrite: true\n\n        input:\n        file mr from mergedReads.collect()\n\n        output:\n        file \"seqtab.RDS\" into seqTable\n        file \"all.mergers.RDS\" into mergerTracking\n\n        when:\n        params.precheck == false\n\n        script:\n        '''\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        mergerFiles <- list.files(path = '.', pattern = '.*.RDS$')\n        pairIds <- sub('.merged.RDS', '', mergerFiles)\n        mergers <- lapply(mergerFiles, function (x) readRDS(x))\n        names(mergers) <- pairIds\n        seqtab <- makeSequenceTable(mergers)\n        seqtab <- seqtab[,nchar(colnames(seqtab)) >= ${params.minLen}]\n\n        saveRDS(seqtab, \"seqtab.RDS\")\n        saveRDS(mergers, \"all.mergers.RDS\")\n        '''\n    }",
        "nb_lignes_process": 29,
        "string_script": "        '''\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        mergerFiles <- list.files(path = '.', pattern = '.*.RDS$')\n        pairIds <- sub('.merged.RDS', '', mergerFiles)\n        mergers <- lapply(mergerFiles, function (x) readRDS(x))\n        names(mergers) <- pairIds\n        seqtab <- makeSequenceTable(mergers)\n        seqtab <- seqtab[,nchar(colnames(seqtab)) >= ${params.minLen}]\n\n        saveRDS(seqtab, \"seqtab.RDS\")\n        saveRDS(mergers, \"all.mergers.RDS\")\n        '''",
        "nb_lignes_script": 14,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mergedReads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "seqTable",
            "mergerTracking"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"SequenceTable\" }",
            "publishDir \"${params.outdir}/dada2-SeqTable\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "ChimeraTaxonomySpecies": {
        "name_process": "ChimeraTaxonomySpecies",
        "string_process": " process ChimeraTaxonomySpecies {\n        cpus 24\n        executor 'slurm'\n        queue myQueue\n        memory \"48 GB\"\n        module dada2Mod\n        publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"link\"\n\n        input:\n        file st from seqTable\n        file ref from refFile\n        file sp from speciesFile\n\n        output:\n        file \"seqtab_final.RDS\" into seqTableFinal,seqTableFinalTree,seqTableFinalAln,seqTableFinalTracking\n        file \"tax_final.RDS\" into taxFinal\n\n        script:\n        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        st.all <- readRDS(\"${st}\")\n\n        # Remove chimeras\n        seqtab <- removeBimeraDenovo(st.all, method=\"consensus\", multithread=${task.cpus})\n\n        # Assign taxonomy\n        tax <- assignTaxonomy(seqtab, \"${ref}\", multithread=${task.cpus})\n        tax <- addSpecies(tax, \"${sp}\")\n\n        # Write to disk\n        saveRDS(seqtab, \"seqtab_final.RDS\")\n        saveRDS(tax, \"tax_final.RDS\")\n        \"\"\"\n    }",
        "nb_lignes_process": 35,
        "string_script": "        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        st.all <- readRDS(\"${st}\")\n\n        # Remove chimeras\n        seqtab <- removeBimeraDenovo(st.all, method=\"consensus\", multithread=${task.cpus})\n\n        # Assign taxonomy\n        tax <- assignTaxonomy(seqtab, \"${ref}\", multithread=${task.cpus})\n        tax <- addSpecies(tax, \"${sp}\")\n\n        # Write to disk\n        saveRDS(seqtab, \"seqtab_final.RDS\")\n        saveRDS(tax, \"tax_final.RDS\")\n        \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTable",
            "refFile",
            "speciesFile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "seqTableFinal",
            "seqTableFinalTree",
            "seqTableFinalAln",
            "seqTableFinalTracking",
            "taxFinal"
        ],
        "nb_outputs": 5,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "cpus 24",
            "executor 'slurm'",
            "queue myQueue",
            "memory \"48 GB\"",
            "module dada2Mod",
            "publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "ChimeraTaxonomy": {
        "name_process": "ChimeraTaxonomy",
        "string_process": " process ChimeraTaxonomy {\n        cpus 24\n        executor 'slurm'\n        queue myQueue\n        memory \"48 GB\"\n        module dada2Mod\n        publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"link\"\n\n        input:\n        file st from seqTable\n        file ref from refFile\n\n        output:\n        file \"seqtab_final.RDS\" into seqTableFinal,seqTableFinalTree,seqTableFinalAln,seqTableFinalTracking\n        file \"tax_final.RDS\" into taxFinal\n\n        script:\n        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        st.all <- readRDS(\"${st}\")\n\n        # Remove chimeras\n        seqtab <- removeBimeraDenovo(st.all, method=\"consensus\", multithread=${task.cpus})\n\n        # Assign taxonomy\n        tax <- assignTaxonomy(seqtab, \"${ref}\", multithread=${task.cpus})\n\n        # Write to disk\n        saveRDS(seqtab, \"seqtab_final.RDS\")\n        saveRDS(tax, \"tax_final.RDS\")\n        \"\"\"\n    }",
        "nb_lignes_process": 33,
        "string_script": "        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        st.all <- readRDS(\"${st}\")\n\n        # Remove chimeras\n        seqtab <- removeBimeraDenovo(st.all, method=\"consensus\", multithread=${task.cpus})\n\n        # Assign taxonomy\n        tax <- assignTaxonomy(seqtab, \"${ref}\", multithread=${task.cpus})\n\n        # Write to disk\n        saveRDS(seqtab, \"seqtab_final.RDS\")\n        saveRDS(tax, \"tax_final.RDS\")\n        \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTable",
            "refFile"
        ],
        "nb_inputs": 2,
        "outputs": [
            "seqTableFinal",
            "seqTableFinalTree",
            "seqTableFinalAln",
            "seqTableFinalTracking",
            "taxFinal"
        ],
        "nb_outputs": 5,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "cpus 24",
            "executor 'slurm'",
            "queue myQueue",
            "memory \"48 GB\"",
            "module dada2Mod",
            "publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "BiomFile": {
        "name_process": "BiomFile",
        "string_process": "\nprocess BiomFile {\n    tag { \"BiomFile\" }\n    publishDir \"${params.outdir}/dada2-BIOM\", mode: \"copy\", overwrite: true\n\n    input:\n    file sTable from seqTableFinalToBiom\n    file tTable from taxFinal\n\n    output:\n    file \"dada2.biom\" into biomFile\n\n    when:\n    params.precheck == false & params.toBIOM == true\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(biomformat)\n    packageVersion(\"biomformat\")\n    seqtab <- readRDS(\"${sTable}\")\n    taxtab <- readRDS(\"${tTable}\")\n    st.biom <- make_biom(t(seqtab), observation_metadata = taxtab)\n    write_biom(st.biom, \"dada2.biom\")\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(biomformat)\n    packageVersion(\"biomformat\")\n    seqtab <- readRDS(\"${sTable}\")\n    taxtab <- readRDS(\"${tTable}\")\n    st.biom <- make_biom(t(seqtab), observation_metadata = taxtab)\n    write_biom(st.biom, \"dada2.biom\")\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTableFinalToBiom",
            "taxFinal"
        ],
        "nb_inputs": 2,
        "outputs": [
            "biomFile"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"BiomFile\" }",
            "publishDir \"${params.outdir}/dada2-BIOM\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false & params.toBIOM == true",
        "stub": ""
    },
    "AlignSequences": {
        "name_process": "AlignSequences",
        "string_process": "\nprocess AlignSequences {\n    cpus 12\n    executor 'slurm'\n    queue myQueue\n    memory \"50 GB\"\n    module dada2Mod\n    publishDir \"${params.outdir}/dada2-Alignment\", mode: \"link\"\n\n    input:\n    file sTable from seqTableFinalAln\n\n    output:\n    file \"aligned_seqs.fasta\" into alnSeq\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    library(DECIPHER)\n    library(phangorn)\n\n    seqs <- getSequences(readRDS(\"${sTable}\"))\n    names(seqs) <- seqs # This propagates to the tip labels of the tree\n    alignment <- AlignSeqs(DNAStringSet(seqs),\n                           anchor=NA,\n                           processors = ${task.cpus})\n    writeXStringSet(alignment, \"aligned_seqs.fasta\")\n\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    library(DECIPHER)\n    library(phangorn)\n\n    seqs <- getSequences(readRDS(\"${sTable}\"))\n    names(seqs) <- seqs # This propagates to the tip labels of the tree\n    alignment <- AlignSeqs(DNAStringSet(seqs),\n                           anchor=NA,\n                           processors = ${task.cpus})\n    writeXStringSet(alignment, \"aligned_seqs.fasta\")\n\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTableFinalAln"
        ],
        "nb_inputs": 1,
        "outputs": [
            "alnSeq"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "cpus 12",
            "executor 'slurm'",
            "queue myQueue",
            "memory \"50 GB\"",
            "module dada2Mod",
            "publishDir \"${params.outdir}/dada2-Alignment\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "GeneratePhyloTree": {
        "name_process": "GeneratePhyloTree",
        "string_process": "\nprocess GeneratePhyloTree {\n    cpus 12\n    executor 'slurm'\n    queue myQueue\n    memory \"20 GB\"\n    module fastTreeMod\n    publishDir \"${params.outdir}/dada2-Alignment\", mode: \"link\"\n\n    input:\n    file aligned from alnSeq\n\n    output:\n    file \"*.tree\"\n\n    when:\n    \"${params.skipMakeTree}\" != \"TRUE\"\n\n    script:\n    \"\"\"\n    \n    OMP_NUM_THREADS=${task.cpus} FastTree -nt -gtr -gamma -spr 4 -mlacc 2 -slownni -out fasttree.tree ${aligned}\n\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    \n    OMP_NUM_THREADS=${task.cpus} FastTree -nt -gtr -gamma -spr 4 -mlacc 2 -slownni -out fasttree.tree ${aligned}\n\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alnSeq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "cpus 12",
            "executor 'slurm'",
            "queue myQueue",
            "memory \"20 GB\"",
            "module fastTreeMod",
            "publishDir \"${params.outdir}/dada2-Alignment\", mode: \"link\""
        ],
        "when": "\"${params.skipMakeTree}\" != \"TRUE\"",
        "stub": ""
    },
    "ReadTracking": {
        "name_process": "ReadTracking",
        "string_process": "\nprocess ReadTracking {\n    tag { \"ReadTracking\" }\n    publishDir \"${params.outdir}/dada2-ReadTracking\", mode: \"copy\", overwrite: true\n\n    input:\n    file trimmedTable from trimmedReadTracking\n    file sTable from seqTableFinalTracking\n    file mergers from mergerTracking\n    file ddFs from dadaForReadTracking\n    file ddRs from dadaRevReadTracking\n\n    output:\n    file \"all.readtracking.txt\"\n\n    when:\n    params.precheck == false\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    packageVersion(\"dada2\")\n    library(dplyr)\n\n    getN <- function(x) sum(getUniques(x))\n\n    # the gsub here might be a bit brittle...\n    dadaFs <- as.data.frame(sapply(readRDS(\"${ddFs}\"), getN))\n    rownames(dadaFs) <- gsub('.R1.filtered.fastq.gz', '',rownames(dadaFs))\n    dadaFs\\$SampleID <- rownames(dadaFs)\n\n    dadaRs <- as.data.frame(sapply(readRDS(\"${ddRs}\"), getN))\n    rownames(dadaRs) <- gsub('.R2.filtered.fastq.gz', '',rownames(dadaRs))\n    dadaRs\\$SampleID <- rownames(dadaRs)\n\n    mergers <- as.data.frame(sapply(readRDS(\"${mergers}\"), getN))\n    rownames(mergers) <- gsub('.R1.filtered.fastq.gz', '',rownames(mergers))\n    mergers\\$SampleID <- rownames(mergers)\n\n    seqtab.nochim <- as.data.frame(rowSums(readRDS(\"${sTable}\")))\n    rownames(seqtab.nochim) <- gsub('.R1.filtered.fastq.gz', '',rownames(seqtab.nochim))\n    seqtab.nochim\\$SampleID <- rownames(seqtab.nochim)\n\n    trimmed <- read.csv(\"${trimmedTable}\")\n\n    track <- Reduce(function(...) merge(..., by = \"SampleID\",  all.x=TRUE),  list(trimmed, dadaFs, dadaRs, mergers, seqtab.nochim))\n    # dropped data in later steps gets converted to NA on the join\n    # these are effectively 0\n    track[is.na(track)] <- 0\n\n    colnames(track) <- c(\"SampleID\", \"SequenceR1\", \"input\", \"filtered\", \"denoisedF\", \"denoisedR\", \"merged\", \"nonchim\")\n    write.table(track, \"all.readtracking.txt\", sep = \"\\t\", row.names = FALSE)\n    \"\"\"\n}",
        "nb_lignes_process": 53,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    packageVersion(\"dada2\")\n    library(dplyr)\n\n    getN <- function(x) sum(getUniques(x))\n\n    # the gsub here might be a bit brittle...\n    dadaFs <- as.data.frame(sapply(readRDS(\"${ddFs}\"), getN))\n    rownames(dadaFs) <- gsub('.R1.filtered.fastq.gz', '',rownames(dadaFs))\n    dadaFs\\$SampleID <- rownames(dadaFs)\n\n    dadaRs <- as.data.frame(sapply(readRDS(\"${ddRs}\"), getN))\n    rownames(dadaRs) <- gsub('.R2.filtered.fastq.gz', '',rownames(dadaRs))\n    dadaRs\\$SampleID <- rownames(dadaRs)\n\n    mergers <- as.data.frame(sapply(readRDS(\"${mergers}\"), getN))\n    rownames(mergers) <- gsub('.R1.filtered.fastq.gz', '',rownames(mergers))\n    mergers\\$SampleID <- rownames(mergers)\n\n    seqtab.nochim <- as.data.frame(rowSums(readRDS(\"${sTable}\")))\n    rownames(seqtab.nochim) <- gsub('.R1.filtered.fastq.gz', '',rownames(seqtab.nochim))\n    seqtab.nochim\\$SampleID <- rownames(seqtab.nochim)\n\n    trimmed <- read.csv(\"${trimmedTable}\")\n\n    track <- Reduce(function(...) merge(..., by = \"SampleID\",  all.x=TRUE),  list(trimmed, dadaFs, dadaRs, mergers, seqtab.nochim))\n    # dropped data in later steps gets converted to NA on the join\n    # these are effectively 0\n    track[is.na(track)] <- 0\n\n    colnames(track) <- c(\"SampleID\", \"SequenceR1\", \"input\", \"filtered\", \"denoisedF\", \"denoisedR\", \"merged\", \"nonchim\")\n    write.table(track, \"all.readtracking.txt\", sep = \"\\t\", row.names = FALSE)\n    \"\"\"",
        "nb_lignes_script": 34,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "trimmedReadTracking",
            "seqTableFinalTracking",
            "mergerTracking",
            "dadaForReadTracking",
            "dadaRevReadTracking"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"ReadTracking\" }",
            "publishDir \"${params.outdir}/dada2-ReadTracking\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "runFastQC": {
        "name_process": "runFastQC",
        "string_process": "\nprocess runFastQC {\n    tag { \"rFQC.${pairId}\" }\n    publishDir \"${params.outdir}/FASTQC-Raw\", mode: \"copy\", overwrite: true\n\n    input:\n    set pairId, file(in_fastq) from dada2ReadPairsToQual\n\n    output:\n    file '*_fastqc.{zip,html}' into fastqc_files,fastqc_files2\n\n    \"\"\"\n    fastqc --nogroup -q ${in_fastq.get(0)} ${in_fastq.get(1)}\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n    fastqc --nogroup -q ${in_fastq.get(0)} ${in_fastq.get(1)}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "dada2ReadPairsToQual"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_files",
            "fastqc_files2"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"rFQC.${pairId}\" }",
            "publishDir \"${params.outdir}/FASTQC-Raw\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "runMultiQC": {
        "name_process": "runMultiQC",
        "string_process": "\nprocess runMultiQC {\n    tag { \"runMultiQC\" }\n    publishDir \"${params.outdir}/MultiQC-Raw\", mode: 'copy', overwrite: true\n\n    input:\n    file('./raw-seq/*') from fastqc_files.collect()\n\n    output:\n    file \"*_report.html\" into multiqc_report\n    file \"*_data\"\n\n    script:\n    interactivePlots = params.interactiveMultiQC == true ? \"-ip\" : \"\"\n    \"\"\"\n    multiqc ${interactivePlots} .\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    interactivePlots = params.interactiveMultiQC == true ? \"-ip\" : \"\"\n    \"\"\"\n    multiqc ${interactivePlots} .\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastqc_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "multiqc_report"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"runMultiQC\" }",
            "publishDir \"${params.outdir}/MultiQC-Raw\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "itsFilterAndTrim": {
        "name_process": "itsFilterAndTrim",
        "string_process": " process itsFilterAndTrim {\n        tag { \"ITS_${pairId}\" }\n        publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"copy\", overwrite: true\n\n        input:\n        set pairId, file(reads) from dada2ReadPairs\n\n        output:\n        set val(pairId), \"*.R1.filtered.fastq.gz\", \"*.R2.filtered.fastq.gz\" optional true into filteredReadsforQC, filteredReads\n        file \"*.R1.filtered.fastq.gz\" optional true into forReads\n        file \"*.R2.filtered.fastq.gz\" optional true into revReads\n        file \"*.trimmed.txt\" into trimTracking\n        file \"*.cutadapt.out\" into cutadaptToMultiQC\n        file \"*.R1.cutadapt.fastq.gz\"\n        file \"*.R2.cutadapt.fastq.gz\"\n\n        when:\n        params.precheck == false\n\n        script:\n        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2); packageVersion(\"dada2\")\n        library(ShortRead); packageVersion(\"ShortRead\")\n        library(Biostrings); packageVersion(\"Biostrings\")\n\n        #Filter out reads with N's\n        out1 <- filterAndTrim(fwd = \"${reads[0]}\",\n                            filt = paste0(\"${pairId}\", \".R1.noN.fastq.gz\"),\n                            rev = \"${reads[1]}\",\n                            filt.rev = paste0(\"${pairId}\", \".R2.noN.fastq.gz\"),\n                            maxN = 0,\n                            multithread = ${task.cpus})\n        FWD.RC <- dada2:::rc(\"${params.fwdprimer}\")\n        REV.RC <- dada2:::rc(\"${params.revprimer}\")\n        # Trim FWD and the reverse-complement of REV off of R1 (forward reads)\n        R1.flags <- paste(\"-g\", \"${params.fwdprimer}\", \"-a\", REV.RC)\n        # Trim REV and the reverse-complement of FWD off of R2 (reverse reads)\n        R2.flags <- paste(\"-G\", \"${params.revprimer}\", \"-A\", FWD.RC)\n        system2('cutadapt', stdout = paste0(\"${pairId}\",\".cutadapt.out\"),\n                            args = c(R1.flags, R2.flags,\n                            \"--cores\", ${task.cpus},\n                            \"-n\", 2,\n                            \"-o\", paste0(\"${pairId}\",\".R1.cutadapt.fastq.gz\"),\n                            \"-p\", paste0(\"${pairId}\",\".R2.cutadapt.fastq.gz\"),\n                            paste0(\"${pairId}\",\".R1.noN.fastq.gz\"),\n                            paste0(\"${pairId}\",\".R2.noN.fastq.gz\")))\n\n        out2 <- filterAndTrim(fwd = paste0(\"${pairId}\",\".R1.cutadapt.fastq.gz\"),\n                            filt = paste0(\"${pairId}\", \".R1.filtered.fastq.gz\"),\n                            rev = paste0(\"${pairId}\",\".R2.cutadapt.fastq.gz\"),\n                            filt.rev = paste0(\"${pairId}\", \".R2.filtered.fastq.gz\"),\n                            maxEE = c(${params.maxEEFor},${params.maxEERev}),\n                            truncLen = c(${params.truncFor},${params.truncRev}),\n                            truncQ = ${params.truncQ},\n                            maxN = ${params.maxN},\n                            rm.phix = as.logical(${params.rmPhiX}),\n                            maxLen = ${params.maxLen},\n                            minLen = ${params.minLen},\n                            compress = TRUE,\n                            verbose = TRUE,\n                            multithread = ${task.cpus})\n        #Change input read counts to actual raw read counts\n        out2[1] <- out1[1]\n        write.csv(out2, paste0(\"${pairId}\", \".trimmed.txt\"))\n        \"\"\"\n    }",
        "nb_lignes_process": 65,
        "string_script": "        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2); packageVersion(\"dada2\")\n        library(ShortRead); packageVersion(\"ShortRead\")\n        library(Biostrings); packageVersion(\"Biostrings\")\n\n        #Filter out reads with N's\n        out1 <- filterAndTrim(fwd = \"${reads[0]}\",\n                            filt = paste0(\"${pairId}\", \".R1.noN.fastq.gz\"),\n                            rev = \"${reads[1]}\",\n                            filt.rev = paste0(\"${pairId}\", \".R2.noN.fastq.gz\"),\n                            maxN = 0,\n                            multithread = ${task.cpus})\n        FWD.RC <- dada2:::rc(\"${params.fwdprimer}\")\n        REV.RC <- dada2:::rc(\"${params.revprimer}\")\n        # Trim FWD and the reverse-complement of REV off of R1 (forward reads)\n        R1.flags <- paste(\"-g\", \"${params.fwdprimer}\", \"-a\", REV.RC)\n        # Trim REV and the reverse-complement of FWD off of R2 (reverse reads)\n        R2.flags <- paste(\"-G\", \"${params.revprimer}\", \"-A\", FWD.RC)\n        system2('cutadapt', stdout = paste0(\"${pairId}\",\".cutadapt.out\"),\n                            args = c(R1.flags, R2.flags,\n                            \"--cores\", ${task.cpus},\n                            \"-n\", 2,\n                            \"-o\", paste0(\"${pairId}\",\".R1.cutadapt.fastq.gz\"),\n                            \"-p\", paste0(\"${pairId}\",\".R2.cutadapt.fastq.gz\"),\n                            paste0(\"${pairId}\",\".R1.noN.fastq.gz\"),\n                            paste0(\"${pairId}\",\".R2.noN.fastq.gz\")))\n\n        out2 <- filterAndTrim(fwd = paste0(\"${pairId}\",\".R1.cutadapt.fastq.gz\"),\n                            filt = paste0(\"${pairId}\", \".R1.filtered.fastq.gz\"),\n                            rev = paste0(\"${pairId}\",\".R2.cutadapt.fastq.gz\"),\n                            filt.rev = paste0(\"${pairId}\", \".R2.filtered.fastq.gz\"),\n                            maxEE = c(${params.maxEEFor},${params.maxEERev}),\n                            truncLen = c(${params.truncFor},${params.truncRev}),\n                            truncQ = ${params.truncQ},\n                            maxN = ${params.maxN},\n                            rm.phix = as.logical(${params.rmPhiX}),\n                            maxLen = ${params.maxLen},\n                            minLen = ${params.minLen},\n                            compress = TRUE,\n                            verbose = TRUE,\n                            multithread = ${task.cpus})\n        #Change input read counts to actual raw read counts\n        out2[1] <- out1[1]\n        write.csv(out2, paste0(\"${pairId}\", \".trimmed.txt\"))\n        \"\"\"",
        "nb_lignes_script": 45,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dada2ReadPairs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "filteredReadsforQC",
            "filteredReads",
            "forReads",
            "revReads",
            "trimTracking",
            "cutadaptToMultiQC"
        ],
        "nb_outputs": 6,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"ITS_${pairId}\" }",
            "publishDir \"${params.outdir}/dada2-FilterAndTrim\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "runFastQC_postfilterandtrim": {
        "name_process": "runFastQC_postfilterandtrim",
        "string_process": "\nprocess runFastQC_postfilterandtrim {\n    tag { \"rFQC_post_FT.${pairId}\" }\n    publishDir \"${params.outdir}/FastQC-Post-FilterTrim\", mode: \"copy\", overwrite: true\n\n    input:\n    set val(pairId), file(filtFor), file(filtRev) from filteredReadsforQC\n\n    output:\n    file '*_fastqc.{zip,html}' into fastqc_files_post\n\n    when:\n    params.precheck == false\n\n    \"\"\"\n    fastqc --nogroup -q ${filtFor} ${filtRev}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n    fastqc --nogroup -q ${filtFor} ${filtRev}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "filteredReadsforQC"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_files_post"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"rFQC_post_FT.${pairId}\" }",
            "publishDir \"${params.outdir}/FastQC-Post-FilterTrim\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "runMultiQC_postfilterandtrim": {
        "name_process": "runMultiQC_postfilterandtrim",
        "string_process": "\nprocess runMultiQC_postfilterandtrim {\n    tag { \"runMultiQC_postfilterandtrim\" }\n    publishDir \"${params.outdir}/MultiQC-Post-FilterTrim\", mode: 'copy', overwrite: true\n\n    input:\n    file('./raw-seq/*') from fastqc_files2.collect()\n    file('./trimmed-seq/*') from fastqc_files_post.collect()\n    file('./cutadapt/*') from cutadaptToMultiQC.collect()\n\n    output:\n    file \"*_report.html\" into multiqc_report_post\n    file \"*_data\"\n\n    when:\n    params.precheck == false\n\n    script:\n    interactivePlots = params.interactiveMultiQC == true ? \"-ip\" : \"\"\n    \"\"\"\n    multiqc ${interactivePlots} .\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    interactivePlots = params.interactiveMultiQC == true ? \"-ip\" : \"\"\n    \"\"\"\n    multiqc ${interactivePlots} .\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastqc_files2",
            "fastqc_files_post",
            "cutadaptToMultiQC"
        ],
        "nb_inputs": 3,
        "outputs": [
            "multiqc_report_post"
        ],
        "nb_outputs": 1,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"runMultiQC_postfilterandtrim\" }",
            "publishDir \"${params.outdir}/MultiQC-Post-FilterTrim\", mode: 'copy', overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "PoolSamplesInferDerepAndMerge": {
        "name_process": "PoolSamplesInferDerepAndMerge",
        "string_process": " process PoolSamplesInferDerepAndMerge {\n        tag { \"PoolSamplesInferDerepAndMerge\" }\n        publishDir \"${params.outdir}/dada2-Derep-Pooled\", mode: \"copy\", overwrite: true\n\n                                                                            \n                                                                              \n                                         \n\n        input:\n        file filts from filteredReads.collect( )\n        file errFor from errorsFor\n        file errRev from errorsRev\n\n        output:\n        file \"seqtab.RDS\" into seqTable\n        file \"all.mergers.RDS\" into mergerTracking\n        file \"all.ddF.RDS\" into dadaForReadTracking\n        file \"all.ddR.RDS\" into dadaRevReadTracking\n        file \"all.derepFs.RDS\" into dadaForDerep\n        file \"all.derepRs.RDS\" into dadaRevDerep\n\n        when:\n        params.precheck == false\n\n        script:\n        if (params.rescueUnmerged == true) {\n        \"\"\"\n        VariableLenMergePairs-Pooled.R --errFor ${errFor} \\\\\n            --errRev ${errRev} \\\\\n            --pool ${params.pool} \\\\\n            --cpus ${task.cpus} \\\\\n            --minOverlap ${params.minOverlap} \\\\\n            --maxMismatch ${params.maxMismatch} \\\\\n            --trimOverhang ${params.trimOverhang} \\\\\n            --justConcatenate ${params.justConcatenate} \\\\\n            --rescueUnmerged ${params.rescueUnmerged}\n        \"\"\"\n        } else {                             \n        \"\"\"\n        MergePairs-Pooled.R --errFor ${errFor} \\\\\n            --errRev ${errRev} \\\\\n            --pool ${params.pool} \\\\\n            --cpus ${task.cpus} \\\\\n            --minOverlap ${params.minOverlap} \\\\\n            --maxMismatch ${params.maxMismatch} \\\\\n            --trimOverhang ${params.trimOverhang} \\\\\n            --justConcatenate ${params.justConcatenate}\n        \"\"\"\n        }\n    }",
        "nb_lignes_process": 48,
        "string_script": "        if (params.rescueUnmerged == true) {\n        \"\"\"\n        VariableLenMergePairs-Pooled.R --errFor ${errFor} \\\\\n            --errRev ${errRev} \\\\\n            --pool ${params.pool} \\\\\n            --cpus ${task.cpus} \\\\\n            --minOverlap ${params.minOverlap} \\\\\n            --maxMismatch ${params.maxMismatch} \\\\\n            --trimOverhang ${params.trimOverhang} \\\\\n            --justConcatenate ${params.justConcatenate} \\\\\n            --rescueUnmerged ${params.rescueUnmerged}\n        \"\"\"\n        } else {                             \n        \"\"\"\n        MergePairs-Pooled.R --errFor ${errFor} \\\\\n            --errRev ${errRev} \\\\\n            --pool ${params.pool} \\\\\n            --cpus ${task.cpus} \\\\\n            --minOverlap ${params.minOverlap} \\\\\n            --maxMismatch ${params.maxMismatch} \\\\\n            --trimOverhang ${params.trimOverhang} \\\\\n            --justConcatenate ${params.justConcatenate}\n        \"\"\"\n        }",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filteredReads",
            "errorsFor",
            "errorsRev"
        ],
        "nb_inputs": 3,
        "outputs": [
            "seqTable",
            "mergerTracking",
            "dadaForReadTracking",
            "dadaRevReadTracking",
            "dadaForDerep",
            "dadaRevDerep"
        ],
        "nb_outputs": 6,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"PoolSamplesInferDerepAndMerge\" }",
            "publishDir \"${params.outdir}/dada2-Derep-Pooled\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "PerSampleInferDerepAndMerge": {
        "name_process": "PerSampleInferDerepAndMerge",
        "string_process": " process PerSampleInferDerepAndMerge {\n        tag { \"PerSampleInferDerepAndMerge\" }\n        publishDir \"${params.outdir}/dada2-Derep\", mode: \"copy\", overwrite: true\n\n        input:\n        set val(pairId), file(filtFor), file(filtRev) from filteredReads\n        file errFor from errorsFor\n        file errRev from errorsRev\n\n        output:\n        file \"seqtab.RDS\" into seqTable\n        file \"all.mergers.RDS\" into mergerTracking\n        file \"all.ddF.RDS\" into dadaForReadTracking\n        file \"all.ddR.RDS\" into dadaRevReadTracking\n        file \"all.derepF.RDS\" into dadaForDerep\n        file \"all.derepR.RDS\" into dadaRevDerep\n\n        when:\n        params.precheck == false\n\n        script:\n        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        errF <- readRDS(\"${errFor}\")\n        errR <- readRDS(\"${errRev}\")\n        cat(\"Processing:\", \"${pairId}\", \"\\\\n\")\n\n        derepF <- derepFastq(\"${filtFor}\")\n\n        ddF <- dada(derepF, err=errF, multithread=${task.cpus}, pool=as.logical(\"${params.pool}\"))\n\n        derepR <- derepFastq(\"${filtRev}\")\n        ddR <- dada(derepR, err=errR, multithread=${task.cpus}, pool=as.logical(\"${params.pool}\"))\n\n        merger <- mergePairs(ddF, derepF, ddR, derepR,\n            returnRejects = TRUE,\n            minOverlap = ${params.minOverlap},\n            maxMismatch = ${params.maxMismatch},\n            trimOverhang = as.logical(\"${params.trimOverhang}\"),\n            justConcatenate=as.logical(\"${params.justConcatenate}\")\n            )\n\n        saveRDS(merger, paste(\"${pairId}\", \"merged\", \"RDS\", sep=\".\"))\n\n        saveRDS(ddFs, \"all.ddF.RDS\")\n        saveRDS(derepFs, \"all.derepFs.RDS\")\n\n        saveRDS(ddRs, \"all.ddR.RDS\")\n        saveRDS(derepRs, \"all.derepRs.RDS\")\n        \"\"\"\n    }",
        "nb_lignes_process": 52,
        "string_script": "        \"\"\"\n        #!/usr/bin/env Rscript\n        library(dada2)\n        packageVersion(\"dada2\")\n\n        errF <- readRDS(\"${errFor}\")\n        errR <- readRDS(\"${errRev}\")\n        cat(\"Processing:\", \"${pairId}\", \"\\\\n\")\n\n        derepF <- derepFastq(\"${filtFor}\")\n\n        ddF <- dada(derepF, err=errF, multithread=${task.cpus}, pool=as.logical(\"${params.pool}\"))\n\n        derepR <- derepFastq(\"${filtRev}\")\n        ddR <- dada(derepR, err=errR, multithread=${task.cpus}, pool=as.logical(\"${params.pool}\"))\n\n        merger <- mergePairs(ddF, derepF, ddR, derepR,\n            returnRejects = TRUE,\n            minOverlap = ${params.minOverlap},\n            maxMismatch = ${params.maxMismatch},\n            trimOverhang = as.logical(\"${params.trimOverhang}\"),\n            justConcatenate=as.logical(\"${params.justConcatenate}\")\n            )\n\n        saveRDS(merger, paste(\"${pairId}\", \"merged\", \"RDS\", sep=\".\"))\n\n        saveRDS(ddFs, \"all.ddF.RDS\")\n        saveRDS(derepFs, \"all.derepFs.RDS\")\n\n        saveRDS(ddRs, \"all.ddR.RDS\")\n        saveRDS(derepRs, \"all.derepRs.RDS\")\n        \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filteredReads",
            "errorsFor",
            "errorsRev"
        ],
        "nb_inputs": 3,
        "outputs": [
            "seqTable",
            "mergerTracking",
            "dadaForReadTracking",
            "dadaRevReadTracking",
            "dadaForDerep",
            "dadaRevDerep"
        ],
        "nb_outputs": 6,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"PerSampleInferDerepAndMerge\" }",
            "publishDir \"${params.outdir}/dada2-Derep\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "RemoveChimeras": {
        "name_process": "RemoveChimeras",
        "string_process": "\nprocess RemoveChimeras {\n    tag { \"RemoveChimeras\" }\n    publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true\n\n    input:\n    file st from seqTable\n\n    output:\n    file \"seqtab_final.RDS\" into seqTableFinalToBiom,seqTableFinalToTax,seqTableFinalTree,seqTableFinalTracking,seqTableToTable\n\n    when:\n    params.precheck == false\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    packageVersion(\"dada2\")\n\n    st.all <- readRDS(\"${st}\")\n\n    # Remove chimeras\n    seqtab <- removeBimeraDenovo(st.all, method=\"consensus\", multithread=${task.cpus})\n\n    saveRDS(seqtab, \"seqtab_final.RDS\")\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    packageVersion(\"dada2\")\n\n    st.all <- readRDS(\"${st}\")\n\n    # Remove chimeras\n    seqtab <- removeBimeraDenovo(st.all, method=\"consensus\", multithread=${task.cpus})\n\n    saveRDS(seqtab, \"seqtab_final.RDS\")\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTable"
        ],
        "nb_inputs": 1,
        "outputs": [
            "seqTableFinalToBiom",
            "seqTableFinalToTax",
            "seqTableFinalTree",
            "seqTableFinalTracking",
            "seqTableToTable"
        ],
        "nb_outputs": 5,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"RemoveChimeras\" }",
            "publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "AssignTaxSpeciesRDP": {
        "name_process": "AssignTaxSpeciesRDP",
        "string_process": " process AssignTaxSpeciesRDP {\n                tag { \"AssignTaxSpeciesRDP\" }\n                publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true\n\n                input:\n                file st from seqTableFinalToTax\n                file ref from refFile\n                file sp from speciesFile\n\n                output:\n                file \"tax_final.RDS\" into taxFinal,taxTableToTable\n                file \"bootstrap_final.RDS\" into bootstrapFinal\n\n                when:\n                params.precheck == false\n\n                script:\n                \"\"\"\n                #!/usr/bin/env Rscript\n                library(dada2)\n                packageVersion(\"dada2\")\n\n                seqtab <- readRDS(\"${st}\")\n\n                # Assign taxonomy\n                tax <- assignTaxonomy(seqtab, \"${ref}\",\n                                        multithread=${task.cpus},\n                                        tryRC = TRUE,\n                                        outputBootstraps = TRUE,\n                                        verbose = TRUE)\n                boots <- tax\\$boot\n\n                tax <- addSpecies(tax\\$tax, \"${sp}\",\n                                 tryRC = TRUE,\n                                 verbose = TRUE)\n\n                # Write original data\n                saveRDS(tax, \"tax_final.RDS\")\n                saveRDS(boots, \"bootstrap_final.RDS\")\n                \"\"\"\n            }",
        "nb_lignes_process": 39,
        "string_script": "                \"\"\"\n                #!/usr/bin/env Rscript\n                library(dada2)\n                packageVersion(\"dada2\")\n\n                seqtab <- readRDS(\"${st}\")\n\n                # Assign taxonomy\n                tax <- assignTaxonomy(seqtab, \"${ref}\",\n                                        multithread=${task.cpus},\n                                        tryRC = TRUE,\n                                        outputBootstraps = TRUE,\n                                        verbose = TRUE)\n                boots <- tax\\$boot\n\n                tax <- addSpecies(tax\\$tax, \"${sp}\",\n                                 tryRC = TRUE,\n                                 verbose = TRUE)\n\n                # Write original data\n                saveRDS(tax, \"tax_final.RDS\")\n                saveRDS(boots, \"bootstrap_final.RDS\")\n                \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTableFinalToTax",
            "refFile",
            "speciesFile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "taxFinal",
            "taxTableToTable",
            "bootstrapFinal"
        ],
        "nb_outputs": 3,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"AssignTaxSpeciesRDP\" }",
            "publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "AssignTaxonomyRDP": {
        "name_process": "AssignTaxonomyRDP",
        "string_process": " process AssignTaxonomyRDP {\n                tag { \"TaxonomyRDP\" }\n                publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true\n\n                input:\n                file st from seqTableFinalToTax\n                file ref from refFile\n\n                output:\n                file \"tax_final.RDS\" into taxFinal,taxTableToTable\n                file \"bootstrap_final.RDS\" into bootstrapFinal\n\n                when:\n                params.precheck == false\n\n                script:\n                \"\"\"\n                #!/usr/bin/env Rscript\n                library(dada2)\n                packageVersion(\"dada2\")\n\n                seqtab <- readRDS(\"${st}\")\n\n                # Assign taxonomy\n                tax <- assignTaxonomy(seqtab, \"${ref}\",\n                                      multithread=${task.cpus},\n                                      tryRC = TRUE,\n                                      outputBootstraps = TRUE,\n                                      verbose = TRUE)\n\n                # Write to disk\n                saveRDS(tax\\$tax, \"tax_final.RDS\")\n                saveRDS(tax\\$boot, \"bootstrap_final.RDS\")\n                \"\"\"\n            }",
        "nb_lignes_process": 33,
        "string_script": "                \"\"\"\n                #!/usr/bin/env Rscript\n                library(dada2)\n                packageVersion(\"dada2\")\n\n                seqtab <- readRDS(\"${st}\")\n\n                # Assign taxonomy\n                tax <- assignTaxonomy(seqtab, \"${ref}\",\n                                      multithread=${task.cpus},\n                                      tryRC = TRUE,\n                                      outputBootstraps = TRUE,\n                                      verbose = TRUE)\n\n                # Write to disk\n                saveRDS(tax\\$tax, \"tax_final.RDS\")\n                saveRDS(tax\\$boot, \"bootstrap_final.RDS\")\n                \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTableFinalToTax",
            "refFile"
        ],
        "nb_inputs": 2,
        "outputs": [
            "taxFinal",
            "taxTableToTable",
            "bootstrapFinal"
        ],
        "nb_outputs": 3,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"TaxonomyRDP\" }",
            "publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "TaxonomyIDTAXA": {
        "name_process": "TaxonomyIDTAXA",
        "string_process": " process TaxonomyIDTAXA {\n            tag { \"TaxonomyIDTAXA\" }\n            publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true\n\n            input:\n            file st from seqTableFinalToTax\n            file ref from refFile                                                    \n\n            output:\n            file \"tax_final.RDS\" into taxFinal,taxTableToTable\n            file \"bootstrap_final.RDS\" into bootstrapFinal\n            file \"raw_idtaxa.RDS\"\n\n            when:\n            params.precheck == false\n\n            script:\n            \"\"\"\n            #!/usr/bin/env Rscript\n            library(dada2)\n            library(DECIPHER)\n            packageVersion(\"DECIPHER\")\n\n            seqtab <- readRDS(\"${st}\")\n\n            # Create a DNAStringSet from the ASVs\n            dna <- DNAStringSet(getSequences(seqtab))\n\n            # load database; this should be a RData file\n            load(\"${refFile}\")\n\n            ids <- IdTaxa(dna, trainingSet,\n                strand=\"both\",\n                processors=${task.cpus},\n                verbose=TRUE)\n            # ranks of interest\n            ranks <- c(\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\")\n            saveRDS(ids, 'raw_idtaxa.RDS')\n\n            # Convert the output object of class \"Taxa\" to a matrix analogous to the output from assignTaxonomy\n            taxid <- t(sapply(ids, function(x) {\n                    m <- match(ranks, x\\$rank)\n                    taxa <- x\\$taxon[m]\n                    taxa[startsWith(taxa, \"unclassified_\")] <- NA\n                    taxa\n            }))\n            colnames(taxid) <- ranks\n            rownames(taxid) <- getSequences(seqtab)\n\n            boots <- t(sapply(ids, function(x) {\n                    m <- match(ranks, x\\$rank)\n                    bs <- x\\$confidence[m]\n                    bs\n            }))\n            colnames(boots) <- ranks\n            rownames(boots) <- getSequences(seqtab)\n\n            # Write to disk\n            saveRDS(taxid, \"tax_final.RDS\")\n            saveRDS(boots, \"bootstrap_final.RDS\")\n            \"\"\"\n        }",
        "nb_lignes_process": 60,
        "string_script": "            \"\"\"\n            #!/usr/bin/env Rscript\n            library(dada2)\n            library(DECIPHER)\n            packageVersion(\"DECIPHER\")\n\n            seqtab <- readRDS(\"${st}\")\n\n            # Create a DNAStringSet from the ASVs\n            dna <- DNAStringSet(getSequences(seqtab))\n\n            # load database; this should be a RData file\n            load(\"${refFile}\")\n\n            ids <- IdTaxa(dna, trainingSet,\n                strand=\"both\",\n                processors=${task.cpus},\n                verbose=TRUE)\n            # ranks of interest\n            ranks <- c(\"domain\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\")\n            saveRDS(ids, 'raw_idtaxa.RDS')\n\n            # Convert the output object of class \"Taxa\" to a matrix analogous to the output from assignTaxonomy\n            taxid <- t(sapply(ids, function(x) {\n                    m <- match(ranks, x\\$rank)\n                    taxa <- x\\$taxon[m]\n                    taxa[startsWith(taxa, \"unclassified_\")] <- NA\n                    taxa\n            }))\n            colnames(taxid) <- ranks\n            rownames(taxid) <- getSequences(seqtab)\n\n            boots <- t(sapply(ids, function(x) {\n                    m <- match(ranks, x\\$rank)\n                    bs <- x\\$confidence[m]\n                    bs\n            }))\n            colnames(boots) <- ranks\n            rownames(boots) <- getSequences(seqtab)\n\n            # Write to disk\n            saveRDS(taxid, \"tax_final.RDS\")\n            saveRDS(boots, \"bootstrap_final.RDS\")\n            \"\"\"",
        "nb_lignes_script": 43,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTableFinalToTax",
            "refFile"
        ],
        "nb_inputs": 2,
        "outputs": [
            "taxFinal",
            "taxTableToTable",
            "bootstrapFinal"
        ],
        "nb_outputs": 3,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"TaxonomyIDTAXA\" }",
            "publishDir \"${params.outdir}/dada2-Chimera-Taxonomy\", mode: \"copy\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "GenerateSeqTables": {
        "name_process": "GenerateSeqTables",
        "string_process": "\nprocess GenerateSeqTables {\n    tag { \"GenerateSeqTables\" }\n    publishDir \"${params.outdir}/dada2-Tables\", mode: \"link\", overwrite: true\n\n    input:\n    file st from seqTableToTable\n\n    output:\n    file \"seqtab_final.simple.RDS\" into seqtabToPhyloseq,seqtabToTaxTable\n    file \"asvs.simple.fna\" into seqsToAln, seqsToQIIME2\n    file \"seqtab_final.simple.qiime2.txt\" into featuretableToQIIME2\n    file \"asvs.mapping.txt\" into seqsToTaxTable\n    file \"*.txt\"\n\n    when:\n    params.precheck == false\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    library(ShortRead)\n\n    seqtab <- readRDS(\"${st}\")\n\n    if (as.logical('${params.sampleRegex}' != FALSE )) {\n        rownames(seqtab) <- gsub('${params.sampleRegex}', \"\\\\\\\\1\", rownames(seqtab), perl = TRUE)\n    }\n\n    # Generate table output\n    write.table(data.frame('SampleID' = row.names(seqtab), seqtab),\n        file = 'seqtab_final.txt',\n        row.names = FALSE,\n        col.names=c('#SampleID', colnames(seqtab)), sep = \"\\t\")\n\n    ######################################################################\n    # Convert to simple table + FASTA, from\n    # https://github.com/LangilleLab/microbiome_helper/blob/master/convert_dada2_out.R#L69\n    ######################################################################\n\n    # replace names\n    seqs <- colnames(seqtab)\n    ids_study <- paste(\"ASV\", 1:ncol(seqtab), sep = \"\")\n    colnames(seqtab) <- ids_study\n\n    # Generate OTU table output (rows = samples, cols = ASV)\n    write.table(data.frame('SampleID' = row.names(seqtab), seqtab),\n        file = 'seqtab_final.simple.txt',\n        row.names = FALSE,\n        col.names=c('#SampleID', colnames(seqtab)),\n        sep = \"\\t\")\n\n    # Generate OTU table for QIIME2 import (rows = ASVs, cols = samples)\n    # TODO: split out into or move to separate process when QIIME2 is requested\n    write.table(\n        data.frame('Taxa' = colnames(seqtab), t(seqtab)),\n        file = 'seqtab_final.simple.qiime2.txt',\n        row.names = FALSE,\n        quote=FALSE,\n        sep = \"\\t\")\n\n    # generate FASTA\n    seqs.dna <- ShortRead(sread = DNAStringSet(seqs), id = BStringSet(ids_study))\n    # Write out fasta file.\n    writeFasta(seqs.dna, file = 'asvs.simple.fna')\n\n    # generate ASV(sequence) -> ID mapping table\n    write.table(\n        data.frame('ASV' = seqs, 'ASVID' = ids_study),\n        file = 'asvs.mapping.txt',\n        row.names = FALSE,\n        quote=FALSE,\n        sep = \"\\t\")\n\n    # Write modified data\n    saveRDS(seqtab, \"seqtab_final.simple.RDS\")\n    \"\"\"\n}",
        "nb_lignes_process": 77,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    library(ShortRead)\n\n    seqtab <- readRDS(\"${st}\")\n\n    if (as.logical('${params.sampleRegex}' != FALSE )) {\n        rownames(seqtab) <- gsub('${params.sampleRegex}', \"\\\\\\\\1\", rownames(seqtab), perl = TRUE)\n    }\n\n    # Generate table output\n    write.table(data.frame('SampleID' = row.names(seqtab), seqtab),\n        file = 'seqtab_final.txt',\n        row.names = FALSE,\n        col.names=c('#SampleID', colnames(seqtab)), sep = \"\\t\")\n\n    ######################################################################\n    # Convert to simple table + FASTA, from\n    # https://github.com/LangilleLab/microbiome_helper/blob/master/convert_dada2_out.R#L69\n    ######################################################################\n\n    # replace names\n    seqs <- colnames(seqtab)\n    ids_study <- paste(\"ASV\", 1:ncol(seqtab), sep = \"\")\n    colnames(seqtab) <- ids_study\n\n    # Generate OTU table output (rows = samples, cols = ASV)\n    write.table(data.frame('SampleID' = row.names(seqtab), seqtab),\n        file = 'seqtab_final.simple.txt',\n        row.names = FALSE,\n        col.names=c('#SampleID', colnames(seqtab)),\n        sep = \"\\t\")\n\n    # Generate OTU table for QIIME2 import (rows = ASVs, cols = samples)\n    # TODO: split out into or move to separate process when QIIME2 is requested\n    write.table(\n        data.frame('Taxa' = colnames(seqtab), t(seqtab)),\n        file = 'seqtab_final.simple.qiime2.txt',\n        row.names = FALSE,\n        quote=FALSE,\n        sep = \"\\t\")\n\n    # generate FASTA\n    seqs.dna <- ShortRead(sread = DNAStringSet(seqs), id = BStringSet(ids_study))\n    # Write out fasta file.\n    writeFasta(seqs.dna, file = 'asvs.simple.fna')\n\n    # generate ASV(sequence) -> ID mapping table\n    write.table(\n        data.frame('ASV' = seqs, 'ASVID' = ids_study),\n        file = 'asvs.mapping.txt',\n        row.names = FALSE,\n        quote=FALSE,\n        sep = \"\\t\")\n\n    # Write modified data\n    saveRDS(seqtab, \"seqtab_final.simple.RDS\")\n    \"\"\"",
        "nb_lignes_script": 58,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqTableToTable"
        ],
        "nb_inputs": 1,
        "outputs": [
            "seqtabToPhyloseq",
            "seqtabToTaxTable",
            "seqsToAln",
            "seqsToQIIME2",
            "featuretableToQIIME2",
            "seqsToTaxTable"
        ],
        "nb_outputs": 6,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"GenerateSeqTables\" }",
            "publishDir \"${params.outdir}/dada2-Tables\", mode: \"link\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "GenerateTaxTables": {
        "name_process": "GenerateTaxTables",
        "string_process": "\nprocess GenerateTaxTables {\n    tag { \"GenerateTaxTables\" }\n    publishDir \"${params.outdir}/dada2-Tables\", mode: \"link\", overwrite: true\n\n    input:\n    file st from seqtabToTaxTable\n    file tax from taxTableToTable\n    file bt from bootstrapFinal\n    file mapping from seqsToTaxTable\n\n    output:\n    file \"tax_final.simple.RDS\" into taxtabToPhyloseq\n    file \"tax_final.simple.txt\" into taxtableToQIIME2\n    file \"*.txt\"\n\n    when:\n    params.precheck == false\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    library(ShortRead)\n\n    seqtab <- readRDS(\"${st}\")\n    tax <- readRDS(\"${tax}\")\n    seqs <- read.table(\"${mapping}\")\n\n    # Note that we use the old ASV ID for output here\n    write.table(data.frame('ASVID' = row.names(tax), tax),\n        file = 'tax_final.txt',\n        row.names = FALSE,\n        col.names=c('#OTU ID', colnames(tax)), sep = \"\\t\")\n\n    # replace names\n    seqs <- colnames(seqtab)\n\n    # Tax table\n    if(!identical(rownames(tax), seqs)){\n        stop(\"sequences in taxa and sequence table are not ordered the same.\")\n    }\n\n    tax[is.na(tax)] <- \"Unclassified\"\n    rownames(tax) <- ids_study\n    taxa_combined <- apply(tax, 1, function(x) paste(x, collapse=\";\"))\n    taxa_out <- data.frame(names(taxa_combined), taxa_combined)\n    colnames(taxa_out) <- c(\"#OTU ID\", \"taxonomy\")\n\n    write.table(data.frame('ASVID' = row.names(tax), tax),\n        file = 'tax_final.simple.full.txt',\n        row.names = FALSE,\n        col.names=c('#OTU ID', colnames(tax)), sep = \"\\t\")\n\n    write.table(taxa_out,\n        file = 'tax_final.simple.txt',\n        row.names = FALSE,\n        sep = \"\\t\")\n\n    if (file.exists('bootstrap_final.RDS')) {\n        boots <- readRDS(\"${bt}\")\n        if(!identical(rownames(boots), seqs)){\n            stop(\"sequences in bootstrap and sequence table are not ordered the same.\")\n        }\n        rownames(boots) <- ids_study\n        write.table(data.frame('ASVID' = row.names(boots), boots),\n            file = 'tax_final.bootstraps.simple.full.txt',\n            row.names = FALSE,\n            col.names=c('#OTU ID', colnames(boots)), sep = \"\\t\")\n    }\n\n    # Write modified data\n    saveRDS(tax, \"tax_final.simple.RDS\")\n    \"\"\"\n}",
        "nb_lignes_process": 73,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n    library(dada2)\n    library(ShortRead)\n\n    seqtab <- readRDS(\"${st}\")\n    tax <- readRDS(\"${tax}\")\n    seqs <- read.table(\"${mapping}\")\n\n    # Note that we use the old ASV ID for output here\n    write.table(data.frame('ASVID' = row.names(tax), tax),\n        file = 'tax_final.txt',\n        row.names = FALSE,\n        col.names=c('#OTU ID', colnames(tax)), sep = \"\\t\")\n\n    # replace names\n    seqs <- colnames(seqtab)\n\n    # Tax table\n    if(!identical(rownames(tax), seqs)){\n        stop(\"sequences in taxa and sequence table are not ordered the same.\")\n    }\n\n    tax[is.na(tax)] <- \"Unclassified\"\n    rownames(tax) <- ids_study\n    taxa_combined <- apply(tax, 1, function(x) paste(x, collapse=\";\"))\n    taxa_out <- data.frame(names(taxa_combined), taxa_combined)\n    colnames(taxa_out) <- c(\"#OTU ID\", \"taxonomy\")\n\n    write.table(data.frame('ASVID' = row.names(tax), tax),\n        file = 'tax_final.simple.full.txt',\n        row.names = FALSE,\n        col.names=c('#OTU ID', colnames(tax)), sep = \"\\t\")\n\n    write.table(taxa_out,\n        file = 'tax_final.simple.txt',\n        row.names = FALSE,\n        sep = \"\\t\")\n\n    if (file.exists('bootstrap_final.RDS')) {\n        boots <- readRDS(\"${bt}\")\n        if(!identical(rownames(boots), seqs)){\n            stop(\"sequences in bootstrap and sequence table are not ordered the same.\")\n        }\n        rownames(boots) <- ids_study\n        write.table(data.frame('ASVID' = row.names(boots), boots),\n            file = 'tax_final.bootstraps.simple.full.txt',\n            row.names = FALSE,\n            col.names=c('#OTU ID', colnames(boots)), sep = \"\\t\")\n    }\n\n    # Write modified data\n    saveRDS(tax, \"tax_final.simple.RDS\")\n    \"\"\"",
        "nb_lignes_script": 53,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqtabToTaxTable",
            "taxTableToTable",
            "bootstrapFinal",
            "seqsToTaxTable"
        ],
        "nb_inputs": 4,
        "outputs": [
            "taxtabToPhyloseq",
            "taxtableToQIIME2"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"GenerateTaxTables\" }",
            "publishDir \"${params.outdir}/dada2-Tables\", mode: \"link\", overwrite: true"
        ],
        "when": "params.precheck == false",
        "stub": ""
    },
    "AlignReadsInfernal": {
        "name_process": "AlignReadsInfernal",
        "string_process": " process AlignReadsInfernal {\n            tag { \"AlignReadsInfernal\" }\n            publishDir \"${params.outdir}/dada2-Infernal\", mode: \"copy\", overwrite: true\n\n            input:\n            file seqs from seqsToAln\n            file cm from cmFile\n\n            output:\n            file \"aligned_seqs.stk\"\n            file \"aln.scores\"\n            file \"aligned_seqs.fasta\" into alnFile,alnToQIIME2\n\n            script:\n            \"\"\"\n            # from the original IM-TORNADO pipeline\n            cmalign --cpu ${task.cpus} \\\\\n                  -g --notrunc --sub --dnaout --noprob \\\\\n                  --sfile aln.scores \\\\\n                  -o aligned_seqs.stk \\\\\n                  ${cm} ${seqs}\n\n            # script from P. Jeraldo (Mayo)\n            stkToFasta.py aligned_seqs.stk aligned_seqs.fasta\n            \"\"\"\n        }",
        "nb_lignes_process": 24,
        "string_script": "            \"\"\"\n            # from the original IM-TORNADO pipeline\n            cmalign --cpu ${task.cpus} \\\\\n                  -g --notrunc --sub --dnaout --noprob \\\\\n                  --sfile aln.scores \\\\\n                  -o aligned_seqs.stk \\\\\n                  ${cm} ${seqs}\n\n            # script from P. Jeraldo (Mayo)\n            stkToFasta.py aligned_seqs.stk aligned_seqs.fasta\n            \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqsToAln",
            "cmFile"
        ],
        "nb_inputs": 2,
        "outputs": [
            "alnFile",
            "alnToQIIME2"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"AlignReadsInfernal\" }",
            "publishDir \"${params.outdir}/dada2-Infernal\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "AlignReadsDECIPHER": {
        "name_process": "AlignReadsDECIPHER",
        "string_process": " process AlignReadsDECIPHER {\n            tag { \"AlignReadsDECIPHER\" }\n            publishDir \"${params.outdir}/dada2-DECIPHER\", mode: \"copy\", overwrite: true\n\n            input:\n            file seqs from seqsToAln\n\n            output:\n            file \"aligned_seqs.fasta\" into alnFile,alnToQIIME2\n\n            script:\n            \"\"\"\n            #!/usr/bin/env Rscript\n            library(dada2)\n            library(DECIPHER)\n\n            seqs <- readDNAStringSet(\"${seqs}\")\n            alignment <- AlignSeqs(seqs,\n                                   anchor=NA,\n                                   processors = ${task.cpus})\n            writeXStringSet(alignment, \"aligned_seqs.fasta\")\n            \"\"\"\n        }",
        "nb_lignes_process": 21,
        "string_script": "            \"\"\"\n            #!/usr/bin/env Rscript\n            library(dada2)\n            library(DECIPHER)\n\n            seqs <- readDNAStringSet(\"${seqs}\")\n            alignment <- AlignSeqs(seqs,\n                                   anchor=NA,\n                                   processors = ${task.cpus})\n            writeXStringSet(alignment, \"aligned_seqs.fasta\")\n            \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seqsToAln"
        ],
        "nb_inputs": 1,
        "outputs": [
            "alnFile",
            "alnToQIIME2"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"AlignReadsDECIPHER\" }",
            "publishDir \"${params.outdir}/dada2-DECIPHER\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "GenerateTreePhangorn": {
        "name_process": "GenerateTreePhangorn",
        "string_process": " process GenerateTreePhangorn {\n            tag { \"GenerateTreePhangorn\" }\n            publishDir \"${params.outdir}/dada2-Phangorn\", mode: \"copy\", overwrite: true\n\n            input:\n            file aln from alnFile\n\n            output:\n            file \"phangorn.tree.RDS\" into treeRDS\n            file \"tree.newick\" into treeFile\n            file \"tree.GTR.newick\" into treeGTRFile\n\n            script:\n            \"\"\"\n            #!/usr/bin/env Rscript\n            library(phangorn)\n\n            phang.align <- read.phyDat(\"aligned_seqs.fasta\",\n                                        format = \"fasta\",\n                                        type = \"DNA\")\n\n            dm <- dist.ml(phang.align)\n            treeNJ <- NJ(dm) # Note, tip order != sequence order\n            fit = pml(treeNJ, data=phang.align)\n            write.tree(fit\\$tree, file = \"tree.newick\")\n\n            ## negative edges length changed to 0!\n            fitGTR <- update(fit, k=4, inv=0.2)\n            fitGTR <- optim.pml(fitGTR, model=\"GTR\", optInv=TRUE, optGamma=TRUE,\n                                  rearrangement = \"stochastic\", control = pml.control(trace = 0))\n            saveRDS(fitGTR, \"phangorn.tree.RDS\")\n            write.tree(fitGTR\\$tree, file = \"tree.GTR.newick\")\n            \"\"\"\n        }",
        "nb_lignes_process": 32,
        "string_script": "            \"\"\"\n            #!/usr/bin/env Rscript\n            library(phangorn)\n\n            phang.align <- read.phyDat(\"aligned_seqs.fasta\",\n                                        format = \"fasta\",\n                                        type = \"DNA\")\n\n            dm <- dist.ml(phang.align)\n            treeNJ <- NJ(dm) # Note, tip order != sequence order\n            fit = pml(treeNJ, data=phang.align)\n            write.tree(fit\\$tree, file = \"tree.newick\")\n\n            ## negative edges length changed to 0!\n            fitGTR <- update(fit, k=4, inv=0.2)\n            fitGTR <- optim.pml(fitGTR, model=\"GTR\", optInv=TRUE, optGamma=TRUE,\n                                  rearrangement = \"stochastic\", control = pml.control(trace = 0))\n            saveRDS(fitGTR, \"phangorn.tree.RDS\")\n            write.tree(fitGTR\\$tree, file = \"tree.GTR.newick\")\n            \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alnFile"
        ],
        "nb_inputs": 1,
        "outputs": [
            "treeRDS",
            "treeFile",
            "treeGTRFile"
        ],
        "nb_outputs": 3,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"GenerateTreePhangorn\" }",
            "publishDir \"${params.outdir}/dada2-Phangorn\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "GenerateTreeFasttree": {
        "name_process": "GenerateTreeFasttree",
        "string_process": " process GenerateTreeFasttree {\n            tag { \"GenerateTreeFasttree\" }\n            publishDir \"${params.outdir}/dada2-Fasttree\", mode: \"copy\", overwrite: true\n\n            input:\n            file aln from alnFile\n\n            output:\n            file \"fasttree.tree\" into treeGTRFile, treeToQIIME2\n                                                                       \n\n            script:\n            \"\"\"\n            OMP_NUM_THREADS=${task.cpus} FastTree -nt \\\\\n                -gtr -gamma -spr 4 -mlacc 2 -slownni \\\\\n                -out fasttree.tree \\\\\n                aligned_seqs.fasta\n            \"\"\"\n        }",
        "nb_lignes_process": 17,
        "string_script": "            \"\"\"\n            OMP_NUM_THREADS=${task.cpus} FastTree -nt \\\\\n                -gtr -gamma -spr 4 -mlacc 2 -slownni \\\\\n                -out fasttree.tree \\\\\n                aligned_seqs.fasta\n            \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alnFile"
        ],
        "nb_inputs": 1,
        "outputs": [
            "treeGTRFile",
            "treeToQIIME2"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"GenerateTreeFasttree\" }",
            "publishDir \"${params.outdir}/dada2-Fasttree\", mode: \"copy\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "RootTree": {
        "name_process": "RootTree",
        "string_process": " process RootTree {\n        tag { \"RootTree\" }\n        publishDir \"${params.outdir}/dada2-RootedTree\", mode: \"link\"\n\n        input:\n        file tree from treeGTRFile\n\n        output:\n        file \"rooted.newick\" into rootedTreeFile, rootedToQIIME2\n                                                                   \n\n        script:\n        \"\"\"\n        #!/usr/bin/env Rscript\n        library(phangorn)\n        library(ape)\n\n        tree <- read.tree(file = \"${tree}\")\n\n        midtree <- midpoint(tree)\n\n        write.tree(midtree, file = \"rooted.newick\")\n        \"\"\"\n    }",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        #!/usr/bin/env Rscript\n        library(phangorn)\n        library(ape)\n\n        tree <- read.tree(file = \"${tree}\")\n\n        midtree <- midpoint(tree)\n\n        write.tree(midtree, file = \"rooted.newick\")\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "treeGTRFile"
        ],
        "nb_inputs": 1,
        "outputs": [
            "rootedTreeFile",
            "rootedToQIIME2"
        ],
        "nb_outputs": 2,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"RootTree\" }",
            "publishDir \"${params.outdir}/dada2-RootedTree\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "toQIIME2FeatureTable": {
        "name_process": "toQIIME2FeatureTable",
        "string_process": " process toQIIME2FeatureTable {\n        tag { \"QIIME2-Output\" }\n        publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\"\n\n        input:\n        file seqtab from featuretableToQIIME2\n\n        output:\n        file \"*.qza\"\n\n        script:\n        \"\"\"\n        biom convert -i ${seqtab} \\\n            -o seqtab-biom-table.biom \\\n            --table-type=\"OTU table\" \\\n            --to-hdf5\n\n        qiime tools import \\\n            --input-path seqtab-biom-table.biom \\\n            --input-format BIOMV210Format \\\n            --output-path seqtab_final.simple.qza \\\n            --type 'FeatureTable[Frequency]'\n        \"\"\"\n    }",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        biom convert -i ${seqtab} \\\n            -o seqtab-biom-table.biom \\\n            --table-type=\"OTU table\" \\\n            --to-hdf5\n\n        qiime tools import \\\n            --input-path seqtab-biom-table.biom \\\n            --input-format BIOMV210Format \\\n            --output-path seqtab_final.simple.qza \\\n            --type 'FeatureTable[Frequency]'\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "BioMe",
            "QIIME"
        ],
        "tools_url": [
            "https://bio.tools/biome",
            "https://bio.tools/qiime"
        ],
        "tools_dico": [
            {
                "name": "BioMe",
                "uri": "https://bio.tools/biome",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3534",
                            "term": "Protein binding sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_1834",
                                    "term": "Protein-metal contact calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1831",
                                    "term": "Metal-bound cysteine detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2950",
                                    "term": "Residue distance calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_1834",
                                    "term": "Residue-metal contact calculation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Biologically Relevant Metals (BioMe) is a web based platform for calculation of various statistical properties of metal binding sites including distribution of coordinate geometry and other descriptive statistics for a metal ion. The underlying database contains for each metal ion: PDB code, structure determination method, types of metal binding chains and names and coordinates of bound ligands, among other details.",
                "homepage": "http://metals.zesoi.fer.hr"
            },
            {
                "name": "QIIME",
                "uri": "https://bio.tools/qiime",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biological science"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. The pipeline is designed to take users from raw sequencing data generated on the Illumina or other platforms through publication quality graphics and statistics. This includes demultiplexing and quality filtering, OTU picking, taxonomic assignment, and phylogenetic reconstruction, and diversity analyses and visualizations.",
                "homepage": "http://qiime.org/"
            }
        ],
        "inputs": [
            "featuretableToQIIME2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"QIIME2-Output\" }",
            "publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "toQIIME2TaxTable": {
        "name_process": "toQIIME2TaxTable",
        "string_process": " process toQIIME2TaxTable {\n        tag { \"QIIME2-Output\" }\n        publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\"\n\n        input:\n        file taxtab from taxtableToQIIME2\n\n        output:\n        file \"*.qza\"\n\n        when:\n        taxtableToQIIME2 != false\n\n        script:\n        \"\"\"\n        tail -n +2 ${taxtab} > headerless.txt\n        qiime tools import \\\n            --input-path headerless.txt \\\n            --input-format HeaderlessTSVTaxonomyFormat \\\n            --output-path tax_final.simple.qza \\\n            --type 'FeatureData[Taxonomy]'\n        \"\"\"\n    }",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        tail -n +2 ${taxtab} > headerless.txt\n        qiime tools import \\\n            --input-path headerless.txt \\\n            --input-format HeaderlessTSVTaxonomyFormat \\\n            --output-path tax_final.simple.qza \\\n            --type 'FeatureData[Taxonomy]'\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "QIIME"
        ],
        "tools_url": [
            "https://bio.tools/qiime"
        ],
        "tools_dico": [
            {
                "name": "QIIME",
                "uri": "https://bio.tools/qiime",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biological science"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. The pipeline is designed to take users from raw sequencing data generated on the Illumina or other platforms through publication quality graphics and statistics. This includes demultiplexing and quality filtering, OTU picking, taxonomic assignment, and phylogenetic reconstruction, and diversity analyses and visualizations.",
                "homepage": "http://qiime.org/"
            }
        ],
        "inputs": [
            "taxtableToQIIME2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"QIIME2-Output\" }",
            "publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\""
        ],
        "when": "taxtableToQIIME2 != false",
        "stub": ""
    },
    "toQIIME2Seq": {
        "name_process": "toQIIME2Seq",
        "string_process": " process toQIIME2Seq {\n        tag { \"QIIME2-Output\" }\n        publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\"\n\n        input:\n        file seqs from seqsToQIIME2\n\n        output:\n        file \"*.qza\"\n\n        script:\n        \"\"\"\n        qiime tools import \\\n            --input-path ${seqs} \\\n            --output-path sequences.qza \\\n            --type 'FeatureData[Sequence]'\n        \"\"\"\n    }",
        "nb_lignes_process": 16,
        "string_script": "        \"\"\"\n        qiime tools import \\\n            --input-path ${seqs} \\\n            --output-path sequences.qza \\\n            --type 'FeatureData[Sequence]'\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "QIIME"
        ],
        "tools_url": [
            "https://bio.tools/qiime"
        ],
        "tools_dico": [
            {
                "name": "QIIME",
                "uri": "https://bio.tools/qiime",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biological science"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. The pipeline is designed to take users from raw sequencing data generated on the Illumina or other platforms through publication quality graphics and statistics. This includes demultiplexing and quality filtering, OTU picking, taxonomic assignment, and phylogenetic reconstruction, and diversity analyses and visualizations.",
                "homepage": "http://qiime.org/"
            }
        ],
        "inputs": [
            "seqsToQIIME2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"QIIME2-Output\" }",
            "publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\""
        ],
        "when": "",
        "stub": ""
    },
    "toQIIME2Aln": {
        "name_process": "toQIIME2Aln",
        "string_process": " process toQIIME2Aln {\n        tag { \"QIIME2-Output\" }\n        publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\"\n\n        input:\n        file aln from alnToQIIME2\n\n        when:\n        alnToQIIME2 != false\n\n        output:\n        file \"*.qza\"\n\n        script:\n        \"\"\"\n        qiime tools import \\\n            --input-path ${aln} \\\n            --output-path aligned-sequences.qza \\\n            --type 'FeatureData[AlignedSequence]'\n        \"\"\"\n    }",
        "nb_lignes_process": 19,
        "string_script": "        \"\"\"\n        qiime tools import \\\n            --input-path ${aln} \\\n            --output-path aligned-sequences.qza \\\n            --type 'FeatureData[AlignedSequence]'\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "QIIME"
        ],
        "tools_url": [
            "https://bio.tools/qiime"
        ],
        "tools_dico": [
            {
                "name": "QIIME",
                "uri": "https://bio.tools/qiime",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biological science"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. The pipeline is designed to take users from raw sequencing data generated on the Illumina or other platforms through publication quality graphics and statistics. This includes demultiplexing and quality filtering, OTU picking, taxonomic assignment, and phylogenetic reconstruction, and diversity analyses and visualizations.",
                "homepage": "http://qiime.org/"
            }
        ],
        "inputs": [
            "alnToQIIME2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"QIIME2-Output\" }",
            "publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\""
        ],
        "when": "alnToQIIME2 != false",
        "stub": ""
    },
    "toQIIME2Tree": {
        "name_process": "toQIIME2Tree",
        "string_process": " process toQIIME2Tree {\n        tag { \"QIIME2-Output\" }\n        publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\"\n\n        input:\n        file rooted from rootedToQIIME2\n        file tree from treeToQIIME2\n\n        output:\n        file \"*.qza\"\n\n        when:\n        treeToQIIME2 != false\n\n        script:\n        \"\"\"\n        qiime tools import \\\n            --input-path ${tree} \\\n            --output-path unrooted-tree.qza \\\n            --type 'Phylogeny[Unrooted]'\n\n        qiime tools import \\\n            --input-path ${rooted} \\\n            --output-path rooted-tree.qza \\\n            --type 'Phylogeny[Rooted]'\n        \"\"\"\n    }",
        "nb_lignes_process": 25,
        "string_script": "        \"\"\"\n        qiime tools import \\\n            --input-path ${tree} \\\n            --output-path unrooted-tree.qza \\\n            --type 'Phylogeny[Unrooted]'\n\n        qiime tools import \\\n            --input-path ${rooted} \\\n            --output-path rooted-tree.qza \\\n            --type 'Phylogeny[Rooted]'\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "QIIME"
        ],
        "tools_url": [
            "https://bio.tools/qiime"
        ],
        "tools_dico": [
            {
                "name": "QIIME",
                "uri": "https://bio.tools/qiime",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3070",
                            "term": "Biological science"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Open-source bioinformatics pipeline for performing microbiome analysis from raw DNA sequencing data. The pipeline is designed to take users from raw sequencing data generated on the Illumina or other platforms through publication quality graphics and statistics. This includes demultiplexing and quality filtering, OTU picking, taxonomic assignment, and phylogenetic reconstruction, and diversity analyses and visualizations.",
                "homepage": "http://qiime.org/"
            }
        ],
        "inputs": [
            "rootedToQIIME2",
            "treeToQIIME2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "HPCBio__16S-rDNA-dada2-pipeline",
        "directive": [
            "tag { \"QIIME2-Output\" }",
            "publishDir \"${params.outdir}/dada2-QIIME2\", mode: \"link\""
        ],
        "when": "treeToQIIME2 != false",
        "stub": ""
    }
}