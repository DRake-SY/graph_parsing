{
    "crams_to_fastq_gz": {
        "name_process": "crams_to_fastq_gz",
        "string_process": "\nprocess crams_to_fastq_gz {\n    tag \"crams to fastq_gz ${samplename} ${batch}\"\n\n                                \n                                                   \n    \n    container \"samtools-1.6\"                                      \n    containerOptions = \"--bind /lustre/scratch117/core/sciops_repository/cram_cache --bind /lustre/scratch118/core/sciops_repository/cram_cache\"\n                                \n    errorStrategy 'retry'\n    maxRetries 3\n    time '300m'\n    cpus 1\n    memory '2G'\n\n                                                                                                            \n                                                                                                                            \n                                                                                \n    publishDir \"${params.outdir}/fastq12/\", mode: 'symlink'\n    \n    when:\n    params.run\n    \n    input: \n    set val(samplename), val(batch), file(crams) \n    output: \n    set val(samplename), val(batch), file(\"*.fastq.gz\")\n    file('*.lostcause.txt') optional true \n    file('numreads.txt') optional true \n    script:\n\n                                                                                \n                                                   \n                                                                                                                                    \n    def cramfile = \"${batch}.${samplename}_merged.cram\"\n    \"\"\"\n    export REF_PATH=/lustre/scratch117/core/sciops_repository/cram_cache/%2s/%2s/%s:/lustre/scratch118/core/sciops_repository/cram_cache/%2s/%2s/%s:URL=http:://sf2-farm-srv1.internal.sanger.ac.uk::8000/%s\n\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n    \n\n    f1=${batch}.${samplename}_1.fastq.gz\n    f2=${batch}.${samplename}_2.fastq.gz\n    f0=${batch}.${samplename}.fastq.gz\n\n    numreads=\\$(samtools view -c -F 0x900 $crams)\n    if (( numreads >= ${params.min_reads} )); then\n                              # -O {stdout} -u {no compression}\n                              # -N {always append /1 and /2 to the read name}\n                              # -F 0x900 (bit 1, 8, filter secondary and supplementary reads)\n      echo -n \\$numreads > numreads.txt\n      samtools collate    \\\\\n          -O -u           \\\\\n          -@ ${task.cpus} \\\\\n          ${crams} | \\\\\n      samtools fastq      \\\\\n          -N              \\\\\n          -F 0x900        \\\\\n          -@ ${task.cpus} \\\\\n          -1 \\$f1 -2 \\$f2  -0 \\$f0 \\\\\n          -\n      sleep 2\n      find . -name \\\"*.fastq.gz\\\" -type 'f' -size -160k -delete\n    else\n      echo -e \"${samplename}\\\\tcram\\\\tlowreads\" > ${batch}.${samplename}.lostcause.txt\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 67,
        "string_script": "    def cramfile = \"${batch}.${samplename}_merged.cram\"\n    \"\"\"\n    export REF_PATH=/lustre/scratch117/core/sciops_repository/cram_cache/%2s/%2s/%s:/lustre/scratch118/core/sciops_repository/cram_cache/%2s/%2s/%s:URL=http:://sf2-farm-srv1.internal.sanger.ac.uk::8000/%s\n\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n    \n\n    f1=${batch}.${samplename}_1.fastq.gz\n    f2=${batch}.${samplename}_2.fastq.gz\n    f0=${batch}.${samplename}.fastq.gz\n\n    numreads=\\$(samtools view -c -F 0x900 $crams)\n    if (( numreads >= ${params.min_reads} )); then\n                              # -O {stdout} -u {no compression}\n                              # -N {always append /1 and /2 to the read name}\n                              # -F 0x900 (bit 1, 8, filter secondary and supplementary reads)\n      echo -n \\$numreads > numreads.txt\n      samtools collate    \\\\\n          -O -u           \\\\\n          -@ ${task.cpus} \\\\\n          ${crams} | \\\\\n      samtools fastq      \\\\\n          -N              \\\\\n          -F 0x900        \\\\\n          -@ ${task.cpus} \\\\\n          -1 \\$f1 -2 \\$f2  -0 \\$f0 \\\\\n          -\n      sleep 2\n      find . -name \\\"*.fastq.gz\\\" -type 'f' -size -160k -delete\n    else\n      echo -e \"${samplename}\\\\tcram\\\\tlowreads\" > ${batch}.${samplename}.lostcause.txt\n    fi\n    \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samplename",
            "batch",
            "crams"
        ],
        "nb_inputs": 3,
        "outputs": [
            "batch"
        ],
        "nb_outputs": 1,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"crams to fastq_gz ${samplename} ${batch}\"",
            "container \"samtools-1.6\"",
            "containerOptions = \"--bind /lustre/scratch117/core/sciops_repository/cram_cache --bind /lustre/scratch118/core/sciops_repository/cram_cache\"",
            "errorStrategy 'retry'",
            "maxRetries 3",
            "time '300m'",
            "cpus 1",
            "memory '2G'",
            "publishDir \"${params.outdir}/fastq12/\", mode: 'symlink'"
        ],
        "when": "params.run",
        "stub": ""
    },
    "lostcause": {
        "name_process": "lostcause",
        "string_process": "\nprocess lostcause {\n\n    publishDir \"${params.outdir}/combined\", mode: 'symlink'\n\n    input:\n    file (inputs)                                                              \n\n    output:\n    file('*.lostcause_mqc.txt')                            \n\n    script:\n    def outputname = \"${params.runtag}.lostcause_mqc.txt\"\n    \"\"\"\n    echo -e \"# plot_type: 'table'\\n# section_name: 'Lost samples'\" > $outputname\n    echo -e \"Sample\\tProcess\\tMessage\" >> $outputname\n    cat $inputs | sort >> $outputname\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    def outputname = \"${params.runtag}.lostcause_mqc.txt\"\n    \"\"\"\n    echo -e \"# plot_type: 'table'\\n# section_name: 'Lost samples'\" > $outputname\n    echo -e \"Sample\\tProcess\\tMessage\" >> $outputname\n    cat $inputs | sort >> $outputname\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "publishDir \"${params.outdir}/combined\", mode: 'symlink'"
        ],
        "when": "",
        "stub": ""
    },
    "merge_salmoncounts": {
        "name_process": "merge_salmoncounts",
        "string_process": "\nprocess merge_salmoncounts {\n    tag \"\"\n    scratch '/tmp'\n    stageInMode 'copy'\n    stageOutMode 'rsync'\n    container \"nfcore-rnaseq\"\n    publishDir \"${params.outdir}/combined\", mode: 'symlink'\n    errorStrategy { task.attempt <= 6 ? 'retry' : 'ignore' }\n    containerOptions = \"--bind /lustre\"\n    maxRetries 6\n                     \n    memory = {  120.GB + 20.GB * (task.attempt-1) }\n    time '900m'\n    queue 'long'\n\n    input:\n    file (all_quant_sf)\n    file (all_quant_genes_sf)\n\n    when:\n    params.run\n\n    output:\n    set file('*transcounts.txt'), file('*transtpm.txt'), file('*genecounts.txt'), file('*genetpm.txt')\n    file(\"fofn_quant_sf_salmon.txt\")\n    file(\"fofn_quant_genes_sf_salmon.txt\")\n    \n    script:\n    def outtranscount = \"${params.runtag}-salmon-transcounts.txt\"\n    def outgenescount = \"${params.runtag}-salmon-genecounts.txt\"\n    def outtranstpm   = \"${params.runtag}-salmon-transtpm.txt\"\n    def outgenestpm   = \"${params.runtag}-salmon-genetpm.txt\"\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    ls . | grep .quant.sf\\$ > fofn_quant_sf_salmon.txt\n    ls . | grep .quant.genes.sf\\$ > fofn_quant_genes_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.genes.sf                                     \\\\\n      -c -1 --skip-comments --header                                  \\\\\n      -o $outgenescount -I fofn_quant_genes_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.sf                                           \\\\\n      -c -1 --skip-comments --header                                  \\\\\n      -o $outtranscount -I fofn_quant_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.genes.sf                                     \\\\\n      -c -2 --skip-comments --header                                  \\\\\n      -o $outgenestpm -I fofn_quant_genes_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.sf                                           \\\\\n      -c -2 --skip-comments --header                                  \\\\\n      -o $outtranstpm -I fofn_quant_sf_salmon.txt\n    \"\"\"\n}",
        "nb_lignes_process": 58,
        "string_script": "    def outtranscount = \"${params.runtag}-salmon-transcounts.txt\"\n    def outgenescount = \"${params.runtag}-salmon-genecounts.txt\"\n    def outtranstpm   = \"${params.runtag}-salmon-transtpm.txt\"\n    def outgenestpm   = \"${params.runtag}-salmon-genetpm.txt\"\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    ls . | grep .quant.sf\\$ > fofn_quant_sf_salmon.txt\n    ls . | grep .quant.genes.sf\\$ > fofn_quant_genes_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.genes.sf                                     \\\\\n      -c -1 --skip-comments --header                                  \\\\\n      -o $outgenescount -I fofn_quant_genes_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.sf                                           \\\\\n      -c -1 --skip-comments --header                                  \\\\\n      -o $outtranscount -I fofn_quant_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.genes.sf                                     \\\\\n      -c -2 --skip-comments --header                                  \\\\\n      -o $outgenestpm -I fofn_quant_genes_sf_salmon.txt\n\n    python3 $workflow.projectDir/../bin/rna_seq/merge_featurecounts.py           \\\\\n      --rm-suffix .quant.sf                                           \\\\\n      -c -2 --skip-comments --header                                  \\\\\n      -o $outtranstpm -I fofn_quant_sf_salmon.txt\n    \"\"\"",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_quant_sf",
            "all_quant_genes_sf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"\"",
            "scratch '/tmp'",
            "stageInMode 'copy'",
            "stageOutMode 'rsync'",
            "container \"nfcore-rnaseq\"",
            "publishDir \"${params.outdir}/combined\", mode: 'symlink'",
            "errorStrategy { task.attempt <= 6 ? 'retry' : 'ignore' }",
            "containerOptions = \"--bind /lustre\"",
            "maxRetries 6",
            "memory = { 120.GB + 20.GB * (task.attempt-1) }",
            "time '900m'",
            "queue 'long'"
        ],
        "when": "params.run",
        "stub": ""
    },
    "info_stats": {
        "name_process": "info_stats",
        "string_process": "\nprocess info_stats {\n    tag \"info_stats\"\n    container \"singularity-rstudio-seurat-tximport\"\n    containerOptions = \"--bind /tmp --bind /lustre\"\n    queue 'normal'\n    time '400m'\n    memory = '10G'\n    cpus 2\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 1\n    publishDir \"${params.outdir}/info_stats/\", mode: 'copy'\n    scratch false \n    cache false\n\n    when:\n    params.run\n\n    input:\n    file(minimal_samples_spreadsheet_tsv)\n    file(imeta_info_tsv)\n    file(sync_status_tsv)\n    file(metrics_summary_csvs)\n\n    output:\n    file(\"samples_status.pdf\")\n    file(\"samples_metainfo.tsv\")\n    file(\"samples_metainfo.xlsx\")\n    file(\"samples_status_dropped.pdf\")\n    file(\"samples_status_pre_pipelines.pdf\")\n    file(\"samples_status_dropped_pre_pipelines.pdf\")\n    file(\"samples_metainfo_supplier_name.tsv\")\n    file(\"samples_metainfo_supplier_name.xlsx\")\n    file(\"recruitment_time_course_plot.pdf\")\n    env(WORK_DIR), emit: work_dir_to_remove\n\n    script:\n    \"\"\"\n/usr/bin/Rscript $workflow.projectDir/../bin/scrna/info_stats.R $minimal_samples_spreadsheet_tsv $imeta_info_tsv $sync_status_tsv\n/usr/bin/Rscript $workflow.projectDir/../bin/scrna/info_stats_supplier_name.R $minimal_samples_spreadsheet_tsv $imeta_info_tsv $sync_status_tsv\n/usr/bin/Rscript $workflow.projectDir/../bin/scrna/recruitment_time_course_plot.R samples_metainfo_supplier_name.tsv\n\nWORK_DIR=\\$PWD\n    \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "    \"\"\"\n/usr/bin/Rscript $workflow.projectDir/../bin/scrna/info_stats.R $minimal_samples_spreadsheet_tsv $imeta_info_tsv $sync_status_tsv\n/usr/bin/Rscript $workflow.projectDir/../bin/scrna/info_stats_supplier_name.R $minimal_samples_spreadsheet_tsv $imeta_info_tsv $sync_status_tsv\n/usr/bin/Rscript $workflow.projectDir/../bin/scrna/recruitment_time_course_plot.R samples_metainfo_supplier_name.tsv\n\nWORK_DIR=\\$PWD\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "minimal_samples_spreadsheet_tsv",
            "imeta_info_tsv",
            "sync_status_tsv",
            "metrics_summary_csvs"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"info_stats\"",
            "container \"singularity-rstudio-seurat-tximport\"",
            "containerOptions = \"--bind /tmp --bind /lustre\"",
            "queue 'normal'",
            "time '400m'",
            "memory = '10G'",
            "cpus 2",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 1",
            "publishDir \"${params.outdir}/info_stats/\", mode: 'copy'",
            "scratch false",
            "cache false"
        ],
        "when": "params.run",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc {\n    container \"nfcore-rnaseq\"\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n    memory = '10G'\n    cpus 2\n    time '300m'\n\n    publishDir \"${params.outdir}/multiqc\", mode: 'copy',\n      saveAs: {filename ->\n          if (filename.indexOf(\"multiqc.html\") > 0) \"combined/$filename\"\n          else if (filename.indexOf(\"_data\") > 0) \"$filename\"\n          else null\n      }\n\n    when:\n    params.run\n\n    input:\n    file (fastqc:'fastqc/*')                                               \n            'lostcause/*'                                                   \n            'mapsummary/*'                                                \n            'featureCounts/*'                                                    \n            'featureCounts_biotype/*'                                                           \n            'star/*'                                                     \n            'salmon/*'                                                       \n\n    output:\n    file \"*_multiqc.html\"\n    file \"*_data\"\n\n    script:\n    def filename = \"${params.runtag}_multiqc.html\"\n    def reporttitle = \"${params.runtag}\"\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    multiqc . -f --title \"$reporttitle\" --filename \"$filename\" -m fastqc\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    def filename = \"${params.runtag}_multiqc.html\"\n    def reporttitle = \"${params.runtag}\"\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    multiqc . -f --title \"$reporttitle\" --filename \"$filename\" -m fastqc\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastqc"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "container \"nfcore-rnaseq\"",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3",
            "memory = '10G'",
            "cpus 2",
            "time '300m'",
            "publishDir \"${params.outdir}/multiqc\", mode: 'copy' , saveAs: {filename -> if (filename.indexOf(\"multiqc.html\") > 0) \"combined/$filename\" else if (filename.indexOf(\"_data\") > 0) \"$filename\" else null }"
        ],
        "when": "params.run",
        "stub": ""
    },
    "solo": {
        "name_process": "solo",
        "string_process": "\nprocess solo {\n    tag \"${samplename}\"\n    queue 'gpu-normal'\n    clusterOptions '-gpu num=1'\n                                                           \n    maxForks 5\n    container 'solo_and_scanpy'\n    containerOptions = \"--nv --bind /lustre/scratch118/humgen/resources/containers/solo_libs/:/home/ubuntu/ --bind /lustre --bind /tmp\"\n    memory = '4G'\n    time '700m'\n    cpus 1\n    errorStrategy { task.attempt <= 1 ? 'retry' : 'ignore' }\n    maxRetries 1\n    publishDir \"${params.outdir}/solo/\", mode: 'symlink', pattern: \"solo_$samplename\", overwrite: true\n    publishDir \"${params.outdir}/solo_tsv/\", mode: 'symlink', pattern: \"${samplename}.tsv\", overwrite: true\n    publishDir \"${params.outdir}/h5ad/$samplename/\", mode: 'symlink', pattern: \"${data_h5_file}ad\", overwrite: true\n\n    when:\n    params.run\n\n    input: \n    set val(samplename), file(data_h5_file)\n    file(solo_params_json)\n\n    output: \n    tuple val(samplename), file(\"solo_$samplename\"), emit: sample_solooutdir\n    tuple val(samplename), file(\"${samplename}.tsv\"), emit: sample_solotsv\n    tuple val(samplename), file(\"${data_h5_file}ad\"), emit: sample_h5ad\n\n    script:\n    \"\"\"\nexport PATH=/opt/conda/bin:/opt/conda/envs/solo/bin:\\$PATH\neval \\\"\\$(conda shell.bash hook)\\\"\n\nconda activate scanpy\npython $workflow.projectDir/../bin/solo/convert_h5_h5ad.py \\\\\n-i $data_h5_file \\\\\n-o ${data_h5_file}ad\n\nconda deactivate \nconda activate solo\nls /home/ubuntu/\n/home/ubuntu/solo $solo_params_json ${data_h5_file}ad -o solo_$samplename -g\n\nconda deactivate \nconda activate scanpy\npython $workflow.projectDir/../bin/solo/solo_outdir_to_tsv.py \\\\\n-d $data_h5_file \\\\\n-s solo_$samplename \\\\\n-o ${samplename}.tsv\n\necho solo done\n    \"\"\"\n}",
        "nb_lignes_process": 53,
        "string_script": "    \"\"\"\nexport PATH=/opt/conda/bin:/opt/conda/envs/solo/bin:\\$PATH\neval \\\"\\$(conda shell.bash hook)\\\"\n\nconda activate scanpy\npython $workflow.projectDir/../bin/solo/convert_h5_h5ad.py \\\\\n-i $data_h5_file \\\\\n-o ${data_h5_file}ad\n\nconda deactivate \nconda activate solo\nls /home/ubuntu/\n/home/ubuntu/solo $solo_params_json ${data_h5_file}ad -o solo_$samplename -g\n\nconda deactivate \nconda activate scanpy\npython $workflow.projectDir/../bin/solo/solo_outdir_to_tsv.py \\\\\n-d $data_h5_file \\\\\n-s solo_$samplename \\\\\n-o ${samplename}.tsv\n\necho solo done\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "BTEVAL",
            "ANACONDA",
            "SoloDel"
        ],
        "tools_url": [
            "https://bio.tools/bteval",
            "https://bio.tools/anaconda",
            "https://bio.tools/solodel"
        ],
        "tools_dico": [
            {
                "name": "BTEVAL",
                "uri": "https://bio.tools/bteval",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Protein sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Sequence analysis (protein)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The aim of BTEVAL server is to evaluate beta turn prediction algorithms on a uniform data set of 426 proteins or subsets of these proteins. It is the new data set in which no two protein chains have more that 25% sequence identity and each chain contains minimum one beta turn.",
                "homepage": "http://www.imtech.res.in/raghava/bteval"
            },
            {
                "name": "ANACONDA",
                "uri": "https://bio.tools/anaconda",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software package specially developed for the study of genes\u2019 primary structure. It uses gene sequences downloaded from public databases, as FASTA and GenBank, and it applies a set of statistical and visualization methods in different ways, to reveal information about codon context, codon usage, nucleotide repeats within open reading frames (ORFeome) and others.",
                "homepage": "http://bioinformatics.ua.pt/software/anaconda/"
            },
            {
                "name": "SoloDel",
                "uri": "https://bio.tools/solodel",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A  somatic deletion caller designed for whole-genome sequencing data from unmatched samples. SoloDel is specialized for identifying somatic deletions with frequently existing sampling issues : low mutational frequency in cell population and absence of the matched control samples.",
                "homepage": "http://sourceforge.net/projects/solodel/"
            }
        ],
        "inputs": [
            "samplename",
            "data_h5_file",
            "solo_params_json"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"${samplename}\"",
            "queue 'gpu-normal'",
            "clusterOptions '-gpu num=1'",
            "maxForks 5",
            "container 'solo_and_scanpy'",
            "containerOptions = \"--nv --bind /lustre/scratch118/humgen/resources/containers/solo_libs/:/home/ubuntu/ --bind /lustre --bind /tmp\"",
            "memory = '4G'",
            "time '700m'",
            "cpus 1",
            "errorStrategy { task.attempt <= 1 ? 'retry' : 'ignore' }",
            "maxRetries 1",
            "publishDir \"${params.outdir}/solo/\", mode: 'symlink', pattern: \"solo_$samplename\", overwrite: true",
            "publishDir \"${params.outdir}/solo_tsv/\", mode: 'symlink', pattern: \"${samplename}.tsv\", overwrite: true",
            "publishDir \"${params.outdir}/h5ad/$samplename/\", mode: 'symlink', pattern: \"${data_h5_file}ad\", overwrite: true"
        ],
        "when": "params.run",
        "stub": ""
    },
    "concat_vcfs": {
        "name_process": "concat_vcfs",
        "string_process": "\nprocess concat_vcfs {\n    memory '60G'\n    tag \"$vcfs_location $name\"\n    cpus 2\n                   \n    time '700m'\n    queue 'normal'\n    container \"graphtyper\"\n    containerOptions = \"--bind /lustre\"\n                                \n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    publishDir \"${params.outdir}/vcfs_concat/\", mode: 'symlink', overwrite: true, pattern: \"${name}.vcf.gz\"\n    publishDir \"${params.outdir}/vcfs_concat/\", mode: 'symlink', overwrite: true, pattern: \"${name}.vcf.gz.csi\"\n    maxRetries 3\n\n    when:\n    params.run\n     \n    input:\n    val(vcfs_location)\n    val(name)\n    \n    output: \n    tuple file(\"${name}.vcf.gz\"), file(\"${name}.vcf.gz.csi\"), emit: vcf_gz\n    tuple file(\"to_concat.list\"), file(\"to_concat_non_empty.list\"), emit: concat_list\n\n    script:\n\"\"\" \nfind $vcfs_location -maxdepth 1 -name 'chr1:*.vcf.gz' -exec sh -c \\\"echo {} \\\\\\$(zcat {} | grep -v '^#' | wc -l)\\\" \\\\; >> to_concat.list\n\ncat to_concat.list | grep -v 'gz 0\\$' | cut -f1 -d ' ' | sort > to_concat_non_empty.list\n\nbcftools concat -f to_concat_non_empty.list --allow-overlaps | bcftools sort -o ${name}.vcf.gz -O z\nbcftools index ${name}.vcf.gz\n\"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "\"\"\" \nfind $vcfs_location -maxdepth 1 -name 'chr1:*.vcf.gz' -exec sh -c \\\"echo {} \\\\\\$(zcat {} | grep -v '^#' | wc -l)\\\" \\\\; >> to_concat.list\n\ncat to_concat.list | grep -v 'gz 0\\$' | cut -f1 -d ' ' | sort > to_concat_non_empty.list\n\nbcftools concat -f to_concat_non_empty.list --allow-overlaps | bcftools sort -o ${name}.vcf.gz -O z\nbcftools index ${name}.vcf.gz\n\"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "vcfs_location",
            "name"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "memory '60G'",
            "tag \"$vcfs_location $name\"",
            "cpus 2",
            "time '700m'",
            "queue 'normal'",
            "container \"graphtyper\"",
            "containerOptions = \"--bind /lustre\"",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "publishDir \"${params.outdir}/vcfs_concat/\", mode: 'symlink', overwrite: true, pattern: \"${name}.vcf.gz\"",
            "publishDir \"${params.outdir}/vcfs_concat/\", mode: 'symlink', overwrite: true, pattern: \"${name}.vcf.gz.csi\"",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "collate_crispr_counts": {
        "name_process": "collate_crispr_counts",
        "string_process": "\nprocess collate_crispr_counts {\n    tag \"collate counts\"\n                                                              \n                                \n                                          \n    publishDir \"${params.outdir}/collate_counts\", mode: 'symlink'\n    memory = '20G'\n    cpus 2\n    time '300m'\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n\n    when:\n    params.run\n\n    input:\n    set val(guide_library), file(samplename_counts_txt_files)\n\n    output:\n    set val(guide_library), file(\"*.count_matrix.txt\")\n    set val(guide_library), file(\"*.fofn_countsfiles.txt\")\n\n    shell:\n    \"\"\"\nexport PATH=/software/hgi/installs/anaconda3/envs/nextflow20/bin/:\\$PATH\n\n    echo count_file > fofn_files.txt\n    ls . | grep .counts.txt\\$ | grep -v genes.counts.txt >> fofn_files.txt\n\n    echo samplename > fofn_samplenames.txt\n    ls . | grep .counts.txt\\$ | grep -v genes.counts.txt | sed s/.counts.txt// >> fofn_samplenames.txt\n\n    paste -d ',' fofn_samplenames.txt fofn_files.txt > ${guide_library}.fofn_countsfiles.txt\n\n    python3 ${workflow.projectDir}/../bin/crispr/collate_counts.py ${guide_library}.fofn_countsfiles.txt \\\"${guide_library}\\\"\n    \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "    \"\"\"\nexport PATH=/software/hgi/installs/anaconda3/envs/nextflow20/bin/:\\$PATH\n\n    echo count_file > fofn_files.txt\n    ls . | grep .counts.txt\\$ | grep -v genes.counts.txt >> fofn_files.txt\n\n    echo samplename > fofn_samplenames.txt\n    ls . | grep .counts.txt\\$ | grep -v genes.counts.txt | sed s/.counts.txt// >> fofn_samplenames.txt\n\n    paste -d ',' fofn_samplenames.txt fofn_files.txt > ${guide_library}.fofn_countsfiles.txt\n\n    python3 ${workflow.projectDir}/../bin/crispr/collate_counts.py ${guide_library}.fofn_countsfiles.txt \\\"${guide_library}\\\"\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "guide_library",
            "samplename_counts_txt_files"
        ],
        "nb_inputs": 2,
        "outputs": [
            "guide_library",
            "guide_library"
        ],
        "nb_outputs": 2,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"collate counts\"",
            "publishDir \"${params.outdir}/collate_counts\", mode: 'symlink'",
            "memory = '20G'",
            "cpus 2",
            "time '300m'",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "iget_cram": {
        "name_process": "iget_cram",
        "string_process": "\nprocess iget_cram {\n    tag \"iget cram ${samplename}\"\n    memory = '10G'\n    time '240m'\n    cpus 1\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n    maxForks 12\n    publishDir \"${params.outdir}/irods_lost/${samplename}/\", mode: 'symlink', pattern: \"*.lostcause.txt\", overwrite: true\n    publishDir \"${params.outdir}/irods_crams/${samplename}/\", mode: 'symlink', pattern: \"*.cram\", overwrite: true\n\n    when:\n    params.run\n\n    input: \n    val samplename                                                   \n    val studyid                                                   \n\n    output: \n    set val(samplename), file('*.cram') optional true                      \n    file('*.lostcause.txt') optional true                           \n\n    script:\n    \"\"\"\n    if bash -euo pipefail $workflow.projectDir/../bin/rna_seq/irods.sh -N ${task.cpus} -t ${studyid} -s ${samplename} ${params.dropqc}; then\n      true\n    else\n      stat=\\$?\n      if [[ \\$stat == 64 ]];\n        then tag='nofiles';\n        echo -e \"${samplename}\\\\tirods\\\\t\\$tag\" > ${samplename}.lostcause.txt\n      else          \n        tag='UNKNOWN'\n        echo -e \"${samplename}\\\\tirods\\\\t\\$tag\" > ${samplename}.lostcause.txt\n        exit \\$stat\n      fi\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "    \"\"\"\n    if bash -euo pipefail $workflow.projectDir/../bin/rna_seq/irods.sh -N ${task.cpus} -t ${studyid} -s ${samplename} ${params.dropqc}; then\n      true\n    else\n      stat=\\$?\n      if [[ \\$stat == 64 ]];\n        then tag='nofiles';\n        echo -e \"${samplename}\\\\tirods\\\\t\\$tag\" > ${samplename}.lostcause.txt\n      else          \n        tag='UNKNOWN'\n        echo -e \"${samplename}\\\\tirods\\\\t\\$tag\" > ${samplename}.lostcause.txt\n        exit \\$stat\n      fi\n    fi\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplename",
            "studyid"
        ],
        "nb_inputs": 2,
        "outputs": [
            "samplename"
        ],
        "nb_outputs": 1,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"iget cram ${samplename}\"",
            "memory = '10G'",
            "time '240m'",
            "cpus 1",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3",
            "maxForks 12",
            "publishDir \"${params.outdir}/irods_lost/${samplename}/\", mode: 'symlink', pattern: \"*.lostcause.txt\", overwrite: true",
            "publishDir \"${params.outdir}/irods_crams/${samplename}/\", mode: 'symlink', pattern: \"*.cram\", overwrite: true"
        ],
        "when": "params.run",
        "stub": ""
    },
    "seurat": {
        "name_process": "seurat",
        "string_process": "\nprocess seurat {\n    tag \"seurat $samplename $raw_filtered\"\n    container \"singularity-rstudio-seurat-tximport\"\n    containerOptions = \"--bind /tmp --bind /lustre\"\n    queue 'long'\n    time '1400m'\n    memory = '80G'\n    cpus 2\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n    publishDir \"${params.outdir}/seurat/$raw_filtered/\", mode: 'symlink'\n    scratch false \n\n    when:\n    params.run\n\n    input:\n    set val(samplename), file(cellranger_matrix_dir), val(raw_filtered), file(metrics_summary_csv)\n\n    output:\n    tuple val(samplename), val(raw_filtered), file(\"${samplename}_${raw_filtered}_TSNEPlot.pdf\"), emit: tsneplot_pdf\n    tuple val(samplename), val(raw_filtered), file(\"${samplename}_${raw_filtered}_stats.tsv\"), file(\"${samplename}_${raw_filtered}_stats.xlsx\"), emit: stats_xslx\n    tuple val(samplename), val(raw_filtered), file(\"${samplename}_${raw_filtered}_clusters_markers_FindAllMarkers.xlsx\"), emit: diffexp_xlsx\n    tuple val(samplename), val(raw_filtered), file(\"${samplename}_${raw_filtered}_seuratimage.rdata\"), emit: seurat_rdata\n\n    script:\n    \"\"\"\n    /usr/bin/Rscript $workflow.projectDir/../bin/scrna/seurat.R $samplename $cellranger_matrix_dir $raw_filtered $metrics_summary_csv\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    /usr/bin/Rscript $workflow.projectDir/../bin/scrna/seurat.R $samplename $cellranger_matrix_dir $raw_filtered $metrics_summary_csv\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplename",
            "raw_filtered",
            "cellranger_matrix_dir",
            "metrics_summary_csv"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"seurat $samplename $raw_filtered\"",
            "container \"singularity-rstudio-seurat-tximport\"",
            "containerOptions = \"--bind /tmp --bind /lustre\"",
            "queue 'long'",
            "time '1400m'",
            "memory = '80G'",
            "cpus 2",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3",
            "publishDir \"${params.outdir}/seurat/$raw_filtered/\", mode: 'symlink'",
            "scratch false"
        ],
        "when": "params.run",
        "stub": ""
    },
    "tximport": {
        "name_process": "tximport",
        "string_process": "\nprocess tximport {\n    tag \"tximport $params.ensembl_lib\"\n    memory = '80G'\n    container \"singularity-rstudio-seurat-tximport\"\n    containerOptions = \"--bind /tmp --bind /lustre\"\n    time '400m'\n    cpus 1\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n    \n    publishDir \"${params.outdir}/tximport\", mode: 'symlink'\n\n    when:\n    params.run\n\n    input:\n    file (quant_sf_files)                   \n\n    output:\n    file(\"fofn_quantfiles.txt\")\n    file(\"txi_gene_counts.csv\")\n    file(\"txi_transcript_counts.csv\")\n    file(\"txi_lengthScaledTPM_gene_counts.csv\")\n    file(\"tximport.rdata\")\n                                                           \n                                                                \n                                                                                  \n\n    script:\n    \"\"\"\n    ls . | grep .quant.sf\\$ > fofn_quantfiles.txt\n\n    /usr/bin/Rscript $workflow.projectDir/../bin/rna_seq/tximport.R \\\"$params.ensembl_lib\\\" fofn_quantfiles.txt \n    \"\"\"\n\n                                                                                          \n                                                          \n                                                                                        \n}",
        "nb_lignes_process": 38,
        "string_script": "    \"\"\"\n    ls . | grep .quant.sf\\$ > fofn_quantfiles.txt\n\n    /usr/bin/Rscript $workflow.projectDir/../bin/rna_seq/tximport.R \\\"$params.ensembl_lib\\\" fofn_quantfiles.txt \n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "quant_sf_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"tximport $params.ensembl_lib\"",
            "memory = '80G'",
            "container \"singularity-rstudio-seurat-tximport\"",
            "containerOptions = \"--bind /tmp --bind /lustre\"",
            "time '400m'",
            "cpus 1",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3",
            "publishDir \"${params.outdir}/tximport\", mode: 'symlink'"
        ],
        "when": "params.run",
        "stub": ""
    },
    "filter_star_aln_rate": {
        "name_process": "filter_star_aln_rate",
        "string_process": "\nprocess filter_star_aln_rate {\n    tag \"filter_star_aln_rate ${samplename}\"\n\n                                \n    errorStrategy 'retry'\n    maxRetries 3\n    time '30m'\n    cpus 1\n    memory '2G'\n\n                                                          \n    \n    when:\n    params.run\n    \n    input:\n    set val(samplename), file(log_final_out)\n    output: \n    set val(samplename), stdout\n    script:\n\n    \"\"\"\n#!/usr/bin/env python3\nimport re\n\nwith open(\\\"${log_final_out}\\\",\\\"r\\\") as f:\n    for line in f:\n        if re.search(\\\"Uniquely mapped reads %\\\",line):\n                if float(re.findall(\\\"\\\\d+\\\\.\\\\d+\\\", line)[0]) > float(${params.min_pct_aln}):\n                    print('above_threshold', end='')\n                else:\n                    print('below_threshold', end='')\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n#!/usr/bin/env python3\nimport re\n\nwith open(\\\"${log_final_out}\\\",\\\"r\\\") as f:\n    for line in f:\n        if re.search(\\\"Uniquely mapped reads %\\\",line):\n                if float(re.findall(\\\"\\\\d+\\\\.\\\\d+\\\", line)[0]) > float(${params.min_pct_aln}):\n                    print('above_threshold', end='')\n                else:\n                    print('below_threshold', end='')\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplename",
            "log_final_out"
        ],
        "nb_inputs": 2,
        "outputs": [
            "samplename"
        ],
        "nb_outputs": 1,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"filter_star_aln_rate ${samplename}\"",
            "errorStrategy 'retry'",
            "maxRetries 3",
            "time '30m'",
            "cpus 1",
            "memory '2G'"
        ],
        "when": "params.run",
        "stub": ""
    },
    "copy_number_v2": {
        "name_process": "copy_number_v2",
        "string_process": "\nprocess copy_number_v2 {\n    memory '4G'\n    tag \"$samplename $egan_id\"\n    cpus 2\n    disk '60 GB'\n    scratch '/tmp'\n    stageInMode 'copy'\n    stageOutMode 'rsync'\n    time '1000m'\n    container \"copy_number_v2\"\n    maxForks 40\n                                               \n                                \n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    publishDir \"${params.outdir}/copy_number/\", mode: 'symlink', overwrite: true \n    maxRetries 3\n\n    when:\n    params.run\n     \n    input: \n    tuple val(samplename), val(egan_id), file(hist_root_file), file(samplename_gt_vcf)\n    \n    output: \n    tuple val(samplename), file(\"${samplename}.noXY.cn.vcf\"), emit: samplename_cn_vcf\n\n    script:\n    \"\"\" \nexport ROOTSYS=/root\nexport MANPATH=/root/man:/usr/local/man:/usr/local/share/man:/usr/share/man\nexport USER_PATH=/home/ubuntu/error/speedseq/bin/:/home/ubuntu/anaconda3/envs/py2/bin:/home/ubuntu/anaconda3/condabin:/usr/local/go/bin:/home/ubuntu/error/root/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/go/bin:/home/ubuntu/go/bin:/bin:/usr/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin\nexport LD_LIBRARY_PATH=/root/lib:/.singularity.d/libs\nexport LIBPATH=/root/lib\nexport JUPYTER_PATH=/root/etc/notebook\nexport DYLD_LIBRARY_PATH=/root/lib\nexport PYTHONPATH=/root/lib\nexport SHLIB_PATH=/root/lib\nexport CMAKE_PREFIX_PATH=/root\nexport CLING_STANDARD_PCH=none\n\nexport PATH=/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/speedseq/bin:/miniconda/bin:\\$PATH\n\n    eval \\\"\\$(conda shell.bash hook)\\\"\n    conda activate py2\n\n   create_coordinates \\\\\n      -i ${samplename_gt_vcf} \\\\\n      -o coordinates.txt\n\n   cat coordinates.txt | grep -v chrX | grep -v chrY > coordinates_nochrXY.txt\n   vcftools --vcf ${samplename_gt_vcf} --not-chr chrX --not-chr chrY --recode --recode-INFO-all --out ${samplename}.noXY\n   \n   svtools copynumber \\\\\n      -i ${samplename}.noXY.recode.vcf \\\\\n      -s ${egan_id} \\\\\n      --cnvnator cnvnator \\\\\n      -w 100 \\\\\n      -r ${hist_root_file} \\\\\n      -c coordinates_nochrXY.txt \\\\\n      > ${samplename}.noXY.cn.vcf\n    \"\"\"\n}",
        "nb_lignes_process": 61,
        "string_script": "    \"\"\" \nexport ROOTSYS=/root\nexport MANPATH=/root/man:/usr/local/man:/usr/local/share/man:/usr/share/man\nexport USER_PATH=/home/ubuntu/error/speedseq/bin/:/home/ubuntu/anaconda3/envs/py2/bin:/home/ubuntu/anaconda3/condabin:/usr/local/go/bin:/home/ubuntu/error/root/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/go/bin:/home/ubuntu/go/bin:/bin:/usr/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin\nexport LD_LIBRARY_PATH=/root/lib:/.singularity.d/libs\nexport LIBPATH=/root/lib\nexport JUPYTER_PATH=/root/etc/notebook\nexport DYLD_LIBRARY_PATH=/root/lib\nexport PYTHONPATH=/root/lib\nexport SHLIB_PATH=/root/lib\nexport CMAKE_PREFIX_PATH=/root\nexport CLING_STANDARD_PCH=none\n\nexport PATH=/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/speedseq/bin:/miniconda/bin:\\$PATH\n\n    eval \\\"\\$(conda shell.bash hook)\\\"\n    conda activate py2\n\n   create_coordinates \\\\\n      -i ${samplename_gt_vcf} \\\\\n      -o coordinates.txt\n\n   cat coordinates.txt | grep -v chrX | grep -v chrY > coordinates_nochrXY.txt\n   vcftools --vcf ${samplename_gt_vcf} --not-chr chrX --not-chr chrY --recode --recode-INFO-all --out ${samplename}.noXY\n   \n   svtools copynumber \\\\\n      -i ${samplename}.noXY.recode.vcf \\\\\n      -s ${egan_id} \\\\\n      --cnvnator cnvnator \\\\\n      -w 100 \\\\\n      -r ${hist_root_file} \\\\\n      -c coordinates_nochrXY.txt \\\\\n      > ${samplename}.noXY.cn.vcf\n    \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "BTEVAL",
            "ANACONDA",
            "VCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bteval",
            "https://bio.tools/anaconda",
            "https://bio.tools/vcftools"
        ],
        "tools_dico": [
            {
                "name": "BTEVAL",
                "uri": "https://bio.tools/bteval",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Protein sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Sequence analysis (protein)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The aim of BTEVAL server is to evaluate beta turn prediction algorithms on a uniform data set of 426 proteins or subsets of these proteins. It is the new data set in which no two protein chains have more that 25% sequence identity and each chain contains minimum one beta turn.",
                "homepage": "http://www.imtech.res.in/raghava/bteval"
            },
            {
                "name": "ANACONDA",
                "uri": "https://bio.tools/anaconda",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software package specially developed for the study of genes\u2019 primary structure. It uses gene sequences downloaded from public databases, as FASTA and GenBank, and it applies a set of statistical and visualization methods in different ways, to reveal information about codon context, codon usage, nucleotide repeats within open reading frames (ORFeome) and others.",
                "homepage": "http://bioinformatics.ua.pt/software/anaconda/"
            },
            {
                "name": "VCFtools",
                "uri": "https://bio.tools/vcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3675",
                                    "term": "Variant filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Provide easily accessible methods for working with complex genetic variation data in the form of VCF files.",
                "homepage": "https://vcftools.github.io/index.html"
            }
        ],
        "inputs": [
            "samplename",
            "egan_id",
            "hist_root_file",
            "samplename_gt_vcf"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "memory '4G'",
            "tag \"$samplename $egan_id\"",
            "cpus 2",
            "disk '60 GB'",
            "scratch '/tmp'",
            "stageInMode 'copy'",
            "stageOutMode 'rsync'",
            "time '1000m'",
            "container \"copy_number_v2\"",
            "maxForks 40",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "publishDir \"${params.outdir}/copy_number/\", mode: 'symlink', overwrite: true",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "merge_featureCounts": {
        "name_process": "merge_featureCounts",
        "string_process": "\nprocess merge_featureCounts {\n    tag \"$aligner\"\n    scratch '/tmp'\n    stageInMode 'copy'\n    stageOutMode 'rsync'\n    container \"nfcore-rnaseq\"\n    publishDir \"${params.outdir}/combined\", mode: 'symlink'\n    containerOptions = \"--bind /lustre\"\n    label 'merge_feature'\n    memory = '100G'\n    cpus 2\n    time '600m'\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n\n    when:\n    params.run\n\n    input:\n    file(collected_fc_gene_txt)\n\n    output:\n    file '*-fc-genecounts.txt'\n    file(\"fofn_gene_featurecount.txt\")\n\n    shell:\n    suffix=['star':'.star.gene.fc.txt', 'hisat2':'.hisat2.gene.fc.txt']\n    aligner = \"star\"                           \n    outputname = \"${params.runtag}-${aligner}-fc-genecounts.txt\"\n    thesuffix  = suffix[aligner] ?: '.txt'\n    '''\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:$PATH\n\n    ls . | grep gene.fc.txt\\$ > fofn_gene_featurecount.txt\n\n    python3 !{workflow.projectDir}/../bin/rna_seq/merge_featurecounts.py        \\\\\n      --rm-suffix !{thesuffix}                                       \\\\\n      -c 1 --skip-comments --header                                  \\\\\n      -o !{outputname} -I fofn_gene_featurecount.txt\n    '''\n}",
        "nb_lignes_process": 40,
        "string_script": "    suffix=['star':'.star.gene.fc.txt', 'hisat2':'.hisat2.gene.fc.txt']\n    aligner = \"star\"                           \n    outputname = \"${params.runtag}-${aligner}-fc-genecounts.txt\"\n    thesuffix  = suffix[aligner] ?: '.txt'\n    '''\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:$PATH\n\n    ls . | grep gene.fc.txt\\$ > fofn_gene_featurecount.txt\n\n    python3 !{workflow.projectDir}/../bin/rna_seq/merge_featurecounts.py        \\\\\n      --rm-suffix !{thesuffix}                                       \\\\\n      -c 1 --skip-comments --header                                  \\\\\n      -o !{outputname} -I fofn_gene_featurecount.txt\n    '''",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "Maligner"
        ],
        "tools_url": [
            "https://bio.tools/maligner"
        ],
        "tools_dico": [
            {
                "name": "Maligner",
                "uri": "https://bio.tools/maligner",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tool for aligning molecular or insilico restriction maps to a reference map.",
                "homepage": "https://github.com/LeeMendelowitz/maligner"
            }
        ],
        "inputs": [
            "collected_fc_gene_txt"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"$aligner\"",
            "scratch '/tmp'",
            "stageInMode 'copy'",
            "stageOutMode 'rsync'",
            "container \"nfcore-rnaseq\"",
            "publishDir \"${params.outdir}/combined\", mode: 'symlink'",
            "containerOptions = \"--bind /lustre\"",
            "label 'merge_feature'",
            "memory = '100G'",
            "cpus 2",
            "time '600m'",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "graphtyper": {
        "name_process": "graphtyper",
        "string_process": "\nprocess graphtyper {\n    memory '20G'\n    tag \"$graphtyper_command\"\n    cpus 4\n                   \n    time '1400m'\n    queue 'long'\n    container \"graphtyper\"\n    containerOptions = \"--bind /lustre\"\n                                \n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/results/$chr/*.vcf.gz\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/results/$chr/*.vcf.gz.tbi\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/haps/$chr/*.vcf.gz\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/haps/$chr/*.vcf.gz.tbi\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/hap_calls/$chr/*.vcf.gz\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/hap_calls/$chr/*.vcf.gz.tbi\"\n    maxRetries 3\n\n    when:\n    params.run\n     \n    input:\n    file(bamlist_file)\n    file(config_sh)\n    tuple graphtyper_command, chr\n\n    output: \n    tuple file(\"graphtyper-pipelines/results/$chr/*.vcf.gz\"),file(\"graphtyper-pipelines/results/$chr/*.vcf.gz.tbi\"), emit: vcf\n    tuple file(\"graphtyper-pipelines/haps/$chr/*.vcf.gz\"),file(\"graphtyper-pipelines/haps/$chr/*.vcf.gz.tbi\"), emit: haps_vcf\n    tuple file(\"graphtyper-pipelines/hap_calls/$chr/*.vcf.gz\"),file(\"graphtyper-pipelines/hap_calls/$chr/*.vcf.gz.tbi\"), emit: hap_calls_vcf\n    tuple stdout, emit: stdout\n\n    script:\n\"\"\" \ncp -r /graphtyper-pipelines .\ncd ./graphtyper-pipelines\nsed -i s'/ --no_sort//'g node_script.sh\nrm -rf .git\nmkdir ../tmp\ncp call_script.sh ..\n\n$graphtyper_command\n\"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "\"\"\" \ncp -r /graphtyper-pipelines .\ncd ./graphtyper-pipelines\nsed -i s'/ --no_sort//'g node_script.sh\nrm -rf .git\nmkdir ../tmp\ncp call_script.sh ..\n\n$graphtyper_command\n\"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bamlist_file",
            "config_sh",
            "graphtyper_command"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "memory '20G'",
            "tag \"$graphtyper_command\"",
            "cpus 4",
            "time '1400m'",
            "queue 'long'",
            "container \"graphtyper\"",
            "containerOptions = \"--bind /lustre\"",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/results/$chr/*.vcf.gz\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/results/$chr/*.vcf.gz.tbi\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/haps/$chr/*.vcf.gz\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/haps/$chr/*.vcf.gz.tbi\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/hap_calls/$chr/*.vcf.gz\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"graphtyper-pipelines/hap_calls/$chr/*.vcf.gz.tbi\"",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "vcf_remove_chrXY": {
        "name_process": "vcf_remove_chrXY",
        "string_process": "\nprocess vcf_remove_chrXY {\n    memory '4G'\n    tag \"$samplename\"\n    cpus 2\n    disk '60 GB'\n    scratch '/tmp'\n    stageInMode 'copy'\n    stageOutMode 'rsync'\n    time '1000m'\n    container \"copy_number_v2\"\n    maxForks 40\n                                               \n                                \n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    publishDir \"${params.outdir}/copy_number/\", mode: 'symlink', overwrite: true \n    maxRetries 3\n\n    when:\n    params.run\n     \n    input: \n    tuple val(samplename), file(samplename_gt_vcf)\n    \n    output: \n    tuple val(samplename), file(\"${samplename}.noXY.recode.vcf\"), emit: samplename_cn_vcf\n\n    script:\n    \"\"\" \nexport ROOTSYS=/root\nexport MANPATH=/root/man:/usr/local/man:/usr/local/share/man:/usr/share/man\nexport USER_PATH=/home/ubuntu/error/speedseq/bin/:/home/ubuntu/anaconda3/envs/py2/bin:/home/ubuntu/anaconda3/condabin:/usr/local/go/bin:/home/ubuntu/error/root/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/go/bin:/home/ubuntu/go/bin:/bin:/usr/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin\nexport LD_LIBRARY_PATH=/root/lib:/.singularity.d/libs\nexport LIBPATH=/root/lib\nexport JUPYTER_PATH=/root/etc/notebook\nexport DYLD_LIBRARY_PATH=/root/lib\nexport PYTHONPATH=/root/lib\nexport SHLIB_PATH=/root/lib\nexport CMAKE_PREFIX_PATH=/root\nexport CLING_STANDARD_PCH=none\n\nexport PATH=/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/speedseq/bin:/miniconda/bin:\\$PATH\n\n    eval \\\"\\$(conda shell.bash hook)\\\"\n    conda activate py2\n   vcftools --vcf ${samplename_gt_vcf} --not-chr chrX --not-chr chrY --recode --recode-INFO-all --out ${samplename}.noXY\n    \"\"\"\n}",
        "nb_lignes_process": 46,
        "string_script": "    \"\"\" \nexport ROOTSYS=/root\nexport MANPATH=/root/man:/usr/local/man:/usr/local/share/man:/usr/share/man\nexport USER_PATH=/home/ubuntu/error/speedseq/bin/:/home/ubuntu/anaconda3/envs/py2/bin:/home/ubuntu/anaconda3/condabin:/usr/local/go/bin:/home/ubuntu/error/root/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/go/bin:/home/ubuntu/go/bin:/bin:/usr/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin\nexport LD_LIBRARY_PATH=/root/lib:/.singularity.d/libs\nexport LIBPATH=/root/lib\nexport JUPYTER_PATH=/root/etc/notebook\nexport DYLD_LIBRARY_PATH=/root/lib\nexport PYTHONPATH=/root/lib\nexport SHLIB_PATH=/root/lib\nexport CMAKE_PREFIX_PATH=/root\nexport CLING_STANDARD_PCH=none\n\nexport PATH=/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/speedseq/bin:/miniconda/bin:\\$PATH\n\n    eval \\\"\\$(conda shell.bash hook)\\\"\n    conda activate py2\n   vcftools --vcf ${samplename_gt_vcf} --not-chr chrX --not-chr chrY --recode --recode-INFO-all --out ${samplename}.noXY\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "BTEVAL",
            "ANACONDA",
            "VCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bteval",
            "https://bio.tools/anaconda",
            "https://bio.tools/vcftools"
        ],
        "tools_dico": [
            {
                "name": "BTEVAL",
                "uri": "https://bio.tools/bteval",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Protein sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Sequence analysis (protein)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The aim of BTEVAL server is to evaluate beta turn prediction algorithms on a uniform data set of 426 proteins or subsets of these proteins. It is the new data set in which no two protein chains have more that 25% sequence identity and each chain contains minimum one beta turn.",
                "homepage": "http://www.imtech.res.in/raghava/bteval"
            },
            {
                "name": "ANACONDA",
                "uri": "https://bio.tools/anaconda",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software package specially developed for the study of genes\u2019 primary structure. It uses gene sequences downloaded from public databases, as FASTA and GenBank, and it applies a set of statistical and visualization methods in different ways, to reveal information about codon context, codon usage, nucleotide repeats within open reading frames (ORFeome) and others.",
                "homepage": "http://bioinformatics.ua.pt/software/anaconda/"
            },
            {
                "name": "VCFtools",
                "uri": "https://bio.tools/vcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3675",
                                    "term": "Variant filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Provide easily accessible methods for working with complex genetic variation data in the form of VCF files.",
                "homepage": "https://vcftools.github.io/index.html"
            }
        ],
        "inputs": [
            "samplename",
            "samplename_gt_vcf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "memory '4G'",
            "tag \"$samplename\"",
            "cpus 2",
            "disk '60 GB'",
            "scratch '/tmp'",
            "stageInMode 'copy'",
            "stageOutMode 'rsync'",
            "time '1000m'",
            "container \"copy_number_v2\"",
            "maxForks 40",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "publishDir \"${params.outdir}/copy_number/\", mode: 'symlink', overwrite: true",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "baton_study": {
        "name_process": "baton_study",
        "string_process": "\nprocess baton_study {\n    tag \"${study_id}\"\n    memory = '4G'\n    time '240m'\n    cpus 1\n    errorStrategy { task.attempt <= 1 ? 'retry' : 'ignore' }\n    maxRetries 1\n    maxForks 12\n    publishDir \"${params.outdir}/samples/study_id_${study_id}/\", mode: 'copy', pattern: \"samples.tsv\", overwrite: true\n    publishDir \"${params.outdir}/samples/study_id_${study_id}/\", mode: 'copy', pattern: \"samples_noduplicates.tsv\", overwrite: true\n\n    when:\n    params.run\n\n    input: \n    val study_id\n\n    output: \n    tuple val(study_id), file('samples.tsv'), emit: samples_tsv\n    tuple val(study_id), file('samples_noduplicates.tsv'), emit: samples_noduplicates_tsv\n\n    script:\n    \"\"\"\n    bash $workflow.projectDir/../bin/irods_fetch/baton.sh ${study_id}\n    awk '!a[\\$1]++' samples.tsv > samples_noduplicates.tsv \n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    bash $workflow.projectDir/../bin/irods_fetch/baton.sh ${study_id}\n    awk '!a[\\$1]++' samples.tsv > samples_noduplicates.tsv \n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "study_id"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"${study_id}\"",
            "memory = '4G'",
            "time '240m'",
            "cpus 1",
            "errorStrategy { task.attempt <= 1 ? 'retry' : 'ignore' }",
            "maxRetries 1",
            "maxForks 12",
            "publishDir \"${params.outdir}/samples/study_id_${study_id}/\", mode: 'copy', pattern: \"samples.tsv\", overwrite: true",
            "publishDir \"${params.outdir}/samples/study_id_${study_id}/\", mode: 'copy', pattern: \"samples_noduplicates.tsv\", overwrite: true"
        ],
        "when": "params.run",
        "stub": ""
    },
    "samtools_index_idxstats": {
        "name_process": "samtools_index_idxstats",
        "string_process": "\nprocess samtools_index_idxstats {\n    tag \"${samplename}\"\n    container \"nfcore-rnaseq\"\n    memory = '8G'\n    cpus 1\n    time '300m'\n    errorStrategy { task.attempt <= 5 ? 'retry' : 'ignore' }\n    maxRetries 5\n    publishDir \"${params.outdir}/idxstats/\", mode: 'symlink', pattern: \"*.idxstats\"\n\n    when:\n    params.run\n\n    input:\n    set val(aligner), val(samplename), file(thebam)                   \n\n    output:\n    set val(samplename), file(\"*.idxstats\")                     \n\n    script:\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    samtools index $thebam\n    samtools idxstats $thebam > ${samplename}.idxstats\n    rm ${thebam}.bai\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    samtools index $thebam\n    samtools idxstats $thebam > ${samplename}.idxstats\n    rm ${thebam}.bai\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "aligner",
            "samplename",
            "thebam"
        ],
        "nb_inputs": 3,
        "outputs": [
            "samplename"
        ],
        "nb_outputs": 1,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"${samplename}\"",
            "container \"nfcore-rnaseq\"",
            "memory = '8G'",
            "cpus 1",
            "time '300m'",
            "errorStrategy { task.attempt <= 5 ? 'retry' : 'ignore' }",
            "maxRetries 5",
            "publishDir \"${params.outdir}/idxstats/\", mode: 'symlink', pattern: \"*.idxstats\""
        ],
        "when": "params.run",
        "stub": ""
    },
    "index_cram": {
        "name_process": "index_cram",
        "string_process": "\nprocess index_cram {\n    memory '3G'\n    tag \"$cram_file\"\n    cpus 1\n                   \n    time '100m'\n    queue 'normal'\n    container \"graphtyper\"\n    containerOptions = \"--bind /lustre\"\n                                \n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    publishDir \"${params.outdir}/cram_index/\", mode: 'symlink', overwrite: true, pattern: \"${cram_file}.crai\"\n    maxRetries 3\n\n    when:\n    params.run\n     \n    input:\n    file(cram_file)\n\n    output: \n    tuple file(\"${cram_file}.crai\"), emit: indexes\n\n    script:\n\"\"\" \nsamtools index $cram_file\n\"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "\"\"\" \nsamtools index $cram_file\n\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "cram_file"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "memory '3G'",
            "tag \"$cram_file\"",
            "cpus 1",
            "time '100m'",
            "queue 'normal'",
            "container \"graphtyper\"",
            "containerOptions = \"--bind /lustre\"",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "publishDir \"${params.outdir}/cram_index/\", mode: 'symlink', overwrite: true, pattern: \"${cram_file}.crai\"",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "count_crispr_reads": {
        "name_process": "count_crispr_reads",
        "string_process": "\nprocess count_crispr_reads {\n    tag \"read_counts $samplename\"\n                                                              \n                                \n                                          \n    publishDir \"${params.outdir}/read_counts\", mode: 'symlink',\n        saveAs: { filename ->\n            if (filename ==~ /.*\\.unmapped_sequences\\.txt/) \"unmapped_sequences/$filename\"\n            else filename\n        }\n    memory = '10G'\n    cpus 1\n    time '300m'\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n\n    when:\n    params.run\n\n    input:\n    set val(samplename), file(fastq_files), val(guide_library), val(includeG) \n    file(library_files)\n\n    output:\n    set val(guide_library), file(\"*.counts.txt\")\n    file(\"${samplename}.mapping.txt\")\n    set val(samplename), val(guide_library), stdout\n    set val(samplename), file(\"*.unmapped_sequences.txt\")\n\n    shell:\n    \"\"\"\nexport PATH=/software/hgi/installs/anaconda3/envs/nextflow20/bin/:\\$PATH\n\n    if [ \\\"${params.read2}\\\"  == \\\"discard\\\" ]; then\n    rm -f *_2.fastq.gz\n    fi\n\n    python3 ${workflow.projectDir}/../bin/crispr/count_reads.py \\$(ls *.fastq.gz) \\\"${guide_library}\\\" ${samplename}.counts.txt ${samplename}.mapping.txt ${includeG}\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    \"\"\"\nexport PATH=/software/hgi/installs/anaconda3/envs/nextflow20/bin/:\\$PATH\n\n    if [ \\\"${params.read2}\\\"  == \\\"discard\\\" ]; then\n    rm -f *_2.fastq.gz\n    fi\n\n    python3 ${workflow.projectDir}/../bin/crispr/count_reads.py \\$(ls *.fastq.gz) \\\"${guide_library}\\\" ${samplename}.counts.txt ${samplename}.mapping.txt ${includeG}\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplename",
            "guide_library",
            "includeG",
            "fastq_files",
            "library_files"
        ],
        "nb_inputs": 5,
        "outputs": [
            "guide_library",
            "guide_library",
            "samplename"
        ],
        "nb_outputs": 3,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"read_counts $samplename\"",
            "publishDir \"${params.outdir}/read_counts\", mode: 'symlink' , saveAs: { filename -> if (filename ==~ /.* .unmapped_sequences .txt/) \"unmapped_sequences/$filename\" else filename }",
            "memory = '10G'",
            "cpus 1",
            "time '300m'",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    },
    "graphtyper_on_interval": {
        "name_process": "graphtyper_on_interval",
        "string_process": "\nprocess graphtyper_on_interval {\n    tag \"$chr $start $end\"\n    memory = {  4.GB + 3.GB * (task.attempt - 1) }\n    cpus 1\n                   \n    scratch '/tmp'\n    time '700m'\n    maxForks 4000\n    queue 'normal'\n    container \"graphtyper\"\n    containerOptions = \"--bind /lustre --bind /tmp\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"results/$chr/*.vcf.gz\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"results/$chr/*.vcf.gz.tbi\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"haps/$chr/*.vcf.gz\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"haps/$chr/*.vcf.gz.tbi\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"hap_calls/$chr/*.vcf.gz\"\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"hap_calls/$chr/*.vcf.gz.tbi\"\n    maxRetries 5\n    errorStrategy { task.attempt <= 5 ? 'retry' : 'ignore' }\n\n    when:\n    params.run\n     \n    input:\n    file(bamlist_file)\n    file(config_sh_files)\n    tuple chr, start, end\n\n    output: \n    tuple file(\"results/$chr/*.vcf.gz\"),file(\"results/$chr/*.vcf.gz.tbi\"), emit: vcf\n    tuple file(\"haps/$chr/*.vcf.gz\"),file(\"haps/$chr/*.vcf.gz.tbi\"), emit: haps_vcf\n    tuple file(\"hap_calls/$chr/*.vcf.gz\"),file(\"hap_calls/$chr/*.vcf.gz.tbi\"), emit: hap_calls_vcf\n    tuple stdout, emit: stdout\n\n    script:\n\"\"\" \nexport CUSTOM_REGION_SIZE=\\$(($end - $start + 1))\nexport CUSTOM_CHROMOSOMES=\\\"$chr\\\"\nexport CUSTOM_NUM_SLICES_RUNNING=1\nexport CUSTOM_SLICE_SIZE=\\$((CUSTOM_REGION_SIZE / 1))\nexport CUSTOM_PAD_SIZE=200 \n\necho \\$CUSTOM_REGION_SIZE\necho \\$CUSTOM_CHROMOSOMES\necho \\$CUSTOM_SLICE_SIZE\necho \\$CUSTOM_PAD_SIZE\necho \\$CUSTOM_NUM_SLICES_RUNNING\n\n./node_script.sh ./graphtyper_pipeline_config_on_interval.sh ./$bamlist_file $chr:$start\n\"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "\"\"\" \nexport CUSTOM_REGION_SIZE=\\$(($end - $start + 1))\nexport CUSTOM_CHROMOSOMES=\\\"$chr\\\"\nexport CUSTOM_NUM_SLICES_RUNNING=1\nexport CUSTOM_SLICE_SIZE=\\$((CUSTOM_REGION_SIZE / 1))\nexport CUSTOM_PAD_SIZE=200 \n\necho \\$CUSTOM_REGION_SIZE\necho \\$CUSTOM_CHROMOSOMES\necho \\$CUSTOM_SLICE_SIZE\necho \\$CUSTOM_PAD_SIZE\necho \\$CUSTOM_NUM_SLICES_RUNNING\n\n./node_script.sh ./graphtyper_pipeline_config_on_interval.sh ./$bamlist_file $chr:$start\n\"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bamlist_file",
            "config_sh_files",
            "chr"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"$chr $start $end\"",
            "memory = { 4.GB + 3.GB * (task.attempt - 1) }",
            "cpus 1",
            "scratch '/tmp'",
            "time '700m'",
            "maxForks 4000",
            "queue 'normal'",
            "container \"graphtyper\"",
            "containerOptions = \"--bind /lustre --bind /tmp\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"results/$chr/*.vcf.gz\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"results/$chr/*.vcf.gz.tbi\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"haps/$chr/*.vcf.gz\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"haps/$chr/*.vcf.gz.tbi\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"hap_calls/$chr/*.vcf.gz\"",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"hap_calls/$chr/*.vcf.gz.tbi\"",
            "maxRetries 5",
            "errorStrategy { task.attempt <= 5 ? 'retry' : 'ignore' }"
        ],
        "when": "params.run",
        "stub": ""
    },
    "salmon": {
        "name_process": "salmon",
        "string_process": "\nprocess salmon {\n    tag \"salmon $samplename\"\n                    \n    memory = {  10.GB + 20.GB * (task.attempt-1) }\n    container \"salmon\"\n    time '700m'\n    errorStrategy { task.attempt <= 6 ? 'retry' : 'ignore' }\n    maxRetries 6\n    \n    publishDir \"${params.outdir}/salmon\", mode: 'symlink'\n\n    when:\n    params.run\n\n    input:\n    set val(samplename), file(reads)                  \n    file salmon_index_dir                                  \n    file salmon_trans_gene_txt                                       \n\n    output:\n    file \"${samplename}.quant.sf\"                        \n    file \"${samplename}.quant.genes.sf\"                       \n    file \"my_outs/${samplename}\"                                 \n\n    script:\n    \"\"\"\n    salmon quant \\\\\n        -i ${salmon_index_dir} \\\\\n        -l ISR \\\\\n        -p ${task.cpus} \\\\\n        --seqBias \\\\\n        --gcBias \\\\\n        --posBias \\\\\n        --no-version-check \\\\\n        -q \\\\\n        -o . \\\\\n        -1 ${reads[0]} \\\\\n        -2 ${reads[1]} \\\\\n        -g ${salmon_trans_gene_txt} \\\\\n        --useVBOpt \\\\\n        --numBootstraps 100\n    mv quant.sf ${samplename}.quant.sf\n    mv quant.genes.sf ${samplename}.quant.genes.sf\n    mkdir -p my_outs/${samplename}/libParams\n    mkdir -p my_outs/${samplename}/aux_info\n    ln -f aux_info/meta_info.json my_outs/${samplename}/aux_info/meta_info.json\n    ln -f libParams/flenDist.txt  my_outs/${samplename}/libParams/flenDist.txt\n    \"\"\"\n\n                                                                                          \n                                                          \n                                                                                        \n}",
        "nb_lignes_process": 52,
        "string_script": "    \"\"\"\n    salmon quant \\\\\n        -i ${salmon_index_dir} \\\\\n        -l ISR \\\\\n        -p ${task.cpus} \\\\\n        --seqBias \\\\\n        --gcBias \\\\\n        --posBias \\\\\n        --no-version-check \\\\\n        -q \\\\\n        -o . \\\\\n        -1 ${reads[0]} \\\\\n        -2 ${reads[1]} \\\\\n        -g ${salmon_trans_gene_txt} \\\\\n        --useVBOpt \\\\\n        --numBootstraps 100\n    mv quant.sf ${samplename}.quant.sf\n    mv quant.genes.sf ${samplename}.quant.genes.sf\n    mkdir -p my_outs/${samplename}/libParams\n    mkdir -p my_outs/${samplename}/aux_info\n    ln -f aux_info/meta_info.json my_outs/${samplename}/aux_info/meta_info.json\n    ln -f libParams/flenDist.txt  my_outs/${samplename}/libParams/flenDist.txt\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "Salmon"
        ],
        "tools_url": [
            "https://bio.tools/salmon"
        ],
        "tools_dico": [
            {
                "name": "Salmon",
                "uri": "https://bio.tools/salmon",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3496",
                                "term": "RNA sequence (raw)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2093",
                                "term": "Data reference"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "A tool for transcript expression quantification from RNA-seq data",
                "homepage": "https://github.com/COMBINE-lab/salmon"
            }
        ],
        "inputs": [
            "samplename",
            "reads",
            "salmon_index_dir",
            "salmon_trans_gene_txt"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"salmon $samplename\"",
            "memory = { 10.GB + 20.GB * (task.attempt-1) }",
            "container \"salmon\"",
            "time '700m'",
            "errorStrategy { task.attempt <= 6 ? 'retry' : 'ignore' }",
            "maxRetries 6",
            "publishDir \"${params.outdir}/salmon\", mode: 'symlink'"
        ],
        "when": "params.run",
        "stub": ""
    },
    "graphtyper_pipeline": {
        "name_process": "graphtyper_pipeline",
        "string_process": "\nprocess graphtyper_pipeline {\n    memory '4G'\n    tag \"$bamlist_file\"\n    cpus 1\n    disk '20 GB'\n    time '100m'\n    container \"graphtyper\"\n    maxForks 60\n    containerOptions = \"--bind /lustre\"\n                                \n    errorStrategy { task.attempt <= 2 ? 'retry' : 'ignore' }\n    publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"commands_split.txt\"\n    maxRetries 2\n\n    when:\n    params.run\n     \n    input:\n    file(bamlist_file)\n    file(config_sh)\n\n    output: \n    tuple file(\"commands_split.txt\"), emit: commands_split\n\n    script:\n\"\"\" \ncp -r /graphtyper-pipelines .\ncd ./graphtyper-pipelines\nrm -rf .git\nbash make_graphtyper_pipeline.sh ../$bamlist_file ../$config_sh > ../commands_split.txt\n\"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "\"\"\" \ncp -r /graphtyper-pipelines .\ncd ./graphtyper-pipelines\nrm -rf .git\nbash make_graphtyper_pipeline.sh ../$bamlist_file ../$config_sh > ../commands_split.txt\n\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bamlist_file",
            "config_sh"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "memory '4G'",
            "tag \"$bamlist_file\"",
            "cpus 1",
            "disk '20 GB'",
            "time '100m'",
            "container \"graphtyper\"",
            "maxForks 60",
            "containerOptions = \"--bind /lustre\"",
            "errorStrategy { task.attempt <= 2 ? 'retry' : 'ignore' }",
            "publishDir \"${params.outdir}/graphtyper/\", mode: 'symlink', overwrite: true, pattern: \"commands_split.txt\"",
            "maxRetries 2"
        ],
        "when": "params.run",
        "stub": ""
    },
    "mapsummary": {
        "name_process": "mapsummary",
        "string_process": "\nprocess mapsummary {\n    tag \"${samplename}\"\n                                \n    publishDir \"${params.outdir}/mapsummary/\", mode: 'symlink'\n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    maxRetries 3\n    memory = '8G'\n    cpus 1\n    time '300m'\n\n    input:\n    set val(samplename), file(thestats)                      \n\n    output:\n    file \"*_mqc.txt\"                         \n\n    script:\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    python $baseDir/../bin/rna_seq/mito.py -m ${params.mito_name} -t $thestats > ${samplename}_mqc.txt\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    python $baseDir/../bin/rna_seq/mito.py -m ${params.mito_name} -t $thestats > ${samplename}_mqc.txt\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplename",
            "thestats"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"${samplename}\"",
            "publishDir \"${params.outdir}/mapsummary/\", mode: 'symlink'",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "maxRetries 3",
            "memory = '8G'",
            "cpus 1",
            "time '300m'"
        ],
        "when": "",
        "stub": ""
    },
    "featureCounts": {
        "name_process": "featureCounts",
        "string_process": "\nprocess featureCounts {\n    tag \"${samplename}\"\n    container \"nfcore-rnaseq\"\n    memory = '5G'\n    time '300m'\n    cpus 1\n    errorStrategy { task.attempt <= 5 ? 'retry' : 'ignore' }\n    maxRetries 5\n    publishDir \"${params.outdir}/featureCounts/\", mode: 'symlink',\n        saveAs: {filename ->\n            if (filename.indexOf(\".biotype_counts_mqc.txt\") > 0) \"biotype_counts_mqc/$filename\"\n            else if (filename.indexOf(\".biotype.fc.txt\") > 0) \"biotype_counts/$filename\"\n            else if (filename.indexOf(\".biotype.fc.txt.summary\") > 0) \"biotype_counts_summaries/$filename\"\n            else if (filename.indexOf(\".gene.fc.txt.summary\") > 0) \"gene_count_summaries/$filename\"\n            else if (filename.indexOf(\".gene.fc.txt\") > 0) \"gene_counts/$filename\"\n            else \"$filename\"\n        }\n\n    when:\n    params.run\n    \n    input:\n    set val(aligner), val(samplename), file(thebam)                        \n    file gtf                                          \n    file biotypes_header\n\n    output:\n    set val(aligner), file(\"*.gene.fc.txt\")                   \n    set val(aligner), file(\"*.gene.fc.txt.summary\")                     \n    set val(aligner), file(\"*.biotype_counts_mqc.txt\")                            \n\n    script:\n    def extraparams = params.fcextra.toString() - ~/^dummy/\n    def fc_direction = 0\n    def tag = \"${samplename}.${aligner}\"\n\n    def pairedend = params.singleend ? \"\" : \"-p\"\n    if (params.forward_stranded && !params.unstranded) {\n        fc_direction = 1\n    } else if (params.reverse_stranded && !params.unstranded){\n        fc_direction = 2\n    }\n    outfile = \"${tag}.gene.fc.txt\"\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    featureCounts -T ${task.cpus} -a $gtf -g gene_id          \\\\\n      -o ${outfile} $pairedend                                \\\\\n      -s $fc_direction ${extraparams} $thebam\n    cut -f 1,7 ${outfile} > reduced.${outfile}   #  This\n    mv reduced.${outfile} ${outfile}             #  reduces the file size from ~ 30M to ~1M\n    featureCounts -T ${task.cpus} -a $gtf -g gene_id  \\\\\n      -o ${tag}.biotype.fc.txt $pairedend                     \\\\\n      -s $fc_direction ${extraparams} $thebam\n    cut -f 1,7 ${tag}.biotype.fc.txt |                        \\\\\n        tail -n +3 | cat $biotypes_header - >> ${tag}.biotype_counts_mqc.txt\n    \"\"\"\n}",
        "nb_lignes_process": 57,
        "string_script": "    def extraparams = params.fcextra.toString() - ~/^dummy/\n    def fc_direction = 0\n    def tag = \"${samplename}.${aligner}\"\n\n    def pairedend = params.singleend ? \"\" : \"-p\"\n    if (params.forward_stranded && !params.unstranded) {\n        fc_direction = 1\n    } else if (params.reverse_stranded && !params.unstranded){\n        fc_direction = 2\n    }\n    outfile = \"${tag}.gene.fc.txt\"\n    \"\"\"\n    export PATH=/opt/conda/envs/nf-core-rnaseq-1.3/bin:\\$PATH\n\n    featureCounts -T ${task.cpus} -a $gtf -g gene_id          \\\\\n      -o ${outfile} $pairedend                                \\\\\n      -s $fc_direction ${extraparams} $thebam\n    cut -f 1,7 ${outfile} > reduced.${outfile}   #  This\n    mv reduced.${outfile} ${outfile}             #  reduces the file size from ~ 30M to ~1M\n    featureCounts -T ${task.cpus} -a $gtf -g gene_id  \\\\\n      -o ${tag}.biotype.fc.txt $pairedend                     \\\\\n      -s $fc_direction ${extraparams} $thebam\n    cut -f 1,7 ${tag}.biotype.fc.txt |                        \\\\\n        tail -n +3 | cat $biotypes_header - >> ${tag}.biotype_counts_mqc.txt\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "FeatureCounts"
        ],
        "tools_url": [
            "https://bio.tools/featurecounts"
        ],
        "tools_dico": [
            {
                "name": "FeatureCounts",
                "uri": "https://bio.tools/featurecounts",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3793",
                                    "term": "Read summarisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "featureCounts is a very efficient read quantifier. It can be used to summarize RNA-seq reads and gDNA-seq reads to a variety of genomic features such as genes, exons, promoters, gene bodies and genomic bins. It is included in the Bioconductor Rsubread package and also in the SourceForge Subread package.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rsubread.html"
            }
        ],
        "inputs": [
            "aligner",
            "samplename",
            "thebam",
            "gtf",
            "biotypes_header"
        ],
        "nb_inputs": 5,
        "outputs": [
            "aligner",
            "aligner",
            "aligner"
        ],
        "nb_outputs": 3,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "tag \"${samplename}\"",
            "container \"nfcore-rnaseq\"",
            "memory = '5G'",
            "time '300m'",
            "cpus 1",
            "errorStrategy { task.attempt <= 5 ? 'retry' : 'ignore' }",
            "maxRetries 5",
            "publishDir \"${params.outdir}/featureCounts/\", mode: 'symlink' , saveAs: {filename -> if (filename.indexOf(\".biotype_counts_mqc.txt\") > 0) \"biotype_counts_mqc/$filename\" else if (filename.indexOf(\".biotype.fc.txt\") > 0) \"biotype_counts/$filename\" else if (filename.indexOf(\".biotype.fc.txt.summary\") > 0) \"biotype_counts_summaries/$filename\" else if (filename.indexOf(\".gene.fc.txt.summary\") > 0) \"gene_count_summaries/$filename\" else if (filename.indexOf(\".gene.fc.txt\") > 0) \"gene_counts/$filename\" else \"$filename\" }"
        ],
        "when": "params.run",
        "stub": ""
    },
    "vcf_split_all_chr": {
        "name_process": "vcf_split_all_chr",
        "string_process": "\nprocess vcf_split_all_chr {\n    memory '4G'\n    tag \"$samplename\"\n    cpus 1\n    disk '20 GB'\n    scratch '/tmp'\n    stageInMode 'copy'\n    stageOutMode 'rsync'\n    time '1000m'\n    container \"copy_number_v2\"\n    maxForks 60\n                                               \n                                \n    errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }\n    publishDir \"${params.outdir}/copy_number_splitchr/chr1/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr1.recode.vcf\"\n    publishDir \"${params.outdir}/copy_number_splitchr/chr2/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr2.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr3/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr3.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr4/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr4.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr5/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr5.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr6/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr6.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr7/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr7.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr8/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr8.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr9/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr9.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr10/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr10.recode.vcf\"\n    publishDir \"${params.outdir}/copy_number_splitchr/chr11/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr11.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr12/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr12.recode.vcf\"\n    publishDir \"${params.outdir}/copy_number_splitchr/chr13/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr13.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr14/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr14.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr15/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr15.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr16/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr16.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr17/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr17.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr18/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr18.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr19/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr19.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr20/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr20.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr21/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr21.recode.vcf\" \n    publishDir \"${params.outdir}/copy_number_splitchr/chr22/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr22.recode.vcf\" \n    maxRetries 3\n\n    when:\n    params.run\n     \n    input: \n    tuple val(samplename), file(cn_vcf)\n    \n    output: \n    tuple val(samplename), file(\"${samplename}.cn.chr*.recode.vcf\"), emit: samplename_cn_vcf\n\n    script:\n    \"\"\" \nexport ROOTSYS=/root\nexport MANPATH=/root/man:/usr/local/man:/usr/local/share/man:/usr/share/man\nexport USER_PATH=/home/ubuntu/error/speedseq/bin/:/home/ubuntu/anaconda3/envs/py2/bin:/home/ubuntu/anaconda3/condabin:/usr/local/go/bin:/home/ubuntu/error/root/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/go/bin:/home/ubuntu/go/bin:/bin:/usr/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin\nexport LD_LIBRARY_PATH=/root/lib:/.singularity.d/libs\nexport LIBPATH=/root/lib\nexport JUPYTER_PATH=/root/etc/notebook\nexport DYLD_LIBRARY_PATH=/root/lib\nexport PYTHONPATH=/root/lib\nexport SHLIB_PATH=/root/lib\nexport CMAKE_PREFIX_PATH=/root\nexport CLING_STANDARD_PCH=none\n\nexport PATH=/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/speedseq/bin:/miniconda/bin:\\$PATH\n\n    eval \\\"\\$(conda shell.bash hook)\\\"\n    conda activate py2\n    for i in {1..22}\n        do vcftools  --vcf  $cn_vcf  --chr chr\\$i  --recode --recode-INFO-all --out  ${samplename}.cn.chr\\$i\n    done\n    \"\"\"\n}",
        "nb_lignes_process": 69,
        "string_script": "    \"\"\" \nexport ROOTSYS=/root\nexport MANPATH=/root/man:/usr/local/man:/usr/local/share/man:/usr/share/man\nexport USER_PATH=/home/ubuntu/error/speedseq/bin/:/home/ubuntu/anaconda3/envs/py2/bin:/home/ubuntu/anaconda3/condabin:/usr/local/go/bin:/home/ubuntu/error/root/bin:/usr/local/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/go/bin:/home/ubuntu/go/bin:/bin:/usr/bin:/sbin:/usr/sbin:/usr/local/bin:/usr/local/sbin\nexport LD_LIBRARY_PATH=/root/lib:/.singularity.d/libs\nexport LIBPATH=/root/lib\nexport JUPYTER_PATH=/root/etc/notebook\nexport DYLD_LIBRARY_PATH=/root/lib\nexport PYTHONPATH=/root/lib\nexport SHLIB_PATH=/root/lib\nexport CMAKE_PREFIX_PATH=/root\nexport CLING_STANDARD_PCH=none\n\nexport PATH=/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/speedseq/bin:/miniconda/bin:\\$PATH\n\n    eval \\\"\\$(conda shell.bash hook)\\\"\n    conda activate py2\n    for i in {1..22}\n        do vcftools  --vcf  $cn_vcf  --chr chr\\$i  --recode --recode-INFO-all --out  ${samplename}.cn.chr\\$i\n    done\n    \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "BTEVAL",
            "ANACONDA"
        ],
        "tools_url": [
            "https://bio.tools/bteval",
            "https://bio.tools/anaconda"
        ],
        "tools_dico": [
            {
                "name": "BTEVAL",
                "uri": "https://bio.tools/bteval",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Protein sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Sequence analysis (protein)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The aim of BTEVAL server is to evaluate beta turn prediction algorithms on a uniform data set of 426 proteins or subsets of these proteins. It is the new data set in which no two protein chains have more that 25% sequence identity and each chain contains minimum one beta turn.",
                "homepage": "http://www.imtech.res.in/raghava/bteval"
            },
            {
                "name": "ANACONDA",
                "uri": "https://bio.tools/anaconda",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software package specially developed for the study of genes\u2019 primary structure. It uses gene sequences downloaded from public databases, as FASTA and GenBank, and it applies a set of statistical and visualization methods in different ways, to reveal information about codon context, codon usage, nucleotide repeats within open reading frames (ORFeome) and others.",
                "homepage": "http://bioinformatics.ua.pt/software/anaconda/"
            }
        ],
        "inputs": [
            "samplename",
            "cn_vcf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "wtsi-hgi__nextflow-pipelines",
        "directive": [
            "memory '4G'",
            "tag \"$samplename\"",
            "cpus 1",
            "disk '20 GB'",
            "scratch '/tmp'",
            "stageInMode 'copy'",
            "stageOutMode 'rsync'",
            "time '1000m'",
            "container \"copy_number_v2\"",
            "maxForks 60",
            "errorStrategy { task.attempt <= 3 ? 'retry' : 'ignore' }",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr1/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr1.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr2/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr2.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr3/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr3.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr4/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr4.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr5/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr5.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr6/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr6.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr7/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr7.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr8/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr8.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr9/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr9.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr10/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr10.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr11/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr11.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr12/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr12.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr13/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr13.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr14/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr14.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr15/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr15.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr16/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr16.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr17/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr17.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr18/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr18.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr19/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr19.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr20/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr20.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr21/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr21.recode.vcf\"",
            "publishDir \"${params.outdir}/copy_number_splitchr/chr22/\", mode: 'symlink', overwrite: true, pattern: \"${samplename}.cn.chr22.recode.vcf\"",
            "maxRetries 3"
        ],
        "when": "params.run",
        "stub": ""
    }
}