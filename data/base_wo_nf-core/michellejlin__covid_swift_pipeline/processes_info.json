{
    "Trimming": {
        "name_process": "Trimming",
        "string_process": "\nprocess Trimming { \n    container \"quay.io/biocontainers/trimmomatic:0.35--6\"\n\n                                         \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        tuple val(base), file(R1), file(R2)                      \n        file ADAPTERS\n    output: \n        tuple val(base), file(\"${base}.trimmed.fastq.gz\"),file(\"${base}_summary.csv\")                   \n        tuple val(base), file(R1),file(R2),file(\"${base}.R1.paired.fastq.gz\"), file(\"${base}.R2.paired.fastq.gz\"),file(\"${base}.R1.unpaired.fastq.gz\"), file(\"${base}.R2.unpaired.fastq.gz\")                    \n        tuple val(base), file(\"${base}.trimmed.fastq.gz\")                    \n\n    publishDir \"${params.OUTDIR}trimmed_fastqs\", mode: 'copy',pattern:'*.trimmed.fastq*'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n\n    trimmomatic PE -threads ${task.cpus} ${R1} ${R2} ${base}.R1.paired.fastq.gz ${base}.R1.unpaired.fastq.gz ${base}.R2.paired.fastq.gz ${base}.R2.unpaired.fastq.gz \\\n    ILLUMINACLIP:${ADAPTERS}:2:30:10:1:true LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:75\n\n    num_r1_untrimmed=\\$(gunzip -c ${R1} | wc -l)\n    num_r2_untrimmed=\\$(gunzip -c ${R2} | wc -l)\n    num_untrimmed=\\$((\\$((num_r1_untrimmed + num_r2_untrimmed))/4))\n\n    num_r1_paired=\\$(gunzip -c ${base}.R1.paired.fastq.gz | wc -l)\n    num_r2_paired=\\$(gunzip -c ${base}.R2.paired.fastq.gz | wc -l)\n    num_paired=\\$((\\$((num_r1_paired + num_r2_paired))/4))\n\n    num_r1_unpaired=\\$(gunzip -c ${base}.R1.unpaired.fastq.gz | wc -l)\n    num_r2_unpaired=\\$(gunzip -c ${base}.R2.unpaired.fastq.gz | wc -l)\n    num_unpaired=\\$((\\$((num_r1_unpaired + num_r2_unpaired))/4))\n\n    num_trimmed=\\$((num_paired + num_unpaired))\n    \n    percent_trimmed=\\$((100-\\$((100*num_trimmed/num_untrimmed))))\n    \n    echo Sample_Name,Raw_Reads,Trimmed_Paired_Reads,Trimmed_Unpaired_Reads,Total_Trimmed_Reads,Percent_Trimmed,Mapped_Reads,Clipped_Mapped_Reads,Mean_Coverage,Spike_Mean_Coverage,Spike_100X_Cov_Percentage,Spike_200X_Cov_Percentage,Lowest_Spike_Cov,Percent_N > ${base}_summary.csv\n    printf \"${base},\\$num_untrimmed,\\$num_paired,\\$num_unpaired,\\$num_trimmed,\\$percent_trimmed\" >> ${base}_summary.csv\n\n    cat *paired.fastq.gz > ${base}.trimmed.fastq.gz\n    \n    \"\"\"\n}",
        "nb_lignes_process": 46,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    trimmomatic PE -threads ${task.cpus} ${R1} ${R2} ${base}.R1.paired.fastq.gz ${base}.R1.unpaired.fastq.gz ${base}.R2.paired.fastq.gz ${base}.R2.unpaired.fastq.gz \\\n    ILLUMINACLIP:${ADAPTERS}:2:30:10:1:true LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:75\n\n    num_r1_untrimmed=\\$(gunzip -c ${R1} | wc -l)\n    num_r2_untrimmed=\\$(gunzip -c ${R2} | wc -l)\n    num_untrimmed=\\$((\\$((num_r1_untrimmed + num_r2_untrimmed))/4))\n\n    num_r1_paired=\\$(gunzip -c ${base}.R1.paired.fastq.gz | wc -l)\n    num_r2_paired=\\$(gunzip -c ${base}.R2.paired.fastq.gz | wc -l)\n    num_paired=\\$((\\$((num_r1_paired + num_r2_paired))/4))\n\n    num_r1_unpaired=\\$(gunzip -c ${base}.R1.unpaired.fastq.gz | wc -l)\n    num_r2_unpaired=\\$(gunzip -c ${base}.R2.unpaired.fastq.gz | wc -l)\n    num_unpaired=\\$((\\$((num_r1_unpaired + num_r2_unpaired))/4))\n\n    num_trimmed=\\$((num_paired + num_unpaired))\n    \n    percent_trimmed=\\$((100-\\$((100*num_trimmed/num_untrimmed))))\n    \n    echo Sample_Name,Raw_Reads,Trimmed_Paired_Reads,Trimmed_Unpaired_Reads,Total_Trimmed_Reads,Percent_Trimmed,Mapped_Reads,Clipped_Mapped_Reads,Mean_Coverage,Spike_Mean_Coverage,Spike_100X_Cov_Percentage,Spike_200X_Cov_Percentage,Lowest_Spike_Cov,Percent_N > ${base}_summary.csv\n    printf \"${base},\\$num_untrimmed,\\$num_paired,\\$num_unpaired,\\$num_trimmed,\\$percent_trimmed\" >> ${base}_summary.csv\n\n    cat *paired.fastq.gz > ${base}.trimmed.fastq.gz\n    \n    \"\"\"",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [
            "Trimmomatic"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            }
        ],
        "inputs": [
            "base",
            "R1",
            "R2",
            "ADAPTERS"
        ],
        "nb_inputs": 4,
        "outputs": [
            "base",
            "base",
            "base"
        ],
        "nb_outputs": 3,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/biocontainers/trimmomatic:0.35--6\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "Fastqc": {
        "name_process": "Fastqc",
        "string_process": "\nprocess Fastqc {\n    container \"quay.io/biocontainers/fastqc:0.11.9--0\"\n\n                                         \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n    tuple val(base), file(R1),file(R2),file(\"${base}.R1.paired.fastq.gz\"), file(\"${base}.R2.paired.fastq.gz\"),file(\"${base}.R1.unpaired.fastq.gz\"), file(\"${base}.R2.unpaired.fastq.gz\")                     \n    output: \n    file(\"*fastqc*\")                  \n\n    publishDir \"${params.OUTDIR}fastqc\", mode: 'copy'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n\n    /usr/local/bin/fastqc ${R1} ${R2} ${base}.R1.paired.fastq.gz ${base}.R2.paired.fastq.gz\n\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    /usr/local/bin/fastqc ${R1} ${R2} ${base}.R1.paired.fastq.gz ${base}.R2.paired.fastq.gz\n\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "base",
            "R1",
            "R2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/biocontainers/fastqc:0.11.9--0\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "Trimming_SE": {
        "name_process": "Trimming_SE",
        "string_process": "\nprocess Trimming_SE { \n    container \"quay.io/biocontainers/trimmomatic:0.35--6\"\n\n                                         \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        file R1                     \n        file ADAPTERS\n    output: \n        tuple env(base),file(\"*.trimmed.fastq.gz\"),file(\"*summary.csv\")                      \n        tuple env(base),file(\"*.trimmed.fastq.gz\")                       \n        tuple env(base),file(\"*.trimmed.fastq.gz\")                       \n\n    publishDir \"${params.OUTDIR}trimmed_fastqs\", mode: 'copy',pattern:'*.trimmed.fastq*'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n\n    base=`basename ${R1} \".fastq.gz\"`\n\n    echo \\$base\n\n    trimmomatic SE -threads ${task.cpus} ${R1} \\$base.trimmed.fastq.gz \\\n    ILLUMINACLIP:${ADAPTERS}:2:30:10:1:true LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:75\n\n    num_untrimmed=\\$((\\$(gunzip -c ${R1} | wc -l)/4))\n    num_trimmed=\\$((\\$(gunzip -c \\$base'.trimmed.fastq.gz' | wc -l)/4))\n    \n    percent_trimmed=\\$((100-\\$((100*num_trimmed/num_untrimmed))))\n    \n    echo Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Mapped_Reads,Clipped_Mapped_Reads,Mean_Coverage,Spike_Mean_Coverage,Spike_100X_Cov_Percentage,Spike_200X_Cov_Percentage,Lowest_Spike_Cov,Percent_N > \\$base'_summary.csv'\n    printf \"\\$base,\\$num_untrimmed,\\$num_trimmed,\\$percent_trimmed\" >> \\$base'_summary.csv'\n    \n    ls -latr\n    \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    base=`basename ${R1} \".fastq.gz\"`\n\n    echo \\$base\n\n    trimmomatic SE -threads ${task.cpus} ${R1} \\$base.trimmed.fastq.gz \\\n    ILLUMINACLIP:${ADAPTERS}:2:30:10:1:true LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:75\n\n    num_untrimmed=\\$((\\$(gunzip -c ${R1} | wc -l)/4))\n    num_trimmed=\\$((\\$(gunzip -c \\$base'.trimmed.fastq.gz' | wc -l)/4))\n    \n    percent_trimmed=\\$((100-\\$((100*num_trimmed/num_untrimmed))))\n    \n    echo Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Mapped_Reads,Clipped_Mapped_Reads,Mean_Coverage,Spike_Mean_Coverage,Spike_100X_Cov_Percentage,Spike_200X_Cov_Percentage,Lowest_Spike_Cov,Percent_N > \\$base'_summary.csv'\n    printf \"\\$base,\\$num_untrimmed,\\$num_trimmed,\\$percent_trimmed\" >> \\$base'_summary.csv'\n    \n    ls -latr\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "Trimmomatic"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            }
        ],
        "inputs": [
            "R1",
            "ADAPTERS"
        ],
        "nb_inputs": 2,
        "outputs": [
            "base",
            "base",
            "base"
        ],
        "nb_outputs": 3,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/biocontainers/trimmomatic:0.35--6\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "Fastqc_SE": {
        "name_process": "Fastqc_SE",
        "string_process": "\nprocess Fastqc_SE {\n    container \"quay.io/biocontainers/fastqc:0.11.9--0\"\n\n                                         \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        tuple val(base),file(\"${base}.trimmed.fastq.gz\")                        \n    output: \n        file(\"*fastqc*\")                  \n\n    publishDir \"${params.OUTDIR}fastqc\", mode: 'copy'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n\n    /usr/local/bin/fastqc ${base}.trimmed.fastq.gz\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    /usr/local/bin/fastqc ${base}.trimmed.fastq.gz\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "base"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/biocontainers/fastqc:0.11.9--0\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "Aligning": {
        "name_process": "Aligning",
        "string_process": "\nprocess Aligning {\n    container \"quay.io/biocontainers/bbmap:38.86--h1296035_0\"\n                                                               \n\n                                         \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input: \n        tuple val(base), file(\"${base}.trimmed.fastq.gz\"),file(\"${base}_summary.csv\")\n        file REFERENCE_FASTA\n    output:\n        tuple val(base), file(\"${base}.bam\"),file(\"${base}_summary2.csv\")                      \n        tuple val (base), file(\"*\")               \n\n    script:\n    \"\"\"\n    #!/bin/bash\n\n    cat ${base}*.fastq.gz > ${base}_cat.fastq.gz\n    /usr/local/bin/bbmap.sh in=${base}_cat.fastq.gz outm=${base}.bam ref=${REFERENCE_FASTA} local=true -Xmx6g > bbmap_out.txt 2>&1\n    reads_mapped=\\$(cat bbmap_out.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    cat ${base}*.fastq.gz > ${base}_cat.fastq.gz\n    /usr/local/bin/bbmap.sh in=${base}_cat.fastq.gz outm=${base}.bam ref=${REFERENCE_FASTA} local=true -Xmx6g > bbmap_out.txt 2>&1\n    reads_mapped=\\$(cat bbmap_out.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "base",
            "REFERENCE_FASTA"
        ],
        "nb_inputs": 2,
        "outputs": [
            "base",
            "base"
        ],
        "nb_outputs": 2,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/biocontainers/bbmap:38.86--h1296035_0\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "CountSubgenomicRNAs": {
        "name_process": "CountSubgenomicRNAs",
        "string_process": "\nprocess CountSubgenomicRNAs {\n    container \"quay.io/thanhleviet/bbtools:latest\"\n\n                                        \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input: \n        tuple val(base), file(\"${base}.trimmed.fastq.gz\")                    \n        file SGRNAS \n    output:\n        file(\"*stats*\")\n        file(\"*_sgrnas.fastq.gz\")\n    \n    publishDir \"${params.OUTDIR}sgRNAs\", mode: 'copy'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n\n    bbduk.sh in=${base}.trimmed.fastq.gz outm=${base}_sgrnas.fastq.gz ref=${SGRNAS} stats=${base}_sgrnas_stats.txt refstats=${base}_sgrnas_refstats.txt k=50 qhdist=2 -Xmx12g\n\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    bbduk.sh in=${base}.trimmed.fastq.gz outm=${base}_sgrnas.fastq.gz ref=${SGRNAS} stats=${base}_sgrnas_stats.txt refstats=${base}_sgrnas_refstats.txt k=50 qhdist=2 -Xmx12g\n\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "base",
            "SGRNAS"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/thanhleviet/bbtools:latest\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "NameSorting": {
        "name_process": "NameSorting",
        "string_process": "\nprocess NameSorting { \n    container \"quay.io/biocontainers/samtools:1.3--h0592bc0_3\"\n\n                                         \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        tuple val (base), file(\"${base}.bam\"),file(\"${base}_summary2.csv\")                      \n    output:\n        tuple val (base), file(\"${base}.sorted.sam\"),file(\"${base}_summary2.csv\")                     \n\n    publishDir \"${params.OUTDIR}inprogress_summary\", mode: 'copy', pattern: '*summary.csv'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n    samtools sort -@ ${task.cpus} -n -O sam ${base}.bam > ${base}.sorted.sam\n\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    samtools sort -@ ${task.cpus} -n -O sam ${base}.bam > ${base}.sorted.sam\n\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "base"
        ],
        "nb_inputs": 1,
        "outputs": [
            "base"
        ],
        "nb_outputs": 1,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/biocontainers/samtools:1.3--h0592bc0_3\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "Clipping": {
        "name_process": "Clipping",
        "string_process": "\nprocess Clipping { \n    container \"quay.io/greninger-lab/swift-pipeline:latest\"\n\n                                         \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        tuple val (base), file(\"${base}.sorted.sam\"),file(\"${base}_summary2.csv\")                     \n        file MASTERFILE\n    output:\n        tuple val (base), file(\"${base}.clipped.bam\"), file(\"${base}.clipped.bam.bai\"),file(\"${base}_summary3.csv\"),env(bamsize)                      \n        tuple val (base), file(\"${base}.clipped.bam\"), file(\"${base}.clipped.bam.bai\"),env(bamsize)                       \n        tuple val (base), file(\"${base}.clipped.bam\"), file(\"${base}.clipped.bam.bai\"),env(bamsize)                       \n\n    publishDir params.OUTDIR, mode: 'copy', pattern: '*.clipped.bam'\n    publishDir \"${params.OUTDIR}inprogress_summary\", mode: 'copy', pattern: '*summary3.csv'\n\n    script:\n        \"\"\"\n        #!/bin/bash\n        ls -latr\n        /./root/.local/bin/primerclip -s ${MASTERFILE} ${base}.sorted.sam ${base}.clipped.sam\n        #/usr/local/miniconda/bin/samtools sort -@ ${task.cpus} -n -O sam ${base}.clipped.sam > ${base}.clipped.sorted.sam\n        #/usr/local/miniconda/bin/samtools view -@ ${task.cpus} -Sb ${base}.clipped.sorted.sam > ${base}.clipped.unsorted.bam\n        #/usr/local/miniconda/bin/samtools sort -@ ${task.cpus} -o ${base}.clipped.unsorted.bam ${base}.clipped.bam\n        /usr/local/miniconda/bin/samtools sort -@ ${task.cpus} ${base}.clipped.sam -o ${base}.clipped.bam\n        /usr/local/miniconda/bin/samtools index ${base}.clipped.bam\n        clipped_reads=\\$(/usr/local/miniconda/bin/samtools flagstat ${base}.clipped.bam | grep \"mapped (\" | awk '{print \\$1}')\n        echo \"clipped reads: \\$clipped_reads\"\n        /usr/local/miniconda/bin/bedtools genomecov -d -ibam ${base}.clipped.bam > ${base}_coverage.txt\n        meancoverage=\\$(cat ${base}_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n        bamsize=\\$((\\$(wc -c ${base}.clipped.bam | awk '{print \\$1'})+0))\n        echo \"bamsize: \\$bamsize\"\n        if (( \\$bamsize > 92 ))\n        then\n            # Spike protein coverage\n            awk '\\$2 ~ /21563/,\\$2 ~ /25384/' ${base}_coverage.txt > ${base}_spike_coverage.txt\n            avgcoverage=\\$(cat ${base}_spike_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n            proteinlength=\\$((25384-21563+1))\n            cov100=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=100' | wc -l)/3822))\n            cov200=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=200' | wc -l)/3822))\n            mincov=\\$(sort -nk 3 ${base}_spike_coverage.txt | head -n 1 | cut -f3)\n        else\n            avgcoverage=0\n            cov100=0\n            cov200=0\n            mincov=0\n        fi\n        \n        cp ${base}_summary2.csv ${base}_summary3.csv\n        printf \",\\$clipped_reads,\\$meancoverage,\\$avgcoverage,\\$cov100,\\$cov200,\\$mincov\" >> ${base}_summary3.csv\n        \"\"\"\n    }",
        "nb_lignes_process": 53,
        "string_script": "        \"\"\"\n        #!/bin/bash\n        ls -latr\n        /./root/.local/bin/primerclip -s ${MASTERFILE} ${base}.sorted.sam ${base}.clipped.sam\n        #/usr/local/miniconda/bin/samtools sort -@ ${task.cpus} -n -O sam ${base}.clipped.sam > ${base}.clipped.sorted.sam\n        #/usr/local/miniconda/bin/samtools view -@ ${task.cpus} -Sb ${base}.clipped.sorted.sam > ${base}.clipped.unsorted.bam\n        #/usr/local/miniconda/bin/samtools sort -@ ${task.cpus} -o ${base}.clipped.unsorted.bam ${base}.clipped.bam\n        /usr/local/miniconda/bin/samtools sort -@ ${task.cpus} ${base}.clipped.sam -o ${base}.clipped.bam\n        /usr/local/miniconda/bin/samtools index ${base}.clipped.bam\n        clipped_reads=\\$(/usr/local/miniconda/bin/samtools flagstat ${base}.clipped.bam | grep \"mapped (\" | awk '{print \\$1}')\n        echo \"clipped reads: \\$clipped_reads\"\n        /usr/local/miniconda/bin/bedtools genomecov -d -ibam ${base}.clipped.bam > ${base}_coverage.txt\n        meancoverage=\\$(cat ${base}_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n        bamsize=\\$((\\$(wc -c ${base}.clipped.bam | awk '{print \\$1'})+0))\n        echo \"bamsize: \\$bamsize\"\n        if (( \\$bamsize > 92 ))\n        then\n            # Spike protein coverage\n            awk '\\$2 ~ /21563/,\\$2 ~ /25384/' ${base}_coverage.txt > ${base}_spike_coverage.txt\n            avgcoverage=\\$(cat ${base}_spike_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n            proteinlength=\\$((25384-21563+1))\n            cov100=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=100' | wc -l)/3822))\n            cov200=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=200' | wc -l)/3822))\n            mincov=\\$(sort -nk 3 ${base}_spike_coverage.txt | head -n 1 | cut -f3)\n        else\n            avgcoverage=0\n            cov100=0\n            cov200=0\n            mincov=0\n        fi\n        \n        cp ${base}_summary2.csv ${base}_summary3.csv\n        printf \",\\$clipped_reads,\\$meancoverage,\\$avgcoverage,\\$cov100,\\$cov200,\\$mincov\" >> ${base}_summary3.csv\n        \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "base",
            "MASTERFILE"
        ],
        "nb_inputs": 2,
        "outputs": [
            "base",
            "base",
            "base"
        ],
        "nb_outputs": 3,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/greninger-lab/swift-pipeline:latest\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "BamSorting": {
        "name_process": "BamSorting",
        "string_process": "\nprocess BamSorting { \n    container \"quay.io/greninger-lab/swift-pipeline:latest\"\n\n\t                                     \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n      tuple val (base), file(\"${base}.bam\"),file(\"${base}_summary2.csv\")                      \n    output:\n      tuple val (base), file(\"${base}.sorted.bam\"),file(\"${base}.sorted.bam.bai\"),file(\"${base}_summary3.csv\"),env(bamsize)                      \n    \n    publishDir \"${params.OUTDIR}inprogress_summary\", mode: 'copy', pattern: '*summary.csv'\n    publishDir params.OUTDIR, mode: 'copy', pattern: '*.sorted.bam'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n    /usr/local/miniconda/bin/samtools sort -@ ${task.cpus} ${base}.bam > ${base}.sorted.bam\n    /usr/local/miniconda/bin/samtools index ${base}.sorted.bam\n\n    clipped_reads=0\n    /usr/local/miniconda/bin/bedtools genomecov -d -ibam ${base}.sorted.bam > ${base}_coverage.txt\n    meancoverage=\\$(cat ${base}_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n    bamsize=\\$((\\$(wc -c ${base}.sorted.bam | awk '{print \\$1'})+0))\n    echo \"bamsize: \\$bamsize\"\n    if (( \\$bamsize > 92 ))\n    then\n        # Spike protein coverage\n        awk '\\$2 ~ /21563/,\\$2 ~ /25384/' ${base}_coverage.txt > ${base}_spike_coverage.txt\n        avgcoverage=\\$(cat ${base}_spike_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n        proteinlength=\\$((25384-21563+1))\n        cov100=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=100' | wc -l)/3822))\n        cov200=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=200' | wc -l)/3822))\n        mincov=\\$(sort -nk 3 ${base}_spike_coverage.txt | head -n 1 | cut -f3)\n    else\n        avgcoverage=0\n        cov100=0\n        cov200=0\n        mincov=0\n    fi\n\n    cp ${base}_summary2.csv ${base}_summary3.csv\n    printf \",\\$clipped_reads,\\$meancoverage,\\$avgcoverage,\\$cov100,\\$cov200,\\$mincov\" >> ${base}_summary3.csv\n\n\n    \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    /usr/local/miniconda/bin/samtools sort -@ ${task.cpus} ${base}.bam > ${base}.sorted.bam\n    /usr/local/miniconda/bin/samtools index ${base}.sorted.bam\n\n    clipped_reads=0\n    /usr/local/miniconda/bin/bedtools genomecov -d -ibam ${base}.sorted.bam > ${base}_coverage.txt\n    meancoverage=\\$(cat ${base}_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n    bamsize=\\$((\\$(wc -c ${base}.sorted.bam | awk '{print \\$1'})+0))\n    echo \"bamsize: \\$bamsize\"\n    if (( \\$bamsize > 92 ))\n    then\n        # Spike protein coverage\n        awk '\\$2 ~ /21563/,\\$2 ~ /25384/' ${base}_coverage.txt > ${base}_spike_coverage.txt\n        avgcoverage=\\$(cat ${base}_spike_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n        proteinlength=\\$((25384-21563+1))\n        cov100=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=100' | wc -l)/3822))\n        cov200=\\$((100*\\$(cat ${base}_spike_coverage.txt | awk '\\$3>=200' | wc -l)/3822))\n        mincov=\\$(sort -nk 3 ${base}_spike_coverage.txt | head -n 1 | cut -f3)\n    else\n        avgcoverage=0\n        cov100=0\n        cov200=0\n        mincov=0\n    fi\n\n    cp ${base}_summary2.csv ${base}_summary3.csv\n    printf \",\\$clipped_reads,\\$meancoverage,\\$avgcoverage,\\$cov100,\\$cov200,\\$mincov\" >> ${base}_summary3.csv\n\n\n    \"\"\"",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "base"
        ],
        "nb_inputs": 1,
        "outputs": [
            "base"
        ],
        "nb_outputs": 1,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/greninger-lab/swift-pipeline:latest\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "GenerateConsensus": {
        "name_process": "GenerateConsensus",
        "string_process": "\nprocess GenerateConsensus {\n    container \"quay.io/greninger-lab/swift-pipeline:latest\"\n\n\t                                     \n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        tuple val (base), file(BAMFILE),file(INDEX_FILE),file(\"${base}_summary3.csv\"),val(bamsize)                      \n        file REFERENCE_FASTA\n        file TRIM_ENDS\n        file FIX_COVERAGE\n        file VCFUTILS\n        file REFERENCE_FASTA_FAI\n        file SPLITCHR\n    output:\n        file(\"${base}_swift.fasta\")\n        file(\"${base}_bcftools.vcf\")\n        file(INDEX_FILE)\n        file(\"${base}_summary.csv\")\n        tuple val(base), val(bamsize), file(\"${base}_pre_bcftools.vcf\")              \n\n    publishDir params.OUTDIR, mode: 'copy'\n\n    shell:\n    '''\n    #!/bin/bash\n    ls -latr\n\n    R1=!{base}\n\n    echo \"bamsize: !{bamsize}\"\n\n    #if [ -s !{BAMFILE} ]\n    # More reliable way of checking bam size, because of aliases\n    if (( !{bamsize} > 92 ))\n    then\n        # Parallelize pileup based on number of cores\n        splitnum=$(($((29903/!{task.cpus}))+1))\n        perl !{VCFUTILS} splitchr -l $splitnum !{REFERENCE_FASTA_FAI} | \\\\\n        #cat !{SPLITCHR} | \\\\\n            xargs -I {} -n 1 -P !{task.cpus} sh -c \\\\\n                \"/usr/local/miniconda/bin/bcftools mpileup \\\\\n                    -f !{REFERENCE_FASTA} -r {} \\\\\n                    --count-orphans \\\\\n                    --no-BAQ \\\\\n                    --max-depth 50000 \\\\\n                    --max-idepth 500000 \\\\\n                    --annotate FORMAT/AD,FORMAT/ADF,FORMAT/ADR,FORMAT/DP,FORMAT/SP,INFO/AD,INFO/ADF,INFO/ADR \\\\\n                !{BAMFILE} | /usr/local/miniconda/bin/bcftools call -A -m -Oz - > tmp.{}.vcf.gz\"\n        \n        # Concatenate parallelized vcfs back together\n        cat *.vcf.gz > \\${R1}_catted.vcf.gz\n\n        # Index and call variants from vcf\n        /usr/local/miniconda/bin/tabix \\${R1}_catted.vcf.gz\n        gunzip \\${R1}_catted.vcf.gz\n        cat \\${R1}_catted.vcf | awk '$1 ~ /^#/ {print $0;next} {print $0 | \"sort -k1,1 -k2,2n\"}' > \\${R1}_pre_bcftools.vcf\n        \n        # Make sure variants are majority variants for consensus calling\n        /usr/local/miniconda/bin/bcftools filter -i '(DP4[0]+DP4[1]) < (DP4[2]+DP4[3]) && ((DP4[2]+DP4[3]) > 0)' --threads !{task.cpus} \\${R1}_pre_bcftools.vcf -o \\${R1}_pre2.vcf\n        /usr/local/miniconda/bin/bcftools filter -e 'IMF < 0.5' \\${R1}_pre2.vcf -o \\${R1}.vcf\n\n        # Index and generate consensus from vcf with majority variants\n        /usr/local/miniconda/bin/bgzip \\${R1}.vcf\n        /usr/local/miniconda/bin/tabix \\${R1}.vcf.gz \n        cat !{REFERENCE_FASTA} | /usr/local/miniconda/bin/bcftools consensus \\${R1}.vcf.gz > \\${R1}.consensus.fa\n\n        # Create coverage file from bam for whole genome, then pipe anything that has less than 6 coverage to bed file,\n        # to be masked later\n        /usr/local/miniconda/bin/bedtools genomecov \\\\\n            -bga \\\\\n            -ibam !{BAMFILE} \\\\\n            -g !{REFERENCE_FASTA} \\\\\n            | awk '\\$4 < 6' | /usr/local/miniconda/bin/bedtools merge > \\${R1}.mask.bed\n        # Get rid of anything outside of the genome we care about, to prevent some sgrnas from screwing with masking\n        awk '{ if(\\$3 > 200 && \\$2 < 29742) {print}}' \\${R1}.mask.bed > a.tmp && mv a.tmp \\${R1}.mask.bed\n\n        # Mask refseq fasta for low coverage areas based on bed file\n        /usr/local/miniconda/bin/bedtools maskfasta \\\\\n            -fi !{REFERENCE_FASTA} \\\\\n            -bed \\${R1}.mask.bed \\\\\n            -fo ref.mask.fasta\n        \n        # Align to Wuhan refseq and unwrap fasta\n        cat ref.mask.fasta \\${R1}.consensus.fa > align_input.fasta\n        /usr/local/miniconda/bin/mafft --auto --thread !{task.cpus} align_input.fasta > repositioned.fasta\n        awk '/^>/ { print (NR==1 ? \"\" : RS) $0; next } { printf \"%s\", $0 } END { printf RS }' repositioned.fasta > repositioned_unwrap.fasta\n        \n        # Trim ends and aligns masking of refseq to our consensus\n        python3 !{TRIM_ENDS} \\${R1}\n\n        # Find percent ns, doesn't work, fix later in python script\n        num_bases=$(grep -v \">\" \\${R1}_swift.fasta | wc | awk '{print $3-$1}')\n        num_ns=$(grep -v \">\" \\${R1}_swift.fasta | awk -F\"n\" '{print NF-1}')\n        percent_n=$(awk -v num_ns=$num_ns -v num_bases=$num_bases 'BEGIN { print ( num_ns * 100 / num_bases ) }')\n        echo \"num_bases=$num_bases\"\n        echo \"num_ns=$num_ns\"\n        echo \"percent_n=$percent_n\"\n        gunzip \\${R1}.vcf.gz\n        mv \\${R1}.vcf \\${R1}_bcftools.vcf\n        #/usr/local/miniconda/bin/samtools view !{BAMFILE} -@ !{task.cpus} | awk -F: '$12 < 600' > \\${R1}'.clipped.cleaned.bam'\n    else\n       echo \"Empty bam detected. Generating empty consensus fasta file...\"\n       # Generate empty stats for empty bam\n       printf '>!{base}\\n' > \\${R1}_swift.fasta\n       printf 'n%.0s' {1..29539} >> \\${R1}_swift.fasta\n       percent_n=100\n       touch \\${R1}_bcftools.vcf\n       touch \\${R1}_pre_bcftools.vcf\n    fi\n    \n    cp \\${R1}_summary3.csv \\${R1}_summary.csv\n    printf \",\\$percent_n\" >> \\${R1}_summary.csv\n\n    cat \\${R1}_summary.csv | tr -d \"[:blank:]\" > a.tmp\n    mv a.tmp \\${R1}_summary.csv\n\n    # Correctly calculates %ns and cleans up the summary file.\n    if [[ !{bamsize} > 92 ]]\n    then\n        python3 !{FIX_COVERAGE} \\${R1}\n        mv \\${R1}_summary_fixed.csv \\${R1}_summary.csv\n    fi\n\n    [ -s \\${R1}_swift.fasta ] || echo \"WARNING: \\${R1} produced blank output. Manual review may be needed.\"\n\n    '''\n}",
        "nb_lignes_process": 128,
        "string_script": "    '''\n    #!/bin/bash\n    ls -latr\n\n    R1=!{base}\n\n    echo \"bamsize: !{bamsize}\"\n\n    #if [ -s !{BAMFILE} ]\n    # More reliable way of checking bam size, because of aliases\n    if (( !{bamsize} > 92 ))\n    then\n        # Parallelize pileup based on number of cores\n        splitnum=$(($((29903/!{task.cpus}))+1))\n        perl !{VCFUTILS} splitchr -l $splitnum !{REFERENCE_FASTA_FAI} | \\\\\n        #cat !{SPLITCHR} | \\\\\n            xargs -I {} -n 1 -P !{task.cpus} sh -c \\\\\n                \"/usr/local/miniconda/bin/bcftools mpileup \\\\\n                    -f !{REFERENCE_FASTA} -r {} \\\\\n                    --count-orphans \\\\\n                    --no-BAQ \\\\\n                    --max-depth 50000 \\\\\n                    --max-idepth 500000 \\\\\n                    --annotate FORMAT/AD,FORMAT/ADF,FORMAT/ADR,FORMAT/DP,FORMAT/SP,INFO/AD,INFO/ADF,INFO/ADR \\\\\n                !{BAMFILE} | /usr/local/miniconda/bin/bcftools call -A -m -Oz - > tmp.{}.vcf.gz\"\n        \n        # Concatenate parallelized vcfs back together\n        cat *.vcf.gz > \\${R1}_catted.vcf.gz\n\n        # Index and call variants from vcf\n        /usr/local/miniconda/bin/tabix \\${R1}_catted.vcf.gz\n        gunzip \\${R1}_catted.vcf.gz\n        cat \\${R1}_catted.vcf | awk '$1 ~ /^#/ {print $0;next} {print $0 | \"sort -k1,1 -k2,2n\"}' > \\${R1}_pre_bcftools.vcf\n        \n        # Make sure variants are majority variants for consensus calling\n        /usr/local/miniconda/bin/bcftools filter -i '(DP4[0]+DP4[1]) < (DP4[2]+DP4[3]) && ((DP4[2]+DP4[3]) > 0)' --threads !{task.cpus} \\${R1}_pre_bcftools.vcf -o \\${R1}_pre2.vcf\n        /usr/local/miniconda/bin/bcftools filter -e 'IMF < 0.5' \\${R1}_pre2.vcf -o \\${R1}.vcf\n\n        # Index and generate consensus from vcf with majority variants\n        /usr/local/miniconda/bin/bgzip \\${R1}.vcf\n        /usr/local/miniconda/bin/tabix \\${R1}.vcf.gz \n        cat !{REFERENCE_FASTA} | /usr/local/miniconda/bin/bcftools consensus \\${R1}.vcf.gz > \\${R1}.consensus.fa\n\n        # Create coverage file from bam for whole genome, then pipe anything that has less than 6 coverage to bed file,\n        # to be masked later\n        /usr/local/miniconda/bin/bedtools genomecov \\\\\n            -bga \\\\\n            -ibam !{BAMFILE} \\\\\n            -g !{REFERENCE_FASTA} \\\\\n            | awk '\\$4 < 6' | /usr/local/miniconda/bin/bedtools merge > \\${R1}.mask.bed\n        # Get rid of anything outside of the genome we care about, to prevent some sgrnas from screwing with masking\n        awk '{ if(\\$3 > 200 && \\$2 < 29742) {print}}' \\${R1}.mask.bed > a.tmp && mv a.tmp \\${R1}.mask.bed\n\n        # Mask refseq fasta for low coverage areas based on bed file\n        /usr/local/miniconda/bin/bedtools maskfasta \\\\\n            -fi !{REFERENCE_FASTA} \\\\\n            -bed \\${R1}.mask.bed \\\\\n            -fo ref.mask.fasta\n        \n        # Align to Wuhan refseq and unwrap fasta\n        cat ref.mask.fasta \\${R1}.consensus.fa > align_input.fasta\n        /usr/local/miniconda/bin/mafft --auto --thread !{task.cpus} align_input.fasta > repositioned.fasta\n        awk '/^>/ { print (NR==1 ? \"\" : RS) $0; next } { printf \"%s\", $0 } END { printf RS }' repositioned.fasta > repositioned_unwrap.fasta\n        \n        # Trim ends and aligns masking of refseq to our consensus\n        python3 !{TRIM_ENDS} \\${R1}\n\n        # Find percent ns, doesn't work, fix later in python script\n        num_bases=$(grep -v \">\" \\${R1}_swift.fasta | wc | awk '{print $3-$1}')\n        num_ns=$(grep -v \">\" \\${R1}_swift.fasta | awk -F\"n\" '{print NF-1}')\n        percent_n=$(awk -v num_ns=$num_ns -v num_bases=$num_bases 'BEGIN { print ( num_ns * 100 / num_bases ) }')\n        echo \"num_bases=$num_bases\"\n        echo \"num_ns=$num_ns\"\n        echo \"percent_n=$percent_n\"\n        gunzip \\${R1}.vcf.gz\n        mv \\${R1}.vcf \\${R1}_bcftools.vcf\n        #/usr/local/miniconda/bin/samtools view !{BAMFILE} -@ !{task.cpus} | awk -F: '$12 < 600' > \\${R1}'.clipped.cleaned.bam'\n    else\n       echo \"Empty bam detected. Generating empty consensus fasta file...\"\n       # Generate empty stats for empty bam\n       printf '>!{base}\\n' > \\${R1}_swift.fasta\n       printf 'n%.0s' {1..29539} >> \\${R1}_swift.fasta\n       percent_n=100\n       touch \\${R1}_bcftools.vcf\n       touch \\${R1}_pre_bcftools.vcf\n    fi\n    \n    cp \\${R1}_summary3.csv \\${R1}_summary.csv\n    printf \",\\$percent_n\" >> \\${R1}_summary.csv\n\n    cat \\${R1}_summary.csv | tr -d \"[:blank:]\" > a.tmp\n    mv a.tmp \\${R1}_summary.csv\n\n    # Correctly calculates %ns and cleans up the summary file.\n    if [[ !{bamsize} > 92 ]]\n    then\n        python3 !{FIX_COVERAGE} \\${R1}\n        mv \\${R1}_summary_fixed.csv \\${R1}_summary.csv\n    fi\n\n    [ -s \\${R1}_swift.fasta ] || echo \"WARNING: \\${R1} produced blank output. Manual review may be needed.\"\n\n    '''",
        "nb_lignes_script": 102,
        "language_script": "bash",
        "tools": [
            "BCFtools",
            "BEDTools",
            "MAFFT",
            "NextSV",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools",
            "https://bio.tools/bedtools",
            "https://bio.tools/MAFFT",
            "https://bio.tools/nextsv",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "MAFFT",
                "uri": "https://bio.tools/MAFFT",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0492",
                                    "term": "Multiple alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "MAFFT (Multiple Alignment using Fast Fourier Transform) is a high speed multiple sequence alignment program.",
                "homepage": "http://mafft.cbrc.jp/alignment/server/index.html"
            },
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "base",
            "bamsize",
            "BAMFILE",
            "INDEX_FILE",
            "REFERENCE_FASTA",
            "TRIM_ENDS",
            "FIX_COVERAGE",
            "VCFUTILS",
            "REFERENCE_FASTA_FAI",
            "SPLITCHR"
        ],
        "nb_inputs": 10,
        "outputs": [
            "INDEX_FILE",
            "bamsize"
        ],
        "nb_outputs": 2,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "container \"quay.io/greninger-lab/swift-pipeline:latest\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "AnnotateVariants": {
        "name_process": "AnnotateVariants",
        "string_process": "\nprocess AnnotateVariants {\n    errorStrategy 'retry'\n    maxRetries 3\n\n    container \"quay.io/vpeddu/lava_image:latest\"\n\n    input:\n        tuple val(base),val(bamsize),file(\"${base}_pre_bcftools.vcf\")              \n        file MAT_PEPTIDES\n        file MAT_PEPTIDE_ADDITION\n        file RIBOSOMAL_SLIPPAGE\n        file RIBOSOMAL_START\n        file PROTEINS\n        file AT_REFGENE\n        file AT_REFGENE_MRNA\n        file CORRECT_AF_BCFTOOLS\n        \n    output: \n        file(\"${base}_bcftools_variants.csv\")\n        file(\"*\")\n    \n    publishDir params.OUTDIR, mode: 'copy', pattern:'*_bcftools_variants.csv'\n\n    shell:\n    '''\n    #!/bin/bash\n    ls -latr\n    \n    if (( !{bamsize} > 92))\n    then\n        # Fixes ploidy issues.\n        #awk -F $\\'\\t\\' \\'BEGIN {FS=OFS=\"\\t\"}{gsub(\"0/0\",\"0/1\",$10)gsub(\"0/0\",\"1/0\",$11)gsub(\"1/1\",\"0/1\",$10)gsub(\"1/1\",\"1/0\",$11)}1\\' !{base}_lofreq.vcf > !{base}_p.vcf\n        awk -F $\\'\\t\\' \\'BEGIN {FS=OFS=\"\\t\"}{gsub(\"0/0\",\"0/1\",$10)gsub(\"0/0\",\"1/0\",$11)gsub(\"1/1\",\"1/0\",$10)gsub(\"1/1\",\"1/0\",$11)}1\\' !{base}_pre_bcftools.vcf > !{base}_p.vcf\n\n        # Converts VCF to .avinput for Annovar.\n        file=\"!{base}\"\"_p.vcf\"\n        #convert2annovar.pl -withfreq -format vcf4 -includeinfo !{base}_p.vcf > !{base}.avinput \n        convert2annovar.pl -withfreq -format vcf4 -includeinfo !{base}_p.vcf > !{base}.avinput \n        annotate_variation.pl -v -buildver AT -outfile !{base} !{base}.avinput .\n\n        #awk -F\":\" '($26+0)>=1{print}' !{base}.exonic_variant_function > !{base}.txt\n        cp !{base}.exonic_variant_function variants.txt\n        #grep \"SNV\" !{base}.txt > a.tmp\n        #grep \"stop\" !{base}.txt >> a.tmp\n        #mv a.tmp variants.txt\n    \n        awk -v name=!{base} -F'[\\t:,]' '{print name\",\"$6\" \"substr($9,3)\",\"$12\",\"$44+0\",\"substr($9,3)\",\"$6\",\"substr($8,3)\",\"substr($8,3,1)\" to \"substr($8,length($8))\",\"$2\",\"$41}' variants.txt > !{base}.csv\n\n        grep -v \"transcript\" !{base}.csv > a.tmp && mv a.tmp !{base}.csv \n        grep -v \"delins\" !{base}.csv > final.csv\n        # Sorts by beginning of mat peptide\n        sort -k2 -t, -n mat_peptides.txt > a.tmp && mv a.tmp mat_peptides.txt\n        # Adds mature peptide differences from protein start.\n        python3 !{MAT_PEPTIDE_ADDITION}\n        rm mat_peptides.txt\n        python3 !{CORRECT_AF_BCFTOOLS} -name !{base}\n        # Corrects for ribosomal slippage.\n        python3 !{RIBOSOMAL_SLIPPAGE} filtered_variants.csv proteins.csv\n        awk NF final.csv > a.tmp && mv a.tmp final.csv\n        echo \"SAMPLE,gene,AAPOS,AAREF,AASUB,TCOV,VCOV,AAFREQ,NTPOS,snpid,nsp,NSPPOS,NSPREF,NSPSUB\" > !{base}_bcftools_variants.csv\n        #sort -h -k2 -t, visualization.csv >> !{base}_bcftools_variants.csv\n        cat visualization.csv >> !{base}_bcftools_variants.csv\n\n    else \n        echo \"Bam is empty, skipping annotation.\"\n        touch !{base}_bcftools_variants.csv\n    fi\n\n    '''\n}",
        "nb_lignes_process": 69,
        "string_script": "    '''\n    #!/bin/bash\n    ls -latr\n    \n    if (( !{bamsize} > 92))\n    then\n        # Fixes ploidy issues.\n        #awk -F $\\'\\t\\' \\'BEGIN {FS=OFS=\"\\t\"}{gsub(\"0/0\",\"0/1\",$10)gsub(\"0/0\",\"1/0\",$11)gsub(\"1/1\",\"0/1\",$10)gsub(\"1/1\",\"1/0\",$11)}1\\' !{base}_lofreq.vcf > !{base}_p.vcf\n        awk -F $\\'\\t\\' \\'BEGIN {FS=OFS=\"\\t\"}{gsub(\"0/0\",\"0/1\",$10)gsub(\"0/0\",\"1/0\",$11)gsub(\"1/1\",\"1/0\",$10)gsub(\"1/1\",\"1/0\",$11)}1\\' !{base}_pre_bcftools.vcf > !{base}_p.vcf\n\n        # Converts VCF to .avinput for Annovar.\n        file=\"!{base}\"\"_p.vcf\"\n        #convert2annovar.pl -withfreq -format vcf4 -includeinfo !{base}_p.vcf > !{base}.avinput \n        convert2annovar.pl -withfreq -format vcf4 -includeinfo !{base}_p.vcf > !{base}.avinput \n        annotate_variation.pl -v -buildver AT -outfile !{base} !{base}.avinput .\n\n        #awk -F\":\" '($26+0)>=1{print}' !{base}.exonic_variant_function > !{base}.txt\n        cp !{base}.exonic_variant_function variants.txt\n        #grep \"SNV\" !{base}.txt > a.tmp\n        #grep \"stop\" !{base}.txt >> a.tmp\n        #mv a.tmp variants.txt\n    \n        awk -v name=!{base} -F'[\\t:,]' '{print name\",\"$6\" \"substr($9,3)\",\"$12\",\"$44+0\",\"substr($9,3)\",\"$6\",\"substr($8,3)\",\"substr($8,3,1)\" to \"substr($8,length($8))\",\"$2\",\"$41}' variants.txt > !{base}.csv\n\n        grep -v \"transcript\" !{base}.csv > a.tmp && mv a.tmp !{base}.csv \n        grep -v \"delins\" !{base}.csv > final.csv\n        # Sorts by beginning of mat peptide\n        sort -k2 -t, -n mat_peptides.txt > a.tmp && mv a.tmp mat_peptides.txt\n        # Adds mature peptide differences from protein start.\n        python3 !{MAT_PEPTIDE_ADDITION}\n        rm mat_peptides.txt\n        python3 !{CORRECT_AF_BCFTOOLS} -name !{base}\n        # Corrects for ribosomal slippage.\n        python3 !{RIBOSOMAL_SLIPPAGE} filtered_variants.csv proteins.csv\n        awk NF final.csv > a.tmp && mv a.tmp final.csv\n        echo \"SAMPLE,gene,AAPOS,AAREF,AASUB,TCOV,VCOV,AAFREQ,NTPOS,snpid,nsp,NSPPOS,NSPREF,NSPSUB\" > !{base}_bcftools_variants.csv\n        #sort -h -k2 -t, visualization.csv >> !{base}_bcftools_variants.csv\n        cat visualization.csv >> !{base}_bcftools_variants.csv\n\n    else \n        echo \"Bam is empty, skipping annotation.\"\n        touch !{base}_bcftools_variants.csv\n    fi\n\n    '''",
        "nb_lignes_script": 44,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "base",
            "bamsize",
            "MAT_PEPTIDES",
            "MAT_PEPTIDE_ADDITION",
            "RIBOSOMAL_SLIPPAGE",
            "RIBOSOMAL_START",
            "PROTEINS",
            "AT_REFGENE",
            "AT_REFGENE_MRNA",
            "CORRECT_AF_BCFTOOLS"
        ],
        "nb_inputs": 10,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "michellejlin__covid_swift_pipeline",
        "directive": [
            "errorStrategy 'retry'",
            "maxRetries 3",
            "container \"quay.io/vpeddu/lava_image:latest\""
        ],
        "when": "",
        "stub": ""
    }
}