{
    "read_file_content": {
        "name_process": "read_file_content",
        "string_process": "process read_file_content {\n    label 'small'\n    label 'preferLocal'\n    container { params.stitching_container }\n\n    input:\n    val(f)\n\n    output:\n    tuple val(f), stdout\n\n    script:\n    \"\"\"\n    if [[ -e ${f} ]]; then\n        cat ${f}\n    else\n        echo \"null\"\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    if [[ -e ${f} ]]; then\n        cat ${f}\n    else\n        echo \"null\"\n    fi\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "f"
        ],
        "nb_inputs": 1,
        "outputs": [
            "f"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "label 'preferLocal'",
            "container { params.stitching_container }"
        ],
        "when": "",
        "stub": ""
    },
    "write_file_content": {
        "name_process": "write_file_content",
        "string_process": "\nprocess write_file_content {\n    label 'small'\n    label 'preferLocal'\n    container { params.stitching_container }\n\n    input:\n    tuple val(f), val(content)\n\n    output:\n    val(f)\n\n    script:\n                                                                     \n    \"\"\"\n    cat > $f <<EOF\n    ${content}\n    EOF\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    cat > $f <<EOF\n    ${content}\n    EOF\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "NeoFuse"
        ],
        "tools_url": [
            "https://bio.tools/NeoFuse"
        ],
        "tools_dico": [
            {
                "name": "NeoFuse",
                "uri": "https://bio.tools/NeoFuse",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2830",
                            "term": "Immunoproteins and antigens"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Peptide immunogenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Immunogenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Antigenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Predicting fusion neoantigens from RNA sequencing data.\n\nThe Section for Bioinformatrics at the Biocenter of Innsbruck Medical University is commited to the generation, management, integration, and leveraging data from genomics studies.\n\nQuantification of the tumor immune contexture.\n\nZlatko Trajanoski awarded with ERC Advanced Grant.",
                "homepage": "https://icbi.i-med.ac.at/NeoFuse/"
            }
        ],
        "inputs": [
            "f",
            "content"
        ],
        "nb_inputs": 2,
        "outputs": [
            "f"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "label 'preferLocal'",
            "container { params.stitching_container }"
        ],
        "when": "",
        "stub": ""
    },
    "get_flatfield_attributes": {
        "name_process": "get_flatfield_attributes",
        "string_process": "process get_flatfield_attributes {\n    label 'small'\n    label 'preferLocal'\n    container { params.deconvolution_container }\n\n    input:\n    tuple val(input_dir), val(ch)\n\n    output:\n    tuple val(input_dir), val(ch), env(attr_file), stdout\n\n    script:\n    \"\"\"\n    attr_file_list=`ls ${input_dir}/${ch}-*flatfield/attributes.json || true`\n    if [[ -z \\${attr_file_list} ]]; then\n        echo \"null\"\n        attr_file=null\n    else\n        cat \\${attr_file_list}\n        attr_file=\\${attr_file_list}\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    attr_file_list=`ls ${input_dir}/${ch}-*flatfield/attributes.json || true`\n    if [[ -z \\${attr_file_list} ]]; then\n        echo \"null\"\n        attr_file=null\n    else\n        cat \\${attr_file_list}\n        attr_file=\\${attr_file_list}\n    fi\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "label 'preferLocal'",
            "container { params.deconvolution_container }"
        ],
        "when": "",
        "stub": ""
    },
    "deconvolution_job": {
        "name_process": "deconvolution_job",
        "string_process": "\nprocess deconvolution_job {\n    container { params.deconvolution_container }\n    cpus { params.deconv_cpus }\n\n    input:\n    val(ch)\n    val(tile_file)\n    val(data_dir)\n    val(output_dir)\n    val(output_file)\n    val(psf_input)\n    val(flatfield_dir)\n    val(background)\n    val(z_resolution)\n    val(iterations)\n\n    output:\n    tuple val(ch),\n          val(data_dir),\n          val(output_dir),\n          val(tile_file),\n          val(output_file),\n          env(output_deconv_file)\n\n    script:\n    def app_args_list = [\n        tile_file,\n        output_file,\n        psf_input,\n        flatfield_dir,\n        background,\n        z_resolution,\n        params.psf_z_step_um,\n        iterations\n    ]\n    def app_args = app_args_list.join(' ')\n    \"\"\"\n    umask 0002\n    if [[ -e ${tile_file} ]]; then\n        /app/entrypoint.sh ${app_args}\n        output_deconv_file=${output_file}\n    else\n        output_deconv_file=\"null\"\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "    def app_args_list = [\n        tile_file,\n        output_file,\n        psf_input,\n        flatfield_dir,\n        background,\n        z_resolution,\n        params.psf_z_step_um,\n        iterations\n    ]\n    def app_args = app_args_list.join(' ')\n    \"\"\"\n    umask 0002\n    if [[ -e ${tile_file} ]]; then\n        /app/entrypoint.sh ${app_args}\n        output_deconv_file=${output_file}\n    else\n        output_deconv_file=\"null\"\n    fi\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch",
            "tile_file",
            "data_dir",
            "output_dir",
            "output_file",
            "psf_input",
            "flatfield_dir",
            "background",
            "z_resolution",
            "iterations"
        ],
        "nb_inputs": 10,
        "outputs": [
            "output_file"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.deconvolution_container }",
            "cpus { params.deconv_cpus }"
        ],
        "when": "",
        "stub": ""
    },
    "prepare_deconv_dir": {
        "name_process": "prepare_deconv_dir",
        "string_process": "\nprocess prepare_deconv_dir {\n    label 'small'\n    label 'preferLocal'\n    container { params.deconvolution_container }\n\n    input:\n    val(data_dir)\n    val(deconv_dir)\n\n    output:\n    tuple val(data_dir), val(deconv_dir)\n\n    script:\n    \"\"\"\n    umask 0002\n    mkdir -p \"${deconv_dir}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    umask 0002\n    mkdir -p \"${deconv_dir}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "data_dir",
            "deconv_dir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "deconv_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "label 'preferLocal'",
            "container { params.deconvolution_container }"
        ],
        "when": "",
        "stub": ""
    },
    "prepare_stitching_data": {
        "name_process": "prepare_stitching_data",
        "string_process": "process prepare_stitching_data {\n    label 'small'\n    label 'preferLocal'\n    container { params.stitching_container }\n    \n    input:\n    val(input_images_dir)\n    val(stitching_output_dir)\n    val(working_dir)\n\n    output:\n    tuple val(input_images_dir),\n          val(stitching_output_dir),\n          val(stitching_working_dir)\n\n    script:\n    stitching_working_dir = working_dir\n        ? working_dir\n        : \"${stitching_output_dir}/tmp\"\n    \"\"\"\n    umask 0002\n    mkdir -p \"${stitching_output_dir}\"\n    mkdir -p \"${stitching_working_dir}\"\n    cp \"${input_images_dir}/ImageList_images.csv\" \"${stitching_output_dir}\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    stitching_working_dir = working_dir\n        ? working_dir\n        : \"${stitching_output_dir}/tmp\"\n    \"\"\"\n    umask 0002\n    mkdir -p \"${stitching_output_dir}\"\n    mkdir -p \"${stitching_working_dir}\"\n    cp \"${input_images_dir}/ImageList_images.csv\" \"${stitching_output_dir}\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_images_dir",
            "stitching_output_dir",
            "working_dir"
        ],
        "nb_inputs": 3,
        "outputs": [
            "stitching_working_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "label 'preferLocal'",
            "container { params.stitching_container }"
        ],
        "when": "",
        "stub": ""
    },
    "clone_stitched_tiles_from_template": {
        "name_process": "clone_stitched_tiles_from_template",
        "string_process": "\nprocess clone_stitched_tiles_from_template {\n    label 'small'\n    label 'preferLocal'\n    container { params.stitching_container }\n\n    input:\n    tuple val(stitched_tiles_template),\n          val(source_tiles_file),\n          val(target_tiles_file)\n    \n    output:\n    tuple val(stitched_tiles_template),\n          val(source_tiles_file),\n          val(target_tiles_file),\n          env(source_tiles_content),\n          env(target_tiles_content)\n\n    script:\n    \"\"\"\n    cp ${stitched_tiles_template} ${target_tiles_file}\n    source_tiles_content=`cat ${source_tiles_file}`\n    target_tiles_content=`cat ${target_tiles_file}`\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    cp ${stitched_tiles_template} ${target_tiles_file}\n    source_tiles_content=`cat ${source_tiles_file}`\n    target_tiles_content=`cat ${target_tiles_file}`\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "stitched_tiles_template",
            "source_tiles_file",
            "target_tiles_file"
        ],
        "nb_inputs": 3,
        "outputs": [
            "target_tiles_file"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "label 'preferLocal'",
            "container { params.stitching_container }"
        ],
        "when": "",
        "stub": ""
    },
    "clone_with_decon_tiles": {
        "name_process": "clone_with_decon_tiles",
        "string_process": "\nprocess clone_with_decon_tiles {\n    label 'small'\n    label 'preferLocal'\n    container { params.stitching_container }\n\n    input:\n    tuple val(data_dir), val(ch)\n\n    output:\n    tuple val(data_dir),\n          val(ch),\n          env(cloned_deconv_final_file),\n          env(source_tiles_content),\n          env(target_tiles_content)\n\n    script:\n    def deconv_final_file = \"${data_dir}/${ch}-decon-final.json\"\n    def deconv_tiles_file = \"${data_dir}/${ch}-decon.json\"\n    \"\"\"\n    if [[ -f ${deconv_final_file} ]]; then\n        # if deconv file exists do not do anything\n        cloned_deconv_final_file=null\n        source_tiles_content=null\n        target_tiles_content=null\n    else\n        if [[ -f ${deconv_tiles_file} ]]; then\n            cp \"${data_dir}/${ch}-final.json\" \"${deconv_final_file}\" || \\\n            cp \"${data_dir}/${ch}.json\" \"${deconv_final_file}\" || \\\n            true\n            if [[ -f ${deconv_final_file} ]]; then\n                cloned_deconv_final_file=${deconv_final_file}\n                source_tiles_content=`cat ${deconv_tiles_file}`\n                target_tiles_content=`cat ${deconv_final_file}`\n            else\n                echo \"Could not find any source for ${data_dir}/${ch}.json to create to ${deconv_final_file}\"\n                cloned_deconv_final_file=null\n                source_tiles_content=null\n                target_tiles_content=null\n            fi\n        else\n            echo \"Cannot clone final decon file ${deconv_final_file} because ${deconv_tiles_file} cannot be found\"\n            cloned_deconv_final_file=null\n            source_tiles_content=null\n            target_tiles_content=null\n        fi\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "    def deconv_final_file = \"${data_dir}/${ch}-decon-final.json\"\n    def deconv_tiles_file = \"${data_dir}/${ch}-decon.json\"\n    \"\"\"\n    if [[ -f ${deconv_final_file} ]]; then\n        # if deconv file exists do not do anything\n        cloned_deconv_final_file=null\n        source_tiles_content=null\n        target_tiles_content=null\n    else\n        if [[ -f ${deconv_tiles_file} ]]; then\n            cp \"${data_dir}/${ch}-final.json\" \"${deconv_final_file}\" || \\\n            cp \"${data_dir}/${ch}.json\" \"${deconv_final_file}\" || \\\n            true\n            if [[ -f ${deconv_final_file} ]]; then\n                cloned_deconv_final_file=${deconv_final_file}\n                source_tiles_content=`cat ${deconv_tiles_file}`\n                target_tiles_content=`cat ${deconv_final_file}`\n            else\n                echo \"Could not find any source for ${data_dir}/${ch}.json to create to ${deconv_final_file}\"\n                cloned_deconv_final_file=null\n                source_tiles_content=null\n                target_tiles_content=null\n            fi\n        else\n            echo \"Cannot clone final decon file ${deconv_final_file} because ${deconv_tiles_file} cannot be found\"\n            cloned_deconv_final_file=null\n            source_tiles_content=null\n            target_tiles_content=null\n        fi\n    fi\n    \"\"\"",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "data_dir",
            "ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "label 'preferLocal'",
            "container { params.stitching_container }"
        ],
        "when": "",
        "stub": ""
    },
    "compute_unet_scaling": {
        "name_process": "compute_unet_scaling",
        "string_process": "\nprocess compute_unet_scaling {\n    container { params.exm_neuron_segmentation_container }\n    cpus { params.neuron_scaling_cpus }\n    memory { params.neuron_scaling_memory }\n    containerOptions { create_container_options([\n        input_image,\n    ]) }\n\n    input:\n    tuple val(input_image), val(input_dataset),\n          val(start),\n          val(end)\n    val(n_tiles_for_scaling)                                                  \n    val(percent_tiles_for_scaling)                                            \n\n    output:\n    tuple val(input_image), val(input_dataset), env(scaling)\n\n    script:\n    def scaling_partition_size_arg = params.neuron_scaling_partition_size\n        ? \"--partition_size ${params.neuron_scaling_partition_size}\"\n        : ''\n    def scaling_plots_dir_arg = params.neuron_scaling_plots_dir\n        ? \"--scaling_plots_dir ${params.neuron_scaling_plots_dir}\"\n        : ''\n    def scaling_plots_mkdir = params.neuron_scaling_plots_dir\n        ? \"mkdir -p ${params.neuron_scaling_plots_dir}\"\n        : ''\n    def start_arg = start ? \"--start ${start}\" : ''\n    def end_arg = end ? \"--end ${end}\" : ''\n    def n_tiles_arg = (n_tiles_for_scaling as int) > 0\n        ? \"-n ${n_tiles_for_scaling}\"\n        : ''\n    def percent_tiles_arg = (percent_tiles_for_scaling as float) > 0\n        ? \"-p ${percent_tiles_for_scaling}\"\n        : ''\n    \"\"\"\n    ${scaling_plots_mkdir}\n    scaling_log=\\$PWD/scaling.log\n    /entrypoint.sh volumeScalingFactor \\\n        -i ${input_image} \\\n        -d ${input_dataset} \\\n        ${n_tiles_arg} ${percent_tiles_arg} \\\n        ${scaling_partition_size_arg} \\\n        ${scaling_plots_dir_arg} \\\n        ${start_arg} ${end_arg} \\\n        > \\$scaling_log\n    echo \"Extract scaling factor from \\$scaling_log\"\n    scaling=`grep -o \"Calculated a scaling factor of \\\\(.*\\\\) based on\" \\$scaling_log | cut -d ' ' -f6`\n    \"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "    def scaling_partition_size_arg = params.neuron_scaling_partition_size\n        ? \"--partition_size ${params.neuron_scaling_partition_size}\"\n        : ''\n    def scaling_plots_dir_arg = params.neuron_scaling_plots_dir\n        ? \"--scaling_plots_dir ${params.neuron_scaling_plots_dir}\"\n        : ''\n    def scaling_plots_mkdir = params.neuron_scaling_plots_dir\n        ? \"mkdir -p ${params.neuron_scaling_plots_dir}\"\n        : ''\n    def start_arg = start ? \"--start ${start}\" : ''\n    def end_arg = end ? \"--end ${end}\" : ''\n    def n_tiles_arg = (n_tiles_for_scaling as int) > 0\n        ? \"-n ${n_tiles_for_scaling}\"\n        : ''\n    def percent_tiles_arg = (percent_tiles_for_scaling as float) > 0\n        ? \"-p ${percent_tiles_for_scaling}\"\n        : ''\n    \"\"\"\n    ${scaling_plots_mkdir}\n    scaling_log=\\$PWD/scaling.log\n    /entrypoint.sh volumeScalingFactor \\\n        -i ${input_image} \\\n        -d ${input_dataset} \\\n        ${n_tiles_arg} ${percent_tiles_arg} \\\n        ${scaling_partition_size_arg} \\\n        ${scaling_plots_dir_arg} \\\n        ${start_arg} ${end_arg} \\\n        > \\$scaling_log\n    echo \"Extract scaling factor from \\$scaling_log\"\n    scaling=`grep -o \"Calculated a scaling factor of \\\\(.*\\\\) based on\" \\$scaling_log | cut -d ' ' -f6`\n    \"\"\"",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_image",
            "input_dataset",
            "start",
            "end",
            "n_tiles_for_scaling",
            "percent_tiles_for_scaling"
        ],
        "nb_inputs": 6,
        "outputs": [
            "input_dataset"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.exm_neuron_segmentation_container }",
            "cpus { params.neuron_scaling_cpus }",
            "memory { params.neuron_scaling_memory }",
            "containerOptions { create_container_options([ input_image, ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "unet_volume_segmentation": {
        "name_process": "unet_volume_segmentation",
        "string_process": "\nprocess unet_volume_segmentation {\n    container { params.exm_neuron_segmentation_container }\n    cpus { params.neuron_segmentation_cpus }\n    memory { params.neuron_segmentation_memory }\n    accelerator 1\n    label 'withGPU'\n    containerOptions { create_container_options([\n        input_image,\n        output_image,\n        file(params.neuron_model).parent\n    ]) }\n\n    input:\n    tuple val(input_image), val(input_dataset),\n          val(output_image), val(output_dataset),\n          val(vol_size),\n          val(start_subvolume),\n          val(end_subvolume),\n          val(scaling)\n\n    output:\n    tuple val(input_image), val(input_dataset),\n          val(output_image), val(output_dataset),\n          val(vol_size),\n          val(start_subvolume),\n          val(end_subvolume)\n\n    script:\n    def gpu_mem_growth_arg = params.use_gpu_mem_growth ? '--set_gpu_mem_growth' : ''\n    def post_processing_arg = params.with_neuron_post_segmentation ? '--with_post_processing' : ''\n    def scaling_arg = scaling ? \"--scaling ${scaling}\" : ''\n    def binary_mask_arg = params.neuron_mask_as_binary ? '--as_binary_mask' : ''\n    \"\"\"\n    /entrypoint.sh volumeSegmentation \\\n        -i ${input_image} \\\n        -id ${input_dataset} \\\n        -o ${output_image} \\\n        -od ${output_dataset} \\\n        -m ${params.neuron_model} \\\n        --image_shape ${vol_size} \\\n        --start ${start_subvolume} \\\n        --end ${end_subvolume} \\\n        ${scaling_arg} \\\n        ${gpu_mem_growth_arg} \\\n        --unet_batch_size ${params.neuron_seg_unet_batch_sz} \\\n        --model_input_shape ${params.neuron_seg_model_in_dims} \\\n        --model_output_shape ${params.neuron_seg_model_out_dims} \\\n        ${binary_mask_arg} \\\n        ${post_processing_arg} \\\n        --high_threshold ${params.neuron_seg_high_th} \\\n        --low_threshold ${params.neuron_seg_low_th} \\\n        --small_region_probability_threshold ${params.neuron_seg_small_region_prob_th} \\\n        --small_region_size_threshold ${params.neuron_seg_small_region_size_th}\n    \"\"\"\n}",
        "nb_lignes_process": 54,
        "string_script": "    def gpu_mem_growth_arg = params.use_gpu_mem_growth ? '--set_gpu_mem_growth' : ''\n    def post_processing_arg = params.with_neuron_post_segmentation ? '--with_post_processing' : ''\n    def scaling_arg = scaling ? \"--scaling ${scaling}\" : ''\n    def binary_mask_arg = params.neuron_mask_as_binary ? '--as_binary_mask' : ''\n    \"\"\"\n    /entrypoint.sh volumeSegmentation \\\n        -i ${input_image} \\\n        -id ${input_dataset} \\\n        -o ${output_image} \\\n        -od ${output_dataset} \\\n        -m ${params.neuron_model} \\\n        --image_shape ${vol_size} \\\n        --start ${start_subvolume} \\\n        --end ${end_subvolume} \\\n        ${scaling_arg} \\\n        ${gpu_mem_growth_arg} \\\n        --unet_batch_size ${params.neuron_seg_unet_batch_sz} \\\n        --model_input_shape ${params.neuron_seg_model_in_dims} \\\n        --model_output_shape ${params.neuron_seg_model_out_dims} \\\n        ${binary_mask_arg} \\\n        ${post_processing_arg} \\\n        --high_threshold ${params.neuron_seg_high_th} \\\n        --low_threshold ${params.neuron_seg_low_th} \\\n        --small_region_probability_threshold ${params.neuron_seg_small_region_prob_th} \\\n        --small_region_size_threshold ${params.neuron_seg_small_region_size_th}\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_image",
            "input_dataset",
            "output_image",
            "output_dataset",
            "vol_size",
            "start_subvolume",
            "end_subvolume",
            "scaling"
        ],
        "nb_inputs": 8,
        "outputs": [
            "end_subvolume"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.exm_neuron_segmentation_container }",
            "cpus { params.neuron_segmentation_cpus }",
            "memory { params.neuron_segmentation_memory }",
            "accelerator 1",
            "label 'withGPU'",
            "containerOptions { create_container_options([ input_image, output_image, file(params.neuron_model).parent ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "unet_classifier": {
        "name_process": "unet_classifier",
        "string_process": "\nprocess unet_classifier {\n    container { params.exm_synapse_container }\n    cpus { cpus }\n    memory { memory }\n    accelerator 1\n    label 'withGPU'\n    containerOptions { create_container_options([\n        input_image,\n        output_image_arg,\n    ]) }\n\n    input:\n    tuple val(input_image),\n          val(input_dataset),\n          val(output_image_arg),\n          val(output_dataset),\n          val(vol_size),\n          val(start_subvolume),\n          val(end_subvolume)\n    val(synapse_model)\n    val(cpus)\n    val(memory)\n\n    output:\n    tuple val(input_image),\n          val(input_dataset),\n          val(output_image),\n          val(output_dataset),\n          val(vol_size),\n          val(start_subvolume),\n          val(end_subvolume)\n\n    script:\n    output_image = output_image_arg ? output_image_arg : input_image\n    def gpu_mem_growth_arg = params.use_gpu_mem_growth ? '--set_gpu_mem_growth' : ''\n    def input_dataset_arg = input_dataset\n        ? \"--input_data_set ${input_dataset}\"\n        : '' \n    def output_dataset_arg = output_dataset\n        ? \"--output_data_set ${output_dataset}\"\n        : '' \n    \"\"\"\n    python /scripts/unet_gpu.py \\\n        -i ${input_image} ${input_dataset_arg} \\\n        -m ${synapse_model} \\\n        --start ${start_subvolume} \\\n        --end ${end_subvolume} \\\n        ${gpu_mem_growth_arg} \\\n        -o ${output_image} ${output_dataset_arg}\n    \"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "    output_image = output_image_arg ? output_image_arg : input_image\n    def gpu_mem_growth_arg = params.use_gpu_mem_growth ? '--set_gpu_mem_growth' : ''\n    def input_dataset_arg = input_dataset\n        ? \"--input_data_set ${input_dataset}\"\n        : '' \n    def output_dataset_arg = output_dataset\n        ? \"--output_data_set ${output_dataset}\"\n        : '' \n    \"\"\"\n    python /scripts/unet_gpu.py \\\n        -i ${input_image} ${input_dataset_arg} \\\n        -m ${synapse_model} \\\n        --start ${start_subvolume} \\\n        --end ${end_subvolume} \\\n        ${gpu_mem_growth_arg} \\\n        -o ${output_image} ${output_dataset_arg}\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_image",
            "input_dataset",
            "output_image_arg",
            "output_dataset",
            "vol_size",
            "start_subvolume",
            "end_subvolume",
            "synapse_model",
            "cpus",
            "memory"
        ],
        "nb_inputs": 10,
        "outputs": [
            "end_subvolume"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.exm_synapse_container }",
            "cpus { cpus }",
            "memory { memory }",
            "accelerator 1",
            "label 'withGPU'",
            "containerOptions { create_container_options([ input_image, output_image_arg, ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "segmentation_postprocessing": {
        "name_process": "segmentation_postprocessing",
        "string_process": "\nprocess segmentation_postprocessing {\n    container { params.exm_synapse_container }\n    cpus { cpus }\n    memory { memory }\n    containerOptions { create_container_options([\n        input_image,\n        mask_image,\n        output_image_arg,\n    ]) }\n\n    input:\n    tuple val(input_image),\n          val(input_dataset),\n          val(mask_image),\n          val(mask_dataset),\n          val(output_image_arg),\n          val(output_dataset),\n          val(output_csv_dir),\n          val(vol_size),\n          val(start_subvolume),\n          val(end_subvolume)\n    val(threshold)\n    val(percentage)\n    val(cpus)\n    val(memory)\n    val(postprocessing_threads)\n\n    output:\n    tuple val(input_image),\n          val(input_dataset),           \n          val(mask_image),\n          val(mask_dataset),\n          val(output_image),\n          val(output_dataset),\n          val(output_csv_dir),\n          val(vol_size),\n          val(start_subvolume),\n          val(end_subvolume)\n\n    script:\n    output_image = output_image_arg ? output_image_arg : input_image\n    def input_dataset_arg = input_dataset\n        ? \"--input_data_set ${input_dataset}\"\n        : '' \n    def output_dataset_arg = output_dataset\n        ? \"--output_data_set ${output_dataset}\"\n        : '' \n    def mask_dataset_arg = mask_dataset\n        ? \"--mask_data_set ${mask_dataset}\"\n        : '' \n    def mask_arg = mask_image ? \"-m ${mask_image} ${mask_dataset_arg}\" : ''\n    def nthreads_arg = postprocessing_threads > 1\n        ? \"--nthreads ${postprocessing_threads}\"\n        : ''\n    \"\"\"\n    mkdir -p ${output_csv_dir}\n\n    /scripts/postprocess_cpu.sh \\\n        -i ${input_image} ${input_dataset_arg} \\\n        -o ${output_image} ${output_dataset_arg} \\\n        --csv_output_path ${output_csv_dir} \\\n        --start ${start_subvolume} \\\n        --end ${end_subvolume} \\\n        -t ${threshold} \\\n        -p ${percentage} \\\n        ${nthreads_arg} \\\n        ${mask_arg}\n    \"\"\"\n}",
        "nb_lignes_process": 68,
        "string_script": "    output_image = output_image_arg ? output_image_arg : input_image\n    def input_dataset_arg = input_dataset\n        ? \"--input_data_set ${input_dataset}\"\n        : '' \n    def output_dataset_arg = output_dataset\n        ? \"--output_data_set ${output_dataset}\"\n        : '' \n    def mask_dataset_arg = mask_dataset\n        ? \"--mask_data_set ${mask_dataset}\"\n        : '' \n    def mask_arg = mask_image ? \"-m ${mask_image} ${mask_dataset_arg}\" : ''\n    def nthreads_arg = postprocessing_threads > 1\n        ? \"--nthreads ${postprocessing_threads}\"\n        : ''\n    \"\"\"\n    mkdir -p ${output_csv_dir}\n\n    /scripts/postprocess_cpu.sh \\\n        -i ${input_image} ${input_dataset_arg} \\\n        -o ${output_image} ${output_dataset_arg} \\\n        --csv_output_path ${output_csv_dir} \\\n        --start ${start_subvolume} \\\n        --end ${end_subvolume} \\\n        -t ${threshold} \\\n        -p ${percentage} \\\n        ${nthreads_arg} \\\n        ${mask_arg}\n    \"\"\"",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_image",
            "input_dataset",
            "mask_image",
            "mask_dataset",
            "output_image_arg",
            "output_dataset",
            "output_csv_dir",
            "vol_size",
            "start_subvolume",
            "end_subvolume",
            "threshold",
            "percentage",
            "cpus",
            "memory",
            "postprocessing_threads"
        ],
        "nb_inputs": 15,
        "outputs": [
            "input_dataset",
            "end_subvolume"
        ],
        "nb_outputs": 2,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.exm_synapse_container }",
            "cpus { cpus }",
            "memory { memory }",
            "containerOptions { create_container_options([ input_image, mask_image, output_image_arg, ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "aggregate_csvs": {
        "name_process": "aggregate_csvs",
        "string_process": "\nprocess aggregate_csvs {\n    container { params.exm_synapse_container }\n    label 'small'\n    containerOptions { create_container_options([\n        input_csvs_dir\n    ]) }\n\n    input:\n    tuple val(input_csvs_dir), val(output_csv)\n\n    output:\n    tuple val(input_csvs_dir), val(output_csv)\n\n    script:\n    \"\"\"\n    python /scripts/aggregate_csvs.py \\\n        -i ${input_csvs_dir} \\\n        -o ${output_csv}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    python /scripts/aggregate_csvs.py \\\n        -i ${input_csvs_dir} \\\n        -o ${output_csv}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_csvs_dir",
            "output_csv"
        ],
        "nb_inputs": 2,
        "outputs": [
            "output_csv"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.exm_synapse_container }",
            "label 'small'",
            "containerOptions { create_container_options([ input_csvs_dir ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "prepare_mask_dirs": {
        "name_process": "prepare_mask_dirs",
        "string_process": "\nprocess prepare_mask_dirs {\n    label 'preferLocal'\n\n    input:\n    tuple val(input_dir), val(shared_temp_dir), val(output_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    script:\n    threshold_dir = \"${shared_temp_dir}/threshold\"\n    connect_dir = \"${shared_temp_dir}/connect\"\n    \"\"\"\n    umask 0002\n    rm -rf \"${shared_temp_dir}/*\"\n    mkdir -p \"${shared_temp_dir}\"\n    mkdir -p \"${output_dir}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    threshold_dir = \"${shared_temp_dir}/threshold\"\n    connect_dir = \"${shared_temp_dir}/connect\"\n    \"\"\"\n    umask 0002\n    rm -rf \"${shared_temp_dir}/*\"\n    mkdir -p \"${shared_temp_dir}\"\n    mkdir -p \"${output_dir}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "shared_temp_dir",
            "output_dir"
        ],
        "nb_inputs": 3,
        "outputs": [
            "connect_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'preferLocal'"
        ],
        "when": "",
        "stub": ""
    },
    "threshold_mask": {
        "name_process": "threshold_mask",
        "string_process": "\nprocess threshold_mask {\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ input_dir, file(threshold_dir).parent ]) }\n\n    cpus { params.threshold_cpus }\n    memory { \"${params.threshold_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    script:\n    if (params.threshold) \n    \"\"\"\n    mkdir -p \"${threshold_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro thresholding_multithread.ijm \"${params.threshold_cpus},${input_dir}/,${threshold_dir}/,${params.threshold}\"\n    \"\"\"\n    else\n    \"\"\"\n    mkdir -p \"${threshold_dir}\"\n    cp \"${input_dir}\"/*.tif \"${threshold_dir}\"\n    \"\"\" \n}",
        "nb_lignes_process": 25,
        "string_script": "    if (params.threshold) \n    \"\"\"\n    mkdir -p \"${threshold_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro thresholding_multithread.ijm \"${params.threshold_cpus},${input_dir}/,${threshold_dir}/,${params.threshold}\"\n    \"\"\"\n    else\n    \"\"\"\n    mkdir -p \"${threshold_dir}\"\n    cp \"${input_dir}\"/*.tif \"${threshold_dir}\"\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir",
            "shared_temp_dir",
            "threshold_dir",
            "connect_dir"
        ],
        "nb_inputs": 5,
        "outputs": [
            "connect_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ input_dir, file(threshold_dir).parent ]) }",
            "cpus { params.threshold_cpus }",
            "memory { \"${params.threshold_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "convert_from_mask": {
        "name_process": "convert_from_mask",
        "string_process": "\nprocess convert_from_mask {\n    label 'withAVX2'\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ input_dir, threshold_dir, file(connect_dir).parent ]) }\n\n    cpus { params.convert_mask_cpus }\n    memory { \"${params.convert_mask_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    script:\n    \"\"\"\n    mkdir -p \"${connect_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro ExpandMask_ExM.ijm \"${threshold_dir}/,${connect_dir}/,${params.convert_mask_cpus}\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    mkdir -p \"${connect_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro ExpandMask_ExM.ijm \"${threshold_dir}/,${connect_dir}/,${params.convert_mask_cpus}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir",
            "shared_temp_dir",
            "threshold_dir",
            "connect_dir"
        ],
        "nb_inputs": 5,
        "outputs": [
            "connect_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'withAVX2'",
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ input_dir, threshold_dir, file(connect_dir).parent ]) }",
            "cpus { params.convert_mask_cpus }",
            "memory { \"${params.convert_mask_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "get_brick_files": {
        "name_process": "get_brick_files",
        "string_process": "\nprocess get_brick_files {\n    label 'preferLocal'\n\n    input:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir), env(BRICKS)\n\n    script:\n    \"\"\"\n    BRICKS=`ls -d ${connect_dir}/**/*.zip`\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    BRICKS=`ls -d ${connect_dir}/**/*.zip`\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir",
            "shared_temp_dir",
            "threshold_dir",
            "connect_dir"
        ],
        "nb_inputs": 5,
        "outputs": [
            "connect_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'preferLocal'"
        ],
        "when": "",
        "stub": ""
    },
    "connect_tiff": {
        "name_process": "connect_tiff",
        "string_process": "\nprocess connect_tiff {\n    label 'withGPU'\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ connect_dir, \"/etc/OpenCL\" ]) }\n\n    cpus { params.connect_mask_cpus }\n    memory { \"${params.connect_mask_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir), val(brick)\n\n    output:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir), val(brick)\n\n    script:\n    \"\"\"\n    export CL_LOG_ERRORS=stdout\n    /app/fiji/entrypoint.sh --headless -macro Mask_connectionGPU.ijm \"${brick},${params.mask_connection_distance},${params.mask_connection_iterations}\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    export CL_LOG_ERRORS=stdout\n    /app/fiji/entrypoint.sh --headless -macro Mask_connectionGPU.ijm \"${brick},${params.mask_connection_distance},${params.mask_connection_iterations}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir",
            "shared_temp_dir",
            "threshold_dir",
            "connect_dir",
            "brick"
        ],
        "nb_inputs": 6,
        "outputs": [
            "brick"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'withGPU'",
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ connect_dir, \"/etc/OpenCL\" ]) }",
            "cpus { params.connect_mask_cpus }",
            "memory { \"${params.connect_mask_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "convert_to_mask": {
        "name_process": "convert_to_mask",
        "string_process": "\nprocess convert_to_mask {\n    label 'withAVX2'\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ threshold_dir, connect_dir ]) }\n\n    cpus { params.convert_mask_cpus }\n    memory { \"${params.convert_mask_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    script:\n    \"\"\"\n    /app/fiji/entrypoint.sh --headless -macro ExpandMask_ExM.ijm \"${threshold_dir}/,${connect_dir}/,${params.convert_mask_cpus}\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    /app/fiji/entrypoint.sh --headless -macro ExpandMask_ExM.ijm \"${threshold_dir}/,${connect_dir}/,${params.convert_mask_cpus}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir",
            "shared_temp_dir",
            "threshold_dir",
            "connect_dir"
        ],
        "nb_inputs": 5,
        "outputs": [
            "connect_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'withAVX2'",
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ threshold_dir, connect_dir ]) }",
            "cpus { params.convert_mask_cpus }",
            "memory { \"${params.convert_mask_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "complete_mask": {
        "name_process": "complete_mask",
        "string_process": "\nprocess complete_mask {\n    label 'preferLocal'\n\n    input:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir), val(shared_temp_dir), val(threshold_dir), val(connect_dir)\n\n    script:\n    \"\"\"\n    cp ${connect_dir}/*.tif ${output_dir}/\n    if [[ \"${params.clean_temp_dirs}\" == \"true\" ]]; then\n        rm -rf ${params.shared_temp_dir}\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    cp ${connect_dir}/*.tif ${output_dir}/\n    if [[ \"${params.clean_temp_dirs}\" == \"true\" ]]; then\n        rm -rf ${params.shared_temp_dir}\n    fi\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir",
            "shared_temp_dir",
            "threshold_dir",
            "connect_dir"
        ],
        "nb_inputs": 5,
        "outputs": [
            "connect_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'preferLocal'"
        ],
        "when": "",
        "stub": ""
    },
    "crosstalk_subtraction": {
        "name_process": "crosstalk_subtraction",
        "string_process": "\nprocess crosstalk_subtraction {\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ input_dir, file(output_dir).parent ]) }\n\n    cpus { params.crosstalk_subtraction_cpus }\n    memory { \"${params.crosstalk_subtraction_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir)\n\n    script:\n    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro subtracting_multithread.ijm \"${params.crosstalk_subtraction_cpus},${input_dir}/,${output_dir}/,${params.crosstalk_threshold}\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro subtracting_multithread.ijm \"${params.crosstalk_subtraction_cpus},${input_dir}/,${output_dir}/,${params.crosstalk_threshold}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "output_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ input_dir, file(output_dir).parent ]) }",
            "cpus { params.crosstalk_subtraction_cpus }",
            "memory { \"${params.crosstalk_subtraction_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "crop_tiff": {
        "name_process": "crop_tiff",
        "string_process": "\nprocess crop_tiff {\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ input_dir, file(output_dir).parent, roi_path ]) }\n\n    cpus { params.crop_cpus }\n    memory { \"${params.crop_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir), val(roi_path)\n\n    output:\n    tuple val(input_dir), val(output_dir)\n\n    script:\n    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro ROI_Crop_multithread.ijm \"${params.crop_format},${params.crop_cpus},${params.crop_start_slice},${params.crop_end_slice},${input_dir}/,${output_dir}/,${roi_path}/\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro ROI_Crop_multithread.ijm \"${params.crop_format},${params.crop_cpus},${params.crop_start_slice},${params.crop_end_slice},${input_dir}/,${output_dir}/,${roi_path}/\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir",
            "roi_path"
        ],
        "nb_inputs": 3,
        "outputs": [
            "output_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ input_dir, file(output_dir).parent, roi_path ]) }",
            "cpus { params.crop_cpus }",
            "memory { \"${params.crop_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "threshold_tiff": {
        "name_process": "threshold_tiff",
        "string_process": "\nprocess threshold_tiff {\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ input_dir, file(output_dir).parent ]) }\n\n    cpus { params.threshold_cpus }\n    memory { \"${params.threshold_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir)\n\n    script:\n    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro thresholding_multithread.ijm \"${params.threshold_cpus},${input_dir}/,${output_dir}/,${params.threshold}\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro thresholding_multithread.ijm \"${params.threshold_cpus},${input_dir}/,${output_dir}/,${params.threshold}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "output_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ input_dir, file(output_dir).parent ]) }",
            "cpus { params.threshold_cpus }",
            "memory { \"${params.threshold_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "tiff_to_mips": {
        "name_process": "tiff_to_mips",
        "string_process": "\nprocess tiff_to_mips {\n\n    container { params.fiji_macro_container }\n    containerOptions { create_container_options([ input_dir, file(output_dir).parent ]) }\n\n    cpus { params.create_mip_cpus }\n    memory { \"${params.create_mip_mem_gb} GB\" }\n\n    input:\n    tuple val(input_dir), val(output_dir)\n\n    output:\n    tuple val(input_dir), val(output_dir)\n\n    script:\n    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro MIPmultithread.ijm \"${params.create_mip_cpus},${input_dir}/,${output_dir}/\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir -p \"${output_dir}\"\n    /app/fiji/entrypoint.sh --headless -macro MIPmultithread.ijm \"${params.create_mip_cpus},${input_dir}/,${output_dir}/\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "output_dir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "output_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.fiji_macro_container }",
            "containerOptions { create_container_options([ input_dir, file(output_dir).parent ]) }",
            "cpus { params.create_mip_cpus }",
            "memory { \"${params.create_mip_mem_gb} GB\" }"
        ],
        "when": "",
        "stub": ""
    },
    "create_n5_volume": {
        "name_process": "create_n5_volume",
        "string_process": "\nprocess create_n5_volume {\n    label 'small'\n\n    container { params.exm_synapse_dask_container }\n    containerOptions { create_container_options([\n        file(template_image).parent,\n    ]) }\n\n    input:\n    tuple val(template_image),\n          val(template_dataset),\n          val(output_image),\n          val(target_dataset),\n          val(data_type)\n\n    output:\n    tuple val(template_image),\n          val(template_dataset),\n          val(output_image),\n          val(target_dataset)\n\n    script:\n    def output_image_dir = file(output_image).parent\n    def template_dataset_arg = template_dataset ? \"--template_data_set ${template_dataset}\" : ''\n    def target_dataset_arg = target_dataset ? \"--target_data_set ${target_dataset}\" : ''\n    def data_type_arg = data_type ? \"--dtype ${data_type}\" : ''\n    \"\"\"\n    mkdir -p ${output_image_dir}\n    /entrypoint.sh create_n5 \\\n        -o ${output_image} \\\n        -t ${template_image} \\\n        ${template_dataset_arg} ${target_dataset_arg} \\\n        --compression ${params.n5_compression} \\\n        ${data_type_arg}\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    def output_image_dir = file(output_image).parent\n    def template_dataset_arg = template_dataset ? \"--template_data_set ${template_dataset}\" : ''\n    def target_dataset_arg = target_dataset ? \"--target_data_set ${target_dataset}\" : ''\n    def data_type_arg = data_type ? \"--dtype ${data_type}\" : ''\n    \"\"\"\n    mkdir -p ${output_image_dir}\n    /entrypoint.sh create_n5 \\\n        -o ${output_image} \\\n        -t ${template_image} \\\n        ${template_dataset_arg} ${target_dataset_arg} \\\n        --compression ${params.n5_compression} \\\n        ${data_type_arg}\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "template_image",
            "template_dataset",
            "output_image",
            "target_dataset",
            "data_type"
        ],
        "nb_inputs": 5,
        "outputs": [
            "target_dataset"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "container { params.exm_synapse_dask_container }",
            "containerOptions { create_container_options([ file(template_image).parent, ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "read_n5_metadata": {
        "name_process": "read_n5_metadata",
        "string_process": "\nprocess read_n5_metadata {\n    label 'small'\n\n    container { params.exm_synapse_dask_container }\n    containerOptions { create_container_options([\n        n5_stack,\n    ]) }\n\n    input:\n    val(n5_stack)\n\n    output:\n    tuple val(n5_stack), env(n5_attributes)\n\n    script:\n    def n5_attributes_file = \"${n5_stack}/attributes.json\"\n    \"\"\"\n    n5_attributes=`cat ${n5_attributes_file} || true`\n    if [[ -z \\${n5_attributes} ]]; then\n        n5_attributes=null\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    def n5_attributes_file = \"${n5_stack}/attributes.json\"\n    \"\"\"\n    n5_attributes=`cat ${n5_attributes_file} || true`\n    if [[ -z \\${n5_attributes} ]]; then\n        n5_attributes=null\n    fi\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "n5_stack"
        ],
        "nb_inputs": 1,
        "outputs": [
            "n5_stack"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "label 'small'",
            "container { params.exm_synapse_dask_container }",
            "containerOptions { create_container_options([ n5_stack, ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "tiff_to_n5": {
        "name_process": "tiff_to_n5",
        "string_process": "\nprocess tiff_to_n5 {\n    container { params.exm_synapse_dask_container }\n    cpus { params.tiff2n5_cpus }\n    memory { params.tiff2n5_memory }\n    containerOptions { create_container_options([\n        file(input_dir).parent,\n    ]) }\n\n    input:\n    tuple val(input_dir), val(input_dataset),\n          val(output_dir), val(output_dataset)\n    val(partial_volume)\n\n    output:\n    tuple env(n5_stack),\n          val(input_dir), val(input_dataset),\n          env(output_n5_dir), env(output_n5_dataset)                 \n\n    script:\n    def input_stack_dir = file(\"${input_dir}/${input_dataset}\")\n    def input_fname_pattern_arg = params.input_imgname_pattern\n        ? \"--input_name_pattern \\\"${params.input_imgname_pattern}\\\"\"\n        : ''\n    def output_dir_as_file = file(\"${output_dir}\")\n    def output_stack_dir = file(\"${output_dir}/${}\")\n    def chunk_size = params.block_size\n    def distributed_args = ''\n    if (params.tiff2n5_workers > 1) {\n        distributed_args = \"--distributed --workers ${params.tiff2n5_workers}\"\n    }\n    def subvol_arg = ''\n    if (partial_volume) {\n        subvol_arg = \"--subvol \\\"${partial_volume}\\\"\"\n    }\n    def n5_dataset = output_dataset\n        ? \"${output_dataset}\"\n        : \"${params.default_n5_dataset}\"               \n    \"\"\"\n    mkdir -p ${output_dir_as_file.parent}\n    if [[ -f \"${input_stack_dir}/attributes.json\" ]]; then\n        # there was no conversion\n        echo \"No tiff to N5 conversion was necessary for ${input_stack_dir}\"\n        n5_stack=${input_stack_dir}\n        output_n5_dir=${input_dir}\n        output_n5_dataset=${input_dataset}\n    else\n        # convert tiffs to n5\n        echo \"Convert ${input_stack_dir} ${params.input_imgname_pattern} -> ${output_dir_as_file}:${n5_dataset}\"\n        /entrypoint.sh tif_to_n5 \\\n        -i ${input_stack_dir} ${input_fname_pattern_arg} \\\n        -o ${output_dir} -d ${n5_dataset} \\\n        -c \"${chunk_size}\" \\\n        ${distributed_args} \\\n        ${subvol_arg} \\\n        --compression ${params.n5_compression}\n        # set the return value\n        n5_stack=\"${output_dir_as_file}/${n5_dataset}\"\n        output_n5_dir=${output_dir_as_file}\n        output_n5_dataset=${n5_dataset}\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 61,
        "string_script": "    def input_stack_dir = file(\"${input_dir}/${input_dataset}\")\n    def input_fname_pattern_arg = params.input_imgname_pattern\n        ? \"--input_name_pattern \\\"${params.input_imgname_pattern}\\\"\"\n        : ''\n    def output_dir_as_file = file(\"${output_dir}\")\n    def output_stack_dir = file(\"${output_dir}/${}\")\n    def chunk_size = params.block_size\n    def distributed_args = ''\n    if (params.tiff2n5_workers > 1) {\n        distributed_args = \"--distributed --workers ${params.tiff2n5_workers}\"\n    }\n    def subvol_arg = ''\n    if (partial_volume) {\n        subvol_arg = \"--subvol \\\"${partial_volume}\\\"\"\n    }\n    def n5_dataset = output_dataset\n        ? \"${output_dataset}\"\n        : \"${params.default_n5_dataset}\"               \n    \"\"\"\n    mkdir -p ${output_dir_as_file.parent}\n    if [[ -f \"${input_stack_dir}/attributes.json\" ]]; then\n        # there was no conversion\n        echo \"No tiff to N5 conversion was necessary for ${input_stack_dir}\"\n        n5_stack=${input_stack_dir}\n        output_n5_dir=${input_dir}\n        output_n5_dataset=${input_dataset}\n    else\n        # convert tiffs to n5\n        echo \"Convert ${input_stack_dir} ${params.input_imgname_pattern} -> ${output_dir_as_file}:${n5_dataset}\"\n        /entrypoint.sh tif_to_n5 \\\n        -i ${input_stack_dir} ${input_fname_pattern_arg} \\\n        -o ${output_dir} -d ${n5_dataset} \\\n        -c \"${chunk_size}\" \\\n        ${distributed_args} \\\n        ${subvol_arg} \\\n        --compression ${params.n5_compression}\n        # set the return value\n        n5_stack=\"${output_dir_as_file}/${n5_dataset}\"\n        output_n5_dir=${output_dir_as_file}\n        output_n5_dataset=${n5_dataset}\n    fi\n    \"\"\"",
        "nb_lignes_script": 41,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_dir",
            "input_dataset",
            "output_dir",
            "output_dataset",
            "partial_volume"
        ],
        "nb_inputs": 5,
        "outputs": [
            "input_dataset"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.exm_synapse_dask_container }",
            "cpus { params.tiff2n5_cpus }",
            "memory { params.tiff2n5_memory }",
            "containerOptions { create_container_options([ file(input_dir).parent, ]) }"
        ],
        "when": "",
        "stub": ""
    },
    "n5_to_tiff": {
        "name_process": "n5_to_tiff",
        "string_process": "\nprocess n5_to_tiff {\n    container { params.exm_synapse_dask_container }\n    cpus { params.n52tiff_cpus }\n    memory { params.n52tiff_memory }\n    containerOptions { create_container_options([\n        input_n5,\n    ]) }\n\n    input:\n    tuple val(input_n5), val(input_dataset), val(output_dir)\n\n    output:\n    tuple val(input_n5), val(input_dataset), val(output_dir)\n\n    script:\n    \"\"\"\n    mkdir -p ${output_dir}\n    /entrypoint.sh n5_to_tif \\\n        -i ${input_n5} \\\n        -d ${input_dataset} \\\n        -o ${output_dir}\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    mkdir -p ${output_dir}\n    /entrypoint.sh n5_to_tif \\\n        -i ${input_n5} \\\n        -d ${input_dataset} \\\n        -o ${output_dir}\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_n5",
            "input_dataset",
            "output_dir"
        ],
        "nb_inputs": 3,
        "outputs": [
            "output_dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "JaneliaSciComp__exllsm-circuit-reconstruction",
        "directive": [
            "container { params.exm_synapse_dask_container }",
            "cpus { params.n52tiff_cpus }",
            "memory { params.n52tiff_memory }",
            "containerOptions { create_container_options([ input_n5, ]) }"
        ],
        "when": "",
        "stub": ""
    }
}