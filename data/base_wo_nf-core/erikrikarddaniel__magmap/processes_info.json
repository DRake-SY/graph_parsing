{
    "TAXONOMY_GENOME_QUALITY": {
        "name_process": "TAXONOMY_GENOME_QUALITY",
        "string_process": "\nprocess TAXONOMY_GENOME_QUALITY {\n    label 'process_m'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    }\n\n    input:\n    path checkm_tsv\n    path gtdbtk_tsv\n    path genes\n\n    output:\n    path \"genomes.tsv\" , emit: genomes\n    path \"versions.yml\", emit: versions\n\n    script:\n    \n    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(readr)\n    library(dplyr)\n    library(tidyr)\n    library(stringr)\n\n    setDTthreads($task.cpus)\n\n    # Read the featureCounts files and subset to a set of unique ids\n    genomes <- fread(cmd = \"gunzip -c ${genes}\") %>% lazy_dt() %>%\n        distinct(genome) %>%\n        as_tibble()\n\n    # CheckM results\n    checkm <- fread(\"${checkm_tsv}\", sep = \"\\\\t\", colClasses = list(character = 1:29)) %>%\n        as_tibble()\n\n    # GTDB-Tk results\n    gtdbtk <- fread(\"${gtdbtk_tsv}\", sep = \"\\\\t\", colClasses = list(character = 1:20)) %>%\n        as_tibble()\n\n    checkm %>%\n        transmute(\n            genome = `Bin Id`, completeness = as.numeric(Completeness), \n            contamination = as.numeric(Contamination), \n            strain_heterogeneity = as.numeric(`Strain heterogeneity`)\n        ) %>%\n        full_join(\n            gtdbtk %>%\n            transmute(genome = user_genome, classification) %>%\n            mutate(classification = str_remove_all(classification, '[a-z]__')) %>%\n            separate(classification, c('domain', 'phylum', 'class', 'order', 'family', 'genus', 'species'), sep = ';'),\n            by = 'genome'\n        ) %>%\n        semi_join(genomes, by = 'genome') %>%\n        write_tsv(\"genomes.tsv\")\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    tidyr: %s\\n    data.table: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('tidyr'),\n            packageVersion('data.table')\n        ),\n        'versions.yml'\n    )\n    \"\"\"\n}",
        "nb_lignes_process": 77,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(readr)\n    library(dplyr)\n    library(tidyr)\n    library(stringr)\n\n    setDTthreads($task.cpus)\n\n    # Read the featureCounts files and subset to a set of unique ids\n    genomes <- fread(cmd = \"gunzip -c ${genes}\") %>% lazy_dt() %>%\n        distinct(genome) %>%\n        as_tibble()\n\n    # CheckM results\n    checkm <- fread(\"${checkm_tsv}\", sep = \"\\\\t\", colClasses = list(character = 1:29)) %>%\n        as_tibble()\n\n    # GTDB-Tk results\n    gtdbtk <- fread(\"${gtdbtk_tsv}\", sep = \"\\\\t\", colClasses = list(character = 1:20)) %>%\n        as_tibble()\n\n    checkm %>%\n        transmute(\n            genome = `Bin Id`, completeness = as.numeric(Completeness), \n            contamination = as.numeric(Contamination), \n            strain_heterogeneity = as.numeric(`Strain heterogeneity`)\n        ) %>%\n        full_join(\n            gtdbtk %>%\n            transmute(genome = user_genome, classification) %>%\n            mutate(classification = str_remove_all(classification, '[a-z]__')) %>%\n            separate(classification, c('domain', 'phylum', 'class', 'order', 'family', 'genus', 'species'), sep = ';'),\n            by = 'genome'\n        ) %>%\n        semi_join(genomes, by = 'genome') %>%\n        write_tsv(\"genomes.tsv\")\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    tidyr: %s\\n    data.table: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('tidyr'),\n            packageVersion('data.table')\n        ),\n        'versions.yml'\n    )\n    \"\"\"",
        "nb_lignes_script": 52,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "checkm_tsv",
            "gtdbtk_tsv",
            "genes"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "label 'process_m'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" } else { container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "BBMAP_ALIGN": {
        "name_process": "BBMAP_ALIGN",
        "string_process": "\nprocess BBMAP_ALIGN {\n    tag \"$meta.id\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"bioconda::bbmap=38.92 bioconda::samtools=1.13 pigz=2.6\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-008daec56b7aaf3f162d7866758142b9f889d690:f5f55fc5623bb7b3f725e8d2f86bedacfd879510-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-008daec56b7aaf3f162d7866758142b9f889d690:f5f55fc5623bb7b3f725e8d2f86bedacfd879510-0\"\n    }\n\n    input:\n    tuple val(meta), path(fastq)\n    path ref\n\n    output:\n    tuple val(meta), path(\"*.bam\"), emit: bam\n    path \"versions.yml\"           , emit: versions\n\n    script:\n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n\n    input = meta.single_end ? \"in=${fastq}\" : \"in=${fastq[0]} in2=${fastq[1]}\"\n\n                                                                                               \n                                                                                                \n                           \n    if ( ref.isDirectory() ) {\n        if ( ref ==~ /(.\\/)?ref\\/?/ ) {\n            db = ''\n        } else {\n            db = \"path=${ref}\"\n        }\n    } else {\n        db = \"ref=${ref}\"\n    }\n\n    \"\"\"\n    bbmap.sh \\\\\n        $db \\\\\n        $input \\\\\n        out=${prefix}.bam \\\\\n        $options.args \\\\\n        threads=$task.cpus \\\\\n        -Xmx${task.memory.toGiga()}g\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(bbversion.sh)\n        samtools: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n        pigz: \\$( pigz --version 2>&1 | sed 's/pigz //g' )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 56,
        "string_script": "    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n\n    input = meta.single_end ? \"in=${fastq}\" : \"in=${fastq[0]} in2=${fastq[1]}\"\n\n                                                                                               \n                                                                                                \n                           \n    if ( ref.isDirectory() ) {\n        if ( ref ==~ /(.\\/)?ref\\/?/ ) {\n            db = ''\n        } else {\n            db = \"path=${ref}\"\n        }\n    } else {\n        db = \"ref=${ref}\"\n    }\n\n    \"\"\"\n    bbmap.sh \\\\\n        $db \\\\\n        $input \\\\\n        out=${prefix}.bam \\\\\n        $options.args \\\\\n        threads=$task.cpus \\\\\n        -Xmx${task.memory.toGiga()}g\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(bbversion.sh)\n        samtools: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n        pigz: \\$( pigz --version 2>&1 | sed 's/pigz //g' )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "wossinput",
            "ODB"
        ],
        "tools_url": [
            "https://bio.tools/wossinput",
            "https://bio.tools/odb"
        ],
        "tools_dico": [
            {
                "name": "wossinput",
                "uri": "https://bio.tools/wossinput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM input data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossinput.html"
            },
            {
                "name": "ODB",
                "uri": "https://bio.tools/odb",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0114",
                            "term": "Gene structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0114",
                            "term": "Gene features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0435",
                                    "term": "Operon prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0579",
                                    "term": "Operon drawing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0308",
                                    "term": "PCR primer design"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Over-representation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0579",
                                    "term": "Operon rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0308",
                                    "term": "PCR primer prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0308",
                                    "term": "Primer design"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Contains all known and conserved operons in completely sequenced genomes.",
                "homepage": "http://operondb.jp/"
            }
        ],
        "inputs": [
            "meta",
            "fastq",
            "ref"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"bioconda::bbmap=38.92 bioconda::samtools=1.13 pigz=2.6\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-008daec56b7aaf3f162d7866758142b9f889d690:f5f55fc5623bb7b3f725e8d2f86bedacfd879510-0\" } else { container \"quay.io/biocontainers/mulled-v2-008daec56b7aaf3f162d7866758142b9f889d690:f5f55fc5623bb7b3f725e8d2f86bedacfd879510-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "TEST": {
        "name_process": "TEST",
        "string_process": "\nprocess TEST {\n    input:\n    tuple val(meta), path(file)\n    val type\n\n    output:\n    path \"${file}.out\", emit: fsize\n\n    script:\n    \"\"\"\n    echo \"$meta.id, $type\" > ${file}.out\n    ls -lL $file >> ${file}.out\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    echo \"$meta.id, $type\" > ${file}.out\n    ls -lL $file >> ${file}.out\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "type"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "COLLECT_STATS": {
        "name_process": "COLLECT_STATS",
        "string_process": "\nprocess COLLECT_STATS {\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    }\n\n    input:\n    val  samples\n    path trimlogs\n    path idxstats\n    path fcs\n    path bbduks\n\n    output:\n    path \"overall_stats.tsv\"     , emit: overall_stats\n    path \"versions.yml\"          , emit: versions\n\n    script:\n    \n    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(dplyr)\n    library(readr)\n    library(purrr)\n    library(tidyr)\n    library(stringr)\n\n    TYPE_ORDER = c('n_pairs_trimmed', 'n_pairs_non_contaminated', 'n_pairs_mapped', 'n_pairs_unmapped', 'n_pairs_features', 'n_pairs_cds')\n\n    # Collect stats for each sample, create a table in long format that can be appended to\n    t <- tibble(sample = c(\"${samples.join('\", \"')}\")) %>%\n        mutate(\n            # N. after trimming\n            t = map(\n                sample, \n                function(s) {\n                    fread(\n                        cmd = sprintf(\"grep 'Reads written (passing filters)' %s*trimming_report.txt | sed 's/.*: *//' | sed 's/ .*//' | sed 's/,//g'\", s), \n                        sep = ',',\n                        col.names = c('n_pairs_trimmed')\n                    )\n                }\n            ),\n            i = map(\n                sample,\n                function(s) {\n                    fread(cmd = sprintf(\"grep -v '^*' %s*idxstats\", s), sep = '\\\\t', col.names = c('chr', 'length', 'n_pairs_mapped', 'n_pairs_unmapped')) %>%\n                        lazy_dt() %>%\n                        summarise(n_pairs_mapped = sum(n_pairs_mapped)/2, n_pairs_unmapped = sum(n_pairs_unmapped)/2) %>%\n                        as_tibble()\n                }\n            )\n        ) %>%\n        unnest(c(t, i)) %>%\n        pivot_longer(2:ncol(.), names_to = 'm', values_to = 'v') %>%\n        union(\n            # Total observation after featureCounts\n            tibble(file = Sys.glob('counts*.tsv.gz')) %>%\n                mutate(d = map(file, function(f) fread(cmd = sprintf(\"gunzip -c %s\", f), sep = '\\\\t'))) %>%\n                as_tibble() %>%\n                unnest(d) %>%\n                group_by(sample) %>% summarise(n_pairs_features = sum(count), .groups = 'drop') %>%\n                pivot_longer(2:ncol(.), names_to = 'm', values_to = 'v')\n        ) %>%\n        union(\n            # Total observation after featureCounts\n            fread(cmd = \"gunzip -c counts.CDS.tsv.gz\", sep = '\\\\t') %>%\n                as_tibble() %>%\n                group_by(sample) %>% summarise(n_pairs_cds = sum(count), .groups = 'drop') %>%\n                pivot_longer(2:ncol(.), names_to = 'm', values_to = 'v')\n        )\n\n    # Add in stats from BBDuk, if present\n    for ( f in Sys.glob('*.bbduk.log') ) {\n        s = str_remove(f, '.bbduk.log')\n        t <- t %>% union(\n            fread(cmd = sprintf(\"grep 'Result:' %s | sed 's/Result:[ \\\\t]*//; s/ reads.*//'\", f), col.names = c('v')) %>%\n                as_tibble() %>%\n                mutate(sample = s, m = 'n_pairs_non_contaminated', v = v/2)\n        )\n    }\n\n    # Write the table in wide format\n    t %>% \n        mutate(m = parse_factor(m, levels = TYPE_ORDER, ordered = TRUE)) %>%\n        arrange(sample, m) %>%\n        pivot_wider(names_from = m, values_from = v) %>%\n        write_tsv('overall_stats.tsv')\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    data.table: %s\\n    readr: %s\\n    purrr: %s\\n    tidyr: %s\\n    stringr: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('data.table'),\n            packageVersion('readr'),\n            packageVersion('purrr'),\n            packageVersion('tidyr'),\n            packageVersion('stringr')\n        ),\n        'versions.yml'\n    )\n    \"\"\"\n}",
        "nb_lignes_process": 114,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(dplyr)\n    library(readr)\n    library(purrr)\n    library(tidyr)\n    library(stringr)\n\n    TYPE_ORDER = c('n_pairs_trimmed', 'n_pairs_non_contaminated', 'n_pairs_mapped', 'n_pairs_unmapped', 'n_pairs_features', 'n_pairs_cds')\n\n    # Collect stats for each sample, create a table in long format that can be appended to\n    t <- tibble(sample = c(\"${samples.join('\", \"')}\")) %>%\n        mutate(\n            # N. after trimming\n            t = map(\n                sample, \n                function(s) {\n                    fread(\n                        cmd = sprintf(\"grep 'Reads written (passing filters)' %s*trimming_report.txt | sed 's/.*: *//' | sed 's/ .*//' | sed 's/,//g'\", s), \n                        sep = ',',\n                        col.names = c('n_pairs_trimmed')\n                    )\n                }\n            ),\n            i = map(\n                sample,\n                function(s) {\n                    fread(cmd = sprintf(\"grep -v '^*' %s*idxstats\", s), sep = '\\\\t', col.names = c('chr', 'length', 'n_pairs_mapped', 'n_pairs_unmapped')) %>%\n                        lazy_dt() %>%\n                        summarise(n_pairs_mapped = sum(n_pairs_mapped)/2, n_pairs_unmapped = sum(n_pairs_unmapped)/2) %>%\n                        as_tibble()\n                }\n            )\n        ) %>%\n        unnest(c(t, i)) %>%\n        pivot_longer(2:ncol(.), names_to = 'm', values_to = 'v') %>%\n        union(\n            # Total observation after featureCounts\n            tibble(file = Sys.glob('counts*.tsv.gz')) %>%\n                mutate(d = map(file, function(f) fread(cmd = sprintf(\"gunzip -c %s\", f), sep = '\\\\t'))) %>%\n                as_tibble() %>%\n                unnest(d) %>%\n                group_by(sample) %>% summarise(n_pairs_features = sum(count), .groups = 'drop') %>%\n                pivot_longer(2:ncol(.), names_to = 'm', values_to = 'v')\n        ) %>%\n        union(\n            # Total observation after featureCounts\n            fread(cmd = \"gunzip -c counts.CDS.tsv.gz\", sep = '\\\\t') %>%\n                as_tibble() %>%\n                group_by(sample) %>% summarise(n_pairs_cds = sum(count), .groups = 'drop') %>%\n                pivot_longer(2:ncol(.), names_to = 'm', values_to = 'v')\n        )\n\n    # Add in stats from BBDuk, if present\n    for ( f in Sys.glob('*.bbduk.log') ) {\n        s = str_remove(f, '.bbduk.log')\n        t <- t %>% union(\n            fread(cmd = sprintf(\"grep 'Result:' %s | sed 's/Result:[ \\\\t]*//; s/ reads.*//'\", f), col.names = c('v')) %>%\n                as_tibble() %>%\n                mutate(sample = s, m = 'n_pairs_non_contaminated', v = v/2)\n        )\n    }\n\n    # Write the table in wide format\n    t %>% \n        mutate(m = parse_factor(m, levels = TYPE_ORDER, ordered = TRUE)) %>%\n        arrange(sample, m) %>%\n        pivot_wider(names_from = m, values_from = v) %>%\n        write_tsv('overall_stats.tsv')\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    data.table: %s\\n    readr: %s\\n    purrr: %s\\n    tidyr: %s\\n    stringr: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('data.table'),\n            packageVersion('readr'),\n            packageVersion('purrr'),\n            packageVersion('tidyr'),\n            packageVersion('stringr')\n        ),\n        'versions.yml'\n    )\n    \"\"\"",
        "nb_lignes_script": 87,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples",
            "trimlogs",
            "idxstats",
            "fcs",
            "bbduks"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" } else { container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "FASTQC": {
        "name_process": "FASTQC",
        "string_process": "\nprocess FASTQC {\n    tag \"$meta.id\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\"\n    } else {\n        container \"quay.io/biocontainers/fastqc:0.11.9--0\"\n    }\n\n    input:\n    tuple val(meta), path(reads)\n\n    output:\n    tuple val(meta), path(\"*.html\"), emit: html\n    tuple val(meta), path(\"*.zip\") , emit: zip\n    path  \"versions.yml\"           , emit: versions\n\n    script:\n                                                                          \n    def prefix = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 47,
        "string_script": "    def prefix = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $options.args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    }",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0\" } else { container \"quay.io/biocontainers/fastqc:0.11.9--0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "GENOMEINDEX": {
        "name_process": "GENOMEINDEX",
        "string_process": "\nprocess GENOMEINDEX {\n    label 'process_long'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::pigz=2.6\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\"\n    }\n\n    input:\n    path gffs\n\n    output:\n    path \"${outfilename}\", emit: genomes2id\n    path \"versions.yml\"  , emit: versions\n\n    script:\n    outfilename = File.createTempFile('outfile', '.gz').getName()\n    cpus        = Math.floor(task.cpus/2).toInteger()\n    \n    \"\"\"\n    echo \"genome\\tID\" | gzip -c > ${outfilename}\n    for f in ${gffs}; do\n        #unpigz -c -p ${cpus} \\$f | grep -o 'ID=[A-Z0-9_]\\\\+' | sed \"s/^/\\$f\\\\t/; s/ID=//; s/.gff.gz//\" | pigz -c -p ${cpus} >> ${outfilename}\n        gunzip -c \\$f | grep -o 'ID=[A-Z0-9_]\\\\+' | sed \"s/^/\\$f\\\\t/; s/ID=//; s/.gff.gz//\" | gzip -c >> ${outfilename}\n    done\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( pigz --version 2>&1 | sed 's/^pigz //' )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "    outfilename = File.createTempFile('outfile', '.gz').getName()\n    cpus        = Math.floor(task.cpus/2).toInteger()\n    \n    \"\"\"\n    echo \"genome\\tID\" | gzip -c > ${outfilename}\n    for f in ${gffs}; do\n        #unpigz -c -p ${cpus} \\$f | grep -o 'ID=[A-Z0-9_]\\\\+' | sed \"s/^/\\$f\\\\t/; s/ID=//; s/.gff.gz//\" | pigz -c -p ${cpus} >> ${outfilename}\n        gunzip -c \\$f | grep -o 'ID=[A-Z0-9_]\\\\+' | sed \"s/^/\\$f\\\\t/; s/ID=//; s/.gff.gz//\" | gzip -c >> ${outfilename}\n    done\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( pigz --version 2>&1 | sed 's/^pigz //' )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gffs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "label 'process_long'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::pigz=2.6\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\" } else { container \"quay.io/biocontainers/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "COLLECT_GENE_INFO": {
        "name_process": "COLLECT_GENE_INFO",
        "string_process": "\nprocess COLLECT_GENE_INFO {\n    tag 'genes.tsv.gz'\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    }\n\n    input:\n    path gff\n    path genome2id\n    path fcs\n\n    output:\n    path \"genes.tsv.gz\", emit: genefile\n    path \"versions.yml\", emit: versions\n\n    script:\n    def software = getSoftwareName(task.process)\n    \n    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(readr)\n    library(dplyr)\n    library(tidyr)\n    library(stringr)\n\n    setDTthreads($task.cpus)\n\n    # Read the featureCounts files and subset to a set of unique ids\n    fcs <- fread(\n        cmd = \"gunzip -c ${fcs} | grep -v '^Geneid' | cut -f 1 | sort -u\", \n        col.names = c('id')\n    ) %>% \n        data.table()\n\n    # Read all gff files and separate out the last, ';'-separated field into separate columns\n    gffs <- fread(\n        #cmd = \"gunzip -c ${gff} | grep -E '\\\\t' | sed 's/.*ID=\\\\([^;]\\\\+\\\\);.*/\\\\1\\\\t&/'\", sep = '\\\\t',\n        cmd = \"gunzip -c ${gff} | grep -E '\\\\t'\", sep = '\\\\t',\n        col.names = c('chromosome', 'gcaller', 'type', 'from', 'to', 'b', 'strand', 'c', 'rest') \n    ) %>% lazy_dt() %>%\n        mutate(id = str_replace(rest, 'ID=([^;]+).*', '\\\\\\\\1')) %>%\n        semi_join(lazy_dt(fcs), by = 'id') %>%\n        select(-id, -b, -c) %>%\n        as.data.table()\n\n    gffs %>%\n        as_tibble() %>%\n        separate_rows(rest, sep = ';') %>%\n        separate(rest, c('t', 'v'), sep = '=') %>%\n        pivot_wider(names_from = t, values_from = v) %>%\n        as.data.table() %>% lazy_dt() %>%\n        inner_join(\n            fread(cmd = \"gunzip -c ${genome2id}\", sep = '\\\\t') %>% lazy_dt(),\n            by = 'ID'\n        ) %>%\n        relocate(genome) %>%\n        as_tibble() %>%\n        write_tsv(\"genes.tsv.gz\")\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    tidyr: %s\\n    data.table: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('tidyr'),\n            packageVersion('data.table')\n        ),\n        'versions.yml'\n    )\n    \"\"\"\n}",
        "nb_lignes_process": 82,
        "string_script": "    def software = getSoftwareName(task.process)\n    \n    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(readr)\n    library(dplyr)\n    library(tidyr)\n    library(stringr)\n\n    setDTthreads($task.cpus)\n\n    # Read the featureCounts files and subset to a set of unique ids\n    fcs <- fread(\n        cmd = \"gunzip -c ${fcs} | grep -v '^Geneid' | cut -f 1 | sort -u\", \n        col.names = c('id')\n    ) %>% \n        data.table()\n\n    # Read all gff files and separate out the last, ';'-separated field into separate columns\n    gffs <- fread(\n        #cmd = \"gunzip -c ${gff} | grep -E '\\\\t' | sed 's/.*ID=\\\\([^;]\\\\+\\\\);.*/\\\\1\\\\t&/'\", sep = '\\\\t',\n        cmd = \"gunzip -c ${gff} | grep -E '\\\\t'\", sep = '\\\\t',\n        col.names = c('chromosome', 'gcaller', 'type', 'from', 'to', 'b', 'strand', 'c', 'rest') \n    ) %>% lazy_dt() %>%\n        mutate(id = str_replace(rest, 'ID=([^;]+).*', '\\\\\\\\1')) %>%\n        semi_join(lazy_dt(fcs), by = 'id') %>%\n        select(-id, -b, -c) %>%\n        as.data.table()\n\n    gffs %>%\n        as_tibble() %>%\n        separate_rows(rest, sep = ';') %>%\n        separate(rest, c('t', 'v'), sep = '=') %>%\n        pivot_wider(names_from = t, values_from = v) %>%\n        as.data.table() %>% lazy_dt() %>%\n        inner_join(\n            fread(cmd = \"gunzip -c ${genome2id}\", sep = '\\\\t') %>% lazy_dt(),\n            by = 'ID'\n        ) %>%\n        relocate(genome) %>%\n        as_tibble() %>%\n        write_tsv(\"genes.tsv.gz\")\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    tidyr: %s\\n    data.table: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('tidyr'),\n            packageVersion('data.table')\n        ),\n        'versions.yml'\n    )\n    \"\"\"",
        "nb_lignes_script": 57,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gff",
            "genome2id",
            "fcs"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag 'genes.tsv.gz'",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" } else { container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "MULTIQC": {
        "name_process": "MULTIQC",
        "string_process": "\nprocess MULTIQC {\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? 'bioconda::multiqc=1.11' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\"\n    }\n\n    input:\n    path multiqc_files\n\n    output:\n    path \"*multiqc_report.html\", emit: report\n    path \"*_data\"              , emit: data\n    path \"*_plots\"             , optional:true, emit: plots\n    path \"versions.yml\"        , emit: versions\n\n    script:\n    \"\"\"\n    multiqc -f $options.args .\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( multiqc --version | sed -e \"s/multiqc, version //g\" )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    multiqc -f $options.args .\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( multiqc --version | sed -e \"s/multiqc, version //g\" )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "multiqc_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? 'bioconda::multiqc=1.11' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0\" } else { container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "CONCATENATE": {
        "name_process": "CONCATENATE",
        "string_process": "\nprocess CONCATENATE {\n    label 'process_long'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::pigz=2.6\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\"\n    }\n\n    input:\n    val  outfile\n    path files\n\n    output:\n    path \"${outfilename}\", emit: file\n\n    script:\n    cpus    = Math.floor(task.cpus/2).toInteger()\n\n                                                                                                         \n    catcmd  = ( files[0] =~ /.gz$/ && options.args ) ? \"unpigz -c -p $cpus\" : \"cat\"\n\n                                                                       \n    outcmd  = ( files[0] =~ /.gz$/ && catcmd == 'cat' ) ? '' : '| pigz -c -p $cpus'\n\n                                                                        \n    outfilename = ( outfile != '' ) ? outfile : File.createTempFile('outfile', '.gz').getName()\n    \n    \"\"\"\n    ${catcmd} $files ${options.args} ${outcmd} > $outfilename\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( pigz --version 2>&1 | sed 's/^pigz //' )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "    cpus    = Math.floor(task.cpus/2).toInteger()\n\n                                                                                                         \n    catcmd  = ( files[0] =~ /.gz$/ && options.args ) ? \"unpigz -c -p $cpus\" : \"cat\"\n\n                                                                       \n    outcmd  = ( files[0] =~ /.gz$/ && catcmd == 'cat' ) ? '' : '| pigz -c -p $cpus'\n\n                                                                        \n    outfilename = ( outfile != '' ) ? outfile : File.createTempFile('outfile', '.gz').getName()\n    \n    \"\"\"\n    ${catcmd} $files ${options.args} ${outcmd} > $outfilename\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( pigz --version 2>&1 | sed 's/^pigz //' )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "outfile",
            "files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "label 'process_long'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::pigz=2.6\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\" } else { container \"quay.io/biocontainers/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:941789bd7fe00db16531c26de8bf3c5c985242a5-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMTOOLS_FLAGSTAT": {
        "name_process": "SAMTOOLS_FLAGSTAT",
        "string_process": "\nprocess SAMTOOLS_FLAGSTAT {\n    tag \"$meta.id\"\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? 'bioconda::samtools=1.13' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\"\n    }\n\n    input:\n    tuple val(meta), path(bam), path(bai)\n\n    output:\n    tuple val(meta), path(\"*.flagstat\"), emit: flagstat\n    path  \"versions.yml\"               , emit: versions\n\n    script:\n    \"\"\"\n    samtools flagstat $bam > ${bam}.flagstat\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    samtools flagstat $bam > ${bam}.flagstat\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "meta",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? 'bioconda::samtools=1.13' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\" } else { container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "BBMAP_INDEX": {
        "name_process": "BBMAP_INDEX",
        "string_process": "\nprocess BBMAP_INDEX {\n    tag \"$fasta\"\n    label 'process_long'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"bioconda::bbmap=38.92\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/bbmap:38.92--he522d1c_0\"\n    } else {\n        container \"quay.io/biocontainers/bbmap:38.92--he522d1c_0\"\n    }\n\n    input:\n    path fasta\n\n    output:\n    path 'ref'                    , emit: index\n    path \"versions.yml\"           , emit: versions\n\n    script:\n    \"\"\"\n    bbmap.sh \\\\\n        ref=${fasta} \\\\\n        $options.args \\\\\n        threads=$task.cpus \\\\\n        -Xmx${task.memory.toGiga()}g\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(bbversion.sh)\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n    bbmap.sh \\\\\n        ref=${fasta} \\\\\n        $options.args \\\\\n        threads=$task.cpus \\\\\n        -Xmx${task.memory.toGiga()}g\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(bbversion.sh)\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$fasta\"",
            "label 'process_long'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"bioconda::bbmap=38.92\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/bbmap:38.92--he522d1c_0\" } else { container \"quay.io/biocontainers/bbmap:38.92--he522d1c_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "COLLECT_FEATURECOUNTS": {
        "name_process": "COLLECT_FEATURECOUNTS",
        "string_process": "\nprocess COLLECT_FEATURECOUNTS {\n    tag \"counts${options.suffix}.tsv.gz\"\n    label 'process_high'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    } else {\n        container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\"\n    }\n\n    input:\n    path inputfiles\n\n    output:\n    path \"*.tsv.gz\"              , emit: counts\n    path \"versions.yml\"          , emit: versions\n\n    script:\n    def software = getSoftwareName(task.process)\n    \n    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(readr)\n    library(dplyr)\n    library(stringr)\n\n    setDTthreads($task.cpus)\n\n\n    tibble(f = Sys.glob('*.featureCounts.txt')) %>%\n        mutate(\n            d = purrr::map(\n                f, \n                function(file) {\n                    fread(file, sep = '\\\\t', skip = 1) %>%\n                        melt(measure.vars = c(ncol(.)), variable.name = 'sample', value.name = 'count') %>%\n                        lazy_dt() %>%\n                        filter(count > 0) %>%\n                        mutate(\n                            sample = str_remove(sample, '.sorted.bam'),\n                            r = count/Length\n                        ) %>%\n                        group_by(sample) %>% mutate(tpm = r/sum(r) * 1e6) %>% ungroup() %>%\n                        select(-r) %>%\n                        as_tibble()\n                }\n            )\n        ) %>%\n        tidyr::unnest(d) %>%\n        select(-f) %>%\n        write_tsv(\"counts${options.suffix}.tsv.gz\")\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    data.table: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('data.table')\n        ),\n        'versions.yml'\n    )\n    \"\"\"\n}",
        "nb_lignes_process": 70,
        "string_script": "    def software = getSoftwareName(task.process)\n    \n    \"\"\"\n    #!/usr/bin/env Rscript\n\n    library(data.table)\n    library(dtplyr)\n    library(readr)\n    library(dplyr)\n    library(stringr)\n\n    setDTthreads($task.cpus)\n\n\n    tibble(f = Sys.glob('*.featureCounts.txt')) %>%\n        mutate(\n            d = purrr::map(\n                f, \n                function(file) {\n                    fread(file, sep = '\\\\t', skip = 1) %>%\n                        melt(measure.vars = c(ncol(.)), variable.name = 'sample', value.name = 'count') %>%\n                        lazy_dt() %>%\n                        filter(count > 0) %>%\n                        mutate(\n                            sample = str_remove(sample, '.sorted.bam'),\n                            r = count/Length\n                        ) %>%\n                        group_by(sample) %>% mutate(tpm = r/sum(r) * 1e6) %>% ungroup() %>%\n                        select(-r) %>%\n                        as_tibble()\n                }\n            )\n        ) %>%\n        tidyr::unnest(d) %>%\n        select(-f) %>%\n        write_tsv(\"counts${options.suffix}.tsv.gz\")\n\n    write(\n        sprintf(\n            \"${getProcessName(task.process)}:\\n    R: %s.%s\\n    dplyr: %s\\n    dtplyr: %s\\n    data.table: %s\\n\",\n            R.Version()\\$major, R.Version()\\$minor,\n            packageVersion('dplyr'),\n            packageVersion('dtplyr'),\n            packageVersion('data.table')\n        ),\n        'versions.yml'\n    )\n    \"\"\"",
        "nb_lignes_script": 47,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputfiles"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"counts${options.suffix}.tsv.gz\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::r-tidyverse=1.3.1 conda-forge::r-data.table=1.14.0 conda-forge::r-dtplyr=1.1.0\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" } else { container \"quay.io/biocontainers/mulled-v2-508c9bc5e929a77a9708902b1deca248c0c84689:0bb5bee2557136d28549f41d3faa08485e967aa1-0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "FETCH_NCBI": {
        "name_process": "FETCH_NCBI",
        "string_process": "\nprocess FETCH_NCBI {\n    tag \"$ncbi_accs\"\n    label 'process_long'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"anaconda::wget=1.20.1\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/wget:1.20.1\"\n    } else {\n        container \"quay.io/biocontainers/wget:1.20.1\"\n    }\n\n    input:\n    path ncbi_accs\n\n    output:\n    path \"*.fna.gz\"    , emit: fnas                    \n    path \"failures.txt\", emit: failures\n    path \"versions.yml\", emit: versions\n\n    script:\n    \n    \"\"\"\n    mkdir genomes/\n\n    # Fetch file indexes\n    wget -O 00refseq.index  ftp://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_refseq.txt\n    wget -O 10genbank.index ftp://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_genbank.txt\n\n    echo \"Contig files for the following accessions were not found at NCBI\" > failures.txt\n    for a in \\$(cat $ncbi_accs); do\n        d=\\$(grep \\$a *.index | cut -f 20 | head -n 1 | sed 's/https/ftp/')\n        echo \"--> \\$a: \\$d <--\"\n        \\$(wget \\${d}/*_genomic.fna.gz)\n        rm -f *from_genomic*.fna.gz \n        if [ \\$(ls *_genomic.fna.gz | wc -l) ]; then\n            echo \"\\$a\"\n        fi\n    done\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( wget --version | grep '^GNU' | sed 's/GNU Wget //' | sed 's/ .*//' )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "    \"\"\"\n    mkdir genomes/\n\n    # Fetch file indexes\n    wget -O 00refseq.index  ftp://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_refseq.txt\n    wget -O 10genbank.index ftp://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_genbank.txt\n\n    echo \"Contig files for the following accessions were not found at NCBI\" > failures.txt\n    for a in \\$(cat $ncbi_accs); do\n        d=\\$(grep \\$a *.index | cut -f 20 | head -n 1 | sed 's/https/ftp/')\n        echo \"--> \\$a: \\$d <--\"\n        \\$(wget \\${d}/*_genomic.fna.gz)\n        rm -f *from_genomic*.fna.gz \n        if [ \\$(ls *_genomic.fna.gz | wc -l) ]; then\n            echo \"\\$a\"\n        fi\n    done\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( wget --version | grep '^GNU' | sed 's/GNU Wget //' | sed 's/ .*//' )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ncbi_accs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$ncbi_accs\"",
            "label 'process_long'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"anaconda::wget=1.20.1\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/wget:1.20.1\" } else { container \"quay.io/biocontainers/wget:1.20.1\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMTOOLS_IDXSTATS": {
        "name_process": "SAMTOOLS_IDXSTATS",
        "string_process": "\nprocess SAMTOOLS_IDXSTATS {\n    tag \"$meta.id\"\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? 'bioconda::samtools=1.13' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\"\n    }\n\n    input:\n    tuple val(meta), path(bam), path(bai)\n\n    output:\n    tuple val(meta), path(\"*.idxstats\"), emit: idxstats\n    path  \"versions.yml\"               , emit: versions\n\n    script:\n    \"\"\"\n    samtools idxstats $bam > ${bam}.idxstats\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    samtools idxstats $bam > ${bam}.idxstats\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "meta",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? 'bioconda::samtools=1.13' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\" } else { container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMTOOLS_SORT": {
        "name_process": "SAMTOOLS_SORT",
        "string_process": "\nprocess SAMTOOLS_SORT {\n    tag \"$meta.id\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? 'bioconda::samtools=1.13' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\"\n    }\n\n    input:\n    tuple val(meta), path(bam)\n\n    output:\n    tuple val(meta), path(\"*.bam\"), emit: bam\n    path  \"versions.yml\"          , emit: versions\n\n    script:\n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    \"\"\"\n    samtools sort $options.args -@ $task.cpus -o ${prefix}.bam -T $prefix $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    \"\"\"\n    samtools sort $options.args -@ $task.cpus -o ${prefix}.bam -T $prefix $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "meta",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? 'bioconda::samtools=1.13' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\" } else { container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SUBREAD_FEATURECOUNTS": {
        "name_process": "SUBREAD_FEATURECOUNTS",
        "string_process": "\nprocess SUBREAD_FEATURECOUNTS {\n    tag \"$meta.id\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"bioconda::subread=2.0.1\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/subread:2.0.1--hed695b0_0\"\n    } else {\n        container \"quay.io/biocontainers/subread:2.0.1--hed695b0_0\"\n    }\n\n    input:\n    tuple val(meta), path(bams), path(annotation)\n\n    output:\n    tuple val(meta), path(\"*featureCounts.txt\")        , emit: counts\n    tuple val(meta), path(\"*featureCounts.txt.summary\"), emit: summary\n    path \"versions.yml\"                                , emit: versions\n\n    script:\n    def prefix     = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    def paired_end = meta.single_end ? '' : '-p'\n\n    def strandedness = 0\n    if (meta.strandedness == 'forward') {\n        strandedness = 1\n    } else if (meta.strandedness == 'reverse') {\n        strandedness = 2\n    }\n    \"\"\"\n    featureCounts \\\\\n        $options.args \\\\\n        $paired_end \\\\\n        -T $task.cpus \\\\\n        -a $annotation \\\\\n        -s $strandedness \\\\\n        -o ${prefix}.featureCounts.txt \\\\\n        ${bams.join(' ')}\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( echo \\$(featureCounts -v 2>&1) | sed -e \"s/featureCounts v//g\")\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "    def prefix     = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    def paired_end = meta.single_end ? '' : '-p'\n\n    def strandedness = 0\n    if (meta.strandedness == 'forward') {\n        strandedness = 1\n    } else if (meta.strandedness == 'reverse') {\n        strandedness = 2\n    }\n    \"\"\"\n    featureCounts \\\\\n        $options.args \\\\\n        $paired_end \\\\\n        -T $task.cpus \\\\\n        -a $annotation \\\\\n        -s $strandedness \\\\\n        -o ${prefix}.featureCounts.txt \\\\\n        ${bams.join(' ')}\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$( echo \\$(featureCounts -v 2>&1) | sed -e \"s/featureCounts v//g\")\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "FeatureCounts"
        ],
        "tools_url": [
            "https://bio.tools/featurecounts"
        ],
        "tools_dico": [
            {
                "name": "FeatureCounts",
                "uri": "https://bio.tools/featurecounts",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3793",
                                    "term": "Read summarisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "featureCounts is a very efficient read quantifier. It can be used to summarize RNA-seq reads and gDNA-seq reads to a variety of genomic features such as genes, exons, promoters, gene bodies and genomic bins. It is included in the Bioconductor Rsubread package and also in the SourceForge Subread package.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rsubread.html"
            }
        ],
        "inputs": [
            "meta",
            "bams",
            "annotation"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"bioconda::subread=2.0.1\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/subread:2.0.1--hed695b0_0\" } else { container \"quay.io/biocontainers/subread:2.0.1--hed695b0_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMPLESHEET_CHECK": {
        "name_process": "SAMPLESHEET_CHECK",
        "string_process": "\nprocess SAMPLESHEET_CHECK {\n    tag \"$samplesheet\"\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/python:3.8.3\"\n    } else {\n        container \"quay.io/biocontainers/python:3.8.3\"\n    }\n\n    input:\n    path samplesheet\n\n    output:\n    path '*.csv'\n\n    script:                                                                    \n    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplesheet"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$samplesheet\"",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/python:3.8.3\" } else { container \"quay.io/biocontainers/python:3.8.3\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMTOOLS_INDEX": {
        "name_process": "SAMTOOLS_INDEX",
        "string_process": "\nprocess SAMTOOLS_INDEX {\n    tag \"$meta.id\"\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? 'bioconda::samtools=1.13' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\"\n    }\n\n    input:\n    tuple val(meta), path(bam)\n\n    output:\n    tuple val(meta), path(\"*.bai\"), optional:true, emit: bai\n    tuple val(meta), path(\"*.csi\"), optional:true, emit: csi\n    path  \"versions.yml\"          , emit: versions\n\n    script:\n    \"\"\"\n    samtools index $options.args $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    samtools index $options.args $bam\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "meta",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? 'bioconda::samtools=1.13' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\" } else { container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "BBMAP_BBDUK": {
        "name_process": "BBMAP_BBDUK",
        "string_process": "\nprocess BBMAP_BBDUK {\n    tag \"$meta.id\"\n    label 'process_medium'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"bioconda::bbmap=38.90\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/bbmap:38.90--he522d1c_1\"\n    } else {\n        container \"quay.io/biocontainers/bbmap:38.90--he522d1c_1\"\n    }\n\n    input:\n    tuple val(meta), path(reads)\n    path contaminants\n\n    output:\n    tuple val(meta), path('*.fastq.gz'), emit: reads\n    tuple val(meta), path('*.log')     , emit: log\n    path \"versions.yml\"                , emit: versions\n\n    script:\n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    def raw      = meta.single_end ? \"in=${reads[0]}\" : \"in1=${reads[0]} in2=${reads[1]}\"\n    def trimmed  = meta.single_end ? \"out=${prefix}.fastq.gz\" : \"out1=${prefix}_1.fastq.gz out2=${prefix}_2.fastq.gz\"\n    def contaminants_fa = contaminants ? \"ref=$contaminants\" : ''\n    \"\"\"\n    maxmem=\\$(echo \\\"$task.memory\\\"| sed 's/ GB/g/g')\n    bbduk.sh \\\\\n        -Xmx\\$maxmem \\\\\n        $raw \\\\\n        $trimmed \\\\\n        threads=$task.cpus \\\\\n        $options.args \\\\\n        $contaminants_fa \\\\\n        &> ${prefix}.bbduk.log\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(bbversion.sh)\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    def raw      = meta.single_end ? \"in=${reads[0]}\" : \"in1=${reads[0]} in2=${reads[1]}\"\n    def trimmed  = meta.single_end ? \"out=${prefix}.fastq.gz\" : \"out1=${prefix}_1.fastq.gz out2=${prefix}_2.fastq.gz\"\n    def contaminants_fa = contaminants ? \"ref=$contaminants\" : ''\n    \"\"\"\n    maxmem=\\$(echo \\\"$task.memory\\\"| sed 's/ GB/g/g')\n    bbduk.sh \\\\\n        -Xmx\\$maxmem \\\\\n        $raw \\\\\n        $trimmed \\\\\n        threads=$task.cpus \\\\\n        $options.args \\\\\n        $contaminants_fa \\\\\n        &> ${prefix}.bbduk.log\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(bbversion.sh)\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "reads",
            "contaminants"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"bioconda::bbmap=38.90\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/bbmap:38.90--he522d1c_1\" } else { container \"quay.io/biocontainers/bbmap:38.90--he522d1c_1\" }"
        ],
        "when": "",
        "stub": ""
    },
    "TRIMGALORE": {
        "name_process": "TRIMGALORE",
        "string_process": "\nprocess TRIMGALORE {\n    tag \"$meta.id\"\n    label 'process_high'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? 'bioconda::trim-galore=0.6.7' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/trim-galore:0.6.7--hdfd78af_0\"\n    } else {\n        container \"quay.io/biocontainers/trim-galore:0.6.7--hdfd78af_0\"\n    }\n\n    input:\n    tuple val(meta), path(reads)\n\n    output:\n    tuple val(meta), path(\"*.fq.gz\")    , emit: reads\n    tuple val(meta), path(\"*report.txt\"), emit: log\n    path \"versions.yml\"                 , emit: versions\n\n    tuple val(meta), path(\"*.html\"), emit: html optional true\n    tuple val(meta), path(\"*.zip\") , emit: zip optional true\n\n    script:\n                                                                             \n                                                                                                                 \n                                                      \n    def cores = 1\n    if (task.cpus) {\n        cores = (task.cpus as int) - 4\n        if (meta.single_end) cores = (task.cpus as int) - 3\n        if (cores < 1) cores = 1\n        if (cores > 4) cores = 4\n    }\n\n                                                                    \n    def c_r1   = params.clip_r1 > 0             ? \"--clip_r1 ${params.clip_r1}\"                         : ''\n    def c_r2   = params.clip_r2 > 0             ? \"--clip_r2 ${params.clip_r2}\"                         : ''\n    def tpc_r1 = params.three_prime_clip_r1 > 0 ? \"--three_prime_clip_r1 ${params.three_prime_clip_r1}\" : ''\n    def tpc_r2 = params.three_prime_clip_r2 > 0 ? \"--three_prime_clip_r2 ${params.three_prime_clip_r2}\" : ''\n\n                                                                           \n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        trim_galore \\\\\n            $options.args \\\\\n            --cores $cores \\\\\n            --gzip \\\\\n            $c_r1 \\\\\n            $tpc_r1 \\\\\n            ${prefix}.fastq.gz\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$(echo \\$(trim_galore --version 2>&1) | sed 's/^.*version //; s/Last.*\\$//')\n            cutadapt: \\$(cutadapt --version)\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        trim_galore \\\\\n            $options.args \\\\\n            --cores $cores \\\\\n            --paired \\\\\n            --gzip \\\\\n            $c_r1 \\\\\n            $c_r2 \\\\\n            $tpc_r1 \\\\\n            $tpc_r2 \\\\\n            ${prefix}_1.fastq.gz \\\\\n            ${prefix}_2.fastq.gz\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$(echo \\$(trim_galore --version 2>&1) | sed 's/^.*version //; s/Last.*\\$//')\n            cutadapt: \\$(cutadapt --version)\n        END_VERSIONS\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 83,
        "string_script": "    def cores = 1\n    if (task.cpus) {\n        cores = (task.cpus as int) - 4\n        if (meta.single_end) cores = (task.cpus as int) - 3\n        if (cores < 1) cores = 1\n        if (cores > 4) cores = 4\n    }\n\n                                                                    \n    def c_r1   = params.clip_r1 > 0             ? \"--clip_r1 ${params.clip_r1}\"                         : ''\n    def c_r2   = params.clip_r2 > 0             ? \"--clip_r2 ${params.clip_r2}\"                         : ''\n    def tpc_r1 = params.three_prime_clip_r1 > 0 ? \"--three_prime_clip_r1 ${params.three_prime_clip_r1}\" : ''\n    def tpc_r2 = params.three_prime_clip_r2 > 0 ? \"--three_prime_clip_r2 ${params.three_prime_clip_r2}\" : ''\n\n                                                                           \n    def prefix   = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        trim_galore \\\\\n            $options.args \\\\\n            --cores $cores \\\\\n            --gzip \\\\\n            $c_r1 \\\\\n            $tpc_r1 \\\\\n            ${prefix}.fastq.gz\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$(echo \\$(trim_galore --version 2>&1) | sed 's/^.*version //; s/Last.*\\$//')\n            cutadapt: \\$(cutadapt --version)\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        trim_galore \\\\\n            $options.args \\\\\n            --cores $cores \\\\\n            --paired \\\\\n            --gzip \\\\\n            $c_r1 \\\\\n            $c_r2 \\\\\n            $tpc_r1 \\\\\n            $tpc_r2 \\\\\n            ${prefix}_1.fastq.gz \\\\\n            ${prefix}_2.fastq.gz\n        cat <<-END_VERSIONS > versions.yml\n        ${getProcessName(task.process)}:\n            ${getSoftwareName(task.process)}: \\$(echo \\$(trim_galore --version 2>&1) | sed 's/^.*version //; s/Last.*\\$//')\n            cutadapt: \\$(cutadapt --version)\n        END_VERSIONS\n        \"\"\"\n    }",
        "nb_lignes_script": 53,
        "language_script": "bash",
        "tools": [
            "CoreSlicer"
        ],
        "tools_url": [
            "https://bio.tools/CoreSlicer"
        ],
        "tools_dico": [
            {
                "name": "CoreSlicer",
                "uri": "https://bio.tools/CoreSlicer",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3384",
                            "term": "Medical imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "Tomography"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "MRI"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "CT"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "Computed tomography"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "TDM"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "Nuclear magnetic resonance imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "Magnetic resonance imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "MRT"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "Magnetic resonance tomography"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "NMRI"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Enables extraction of morphomic markers from CT images by non-technically skilled clinicians.",
                "homepage": "https://coreslicer.com/"
            }
        ],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? 'bioconda::trim-galore=0.6.7' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/trim-galore:0.6.7--hdfd78af_0\" } else { container \"quay.io/biocontainers/trim-galore:0.6.7--hdfd78af_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "PRODIGAL": {
        "name_process": "PRODIGAL",
        "string_process": "\nprocess PRODIGAL {\n    tag \"$meta.id\"\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"bioconda::prodigal=2.6.3\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/prodigal:2.6.3--h516909a_2\"\n    } else {\n        container \"quay.io/biocontainers/prodigal:2.6.3--h516909a_2\"\n    }\n\n    input:\n    tuple val(meta), path(genome)\n    val(output_format)\n\n    output:\n    tuple val(meta), path(\"${prefix}.${output_format}\"), emit: gene_annotations\n    tuple val(meta), path(\"${prefix}.fna\"), emit: nucleotide_fasta\n    tuple val(meta), path(\"${prefix}.faa\"), emit: amino_acid_fasta\n    tuple val(meta), path(\"${prefix}_all.txt\"), emit: all_gene_annotations\n    path \"versions.yml\"           , emit: versions\n\n    script:\n    prefix = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    \"\"\"\n    prodigal -i \"${genome}\" \\\\\n        $options.args \\\\\n        -f $output_format \\\\\n        -d \"${prefix}.fna\" \\\\\n        -o \"${prefix}.${output_format}\" \\\\\n        -a \"${prefix}.faa\" \\\\\n        -s \"${prefix}_all.txt\"\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(prodigal -v 2>&1 | sed -n 's/Prodigal V\\\\(.*\\\\):.*/\\\\1/p')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "    prefix = options.suffix ? \"${meta.id}${options.suffix}\" : \"${meta.id}\"\n    \"\"\"\n    prodigal -i \"${genome}\" \\\\\n        $options.args \\\\\n        -f $output_format \\\\\n        -d \"${prefix}.fna\" \\\\\n        -o \"${prefix}.${output_format}\" \\\\\n        -a \"${prefix}.faa\" \\\\\n        -s \"${prefix}_all.txt\"\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(prodigal -v 2>&1 | sed -n 's/Prodigal V\\\\(.*\\\\):.*/\\\\1/p')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "genome",
            "output_format"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"bioconda::prodigal=2.6.3\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/prodigal:2.6.3--h516909a_2\" } else { container \"quay.io/biocontainers/prodigal:2.6.3--h516909a_2\" }"
        ],
        "when": "",
        "stub": ""
    },
    "GUNZIP": {
        "name_process": "GUNZIP",
        "string_process": "\nprocess GUNZIP {\n    tag \"$archive\"\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }\n\n    conda (params.enable_conda ? \"conda-forge::sed=4.7\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img\"\n    } else {\n        container \"biocontainers/biocontainers:v1.2.0_cv1\"\n    }\n\n    input:\n    path archive\n\n    output:\n    path \"$gunzip\",       emit: gunzip\n    path \"versions.yml\" , emit: versions\n\n    script:\n    gunzip       = archive.toString() - '.gz'\n    \"\"\"\n    gunzip \\\\\n        -f \\\\\n        -c \\\\\n        $options.args \\\\\n        $archive > $gunzip\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(gunzip --version 2>&1) | sed 's/^.*(gzip) //; s/ Copyright.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    gunzip       = archive.toString() - '.gz'\n    \"\"\"\n    gunzip \\\\\n        -f \\\\\n        -c \\\\\n        $options.args \\\\\n        $archive > $gunzip\n\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(gunzip --version 2>&1) | sed 's/^.*(gzip) //; s/ Copyright.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "archive"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$archive\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"conda-forge::sed=4.7\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img\" } else { container \"biocontainers/biocontainers:v1.2.0_cv1\" }"
        ],
        "when": "",
        "stub": ""
    },
    "SAMTOOLS_STATS": {
        "name_process": "SAMTOOLS_STATS",
        "string_process": "\nprocess SAMTOOLS_STATS {\n    tag \"$meta.id\"\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? 'bioconda::samtools=1.13' : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\"\n    } else {\n        container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\"\n    }\n\n    input:\n    tuple val(meta), path(bam), path(bai)\n\n    output:\n    tuple val(meta), path(\"*.stats\"), emit: stats\n    path  \"versions.yml\"            , emit: versions\n\n    script:\n    \"\"\"\n    samtools stats $bam > ${bam}.stats\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    samtools stats $bam > ${bam}.stats\n    cat <<-END_VERSIONS > versions.yml\n    ${getProcessName(task.process)}:\n        ${getSoftwareName(task.process)}: \\$(echo \\$(samtools --version 2>&1) | sed 's/^.*samtools //; s/Using.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "meta",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? 'bioconda::samtools=1.13' : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/samtools:1.13--h8c37831_0\" } else { container \"quay.io/biocontainers/samtools:1.13--h8c37831_0\" }"
        ],
        "when": "",
        "stub": ""
    },
    "CUSTOM_DUMPSOFTWAREVERSIONS": {
        "name_process": "CUSTOM_DUMPSOFTWAREVERSIONS",
        "string_process": "\nprocess CUSTOM_DUMPSOFTWAREVERSIONS {\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }\n\n                                                                                                  \n    conda (params.enable_conda ? \"bioconda::multiqc=1.11\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0\"\n    } else {\n        container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\"\n    }\n\n    input:\n    path versions\n\n    output:\n    path \"software_versions.yml\"    , emit: yml\n    path \"software_versions_mqc.yml\", emit: mqc_yml\n    path \"versions.yml\"             , emit: versions\n\n    script:\n    \"\"\"\n    #!/usr/bin/env python\n\n    import yaml\n    import platform\n    from textwrap import dedent\n\n    def _make_versions_html(versions):\n        html = [\n            dedent(\n                '''\\\\\n                <style>\n                #nf-core-versions tbody:nth-child(even) {\n                    background-color: #f2f2f2;\n                }\n                </style>\n                <table class=\"table\" style=\"width:100%\" id=\"nf-core-versions\">\n                    <thead>\n                        <tr>\n                            <th> Process Name </th>\n                            <th> Software </th>\n                            <th> Version  </th>\n                        </tr>\n                    </thead>\n                '''\n            )\n        ]\n        for process, tmp_versions in sorted(versions.items()):\n            html.append(\"<tbody>\")\n            for i, (tool, version) in enumerate(sorted(tmp_versions.items())):\n                html.append(\n                    dedent(\n                        f'''\\\\\n                        <tr>\n                            <td><samp>{process if (i == 0) else ''}</samp></td>\n                            <td><samp>{tool}</samp></td>\n                            <td><samp>{version}</samp></td>\n                        </tr>\n                        '''\n                    )\n                )\n            html.append(\"</tbody>\")\n        html.append(\"</table>\")\n        return \"\\\\n\".join(html)\n\n    module_versions = {}\n    module_versions[\"${getProcessName(task.process)}\"] = {\n        'python': platform.python_version(),\n        'yaml': yaml.__version__\n    }\n\n    with open(\"$versions\") as f:\n        workflow_versions = yaml.safe_load(f) | module_versions\n\n    workflow_versions[\"Workflow\"] = {\n        \"Nextflow\": \"$workflow.nextflow.version\",\n        \"$workflow.manifest.name\": \"$workflow.manifest.version\"\n    }\n\n    versions_mqc = {\n        'id': 'software_versions',\n        'section_name': '${workflow.manifest.name} Software Versions',\n        'section_href': 'https://github.com/${workflow.manifest.name}',\n        'plot_type': 'html',\n        'description': 'are collected at run time from the software output.',\n        'data': _make_versions_html(workflow_versions)\n    }\n\n    with open(\"software_versions.yml\", 'w') as f:\n        yaml.dump(workflow_versions, f, default_flow_style=False)\n    with open(\"software_versions_mqc.yml\", 'w') as f:\n        yaml.dump(versions_mqc, f, default_flow_style=False)\n\n    with open('versions.yml', 'w') as f:\n        yaml.dump(module_versions, f, default_flow_style=False)\n    \"\"\"\n}",
        "nb_lignes_process": 99,
        "string_script": "    \"\"\"\n    #!/usr/bin/env python\n\n    import yaml\n    import platform\n    from textwrap import dedent\n\n    def _make_versions_html(versions):\n        html = [\n            dedent(\n                '''\\\\\n                <style>\n                #nf-core-versions tbody:nth-child(even) {\n                    background-color: #f2f2f2;\n                }\n                </style>\n                <table class=\"table\" style=\"width:100%\" id=\"nf-core-versions\">\n                    <thead>\n                        <tr>\n                            <th> Process Name </th>\n                            <th> Software </th>\n                            <th> Version  </th>\n                        </tr>\n                    </thead>\n                '''\n            )\n        ]\n        for process, tmp_versions in sorted(versions.items()):\n            html.append(\"<tbody>\")\n            for i, (tool, version) in enumerate(sorted(tmp_versions.items())):\n                html.append(\n                    dedent(\n                        f'''\\\\\n                        <tr>\n                            <td><samp>{process if (i == 0) else ''}</samp></td>\n                            <td><samp>{tool}</samp></td>\n                            <td><samp>{version}</samp></td>\n                        </tr>\n                        '''\n                    )\n                )\n            html.append(\"</tbody>\")\n        html.append(\"</table>\")\n        return \"\\\\n\".join(html)\n\n    module_versions = {}\n    module_versions[\"${getProcessName(task.process)}\"] = {\n        'python': platform.python_version(),\n        'yaml': yaml.__version__\n    }\n\n    with open(\"$versions\") as f:\n        workflow_versions = yaml.safe_load(f) | module_versions\n\n    workflow_versions[\"Workflow\"] = {\n        \"Nextflow\": \"$workflow.nextflow.version\",\n        \"$workflow.manifest.name\": \"$workflow.manifest.version\"\n    }\n\n    versions_mqc = {\n        'id': 'software_versions',\n        'section_name': '${workflow.manifest.name} Software Versions',\n        'section_href': 'https://github.com/${workflow.manifest.name}',\n        'plot_type': 'html',\n        'description': 'are collected at run time from the software output.',\n        'data': _make_versions_html(workflow_versions)\n    }\n\n    with open(\"software_versions.yml\", 'w') as f:\n        yaml.dump(workflow_versions, f, default_flow_style=False)\n    with open(\"software_versions_mqc.yml\", 'w') as f:\n        yaml.dump(versions_mqc, f, default_flow_style=False)\n\n    with open('versions.yml', 'w') as f:\n        yaml.dump(module_versions, f, default_flow_style=False)\n    \"\"\"",
        "nb_lignes_script": 75,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "versions"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "erikrikarddaniel__magmap",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:'pipeline_info', meta:[:], publish_by_meta:[]) }",
            "conda (params.enable_conda ? \"bioconda::multiqc=1.11\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0\" } else { container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\" }"
        ],
        "when": "",
        "stub": ""
    }
}