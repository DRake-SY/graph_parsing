{
    "PYCISTOPIC__MACS2_CALL_PEAKS": {
        "name_process": "PYCISTOPIC__MACS2_CALL_PEAKS",
        "string_process": "\nprocess PYCISTOPIC__MACS2_CALL_PEAKS {\n\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(bam),\n              path(bam_index)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}_peaks.narrowPeak\"),\n              path(\"${sampleId}_summits.bed\")\n\n    script:\n                                                                                    \n        \"\"\"\n        macs2 callpeak \\\n            --treatment ${bam} \\\n            --name ${sampleId} \\\n            --outdir . \\\n            --format BAMPE \\\n            --gsize ${processParams.gsize} \\\n            --qvalue ${processParams.qvalue} \\\n            --nomodel \\\n            --shift ${processParams.shift} \\\n            --extsize ${processParams.extsize} \\\n            --keep-dup ${processParams.keepdup} \\\n            --call-summits \\\n            --nolambda\n        \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "        \"\"\"\n        macs2 callpeak \\\n            --treatment ${bam} \\\n            --name ${sampleId} \\\n            --outdir . \\\n            --format BAMPE \\\n            --gsize ${processParams.gsize} \\\n            --qvalue ${processParams.qvalue} \\\n            --nomodel \\\n            --shift ${processParams.shift} \\\n            --extsize ${processParams.extsize} \\\n            --keep-dup ${processParams.keepdup} \\\n            --call-summits \\\n            --nolambda\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "bam",
            "bam_index"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "GENERATE_REPORT": {
        "name_process": "GENERATE_REPORT",
        "string_process": "\nprocess GENERATE_REPORT {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/notebooks/\", mode: params.utils.publish.mode\n    label 'compute_resources__report'\n\n    input:\n        path(ipynb)\n        tuple val(sampleId),\n              path(bap_final)\n        val(reportTitle)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.${reportTitle}.ipynb\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_multiplet)\n        processParams = sampleParams.local\n        bap_params = toJson(processParams)\n        \"\"\"\n        papermill ${ipynb} \\\n            --report-mode \\\n            ${sampleId}.${reportTitle}.ipynb \\\n            -p SAMPLE ${sampleId} \\\n            -p WORKFLOW_PARAMETERS '${bap_params}' \\\n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_multiplet)\n        processParams = sampleParams.local\n        bap_params = toJson(processParams)\n        \"\"\"\n        papermill ${ipynb} \\\n            --report-mode \\\n            ${sampleId}.${reportTitle}.ipynb \\\n            -p SAMPLE ${sampleId} \\\n            -p WORKFLOW_PARAMETERS '${bap_params}' \\\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ipynb",
            "sampleId",
            "bap_final",
            "reportTitle"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/notebooks/\", mode: params.utils.publish.mode",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "REPORT_TO_HTML": {
        "name_process": "REPORT_TO_HTML",
        "string_process": "\nprocess REPORT_TO_HTML {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/notebooks/\", mode: params.utils.publish.mode\n    label 'compute_resources__report'\n\n    input:\n        path(ipynb)\n\n    output:\n        file(\"*.html\")\n\n    script:\n        \"\"\"\n        jupyter nbconvert ${ipynb} --to html\n        \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "        \"\"\"\n        jupyter nbconvert ${ipynb} --to html\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Jupyterhub"
        ],
        "tools_url": [
            "https://bio.tools/Jupyterhub"
        ],
        "tools_dico": [
            {
                "name": "Jupyterhub",
                "uri": "https://bio.tools/Jupyterhub",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Jupyter notebooks in science gateways.\n\nJupyter Notebooks empower scientists to create executable documents that include text, equations, code and figures. Notebooks are a simple way to create reproducible and shareable workflows. The Jupyter developers have also released a multi-user notebook environment: Jupyterhub. Jupyterhub provides an extensible platform for handling user authentication and spawning the Notebook application to each user. I developed a plugin for Jupyterhub to spawn notebooks on a Supercomputer and integrated the authentication with CILogon and XSEDE. Scientists can authenticate on their browser and connect to a Jupyter Notebook instance running on the computing node of a Supercomputer, in my test deployment SDSC Comet. Jupyterhub can benefit Science Gateways by providing an expressive interface to a centralized environment with many software tools pre-installed and allow scientists to access Gateway functionality via web API.\n\n||| HOMEPAGE MISSING!",
                "homepage": "https://doi.org/10.7287/PEERJ.PREPRINTS.2577V2"
            }
        ],
        "inputs": [
            "ipynb"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/notebooks/\", mode: params.utils.publish.mode",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__POPSCLE__DEMUXLET": {
        "name_process": "SC__POPSCLE__DEMUXLET",
        "string_process": "\nprocess SC__POPSCLE__DEMUXLET {\n\n    container params.tools.popscle.container\n    publishDir \"${params.global.outdir}/data/demuxlet\", mode: params.utils.publish.mode\n    label 'compute_resources__cpu'\n\n    input:\n        tuple val(sampleId), path(f)\n        file vcf\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}_demuxlet*\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.popscle.demuxlet)\n\t\tprocessParams = sampleParams.local\n\n        \"\"\"\n        popscle demuxlet \\\n            --vcf ${vcf} \\\n            ${(processParams.containsKey('field')) ? '--field ' + processParams.field : ''} \\\n            --plp ${sampleId}_dsc-pileup \\\n            --out ${sampleId}_demuxlet\n        \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.popscle.demuxlet)\n\t\tprocessParams = sampleParams.local\n\n        \"\"\"\n        popscle demuxlet \\\n            --vcf ${vcf} \\\n            ${(processParams.containsKey('field')) ? '--field ' + processParams.field : ''} \\\n            --plp ${sampleId}_dsc-pileup \\\n            --out ${sampleId}_demuxlet\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "vcf"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.popscle.container",
            "publishDir \"${params.global.outdir}/data/demuxlet\", mode: params.utils.publish.mode",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__POPSCLE__FREEMUXLET": {
        "name_process": "SC__POPSCLE__FREEMUXLET",
        "string_process": "\nprocess SC__POPSCLE__FREEMUXLET {\n\n    container params.tools.popscle.container\n    publishDir \"${params.global.outdir}/data/freemuxlet\", mode: params.utils.publish.mode\n    label 'compute_resources__cpu'\n\n    input:\n        tuple val(sampleId), path(f)\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}_freemuxlet*\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.popscle.freemuxlet)\n\t\tprocessParams = sampleParams.local\n\n        \"\"\"\n        popscle freemuxlet \\\n            --nsample ${processParams.nSamples} \\\n            --plp ${sampleId}_dsc-pileup \\\n            --out ${sampleId}_freemuxlet\n        \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.popscle.freemuxlet)\n\t\tprocessParams = sampleParams.local\n\n        \"\"\"\n        popscle freemuxlet \\\n            --nsample ${processParams.nSamples} \\\n            --plp ${sampleId}_dsc-pileup \\\n            --out ${sampleId}_freemuxlet\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.popscle.container",
            "publishDir \"${params.global.outdir}/data/freemuxlet\", mode: params.utils.publish.mode",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "FIX_AND_COMPRESS_SRA_FASTQS": {
        "name_process": "FIX_AND_COMPRESS_SRA_FASTQS",
        "string_process": "\nprocess FIX_AND_COMPRESS_SRA_FASTQS {\n\n    container \"vibsinglecellnf/singlecelltoolkit:2021-07-29-09cac13\"\n    publishDir \"${params.global.outdir}/data/raw/fastqs_fixed_and_compressed\", mode: 'symlink', overwrite: true\n    label 'compute_resources__cpu'\n\n    input:\n        tuple val(sraId), file(\"${sraId}_*.fastq\")\n    \n    output:\n        tuple val(sraId), file(\"${sraId}_*.fastq.gz\")\n    \n    script:\n        \"\"\"\n        # Fixing the FASTQ files is required for future pre-processing (e.g.: scATAC-seq pipelines) because fasterq-dump does not have the -F option as fastq-dump do to keep original sequence names.\n        # Fix the FASTQ files and compress them\n        export compress_fastq_threads=\"${task.cpus}\"\n        NUM_FASTQ_FILES=\\$(ls ./*.fastq | wc -l)\n        echo \"Fixing and compressing \\${NUM_FASTQ_FILES} FASTQ files in parallel with \\${compress_fastq_threads} compression threads for each task...\"\n        echo *.fastq | tr ' ' '\\n' | xargs -P \"\\${NUM_FASTQ_FILES}\" -n 1 -I {} fix_sra_fastq.sh \"{}\" \"{}.gz\" pigz\n        echo \"Removing all uncompressed FASTQ files\"\n        for FASTQ in *.fastq; do\n           echo \"Removing uncompressed FASTQ file \\${FASTQ}...\"\n           rm \"\\$(readlink -f \\${FASTQ})\"\n        done\n        echo \"Done.\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "        \"\"\"\n        # Fixing the FASTQ files is required for future pre-processing (e.g.: scATAC-seq pipelines) because fasterq-dump does not have the -F option as fastq-dump do to keep original sequence names.\n        # Fix the FASTQ files and compress them\n        export compress_fastq_threads=\"${task.cpus}\"\n        NUM_FASTQ_FILES=\\$(ls ./*.fastq | wc -l)\n        echo \"Fixing and compressing \\${NUM_FASTQ_FILES} FASTQ files in parallel with \\${compress_fastq_threads} compression threads for each task...\"\n        echo *.fastq | tr ' ' '\\n' | xargs -P \"\\${NUM_FASTQ_FILES}\" -n 1 -I {} fix_sra_fastq.sh \"{}\" \"{}.gz\" pigz\n        echo \"Removing all uncompressed FASTQ files\"\n        for FASTQ in *.fastq; do\n           echo \"Removing uncompressed FASTQ file \\${FASTQ}...\"\n           rm \"\\$(readlink -f \\${FASTQ})\"\n        done\n        echo \"Done.\"\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sraId"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sraId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container \"vibsinglecellnf/singlecelltoolkit:2021-07-29-09cac13\"",
            "publishDir \"${params.global.outdir}/data/raw/fastqs_fixed_and_compressed\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "FASTP__CLEAN_AND_FASTQC": {
        "name_process": "FASTP__CLEAN_AND_FASTQC",
        "string_process": "\nprocess FASTP__CLEAN_AND_FASTQC {\n\n    container params.tools.fastp.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        set val(sample), path(reads)\n    \n    output:\n        tuple file('*_R{1,2}.clean.fastq.gz'), emit: fastq\n        tuple file('*_fastp.{json,html}'), emit: report\n    \n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.fastp)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        fastp --thread ${processParams.thread} \\\n            -i ${reads[0]} \\\n            -I ${reads[1]} \\\n            -o ${sample}_R1.clean.fastq.gz \\\n            -O ${sample}_R2.clean.fastq.gz \\\n            --length_required ${processParams.clean_and_fastqc.length_required} \\\n            --adapter_fasta ${processParams.clean_and_fastqc.adapter_fasta} \\\n            -j ${sample}_fastp.json \\\n            -h ${sample}_fastp.html\n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.fastp)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        fastp --thread ${processParams.thread} \\\n            -i ${reads[0]} \\\n            -I ${reads[1]} \\\n            -o ${sample}_R1.clean.fastq.gz \\\n            -O ${sample}_R2.clean.fastq.gz \\\n            --length_required ${processParams.clean_and_fastqc.length_required} \\\n            --adapter_fasta ${processParams.clean_and_fastqc.adapter_fasta} \\\n            -j ${sample}_fastp.json \\\n            -h ${sample}_fastp.html\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "sample",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.fastp.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "AUCELL": {
        "name_process": "AUCELL",
        "string_process": "\nprocess AUCELL {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}/aucell/${\"numRuns\" in toolParams && toolParams.numRuns > 1 ? \"run_\" + runId : \"\"}\", mode: 'link', overwrite: true\n    label 'compute_resources__scenic_aucell'\n\n    input:\n        tuple \\\n           val(sampleId), \\\n           path(filteredLoom), \\\n           path(regulons), \\\n           val(runId)\n        val type\n\n    output:\n        tuple \\\n           val(sampleId), \\\n           path(filteredLoom), \\\n           path(\"${outputFileName}\"), \\\n           val(runId)\n\n    script:\n        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? \n            sampleId + \"__run_\" + runId +\"__auc_\" + type + \".loom\": \n            sampleId + \"__auc_\" + type + \".loom\"\n        seed = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? \n            (params.global.seed + runId) : \n            params.global.seed\n        \"\"\"\n        export MKL_NUM_THREADS=1\n\t\texport NUMEXPR_NUM_THREADS=1\n\t\texport OMP_NUM_THREADS=1\n        pyscenic aucell \\\n            $filteredLoom \\\n            $regulons \\\n            -o \"${outputFileName}\" \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n            --seed ${seed} \\\n            --num_workers ${task.cpus}\n        \"\"\"\n\n}",
        "nb_lignes_process": 46,
        "string_script": "        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? \n            sampleId + \"__run_\" + runId +\"__auc_\" + type + \".loom\": \n            sampleId + \"__auc_\" + type + \".loom\"\n        seed = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? \n            (params.global.seed + runId) : \n            params.global.seed\n        \"\"\"\n        export MKL_NUM_THREADS=1\n\t\texport NUMEXPR_NUM_THREADS=1\n\t\texport OMP_NUM_THREADS=1\n        pyscenic aucell \\\n            $filteredLoom \\\n            $regulons \\\n            -o \"${outputFileName}\" \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n            --seed ${seed} \\\n            --num_workers ${task.cpus}\n        \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "Seed"
        ],
        "tools_url": [
            "https://bio.tools/seed-eco"
        ],
        "tools_dico": [
            {
                "name": "Seed",
                "uri": "https://bio.tools/seed-eco",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0610",
                            "term": "Ecology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3365",
                            "term": "Data architecture, analysis and design"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An R/Shiny package for visualizing ecological data. It provides a visual interface for generating a wide variety of plots, including histograms, scatterplots, bar plots, stacked bar plots, PCoA plots, cluster dendrograms, and heatmaps.",
                "homepage": "https://github.com/danlbek/Seed"
            }
        ],
        "inputs": [
            "sampleId",
            "filteredLoom",
            "regulons",
            "runId",
            "type"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId",
            "filteredLoom",
            "runId"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}/aucell/${\"numRuns\" in toolParams && toolParams.numRuns > 1 ? \"run_\" + runId : \"\"}\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic_aucell'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELDA__DECONTX": {
        "name_process": "SC__CELDA__DECONTX",
        "string_process": "\nprocess SC__CELDA__DECONTX {\n    \n    container params.tools.celda.container\n    publishDir \"${params.global.outdir}/data/${moduleName}\", mode: 'link'\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.CELDA__DECONTX.Rds\"), \\\n            emit: main\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.CELDA__DECONTX.Contamination_Outlier_Table.tsv\"), \\\n            emit: outlier_table\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.CELDA__DECONTX.{*.pdf,*.tsv}\"), \\\n            emit: other\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.celda.decontx)\n        processParams = sampleParams.local\n        \n        def filterNumMadsThresholdsAsArguments = ''\n        def filterContaminationScoreThresholdsAsArguments = ''\n\n        if(processParams?.filters) {\n            filterNumMadsThresholdsAsArguments = processParams.filters.containsKey('numMadsThresholds') ?\n                processParams.filters.numMadsThresholds.collect({\n                    '--num-mads-threshold ' + ' ' + it \n                }).join(' ') :\n                ''\n            filterContaminationScoreThresholdsAsArguments = processParams.filters.containsKey('contaminationScoreThresholds') ?\n                processParams.filters.contaminationScoreThresholds.collect({ \n                    '--custom-threshold ' + ' ' + it\n                }).join(' ') :\n                ''\n        }\n\n        def roundToIntAsArgument = ''\n        if(processParams?.roundToInt) {\n            roundToIntAsArgument = '--round-to-int '+ processParams.roundToInt\n        }\n        def filterEmptyCells = ''\n        if(processParams?.filterEmptyCells) {\n            filterEmptyCells = '--filter-empty-cells '+ processParams.filterEmptyCells\n        }\n\n        \"\"\"\n        ${binDir}/run_decontx.R \\\n            --sample-id ${sampleId} \\\n            --seed ${params.global.seed} \\\n            ${filterNumMadsThresholdsAsArguments} \\\n            ${filterContaminationScoreThresholdsAsArguments} \\\n            ${roundToIntAsArgument} \\\n            ${filterEmptyCells} \\\n            --output-prefix \"${sampleId}.CELDA__DECONTX\" \\\n            $f\n        \"\"\"\n\n}",
        "nb_lignes_process": 66,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.celda.decontx)\n        processParams = sampleParams.local\n        \n        def filterNumMadsThresholdsAsArguments = ''\n        def filterContaminationScoreThresholdsAsArguments = ''\n\n        if(processParams?.filters) {\n            filterNumMadsThresholdsAsArguments = processParams.filters.containsKey('numMadsThresholds') ?\n                processParams.filters.numMadsThresholds.collect({\n                    '--num-mads-threshold ' + ' ' + it \n                }).join(' ') :\n                ''\n            filterContaminationScoreThresholdsAsArguments = processParams.filters.containsKey('contaminationScoreThresholds') ?\n                processParams.filters.contaminationScoreThresholds.collect({ \n                    '--custom-threshold ' + ' ' + it\n                }).join(' ') :\n                ''\n        }\n\n        def roundToIntAsArgument = ''\n        if(processParams?.roundToInt) {\n            roundToIntAsArgument = '--round-to-int '+ processParams.roundToInt\n        }\n        def filterEmptyCells = ''\n        if(processParams?.filterEmptyCells) {\n            filterEmptyCells = '--filter-empty-cells '+ processParams.filterEmptyCells\n        }\n\n        \"\"\"\n        ${binDir}/run_decontx.R \\\n            --sample-id ${sampleId} \\\n            --seed ${params.global.seed} \\\n            ${filterNumMadsThresholdsAsArguments} \\\n            ${filterContaminationScoreThresholdsAsArguments} \\\n            ${roundToIntAsArgument} \\\n            ${filterEmptyCells} \\\n            --output-prefix \"${sampleId}.CELDA__DECONTX\" \\\n            $f\n        \"\"\"",
        "nb_lignes_script": 38,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId",
            "sampleId",
            "sampleId"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.celda.container",
            "publishDir \"${params.global.outdir}/data/${moduleName}\", mode: 'link'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__POPSCLE__DSC_PILEUP": {
        "name_process": "SC__POPSCLE__DSC_PILEUP",
        "string_process": "\nprocess SC__POPSCLE__DSC_PILEUP {\n\n    container params.tools.popscle.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId), path(f)\n        file vcf\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}_dsc-pileup*.gz\")\n\n    script:\n        \"\"\"\n        popscle dsc-pileup \\\n            --sam ${f} \\\n            ${toolParams?.barcode_tag ? '--tag-group ' +  toolParams.barcode_tag : ''} \\\n            --vcf ${vcf} \\\n            --out ${sampleId}_dsc-pileup\n        \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        popscle dsc-pileup \\\n            --sam ${f} \\\n            ${toolParams?.barcode_tag ? '--tag-group ' +  toolParams.barcode_tag : ''} \\\n            --vcf ${vcf} \\\n            --out ${sampleId}_dsc-pileup\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "vcf"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.popscle.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__POPSCLE__PREFILTER_DSC_PILEUP": {
        "name_process": "SC__POPSCLE__PREFILTER_DSC_PILEUP",
        "string_process": "\nprocess SC__POPSCLE__PREFILTER_DSC_PILEUP {\n\n    container params.tools.popscle.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'\n    label 'compute_resources__cpu'\n\n    input:\n        tuple val(sampleId),\n              path(bam),\n              path(barcodes)\n        file vcf\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}_filtered_possorted_genome_bam.bam\")\n\n    script:\n        \"\"\"\n        filter_bam_file_for_popscle_dsc_pileup.sh \\\n            ${bam} \\\n            ${barcodes} \\\n            ${vcf} \\\n            ${sampleId}_filtered_possorted_genome_bam.bam \\\n            ${toolParams?.barcode_tag ? toolParams.barcode_tag : ''}\n        \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "        \"\"\"\n        filter_bam_file_for_popscle_dsc_pileup.sh \\\n            ${bam} \\\n            ${barcodes} \\\n            ${vcf} \\\n            ${sampleId}_filtered_possorted_genome_bam.bam \\\n            ${toolParams?.barcode_tag ? toolParams.barcode_tag : ''}\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "bam",
            "barcodes",
            "vcf"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.popscle.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "EDIRECT__SRAID_TO_SAMPLENAME": {
        "name_process": "EDIRECT__SRAID_TO_SAMPLENAME",
        "string_process": "\nprocess EDIRECT__SRAID_TO_SAMPLENAME {\n    \n    container params.edirect.container\n    label 'compute_resources__default'\n    maxForks 1\n\n    input:\n        val(sraId)\n    output:\n        tuple val(sraId), stdout\n    shell:\n        \"\"\"\n        esearch -db sra -query ${sraId} \\\n           | efetch --format native \\\n           | sed -r 's/(.*)<TITLE>(.*)<\\\\/TITLE>(.*)/\\\\2/' \\\n           | grep \"^[^<;]\" \\\n           | tr -d '\\\\n' \n        \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "        \"\"\"\n        esearch -db sra -query ${sraId} \\\n           | efetch --format native \\\n           | sed -r 's/(.*)<TITLE>(.*)<\\\\/TITLE>(.*)/\\\\2/' \\\n           | grep \"^[^<;]\" \\\n           | tr -d '\\\\n' \n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "QResearch",
            "eFetch Snp"
        ],
        "tools_url": [
            "https://bio.tools/QResearch",
            "https://bio.tools/efetch_snp"
        ],
        "tools_dico": [
            {
                "name": "QResearch",
                "uri": "https://bio.tools/QResearch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatric medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "https://en.wikipedia.org/wiki/Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3283",
                                    "term": "Anonymisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3283",
                                    "term": "Data anonymisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "General practice database for research.",
                "homepage": "http://www.qresearch.org"
            },
            {
                "name": "eFetch Snp",
                "uri": "https://bio.tools/efetch_snp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Get SNPs information given SNP ID list.",
                "homepage": "http://www.ncbi.nlm.nih.gov/corehtml/query/static/efetchseq_help.html"
            }
        ],
        "inputs": [
            "sraId"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sraId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.edirect.container",
            "label 'compute_resources__default'",
            "maxForks 1"
        ],
        "when": "",
        "stub": ""
    },
    "AGGR_MULTI_RUNS_FEATURES": {
        "name_process": "AGGR_MULTI_RUNS_FEATURES",
        "string_process": "\nprocess AGGR_MULTI_RUNS_FEATURES {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_cistarget/\", mode: 'link', overwrite: true\n                                                                                                                              \n                                                                                                 \n    label 'compute_resources__scenic_multiruns'\n\n    input:\n\t\ttuple val(sampleId), path(f)\n\t\tval type\n\n    output:\n    \ttuple val(sampleId), path(\"multi_runs_features_${type}.${output_format_ext}${compression_ext}\")\n\n    script:\n\t\toutput_format = processParams.output_format\n\t\toutput_format_ext = output_format\n\t\tif(output_format == 'pickle') {\n\t\toutput_format_ext = 'pkl'\n\t\t}\n\t\tcompression = processParams.compression\n\t\tcompression_ext = ''\n\t\tif(compression == 'gzip') {\n\t\tcompression_ext = '.gz'\n\t\t}\n\t\t\"\"\"\n\t\t${binDir}aggregate_multi_runs_features.py \\\n\t\t\t${f} \\\n\t\t\t--output \"multi_runs_features_${type}.${output_format_ext}${compression_ext}\" \\\n\t\t\t--output-format ${output_format} \\\n\t\t\t--use-chunking ${processParams.use_chunking}\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 35,
        "string_script": "\t\toutput_format = processParams.output_format\n\t\toutput_format_ext = output_format\n\t\tif(output_format == 'pickle') {\n\t\toutput_format_ext = 'pkl'\n\t\t}\n\t\tcompression = processParams.compression\n\t\tcompression_ext = ''\n\t\tif(compression == 'gzip') {\n\t\tcompression_ext = '.gz'\n\t\t}\n\t\t\"\"\"\n\t\t${binDir}aggregate_multi_runs_features.py \\\n\t\t\t${f} \\\n\t\t\t--output \"multi_runs_features_${type}.${output_format_ext}${compression_ext}\" \\\n\t\t\t--output-format ${output_format} \\\n\t\t\t--use-chunking ${processParams.use_chunking}\n\t\t\"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_cistarget/\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic_multiruns'"
        ],
        "when": "",
        "stub": ""
    },
    "ARBORETO_WITH_MULTIPROCESSING": {
        "name_process": "ARBORETO_WITH_MULTIPROCESSING",
        "string_process": "\nprocess ARBORETO_WITH_MULTIPROCESSING {\n\n    cache 'deep'\n    container toolParams.container\n                                                                                                                                                                                                 \n    label 'compute_resources__scenic_grn'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(filteredLoom), \\\n            val(runId)\n        file tfs\n\n    output:\n        tuple val(sampleId), \\\n        file(filteredLoom), \\\n        file(\"${outputFileName}\"), \\\n        val(runId)\n\n    script:\n        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? sampleId + \"__run_\" + runId +\"__adj.tsv.gz\" : sampleId + \"__adj.tsv.gz\"\n        seed = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? (params.global.seed + runId) : params.global.seed\n        \"\"\"\n        arboreto_with_multiprocessing.py \\\n            $filteredLoom \\\n            $tfs \\\n            --output ${outputFileName} \\\n            --num_workers ${task.cpus} \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n            --method ${processParams.algorithm} \\\n            --seed ${seed}\n        \"\"\"\n\n}",
        "nb_lignes_process": 37,
        "string_script": "        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? sampleId + \"__run_\" + runId +\"__adj.tsv.gz\" : sampleId + \"__adj.tsv.gz\"\n        seed = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? (params.global.seed + runId) : params.global.seed\n        \"\"\"\n        arboreto_with_multiprocessing.py \\\n            $filteredLoom \\\n            $tfs \\\n            --output ${outputFileName} \\\n            --num_workers ${task.cpus} \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n            --method ${processParams.algorithm} \\\n            --seed ${seed}\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "Seed"
        ],
        "tools_url": [
            "https://bio.tools/seed-eco"
        ],
        "tools_dico": [
            {
                "name": "Seed",
                "uri": "https://bio.tools/seed-eco",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0610",
                            "term": "Ecology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3365",
                            "term": "Data architecture, analysis and design"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An R/Shiny package for visualizing ecological data. It provides a visual interface for generating a wide variety of plots, including histograms, scatterplots, bar plots, stacked bar plots, PCoA plots, cluster dendrograms, and heatmaps.",
                "homepage": "https://github.com/danlbek/Seed"
            }
        ],
        "inputs": [
            "sampleId",
            "filteredLoom",
            "runId",
            "tfs"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId",
            "filteredLoom",
            "runId"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "label 'compute_resources__scenic_grn'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__HARMONY__HARMONY_MATRIX": {
        "name_process": "SC__HARMONY__HARMONY_MATRIX",
        "string_process": "\nprocess SC__HARMONY__HARMONY_MATRIX {\n    \n    container params.tools.harmony.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__HARMONY__HARMONY_MATRIX.tsv\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.harmony)\n\t\tprocessParams = sampleParams.local\n        varsUseAsArguments = processParams.varsUse.collect({ '--vars-use' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}run_harmony.R \\\n            ${f} \\\n            --seed ${params.global.seed} \\\n            ${varsUseAsArguments} \\\n            ${processParams?.theta ? \"--theta \"+ processParams.theta : \"\" } \\\n            ${processParams?.lambda ? \"--lambda \"+ processParams.lambda : \"\" } \\\n            ${processParams?.epsilonHarmony ? \"--epsilon-harmony \"+ processParams.epsilonHarmony : \"\" } \\\n            --output-prefix \"${sampleId}.SC__HARMONY__HARMONY_MATRIX\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 31,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.harmony)\n\t\tprocessParams = sampleParams.local\n        varsUseAsArguments = processParams.varsUse.collect({ '--vars-use' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}run_harmony.R \\\n            ${f} \\\n            --seed ${params.global.seed} \\\n            ${varsUseAsArguments} \\\n            ${processParams?.theta ? \"--theta \"+ processParams.theta : \"\" } \\\n            ${processParams?.lambda ? \"--lambda \"+ processParams.lambda : \"\" } \\\n            ${processParams?.epsilonHarmony ? \"--epsilon-harmony \"+ processParams.epsilonHarmony : \"\" } \\\n            --output-prefix \"${sampleId}.SC__HARMONY__HARMONY_MATRIX\"\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.harmony.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__DETECT_REPAIR_BARCODE_SYNTHESIS_ERRORS": {
        "name_process": "SC__DROP_SEQ_TOOLS__DETECT_REPAIR_BARCODE_SYNTHESIS_ERRORS",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__DETECT_REPAIR_BARCODE_SYNTHESIS_ERRORS {\n\n\tcontainer params.tools.dropseqtools.container\n\tpublishDir \"${params.global.outdir}/02.map\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n    \ttuple val(sample), path(bam)\n\n\toutput:\n\t\ttuple val(sample), path(\"*.final_cleaned.bam\"), emit: bam\n\t\ttuple file(\"*.synthesis_stats.txt\"), emit: stats\n\t\t                                                                  \n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.detect_repair_barcode_synthesis_errors)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\tDetectBeadSynthesisErrors \\\n\t\t\tI=${bam} \\\n\t\t\tO=${sample}.final_cleaned.bam \\\n\t\t\tOUTPUT_STATS=${sample}.synthesis_stats.txt \\\n\t\t\tSUMMARY=${sample}.synthesis_stats.summary.txt \\\n\t\t\tNUM_BARCODES=${processParams.numBarcodes * 2} \\\n\t\t\tPRIMER_SEQUENCE=${processParams.primerSequence} \\\n\t\t\tTMP_DIR=$DWMAX/tmp\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.detect_repair_barcode_synthesis_errors)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\tDetectBeadSynthesisErrors \\\n\t\t\tI=${bam} \\\n\t\t\tO=${sample}.final_cleaned.bam \\\n\t\t\tOUTPUT_STATS=${sample}.synthesis_stats.txt \\\n\t\t\tSUMMARY=${sample}.synthesis_stats.summary.txt \\\n\t\t\tNUM_BARCODES=${processParams.numBarcodes * 2} \\\n\t\t\tPRIMER_SEQUENCE=${processParams.primerSequence} \\\n\t\t\tTMP_DIR=$DWMAX/tmp\n\t\t\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "TMPD"
        ],
        "tools_url": [
            "https://bio.tools/tmpd"
        ],
        "tools_dico": [
            {
                "name": "TMPD",
                "uri": "https://bio.tools/tmpd",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plants"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Botany"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Tobacco Markers & Primers Database.",
                "homepage": "http://biodb.sdau.edu.cn/tmpd/index.html"
            }
        ],
        "inputs": [
            "sample",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/02.map\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__ANNOTATE_BY_CELL_METADATA": {
        "name_process": "SC__ANNOTATE_BY_CELL_METADATA",
        "string_process": "\nprocess SC__ANNOTATE_BY_CELL_METADATA {\n\n    container params.tools.scanpy.container\n    publishDir \"${getPublishDir(params.global.outdir,tool)}\", mode: \"${getMode(tool)}\", overwrite: true\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            path(metadata)\n                                             \n        val(tool)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.${toolTag}SC__ANNOTATE_BY_CELL_METADATA.h5ad\")\n\n    script:\n        def sampleParams = params.parseConfig(\n            sampleId,\n            params.global,\n            isParamNull(tool) ? params.utils.cell_annotate : getToolParams(params.tools, tool)[\"cell_annotate\"]\n        )\n\t\tprocessParams = sampleParams.local\n        toolTag = isParamNull(tool) ? '' : tool.toUpperCase() + '.'\n        annotationColumnNamesAsArguments = processParams.containsKey(\"annotationColumnNames\") ?\n            processParams.annotationColumnNames.collect({ '--annotation-column-name' + ' ' + it }).join(' ')\n            : ''\n        \"\"\"\n        ${binDir}/sc_h5ad_annotate_by_cell_metadata.py \\\n            ${processParams.containsKey('method') ? '--method ' + processParams.method : ''} \\\n            --index-column-name ${processParams.indexColumnName} \\\n            --sample-id ${sampleId} \\\n            ${processParams.containsKey('sampleColumnName') ? '--sample-column-name ' + processParams.sampleColumnName : ''} \\\n            ${annotationColumnNamesAsArguments} \\\n            $f \\\n            ${metadata} \\\n            --output \"${sampleId}.${toolTag}SC__ANNOTATE_BY_CELL_METADATA.h5ad\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 42,
        "string_script": "        def sampleParams = params.parseConfig(\n            sampleId,\n            params.global,\n            isParamNull(tool) ? params.utils.cell_annotate : getToolParams(params.tools, tool)[\"cell_annotate\"]\n        )\n\t\tprocessParams = sampleParams.local\n        toolTag = isParamNull(tool) ? '' : tool.toUpperCase() + '.'\n        annotationColumnNamesAsArguments = processParams.containsKey(\"annotationColumnNames\") ?\n            processParams.annotationColumnNames.collect({ '--annotation-column-name' + ' ' + it }).join(' ')\n            : ''\n        \"\"\"\n        ${binDir}/sc_h5ad_annotate_by_cell_metadata.py \\\n            ${processParams.containsKey('method') ? '--method ' + processParams.method : ''} \\\n            --index-column-name ${processParams.indexColumnName} \\\n            --sample-id ${sampleId} \\\n            ${processParams.containsKey('sampleColumnName') ? '--sample-column-name ' + processParams.sampleColumnName : ''} \\\n            ${annotationColumnNamesAsArguments} \\\n            $f \\\n            ${metadata} \\\n            --output \"${sampleId}.${toolTag}SC__ANNOTATE_BY_CELL_METADATA.h5ad\"\n        \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "metadata",
            "tool"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${getPublishDir(params.global.outdir,tool)}\", mode: \"${getMode(tool)}\", overwrite: true",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__ANNOTATE_BY_SAMPLE_METADATA": {
        "name_process": "SC__ANNOTATE_BY_SAMPLE_METADATA",
        "string_process": "\nprocess SC__ANNOTATE_BY_SAMPLE_METADATA {\n\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__ANNOTATE_BY_SAMPLE_METADATA.${processParams.off}\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.sample_annotate)\n        processParams = sampleParams.local\n\n                              \n        methodAsArgument = ''\n        if(processParams.containsKey(\"by\")) {\n            methodAsArgument = processParams.by.containsKey('method') ? processParams.by.method : ''\n        } else {\n                                                                              \n            methodAsArgument = processParams.containsKey('type') ? processParams.type : methodAsArgument\n        }\n\n                                 \n        metadataFilePathAsArgument = getMetadataFilePath(processParams)\n\n        compIndexColumnNamesFromAdataAsArguments = ''\n        compIndexColumnNamesFromMetadataAsArguments = ''\n        annotationColumnNamesAsArguments = ''\n        if(processParams.containsKey(\"by\")) {\n            compIndexColumnNamesFromAdataAsArguments = processParams.by.containsKey('compIndexColumnNames') ?\n                processParams.by.compIndexColumnNames.collect { key, value -> return key }.collect({ '--adata-comp-index-column-name ' + ' ' + it }).join(' ') :\n                ''\n            compIndexColumnNamesFromMetadataAsArguments = processParams.by.containsKey('compIndexColumnNames') ?\n                processParams.by.compIndexColumnNames.collect { key, value -> return value }.collect({ '--metadata-comp-index-column-name ' + ' ' + it }).join(' ') :\n                ''\n            annotationColumnNamesAsArguments = processParams.by.containsKey('annotationColumnNames') ?\n                processParams.by.annotationColumnNames.collect({ '--annotation-column-name' + ' ' + it }).join(' ') :\n                ''\n        }\n\n                            \n        sampleColumnName = ''\n        if(processParams.containsKey(\"by\")) {\n            if(!processParams.by.containsKey(\"sampleColumnName\")) {\n                throw new Exception(\"VSN ERROR: Missing sampleColumnName param in params.utils.sample_annotate.by.\")\n            }\n            sampleColumnName = processParams.by.sampleColumnName\n        } else {\n            if(!processParams.containsKey(\"sampleColumnName\")) {\n                throw new Exception(\"VSN ERROR: Missing sampleColumnName param in params.utils.sample_annotate.\")\n            }\n                                                                              \n            sampleColumnName = processParams.sampleColumnName\n        }\n\n        \"\"\"\n        ${binDir}/sc_h5ad_annotate_by_sample_metadata.py \\\n            --sample-id ${sampleId} \\\n            ${methodAsArgument != '' ? '--method ' + methodAsArgument : '' } \\\n            ${metadataFilePathAsArgument != '' ? '--metadata-file-path ' + metadataFilePathAsArgument : '' } \\\n            ${'--sample-column-name ' + sampleColumnName} \\\n            ${compIndexColumnNamesFromAdataAsArguments} \\\n            ${compIndexColumnNamesFromMetadataAsArguments} \\\n            ${annotationColumnNamesAsArguments} \\\n            $f \\\n            \"${sampleId}.SC__ANNOTATE_BY_SAMPLE_METADATA.${processParams.off}\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 75,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.sample_annotate)\n        processParams = sampleParams.local\n\n                              \n        methodAsArgument = ''\n        if(processParams.containsKey(\"by\")) {\n            methodAsArgument = processParams.by.containsKey('method') ? processParams.by.method : ''\n        } else {\n                                                                              \n            methodAsArgument = processParams.containsKey('type') ? processParams.type : methodAsArgument\n        }\n\n                                 \n        metadataFilePathAsArgument = getMetadataFilePath(processParams)\n\n        compIndexColumnNamesFromAdataAsArguments = ''\n        compIndexColumnNamesFromMetadataAsArguments = ''\n        annotationColumnNamesAsArguments = ''\n        if(processParams.containsKey(\"by\")) {\n            compIndexColumnNamesFromAdataAsArguments = processParams.by.containsKey('compIndexColumnNames') ?\n                processParams.by.compIndexColumnNames.collect { key, value -> return key }.collect({ '--adata-comp-index-column-name ' + ' ' + it }).join(' ') :\n                ''\n            compIndexColumnNamesFromMetadataAsArguments = processParams.by.containsKey('compIndexColumnNames') ?\n                processParams.by.compIndexColumnNames.collect { key, value -> return value }.collect({ '--metadata-comp-index-column-name ' + ' ' + it }).join(' ') :\n                ''\n            annotationColumnNamesAsArguments = processParams.by.containsKey('annotationColumnNames') ?\n                processParams.by.annotationColumnNames.collect({ '--annotation-column-name' + ' ' + it }).join(' ') :\n                ''\n        }\n\n                            \n        sampleColumnName = ''\n        if(processParams.containsKey(\"by\")) {\n            if(!processParams.by.containsKey(\"sampleColumnName\")) {\n                throw new Exception(\"VSN ERROR: Missing sampleColumnName param in params.utils.sample_annotate.by.\")\n            }\n            sampleColumnName = processParams.by.sampleColumnName\n        } else {\n            if(!processParams.containsKey(\"sampleColumnName\")) {\n                throw new Exception(\"VSN ERROR: Missing sampleColumnName param in params.utils.sample_annotate.\")\n            }\n                                                                              \n            sampleColumnName = processParams.sampleColumnName\n        }\n\n        \"\"\"\n        ${binDir}/sc_h5ad_annotate_by_sample_metadata.py \\\n            --sample-id ${sampleId} \\\n            ${methodAsArgument != '' ? '--method ' + methodAsArgument : '' } \\\n            ${metadataFilePathAsArgument != '' ? '--metadata-file-path ' + metadataFilePathAsArgument : '' } \\\n            ${'--sample-column-name ' + sampleColumnName} \\\n            ${compIndexColumnNamesFromAdataAsArguments} \\\n            ${compIndexColumnNamesFromMetadataAsArguments} \\\n            ${annotationColumnNamesAsArguments} \\\n            $f \\\n            \"${sampleId}.SC__ANNOTATE_BY_SAMPLE_METADATA.${processParams.off}\"\n        \"\"\"",
        "nb_lignes_script": 56,
        "language_script": "bash",
        "tools": [
            "noreturn"
        ],
        "tools_url": [
            "https://bio.tools/noreturn"
        ],
        "tools_dico": [
            {
                "name": "noreturn",
                "uri": "https://bio.tools/noreturn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "Remove carriage return from ASCII files.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/noreturn.html"
            }
        ],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__H5AD_UPDATE_X_PCA": {
        "name_process": "SC__H5AD_UPDATE_X_PCA",
        "string_process": "\nprocess SC__H5AD_UPDATE_X_PCA {\n\n\tcontainer params.tools.scanpy.container\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple \\\n            val(sampleId), \\\n\t\t    path(data), \\\n            path(xPca)\n\n\toutput:\n\t\ttuple \\\n            val(sampleId), \\\n\t\t    path(\"${sampleId}.SC__H5AD_UPDATE_X_PCA.h5ad\")\n\n\tscript:\n\t\t\"\"\"\n\t\t${binDir}/sc_h5ad_update.py \\\n\t\t\t--x-pca ${xPca} \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__H5AD_UPDATE_X_PCA.h5ad\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 24,
        "string_script": "\t\t\"\"\"\n\t\t${binDir}/sc_h5ad_update.py \\\n\t\t\t--x-pca ${xPca} \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__H5AD_UPDATE_X_PCA.h5ad\"\n\t\t\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "data",
            "xPca"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__H5AD_CLEAN": {
        "name_process": "SC__H5AD_CLEAN",
        "string_process": "\nprocess SC__H5AD_CLEAN {\n\n\tcontainer params.tools.scanpy.container\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple \\\n            val(sampleId), \\\n\t\t    path(data), \\\n\t\t\tval(stashedParams)\n\n\toutput:\n\t\ttuple \\\n            val(sampleId), \\\n\t\t    path(\"${sampleId}.SC__H5AD_CLEAN.h5ad\"), \\\n\t\t\tval(stashedParams)\n\n\tscript:\n\t\t\"\"\"\n\t\t${binDir}/sc_h5ad_update.py \\\n\t\t\t--empty-x \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__H5AD_CLEAN.h5ad\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "\t\t\"\"\"\n\t\t${binDir}/sc_h5ad_update.py \\\n\t\t\t--empty-x \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__H5AD_CLEAN.h5ad\"\n\t\t\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "data",
            "stashedParams"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId",
            "stashedParams"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__H5AD_BEAUTIFY": {
        "name_process": "SC__H5AD_BEAUTIFY",
        "string_process": "\nprocess SC__H5AD_BEAUTIFY {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple \\\n            val(sampleId), \\\n\t\t    path(data), \\\n\t\t\tval(stashedParams)\n\n\toutput:\n\t\ttuple \\\n            val(sampleId), \\\n\t\t    path(\"${sampleId}.SC__H5AD_BEAUTIFY.h5ad\"), \\\n\t\t\tval(stashedParams)\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.utils.file_cleaner)\n        processParams = sampleParams.local\n\n\t\tobsColumnsToRemoveAsArgument = processParams.containsKey(\"obsColumnsToRemove\") ? \n\t\t\tprocessParams.obsColumnsToRemove.collect({ '--obs-column-to-remove' + ' ' + it }).join(' ') : \n\t\t\t''\n\t\t\"\"\"\n\t\t${binDir}/sc_h5ad_update.py \\\n\t\t\t${obsColumnsToRemoveAsArgument} \\\n\t\t\t${processParams.containsKey(\"obsColumnMapper\") ? \"--obs-column-mapper '\" + toJson(processParams.obsColumnMapper) + \"'\": ''} \\\n\t\t\t${processParams.containsKey(\"obsColumnValueMapper\") ? \"--obs-column-value-mapper '\" + toJson(processParams.obsColumnValueMapper) + \"'\": ''} \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__H5AD_BEAUTIFY.h5ad\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 34,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.utils.file_cleaner)\n        processParams = sampleParams.local\n\n\t\tobsColumnsToRemoveAsArgument = processParams.containsKey(\"obsColumnsToRemove\") ? \n\t\t\tprocessParams.obsColumnsToRemove.collect({ '--obs-column-to-remove' + ' ' + it }).join(' ') : \n\t\t\t''\n\t\t\"\"\"\n\t\t${binDir}/sc_h5ad_update.py \\\n\t\t\t${obsColumnsToRemoveAsArgument} \\\n\t\t\t${processParams.containsKey(\"obsColumnMapper\") ? \"--obs-column-mapper '\" + toJson(processParams.obsColumnMapper) + \"'\": ''} \\\n\t\t\t${processParams.containsKey(\"obsColumnValueMapper\") ? \"--obs-column-value-mapper '\" + toJson(processParams.obsColumnValueMapper) + \"'\": ''} \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__H5AD_BEAUTIFY.h5ad\"\n\t\t\"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "data",
            "stashedParams"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId",
            "stashedParams"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD__MERGE_SAM_FILES_AND_SORT": {
        "name_process": "PICARD__MERGE_SAM_FILES_AND_SORT",
        "string_process": "\nprocess PICARD__MERGE_SAM_FILES_AND_SORT {\n\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(bams)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.bwa.out.fixmate.merged.bam\")\n\n    script:\n                                                                                    \n                                            \n        \"\"\"\n        gatk MergeSamFiles \\\n            ${\"-I \"+bams.join(\" -I \")} \\\n            -O /dev/stdout \\\n        | gatk SortSam \\\n            -I /dev/stdin \\\n            -O ${sampleId}.bwa.out.fixmate.merged.bam \\\n            --SORT_ORDER queryname\n        \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "        \"\"\"\n        gatk MergeSamFiles \\\n            ${\"-I \"+bams.join(\" -I \")} \\\n            -O /dev/stdout \\\n        | gatk SortSam \\\n            -I /dev/stdin \\\n            -O ${sampleId}.bwa.out.fixmate.merged.bam \\\n            --SORT_ORDER queryname\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "sampleId",
            "bams"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER__PREPARE_FOLDER": {
        "name_process": "SC__CELLRANGER__PREPARE_FOLDER",
        "string_process": "\nprocess SC__CELLRANGER__PREPARE_FOLDER {\n\n    publishDir \"${params.global.outdir}/data/raw/cellranger_fastq_folders\", mode: 'symlink', overwrite: true\n    label 'compute_resources__minimal'\n\n    input:\n        tuple val(sampleId), val(fastqs)\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}_s*\")\n\n    script:\n        def cmd = ''\n        for(int i = 0; i < fastqs.size(); i++) {\n            cmd += \"mkdir ${sampleId}_s${i+1}; \"\n            cmd += \"ln -s ${fastqs[i].join(' ')} ${sampleId}_s${i+1}; \"\n        }\n        \"\"\"\n        $cmd\n        \"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "        def cmd = ''\n        for(int i = 0; i < fastqs.size(); i++) {\n            cmd += \"mkdir ${sampleId}_s${i+1}; \"\n            cmd += \"ln -s ${fastqs[i].join(' ')} ${sampleId}_s${i+1}; \"\n        }\n        \"\"\"\n        $cmd\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "fastqs"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/data/raw/cellranger_fastq_folders\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__minimal'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__CLUSTERING_PREFLIGHT_CHECKS": {
        "name_process": "SC__SCANPY__CLUSTERING_PREFLIGHT_CHECKS",
        "string_process": "\nprocess SC__SCANPY__CLUSTERING_PREFLIGHT_CHECKS {\n\n\tcontainer params.tools.scanpy.container\n\tlabel 'compute_resources__mem'\n\n\tinput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(f)\n\n\toutput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(f)\n\n  \tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.clustering)\n\t\tprocessParams = sampleParams.local\n\t\tmethodAsArguments = processParams?.methods ? processParams.methods.collect({ '--method' + ' ' + it }).join(' ') : '--method ' + processParams.method\n\t\tresolutionAsArguments = processParams?.resolutions ? processParams?.resolutions.collect({ '--resolution' + ' ' + it }).join(' ') : '--resolution ' + processParams.resolution\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_clustering_preflight_checks.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t${methodAsArguments} \\\n\t\t\t${resolutionAsArguments} \\\n\t\t\t$f \\\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.clustering)\n\t\tprocessParams = sampleParams.local\n\t\tmethodAsArguments = processParams?.methods ? processParams.methods.collect({ '--method' + ' ' + it }).join(' ') : '--method ' + processParams.method\n\t\tresolutionAsArguments = processParams?.resolutions ? processParams?.resolutions.collect({ '--resolution' + ' ' + it }).join(' ') : '--resolution ' + processParams.resolution\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_clustering_preflight_checks.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t${methodAsArguments} \\\n\t\t\t${resolutionAsArguments} \\\n\t\t\t$f \\\n\t\t\"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId",
            "f"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__CLUSTERING": {
        "name_process": "SC__SCANPY__CLUSTERING",
        "string_process": "\nprocess SC__SCANPY__CLUSTERING {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n  \tinput:\n    \ttuple val(sampleId), path(f)\n\n  \toutput:\n    \ttuple val(sampleId), path(\"${sampleId}.SC__SCANPY__CLUSTERING.${processParams.off}\")\n\n  \tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.clustering)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_clustering.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('resolution')) ? '--resolution ' + processParams.resolution : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__CLUSTERING.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 24,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.clustering)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_clustering.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('resolution')) ? '--resolution ' + processParams.resolution : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__CLUSTERING.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__PARAM_EXPLORE_CLUSTERING": {
        "name_process": "SC__SCANPY__PARAM_EXPLORE_CLUSTERING",
        "string_process": "\nprocess SC__SCANPY__PARAM_EXPLORE_CLUSTERING {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/data/intermediate/clustering/${isParamNull(method) ? \"default\": method.toLowerCase()}/${isParamNull(resolution) ? \"default\" : \"res_\" + resolution}\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n  \tinput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(f), \\\n\t\t\tval(stashedParams), \\\n\t\t\tval(method), \\\n\t\t\tval(resolution)\n\n  \toutput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__SCANPY__PARAM_EXPLORE_CLUSTERING.${processParams.off}\"), \\\n\t\t\tval(method), \\\n\t\t\tval(resolution)\n\n  \tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.clustering)\n\t\tprocessParams = sampleParams.local\n\t\tdef _processParams = new SC__SCANPY__CLUSTERING_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_clustering.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t${_processParams.getMethodAsArgument(method)} \\\n\t\t\t${_processParams.getResolutionAsArgument(resolution)} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__PARAM_EXPLORE_CLUSTERING.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 37,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.clustering)\n\t\tprocessParams = sampleParams.local\n\t\tdef _processParams = new SC__SCANPY__CLUSTERING_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_clustering.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t${_processParams.getMethodAsArgument(method)} \\\n\t\t\t${_processParams.getResolutionAsArgument(resolution)} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__PARAM_EXPLORE_CLUSTERING.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "stashedParams",
            "method",
            "resolution"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId",
            "method",
            "resolution"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate/clustering/${isParamNull(method) ? \"default\": method.toLowerCase()}/${isParamNull(resolution) ? \"default\" : \"res_\" + resolution}\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__NEIGHBORHOOD_GRAPH": {
        "name_process": "SC__SCANPY__NEIGHBORHOOD_GRAPH",
        "string_process": "\nprocess SC__SCANPY__NEIGHBORHOOD_GRAPH {\n\n  \tcontainer params.tools.scanpy.container\n    label 'compute_resources__mem'\n\n  \tinput:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            val(stashedParams), \\\n\t\t\tval(nPcs)\n\n\toutput:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__SCANPY__NEIGHBORHOOD_GRAPH.${processParams.off}\"), \\\n            val(stashedParams),\n\t\t\tval(nPcs)\n\n\tscript:\n        def sampleParams = params.parseConfig(\n\t\t\tsampleId,\n\t\t\tparams.global,\n\t\t\tparams.tools.scanpy.neighborhood_graph\n\t\t)\n\t\tprocessParams = sampleParams.local\n                                                                                                              \n\t\t                                                       \n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\t                                                                                               \n\t\tdef _processParams = new SC__SCANPY__NEIGHBORHOOD_GRAPH_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n        \"\"\"\n        ${binDir}/nn/sc_neighborhood_graph.py \\\n            $f \\\n            ${sampleId}.SC__SCANPY__NEIGHBORHOOD_GRAPH.${processParams.off} \\\n\t\t\t--seed ${params.global.seed} \\\n            ${(processParams.containsKey('nNeighbors')) ? '--n-neighbors ' + processParams.nNeighbors : ''} \\\n\t\t\t${_processParams.getNPcsAsArgument(nPcs)}\n        \"\"\"\n\n}",
        "nb_lignes_process": 44,
        "string_script": "        def sampleParams = params.parseConfig(\n\t\t\tsampleId,\n\t\t\tparams.global,\n\t\t\tparams.tools.scanpy.neighborhood_graph\n\t\t)\n\t\tprocessParams = sampleParams.local\n                                                                                                              \n\t\t                                                       \n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\t                                                                                               \n\t\tdef _processParams = new SC__SCANPY__NEIGHBORHOOD_GRAPH_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n        \"\"\"\n        ${binDir}/nn/sc_neighborhood_graph.py \\\n            $f \\\n            ${sampleId}.SC__SCANPY__NEIGHBORHOOD_GRAPH.${processParams.off} \\\n\t\t\t--seed ${params.global.seed} \\\n            ${(processParams.containsKey('nNeighbors')) ? '--n-neighbors ' + processParams.nNeighbors : ''} \\\n\t\t\t${_processParams.getNPcsAsArgument(nPcs)}\n        \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "stashedParams",
            "nPcs"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId",
            "nPcs"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__FILE_CONVERTER": {
        "name_process": "SC__FILE_CONVERTER",
        "string_process": "\nprocess SC__FILE_CONVERTER {\n\n    cache 'deep'\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    container \"${getConverterContainer(params,converterToUse)}\"\n    label 'compute_resources__mem'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            val(inputDataType), \\\n            val(outputDataType), \\\n            val(group)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__FILE_CONVERTER.${outputExtension}\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.file_converter)\n        processParams = sampleParams.local\n\n        switch(inputDataType) {\n            case \"10x_cellranger_mex\":\n                                          \n            break;\n            case \"10x_cellranger_mex_outs\":\n                                                                                                                                                 \n                                                                         \n                cellranger_outs_v2_mex = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_gene_bc_matrices/\")\n                cellranger_outs_v3_mex = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_feature_bc_matrix/\")\n                cellRangerData = detectCellRangerVersionData(cellranger_outs_v2_mex, cellranger_outs_v3_mex)\n                f = cellRangerData.path\n                inputDataType = \"10x_cellranger_mex\"\n            break;\n            case \"10x_cellranger_h5\":\n                                          \n            break;\n            case \"10x_cellranger_h5_outs\":\n                                                                         \n                cellranger_outs_v2_h5 = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_gene_bc_matrices.h5\")\n                cellranger_outs_v3_h5 = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_feature_bc_matrix.h5\")\n                cellRangerData = detectCellRangerVersionData(cellranger_outs_v2_h5, cellranger_outs_v3_h5)\n                f = cellRangerData.path\n                inputDataType = \"10x_cellranger_h5\"\n            case \"10x_atac_cellranger_mex_outs\":\n                                          \n            break;\n            case \"csv\":\n            case \"tsv\":\n            case \"h5ad\":\n            case \"loom\":\n            case \"seurat_rds\":\n                                          \n            break;\n            \n            default:\n                throw new Exception(\"VSN ERROR: The given input format ${inputDataType} is not recognized.\")\n            break;\n        }\n\n                                                                              \n        converterToUse = getConverter(\n            inputDataType,\n            outputDataType\n        )\n        outputExtension = getOutputExtension(outputDataType)\n\n        switch(converterToUse) {\n            case \"cistopic\":\n                \"\"\"\n                ${binDir}/create_cistopic_object.R \\\n                    --tenx_path ${f} \\\n                    --sampleId ${sampleId} \\\n                    --output ${sampleId}.SC__FILE_CONVERTER.${outputExtension}\n                \"\"\"\n                break;\n            case \"r\":\n                runRConverter(\n                    \"SC__FILE_CONVERTER\",\n                    processParams,\n                    sampleId,\n                    inputDataType,\n                    outputDataType,\n                    outputExtension,\n                    group,\n                    f\n                )\n                break;\n            case \"python\":\n                runPythonConverter(\n                    processParams,\n                    sampleId,\n                    inputDataType,\n                    outputDataType,\n                    outputExtension,\n                    group,\n                    f\n                )\n                break;\n            default:\n                throw new Exception(\"VSN ERROR: Unrecognized file converter.\")\n        }\n\n}",
        "nb_lignes_process": 106,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.file_converter)\n        processParams = sampleParams.local\n\n        switch(inputDataType) {\n            case \"10x_cellranger_mex\":\n                                          \n            break;\n            case \"10x_cellranger_mex_outs\":\n                                                                                                                                                 \n                                                                         \n                cellranger_outs_v2_mex = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_gene_bc_matrices/\")\n                cellranger_outs_v3_mex = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_feature_bc_matrix/\")\n                cellRangerData = detectCellRangerVersionData(cellranger_outs_v2_mex, cellranger_outs_v3_mex)\n                f = cellRangerData.path\n                inputDataType = \"10x_cellranger_mex\"\n            break;\n            case \"10x_cellranger_h5\":\n                                          \n            break;\n            case \"10x_cellranger_h5_outs\":\n                                                                         \n                cellranger_outs_v2_h5 = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_gene_bc_matrices.h5\")\n                cellranger_outs_v3_h5 = file(\"${f.toRealPath()}/${processParams.useFilteredMatrix ? \"filtered\" : \"raw\"}_feature_bc_matrix.h5\")\n                cellRangerData = detectCellRangerVersionData(cellranger_outs_v2_h5, cellranger_outs_v3_h5)\n                f = cellRangerData.path\n                inputDataType = \"10x_cellranger_h5\"\n            case \"10x_atac_cellranger_mex_outs\":\n                                          \n            break;\n            case \"csv\":\n            case \"tsv\":\n            case \"h5ad\":\n            case \"loom\":\n            case \"seurat_rds\":\n                                          \n            break;\n            \n            default:\n                throw new Exception(\"VSN ERROR: The given input format ${inputDataType} is not recognized.\")\n            break;\n        }\n\n                                                                              \n        converterToUse = getConverter(\n            inputDataType,\n            outputDataType\n        )\n        outputExtension = getOutputExtension(outputDataType)\n\n        switch(converterToUse) {\n            case \"cistopic\":\n                \"\"\"\n                ${binDir}/create_cistopic_object.R \\\n                    --tenx_path ${f} \\\n                    --sampleId ${sampleId} \\\n                    --output ${sampleId}.SC__FILE_CONVERTER.${outputExtension}\n                \"\"\"\n                break;\n            case \"r\":\n                runRConverter(\n                    \"SC__FILE_CONVERTER\",\n                    processParams,\n                    sampleId,\n                    inputDataType,\n                    outputDataType,\n                    outputExtension,\n                    group,\n                    f\n                )\n                break;\n            case \"python\":\n                runPythonConverter(\n                    processParams,\n                    sampleId,\n                    inputDataType,\n                    outputDataType,\n                    outputExtension,\n                    group,\n                    f\n                )\n                break;\n            default:\n                throw new Exception(\"VSN ERROR: Unrecognized file converter.\")\n        }",
        "nb_lignes_script": 83,
        "language_script": "bash",
        "tools": [
            "CASE",
            "BreakSeq"
        ],
        "tools_url": [
            "https://bio.tools/CASE",
            "https://bio.tools/breakseq"
        ],
        "tools_dico": [
            {
                "name": "CASE",
                "uri": "https://bio.tools/CASE",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3559",
                                    "term": "Ontology visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3559",
                                    "term": "Ontology browsing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Advancing Coordinated Cyber-investigations and Tool Interoperability using a Community Developed Specification Language.\n\nSource files for the CASE website.\n\nAPI used for instantiating CASE objects (includes ontological verification and type checking).\n\nCyber-investigation Analysis Standard Expression (CASE).\n\nRead the CASE Wiki tab to learn everything you need to know about the Cyber-investigation Analysis Standard Expression (CASE) ontology. For learning about the Unified Cyber Ontology, CASE's parent, see UCO.\n\n\"@vocab\": \"http://case.example.org/core#\",.\n\nDET ER DINE PENGER DET DREIER SEG OM...\n\nVi er ikke st\ufffdrst, men garanterer effektiv behandling.\n\nLast ned v\ufffdr brosjyre i PDF format.\n\n||| COMMON LINK WITH (PUB. & NAME DIFFERENT) bio.tools/pymzml (GITHUB.COM).\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'UCO', 'cyber-investigation', 'cyber-investigations', 'plaso'",
                "homepage": "http://CASE.as"
            },
            {
                "name": "BreakSeq",
                "uri": "https://bio.tools/breakseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Database of known human breakpoint junctions and software to search short reads against them.",
                "homepage": "http://sv.gersteinlab.org/breakseq/"
            }
        ],
        "inputs": [
            "sampleId",
            "f",
            "inputDataType",
            "outputDataType",
            "group"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "container \"${getConverterContainer(params,converterToUse)}\"",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__FILE_CONVERTER_FROM_SCE": {
        "name_process": "SC__FILE_CONVERTER_FROM_SCE",
        "string_process": "\nprocess SC__FILE_CONVERTER_FROM_SCE {\n\n    cache 'deep'\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    container \"${getConverterContainer(params,converterToUse)}\"\n    label 'compute_resources__mem'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            val(group)\n        val(outputDataType)\n        val(mainLayer)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__FILE_CONVERTER_FROM_SCE.${outputDataType}\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.file_converter)\n        processParams = sampleParams.local\n        def _outputDataType = outputDataType\n        converterToUse = getConverter(\n            \"sce_rds\",\n            _outputDataType\n        )\n        def outputExtension = getOutputExtension(_outputDataType)\n\n        runRConverter(\n            \"SC__FILE_CONVERTER_FROM_SCE\",\n            processParams,\n            sampleId,\n            \"sce_rds\",\n            _outputDataType,\n            outputExtension,\n            group,\n            f,\n            mainLayer\n        )\n\n}",
        "nb_lignes_process": 42,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.file_converter)\n        processParams = sampleParams.local\n        def _outputDataType = outputDataType\n        converterToUse = getConverter(\n            \"sce_rds\",\n            _outputDataType\n        )\n        def outputExtension = getOutputExtension(_outputDataType)\n\n        runRConverter(\n            \"SC__FILE_CONVERTER_FROM_SCE\",\n            processParams,\n            sampleId,\n            \"sce_rds\",\n            _outputDataType,\n            outputExtension,\n            group,\n            f,\n            mainLayer\n        )",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "group",
            "outputDataType",
            "mainLayer"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "container \"${getConverterContainer(params,converterToUse)}\"",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__FILE_CONCATENATOR": {
        "name_process": "SC__FILE_CONCATENATOR",
        "string_process": "\nprocess SC__FILE_CONCATENATOR {\n\n    cache 'deep'\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n    input:\n        file(\"*\")\n\n    output:\n        tuple val(params.global.project_name), path(\"${params.global.project_name}.SC__FILE_CONCATENATOR.${processParams.off}\")\n\n    script:\n        processParams = params.utils.file_concatenator\n        \"\"\"\n        ${binDir}/sc_file_concatenator.py \\\n            --file-format $processParams.off \\\n            ${(processParams.containsKey('join')) ? '--join ' + processParams.join : ''} \\\n            --output \"${params.global.project_name}.SC__FILE_CONCATENATOR.${processParams.off}\" *\n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        processParams = params.utils.file_concatenator\n        \"\"\"\n        ${binDir}/sc_file_concatenator.py \\\n            --file-format $processParams.off \\\n            ${(processParams.containsKey('join')) ? '--join ' + processParams.join : ''} \\\n            --output \"${params.global.project_name}.SC__FILE_CONCATENATOR.${processParams.off}\" *\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "params"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__PUBLISH": {
        "name_process": "SC__PUBLISH",
        "string_process": "\nprocess SC__PUBLISH {\n\n    publishDir \\\n        \"${getPublishDir(params.global.outdir,toolName)}\", \\\n        mode: \"${params.utils.publish?.mode ? params.utils.publish.mode: 'link'}\"\n\n    label 'compute_resources__minimal'\n    \n    input:\n        tuple \\\n            val(tag), \\\n            path(f), \\\n            val(stashedParams)\n        val(fileOutputSuffix)\n        val(toolName)\n        val(isParameterExplorationModeOn)\n\n    output:\n        tuple \\\n            val(tag), \\\n            path(outputFileName), \\\n            val(stashedParams)\n\n    script:\n        outputFileName = getOutputFileName(\n            params,\n            tag,\n            f,\n            fileOutputSuffix,\n            isParameterExplorationModeOn,\n            stashedParams\n        )\n        \"\"\"\n        # In case f and outputFileName are colliding, rename to f to dummy tmp filename\n        mv ${f} tmp\n        # FIXME: should avoid copying data (currently it's the only option to work without causing #317 and #345)\n        cp -rL tmp \"${outputFileName}\"\n        \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "        outputFileName = getOutputFileName(\n            params,\n            tag,\n            f,\n            fileOutputSuffix,\n            isParameterExplorationModeOn,\n            stashedParams\n        )\n        \"\"\"\n        # In case f and outputFileName are colliding, rename to f to dummy tmp filename\n        mv ${f} tmp\n        # FIXME: should avoid copying data (currently it's the only option to work without causing #317 and #345)\n        cp -rL tmp \"${outputFileName}\"\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tag",
            "f",
            "stashedParams",
            "fileOutputSuffix",
            "toolName",
            "isParameterExplorationModeOn"
        ],
        "nb_inputs": 6,
        "outputs": [
            "tag",
            "outputFileName",
            "stashedParams"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${getPublishDir(params.global.outdir,toolName)}\", mode: \"${params.utils.publish?.mode ? params.utils.publish.mode: 'link'}\"",
            "label 'compute_resources__minimal'"
        ],
        "when": "",
        "stub": ""
    },
    "SIMPLE_PUBLISH": {
        "name_process": "SIMPLE_PUBLISH",
        "string_process": "\nprocess SIMPLE_PUBLISH {\n\n    publishDir \\\n        \"${getPublishDir(params.global.outdir,toolName)}\", \\\n        mode: \"${params.utils.publish?.mode ? params.utils.publish.mode: 'link'}\", \\\n        saveAs: { filename -> \"${outputFileName}\" }\n\n    label 'compute_resources__minimal'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f, stageAs: 'input_file')\n        val(outputFileSuffix)\n        val(toolName)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(outputFileName)\n\n    script:\n        outputFileName = \"${sampleId}${outputFileSuffix}\"\n        \"\"\"\n        if [ ! -f ${outputFileName} ]; then\n            ln -s input_file \"${outputFileName}\"\n        fi\n        \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "        outputFileName = \"${sampleId}${outputFileSuffix}\"\n        \"\"\"\n        if [ ! -f ${outputFileName} ]; then\n            ln -s input_file \"${outputFileName}\"\n        fi\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "outputFileSuffix",
            "toolName"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId",
            "outputFileName"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${getPublishDir(params.global.outdir,toolName)}\", mode: \"${params.utils.publish?.mode ? params.utils.publish.mode: 'link'}\", saveAs: { filename -> \"${outputFileName}\" }",
            "label 'compute_resources__minimal'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD__CREATE_SEQUENCE_DICTIONARY": {
        "name_process": "PICARD__CREATE_SEQUENCE_DICTIONARY",
        "string_process": "\nprocess PICARD__CREATE_SEQUENCE_DICTIONARY {\n\n    container params.tools.picard.container\n    publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        file(genome)\n        file(tmpDir)\n    \n    output:\n        file \"${genome.baseName}.dict\"\n\n    script:\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                CreateSequenceDictionary \\\n                    R=${genome} \\\n                    O=${genome.baseName}.dict\n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                CreateSequenceDictionary \\\n                    R=${genome} \\\n                    O=${genome.baseName}.dict\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome",
            "tmpDir"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.picard.container",
            "publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__UTILS__EXTRACT_FEATURE_METADATA": {
        "name_process": "SC__UTILS__EXTRACT_FEATURE_METADATA",
        "string_process": "\nprocess SC__UTILS__EXTRACT_FEATURE_METADATA {\n\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId), path(f)\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}.SC__UTILS__EXTRACT_FEATURE_METADATA.tsv\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.extract_feature_metadata)\n\t\tprocessParams = sampleParams.local\n        columnNamesAsArguments = processParams.columnNames.collect({ '--column-name' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}/sc_h5ad_extract_metadata.py \\\n            --axis feature \\\n            ${columnNamesAsArguments} \\\n            $f \\\n            \"${sampleId}.SC__UTILS__EXTRACT_FEATURE_METADATA.tsv\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 24,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.extract_feature_metadata)\n\t\tprocessParams = sampleParams.local\n        columnNamesAsArguments = processParams.columnNames.collect({ '--column-name' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}/sc_h5ad_extract_metadata.py \\\n            --axis feature \\\n            ${columnNamesAsArguments} \\\n            $f \\\n            \"${sampleId}.SC__UTILS__EXTRACT_FEATURE_METADATA.tsv\"\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__BATCH_EFFECT_CORRECTION": {
        "name_process": "SC__SCANPY__BATCH_EFFECT_CORRECTION",
        "string_process": "\nprocess SC__SCANPY__BATCH_EFFECT_CORRECTION {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n  \tinput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(f), \\\n\t\t\tval(stashedParams)\n\n  \toutput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__SCANPY__BATCH_EFFECT_CORRECTION.${processParams.off}\"), \\\n\t\t\tval(stashedParams)\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.batch_effect_correct)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}aggregate/sc_batch_effect_correction.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t--output-file \"${sampleId}.SC__SCANPY__BATCH_EFFECT_CORRECTION.${processParams.off}\" \\\n\t\t\t${(processParams.containsKey('key')) ? '--key ' + processParams.key : ''} \\\n\t\t\t${(processParams.containsKey('batchKey')) ? '--batch-key ' + processParams.batchKey : ''} \\\n\t\t\t${(processParams.containsKey('nPcs')) ? '--n-pcs ' + processParams.nPcs : ''} \\\n\t\t\t${(processParams.containsKey('k')) ? '--k ' + processParams.k : ''} \\\n\t\t\t${(processParams.containsKey('varIndex')) ? '--var-index ' + processParams.varIndex : ''} \\\n\t\t\t${(processParams.containsKey('varSubset')) ? '--var-subset ' + processParams.varSubset : ''} \\\n            --n-jobs ${task.cpus} \\\n\t\t\t${(processParams.containsKey('neighborsWithinBatch')) ? '--neighbors-within-batch ' + processParams.neighborsWithinBatch : ''} \\\n\t\t\t${(processParams.containsKey('trim')) ? '--trim ' + processParams.trim : ''} \\\n\t\t\t$f\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 37,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.batch_effect_correct)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}aggregate/sc_batch_effect_correction.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t--output-file \"${sampleId}.SC__SCANPY__BATCH_EFFECT_CORRECTION.${processParams.off}\" \\\n\t\t\t${(processParams.containsKey('key')) ? '--key ' + processParams.key : ''} \\\n\t\t\t${(processParams.containsKey('batchKey')) ? '--batch-key ' + processParams.batchKey : ''} \\\n\t\t\t${(processParams.containsKey('nPcs')) ? '--n-pcs ' + processParams.nPcs : ''} \\\n\t\t\t${(processParams.containsKey('k')) ? '--k ' + processParams.k : ''} \\\n\t\t\t${(processParams.containsKey('varIndex')) ? '--var-index ' + processParams.varIndex : ''} \\\n\t\t\t${(processParams.containsKey('varSubset')) ? '--var-subset ' + processParams.varSubset : ''} \\\n            --n-jobs ${task.cpus} \\\n\t\t\t${(processParams.containsKey('neighborsWithinBatch')) ? '--neighbors-within-batch ' + processParams.neighborsWithinBatch : ''} \\\n\t\t\t${(processParams.containsKey('trim')) ? '--trim ' + processParams.trim : ''} \\\n\t\t\t$f\n\t\t\"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "stashedParams"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId",
            "stashedParams"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__STAR__UNLOAD_GENOME": {
        "name_process": "SC__STAR__UNLOAD_GENOME",
        "string_process": "\nprocess SC__STAR__UNLOAD_GENOME {\n\n\tcontainer params.tools.star.container\n    label 'compute_resources__default'\n\n\tinput:\n\t\tfile(transcriptome)\n\t\tval allDone\n\n\tscript:\n\t\t\"\"\"\n\t\techo \"--genomeDir ${transcriptome}\"\n\t\tSTAR \\\n\t\t\t--genomeLoad Remove \\\n\t\t\t--genomeDir ${transcriptome}\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 17,
        "string_script": "\t\t\"\"\"\n\t\techo \"--genomeDir ${transcriptome}\"\n\t\tSTAR \\\n\t\t\t--genomeLoad Remove \\\n\t\t\t--genomeDir ${transcriptome}\n\t\t\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "transcriptome",
            "allDone"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.star.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__TAG_UNALIGNED_BAM_WITH_CELLBARCODE": {
        "name_process": "SC__DROP_SEQ_TOOLS__TAG_UNALIGNED_BAM_WITH_CELLBARCODE",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__TAG_UNALIGNED_BAM_WITH_CELLBARCODE {\n\n\tcontainer params.tools.dropseqtools.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n    \ttuple val(sample), path(bam)\n\n\toutput:\n\t\ttuple val(sample), path('*.unaligned_tagged_Cell.bam'), emit: bam\n\t\ttuple file('*.unaligned_tagged_Cellular.bam_summary.txt'), emit: report\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.tag_unaligned_bam_with_cellbarcode)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\tTagBamWithReadSequenceExtended \\\n\t\t\tINPUT=${bam} \\\n\t\t\tOUTPUT=${sample}.unaligned_tagged_Cell.bam \\\n\t\t\tSUMMARY=${sample}.unaligned_tagged_Cellular.bam_summary.txt \\\n\t\t\tBASE_RANGE=${processParams.baseRange} \\\n\t\t\tBASE_QUALITY=${processParams.baseQuality} \\\n\t\t\tBARCODED_READ=${processParams.barcodedRead} \\\n\t\t\tDISCARD_READ=${processParams.discardRead} \\\n\t\t\tTAG_NAME=${processParams.barcodeTagName} \\\n\t\t\tNUM_BASES_BELOW_QUALITY=${processParams.numBasesBelowQuality}        \n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 29,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.tag_unaligned_bam_with_cellbarcode)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\tTagBamWithReadSequenceExtended \\\n\t\t\tINPUT=${bam} \\\n\t\t\tOUTPUT=${sample}.unaligned_tagged_Cell.bam \\\n\t\t\tSUMMARY=${sample}.unaligned_tagged_Cellular.bam_summary.txt \\\n\t\t\tBASE_RANGE=${processParams.baseRange} \\\n\t\t\tBASE_QUALITY=${processParams.baseQuality} \\\n\t\t\tBARCODED_READ=${processParams.barcodedRead} \\\n\t\t\tDISCARD_READ=${processParams.discardRead} \\\n\t\t\tTAG_NAME=${processParams.barcodeTagName} \\\n\t\t\tNUM_BASES_BELOW_QUALITY=${processParams.numBasesBelowQuality}        \n\t\t\"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__TAG_UNALIGNED_BAM_WITH_CELLMOLECULAR": {
        "name_process": "SC__DROP_SEQ_TOOLS__TAG_UNALIGNED_BAM_WITH_CELLMOLECULAR",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__TAG_UNALIGNED_BAM_WITH_CELLMOLECULAR {\n\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n    \ttuple val(sample), path(bam)\n\n\toutput:\n\t\ttuple val(sample), path('*.unaligned_tagged_CellMolecular.bam'), emit: bam\n\t\ttuple file('*.unaligned_tagged_Molecular.bam_summary.txt'), emit: report\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.tag_unaligned_bam_with_cellmolecular)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\tsource $DWMAX/documents/aertslab/scripts/src_dwmax/bash-utils/utils.sh\n\t\tsoftware load drop-seq_tools/1.12\n\t\tTagBamWithReadSequenceExtended \\\n\t\t\tINPUT=${bam} \\\n\t\t\tOUTPUT=${sample}.unaligned_tagged_CellMolecular.bam \\\n\t\t\tSUMMARY=${sample}.unaligned_tagged_Molecular.bam_summary.txt \\\n\t\t\tBASE_RANGE=${processParams.baseRange} \\\n\t\t\tBASE_QUALITY=${processParams.baseQuality} \\\n\t\t\tBARCODED_READ=${processParams.barcodedRead} \\\n\t\t\tDISCARD_READ=${processParams.discardRead} \\\n\t\t\tTAG_NAME=${processParams.barcodeTagName} \\\n\t\t\tNUM_BASES_BELOW_QUALITY=${processParams.numBasesBelowQuality}        \n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 30,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.tag_unaligned_bam_with_cellmolecular)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\tsource $DWMAX/documents/aertslab/scripts/src_dwmax/bash-utils/utils.sh\n\t\tsoftware load drop-seq_tools/1.12\n\t\tTagBamWithReadSequenceExtended \\\n\t\t\tINPUT=${bam} \\\n\t\t\tOUTPUT=${sample}.unaligned_tagged_CellMolecular.bam \\\n\t\t\tSUMMARY=${sample}.unaligned_tagged_Molecular.bam_summary.txt \\\n\t\t\tBASE_RANGE=${processParams.baseRange} \\\n\t\t\tBASE_QUALITY=${processParams.baseQuality} \\\n\t\t\tBARCODED_READ=${processParams.barcodedRead} \\\n\t\t\tDISCARD_READ=${processParams.discardRead} \\\n\t\t\tTAG_NAME=${processParams.barcodeTagName} \\\n\t\t\tNUM_BASES_BELOW_QUALITY=${processParams.numBasesBelowQuality}        \n\t\t\"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "ABI software"
        ],
        "tools_url": [
            "https://bio.tools/ABI_software"
        ],
        "tools_dico": [
            {
                "name": "ABI software",
                "uri": "https://bio.tools/ABI_software",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "Neurology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "https://en.wikipedia.org/wiki/Neurology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Experimental Brain Computer Interface Software for the ModularEEG.",
                "homepage": "https://users.dcc.uchile.cl/~peortega/abi/"
            }
        ],
        "inputs": [
            "sample",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "TRIMGALORE__TRIM": {
        "name_process": "TRIMGALORE__TRIM",
        "string_process": "\nprocess TRIMGALORE__TRIM {\n\n    container toolParams.container\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(fastq_PE1),\n              path(fastq_PE2)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}_dex_R1_val_1.fq.gz\"),\n              path(\"${sampleId}_dex_R2_val_2.fq.gz\"),\n              path(\"${sampleId}_dex_R1.fastq.gz_trimming_report.txt\"),\n              path(\"${sampleId}_dex_R2.fastq.gz_trimming_report.txt\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.trim)\n        processParams = sampleParams.local\n        def max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        trim_galore \\\n            -j ${max_threads} \\\n            -o . \\\n            ${fastq_PE1} \\\n            ${fastq_PE2} \\\n            --paired \\\n            --gzip\n        \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.trim)\n        processParams = sampleParams.local\n        def max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        trim_galore \\\n            -j ${max_threads} \\\n            -o . \\\n            ${fastq_PE1} \\\n            ${fastq_PE2} \\\n            --paired \\\n            --gzip\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "fastq_PE1",
            "fastq_PE2"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "BWAMAPTOOLS__BWA_MEM_PE": {
        "name_process": "BWAMAPTOOLS__BWA_MEM_PE",
        "string_process": "\nprocess BWAMAPTOOLS__BWA_MEM_PE {\n\n    container toolParams.container\n    label 'compute_resources__bwa_mem'\n\n    input:\n        tuple path(bwa_fasta),\n              path(bwa_index),\n              val(unique_sampleId),\n              val(sampleId),\n              path(fastq_PE1),\n              path(fastq_PE2)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.bwa.out.fixmate.bam\")\n\n    script:\n        def sampleParams = params.parseConfig(unique_sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        id=\\$(zcat ${fastq_PE1} | head -n 1 | cut -f 1-4 -d':' | sed 's/@//')\n        ${toolParams.bwa_version} mem \\\n            -t ${task.cpus} \\\n            -C \\\n            -R \"@RG\\\\tID:\\${id}\\\\tSM:${unique_sampleId}\\\\tLB:\\${id}\"__\"${unique_sampleId}\\\\tPL:ILLUMINA\" \\\n            ${bwa_fasta} \\\n            ${fastq_PE1} \\\n            ${fastq_PE2} \\\n        | samtools fixmate -m -O bam - ${sampleId}.bwa.out.fixmate.bam\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "        def sampleParams = params.parseConfig(unique_sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        id=\\$(zcat ${fastq_PE1} | head -n 1 | cut -f 1-4 -d':' | sed 's/@//')\n        ${toolParams.bwa_version} mem \\\n            -t ${task.cpus} \\\n            -C \\\n            -R \"@RG\\\\tID:\\${id}\\\\tSM:${unique_sampleId}\\\\tLB:\\${id}\"__\"${unique_sampleId}\\\\tPL:ILLUMINA\" \\\n            ${bwa_fasta} \\\n            ${fastq_PE1} \\\n            ${fastq_PE2} \\\n        | samtools fixmate -m -O bam - ${sampleId}.bwa.out.fixmate.bam\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "unique_sampleId",
            "sampleId",
            "bwa_fasta",
            "bwa_index",
            "fastq_PE1",
            "fastq_PE2"
        ],
        "nb_inputs": 6,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__bwa_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__STAR__MAP_COUNT": {
        "name_process": "SC__STAR__MAP_COUNT",
        "string_process": "\nprocess SC__STAR__MAP_COUNT {\n\n\tcontainer params.tools.star.container\n    label 'compute_resources__star_map_count'\n\n\tinput:\n\t\tfile(starIndex)\n\t\tval starIndexLoaded\n\t\ttuple val(sample), path(fastqs)\n\n\toutput:\n\t\tval success, emit: isDone\n\t\ttuple val(sample), path(\"*ReadsPerGene.out.tab\"), emit: counts optional processParams.containsKey('quantMode') && processParams.quantMode == \"GeneCounts\" ? true: false\n\t\ttuple val(sample), path(\"*.STAR_Aligned.sortedByCoord.out.bam\"), emit: bam\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.star.map_count)\n\t\tprocessParams = sampleParams.local\n\t\tsuccess = true\n\t\t\"\"\"\n\t\tSTAR \\\n\t\t\t--genomeLoad LoadAndKeep \\\n\t\t\t--genomeDir ${starIndex} \\\n            --runThreadN ${task.cpus} \\\n\t\t\t${(processParams.containsKey('limitBAMsortRAM')) ? '--limitBAMsortRAM ' + processParams.limitBAMsortRAM: ''} \\\n\t\t\t${(processParams.containsKey('outSAMtype')) ? '--outSAMtype ' + processParams.outSAMtype: ''} \\\n\t\t\t${(processParams.containsKey('quantMode')) ? '--quantMode ' + processParams.quantMode: ''} \\\n\t\t\t${(processParams.containsKey('outReadsUnmapped')) ? '--outReadsUnmapped ' + processParams.outReadsUnmapped: ''} \\\n\t\t\t--readFilesIn ${fastqs} \\\n\t\t\t${(fastqs.name.endsWith(\".gz\")) ? '--readFilesCommand zcat' : ''} \\\n\t\t\t--outFileNamePrefix ${sample}.STAR_\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 33,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.star.map_count)\n\t\tprocessParams = sampleParams.local\n\t\tsuccess = true\n\t\t\"\"\"\n\t\tSTAR \\\n\t\t\t--genomeLoad LoadAndKeep \\\n\t\t\t--genomeDir ${starIndex} \\\n            --runThreadN ${task.cpus} \\\n\t\t\t${(processParams.containsKey('limitBAMsortRAM')) ? '--limitBAMsortRAM ' + processParams.limitBAMsortRAM: ''} \\\n\t\t\t${(processParams.containsKey('outSAMtype')) ? '--outSAMtype ' + processParams.outSAMtype: ''} \\\n\t\t\t${(processParams.containsKey('quantMode')) ? '--quantMode ' + processParams.quantMode: ''} \\\n\t\t\t${(processParams.containsKey('outReadsUnmapped')) ? '--outReadsUnmapped ' + processParams.outReadsUnmapped: ''} \\\n\t\t\t--readFilesIn ${fastqs} \\\n\t\t\t${(fastqs.name.endsWith(\".gz\")) ? '--readFilesCommand zcat' : ''} \\\n\t\t\t--outFileNamePrefix ${sample}.STAR_\n\t\t\"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "starIndex",
            "starIndexLoaded",
            "sample",
            "fastqs"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.star.container",
            "label 'compute_resources__star_map_count'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__NORMALIZATION": {
        "name_process": "SC__SCANPY__NORMALIZATION",
        "string_process": "\nprocess SC__SCANPY__NORMALIZATION {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple val(sampleId), path(f)\n\n\toutput:\n\t\ttuple val(sampleId), path(\"${sampleId}.SC__SCANPY__NORMALIZATION.${processParams.off}\")\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.normalization)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/transform/sc_normalization.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('targetSum')) ? '--target-sum ' + processParams.targetSum : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__NORMALIZATION.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.normalization)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/transform/sc_normalization.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('targetSum')) ? '--target-sum ' + processParams.targetSum : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__NORMALIZATION.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__DATA_TRANSFORMATION": {
        "name_process": "SC__SCANPY__DATA_TRANSFORMATION",
        "string_process": "\nprocess SC__SCANPY__DATA_TRANSFORMATION {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple val(sampleId), path(f)\n\t\n\toutput:\n\t\ttuple val(sampleId), path(\"${sampleId}.SC__SCANPY__DATA_TRANSFORMATION.${processParams.off}\")\n\t\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.data_transformation)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/transform/sc_data_transformation.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__DATA_TRANSFORMATION.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.data_transformation)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/transform/sc_data_transformation.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__DATA_TRANSFORMATION.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__FEATURE_SCALING": {
        "name_process": "SC__SCANPY__FEATURE_SCALING",
        "string_process": "\nprocess SC__SCANPY__FEATURE_SCALING {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(f)\n\t\n\toutput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__SCANPY__FEATURE_SCALING.${processParams.off}\")\n\t\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.feature_scaling)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/transform/sc_feature_scaling.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('maxSD')) ? '--max-sd ' + processParams.maxSD : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__FEATURE_SCALING.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 27,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.feature_scaling)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/transform/sc_feature_scaling.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('maxSD')) ? '--max-sd ' + processParams.maxSD : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__FEATURE_SCALING.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__REGRESS_OUT": {
        "name_process": "SC__SCANPY__REGRESS_OUT",
        "string_process": "\nprocess SC__SCANPY__REGRESS_OUT {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__cpu'\n\n\tinput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(f)\n\n\toutput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__SCANPY__REGRESS_OUT.${processParams.off}\")\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.regress_out)\n\t\tprocessParams = sampleParams.local\n\t\tvariablesToRegressOutAsArguments = processParams.variablesToRegressOut.collect({ '--variable-to-regress-out' + ' ' + it }).join(' ')\n\t\t\"\"\"\n\t\texport MKL_NUM_THREADS=1\n\t\texport NUMEXPR_NUM_THREADS=1\n\t\texport OMP_NUM_THREADS=1\n\t\t${binDir}adjust/sc_regress_out.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('variablesToRegressOut')) ? variablesToRegressOutAsArguments : ''} \\\n\t\t\t--n-jobs ${task.cpus} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__REGRESS_OUT.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 32,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.regress_out)\n\t\tprocessParams = sampleParams.local\n\t\tvariablesToRegressOutAsArguments = processParams.variablesToRegressOut.collect({ '--variable-to-regress-out' + ' ' + it }).join(' ')\n\t\t\"\"\"\n\t\texport MKL_NUM_THREADS=1\n\t\texport NUMEXPR_NUM_THREADS=1\n\t\texport OMP_NUM_THREADS=1\n\t\t${binDir}adjust/sc_regress_out.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('variablesToRegressOut')) ? variablesToRegressOutAsArguments : ''} \\\n\t\t\t--n-jobs ${task.cpus} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__REGRESS_OUT.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "GET_SRA_DB": {
        "name_process": "GET_SRA_DB",
        "string_process": "\nprocess GET_SRA_DB {\n\n    container params.utils.container\n    publishDir \"${processParams.sraDbOutDir}\", mode: 'link', overwrite: true\n    label 'compute_resources__default'\n\n    output:\n        file(\"SRAmetadb.sqlite\")\n\n    script:\n        \"\"\"\n        pysradb metadb \\\n            --out-dir \".\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 15,
        "string_script": "        \"\"\"\n        pysradb metadb \\\n            --out-dir \".\"\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "pysradb"
        ],
        "tools_url": [
            "https://bio.tools/pysradb"
        ],
        "tools_dico": [
            {
                "name": "pysradb",
                "uri": "https://bio.tools/pysradb",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Python package to query next-generation sequencing metadata and data from NCBI Sequence Read Archive.",
                "homepage": "https://github.com/saketkc/pysradb"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.utils.container",
            "publishDir \"${processParams.sraDbOutDir}\", mode: 'link', overwrite: true",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SRA_TO_METADATA": {
        "name_process": "SRA_TO_METADATA",
        "string_process": "\nprocess SRA_TO_METADATA {\n\n    container params.utils.container\n    publishDir \"${params.global.outdir}/metadata\", mode: 'link', overwrite: true\n    errorStrategy 'retry'\n    maxRetries 5\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sraId), val(sampleFilters)\n        file(sraDb)\n\n    output:\n        file \"${sraId}_metadata.tsv\"\n\n    script:\n        if(processParams.mode == 'db') {\n            if(sraDb.name != 'NO_FILE') {\n                sraDbAsArgument = \"--sra-db ${sraDb}\"\n            } else {\n                if(!processParams.containsKey('sraDb') || processParams.sraDb == '')\n                    throw new Exception(\"The db modue requires sraDb to be specified\")\n                sraDbAsArgument = '--sra-db ' + processParams.sraDb\n            }\n        } else if(processParams.mode == 'web') {\n            sraDbAsArgument = ''\n        } else {\n            throw new Exception(\"The \"+ processParams.mode +\" mode does not exist. Choose one of: web, db.\")\n        }\n        def sampleFiltersAsArguments = sampleFilters.collect({ '--sample-filter' + ' \"' + it + '\"'}).join(' ')\n        \"\"\"\n        ${binDir}/sra_to_metadata.py \\\n            ${sraId} \\\n            ${sraDbAsArgument} \\\n            ${sampleFiltersAsArguments} \\\n            --output \"${sraId}_metadata.tsv\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 38,
        "string_script": "        if(processParams.mode == 'db') {\n            if(sraDb.name != 'NO_FILE') {\n                sraDbAsArgument = \"--sra-db ${sraDb}\"\n            } else {\n                if(!processParams.containsKey('sraDb') || processParams.sraDb == '')\n                    throw new Exception(\"The db modue requires sraDb to be specified\")\n                sraDbAsArgument = '--sra-db ' + processParams.sraDb\n            }\n        } else if(processParams.mode == 'web') {\n            sraDbAsArgument = ''\n        } else {\n            throw new Exception(\"The \"+ processParams.mode +\" mode does not exist. Choose one of: web, db.\")\n        }\n        def sampleFiltersAsArguments = sampleFilters.collect({ '--sample-filter' + ' \"' + it + '\"'}).join(' ')\n        \"\"\"\n        ${binDir}/sra_to_metadata.py \\\n            ${sraId} \\\n            ${sraDbAsArgument} \\\n            ${sampleFiltersAsArguments} \\\n            --output \"${sraId}_metadata.tsv\"\n        \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sraId",
            "sampleFilters",
            "sraDb"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.utils.container",
            "publishDir \"${params.global.outdir}/metadata\", mode: 'link', overwrite: true",
            "errorStrategy 'retry'",
            "maxRetries 5",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "NORMALIZE_SRA_FASTQS": {
        "name_process": "NORMALIZE_SRA_FASTQS",
        "string_process": "\nprocess NORMALIZE_SRA_FASTQS {\n\n                                                                 \n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId), file(fastqs)\n\n    output:\n        tuple val(sampleId), path(\"*.fastq.gz\")\n\n    script:\n        def normalizedFastqs = fastqs\n            .collect {\n                fastq -> normalizeSRAFastQ(fastq, sampleId, params.utils.sra_normalize_fastqs.fastq_read_suffixes)\n            }\n        def cmd = ''\n        for(int i = 0; i < normalizedFastqs.size(); i++)\n            cmd += \"ln -s ${normalizedFastqs[i][0]} ${normalizedFastqs[i][1]}; \" \n        \"\"\"\n        $cmd\n        \"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "        def normalizedFastqs = fastqs\n            .collect {\n                fastq -> normalizeSRAFastQ(fastq, sampleId, params.utils.sra_normalize_fastqs.fastq_read_suffixes)\n            }\n        def cmd = ''\n        for(int i = 0; i < normalizedFastqs.size(); i++)\n            cmd += \"ln -s ${normalizedFastqs[i][0]} ${normalizedFastqs[i][1]}; \" \n        \"\"\"\n        $cmd\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "sampleId",
            "fastqs"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD__SORT_SAM": {
        "name_process": "PICARD__SORT_SAM",
        "string_process": "\nprocess PICARD__SORT_SAM {\n\n    container params.tools.picard.container\n    publishDir \"${params.global.outdir}/02.map\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sample), path(bam)\n        file(tmpDir)\n\n    output:\n        tuple val(sample), path(\"*.STAR_aligned_sorted.bam\")\n    \n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.picard.sort_sam)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                SortSam \\\n                    I=${bam} \\\n                    O=${sample}.STAR_aligned_sorted.bam \\\n                    SO=${processParams.so}\n        \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.picard.sort_sam)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                SortSam \\\n                    I=${bam} \\\n                    O=${sample}.STAR_aligned_sorted.bam \\\n                    SO=${processParams.so}\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "bam",
            "tmpDir"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.picard.container",
            "publishDir \"${params.global.outdir}/02.map\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SCTK__BARCODE_CORRECTION": {
        "name_process": "SCTK__BARCODE_CORRECTION",
        "string_process": "\nprocess SCTK__BARCODE_CORRECTION {\n\n    container toolParams.container\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              val(technology),\n              path(fastq_PE1),\n              path(fastq_bc),\n              path(fastq_PE2),\n              path(bc_whitelist)\n\n    output:\n        tuple val(sampleId),\n              val(technology),\n              path(fastq_PE1),\n              path(\"${sampleId}_bc_corrected.fastq.gz\"),\n              path(fastq_PE2),\n              path(\"${sampleId}_bc_corrected.fastq.gz.corrected.bc_stats.tsv\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_correction)\n        processParams = sampleParams.local\n        \"\"\"\n        correct_barcode_in_fastq.sh \\\n            ${bc_whitelist} \\\n            ${fastq_bc} \\\n            ${sampleId}_bc_corrected.fastq.gz \\\n            ${processParams.max_mismatches} \\\n            ${processParams.min_frac_bcs_to_find}\n        \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_correction)\n        processParams = sampleParams.local\n        \"\"\"\n        correct_barcode_in_fastq.sh \\\n            ${bc_whitelist} \\\n            ${fastq_bc} \\\n            ${sampleId}_bc_corrected.fastq.gz \\\n            ${processParams.max_mismatches} \\\n            ${processParams.min_frac_bcs_to_find}\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "technology",
            "fastq_PE1",
            "fastq_bc",
            "fastq_PE2",
            "bc_whitelist"
        ],
        "nb_inputs": 6,
        "outputs": [
            "technology"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__DIGITAL_EXPRESSION": {
        "name_process": "SC__DROP_SEQ_TOOLS__DIGITAL_EXPRESSION",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__DIGITAL_EXPRESSION {\n\n    container params.tools.dropseqtools.container\n    publishDir \"03.count\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sample), path(bam), val(tag), path(selectedBarcodes)\n\n    output:\n        tuple file(\"*.${tag}.cells_dge.txt.gz\"), emit: dgem\n\n    shell:\n        \"\"\"\n        DigitalExpression \\\n            I=${bam} \\\n            O=${sample}.${tag}.cells_dge.txt.gz \\\n            SUMMARY=${sample}.${tag}.cells_dge.summary.txt \\\n            CELL_BC_FILE=${selectedBarcodes} \\\n            TMP_DIR=$DWMAX/tmp\n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        DigitalExpression \\\n            I=${bam} \\\n            O=${sample}.${tag}.cells_dge.txt.gz \\\n            SUMMARY=${sample}.${tag}.cells_dge.summary.txt \\\n            CELL_BC_FILE=${selectedBarcodes} \\\n            TMP_DIR=$DWMAX/tmp\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "TMPD"
        ],
        "tools_url": [
            "https://bio.tools/tmpd"
        ],
        "tools_dico": [
            {
                "name": "TMPD",
                "uri": "https://bio.tools/tmpd",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plants"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Botany"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0780",
                            "term": "Plant"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Tobacco Markers & Primers Database.",
                "homepage": "http://biodb.sdau.edu.cn/tmpd/index.html"
            }
        ],
        "inputs": [
            "sample",
            "tag",
            "bam",
            "selectedBarcodes"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"03.count\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "BAP__BARCODE_MULTIPLET_PIPELINE": {
        "name_process": "BAP__BARCODE_MULTIPLET_PIPELINE",
        "string_process": "\nprocess BAP__BARCODE_MULTIPLET_PIPELINE {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/data/bap\", mode: params.utils.publish.mode\n    label 'compute_resources__bap_barcode_multiplet_pipeline'\n\n    input:\n        tuple val(sampleId),\n              path(\"input.bam\"),\n              path(\"input.bam.bai\")\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}/final/${sampleId}.bap.bam\"),\n              path(\"${sampleId}/final/${sampleId}.bap.bam.bai\"),\n              path(\"${sampleId}/final/*\"),\n              path(\"${sampleId}/knee/*\"),\n              path(\"${sampleId}/logs/*\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_multiplet)\n        processParams = sampleParams.local\n        \"\"\"\n        bap2 bam \\\n            --input input.bam \\\n            --output ${sampleId} \\\n            --name ${sampleId} \\\n            --ncores ${task.cpus} \\\n            --drop-tag ${processParams.drop_tag} \\\n            --bead-tag ${processParams.bead_tag} \\\n            --minimum-barcode-fragments ${processParams.minimum_barcode_fragments} \\\n            ${processParams?.barcode_whitelist ? '--barcode-whitelist ' + processParams.barcode_whitelist : ''} \\\n            --minimum-jaccard-index ${processParams.minimum_jaccard_index} \\\n            --nc-threshold ${processParams.nc_threshold} \\\n            --mapq ${processParams.mapq} \\\n            --max-insert ${processParams.max_insert} \\\n            ${processParams?.reference_genome ? '--reference-genome ' + processParams.reference_genome : ''} \\\n            ${processParams?.bedtools_genome ? '--bedtools-genome ' + processParams.bedtools_genome : ''} \\\n            ${processParams?.blacklist_file ? '--blacklist-file ' + processParams.blacklist_file : ''} \\\n            ${processParams?.tss_file ? '--tss-file ' + processParams.tss_file : ''} \\\n            --mito-chromosome ${processParams.mito_chromosome}\n        \"\"\"\n}",
        "nb_lignes_process": 42,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_multiplet)\n        processParams = sampleParams.local\n        \"\"\"\n        bap2 bam \\\n            --input input.bam \\\n            --output ${sampleId} \\\n            --name ${sampleId} \\\n            --ncores ${task.cpus} \\\n            --drop-tag ${processParams.drop_tag} \\\n            --bead-tag ${processParams.bead_tag} \\\n            --minimum-barcode-fragments ${processParams.minimum_barcode_fragments} \\\n            ${processParams?.barcode_whitelist ? '--barcode-whitelist ' + processParams.barcode_whitelist : ''} \\\n            --minimum-jaccard-index ${processParams.minimum_jaccard_index} \\\n            --nc-threshold ${processParams.nc_threshold} \\\n            --mapq ${processParams.mapq} \\\n            --max-insert ${processParams.max_insert} \\\n            ${processParams?.reference_genome ? '--reference-genome ' + processParams.reference_genome : ''} \\\n            ${processParams?.bedtools_genome ? '--bedtools-genome ' + processParams.bedtools_genome : ''} \\\n            ${processParams?.blacklist_file ? '--blacklist-file ' + processParams.blacklist_file : ''} \\\n            ${processParams?.tss_file ? '--tss-file ' + processParams.tss_file : ''} \\\n            --mito-chromosome ${processParams.mito_chromosome}\n        \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/data/bap\", mode: params.utils.publish.mode",
            "label 'compute_resources__bap_barcode_multiplet_pipeline'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER__COUNT": {
        "name_process": "SC__CELLRANGER__COUNT",
        "string_process": "\nprocess SC__CELLRANGER__COUNT {\n\n\tcache 'deep'\n\tcontainer toolParams.container\n\tpublishDir \"${params.global.outdir}/counts\", saveAs: {\"${sampleId}/outs\"}, mode: 'link', overwrite: true\n    label 'compute_resources__cellranger_count'\n\n    input:\n\t\tpath(transcriptome)\n\t\ttuple \\\n\t\t\tval(sampleId), \n\t\t\tpath(fastqs, stageAs: \"fastqs_??/*\")\n\n  \toutput:\n    \ttuple val(sampleId), path(\"${sampleId}/outs\")\n\n  \tscript:\n\t  \tdef sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n\t\tprocessParams = sampleParams.local\n\t\tif(processParams.sample == '') {\n\t\t\tthrow new Exception(\"Regards params.tools.cellranger.count: sample parameter cannot be empty\")\n\t\t}\n\t\t                                                           \n\t\tfastqs = fastqs instanceof List ? fastqs.join(',') : fastqs\n\t\trunCellRangerCount(\n\t\t\tprocessParams,\n\t\t\ttranscriptome,\n            task,\n\t\t\tsampleId,\n\t\t\tsampleId,\n\t\t\tfastqs\n\t\t)\n\n}",
        "nb_lignes_process": 33,
        "string_script": "\t  \tdef sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n\t\tprocessParams = sampleParams.local\n\t\tif(processParams.sample == '') {\n\t\t\tthrow new Exception(\"Regards params.tools.cellranger.count: sample parameter cannot be empty\")\n\t\t}\n\t\t                                                           \n\t\tfastqs = fastqs instanceof List ? fastqs.join(',') : fastqs\n\t\trunCellRangerCount(\n\t\t\tprocessParams,\n\t\t\ttranscriptome,\n            task,\n\t\t\tsampleId,\n\t\t\tsampleId,\n\t\t\tfastqs\n\t\t)",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "transcriptome",
            "sampleId",
            "fastqs"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/counts\", saveAs: {\"${sampleId}/outs\"}, mode: 'link', overwrite: true",
            "label 'compute_resources__cellranger_count'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER__COUNT_WITH_LIBRARIES": {
        "name_process": "SC__CELLRANGER__COUNT_WITH_LIBRARIES",
        "string_process": "\nprocess SC__CELLRANGER__COUNT_WITH_LIBRARIES {\n\n\tcache 'deep'\n\tcontainer toolParams.container\n\tpublishDir \"${params.global.outdir}/counts\", saveAs: {\"${sampleId}/outs\"}, mode: 'link', overwrite: true\n    label 'compute_resources__cellranger_count'\n\n    input:\n\t\tpath(transcriptome)\n\t\tpath(featureRef)\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(fastqs, stageAs: \"fastqs_??/*\"),\n\t\t\tval(sampleNames),\n\t\t\tval(assays)\n\n  \toutput:\n    \ttuple val(sampleId), path(\"${sampleId}/outs\")\n\n  \tscript:\n\t  \tdef sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n\t\tprocessParams = sampleParams.local\n\n\t\tif(processParams.sample == '') {\n\t\t\tthrow new Exception(\"Regards params.tools.cellranger.count: sample parameter cannot be empty\")\n\t\t}\n\n\t\t                                                                                \n\n\t\tcsvData = \"fastqs,sample,library_type\\n\"\n\t\tfastqs.eachWithIndex { fastq, ix -> \n\t\t\tif (sampleNames[ix] != null) {\n\t\t\t\tcsvData += \"\\$PWD/${fastq},${sampleNames[ix]},${assays[ix]}\\n\"\n\t\t\t}\n\t\t}\n\n\t\t\"\"\"\n\t\techo \"${csvData}\" > libraries.csv\n\t\t\"\"\" + runCellRangerCountLibraries(\n\t\t\tprocessParams,\n\t\t\ttranscriptome,\n            task,\n\t\t\tsampleId,\n\t\t\tfeatureRef,\n\t\t\t\"libraries.csv\"\n\t\t)\n\n}",
        "nb_lignes_process": 47,
        "string_script": "\t  \tdef sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n\t\tprocessParams = sampleParams.local\n\n\t\tif(processParams.sample == '') {\n\t\t\tthrow new Exception(\"Regards params.tools.cellranger.count: sample parameter cannot be empty\")\n\t\t}\n\n\t\t                                                                                \n\n\t\tcsvData = \"fastqs,sample,library_type\\n\"\n\t\tfastqs.eachWithIndex { fastq, ix -> \n\t\t\tif (sampleNames[ix] != null) {\n\t\t\t\tcsvData += \"\\$PWD/${fastq},${sampleNames[ix]},${assays[ix]}\\n\"\n\t\t\t}\n\t\t}\n\n\t\t\"\"\"\n\t\techo \"${csvData}\" > libraries.csv\n\t\t\"\"\" + runCellRangerCountLibraries(\n\t\t\tprocessParams,\n\t\t\ttranscriptome,\n            task,\n\t\t\tsampleId,\n\t\t\tfeatureRef,\n\t\t\t\"libraries.csv\"\n\t\t)",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "transcriptome",
            "featureRef",
            "sampleId",
            "sampleNames",
            "assays",
            "fastqs"
        ],
        "nb_inputs": 6,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/counts\", saveAs: {\"${sampleId}/outs\"}, mode: 'link', overwrite: true",
            "label 'compute_resources__cellranger_count'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER__COUNT_WITH_METADATA": {
        "name_process": "SC__CELLRANGER__COUNT_WITH_METADATA",
        "string_process": "\nprocess SC__CELLRANGER__COUNT_WITH_METADATA {\n\n\tcache 'deep'\n\tcontainer toolParams.container\n\tpublishDir \"${params.global.outdir}/counts\", saveAs: {\"${sampleId}/outs\"}, mode: 'link', overwrite: true\n    label 'compute_resources__cellranger_count'\n\n    input:\n\t\tpath(transcriptome)\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tval(samplePrefix), \\\n\t\t\tpath(fastqs, stageAs: \"fastqs_??/*\"), \\\n\t\t\tval(expectCells), \\\n\t\t\tval(chemistry)\n\n  \toutput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}/outs\")\n\n  \tscript:\n\t  \tdef sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n\t\tprocessParams = sampleParams.local\n\t\tfastqs = fastqs instanceof List ? fastqs.join(',') : fastqs\n\n\t\trunCellRangerCount(\n\t\t\tprocessParams,\n\t\t\ttranscriptome,\n            task,\n\t\t\tsampleId,\n\t\t\tsamplePrefix,\n\t\t\tfastqs,\n\t\t\texpectCells,\n\t\t\tchemistry\n\t\t)\n\n}",
        "nb_lignes_process": 37,
        "string_script": "\t  \tdef sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n\t\tprocessParams = sampleParams.local\n\t\tfastqs = fastqs instanceof List ? fastqs.join(',') : fastqs\n\n\t\trunCellRangerCount(\n\t\t\tprocessParams,\n\t\t\ttranscriptome,\n            task,\n\t\t\tsampleId,\n\t\t\tsamplePrefix,\n\t\t\tfastqs,\n\t\t\texpectCells,\n\t\t\tchemistry\n\t\t)",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "transcriptome",
            "sampleId",
            "samplePrefix",
            "fastqs",
            "expectCells",
            "chemistry"
        ],
        "nb_inputs": 6,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/counts\", saveAs: {\"${sampleId}/outs\"}, mode: 'link', overwrite: true",
            "label 'compute_resources__cellranger_count'"
        ],
        "when": "",
        "stub": ""
    },
    "DOWNLOAD_FASTQS_FROM_SRA_ACC_ID": {
        "name_process": "DOWNLOAD_FASTQS_FROM_SRA_ACC_ID",
        "string_process": "\nprocess DOWNLOAD_FASTQS_FROM_SRA_ACC_ID {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/data/raw/fastqs\", mode: 'symlink', overwrite: true\n    label 'compute_resources__sratoolkit'\n\n    input:\n        tuple val(sraId), val(sampleId)\n    \n    output:\n        tuple val(sraId), file(\"${sraId}*.fastq\")\n    \n    script:\n        if(sampleId == null || sampleId.length() < 1) {\n            throw new Exception(\"DOWNLOAD_FASTQS_FROM_SRA_ACC_ID: Sample ID is empty.\")\n        }\n        \"\"\"\n        SRA_FILE_LOCK=./ncbi/public/sra/${sraId}.sra.lock\n        if [[ -f \"\\${SRA_FILE_LOCK}\" ]]; then\n            echo \"SRA file lock found for ${sraId}. Removing file lock...\"\n            rm \\${SRA_FILE_LOCK}\n        fi\n        # Fetch SRA file\n        prefetch \\\n           -v \\\n           -p 1 \\\n           ${params.tools.sratoolkit?.maxSize ? '--max-size '+ params.tools.sratoolkit.maxSize: ''} \\\n           ${sraId}\n        # Convert SRA file to FASTQ files\n        fasterq-dump \\\n           -S \\\n           -v \\\n           -p \\\n           -e ${task.cpus} \\\n           ${params.tools.sratoolkit?.includeTechnicalReads ? '--include-technical' : ''} \\\n           -O . \\\n           ${sraId}\n        \"\"\"\n\n}",
        "nb_lignes_process": 39,
        "string_script": "        if(sampleId == null || sampleId.length() < 1) {\n            throw new Exception(\"DOWNLOAD_FASTQS_FROM_SRA_ACC_ID: Sample ID is empty.\")\n        }\n        \"\"\"\n        SRA_FILE_LOCK=./ncbi/public/sra/${sraId}.sra.lock\n        if [[ -f \"\\${SRA_FILE_LOCK}\" ]]; then\n            echo \"SRA file lock found for ${sraId}. Removing file lock...\"\n            rm \\${SRA_FILE_LOCK}\n        fi\n        # Fetch SRA file\n        prefetch \\\n           -v \\\n           -p 1 \\\n           ${params.tools.sratoolkit?.maxSize ? '--max-size '+ params.tools.sratoolkit.maxSize: ''} \\\n           ${sraId}\n        # Convert SRA file to FASTQ files\n        fasterq-dump \\\n           -S \\\n           -v \\\n           -p \\\n           -e ${task.cpus} \\\n           ${params.tools.sratoolkit?.includeTechnicalReads ? '--include-technical' : ''} \\\n           -O . \\\n           ${sraId}\n        \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sraId",
            "sampleId"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sraId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/data/raw/fastqs\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__sratoolkit'"
        ],
        "when": "",
        "stub": ""
    },
    "rename_fragments": {
        "name_process": "rename_fragments",
        "string_process": "\nprocess rename_fragments {\n\n    container toolParams.container\n    label 'compute_resources__minimal'\n\n    input:\n        tuple val(sampleId),\n              path(f)\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}_${f}*\")\n\n    script:\n        \"\"\"\n        ln -s ${f[0]} ${sampleId}_${f[0]}\n        ln -s ${f[1]} ${sampleId}_${f[1]}\n        \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "        \"\"\"\n        ln -s ${f[0]} ${sampleId}_${f[0]}\n        ln -s ${f[1]} ${sampleId}_${f[1]}\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__minimal'"
        ],
        "when": "",
        "stub": ""
    },
    "PYCISTOPIC__COMPUTE_QC_STATS": {
        "name_process": "PYCISTOPIC__COMPUTE_QC_STATS",
        "string_process": "\nprocess PYCISTOPIC__COMPUTE_QC_STATS {\n\n    publishDir \"${params.global.outdir}/data/pycistopic/qc/\", mode: params.utils.publish.mode\n    container toolParams.container\n    label 'compute_resources__pycisTopic'\n\n    input:\n        val(input)\n        path(biomart_annot)\n        path(fragments)\n        path(peaks)\n\n    output:\n        tuple path(\"${params.global.project_name}__metadata.pickle\"),\n              path(\"${params.global.project_name}__profile_data.pickle\")\n\n    script:\n        \"\"\"\n        export NUMEXPR_MAX_THREADS=1\n        export OMP_NUM_THREADS=1\n        ${binDir}compute_qc_stats.py \\\n            ${\"--input_files \"+input.join(\" --input_files \")} \\\n            --n_frag ${processParams.n_frag} \\\n            --tss_flank_window ${processParams.tss_flank_window} \\\n            --tss_window ${processParams.tss_window} \\\n            --tss_minimum_signal_window ${processParams.tss_minimum_signal_window} \\\n            --tss_rolling_window ${processParams.tss_rolling_window} \\\n            --min_norm ${processParams.min_norm} \\\n            --threads ${task.cpus} \\\n            --biomart_annot_pkl ${biomart_annot} \\\n            --output_metadata_pkl ${params.global.project_name}__metadata.pickle \\\n            --output_profile_data_pkl ${params.global.project_name}__profile_data.pickle\n        \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "        \"\"\"\n        export NUMEXPR_MAX_THREADS=1\n        export OMP_NUM_THREADS=1\n        ${binDir}compute_qc_stats.py \\\n            ${\"--input_files \"+input.join(\" --input_files \")} \\\n            --n_frag ${processParams.n_frag} \\\n            --tss_flank_window ${processParams.tss_flank_window} \\\n            --tss_window ${processParams.tss_window} \\\n            --tss_minimum_signal_window ${processParams.tss_minimum_signal_window} \\\n            --tss_rolling_window ${processParams.tss_rolling_window} \\\n            --min_norm ${processParams.min_norm} \\\n            --threads ${task.cpus} \\\n            --biomart_annot_pkl ${biomart_annot} \\\n            --output_metadata_pkl ${params.global.project_name}__metadata.pickle \\\n            --output_profile_data_pkl ${params.global.project_name}__profile_data.pickle\n        \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input",
            "biomart_annot",
            "fragments",
            "peaks"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/data/pycistopic/qc/\", mode: params.utils.publish.mode",
            "container toolParams.container",
            "label 'compute_resources__pycisTopic'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__PREPARE_OBS_FILTER": {
        "name_process": "SC__PREPARE_OBS_FILTER",
        "string_process": "\nprocess SC__PREPARE_OBS_FILTER {\n\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            val(filterConfig)\n                                             \n        val(tool)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            path(\"${sampleId}.${toolTag}SC__PREPARE_OBS_FILTER.${filterConfig.id}.txt\")\n\n    script:\n        def sampleParams = params.parseConfig(\n            sampleId,\n            params.global,\n            isParamNull(tool) ? params.utils.cell_filter : params.tools[tool][\"cell_filter\"]\n        )\n\t\tprocessParams = sampleParams.local\n        toolTag = isParamNull(tool) ? '' : tool.toUpperCase() + '.'\n\n        input = null\n        if(processParams.method == 'internal') {\n            input = f\n        } else if (processParams.method == 'external') {\n            if(!filterConfig.cellMetaDataFilePath) {\n                throw new Exception(\"VSN ERROR: A filter in params.utils.cell_filter does not provide a cellMetaDataFilePath entry.\")\n            }\n            input = filterConfig.cellMetaDataFilePath\n        } else {\n            throw new Exception(\"VSN ERROR: The given method\" + args.method + \" is not implemented. Choose either: internal or external.\")\n        }\n        if(!isCollectionOrArray(filterConfig.valuesToKeepFromFilterColumn)) {\n            throw new Exception(\"VSN ERROR: The given valuesToKeepFromFilterColumn \" + filterConfig.valuesToKeepFromFilterColumn + \" is expected to be an array.\")\n        }\n\n        valuesToKeepFromFilterColumnAsArguments = filterConfig.valuesToKeepFromFilterColumn.collect({ '--value-to-keep-from-filter-column' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}/sc_h5ad_prepare_obs_filter.py \\\n            ${processParams.containsKey('method') ? '--method ' + processParams.method : ''} \\\n            --sample-id ${sampleId} \\\n            --filter-column-name ${filterConfig.filterColumnName} \\\n            ${valuesToKeepFromFilterColumnAsArguments} \\\n            ${filterConfig.containsKey('indexColumnName') ? '--index-column-name ' + filterConfig.indexColumnName : ''} \\\n            ${filterConfig.containsKey('sampleColumnName') ? '--sample-column-name ' + filterConfig.sampleColumnName : ''} \\\n            $input \\\n            \"${sampleId}.${toolTag}SC__PREPARE_OBS_FILTER.${filterConfig.id}.txt\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 57,
        "string_script": "        def sampleParams = params.parseConfig(\n            sampleId,\n            params.global,\n            isParamNull(tool) ? params.utils.cell_filter : params.tools[tool][\"cell_filter\"]\n        )\n\t\tprocessParams = sampleParams.local\n        toolTag = isParamNull(tool) ? '' : tool.toUpperCase() + '.'\n\n        input = null\n        if(processParams.method == 'internal') {\n            input = f\n        } else if (processParams.method == 'external') {\n            if(!filterConfig.cellMetaDataFilePath) {\n                throw new Exception(\"VSN ERROR: A filter in params.utils.cell_filter does not provide a cellMetaDataFilePath entry.\")\n            }\n            input = filterConfig.cellMetaDataFilePath\n        } else {\n            throw new Exception(\"VSN ERROR: The given method\" + args.method + \" is not implemented. Choose either: internal or external.\")\n        }\n        if(!isCollectionOrArray(filterConfig.valuesToKeepFromFilterColumn)) {\n            throw new Exception(\"VSN ERROR: The given valuesToKeepFromFilterColumn \" + filterConfig.valuesToKeepFromFilterColumn + \" is expected to be an array.\")\n        }\n\n        valuesToKeepFromFilterColumnAsArguments = filterConfig.valuesToKeepFromFilterColumn.collect({ '--value-to-keep-from-filter-column' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}/sc_h5ad_prepare_obs_filter.py \\\n            ${processParams.containsKey('method') ? '--method ' + processParams.method : ''} \\\n            --sample-id ${sampleId} \\\n            --filter-column-name ${filterConfig.filterColumnName} \\\n            ${valuesToKeepFromFilterColumnAsArguments} \\\n            ${filterConfig.containsKey('indexColumnName') ? '--index-column-name ' + filterConfig.indexColumnName : ''} \\\n            ${filterConfig.containsKey('sampleColumnName') ? '--sample-column-name ' + filterConfig.sampleColumnName : ''} \\\n            $input \\\n            \"${sampleId}.${toolTag}SC__PREPARE_OBS_FILTER.${filterConfig.id}.txt\"\n        \"\"\"",
        "nb_lignes_script": 34,
        "language_script": "bash",
        "tools": [
            "wossinput"
        ],
        "tools_url": [
            "https://bio.tools/wossinput"
        ],
        "tools_dico": [
            {
                "name": "wossinput",
                "uri": "https://bio.tools/wossinput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM input data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossinput.html"
            }
        ],
        "inputs": [
            "sampleId",
            "f",
            "filterConfig",
            "tool"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId",
            "f"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__APPLY_OBS_FILTER": {
        "name_process": "SC__APPLY_OBS_FILTER",
        "string_process": "\nprocess SC__APPLY_OBS_FILTER {\n\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            path(filters)\n                                             \n        val(tool)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.${toolTag}SC__APPLY_OBS_FILTER.${processParams.off}\")\n\n    script:\n        def sampleParams = params.parseConfig(\n            sampleId,\n            params.global,\n            isParamNull(tool) ? params.utils.cell_filter : getToolParams(params.tools, tool)[\"cell_filter\"]\n        )\n\t\tprocessParams = sampleParams.local\n        toolTag = isParamNull(tool) ? '' : tool.toUpperCase() + '.'\n\n        filtersAsArguments = filters.collect({ '--filter-file-path' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}/sc_h5ad_apply_obs_filter.py \\\n            $f \\\n            --output \"${sampleId}.${toolTag}SC__APPLY_OBS_FILTER.${processParams.off}\" \\\n            $filtersAsArguments\n        \"\"\"\n\n}",
        "nb_lignes_process": 36,
        "string_script": "        def sampleParams = params.parseConfig(\n            sampleId,\n            params.global,\n            isParamNull(tool) ? params.utils.cell_filter : getToolParams(params.tools, tool)[\"cell_filter\"]\n        )\n\t\tprocessParams = sampleParams.local\n        toolTag = isParamNull(tool) ? '' : tool.toUpperCase() + '.'\n\n        filtersAsArguments = filters.collect({ '--filter-file-path' + ' ' + it }).join(' ')\n        \"\"\"\n        ${binDir}/sc_h5ad_apply_obs_filter.py \\\n            $f \\\n            --output \"${sampleId}.${toolTag}SC__APPLY_OBS_FILTER.${processParams.off}\" \\\n            $filtersAsArguments\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "filters",
            "tool"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__H5AD_TO_LOOM": {
        "name_process": "SC__H5AD_TO_LOOM",
        "string_process": "\nprocess SC__H5AD_TO_LOOM {\n\n\tcontainer params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/loom\", mode: 'link', overwrite: true, saveAs: { filename -> \"${sampleId}.SCope_output.loom\" }\n    label 'compute_resources__mem'\n\n\tinput:\n\t\t           \n\t\t                                                                                            \n\t\t                                                                                            \n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(rawFilteredData), \\\n\t\t\tpath(data)\n\n\toutput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__H5AD_TO_LOOM.loom\")\n\n\tscript:\n\t\t\"\"\"\n\t\t${binDir}/h5ad_to_loom.py \\\n\t\t\t${params.utils?.scope.genome.length() > 0 ? '--nomenclature \"' + params.utils?.scope.genome + '\"' : ''} \\\n\t\t\t${params.utils?.scope.tree.level_1.length() > 0 ? '--scope-tree-level-1 \"' + params.utils.scope.tree.level_1 + '\"'  : ''} \\\n\t\t\t${params.utils?.scope.tree.level_2.length() > 0 ? '--scope-tree-level-2 \"' + params.utils.scope.tree.level_2 + '\"'  : ''} \\\n\t\t\t${params.utils?.scope.tree.level_3.length() > 0  ? '--scope-tree-level-3 \"' + params.utils.scope.tree.level_3 + '\"'  : ''} \\\n\t\t\t${params.utils?.scope?.markers?.log_fc_threshold ? '--markers-log-fc-threshold ' + params.utils.scope.markers.log_fc_threshold : ''} \\\n\t\t\t${params.utils?.scope?.markers?.fdr_threshold ? '--markers-fdr-threshold ' + params.utils.scope.markers.fdr_threshold : ''} \\\n\t\t\t$data \\\n\t\t\t$rawFilteredData \\\n\t\t\t\"${sampleId}.SC__H5AD_TO_LOOM.loom\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 34,
        "string_script": "\t\t\"\"\"\n\t\t${binDir}/h5ad_to_loom.py \\\n\t\t\t${params.utils?.scope.genome.length() > 0 ? '--nomenclature \"' + params.utils?.scope.genome + '\"' : ''} \\\n\t\t\t${params.utils?.scope.tree.level_1.length() > 0 ? '--scope-tree-level-1 \"' + params.utils.scope.tree.level_1 + '\"'  : ''} \\\n\t\t\t${params.utils?.scope.tree.level_2.length() > 0 ? '--scope-tree-level-2 \"' + params.utils.scope.tree.level_2 + '\"'  : ''} \\\n\t\t\t${params.utils?.scope.tree.level_3.length() > 0  ? '--scope-tree-level-3 \"' + params.utils.scope.tree.level_3 + '\"'  : ''} \\\n\t\t\t${params.utils?.scope?.markers?.log_fc_threshold ? '--markers-log-fc-threshold ' + params.utils.scope.markers.log_fc_threshold : ''} \\\n\t\t\t${params.utils?.scope?.markers?.fdr_threshold ? '--markers-fdr-threshold ' + params.utils.scope.markers.fdr_threshold : ''} \\\n\t\t\t$data \\\n\t\t\t$rawFilteredData \\\n\t\t\t\"${sampleId}.SC__H5AD_TO_LOOM.loom\"\n\t\t\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "rawFilteredData",
            "data"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/loom\", mode: 'link', overwrite: true, saveAs: { filename -> \"${sampleId}.SCope_output.loom\" }",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__H5AD_TO_FILTERED_LOOM": {
        "name_process": "SC__H5AD_TO_FILTERED_LOOM",
        "string_process": "\nprocess SC__H5AD_TO_FILTERED_LOOM {\n\n\tcontainer params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple val(sampleId), path(f)\n\n\toutput:\n\t\ttuple val(sampleId), path(\"${sampleId}.filtered.loom\")\n\n\tscript:\n\t\t\"\"\"\n\t\t${binDir}/h5ad_to_filtered_loom.py \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.filtered.loom\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "\t\t\"\"\"\n\t\t${binDir}/h5ad_to_filtered_loom.py \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.filtered.loom\"\n\t\t\"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "PYCISTOPIC__PLOT_QC_STATS": {
        "name_process": "PYCISTOPIC__PLOT_QC_STATS",
        "string_process": "\nprocess PYCISTOPIC__PLOT_QC_STATS {\n\n    container toolParams.container\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              path(output_metadata),\n              path(output_metadata_pkl),\n              path(output_profile_data_pkl)\n\n    output:\n        tuple val(sampleId),\n              path(output_pdf)\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        output_metadata = \"${sampleId}_metadata.tsv.gz\"\n        output_pdf = \"${sampleId}_qc_sample_metrics.pdf\"\n        output_metadata_pkl = \"${sampleId}_metadata.pickle\"\n        output_profile_data_pkl = \"${sampleId}_profile_data.pickle\"\n        \"\"\"\n        ${binDir}plot_qc_stats.py \\\n            --sampleId ${sampleId} \\\n            --profile_data_pkl ${output_profile_data_pkl} \\\n            --output_pdf ${output_pdf}\n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        output_metadata = \"${sampleId}_metadata.tsv.gz\"\n        output_pdf = \"${sampleId}_qc_sample_metrics.pdf\"\n        output_metadata_pkl = \"${sampleId}_metadata.pickle\"\n        output_profile_data_pkl = \"${sampleId}_profile_data.pickle\"\n        \"\"\"\n        ${binDir}plot_qc_stats.py \\\n            --sampleId ${sampleId} \\\n            --profile_data_pkl ${output_profile_data_pkl} \\\n            --output_pdf ${output_pdf}\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "output_metadata",
            "output_metadata_pkl",
            "output_profile_data_pkl"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "PYCISTOPIC__BIOMART_ANNOT": {
        "name_process": "PYCISTOPIC__BIOMART_ANNOT",
        "string_process": "\nprocess PYCISTOPIC__BIOMART_ANNOT {\n\n    publishDir \"${params.global.outdir}/intermediate/pycistopic/biomart/\", mode: 'symlink'\n    container toolParams.container\n    label 'compute_resources__default'\n\n    output:\n        path(\"biomart_annot.pickle\")\n\n    script:\n        \"\"\"\n        ${binDir}biomart_annot.py \\\n            --biomart_dataset_name ${processParams.biomart_dataset_name} \\\n            --biomart_host ${processParams.biomart_host}\n        \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "        \"\"\"\n        ${binDir}biomart_annot.py \\\n            --biomart_dataset_name ${processParams.biomart_dataset_name} \\\n            --biomart_host ${processParams.biomart_host}\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/intermediate/pycistopic/biomart/\", mode: 'symlink'",
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD__BAM_TO_FASTQ": {
        "name_process": "PICARD__BAM_TO_FASTQ",
        "string_process": "\nprocess PICARD__BAM_TO_FASTQ {\n\n    container params.tools.picard.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sample), path(bam)\n        file(tmpDir)\n\n    output:\n        tuple val(sample), path('*.unaligned_tagged_polyA_filtered.fastq'), emit: fastq\n\n    script:\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                SamToFastq \\\n                    INPUT=${bam} \\\n                    FASTQ=${sample}.unaligned_tagged_polyA_filtered.fastq\n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                SamToFastq \\\n                    INPUT=${bam} \\\n                    FASTQ=${sample}.unaligned_tagged_polyA_filtered.fastq\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "bam",
            "tmpDir"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.picard.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "CONVERT_MULTI_RUNS_FEATURES_TO_REGULONS": {
        "name_process": "CONVERT_MULTI_RUNS_FEATURES_TO_REGULONS",
        "string_process": "\nprocess CONVERT_MULTI_RUNS_FEATURES_TO_REGULONS {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_cistarget/\", mode: 'link', overwrite: true\n                                                                                                            \n                                                                                                 \n    label 'compute_resources__scenic_multiruns_motifs2regulons'\n\n    input:\n        tuple val(sampleId), path(multiRunsAggrMotifEnrichmentTable), path(multiRunsAggrRegulonsFolder)\n        val type\n\n    output:\n        tuple val(sampleId), path(\"multi_runs_regulons_${type}.pkl.gz\")\n\n    script:\n        \"\"\"\n        ${binDir}convert_multi_runs_features_to_regulons.py \\\n            $multiRunsAggrMotifEnrichmentTable \\\n            $multiRunsAggrRegulonsFolder \\\n            -o \"multi_runs_regulons_${type}.pkl.gz\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 24,
        "string_script": "        \"\"\"\n        ${binDir}convert_multi_runs_features_to_regulons.py \\\n            $multiRunsAggrMotifEnrichmentTable \\\n            $multiRunsAggrRegulonsFolder \\\n            -o \"multi_runs_regulons_${type}.pkl.gz\"\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "multiRunsAggrMotifEnrichmentTable",
            "multiRunsAggrRegulonsFolder",
            "type"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_cistarget/\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic_multiruns_motifs2regulons'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DIRECTS__SELECT_DEFAULT_CLUSTERING": {
        "name_process": "SC__DIRECTS__SELECT_DEFAULT_CLUSTERING",
        "string_process": "\nprocess SC__DIRECTS__SELECT_DEFAULT_CLUSTERING {\n\n    container params.tools.directs.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f), \\\n            val(stashedParams)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__DIRECTS__SELECT_DEFAULT_CLUSTERING.loom\"), \\\n            val(stashedParams)\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.directs.select_default_clustering)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}select_default_clustering.py \\\n            ${f} \\\n            ${sampleId}.SC__DIRECTS__SELECT_DEFAULT_CLUSTERING.loom \\\n            ${(processParams.containsKey('cellEmbeddingsIndex')) ? '--cell-embeddings-index ' + processParams.cellEmbeddingsIndex : ''} \\\n            ${(processParams.containsKey('fromMinClusterSize')) ? '--from-min-cluster-size ' + processParams.fromMinClusterSize : ''} \\\n            ${(processParams.containsKey('toMinClusterSize')) ? '--to-min-cluster-size ' + processParams.toMinClusterSize : ''} \\\n            ${(processParams.containsKey('byMinClusterSize')) ? '--by-min-cluster-size ' + processParams.byMinClusterSize : ''} \\\n            ${(processParams.containsKey('fromMinSamples')) ? '--from-min-samples ' + processParams.fromMinSamples : ''} \\\n            ${(processParams.containsKey('toMinSamples')) ? '--to-min-samples ' + processParams.toMinSamples : ''} \\\n            ${(processParams.containsKey('byMinSamples')) ? '--by-min-samples ' + processParams.byMinSamples : ''}\n        \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.directs.select_default_clustering)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}select_default_clustering.py \\\n            ${f} \\\n            ${sampleId}.SC__DIRECTS__SELECT_DEFAULT_CLUSTERING.loom \\\n            ${(processParams.containsKey('cellEmbeddingsIndex')) ? '--cell-embeddings-index ' + processParams.cellEmbeddingsIndex : ''} \\\n            ${(processParams.containsKey('fromMinClusterSize')) ? '--from-min-cluster-size ' + processParams.fromMinClusterSize : ''} \\\n            ${(processParams.containsKey('toMinClusterSize')) ? '--to-min-cluster-size ' + processParams.toMinClusterSize : ''} \\\n            ${(processParams.containsKey('byMinClusterSize')) ? '--by-min-cluster-size ' + processParams.byMinClusterSize : ''} \\\n            ${(processParams.containsKey('fromMinSamples')) ? '--from-min-samples ' + processParams.fromMinSamples : ''} \\\n            ${(processParams.containsKey('toMinSamples')) ? '--to-min-samples ' + processParams.toMinSamples : ''} \\\n            ${(processParams.containsKey('byMinSamples')) ? '--by-min-samples ' + processParams.byMinSamples : ''}\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "stashedParams"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId",
            "stashedParams"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.directs.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__FIND_HIGHLY_VARIABLE_GENES": {
        "name_process": "SC__SCANPY__FIND_HIGHLY_VARIABLE_GENES",
        "string_process": "\nprocess SC__SCANPY__FIND_HIGHLY_VARIABLE_GENES {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n  \tinput:\n    \ttuple val(sampleId), path(f)\n\n  \toutput:\n    \ttuple val(sampleId), path(\"${sampleId}.SC__SCANPY__FIND_HIGHLY_VARIABLE_GENES.${processParams.off}\")\n\n  \tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.feature_selection)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/feature_selection/sc_find_variable_genes.py \\\n\t\t\t${(processParams.containsKey('flavor')) ? '--flavor ' + processParams.flavor : ''} \\\n\t\t\t${(processParams.containsKey('nTopGenes')) ? '--n-top-genes ' + processParams.nTopGenes : ''} \\\n\t\t\t${(processParams.containsKey('minMean')) ? '--min-mean ' + processParams.minMean : ''} \\\n\t\t\t${(processParams.containsKey('maxMean')) ? '--max-mean ' + processParams.maxMean : ''} \\\n\t\t\t${(processParams.containsKey('minDisp')) ? '--min-disp ' + processParams.minDisp : ''} \\\n\t\t\t${(processParams.containsKey('maxDisp')) ? '--max-disp ' + processParams.maxDisp : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__FIND_HIGHLY_VARIABLE_GENES.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 27,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.feature_selection)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/feature_selection/sc_find_variable_genes.py \\\n\t\t\t${(processParams.containsKey('flavor')) ? '--flavor ' + processParams.flavor : ''} \\\n\t\t\t${(processParams.containsKey('nTopGenes')) ? '--n-top-genes ' + processParams.nTopGenes : ''} \\\n\t\t\t${(processParams.containsKey('minMean')) ? '--min-mean ' + processParams.minMean : ''} \\\n\t\t\t${(processParams.containsKey('maxMean')) ? '--max-mean ' + processParams.maxMean : ''} \\\n\t\t\t${(processParams.containsKey('minDisp')) ? '--min-disp ' + processParams.minDisp : ''} \\\n\t\t\t${(processParams.containsKey('maxDisp')) ? '--max-disp ' + processParams.maxDisp : ''} \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__FIND_HIGHLY_VARIABLE_GENES.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__SUBSET_HIGHLY_VARIABLE_GENES": {
        "name_process": "SC__SCANPY__SUBSET_HIGHLY_VARIABLE_GENES",
        "string_process": "\nprocess SC__SCANPY__SUBSET_HIGHLY_VARIABLE_GENES {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n  \tinput:\n    \ttuple val(sampleId), path(f)\n\n  \toutput:\n    \ttuple val(sampleId), path(\"${sampleId}.SC__SCANPY__SUBSET_HIGHLY_VARIABLE_GENES.${processParams.off}\")\n\n  \tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.feature_selection)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/feature_selection/sc_subset_variable_genes.py \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__SUBSET_HIGHLY_VARIABLE_GENES.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.feature_selection)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/feature_selection/sc_subset_variable_genes.py \\\n\t\t\t$f \\\n\t\t\t\"${sampleId}.SC__SCANPY__SUBSET_HIGHLY_VARIABLE_GENES.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SCTK__BARCODE_10X_SCATAC_FASTQ": {
        "name_process": "SCTK__BARCODE_10X_SCATAC_FASTQ",
        "string_process": "\nprocess SCTK__BARCODE_10X_SCATAC_FASTQ {\n\n    container toolParams.container\n    label 'compute_resources__cpu'\n\n    input:\n        tuple val(sampleId),\n              val(technology),\n              path(fastq_PE1),\n              path(fastq_bc),\n              path(fastq_PE2)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}_dex_R1.fastq.gz\"),\n              path(\"${sampleId}_dex_R2.fastq.gz\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_10x_scatac_fastqs)\n        processParams = sampleParams.local\n        def max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        export compress_fastq_threads=\"${max_threads}\"\n        barcode_10x_scatac_fastqs.sh \\\n            ${fastq_PE1} \\\n            ${fastq_bc} \\\n            ${fastq_PE2} \\\n            ${sampleId}_dex \\\n            false \\\n            true \\\n            ${processParams.uncorrected_bc_tag}_${processParams.barcode_quality_tag}\n        \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_10x_scatac_fastqs)\n        processParams = sampleParams.local\n        def max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        export compress_fastq_threads=\"${max_threads}\"\n        barcode_10x_scatac_fastqs.sh \\\n            ${fastq_PE1} \\\n            ${fastq_bc} \\\n            ${fastq_PE2} \\\n            ${sampleId}_dex \\\n            false \\\n            true \\\n            ${processParams.uncorrected_bc_tag}_${processParams.barcode_quality_tag}\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "technology",
            "fastq_PE1",
            "fastq_bc",
            "fastq_PE2"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "SCTK__EXTRACT_AND_CORRECT_BIORAD_BARCODE": {
        "name_process": "SCTK__EXTRACT_AND_CORRECT_BIORAD_BARCODE",
        "string_process": "\nprocess SCTK__EXTRACT_AND_CORRECT_BIORAD_BARCODE {\n\n    container toolParams.container\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              val(technology),\n              path(fastq_PE1),\n              path(fastq_PE2)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}_dex_R1.fastq.gz\"),\n              path(\"${sampleId}_dex_R2.fastq.gz\"),\n              path(\"${sampleId}_dex.corrected_bc_stats.tsv\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n                                            \n        \"\"\"\n        extract_and_correct_biorad_barcode_in_fastq.sh \\\n            ${fastq_PE1} \\\n            ${fastq_PE2} \\\n            ${sampleId}_dex\n        \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n                                            \n        \"\"\"\n        extract_and_correct_biorad_barcode_in_fastq.sh \\\n            ${fastq_PE1} \\\n            ${fastq_PE2} \\\n            ${sampleId}_dex\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "technology",
            "fastq_PE1",
            "fastq_PE2"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__STAR__BUILD_INDEX": {
        "name_process": "SC__STAR__BUILD_INDEX",
        "string_process": "\nprocess SC__STAR__BUILD_INDEX {\n\n    container params.tools.star.container\n    label 'compute_resources__star_build_genome'\n\n    input:\n        file(annotation)\n        file(genome)\n\n    output:\n        file(\"STAR_index\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.star.build_genome)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        mkdir STAR_index\n        STAR \\\n            --runThreadN ${task.cpus} \\\n            --runMode genomeGenerate \\\n            --genomeDir STAR_index \\\n            --genomeFastaFiles ${genome} \\\n            --sjdbGTFfile ${annotation} \\\n            --sjdbOverhang ${processParams.sjdbOverhang} \\\n            --genomeSAindexNbases ${processParams.genomeSAindexNbases} # Suggested by STAR (default: 14), otherwise keeps on hanging\n        \"\"\"\n\n}",
        "nb_lignes_process": 27,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.star.build_genome)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        mkdir STAR_index\n        STAR \\\n            --runThreadN ${task.cpus} \\\n            --runMode genomeGenerate \\\n            --genomeDir STAR_index \\\n            --genomeFastaFiles ${genome} \\\n            --sjdbGTFfile ${annotation} \\\n            --sjdbOverhang ${processParams.sjdbOverhang} \\\n            --genomeSAindexNbases ${processParams.genomeSAindexNbases} # Suggested by STAR (default: 14), otherwise keeps on hanging\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "annotation",
            "genome"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.star.container",
            "label 'compute_resources__star_build_genome'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__TAG_READ_WITH_GENE_EXON": {
        "name_process": "SC__DROP_SEQ_TOOLS__TAG_READ_WITH_GENE_EXON",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__TAG_READ_WITH_GENE_EXON {\n\n    publishDir \"${params.global.outdir}/02.map\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sample), path(bam)\n        file(annotation)\n\n    output:\n        tuple val(sample), path(\"*.merged_gene-exon-tagged.bam\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.tag_read_with_gene_exon)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        source $DWMAX/documents/aertslab/scripts/src_dwmax/bash-utils/utils.sh\n        software load drop-seq_tools/1.12\n        TagReadWithGeneExon \\\n            I=${bam} \\\n            O=${sample}.merged_gene-exon-tagged.bam \\\n            ANNOTATIONS_FILE=${annotation} \\\n            TAG=${processParams.tag}\n        \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.tag_read_with_gene_exon)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        source $DWMAX/documents/aertslab/scripts/src_dwmax/bash-utils/utils.sh\n        software load drop-seq_tools/1.12\n        TagReadWithGeneExon \\\n            I=${bam} \\\n            O=${sample}.merged_gene-exon-tagged.bam \\\n            ANNOTATIONS_FILE=${annotation} \\\n            TAG=${processParams.tag}\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "ABI software"
        ],
        "tools_url": [
            "https://bio.tools/ABI_software"
        ],
        "tools_dico": [
            {
                "name": "ABI software",
                "uri": "https://bio.tools/ABI_software",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "Neurology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "https://en.wikipedia.org/wiki/Neurology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Experimental Brain Computer Interface Software for the ModularEEG.",
                "homepage": "https://users.dcc.uchile.cl/~peortega/abi/"
            }
        ],
        "inputs": [
            "sample",
            "bam",
            "annotation"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/02.map\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "BWAMAPTOOLS__MAPPING_SUMMARY": {
        "name_process": "BWAMAPTOOLS__MAPPING_SUMMARY",
        "string_process": "\nprocess BWAMAPTOOLS__MAPPING_SUMMARY {\n\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(bam),\n              path(bai)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.mapping_stats.tsv\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        ${binDir}mapping_summary.sh \\\n            ${sampleId} \\\n            ${bam} \\\n        \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        ${binDir}mapping_summary.sh \\\n            ${sampleId} \\\n            ${bam} \\\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "FLYBASER__CONVERT_FBGN_TO_GENE_SYMBOL": {
        "name_process": "FLYBASER__CONVERT_FBGN_TO_GENE_SYMBOL",
        "string_process": "\nprocess FLYBASER__CONVERT_FBGN_TO_GENE_SYMBOL {\n    \n    container params.tools.flybaser.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f)\n    \n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.FLYBASER__CONVERT_FBGN_TO_GENE_SYMBOL.tsv\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.flybaser.convert_fbgn_to_gene_symbol)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}convertFBgnToGeneSymbol.R \\\n            ${f} \\\n            ${processParams.columnName} \\\n            \"${sampleId}.FLYBASER__CONVERT_FBGN_TO_GENE_SYMBOL.tsv\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 26,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.flybaser.convert_fbgn_to_gene_symbol)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}convertFBgnToGeneSymbol.R \\\n            ${f} \\\n            ${processParams.columnName} \\\n            \"${sampleId}.FLYBASER__CONVERT_FBGN_TO_GENE_SYMBOL.tsv\"\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.flybaser.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__UTILS__UPDATE_FEATURE_METADATA_INDEX": {
        "name_process": "SC__UTILS__UPDATE_FEATURE_METADATA_INDEX",
        "string_process": "\nprocess SC__UTILS__UPDATE_FEATURE_METADATA_INDEX {\n\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId), path(f), path(additionalMetadata)\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}.SC__UTILS__UPDATE_FEATURE_METADATA_INDEX.h5ad\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.update_feature_metadata_index)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/sc_h5ad_update_metadata.py \\\n            --additional-metadata ${additionalMetadata} \\\n            --axis feature \\\n            --index-column-name ${processParams.indexColumnName} \\\n            --join-key ${processParams.joinKey} \\\n            $f \\\n            \"${sampleId}.SC__UTILS__UPDATE_FEATURE_METADATA_INDEX.h5ad\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.utils.update_feature_metadata_index)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/sc_h5ad_update_metadata.py \\\n            --additional-metadata ${additionalMetadata} \\\n            --axis feature \\\n            --index-column-name ${processParams.indexColumnName} \\\n            --join-key ${processParams.joinKey} \\\n            $f \\\n            \"${sampleId}.SC__UTILS__UPDATE_FEATURE_METADATA_INDEX.h5ad\"\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "additionalMetadata"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "CISTARGET": {
        "name_process": "CISTARGET",
        "string_process": "\nprocess CISTARGET {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}/cistarget/${\"numRuns\" in toolParams && toolParams.numRuns > 1 ? \"run_\" + runId : \"\"}\", mode: 'link', overwrite: true\n    label 'compute_resources__scenic_cistarget'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(filteredLoom), \\\n            path(f), \\\n            val(runId)\n        file featherDB\n        file annotation\n        val type\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(filteredLoom), \\\n            path(\"${outputFileName}\"), \\\n            val(runId)\n\n    script:\n        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? sampleId + \"__run_\" + runId +\"__reg_\" + type + \".csv.gz\" : sampleId + \"__reg_\" + type + \".csv.gz\"\n        \"\"\"\n        export MKL_NUM_THREADS=1\n\t\texport NUMEXPR_NUM_THREADS=1\n\t\texport OMP_NUM_THREADS=1\n        pyscenic ctx \\\n            ${f} \\\n            ${featherDB} \\\n            ${processParams.containsKey('all_modules') && processParams.all_modules ? '--all_modules': ''} \\\n            --annotations_fname ${annotation} \\\n            --expression_mtx_fname ${filteredLoom} \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n            --mode \"dask_multiprocessing\" \\\n            --output ${outputFileName} \\\n            --num_workers ${task.cpus} \\\n        \"\"\"\n\n}",
        "nb_lignes_process": 45,
        "string_script": "        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? sampleId + \"__run_\" + runId +\"__reg_\" + type + \".csv.gz\" : sampleId + \"__reg_\" + type + \".csv.gz\"\n        \"\"\"\n        export MKL_NUM_THREADS=1\n\t\texport NUMEXPR_NUM_THREADS=1\n\t\texport OMP_NUM_THREADS=1\n        pyscenic ctx \\\n            ${f} \\\n            ${featherDB} \\\n            ${processParams.containsKey('all_modules') && processParams.all_modules ? '--all_modules': ''} \\\n            --annotations_fname ${annotation} \\\n            --expression_mtx_fname ${filteredLoom} \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n            --mode \"dask_multiprocessing\" \\\n            --output ${outputFileName} \\\n            --num_workers ${task.cpus} \\\n        \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "filteredLoom",
            "f",
            "runId",
            "featherDB",
            "annotation",
            "type"
        ],
        "nb_inputs": 7,
        "outputs": [
            "sampleId",
            "filteredLoom",
            "runId"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}/cistarget/${\"numRuns\" in toolParams && toolParams.numRuns > 1 ? \"run_\" + runId : \"\"}\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic_cistarget'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER_ATAC__COUNT": {
        "name_process": "SC__CELLRANGER_ATAC__COUNT",
        "string_process": "\nprocess SC__CELLRANGER_ATAC__COUNT {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${params.global.outdir}/counts\", mode: 'link', overwrite: true\n    label 'compute_resources__cellranger_count'\n\n    input:\n        file(reference)\n        tuple val(sampleId), file(fastqs)\n\n    output:\n        tuple val(sampleId), file(\"${sampleId}/outs\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n        processParams = sampleParams.local\n        if(processParams.sample == '') {\n            throw new Exception(\"Regards params.tools.cellranger_atac.count: sample parameter cannot be empty\")\n        }\n        runCellRangerAtacCount(\n            sampleId,\n            sampleId,\n            fastqs,\n            processParams,\n            task\n        )\n\n}",
        "nb_lignes_process": 28,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n        processParams = sampleParams.local\n        if(processParams.sample == '') {\n            throw new Exception(\"Regards params.tools.cellranger_atac.count: sample parameter cannot be empty\")\n        }\n        runCellRangerAtacCount(\n            sampleId,\n            sampleId,\n            fastqs,\n            processParams,\n            task\n        )",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "MD-TASK"
        ],
        "tools_url": [
            "https://bio.tools/md-task"
        ],
        "tools_dico": [
            {
                "name": "MD-TASK",
                "uri": "https://bio.tools/md-task",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2258",
                            "term": "Cheminformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2258",
                            "term": "Chemoinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2258",
                            "term": "Chemical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2476",
                                    "term": "Molecular dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2476",
                                    "term": "Molecular dynamics simulation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tool suite for analysing molecular dynamics trajectories using network analysis and PRS.",
                "homepage": "https://github.com/RUBi-ZA/MD-TASK"
            }
        ],
        "inputs": [
            "reference",
            "sampleId",
            "fastqs"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/counts\", mode: 'link', overwrite: true",
            "label 'compute_resources__cellranger_count'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER_ATAC__COUNT_WITH_METADATA": {
        "name_process": "SC__CELLRANGER_ATAC__COUNT_WITH_METADATA",
        "string_process": "\nprocess SC__CELLRANGER_ATAC__COUNT_WITH_METADATA {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${params.global.outdir}/counts\", mode: 'link', overwrite: true\n    label 'compute_resources__cellranger_count'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            val(samplePrefix), \\\n            file(fastqs), \\\n            val(expectCells)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            file(\"${sampleId}/outs\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n        processParams = sampleParams.local\n        runCellRangerAtacCount(\n            sampleId,\n            samplePrefix,\n            fastqs,\n            processParams,\n            task,\n            expectCells\n        )\n\n}",
        "nb_lignes_process": 31,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.count)\n        processParams = sampleParams.local\n        runCellRangerAtacCount(\n            sampleId,\n            samplePrefix,\n            fastqs,\n            processParams,\n            task,\n            expectCells\n        )",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "samplePrefix",
            "fastqs",
            "expectCells"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/counts\", mode: 'link', overwrite: true",
            "label 'compute_resources__cellranger_count'"
        ],
        "when": "",
        "stub": ""
    },
    "AGGR_MULTI_RUNS_REGULONS": {
        "name_process": "AGGR_MULTI_RUNS_REGULONS",
        "string_process": "\nprocess AGGR_MULTI_RUNS_REGULONS {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}\", mode: 'link', overwrite: true\n    label 'compute_resources__scenic_multiruns'\n\n    input:\n\t\ttuple val(sampleId), path(f)\n\t\tval type\n\n    output:\n    \ttuple val(sampleId), path(\"multi_runs_regulons_${type}\")\n\n\tscript:\n\t\t\"\"\"\n\t\t${binDir}aggregate_multi_runs_regulons.py \\\n\t\t\t${f} \\\n\t\t\t--output \"multi_runs_regulons_${type}\" \\\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "\t\t\"\"\"\n\t\t${binDir}aggregate_multi_runs_regulons.py \\\n\t\t\t${f} \\\n\t\t\t--output \"multi_runs_regulons_${type}\" \\\n\t\t\"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic_multiruns'"
        ],
        "when": "",
        "stub": ""
    },
    "FASTP__ADAPTER_TRIMMING": {
        "name_process": "FASTP__ADAPTER_TRIMMING",
        "string_process": "\nprocess FASTP__ADAPTER_TRIMMING {\n\n    container toolParams.container\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(fastq_PE1),\n              path(fastq_PE2)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}_dex_R1_val_1.fq.gz\"),\n              path(\"${sampleId}_dex_R2_val_2.fq.gz\"),\n              path(\"${sampleId}_fastp.html\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        def max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        fastp \\\n            --in1 ${fastq_PE1} \\\n            --in2 ${fastq_PE2} \\\n            --out1 ${sampleId}_dex_R1_val_1.fq.gz \\\n            --out2 ${sampleId}_dex_R2_val_2.fq.gz \\\n            --detect_adapter_for_pe \\\n            --html ${sampleId}_fastp.html \\\n            --thread ${max_threads}\n        \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        def max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        fastp \\\n            --in1 ${fastq_PE1} \\\n            --in2 ${fastq_PE2} \\\n            --out1 ${sampleId}_dex_R1_val_1.fq.gz \\\n            --out2 ${sampleId}_dex_R2_val_2.fq.gz \\\n            --detect_adapter_for_pe \\\n            --html ${sampleId}_fastp.html \\\n            --thread ${max_threads}\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "sampleId",
            "fastq_PE1",
            "fastq_PE2"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__TRIM_POLYA_UNALIGNED_TAGGED_TRIMMED_SMART": {
        "name_process": "SC__DROP_SEQ_TOOLS__TRIM_POLYA_UNALIGNED_TAGGED_TRIMMED_SMART",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__TRIM_POLYA_UNALIGNED_TAGGED_TRIMMED_SMART {\n\n    container params.tools.dropseqtools.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n    tuple val(sample), path(bam)\n\n    output:\n    tuple val(sample), path('*.unaligned_tagged_polyA_filtered.bam'), emit: bam\n    tuple file('*.polyA_trimming_report.txt'), emit: report\n\n    script:\n    def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.trim_polya_unaligned_tagged_trimmed_smart)\n\t\tprocessParams = sampleParams.local\n    \"\"\"\n    PolyATrimmer \\\n        INPUT=${bam} \\\n        OUTPUT=${sample}.unaligned_tagged_polyA_filtered.bam \\\n        OUTPUT_SUMMARY=${sample}.polyA_trimming_report.txt \\\n        MISMATCHES=${processParams.mismatches} \\\n        NUM_BASES=${processParams.numBases}\n    \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "    def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.trim_polya_unaligned_tagged_trimmed_smart)\n\t\tprocessParams = sampleParams.local\n    \"\"\"\n    PolyATrimmer \\\n        INPUT=${bam} \\\n        OUTPUT=${sample}.unaligned_tagged_polyA_filtered.bam \\\n        OUTPUT_SUMMARY=${sample}.polyA_trimming_report.txt \\\n        MISMATCHES=${processParams.mismatches} \\\n        NUM_BASES=${processParams.numBases}\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER_ATAC__MKFASTQ": {
        "name_process": "SC__CELLRANGER_ATAC__MKFASTQ",
        "string_process": "\nprocess SC__CELLRANGER_ATAC__MKFASTQ {\n\n    publishDir \"${params.global.outdir}/fastqs\", saveAs: { filename -> dirname = filename =~ /(.*)_fastqOut/; \"${dirname[0][1]}\" }, mode: 'link', overwrite: true\n    container toolParams.container\n    label 'compute_resources__cellranger_mkfastq'\n\n    input:\n        file(csv)\n        file(runFolder)\n\n    output:\n        file \"*_fastqOut\"\n\n    script:\n        \"\"\"\n        cellranger-atac mkfastq \\\n            --run=${runFolder} \\\n            --csv=${csv} \\\n            ${(toolParams.mkfastq.containsKey('samplesheet')) ? '--samplesheet ' + toolParams.mkfastq.samplesheet: ''} \\\n            ${(toolParams.mkfastq.containsKey('qc')) ? '--qc ' + toolParams.mkfastq.qc: ''} \\\n            ${(toolParams.mkfastq.containsKey('lanes')) ? '--lanes ' + toolParams.mkfastq.lanes: ''} \\\n            ${(toolParams.mkfastq.containsKey('useBasesMask')) ? '--use-bases-mask ' + toolParams.mkfastq.useBasesMask: ''} \\\n            ${(toolParams.mkfastq.containsKey('deleteUndetermined')) ? '--delete-undetermined ' + toolParams.mkfastq.deleteUndetermined: ''} \\\n            ${(toolParams.mkfastq.containsKey('outputDir')) ? '--output-dir ' + toolParams.mkfastq.outputDir: ''} \\\n            ${(toolParams.mkfastq.containsKey('project')) ? '--project ' + toolParams.mkfastq.project: ''} \\\n            --jobmode=local \\\n            --localcores=${task.cpus} \\\n            --localmem=${task.memory.toGiga()}\n        \n        for sample in \\$(tail -n+2 ${csv} | cut -f2 -d','); do\n            ln -s ${(params.global.containsKey('outputDir')) ? params.global.outputDir + \"*/\\${sample}\" : \"*/outs/fastq_path/*/\\${sample}\"} \\${sample}_fastqOut\n        done\n        \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "        \"\"\"\n        cellranger-atac mkfastq \\\n            --run=${runFolder} \\\n            --csv=${csv} \\\n            ${(toolParams.mkfastq.containsKey('samplesheet')) ? '--samplesheet ' + toolParams.mkfastq.samplesheet: ''} \\\n            ${(toolParams.mkfastq.containsKey('qc')) ? '--qc ' + toolParams.mkfastq.qc: ''} \\\n            ${(toolParams.mkfastq.containsKey('lanes')) ? '--lanes ' + toolParams.mkfastq.lanes: ''} \\\n            ${(toolParams.mkfastq.containsKey('useBasesMask')) ? '--use-bases-mask ' + toolParams.mkfastq.useBasesMask: ''} \\\n            ${(toolParams.mkfastq.containsKey('deleteUndetermined')) ? '--delete-undetermined ' + toolParams.mkfastq.deleteUndetermined: ''} \\\n            ${(toolParams.mkfastq.containsKey('outputDir')) ? '--output-dir ' + toolParams.mkfastq.outputDir: ''} \\\n            ${(toolParams.mkfastq.containsKey('project')) ? '--project ' + toolParams.mkfastq.project: ''} \\\n            --jobmode=local \\\n            --localcores=${task.cpus} \\\n            --localmem=${task.memory.toGiga()}\n        \n        for sample in \\$(tail -n+2 ${csv} | cut -f2 -d','); do\n            ln -s ${(params.global.containsKey('outputDir')) ? params.global.outputDir + \"*/\\${sample}\" : \"*/outs/fastq_path/*/\\${sample}\"} \\${sample}_fastqOut\n        done\n        \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "csv",
            "runFolder"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/fastqs\", saveAs: { filename -> dirname = filename =~ /(.*)_fastqOut/; \"${dirname[0][1]}\" }, mode: 'link', overwrite: true",
            "container toolParams.container",
            "label 'compute_resources__cellranger_mkfastq'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD__MERGE_BAM_ALIGNMENT": {
        "name_process": "PICARD__MERGE_BAM_ALIGNMENT",
        "string_process": "\nprocess PICARD__MERGE_BAM_ALIGNMENT {\n\n    container params.tools.picard.container\n    publishDir \"${params.global.outdir}/02.map\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sample), path(unmappedBam)\n        tuple val(sample), path(mappedBam)\n        file(genome)\n        file(dict)\n        file(tmpDir)\n\n    output:\n        tuple val(sample), path(\"*.merged.bam\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.picard.merge_bam_alignment)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                MergeBamAlignment \\\n                    REFERENCE_SEQUENCE=${genome} \\\n                    UNMAPPED_BAM=${unmappedBam} \\\n                    ALIGNED_BAM=${mappedBam} \\\n                    OUTPUT=${sample}.merged.bam \\\n                    INCLUDE_SECONDARY_ALIGNMENTS=${processParams.includeSecondaryAlignments} \\\n                    PAIRED_RUN=${processParams.pairedRun}\n        \"\"\"\n\n}",
        "nb_lignes_process": 31,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.picard.merge_bam_alignment)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                MergeBamAlignment \\\n                    REFERENCE_SEQUENCE=${genome} \\\n                    UNMAPPED_BAM=${unmappedBam} \\\n                    ALIGNED_BAM=${mappedBam} \\\n                    OUTPUT=${sample}.merged.bam \\\n                    INCLUDE_SECONDARY_ALIGNMENTS=${processParams.includeSecondaryAlignments} \\\n                    PAIRED_RUN=${processParams.pairedRun}\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "unmappedBam",
            "sample",
            "mappedBam",
            "genome",
            "dict",
            "tmpDir"
        ],
        "nb_inputs": 7,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.picard.container",
            "publishDir \"${params.global.outdir}/02.map\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__TRIM_SMART_UNALIGNED_TAGGED_FILTERED_BAM": {
        "name_process": "SC__DROP_SEQ_TOOLS__TRIM_SMART_UNALIGNED_TAGGED_FILTERED_BAM",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__TRIM_SMART_UNALIGNED_TAGGED_FILTERED_BAM {\n\n    container params.tools.dropseqtools.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sample), path(bam)\n\n    output:\n        tuple val(sample), path('*.unaligned_tagged_trimmed_smart.bam'), emit: bam\n        tuple file('*.adapter_trimming_report.txt'), emit: report\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.trim_smart_unaligned_tagged_filtered_bam)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        TrimStartingSequence \\\n            INPUT=${bam} \\\n            OUTPUT=${sample}.unaligned_tagged_trimmed_smart.bam \\\n            OUTPUT_SUMMARY=${sample}.adapter_trimming_report.txt \\\n            SEQUENCE=${processParams.adapterSequence} \\\n            MISMATCHES=${processParams.mismatches} \\\n            NUM_BASES=${processParams.numBases}\n        \"\"\"\n\n}",
        "nb_lignes_process": 26,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.trim_smart_unaligned_tagged_filtered_bam)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        TrimStartingSequence \\\n            INPUT=${bam} \\\n            OUTPUT=${sample}.unaligned_tagged_trimmed_smart.bam \\\n            OUTPUT_SUMMARY=${sample}.adapter_trimming_report.txt \\\n            SEQUENCE=${processParams.adapterSequence} \\\n            MISMATCHES=${processParams.mismatches} \\\n            NUM_BASES=${processParams.numBases}\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__FILTER_UNALIGNED_TAGGED_BAM": {
        "name_process": "SC__DROP_SEQ_TOOLS__FILTER_UNALIGNED_TAGGED_BAM",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__FILTER_UNALIGNED_TAGGED_BAM {\n\n    container params.tools.dropseqtools.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sample), path(bam)\n\n    output:\n        tuple val(sample), path('*.unaligned_tagged_filtered.bam'), emit: bam\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.filter_unaligned_tagged_bam)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        FilterBAM \\\n            TAG_REJECT=${processParams.tagReject} \\\n            INPUT=${bam} \\\n            OUTPUT=${sample}.unaligned_tagged_filtered.bam\n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.filter_unaligned_tagged_bam)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        FilterBAM \\\n            TAG_REJECT=${processParams.tagReject} \\\n            INPUT=${bam} \\\n            OUTPUT=${sample}.unaligned_tagged_filtered.bam\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SCTK__EXTRACT_HYDROP_ATAC_BARCODE": {
        "name_process": "SCTK__EXTRACT_HYDROP_ATAC_BARCODE",
        "string_process": "\nprocess SCTK__EXTRACT_HYDROP_ATAC_BARCODE {\n\n    container toolParams.container\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              val(technology),\n              path(fastq_PE1),\n              path(fastq_bc),\n              path(fastq_PE2)\n        val(hydrop_atac_barcode_design)\n\n    output:\n        tuple val(sampleId),\n              val(technology),\n              path(fastq_PE1),\n              path(\"${sampleId}_hydrop_barcode_R2.fastq.gz\"),\n              path(fastq_PE2)\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n                                            \n        \"\"\"\n        extract_hydrop_atac_barcode_from_R2_fastq.sh \\\n            ${fastq_bc} \\\n            ${sampleId}_hydrop_barcode_R2.fastq.gz \\\n            ${hydrop_atac_barcode_design} \\\n            pigz\n        \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n                                            \n        \"\"\"\n        extract_hydrop_atac_barcode_from_R2_fastq.sh \\\n            ${fastq_bc} \\\n            ${sampleId}_hydrop_barcode_R2.fastq.gz \\\n            ${hydrop_atac_barcode_design} \\\n            pigz\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "technology",
            "fastq_PE1",
            "fastq_bc",
            "fastq_PE2",
            "hydrop_atac_barcode_design"
        ],
        "nb_inputs": 6,
        "outputs": [
            "technology"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__COMPUTE_QC_STATS": {
        "name_process": "SC__SCANPY__COMPUTE_QC_STATS",
        "string_process": "\nprocess SC__SCANPY__COMPUTE_QC_STATS {\n\n  \tcontainer params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n  \tinput:\n        tuple val(sampleId), path(f)\n\n\toutput:\n        tuple val(sampleId), path(\"${sampleId}.SC__SCANPY__COMPUTE_QC_STATS.${processParams.off}\")\n\n\tscript:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.filter)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/filter/sc_cell_gene_filtering.py \\\n            compute \\\n            $f \\\n            ${sampleId}.SC__SCANPY__COMPUTE_QC_STATS.${processParams.off} \\\n            ${processParams?.cellFilterStrategy ? '--cell-filter-strategy ' + processParams.cellFilterStrategy : ''} \\\n            ${processParams?.cellFilterMinNCounts ? '--min-n-counts ' + processParams.cellFilterMinNCounts : ''} \\\n            ${processParams?.cellFilterMaxNCounts ? '--max-n-counts ' + processParams.cellFilterMaxNCounts : ''} \\\n            ${processParams?.cellFilterMinNGenes ? '--min-n-genes ' + processParams.cellFilterMinNGenes : ''} \\\n            ${processParams?.cellFilterMaxNGenes ? '--max-n-genes ' + processParams.cellFilterMaxNGenes : ''} \\\n            ${processParams?.cellFilterMaxPercentMito ? '--max-percent-mito ' + processParams.cellFilterMaxPercentMito : ''} \\\n            ${processParams?.geneFilterMinNCells ? '--min-number-cells ' + processParams.geneFilterMinNCells : ''}\n        \"\"\"\n\n}",
        "nb_lignes_process": 29,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.filter)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/filter/sc_cell_gene_filtering.py \\\n            compute \\\n            $f \\\n            ${sampleId}.SC__SCANPY__COMPUTE_QC_STATS.${processParams.off} \\\n            ${processParams?.cellFilterStrategy ? '--cell-filter-strategy ' + processParams.cellFilterStrategy : ''} \\\n            ${processParams?.cellFilterMinNCounts ? '--min-n-counts ' + processParams.cellFilterMinNCounts : ''} \\\n            ${processParams?.cellFilterMaxNCounts ? '--max-n-counts ' + processParams.cellFilterMaxNCounts : ''} \\\n            ${processParams?.cellFilterMinNGenes ? '--min-n-genes ' + processParams.cellFilterMinNGenes : ''} \\\n            ${processParams?.cellFilterMaxNGenes ? '--max-n-genes ' + processParams.cellFilterMaxNGenes : ''} \\\n            ${processParams?.cellFilterMaxPercentMito ? '--max-percent-mito ' + processParams.cellFilterMaxPercentMito : ''} \\\n            ${processParams?.geneFilterMinNCells ? '--min-number-cells ' + processParams.geneFilterMinNCells : ''}\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "Computel"
        ],
        "tools_url": [
            "https://bio.tools/computel"
        ],
        "tools_dico": [
            {
                "name": "Computel",
                "uri": "https://bio.tools/computel",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Nucleic acid feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Sequence feature detection (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Computation of Mean Telomere Length from Whole-Genome Next-Generation Sequencing Data.",
                "homepage": "https://github.com/lilit-nersisyan/computel"
            }
        ],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__GENE_FILTER": {
        "name_process": "SC__SCANPY__GENE_FILTER",
        "string_process": "\nprocess SC__SCANPY__GENE_FILTER {\n\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n    input:\n        tuple val(sampleId), path(f)\n\n\toutput:\n        tuple val(sampleId), path(\"${sampleId}.SC__SCANPY__GENE_FILTER.${processParams.off}\")\n\n\tscript:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.filter)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/filter/sc_cell_gene_filtering.py \\\n            genefilter \\\n            $f \\\n            ${sampleId}.SC__SCANPY__GENE_FILTER.${processParams.off} \\\n            ${processParams?.geneFilterMinNCells ? '--min-number-cells ' + processParams.geneFilterMinNCells : ''}\n        \"\"\"\n\n}",
        "nb_lignes_process": 23,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.filter)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/filter/sc_cell_gene_filtering.py \\\n            genefilter \\\n            $f \\\n            ${sampleId}.SC__SCANPY__GENE_FILTER.${processParams.off} \\\n            ${processParams?.geneFilterMinNCells ? '--min-number-cells ' + processParams.geneFilterMinNCells : ''}\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "genefilter"
        ],
        "tools_url": [
            "https://bio.tools/genefilter"
        ],
        "tools_dico": [
            {
                "name": "genefilter",
                "uri": "https://bio.tools/genefilter",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3321",
                            "term": "Molecular genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3695",
                                    "term": "Filtering"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Some basic functions for filtering genes.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/genefilter.html"
            }
        ],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__CELL_FILTER": {
        "name_process": "SC__SCANPY__CELL_FILTER",
        "string_process": "\nprocess SC__SCANPY__CELL_FILTER {\n\n    container params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n    input:\n        tuple val(sampleId), path(f)\n\n\toutput:\n        tuple val(sampleId), path(\"${sampleId}.SC__SCANPY__CELL_FILTER.${processParams.off}\")\n    \n\tscript:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.filter)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/filter/sc_cell_gene_filtering.py \\\n            cellfilter \\\n            $f \\\n            ${sampleId}.SC__SCANPY__CELL_FILTER.${processParams.off} \\\n            ${processParams?.cellFilterStrategy ? '--cell-filter-strategy ' + processParams.cellFilterStrategy : ''} \\\n            ${processParams?.cellFilterMinNCounts ? '--min-n-counts ' + processParams.cellFilterMinNCounts : ''} \\\n            ${processParams?.cellFilterMaxNCounts ? '--max-n-counts ' + processParams.cellFilterMaxNCounts : ''} \\\n            ${processParams?.cellFilterMinNGenes ? '--min-n-genes ' + processParams.cellFilterMinNGenes : ''} \\\n            ${processParams?.cellFilterMaxNGenes ? '--max-n-genes ' + processParams.cellFilterMaxNGenes : ''} \\\n            ${processParams?.cellFilterMaxPercentMito ? '--max-percent-mito ' + processParams.cellFilterMaxPercentMito : ''}\n        \"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.filter)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}/filter/sc_cell_gene_filtering.py \\\n            cellfilter \\\n            $f \\\n            ${sampleId}.SC__SCANPY__CELL_FILTER.${processParams.off} \\\n            ${processParams?.cellFilterStrategy ? '--cell-filter-strategy ' + processParams.cellFilterStrategy : ''} \\\n            ${processParams?.cellFilterMinNCounts ? '--min-n-counts ' + processParams.cellFilterMinNCounts : ''} \\\n            ${processParams?.cellFilterMaxNCounts ? '--max-n-counts ' + processParams.cellFilterMaxNCounts : ''} \\\n            ${processParams?.cellFilterMinNGenes ? '--min-n-genes ' + processParams.cellFilterMinNGenes : ''} \\\n            ${processParams?.cellFilterMaxNGenes ? '--max-n-genes ' + processParams.cellFilterMaxNGenes : ''} \\\n            ${processParams?.cellFilterMaxPercentMito ? '--max-percent-mito ' + processParams.cellFilterMaxPercentMito : ''}\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__DIM_REDUCTION": {
        "name_process": "SC__SCANPY__DIM_REDUCTION",
        "string_process": "\nprocess SC__SCANPY__DIM_REDUCTION {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__cpu'\n\n\tinput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(data), \\\n\t\t\tval(stashedParams), \\\n\t\t\tval(nComps)\n\n\toutput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__SCANPY__DIM_REDUCTION_${method}.${!isParamNull(stashedParams) ? uuid + '.' : ''}${processParams.off}\"), \\\n\t\t\tval(stashedParams), \\\n\t\t\tval(nComps)\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.dim_reduction.get(params.method))\n\t\tprocessParams = sampleParams.local\n\t\t                                                                                                      \n\t\t                                                       \n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\tmethod = processParams.method.replaceAll('-','').toUpperCase()\n\t\t                                                                                                 \n\t\tdef _processParams = new SC__SCANPY__DIM_REDUCTION_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n\t\t\"\"\"\n\t\t${binDir}/dim_reduction/sc_dim_reduction.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t--method ${processParams.method} \\\n\t\t\t${(processParams.containsKey('svdSolver')) ? '--svd-solver ' + processParams.svdSolver : ''} \\\n\t\t\t${(processParams.containsKey('perplexity')) ? '--perplexity ' + processParams.perplexity : ''} \\\n\t\t\t${(processParams.containsKey('nNeighbors')) ? '--n-neighbors ' + processParams.nNeighbors : ''} \\\n\t\t\t${_processParams.getNCompsAsArgument(nComps)} \\\n\t\t\t${(processParams.containsKey('nPcs')) ? '--n-pcs ' + processParams.nPcs : ''} \\\n            --n-jobs ${task.cpus} \\\n\t\t\t${(processParams.containsKey('useFastTsne')) ? '--use-fast-tsne ' + processParams.useFastTsne : ''} \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__SCANPY__DIM_REDUCTION_${method}.${!isParamNull(stashedParams) ? uuid + '.' : ''}${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 48,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.dim_reduction.get(params.method))\n\t\tprocessParams = sampleParams.local\n\t\t                                                                                                      \n\t\t                                                       \n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\tmethod = processParams.method.replaceAll('-','').toUpperCase()\n\t\t                                                                                                 \n\t\tdef _processParams = new SC__SCANPY__DIM_REDUCTION_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n\t\t\"\"\"\n\t\t${binDir}/dim_reduction/sc_dim_reduction.py \\\n\t\t\t--seed ${params.global.seed} \\\n\t\t\t--method ${processParams.method} \\\n\t\t\t${(processParams.containsKey('svdSolver')) ? '--svd-solver ' + processParams.svdSolver : ''} \\\n\t\t\t${(processParams.containsKey('perplexity')) ? '--perplexity ' + processParams.perplexity : ''} \\\n\t\t\t${(processParams.containsKey('nNeighbors')) ? '--n-neighbors ' + processParams.nNeighbors : ''} \\\n\t\t\t${_processParams.getNCompsAsArgument(nComps)} \\\n\t\t\t${(processParams.containsKey('nPcs')) ? '--n-pcs ' + processParams.nPcs : ''} \\\n            --n-jobs ${task.cpus} \\\n\t\t\t${(processParams.containsKey('useFastTsne')) ? '--use-fast-tsne ' + processParams.useFastTsne : ''} \\\n\t\t\t$data \\\n\t\t\t\"${sampleId}.SC__SCANPY__DIM_REDUCTION_${method}.${!isParamNull(stashedParams) ? uuid + '.' : ''}${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "pcaMethods"
        ],
        "tools_url": [
            "https://bio.tools/pcamethods"
        ],
        "tools_dico": [
            {
                "name": "pcaMethods",
                "uri": "https://bio.tools/pcamethods",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            },
                            {
                                "uri": "http://edamontology.org/data_1772",
                                "term": "Score"
                            },
                            {
                                "uri": "http://edamontology.org/data_2884",
                                "term": "Plot"
                            }
                        ]
                    }
                ],
                "description": "This tool provides BPCA, PPCA and NipalsPCA that can be used to perform PCA on incomplete data as well as for accurate missing value estimation. A set of methods for printing and plotting the results is also provided. All PCA methods make use of the same data structure to provide a common interface to the PCA results.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/pcaMethods.html"
            }
        ],
        "inputs": [
            "sampleId",
            "data",
            "stashedParams",
            "nComps"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId",
            "stashedParams",
            "nComps"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__CONVERT_TO_REFFLAT": {
        "name_process": "SC__DROP_SEQ_TOOLS__CONVERT_TO_REFFLAT",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__CONVERT_TO_REFFLAT {\n    \n    container params.tools.dropseqtools.container\n    publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        file(annotation)\n        file(seqdict)\n    \n    output:\n        file(\"${seqdict.baseName}.refFlat\")\n    \n    script:\n        \"\"\"\n        ConvertToRefFlat \\\n            ANNOTATIONS_FILE=${annotation} \\\n            SEQUENCE_DICTIONARY=${seqdict} \\\n            OUTPUT=${seqdict.baseName}.refFlat\n        \"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        ConvertToRefFlat \\\n            ANNOTATIONS_FILE=${annotation} \\\n            SEQUENCE_DICTIONARY=${seqdict} \\\n            OUTPUT=${seqdict.baseName}.refFlat\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotation",
            "seqdict"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER__PREFLIGHT": {
        "name_process": "SC__CELLRANGER__PREFLIGHT",
        "string_process": "\nprocess SC__CELLRANGER__PREFLIGHT {\n\n    exec:\n        if (toolParams.containsKey('container')) {\n            if (toolParams.container == '/path/to/cellranger/cellranger' || toolParams.container == '') {\n                throw new Exception(\"You must specify a container image for Cellranger!\")\n            }   \n        } else {\n            throw new Exception(\"No container entry\")\n        }\n        \n}",
        "nb_lignes_process": 11,
        "string_script": "        if (toolParams.containsKey('container')) {\n            if (toolParams.container == '/path/to/cellranger/cellranger' || toolParams.container == '') {\n                throw new Exception(\"You must specify a container image for Cellranger!\")\n            }   \n        } else {\n            throw new Exception(\"No container entry\")\n        }",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "PICARD__MARK_DUPLICATES_AND_SORT": {
        "name_process": "PICARD__MARK_DUPLICATES_AND_SORT",
        "string_process": "\nprocess PICARD__MARK_DUPLICATES_AND_SORT {\n\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(bam)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bam\"),\n              path(\"${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bai\"),\n              path(\"${sampleId}.bwa.out.fixmate.picard_markdup.metrics.txt\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        set -euo pipefail\n        gatk MarkDuplicates \\\n            -I ${bam} \\\n            -O /dev/stdout \\\n            --METRICS_FILE ${sampleId}.bwa.out.fixmate.picard_markdup.metrics.txt \\\n            --BARCODE_TAG CB \\\n            --COMPRESSION_LEVEL 0 \\\n            --QUIET true \\\n            --ASSUME_SORT_ORDER queryname \\\n        | gatk SortSam \\\n            -I /dev/stdin \\\n            -O ${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bam \\\n            --SORT_ORDER coordinate \\\n            --CREATE_INDEX true\n        \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        set -euo pipefail\n        gatk MarkDuplicates \\\n            -I ${bam} \\\n            -O /dev/stdout \\\n            --METRICS_FILE ${sampleId}.bwa.out.fixmate.picard_markdup.metrics.txt \\\n            --BARCODE_TAG CB \\\n            --COMPRESSION_LEVEL 0 \\\n            --QUIET true \\\n            --ASSUME_SORT_ORDER queryname \\\n        | gatk SortSam \\\n            -I /dev/stdin \\\n            -O ${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bam \\\n            --SORT_ORDER coordinate \\\n            --CREATE_INDEX true\n        \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "sampleId",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "GATK__MARK_DUPLICATES_SPARK": {
        "name_process": "GATK__MARK_DUPLICATES_SPARK",
        "string_process": "\nprocess GATK__MARK_DUPLICATES_SPARK {\n\n    container toolParams.container\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(bam)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bam\"),\n              path(\"${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bam.bai\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n                                            \n        \"\"\"\n        gatk MarkDuplicatesSpark \\\n            -I ${bam} \\\n            -O ${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bam \\\n            -- \\\n            --spark-runner LOCAL \\\n            --spark-master local[${task.cpus}]\n        \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n                                            \n        \"\"\"\n        gatk MarkDuplicatesSpark \\\n            -I ${bam} \\\n            -O ${sampleId}.bwa.out.fixmate.picard_markdup.possorted.bam \\\n            -- \\\n            --spark-runner LOCAL \\\n            --spark-master local[${task.cpus}]\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "sampleId",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__GENERATE_REPORT": {
        "name_process": "SC__SCANPY__GENERATE_REPORT",
        "string_process": "\nprocess SC__SCANPY__GENERATE_REPORT {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__report'\n\n\tinput:\n\t\tfile ipynb\n\t\ttuple val(sampleId), path(adata)\n\t\tval(reportTitle)\n\n\toutput:\n\t\ttuple val(sampleId), path(\"${sampleId}.${reportTitle}.ipynb\")\n\n\tscript:\n\t\tdef reportParams = new Yaml().dump(annotations_to_plot: params.tools.scanpy.report.annotations_to_plot)\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.${reportTitle}.ipynb \\\n\t\t\t-p FILE $adata \\\n\t\t\t-y \"${reportParams}\" \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 26,
        "string_script": "\t\tdef reportParams = new Yaml().dump(annotations_to_plot: params.tools.scanpy.report.annotations_to_plot)\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.${reportTitle}.ipynb \\\n\t\t\t-p FILE $adata \\\n\t\t\t-y \"${reportParams}\" \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ipynb",
            "sampleId",
            "adata",
            "reportTitle"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__PARAM_EXPLORE_CLUSTERING_GENERATE_REPORT": {
        "name_process": "SC__SCANPY__PARAM_EXPLORE_CLUSTERING_GENERATE_REPORT",
        "string_process": "\nprocess SC__SCANPY__PARAM_EXPLORE_CLUSTERING_GENERATE_REPORT {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/notebooks/intermediate/clustering/${isParamNull(method) ? \"default\": method.toLowerCase()}/${isParamNull(resolution) ? \"res_\": resolution}\", mode: 'symlink', overwrite: true\n    label 'compute_resources__report'\n\n\tinput:\n\t\tfile ipynb\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(adata), \\\n\t\t\tval(method), \\\n\t\t\tval(resolution)\n\t\tval(reportTitle)\n\n\toutput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.${reportTitle}.${uuid}.ipynb\"), \\\n\t\t\tval(method), \\\n\t\t\tval(resolution)\n\n\tscript:\n\t\t                                                                                                      \n\t\t                                                       \n\t\tstashedParams = [method, resolution]\n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\tdef reportParams = new Yaml().dump(annotations_to_plot: params.tools.scanpy.report.annotations_to_plot)\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.${reportTitle}.${uuid}.ipynb \\\n\t\t\t-p FILE $adata \\\n\t\t\t-y \"${reportParams}\" \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 39,
        "string_script": "\t\tstashedParams = [method, resolution]\n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\tdef reportParams = new Yaml().dump(annotations_to_plot: params.tools.scanpy.report.annotations_to_plot)\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.${reportTitle}.${uuid}.ipynb \\\n\t\t\t-p FILE $adata \\\n\t\t\t-y \"${reportParams}\" \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ipynb",
            "sampleId",
            "adata",
            "method",
            "resolution",
            "reportTitle"
        ],
        "nb_inputs": 6,
        "outputs": [
            "sampleId",
            "method",
            "resolution"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate/clustering/${isParamNull(method) ? \"default\": method.toLowerCase()}/${isParamNull(resolution) ? \"res_\": resolution}\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__GENERATE_DUAL_INPUT_REPORT": {
        "name_process": "SC__SCANPY__GENERATE_DUAL_INPUT_REPORT",
        "string_process": "\nprocess SC__SCANPY__GENERATE_DUAL_INPUT_REPORT {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__report'\n\n  \tinput:\n\t\tfile(ipynb)\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tfile(data1), \\\n\t\t\tfile(data2), \\\n\t\t\tval(stashedParams)\n\t\tval(reportTitle)\n\t\tval(isParameterExplorationModeOn)\n\n  \toutput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tfile(\"${sampleId}.${reportTitle}.${isParameterExplorationModeOn ? uuid + \".\" : ''}ipynb\"), \\\n\t\t\tval(stashedParams)\n\n  \tscript:\n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\tdef reportParams = new Yaml().dump(annotations_to_plot: params.tools.scanpy.report.annotations_to_plot)\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.${reportTitle}.${isParameterExplorationModeOn ? uuid + \".\" : ''}ipynb \\\n\t\t\t-p FILE1 $data1 -p FILE2 $data2 \\\n\t\t\t-y \"${reportParams}\" \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 36,
        "string_script": "\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\tdef reportParams = new Yaml().dump(annotations_to_plot: params.tools.scanpy.report.annotations_to_plot)\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.${reportTitle}.${isParameterExplorationModeOn ? uuid + \".\" : ''}ipynb \\\n\t\t\t-p FILE1 $data1 -p FILE2 $data2 \\\n\t\t\t-y \"${reportParams}\" \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ipynb",
            "sampleId",
            "data1",
            "data2",
            "stashedParams",
            "reportTitle",
            "isParameterExplorationModeOn"
        ],
        "nb_inputs": 7,
        "outputs": [
            "sampleId",
            "stashedParams"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__REPORT_TO_HTML": {
        "name_process": "SC__SCANPY__REPORT_TO_HTML",
        "string_process": "\nprocess SC__SCANPY__REPORT_TO_HTML {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true\n\t                                               \n\tpublishDir \"${params.global.outdir}/notebooks\", pattern: '*merged_report*', mode: 'link', overwrite: true\n    label 'compute_resources__report'\n\n\tinput:\n\t\ttuple val(sampleId), path(ipynb)\n\n\toutput:\n\t\tfile(\"*.html\")\n\n\tscript:\n\t\t\"\"\"\n\t\tjupyter nbconvert ${ipynb} --to html\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "\t\t\"\"\"\n\t\tjupyter nbconvert ${ipynb} --to html\n\t\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Jupyterhub"
        ],
        "tools_url": [
            "https://bio.tools/Jupyterhub"
        ],
        "tools_dico": [
            {
                "name": "Jupyterhub",
                "uri": "https://bio.tools/Jupyterhub",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Jupyter notebooks in science gateways.\n\nJupyter Notebooks empower scientists to create executable documents that include text, equations, code and figures. Notebooks are a simple way to create reproducible and shareable workflows. The Jupyter developers have also released a multi-user notebook environment: Jupyterhub. Jupyterhub provides an extensible platform for handling user authentication and spawning the Notebook application to each user. I developed a plugin for Jupyterhub to spawn notebooks on a Supercomputer and integrated the authentication with CILogon and XSEDE. Scientists can authenticate on their browser and connect to a Jupyter Notebook instance running on the computing node of a Supercomputer, in my test deployment SDSC Comet. Jupyterhub can benefit Science Gateways by providing an expressive interface to a centralized environment with many software tools pre-installed and allow scientists to access Gateway functionality via web API.\n\n||| HOMEPAGE MISSING!",
                "homepage": "https://doi.org/10.7287/PEERJ.PREPRINTS.2577V2"
            }
        ],
        "inputs": [
            "sampleId",
            "ipynb"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true",
            "publishDir \"${params.global.outdir}/notebooks\", pattern: '*merged_report*', mode: 'link', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__MERGE_REPORTS": {
        "name_process": "SC__SCANPY__MERGE_REPORTS",
        "string_process": "\nprocess SC__SCANPY__MERGE_REPORTS {\n\n\tcontainer params.tools.scanpy.container\n\tpublishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true\n\t                                                \n\tpublishDir \"${params.global.outdir}/notebooks\", pattern: '*merged_report*', mode: 'link', overwrite: true\n    label 'compute_resources__report'\n\n\tinput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(ipynbs), \\\n\t\t\tval(stashedParams)\n\t\tval(reportTitle)\n\t\tval(isParameterExplorationModeOn)\n\n\toutput:\n\t\ttuple val(sampleId), path(\"${sampleId}.${reportTitle}.${isParameterExplorationModeOn ? uuid + '.' : ''}ipynb\")\n\n\tscript:\n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\t\"\"\"\n\t\tnbmerge \\\n\t\t\t${ipynbs} \\\n\t\t\t-o \"${sampleId}.${reportTitle}.${isParameterExplorationModeOn ? uuid + '.' : ''}ipynb\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\t\"\"\"\n\t\tnbmerge \\\n\t\t\t${ipynbs} \\\n\t\t\t-o \"${sampleId}.${reportTitle}.${isParameterExplorationModeOn ? uuid + '.' : ''}ipynb\"\n\t\t\"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "ipynbs",
            "stashedParams",
            "reportTitle",
            "isParameterExplorationModeOn"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true",
            "publishDir \"${params.global.outdir}/notebooks\", pattern: '*merged_report*', mode: 'link', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__STAR__LOAD_GENOME": {
        "name_process": "SC__STAR__LOAD_GENOME",
        "string_process": "\nprocess SC__STAR__LOAD_GENOME {\n\n  \tcontainer params.tools.star.container\n    label 'compute_resources__default'\n\n\tinput:\n\t\tfile(starIndex)\n\n\toutput:\n\t\tval starIndexLoaded \n\n\tscript:\n\t\tstarIndexLoaded = true\n\t\t\"\"\"\n\t\tSTAR \\\n\t\t\t--genomeLoad LoadAndExit \\\n\t\t\t--genomeDir ${starIndex}\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "\t\tstarIndexLoaded = true\n\t\t\"\"\"\n\t\tSTAR \\\n\t\t\t--genomeLoad LoadAndExit \\\n\t\t\t--genomeDir ${starIndex}\n\t\t\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "starIndex"
        ],
        "nb_inputs": 1,
        "outputs": [
            "starIndexLoaded"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.star.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD__ESTIMATE_LIBRARY_COMPLEXITY": {
        "name_process": "PICARD__ESTIMATE_LIBRARY_COMPLEXITY",
        "string_process": "\nprocess PICARD__ESTIMATE_LIBRARY_COMPLEXITY {\n\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(bam)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.picard_library_complexity_metrics.txt\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.estimate_library_complexity)\n        processParams = sampleParams.local\n        \"\"\"\n        gatk EstimateLibraryComplexity \\\n            -I ${bam} \\\n            -O ${sampleId}.picard_library_complexity_metrics.txt \\\n            --BARCODE_TAG ${processParams.barcode_tag} \\\n        \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.estimate_library_complexity)\n        processParams = sampleParams.local\n        \"\"\"\n        gatk EstimateLibraryComplexity \\\n            -I ${bam} \\\n            -O ${sampleId}.picard_library_complexity_metrics.txt \\\n            --BARCODE_TAG ${processParams.barcode_tag} \\\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "sampleId",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SCTK__SATURATION": {
        "name_process": "SCTK__SATURATION",
        "string_process": "\nprocess SCTK__SATURATION {\n\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(fragments),\n              path(fragments_index)\n        file(bc_whitelists)\n        val(optional)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.sampling_stats.tsv\"),\n              path(\"${sampleId}.saturation.png\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        def bc_wl_param = optional == 'RUN' ? '-w selected_barcodes/' + sampleId + '.cell_barcodes.txt' : ''\n        def polars_max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        # Max threads polars is allowed to use (else will uses all cores).\n        export POLARS_MAX_THREADS=${polars_max_threads};\n        # Max threads pyarrow is allowed to use (else will uses all cores) (used to read the fragments file in the beginning).\n        export OMP_NUM_THREADS=${polars_max_threads};\n        calculate_saturation_from_fragments.py \\\n            -i ${fragments} \\\n            -o ${sampleId} \\\n            -p ${toolParams.saturation.percentages} \\\n            -m ${toolParams.saturation.min_frags_per_cb} \\\n            -s ${toolParams.saturation.sampling_fractions} \\\n            ${bc_wl_param}\n        \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        def bc_wl_param = optional == 'RUN' ? '-w selected_barcodes/' + sampleId + '.cell_barcodes.txt' : ''\n        def polars_max_threads = (task.cpus > 6) ? 6 : task.cpus\n        \"\"\"\n        # Max threads polars is allowed to use (else will uses all cores).\n        export POLARS_MAX_THREADS=${polars_max_threads};\n        # Max threads pyarrow is allowed to use (else will uses all cores) (used to read the fragments file in the beginning).\n        export OMP_NUM_THREADS=${polars_max_threads};\n        calculate_saturation_from_fragments.py \\\n            -i ${fragments} \\\n            -o ${sampleId} \\\n            -p ${toolParams.saturation.percentages} \\\n            -m ${toolParams.saturation.min_frags_per_cb} \\\n            -s ${toolParams.saturation.sampling_fractions} \\\n            ${bc_wl_param}\n        \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "fragments",
            "fragments_index",
            "bc_whitelists",
            "optional"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "PICARD__FASTQ_TO_BAM": {
        "name_process": "PICARD__FASTQ_TO_BAM",
        "string_process": "\nprocess PICARD__FASTQ_TO_BAM {\n\n    container params.tools.picard.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        file(reads)\n        file(tmpDir)\n    \n    output:\n        tuple val(sample), path('*.unaligned.bam'), emit: bam\n    \n    script:\n        sample = reads[0].toString() - ~/(_R1)?(\\.clean)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                FastqToSam \\\n                    FASTQ=${reads[0]} \\\n                    FASTQ2=${reads[1]} \\\n                    O=${sample}.unaligned.bam \\\n                    SAMPLE_NAME=${sample}\n        \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "        sample = reads[0].toString() - ~/(_R1)?(\\.clean)?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n        \"\"\"\n        java -Djava.io.tmpdir=$tmpDir -jar \\\n            /picard.jar \\\n                FastqToSam \\\n                    FASTQ=${reads[0]} \\\n                    FASTQ2=${reads[1]} \\\n                    O=${sample}.unaligned.bam \\\n                    SAMPLE_NAME=${sample}\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "SAMPLE"
        ],
        "tools_url": [
            "https://bio.tools/sample"
        ],
        "tools_dico": [
            {
                "name": "SAMPLE",
                "uri": "https://bio.tools/sample",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Linkage mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Functional mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic cartography"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map generation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The tool is designed to identify regions that are linked to a recessive disease by analysing genotype data from the parents and unaffected sibs of affected individuals. Since this analysis does not use data from affected patients, it is suited to the identification of lethal recessive genes, when the patients may have died before DNA samples could be obtained.",
                "homepage": "http://dna.leeds.ac.uk/sample/"
            }
        ],
        "inputs": [
            "reads",
            "tmpDir"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.picard.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROPLET_UTILS__BARCODE_SELECTION": {
        "name_process": "SC__DROPLET_UTILS__BARCODE_SELECTION",
        "string_process": "\nprocess SC__DROPLET_UTILS__BARCODE_SELECTION {\n    \n    container params.tools.dropletutils.container\n    publishDir \"03.count\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sample), path(readCounts)\n    \n    output:\n        tuple val(sample), val(\"knee\"), path(\"*.selected_cell_barcodes_by_knee.txt\"), emit: selectedCellBarcodesByKnee\n        tuple val(sample), val(\"inflection\"), path(\"*.selected_cell_barcodes_by_inflection.txt\"), emit: selectedCellBarcodesByInflection\n        tuple file(\"*.barcode_rank_vs_total_umi_plot.png\"), emit: plot\n    \n    script:\n        \"\"\"\n        Rscript ${workflow.projectDir}/src/dropletutils/bin/barcode_selection.R \\\n            ${readCounts} \\\n            ${sample}\n        \"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        Rscript ${workflow.projectDir}/src/dropletutils/bin/barcode_selection.R \\\n            ${readCounts} \\\n            ${sample}\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "readCounts"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropletutils.container",
            "publishDir \"03.count\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "PYCISTOPIC__BARCODE_LEVEL_STATISTICS": {
        "name_process": "PYCISTOPIC__BARCODE_LEVEL_STATISTICS",
        "string_process": "\nprocess PYCISTOPIC__BARCODE_LEVEL_STATISTICS {\n\n    publishDir \"${params.global.outdir}/intermediate/pycistopic/qc/\", mode: 'symlink'\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(metadata),\n              path(metadata_pkl),\n              path(profile_data_pkl)\n\n    output:\n        tuple val(sampleId),\n              path(selected_barcodes),\n              path(output_pdf_ff),\n              path(output_pdf_tf),\n              path(output_pdf_df)\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_level_statistics)\n        processParams = sampleParams.local\n        selected_barcodes = \"${sampleId}__selected_barcodes.txt\"\n        output_pdf_ff = \"${sampleId}__FRIP-vs-nFrag.pdf\"\n        output_pdf_tf = \"${sampleId}__TSS-vs-nFrag.pdf\"\n        output_pdf_df = \"${sampleId}__duprate-vs-nFrag.pdf\"\n        \"\"\"\n        export NUMEXPR_MAX_THREADS=${task.cpus}\n        ${binDir}barcode_level_statistics.py \\\n            --sampleId ${sampleId} \\\n            --metadata_pkl ${metadata_pkl} \\\n            --selected_barcodes ${selected_barcodes} \\\n            ${processParams?.filter_frags_lower    ? '--filter_frags_lower '    + processParams?.filter_frags_lower    : ''} \\\n            ${processParams?.filter_frags_upper    ? '--filter_frags_upper '    + processParams?.filter_frags_upper    : ''} \\\n            ${processParams?.filter_tss_lower      ? '--filter_tss_lower '      + processParams?.filter_tss_lower      : ''} \\\n            ${processParams?.filter_tss_upper      ? '--filter_tss_upper '      + processParams?.filter_tss_upper      : ''} \\\n            ${processParams?.filter_frip_lower     ? '--filter_frip_lower '     + processParams?.filter_frip_lower     : ''} \\\n            ${processParams?.filter_frip_upper     ? '--filter_frip_upper '     + processParams?.filter_frip_upper     : ''} \\\n            ${processParams?.filter_dup_rate_lower ? '--filter_dup_rate_lower ' + processParams?.filter_dup_rate_lower : ''} \\\n            ${processParams?.filter_dup_rate_upper ? '--filter_dup_rate_upper ' + processParams?.filter_dup_rate_upper : ''}\n        \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.barcode_level_statistics)\n        processParams = sampleParams.local\n        selected_barcodes = \"${sampleId}__selected_barcodes.txt\"\n        output_pdf_ff = \"${sampleId}__FRIP-vs-nFrag.pdf\"\n        output_pdf_tf = \"${sampleId}__TSS-vs-nFrag.pdf\"\n        output_pdf_df = \"${sampleId}__duprate-vs-nFrag.pdf\"\n        \"\"\"\n        export NUMEXPR_MAX_THREADS=${task.cpus}\n        ${binDir}barcode_level_statistics.py \\\n            --sampleId ${sampleId} \\\n            --metadata_pkl ${metadata_pkl} \\\n            --selected_barcodes ${selected_barcodes} \\\n            ${processParams?.filter_frags_lower    ? '--filter_frags_lower '    + processParams?.filter_frags_lower    : ''} \\\n            ${processParams?.filter_frags_upper    ? '--filter_frags_upper '    + processParams?.filter_frags_upper    : ''} \\\n            ${processParams?.filter_tss_lower      ? '--filter_tss_lower '      + processParams?.filter_tss_lower      : ''} \\\n            ${processParams?.filter_tss_upper      ? '--filter_tss_upper '      + processParams?.filter_tss_upper      : ''} \\\n            ${processParams?.filter_frip_lower     ? '--filter_frip_lower '     + processParams?.filter_frip_lower     : ''} \\\n            ${processParams?.filter_frip_upper     ? '--filter_frip_upper '     + processParams?.filter_frip_upper     : ''} \\\n            ${processParams?.filter_dup_rate_lower ? '--filter_dup_rate_lower ' + processParams?.filter_dup_rate_lower : ''} \\\n            ${processParams?.filter_dup_rate_upper ? '--filter_dup_rate_upper ' + processParams?.filter_dup_rate_upper : ''}\n        \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "metadata",
            "metadata_pkl",
            "profile_data_pkl"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/intermediate/pycistopic/qc/\", mode: 'symlink'",
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "PCACV__FIND_OPTIMAL_NPCS": {
        "name_process": "PCACV__FIND_OPTIMAL_NPCS",
        "string_process": "\nprocess PCACV__FIND_OPTIMAL_NPCS {\n    \n    container params.tools.pcacv.container\n    publishDir \"${params.global.outdir}/data/pcacv\", mode: 'link'\n    label 'compute_resources__pcacv'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            stdout, \\\n            emit: optimalNumberPC\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.PCACV__FIND_OPTIMAL_NPCS.*\"), \\\n            emit: files\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.pcacv.find_optimal_npcs)\n        processParams = sampleParams.local\n        \"\"\"\n        export OPENBLAS_NUM_THREADS=1\n        ${binDir}/run_pca_cv.R \\\n            --input-file ${f} \\\n            --seed ${params.global.seed} \\\n            ${(processParams.containsKey('accessor')) ? '--accessor \"' + processParams.accessor.replace('$','\\\\$') + '\"': ''} \\\n            ${(processParams.containsKey('useVariableFeatures')) ? '--use-variable-features ' + processParams.useVariableFeatures: ''} \\\n            ${(processParams.containsKey('kFold')) ? '--k-fold ' + processParams.kFold: ''} \\\n            ${(processParams.containsKey('fromNPC')) ? '--from-n-pc ' + processParams.fromNPC: ''} \\\n            ${(processParams.containsKey('toNPC')) ? '--to-n-pc ' + processParams.toNPC: ''} \\\n            ${(processParams.containsKey('byNPC')) ? '--by-n-pc ' + processParams.byNPC: ''} \\\n            ${(processParams.containsKey('nPCFallback')) ? '--n-pc-fallback ' + processParams.nPCFallback: ''} \\\n            ${(processParams.containsKey('maxIters')) ? '--max-iters ' + processParams.maxIters: ''} \\\n            --n-cores ${task.cpus} \\\n            ${(processParams.containsKey('defaultSVD')) ? '--default-svd ' + processParams.defaultSVD: ''} \\\n            ${(processParams.containsKey('verbose')) ? '--verbose ' + processParams.verbose: ''} \\\n            --output-prefix \"${sampleId}.PCACV__FIND_OPTIMAL_NPCS\" \\\n            > .command.log 2>&1\n        cat \"${sampleId}.PCACV__FIND_OPTIMAL_NPCS.OPTIMAL_NPCS.txt\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 45,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.pcacv.find_optimal_npcs)\n        processParams = sampleParams.local\n        \"\"\"\n        export OPENBLAS_NUM_THREADS=1\n        ${binDir}/run_pca_cv.R \\\n            --input-file ${f} \\\n            --seed ${params.global.seed} \\\n            ${(processParams.containsKey('accessor')) ? '--accessor \"' + processParams.accessor.replace('$','\\\\$') + '\"': ''} \\\n            ${(processParams.containsKey('useVariableFeatures')) ? '--use-variable-features ' + processParams.useVariableFeatures: ''} \\\n            ${(processParams.containsKey('kFold')) ? '--k-fold ' + processParams.kFold: ''} \\\n            ${(processParams.containsKey('fromNPC')) ? '--from-n-pc ' + processParams.fromNPC: ''} \\\n            ${(processParams.containsKey('toNPC')) ? '--to-n-pc ' + processParams.toNPC: ''} \\\n            ${(processParams.containsKey('byNPC')) ? '--by-n-pc ' + processParams.byNPC: ''} \\\n            ${(processParams.containsKey('nPCFallback')) ? '--n-pc-fallback ' + processParams.nPCFallback: ''} \\\n            ${(processParams.containsKey('maxIters')) ? '--max-iters ' + processParams.maxIters: ''} \\\n            --n-cores ${task.cpus} \\\n            ${(processParams.containsKey('defaultSVD')) ? '--default-svd ' + processParams.defaultSVD: ''} \\\n            ${(processParams.containsKey('verbose')) ? '--verbose ' + processParams.verbose: ''} \\\n            --output-prefix \"${sampleId}.PCACV__FIND_OPTIMAL_NPCS\" \\\n            > .command.log 2>&1\n        cat \"${sampleId}.PCACV__FIND_OPTIMAL_NPCS.OPTIMAL_NPCS.txt\"\n        \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId",
            "sampleId"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.pcacv.container",
            "publishDir \"${params.global.outdir}/data/pcacv\", mode: 'link'",
            "label 'compute_resources__pcacv'"
        ],
        "when": "",
        "stub": ""
    },
    "BWAMAPTOOLS__INDEX_BAM": {
        "name_process": "BWAMAPTOOLS__INDEX_BAM",
        "string_process": "\nprocess BWAMAPTOOLS__INDEX_BAM {\n\n    container toolParams.container\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              path(bam)\n\n    output:\n        tuple val(sampleId),\n              path(bam),\n              path(\"*.bai\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        samtools index ${bam}\n        \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        samtools index ${bam}\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sampleId",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "BWAMAPTOOLS__INDEX_BED": {
        "name_process": "BWAMAPTOOLS__INDEX_BED",
        "string_process": "\nprocess BWAMAPTOOLS__INDEX_BED {\n\n    container toolParams.container\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              path(bed)\n\n    output:\n        tuple val(sampleId),\n              path(\"*.tbi\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        tabix -p bed ${bed}\n        \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        tabix -p bed ${bed}\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "bed"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "BAP__BIORAD_DEBARCODE": {
        "name_process": "BAP__BIORAD_DEBARCODE",
        "string_process": "\nprocess BAP__BIORAD_DEBARCODE {\n\n    container toolParams.container\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(fastq_PE1),\n              path(fastq_PE2)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}*1.fastq.gz\"),\n              path(\"${sampleId}*2.fastq.gz\"),\n              path(\"${sampleId}-parse.sumstats.log\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.biorad_debarcode)\n        processParams = sampleParams.local\n        \"\"\"\n        bap-barcode ${processParams.protocol} \\\n            -a ${fastq_PE1} \\\n            -b ${fastq_PE2} \\\n            --ncores ${task.cpus} \\\n            --nmismatches ${processParams.nmismatches} \\\n            --output ${sampleId} \n        \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.biorad_debarcode)\n        processParams = sampleParams.local\n        \"\"\"\n        bap-barcode ${processParams.protocol} \\\n            -a ${fastq_PE1} \\\n            -b ${fastq_PE2} \\\n            --ncores ${task.cpus} \\\n            --nmismatches ${processParams.nmismatches} \\\n            --output ${sampleId} \n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "fastq_PE1",
            "fastq_PE2"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "BAP__MERGE_FASTQS": {
        "name_process": "BAP__MERGE_FASTQS",
        "string_process": "\nprocess BAP__MERGE_FASTQS {\n\n    container toolParams.container\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              path(fastq_PE1),\n              path(fastq_PE2),\n              path(log)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}_dex_R1.fastq.gz\"),\n              path(\"${sampleId}_dex_R2.fastq.gz\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        cat ${fastq_PE1} > ${sampleId}_dex_R1.fastq.gz\n        cat ${fastq_PE2} > ${sampleId}_dex_R2.fastq.gz\n        \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n        \"\"\"\n        cat ${fastq_PE1} > ${sampleId}_dex_R1.fastq.gz\n        cat ${fastq_PE2} > ${sampleId}_dex_R2.fastq.gz\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "fastq_PE1",
            "fastq_PE2",
            "log"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCRUBLET__DOUBLET_DETECTION_REPORT": {
        "name_process": "SC__SCRUBLET__DOUBLET_DETECTION_REPORT",
        "string_process": "\nprocess SC__SCRUBLET__DOUBLET_DETECTION_REPORT {\n\n\tcontainer params.tools.scrublet.container\n\tpublishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true\n\tlabel 'compute_resources__report'\n\n  \tinput:\n\t\tfile(ipynb)\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n            file(scrubletObjectFile), \\\n\t\t\tfile(adataWithScrubletInfo), \\\n\t\t\tfile(adataWithDimRed)\n\n  \toutput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tfile(\"${sampleId}.SC_Scrublet_doublet_detection_report.ipynb\")\n\n  \tscript:\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.SC_Scrublet_doublet_detection_report.ipynb \\\n\t\t\t-p SCRUBLET_OBJECT_FILE $scrubletObjectFile \\\n            -p H5AD_WITH_SCRUBLET_INFO $adataWithScrubletInfo \\\n            -p H5AD_WITH_DIM_RED $adataWithDimRed \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 31,
        "string_script": "\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t    --report-mode \\\n\t\t\t${sampleId}.SC_Scrublet_doublet_detection_report.ipynb \\\n\t\t\t-p SCRUBLET_OBJECT_FILE $scrubletObjectFile \\\n            -p H5AD_WITH_SCRUBLET_INFO $adataWithScrubletInfo \\\n            -p H5AD_WITH_DIM_RED $adataWithDimRed \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ipynb",
            "sampleId",
            "scrubletObjectFile",
            "adataWithScrubletInfo",
            "adataWithDimRed"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scrublet.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCRUBLET__DOUBLET_DETECTION": {
        "name_process": "SC__SCRUBLET__DOUBLET_DETECTION",
        "string_process": "\nprocess SC__SCRUBLET__DOUBLET_DETECTION {\n\n\tcontainer params.tools.scrublet.container\n\tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n\tinput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(adataRaw), \\\n            path(adataWithHvgInfo), \\\n\t\t\tval(stashedParams), \\\n\t\t\tval(nPrinComps)\n\n\toutput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__SCRUBLET__DOUBLET_DETECTION.ScrubletDoubletTable.tsv\"), \\\n\t\t\tpath(\"${sampleId}.SC__SCRUBLET__DOUBLET_DETECTION.ScrubletObject.pklz\"), \\\n\t\t\tval(stashedParams), \\\n\t\t\tval(nPrinComps)\n\n\tscript:\n\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scrublet.doublet_detection)\n\t\tprocessParams = sampleParams.local\n\t\tdef _processParams = new SC__SCRUBLET__DOUBLET_DETECTION_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n\t\t\"\"\"\n\t\t${binDir}/sc_doublet_detection.py \\\n\t\t\t${processParams?.useVariableFeatures ? '--use-variable-features ' + processParams.useVariableFeatures : ''} \\\n            ${processParams?.syntheticDoubletUmiSubsampling ? '--synthetic-doublet-umi-subsampling ' + processParams.syntheticDoubletUmiSubsampling : ''} \\\n            ${processParams?.minCounts ? '--min-counts ' + processParams.minCounts : ''} \\\n            ${processParams?.minCells ? '--min-cells ' + processParams.minCells : ''} \\\n            ${processParams?.minGeneVariabilityPctl ? '--min-gene-variability-pctl ' + processParams.minGeneVariabilityPctl : ''} \\\n            ${processParams?.logTransform ? '--log-transform ' + processParams.logTransform : ''} \\\n            ${processParams?.meanCenter ? '--mean-center ' + processParams.meanCenter : ''} \\\n            ${processParams?.normalizeVariance ? '--normalize-variance ' + processParams.normalizeVariance : ''} \\\n            ${_processParams.getNPrinCompsAsArgument(nPrinComps)} \\\n            ${processParams?.technology ? '--technology ' + processParams.technology : ''} \\\n\t\t\t${processParams?.useVariableFeatures ? '--h5ad-with-variable-features-info ' + adataWithHvgInfo : ''} \\\n\t\t\t${processParams?.threshold ? '--threshold ' + processParams.threshold : ''} \\\n\t\t\t--output-prefix \"${sampleId}.SC__SCRUBLET__DOUBLET_DETECTION\" \\\n\t\t\t$adataRaw\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 47,
        "string_script": "\t\tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scrublet.doublet_detection)\n\t\tprocessParams = sampleParams.local\n\t\tdef _processParams = new SC__SCRUBLET__DOUBLET_DETECTION_PARAMS()\n\t\t_processParams.setEnv(this)\n\t\t_processParams.setParams(params)\n\t\t_processParams.setConfigParams(processParams)\n\t\t\"\"\"\n\t\t${binDir}/sc_doublet_detection.py \\\n\t\t\t${processParams?.useVariableFeatures ? '--use-variable-features ' + processParams.useVariableFeatures : ''} \\\n            ${processParams?.syntheticDoubletUmiSubsampling ? '--synthetic-doublet-umi-subsampling ' + processParams.syntheticDoubletUmiSubsampling : ''} \\\n            ${processParams?.minCounts ? '--min-counts ' + processParams.minCounts : ''} \\\n            ${processParams?.minCells ? '--min-cells ' + processParams.minCells : ''} \\\n            ${processParams?.minGeneVariabilityPctl ? '--min-gene-variability-pctl ' + processParams.minGeneVariabilityPctl : ''} \\\n            ${processParams?.logTransform ? '--log-transform ' + processParams.logTransform : ''} \\\n            ${processParams?.meanCenter ? '--mean-center ' + processParams.meanCenter : ''} \\\n            ${processParams?.normalizeVariance ? '--normalize-variance ' + processParams.normalizeVariance : ''} \\\n            ${_processParams.getNPrinCompsAsArgument(nPrinComps)} \\\n            ${processParams?.technology ? '--technology ' + processParams.technology : ''} \\\n\t\t\t${processParams?.useVariableFeatures ? '--h5ad-with-variable-features-info ' + adataWithHvgInfo : ''} \\\n\t\t\t${processParams?.threshold ? '--threshold ' + processParams.threshold : ''} \\\n\t\t\t--output-prefix \"${sampleId}.SC__SCRUBLET__DOUBLET_DETECTION\" \\\n\t\t\t$adataRaw\n\t\t\"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "adataRaw",
            "adataWithHvgInfo",
            "stashedParams",
            "nPrinComps"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId",
            "stashedParams",
            "nPrinComps"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scrublet.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__DROP_SEQ_TOOLS__BAM_TAG_HISTOGRAM": {
        "name_process": "SC__DROP_SEQ_TOOLS__BAM_TAG_HISTOGRAM",
        "string_process": "\nprocess SC__DROP_SEQ_TOOLS__BAM_TAG_HISTOGRAM {\n    \n    container params.tools.dropseqtools.container\n    publishDir \"${params.global.outdir}/03.count\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sample), path(bam)\n    \n    output:\n\t    tuple val(sample), path(\"*.cell_readcounts.txt.gz\")\n    \n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.bam_tag_histogram)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        BAMTagHistogram \\\n            I=${bam} \\\n            O=${sample}.cell_readcounts.txt.gz \\\n            TAG=${processParams.tag}\n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, params.tools.dropseqtools.bam_tag_histogram)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        BAMTagHistogram \\\n            I=${bam} \\\n            O=${sample}.cell_readcounts.txt.gz \\\n            TAG=${processParams.tag}\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "bam"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/03.count\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__STAR__SOLO_MAP_COUNT": {
        "name_process": "SC__STAR__SOLO_MAP_COUNT",
        "string_process": "\nprocess SC__STAR__SOLO_MAP_COUNT {\n\n  container params.tools.star.container\n  label 'compute_resources__star_map_count'\n\n  input:\n    file(transcriptome)\n    val genome_loaded\n    file(fastqs)\n\n  output:\n    val success\n                                   \n\n  script:\n    sample = fastqs.getName()\n    _sampleName = sample\n    success = true\n\n    \"\"\"\n    STAR \\\n      --genomeLoad LoadAndKeep \\\n      --soloType Droplet \\\n      --genomeDir ${transcriptome} \\\n      --runThreadN ${task.cpus} \\\n      ${(params.tools.star.map_count.containsKey('limitBAMsortRAM')) ? '--limitBAMsortRAM ' + params.tools.star.map_count.limitBAMsortRAM: ''} \\\n      ${(params.tools.star.map_count.containsKey('outSAMtype')) ? '--outSAMtype ' + params.tools.star.map_count.outSAMtype: ''} \\\n      ${(params.tools.star.map_count.containsKey('quantMode')) ? '--quantMode ' + params.tools.star.map_count.quantMode: ''} \\\n      ${(params.tools.star.map_count.containsKey('outReadsUnmapped')) ? '--outReadsUnmapped ' + params.tools.star.map_count.outReadsUnmapped: ''} \\\n      --readFilesIn ${fastqs} \\\n      ${(fastqs.name.endsWith(\".gz\")) ? '--readFilesCommand zcat' : ''} \\\n      --outFileNamePrefix ${_sampleName}\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    sample = fastqs.getName()\n    _sampleName = sample\n    success = true\n\n    \"\"\"\n    STAR \\\n      --genomeLoad LoadAndKeep \\\n      --soloType Droplet \\\n      --genomeDir ${transcriptome} \\\n      --runThreadN ${task.cpus} \\\n      ${(params.tools.star.map_count.containsKey('limitBAMsortRAM')) ? '--limitBAMsortRAM ' + params.tools.star.map_count.limitBAMsortRAM: ''} \\\n      ${(params.tools.star.map_count.containsKey('outSAMtype')) ? '--outSAMtype ' + params.tools.star.map_count.outSAMtype: ''} \\\n      ${(params.tools.star.map_count.containsKey('quantMode')) ? '--quantMode ' + params.tools.star.map_count.quantMode: ''} \\\n      ${(params.tools.star.map_count.containsKey('outReadsUnmapped')) ? '--outReadsUnmapped ' + params.tools.star.map_count.outReadsUnmapped: ''} \\\n      --readFilesIn ${fastqs} \\\n      ${(fastqs.name.endsWith(\".gz\")) ? '--readFilesCommand zcat' : ''} \\\n      --outFileNamePrefix ${_sampleName}\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "SAMPLE",
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/sample",
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "SAMPLE",
                "uri": "https://bio.tools/sample",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Linkage mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Functional mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic cartography"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map generation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The tool is designed to identify regions that are linked to a recessive disease by analysing genotype data from the parents and unaffected sibs of affected individuals. Since this analysis does not use data from affected patients, it is suited to the identification of lethal recessive genes, when the patients may have died before DNA samples could be obtained.",
                "homepage": "http://dna.leeds.ac.uk/sample/"
            },
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "transcriptome",
            "genome_loaded",
            "fastqs"
        ],
        "nb_inputs": 3,
        "outputs": [
            "success"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.star.container",
            "label 'compute_resources__star_map_count'"
        ],
        "when": "",
        "stub": ""
    },
    "PYCISTOPIC__CALL_CELLS": {
        "name_process": "PYCISTOPIC__CALL_CELLS",
        "string_process": "\nprocess PYCISTOPIC__CALL_CELLS {\n\n    publishDir \"${params.global.outdir}/intermediate/pycistopic/qc/\", mode: 'symlink'\n    container toolParams.container\n    label 'compute_resources__default','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(metadata),\n              path(metadata_pkl),\n              path(profile_data_pkl)\n\n    output:\n        tuple val(sampleId),\n              path(selected_barcodes),\n              path(output_pdf)\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.call_cells)\n        processParams = sampleParams.local\n        selected_barcodes = \"${sampleId}__selected_barcodes.txt\"\n        output_metadata_pkl = \"${sampleId}__metadata_with_calls.pickle\"\n        output_pdf = \"${sampleId}__fragments_qc.pdf\"\n        \"\"\"\n        ${binDir}call_cells.py \\\n            --sampleId ${sampleId} \\\n            --metadata_pkl ${metadata_pkl} \\\n            ${processParams?.filter_frags_lower    ? '--filter_frags_lower '    + processParams?.filter_frags_lower    : ''} \\\n            ${processParams?.filter_frags_upper    ? '--filter_frags_upper '    + processParams?.filter_frags_upper    : ''} \\\n            ${processParams?.filter_tss_lower      ? '--filter_tss_lower '      + processParams?.filter_tss_lower      : ''} \\\n            ${processParams?.filter_tss_upper      ? '--filter_tss_upper '      + processParams?.filter_tss_upper      : ''} \\\n            ${processParams?.filter_frip_lower     ? '--filter_frip_lower '     + processParams?.filter_frip_lower     : ''} \\\n            ${processParams?.filter_frip_upper     ? '--filter_frip_upper '     + processParams?.filter_frip_upper     : ''} \\\n            ${processParams?.filter_dup_rate_lower ? '--filter_dup_rate_lower ' + processParams?.filter_dup_rate_lower : ''} \\\n            ${processParams?.filter_dup_rate_upper ? '--filter_dup_rate_upper ' + processParams?.filter_dup_rate_upper : ''}\n        \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.call_cells)\n        processParams = sampleParams.local\n        selected_barcodes = \"${sampleId}__selected_barcodes.txt\"\n        output_metadata_pkl = \"${sampleId}__metadata_with_calls.pickle\"\n        output_pdf = \"${sampleId}__fragments_qc.pdf\"\n        \"\"\"\n        ${binDir}call_cells.py \\\n            --sampleId ${sampleId} \\\n            --metadata_pkl ${metadata_pkl} \\\n            ${processParams?.filter_frags_lower    ? '--filter_frags_lower '    + processParams?.filter_frags_lower    : ''} \\\n            ${processParams?.filter_frags_upper    ? '--filter_frags_upper '    + processParams?.filter_frags_upper    : ''} \\\n            ${processParams?.filter_tss_lower      ? '--filter_tss_lower '      + processParams?.filter_tss_lower      : ''} \\\n            ${processParams?.filter_tss_upper      ? '--filter_tss_upper '      + processParams?.filter_tss_upper      : ''} \\\n            ${processParams?.filter_frip_lower     ? '--filter_frip_lower '     + processParams?.filter_frip_lower     : ''} \\\n            ${processParams?.filter_frip_upper     ? '--filter_frip_upper '     + processParams?.filter_frip_upper     : ''} \\\n            ${processParams?.filter_dup_rate_lower ? '--filter_dup_rate_lower ' + processParams?.filter_dup_rate_lower : ''} \\\n            ${processParams?.filter_dup_rate_upper ? '--filter_dup_rate_upper ' + processParams?.filter_dup_rate_upper : ''}\n        \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "metadata",
            "metadata_pkl",
            "profile_data_pkl"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/intermediate/pycistopic/qc/\", mode: 'symlink'",
            "container toolParams.container",
            "label 'compute_resources__default','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "PYCISTOPIC__QC_REPORT": {
        "name_process": "PYCISTOPIC__QC_REPORT",
        "string_process": "\nprocess PYCISTOPIC__QC_REPORT {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/notebooks/\", mode: params.utils.publish.mode, pattern: '*ipynb'\n    publishDir \"${params.global.outdir}/data/pycistopic/qc/\", mode: params.utils.publish.mode, pattern: 'selected_barcodes'\n    publishDir \"${params.global.outdir}/data/pycistopic/qc/\", mode: params.utils.publish.mode, pattern: 'selected_barcodes_nFrag'\n    label 'compute_resources__report'\n\n    input:\n        path(ipynb)\n        val(sampleId)\n        tuple path(metadata_pickle),\n              path(profile_data_pickle)\n        val(reportTitle)\n\n    output:\n        tuple path(\"${reportTitle}.ipynb\"),\n              path(\"selected_barcodes/\"),\n              path(\"selected_barcodes_nFrag/\")\n\n    script:\n        pycistopic_params = toJson(toolParams)\n        \"\"\"\n        papermill ${ipynb} \\\n            --report-mode \\\n            ${reportTitle}.ipynb \\\n            -p SAMPLES \"${sampleId.join(\",\")}\" \\\n            -p METADATAPKL \"${metadata_pickle}\" \\\n            -p PROFDATAPKL \"${profile_data_pickle}\" \\\n            -p WORKFLOW_PARAMETERS '${pycistopic_params}' \\\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "        pycistopic_params = toJson(toolParams)\n        \"\"\"\n        papermill ${ipynb} \\\n            --report-mode \\\n            ${reportTitle}.ipynb \\\n            -p SAMPLES \"${sampleId.join(\",\")}\" \\\n            -p METADATAPKL \"${metadata_pickle}\" \\\n            -p PROFDATAPKL \"${profile_data_pickle}\" \\\n            -p WORKFLOW_PARAMETERS '${pycistopic_params}' \\\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ipynb",
            "sampleId",
            "metadata_pickle",
            "profile_data_pickle",
            "reportTitle"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/notebooks/\", mode: params.utils.publish.mode, pattern: '*ipynb'",
            "publishDir \"${params.global.outdir}/data/pycistopic/qc/\", mode: params.utils.publish.mode, pattern: 'selected_barcodes'",
            "publishDir \"${params.global.outdir}/data/pycistopic/qc/\", mode: params.utils.publish.mode, pattern: 'selected_barcodes_nFrag'",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__MARKER_GENES": {
        "name_process": "SC__SCANPY__MARKER_GENES",
        "string_process": "\nprocess SC__SCANPY__MARKER_GENES {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n  \n  \tinput:\n\t\t           \n\t\t                                                                              \n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(normalizedTransformedData), \\\n\t\t\tpath(clusteredData)\n  \n  \toutput:\n    \ttuple val(sampleId), path(\"${sampleId}.SC__SCANPY__MARKER_GENES.${processParams.off}\")\n  \n  \tscript:\n    \tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.marker_genes)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_marker_genes.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('groupby')) ? '--groupby ' + processParams.groupby : ''} \\\n\t\t\t${(processParams.containsKey('ngenes')) ? '--ngenes ' + processParams.ngenes : ''} \\\n\t\t\t$normalizedTransformedData \\\n\t\t\t$clusteredData \\\n\t\t\t\"${sampleId}.SC__SCANPY__MARKER_GENES.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 30,
        "string_script": "    \tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.marker_genes)\n\t\tprocessParams = sampleParams.local\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_marker_genes.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${(processParams.containsKey('groupby')) ? '--groupby ' + processParams.groupby : ''} \\\n\t\t\t${(processParams.containsKey('ngenes')) ? '--ngenes ' + processParams.ngenes : ''} \\\n\t\t\t$normalizedTransformedData \\\n\t\t\t$clusteredData \\\n\t\t\t\"${sampleId}.SC__SCANPY__MARKER_GENES.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "normalizedTransformedData",
            "clusteredData"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SCANPY__PARAM_EXPLORE_MARKER_GENES": {
        "name_process": "SC__SCANPY__PARAM_EXPLORE_MARKER_GENES",
        "string_process": "\nprocess SC__SCANPY__PARAM_EXPLORE_MARKER_GENES {\n\n  \tcontainer params.tools.scanpy.container\n  \tpublishDir \"${params.global.outdir}/data/intermediate/markers/${isParamNull(clusteringMethod) ? \"default\": clusteringMethod.toLowerCase()}/${isParamNull(clusteringResolution) ? \"res_\": clusteringResolution}\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n  \n  \tinput:\n\t\t           \n\t\t                                                                              \n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(normalizedTransformedData), \\\n\t\t\tpath(clusteredData), \\\n\t\t\tval(clusteringMethod), \\\n\t\t\tval(clusteringResolution)\n  \n  \toutput:\n    \ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(\"${sampleId}.SC__SCANPY__PARAM_EXPLORE_MARKER_GENES.${uuid}.${processParams.off}\"), \\\n\t\t\tval(clusteringMethod), \\\n\t\t\tval(clusteringResolution)\n  \n  \tscript:\n    \tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.marker_genes)\n\t\tprocessParams = sampleParams.local\n\t\t                                                                                                      \n\t\t                                                       \n\t\tstashedParams = [clusteringMethod, clusteringResolution]\n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_marker_genes.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${!isParamNull(clusteringMethod) ? '--groupby ' + clusteringMethod : ''} \\\n\t\t\t${(processParams.containsKey('ngenes')) ? '--ngenes ' + processParams.ngenes : ''} \\\n\t\t\t$normalizedTransformedData \\\n\t\t\t$clusteredData \\\n\t\t\t\"${sampleId}.SC__SCANPY__PARAM_EXPLORE_MARKER_GENES.${uuid}.${processParams.off}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 41,
        "string_script": "    \tdef sampleParams = params.parseConfig(sampleId, params.global, params.tools.scanpy.marker_genes)\n\t\tprocessParams = sampleParams.local\n\t\t                                                                                                      \n\t\t                                                       \n\t\tstashedParams = [clusteringMethod, clusteringResolution]\n\t\tif(!isParamNull(stashedParams))\n\t\t\tuuid = stashedParams.findAll { it != 'NULL' }.join('_')\n\t\t\"\"\"\n\t\t${binDir}/cluster/sc_marker_genes.py \\\n\t\t\t${(processParams.containsKey('method')) ? '--method ' + processParams.method : ''} \\\n\t\t\t${!isParamNull(clusteringMethod) ? '--groupby ' + clusteringMethod : ''} \\\n\t\t\t${(processParams.containsKey('ngenes')) ? '--ngenes ' + processParams.ngenes : ''} \\\n\t\t\t$normalizedTransformedData \\\n\t\t\t$clusteredData \\\n\t\t\t\"${sampleId}.SC__SCANPY__PARAM_EXPLORE_MARKER_GENES.${uuid}.${processParams.off}\"\n\t\t\"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "normalizedTransformedData",
            "clusteredData",
            "clusteringMethod",
            "clusteringResolution"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId",
            "clusteringMethod",
            "clusteringResolution"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate/markers/${isParamNull(clusteringMethod) ? \"default\": clusteringMethod.toLowerCase()}/${isParamNull(clusteringResolution) ? \"res_\": clusteringResolution}\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "AUCELL_FROM_FOLDER": {
        "name_process": "AUCELL_FROM_FOLDER",
        "string_process": "\nprocess AUCELL_FROM_FOLDER {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_aucell/\", mode: 'link', overwrite: true\n    label 'compute_resources__scenic_multiruns'\n\n    input:\n        tuple val(sampleId), path(filteredLoom), path(multiRunsAggrRegulonsFolder)\n        val type\n\n    output:\n        tuple val(sampleId), path(\"multi_runs_regulons_auc_${type}.tsv\")\n\n    script:\n        \"\"\"\n        ${binDir}aucell_from_folder.py \\\n            $filteredLoom \\\n            $multiRunsAggrRegulonsFolder \\\n            -o \"multi_runs_regulons_auc_${type}.tsv\" \\\n            --min-genes ${processParams.min_genes_regulon} \\\n            --auc-threshold ${processParams.auc_threshold} \\\n            ${processParams.containsKey('percentile_threshold') ? \"--percentile-threshold \" + processParams.percentile_threshold : \"\"} \\\n            --min-regulon-gene-occurrence ${processParams.min_regulon_gene_occurrence} \\\n            --num-workers ${task.cpus} \\\n            --cell-id-attribute ${toolParams.cell_id_attribute} \\\n            --gene-attribute ${toolParams.gene_attribute}\n        \"\"\"\n\n}",
        "nb_lignes_process": 29,
        "string_script": "        \"\"\"\n        ${binDir}aucell_from_folder.py \\\n            $filteredLoom \\\n            $multiRunsAggrRegulonsFolder \\\n            -o \"multi_runs_regulons_auc_${type}.tsv\" \\\n            --min-genes ${processParams.min_genes_regulon} \\\n            --auc-threshold ${processParams.auc_threshold} \\\n            ${processParams.containsKey('percentile_threshold') ? \"--percentile-threshold \" + processParams.percentile_threshold : \"\"} \\\n            --min-regulon-gene-occurrence ${processParams.min_regulon_gene_occurrence} \\\n            --num-workers ${task.cpus} \\\n            --cell-id-attribute ${toolParams.cell_id_attribute} \\\n            --gene-attribute ${toolParams.gene_attribute}\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "filteredLoom",
            "multiRunsAggrRegulonsFolder",
            "type"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_aucell/\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic_multiruns'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELLRANGER__MKFASTQ": {
        "name_process": "SC__CELLRANGER__MKFASTQ",
        "string_process": "\nprocess SC__CELLRANGER__MKFASTQ {\n\n\tpublishDir \"${params.global.outdir}/fastqs\", saveAs: { outputF = file(it); \"${outputF.getParent().getName()}/${outputF.name}\" }, mode: 'link', overwrite: true\n  \tcontainer toolParams.container\n    label 'compute_resources__cellranger_mkfastq'\n\n  \tinput:\n\t\tfile(csv)\n    \tfile(runFolder)\n\n  \toutput:\n    \tpath \"*/outs/fastq_path/*/*/*.fastq.gz\"\n\n  \tscript:\n\t\t\"\"\"\n\t\tcellranger mkfastq \\\n\t\t\t--run=${runFolder} \\\n\t\t\t--csv=${csv} \\\n\t\t\t${(toolParams.mkfastq.containsKey('runID')) ? '--id ' + toolParams.mkfastq.runID: params.global.containsKey('project_name') ? '--id ' + params.global.project_name: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('samplesheet')) ? '--samplesheet ' + toolParams.mkfastq.samplesheet: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('ignoreDualIndex')) ? '--ignore-dual-index ' + toolParams.mkfastq.ignoreDualIndex: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('qc')) ? '--qc ' + toolParams.mkfastq.qc: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('lanes')) ? '--lanes ' + toolParams.mkfastq.lanes: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('useBasesMask')) ? '--use-bases-mask ' + toolParams.mkfastq.useBasesMask: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('deleteUndetermined')) ? '--delete-undetermined ' + toolParams.mkfastq.deleteUndetermined: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('outputDir')) ? '--output-dir ' + toolParams.mkfastq.outputDir: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('project')) ? '--project ' + toolParams.mkfastq.project: ''} \\\n            --jobmode=local \\\n            --localcores=${task.cpus} \\\n            --localmem=${task.memory.toGiga()}\n\t\t\"\"\"\n\n\n}",
        "nb_lignes_process": 33,
        "string_script": "\t\t\"\"\"\n\t\tcellranger mkfastq \\\n\t\t\t--run=${runFolder} \\\n\t\t\t--csv=${csv} \\\n\t\t\t${(toolParams.mkfastq.containsKey('runID')) ? '--id ' + toolParams.mkfastq.runID: params.global.containsKey('project_name') ? '--id ' + params.global.project_name: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('samplesheet')) ? '--samplesheet ' + toolParams.mkfastq.samplesheet: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('ignoreDualIndex')) ? '--ignore-dual-index ' + toolParams.mkfastq.ignoreDualIndex: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('qc')) ? '--qc ' + toolParams.mkfastq.qc: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('lanes')) ? '--lanes ' + toolParams.mkfastq.lanes: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('useBasesMask')) ? '--use-bases-mask ' + toolParams.mkfastq.useBasesMask: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('deleteUndetermined')) ? '--delete-undetermined ' + toolParams.mkfastq.deleteUndetermined: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('outputDir')) ? '--output-dir ' + toolParams.mkfastq.outputDir: ''} \\\n\t\t\t${(toolParams.mkfastq.containsKey('project')) ? '--project ' + toolParams.mkfastq.project: ''} \\\n            --jobmode=local \\\n            --localcores=${task.cpus} \\\n            --localmem=${task.memory.toGiga()}\n\t\t\"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "csv",
            "runFolder"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/fastqs\", saveAs: { outputF = file(it); \"${outputF.getParent().getName()}/${outputF.name}\" }, mode: 'link', overwrite: true",
            "container toolParams.container",
            "label 'compute_resources__cellranger_mkfastq'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__SOUPX": {
        "name_process": "SC__SOUPX",
        "string_process": "\nprocess SC__SOUPX {\n    \n    container toolParams.container\n    publishDir \"${params.global.outdir}/data/${moduleName}\", mode: 'link'\n    label 'compute_resources__default'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(f)\n\n    output:\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__SOUPX.Rds\"), \\\n            emit: main\n        tuple \\\n            val(sampleId), \\\n            path(\"${sampleId}.SC__SOUPX.*.pdf\"), \\\n            emit: other\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n\n        def roundToIntAsArgument = ''\n        if(processParams?.roundToInt) {\n            roundToIntAsArgument = '--round-to-int '+ processParams.roundToInt\n        }\n\n        \"\"\"\n        export NXF_BIN_DIR=$binDir\n        ${binDir}/run_soupx.R \\\n            --sample-id ${sampleId} \\\n            --seed ${params.global.seed} \\\n            ${roundToIntAsArgument} \\\n            --output-prefix \"${sampleId}.SC__SOUPX\" \\\n            $f\n        \"\"\"\n\n}",
        "nb_lignes_process": 40,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams)\n        processParams = sampleParams.local\n\n        def roundToIntAsArgument = ''\n        if(processParams?.roundToInt) {\n            roundToIntAsArgument = '--round-to-int '+ processParams.roundToInt\n        }\n\n        \"\"\"\n        export NXF_BIN_DIR=$binDir\n        ${binDir}/run_soupx.R \\\n            --sample-id ${sampleId} \\\n            --seed ${params.global.seed} \\\n            ${roundToIntAsArgument} \\\n            --output-prefix \"${sampleId}.SC__SOUPX\" \\\n            $f\n        \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId",
            "sampleId"
        ],
        "nb_outputs": 2,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/data/${moduleName}\", mode: 'link'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__CELDA__DECONTX_MERGE_OUTLIER_TABLES": {
        "name_process": "SC__CELDA__DECONTX_MERGE_OUTLIER_TABLES",
        "string_process": "\nprocess SC__CELDA__DECONTX_MERGE_OUTLIER_TABLES {\n\n    publishDir \"${params.global.outdir}/data/${moduleName}\", mode: 'link'\n    label 'compute_resources__default'\n\n    input:\n        file(\"*\")\n\n    output:\n        path(\"all.CELDA__DECONTX.Contamination_Outlier_Table.tsv.gz\")\n\n    script:\n        \"\"\"\n        cat * > tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv\n        cat \\\n            <(head -n1 tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv) \\\n            <(cat tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv | sed \"/^index/d\") \\\n            | gzip -c > all.CELDA__DECONTX.Contamination_Outlier_Table.tsv.gz\n        rm tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv\n        \"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        cat * > tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv\n        cat \\\n            <(head -n1 tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv) \\\n            <(cat tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv | sed \"/^index/d\") \\\n            | gzip -c > all.CELDA__DECONTX.Contamination_Outlier_Table.tsv.gz\n        rm tmp.CELDA__DECONTX.Contamination_Outlier_Table.tsv\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/data/${moduleName}\", mode: 'link'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__ARCHR__CELL_CALLING": {
        "name_process": "SC__ARCHR__CELL_CALLING",
        "string_process": "\nprocess SC__ARCHR__CELL_CALLING {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/archr/\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        tuple val(sampleId),\n              path(arrow)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}-TSSEnrichment_vs_nFrags.pdf\"),\n              path(\"${sampleId}-qc_stats.txt\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.cell_calling)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}cell_calling.R \\\n        --arrow_file ${arrow} \\\n        --output_dir . \\\n        --filter_frags ${processParams.filter_frags} \\\n        --filter_tss ${processParams.filter_tss} \\\n        --seed ${params.global.seed} \\\n        --threads ${task.cpus} \\\n        --genome ${toolParams.genome}\n        \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.cell_calling)\n\t\tprocessParams = sampleParams.local\n        \"\"\"\n        ${binDir}cell_calling.R \\\n        --arrow_file ${arrow} \\\n        --output_dir . \\\n        --filter_frags ${processParams.filter_frags} \\\n        --filter_tss ${processParams.filter_tss} \\\n        --seed ${params.global.seed} \\\n        --threads ${task.cpus} \\\n        --genome ${toolParams.genome}\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "arrow"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/archr/\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SINTO__FRAGMENTS": {
        "name_process": "SINTO__FRAGMENTS",
        "string_process": "\nprocess SINTO__FRAGMENTS {\n\n    container toolParams.container\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sampleId),\n              path(bam),\n              path(bai)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.fragments.bed\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.fragments)\n        processParams = sampleParams.local\n        \"\"\"\n        sinto fragments \\\n            -b ${bam} \\\n            -m ${processParams.min_mapq} \\\n            ${processParams.containsKey('barcodetag') && processParams.barcodetag ? '--barcodetag ' + processParams.barcodetag: ''} \\\n            ${processParams.containsKey('barcode_regex') && processParams.barcode_regex ? '--barcode_regex ' + processParams.barcode_regex: ''} \\\n            ${processParams.containsKey('use_chrom') && processParams.use_chrom ? '--use_chrom ' + processParams.use_chrom: ''} \\\n            ${processParams.containsKey('min_distance') && processParams.min_distance ? '--min_distance ' + processParams.min_distance: ''} \\\n            ${processParams.containsKey('max_distance') && processParams.max_distance ? '--max_distance ' + processParams.max_distance: ''} \\\n            ${processParams.containsKey('chunksize') && processParams.chunksize ? '--chunksize ' + processParams.chunksize: ''} \\\n            -p ${task.cpus} \\\n            -f ${sampleId}.fragments.bed\n        \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.fragments)\n        processParams = sampleParams.local\n        \"\"\"\n        sinto fragments \\\n            -b ${bam} \\\n            -m ${processParams.min_mapq} \\\n            ${processParams.containsKey('barcodetag') && processParams.barcodetag ? '--barcodetag ' + processParams.barcodetag: ''} \\\n            ${processParams.containsKey('barcode_regex') && processParams.barcode_regex ? '--barcode_regex ' + processParams.barcode_regex: ''} \\\n            ${processParams.containsKey('use_chrom') && processParams.use_chrom ? '--use_chrom ' + processParams.use_chrom: ''} \\\n            ${processParams.containsKey('min_distance') && processParams.min_distance ? '--min_distance ' + processParams.min_distance: ''} \\\n            ${processParams.containsKey('max_distance') && processParams.max_distance ? '--max_distance ' + processParams.max_distance: ''} \\\n            ${processParams.containsKey('chunksize') && processParams.chunksize ? '--chunksize ' + processParams.chunksize: ''} \\\n            -p ${task.cpus} \\\n            -f ${sampleId}.fragments.bed\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "SINTO__SORT_FRAGMENTS": {
        "name_process": "SINTO__SORT_FRAGMENTS",
        "string_process": "\nprocess SINTO__SORT_FRAGMENTS {\n\n    container toolParams.container\n    label 'compute_resources__mem'\n\n    input:\n        tuple val(sampleId),\n              path(fragments_bed)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.sinto.fragments.tsv.gz\")\n\n    script:\n        \"\"\"\n        LC_ALL=C sort -k 1,1 -k 2,2n -k 3,3n \\\n            ${fragments_bed} \\\n            | bgzip -c \\\n            > ${sampleId}.sinto.fragments.tsv.gz\n        \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "        \"\"\"\n        LC_ALL=C sort -k 1,1 -k 2,2n -k 3,3n \\\n            ${fragments_bed} \\\n            | bgzip -c \\\n            > ${sampleId}.sinto.fragments.tsv.gz\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "fragments_bed"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "FORMAT_GTF": {
        "name_process": "FORMAT_GTF",
        "string_process": "\nprocess FORMAT_GTF {\n\n    publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        file(annotation)\n\n    output:\n        file \"*.formatted.gtf\"\n\n    script:\n        \"\"\"\n        sed -r 's/(.*); transcript_id (.*); (.*); gene_name (.*); \\$/\\\\1; transcript_id \\\\2; \\\\3; gene_name \\\\4; transcript_name \\\\2;/' \\\n            ${annotation} \\\n            > ${annotation.baseName}.formatted.gtf\n        \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "        \"\"\"\n        sed -r 's/(.*); transcript_id (.*); (.*); gene_name (.*); \\$/\\\\1; transcript_id \\\\2; \\\\3; gene_name \\\\4; transcript_name \\\\2;/' \\\n            ${annotation} \\\n            > ${annotation.baseName}.formatted.gtf\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotation"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "FORMAT_GTF_IGENOMES": {
        "name_process": "FORMAT_GTF_IGENOMES",
        "string_process": "\nprocess FORMAT_GTF_IGENOMES {\n\n    publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'\n    label 'compute_resources__default'\n\n    input:\n        file(annotation)\n\n    output:\n        file \"*.formatted.gtf\"\n\n    script:\n        \"\"\"\n        sed -r 's/(.*); gene_name (.*); transcript_id (.*); (.*);\\$/\\\\1; gene_name \\\\2; transcript_id \\\\3; \\\\4; transcript_name \\\\3;/' \\\n            ${annotation} \\\n            > ${annotation.baseName}.formatted.gtf\n        \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "        \"\"\"\n        sed -r 's/(.*); gene_name (.*); transcript_id (.*); (.*);\\$/\\\\1; gene_name \\\\2; transcript_id \\\\3; \\\\4; transcript_name \\\\3;/' \\\n            ${annotation} \\\n            > ${annotation.baseName}.formatted.gtf\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotation"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${params.global.outdir}/00.refdata\", mode: 'symlink'",
            "label 'compute_resources__default'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__ARCHR__CREATE_ARROW_UNFILTERED": {
        "name_process": "SC__ARCHR__CREATE_ARROW_UNFILTERED",
        "string_process": "\nprocess SC__ARCHR__CREATE_ARROW_UNFILTERED {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/archr/\", mode: 'symlink'\n    label 'compute_resources__cpu'\n\n    input:\n        tuple val(sampleId),\n              path(fragments),\n              path(fragments_index),\n              val(filetype)\n\n    output:\n        tuple val(sampleId),\n              path(\"${sampleId}.arrow\")\n\n    script:\n        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.createArrow)\n        processParams = sampleParams.local\n        \"\"\"\n        ${binDir}createArrow_unfiltered.R \\\n        --fragments_file ${fragments} \\\n        --sample_name ${sampleId} \\\n        --filter_frags ${processParams.filter_frags} \\\n        --filter_tss ${processParams.filter_tss} \\\n        --min_frags ${processParams.min_frags} \\\n        --seed ${params.global.seed} \\\n        --threads ${task.cpus} \\\n        --genome ${toolParams.genome}\n        \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "        def sampleParams = params.parseConfig(sampleId, params.global, toolParams.createArrow)\n        processParams = sampleParams.local\n        \"\"\"\n        ${binDir}createArrow_unfiltered.R \\\n        --fragments_file ${fragments} \\\n        --sample_name ${sampleId} \\\n        --filter_frags ${processParams.filter_frags} \\\n        --filter_tss ${processParams.filter_tss} \\\n        --min_frags ${processParams.min_frags} \\\n        --seed ${params.global.seed} \\\n        --threads ${task.cpus} \\\n        --genome ${toolParams.genome}\n        \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "filetype",
            "fragments",
            "fragments_index"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/archr/\", mode: 'symlink'",
            "label 'compute_resources__cpu'"
        ],
        "when": "",
        "stub": ""
    },
    "ADD_PEARSON_CORRELATION": {
        "name_process": "ADD_PEARSON_CORRELATION",
        "string_process": "\nprocess ADD_PEARSON_CORRELATION {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}/arboreto_with_multiprocessing/${\"numRuns\" in toolParams && toolParams.numRuns > 1 ? \"run_\" + runId : \"\"}\", mode: 'link', overwrite: true, pattern: '*__adj.tsv'\n    label 'compute_resources__scenic_aucell'\n\n    input:\n        tuple \\\n            val(sampleId), \\\n            path(filteredLoom), \\\n            path(adj), \\\n            val(runId)\n\n    output:\n        tuple val(sampleId), \\\n            file(filteredLoom), \\\n            file(\"${outputFileName}\"), \\\n            val(runId)\n\n    script:\n        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? sampleId + \"__run_\" + runId +\"__adj.tsv\" : sampleId + \"__adj.tsv\"\n        seed = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? (params.global.seed + runId) : params.global.seed\n        \"\"\"\n        pyscenic add_cor \\\n            ${adj} \\\n            $filteredLoom \\\n            --output ${outputFileName} \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n        \"\"\"\n\n}",
        "nb_lignes_process": 34,
        "string_script": "        if(toolParams.numRuns > 2 && task.maxForks > 1 && task.executor == \"local\")\n            println(\"Running multi-runs SCENIC is quite computationally extensive. Consider submitting this as a job, or limit the number of parallel processes with 'maxForks'.\")\n        outputFileName = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? sampleId + \"__run_\" + runId +\"__adj.tsv\" : sampleId + \"__adj.tsv\"\n        seed = \"numRuns\" in toolParams && toolParams.numRuns > 1 ? (params.global.seed + runId) : params.global.seed\n        \"\"\"\n        pyscenic add_cor \\\n            ${adj} \\\n            $filteredLoom \\\n            --output ${outputFileName} \\\n            --cell_id_attribute ${toolParams.cell_id_attribute} \\\n            --gene_attribute ${toolParams.gene_attribute} \\\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "Seed"
        ],
        "tools_url": [
            "https://bio.tools/seed-eco"
        ],
        "tools_dico": [
            {
                "name": "Seed",
                "uri": "https://bio.tools/seed-eco",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0610",
                            "term": "Ecology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3365",
                            "term": "Data architecture, analysis and design"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An R/Shiny package for visualizing ecological data. It provides a visual interface for generating a wide variety of plots, including histograms, scatterplots, bar plots, stacked bar plots, PCoA plots, cluster dendrograms, and heatmaps.",
                "homepage": "https://github.com/danlbek/Seed"
            }
        ],
        "inputs": [
            "sampleId",
            "filteredLoom",
            "adj",
            "runId"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sampleId",
            "filteredLoom",
            "runId"
        ],
        "nb_outputs": 3,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}/arboreto_with_multiprocessing/${\"numRuns\" in toolParams && toolParams.numRuns > 1 ? \"run_\" + runId : \"\"}\", mode: 'link', overwrite: true, pattern: '*__adj.tsv'",
            "label 'compute_resources__scenic_aucell'"
        ],
        "when": "",
        "stub": ""
    },
    "SC__H5AD_MERGE": {
        "name_process": "SC__H5AD_MERGE",
        "string_process": "\nprocess SC__H5AD_MERGE {\n\n\tcontainer params.tools.scanpy.container\n    publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true\n    label 'compute_resources__mem'\n\n\tinput:\n\t\t           \n\t\t                                                                             \n\t\ttuple \\\n            val(sampleId), \\\n\t\t\tpath(data)\n\n\toutput:\n\t\ttuple \\\n            val(sampleId), \\\n\t\t    path(\"${sampleId}.SC__H5AD_MERGE.h5ad\")\n\n\tscript:\n\t\t\"\"\"\n        ${binDir}/sc_h5ad_merge.py \\\n            * \\\n            \"${sampleId}.SC__H5AD_MERGE.h5ad\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "\t\t\"\"\"\n        ${binDir}/sc_h5ad_merge.py \\\n            * \\\n            \"${sampleId}.SC__H5AD_MERGE.h5ad\"\n\t\t\"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "data"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.scanpy.container",
            "publishDir \"${params.global.outdir}/data/intermediate\", mode: 'symlink', overwrite: true",
            "label 'compute_resources__mem'"
        ],
        "when": "",
        "stub": ""
    },
    "GZIP": {
        "name_process": "GZIP",
        "string_process": "\nprocess GZIP {\n\n    container params.tools.dropseqtools.container\n    publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'\n    label 'compute_resources__cpu','compute_resources__24hqueue'\n\n    input:\n        tuple val(sample), path(f)\n\n    output:\n        tuple val(sample), path(\"*.unaligned_tagged_polyA_filtered.fastq.gz\"), emit: fastq_gz\n\n    script:\n        \"\"\"\n        gzip --force ${f}\n        \"\"\"\n\n}",
        "nb_lignes_process": 17,
        "string_script": "        \"\"\"\n        gzip --force ${f}\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.tools.dropseqtools.container",
            "publishDir \"${params.global.outdir}/01.clean\", mode: 'symlink'",
            "label 'compute_resources__cpu','compute_resources__24hqueue'"
        ],
        "when": "",
        "stub": ""
    },
    "UTILS__GENERATE_WORKFLOW_CONFIG_REPORT": {
        "name_process": "UTILS__GENERATE_WORKFLOW_CONFIG_REPORT",
        "string_process": "\nprocess UTILS__GENERATE_WORKFLOW_CONFIG_REPORT {\n\n  \tcontainer params.utils.container\n  \tpublishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true\n    label 'compute_resources__report'\n\n    input:\n        path(ipynb)\n\n\toutput:\n\t\tpath(\"workflow_configuration_report.ipynb\")\n\n\tscript:\n\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t\tworkflow_configuration_report.ipynb \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "\t\t\"\"\"\n\t\tpapermill ${ipynb} \\\n\t\t\tworkflow_configuration_report.ipynb \\\n\t\t\t-p WORKFLOW_MANIFEST '${params.misc.manifestAsJSON}' \\\n\t\t\t-p WORKFLOW_PARAMETERS '${params.misc.paramsAsJSON}'\n\t\t\"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ipynb"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.utils.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "UTILS__REPORT_TO_HTML": {
        "name_process": "UTILS__REPORT_TO_HTML",
        "string_process": "\nprocess UTILS__REPORT_TO_HTML {\n\n\tcontainer params.utils.container\n\tpublishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true\n\t                                               \n\tpublishDir \"${params.global.outdir}/notebooks\", pattern: '*merged_report*', mode: 'link', overwrite: true\n\tlabel 'compute_resources__report'\n\n\tinput:\n\t\ttuple \\\n\t\t\tval(sampleId), \\\n\t\t\tpath(ipynb)\n\n\toutput:\n\t\tfile(\"*.html\")\n\n\tscript:\n\t\t\"\"\"\n\t\tjupyter nbconvert ${ipynb} --to html\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 21,
        "string_script": "\t\t\"\"\"\n\t\tjupyter nbconvert ${ipynb} --to html\n\t\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Jupyterhub"
        ],
        "tools_url": [
            "https://bio.tools/Jupyterhub"
        ],
        "tools_dico": [
            {
                "name": "Jupyterhub",
                "uri": "https://bio.tools/Jupyterhub",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software engineering"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Computer programming"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3372",
                            "term": "Software development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Jupyter notebooks in science gateways.\n\nJupyter Notebooks empower scientists to create executable documents that include text, equations, code and figures. Notebooks are a simple way to create reproducible and shareable workflows. The Jupyter developers have also released a multi-user notebook environment: Jupyterhub. Jupyterhub provides an extensible platform for handling user authentication and spawning the Notebook application to each user. I developed a plugin for Jupyterhub to spawn notebooks on a Supercomputer and integrated the authentication with CILogon and XSEDE. Scientists can authenticate on their browser and connect to a Jupyter Notebook instance running on the computing node of a Supercomputer, in my test deployment SDSC Comet. Jupyterhub can benefit Science Gateways by providing an expressive interface to a centralized environment with many software tools pre-installed and allow scientists to access Gateway functionality via web API.\n\n||| HOMEPAGE MISSING!",
                "homepage": "https://doi.org/10.7287/PEERJ.PREPRINTS.2577V2"
            }
        ],
        "inputs": [
            "sampleId",
            "ipynb"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container params.utils.container",
            "publishDir \"${params.global.outdir}/notebooks/intermediate\", mode: 'link', overwrite: true",
            "publishDir \"${params.global.outdir}/notebooks\", pattern: '*merged_report*', mode: 'link', overwrite: true",
            "label 'compute_resources__report'"
        ],
        "when": "",
        "stub": ""
    },
    "PUBLISH_LOOM": {
        "name_process": "PUBLISH_LOOM",
        "string_process": "\nprocess PUBLISH_LOOM {\n\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}\", mode: 'link', overwrite: true, saveAs: { filename -> toolParams.scenicScopeOutputLoom }\n    label 'compute_resources__minimal'\n\n    input:\n        tuple val(sampleId), path(f)\n\n    output:\n        tuple val(sampleId), path(f)\n\n    script:\n        \"\"\"\n        \"\"\"\n\n}",
        "nb_lignes_process": 15,
        "string_script": "        \"\"\"\n        \"\"\"",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "f"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}\", mode: 'link', overwrite: true, saveAs: { filename -> toolParams.scenicScopeOutputLoom }",
            "label 'compute_resources__minimal'"
        ],
        "when": "",
        "stub": ""
    },
    "VISUALIZE": {
        "name_process": "VISUALIZE",
        "string_process": "\nprocess VISUALIZE {\n\n    container toolParams.container\n    label 'compute_resources__scenic'\n\n    input:\n        tuple val(sampleId), path(inputLoom)\n\n    output:\n        tuple val(sampleId), path(\"scenic_visualize.loom\")\n\n    script:\n        \"\"\"\n        ${binDir}add_visualization.py \\\n            --loom_input ${inputLoom} \\\n            --loom_output scenic_visualize.loom \\\n            --num_workers ${task.cpus}\n        \"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "        \"\"\"\n        ${binDir}add_visualization.py \\\n            --loom_input ${inputLoom} \\\n            --loom_output scenic_visualize.loom \\\n            --num_workers ${task.cpus}\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "inputLoom"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "label 'compute_resources__scenic'"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_MOTIF_TRACK_LOOMS": {
        "name_process": "MERGE_MOTIF_TRACK_LOOMS",
        "string_process": "\nprocess MERGE_MOTIF_TRACK_LOOMS {\n\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}\", mode: 'link', overwrite: true\n    label 'compute_resources__scenic'\n\n    input:\n        tuple val(sampleId), path(motifLoom), path(trackLoom)\n\n    output:\n        tuple val(sampleId), path(toolParams.scenicOutputLoom)\n\n    script:\n        \"\"\"\n        ${binDir}merge_motif_track_loom.py \\\n            --loom_motif ${motifLoom} \\\n            --loom_track ${trackLoom} \\\n            --loom_output ${toolParams.scenicOutputLoom}\n        \"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "        \"\"\"\n        ${binDir}merge_motif_track_loom.py \\\n            --loom_motif ${motifLoom} \\\n            --loom_track ${trackLoom} \\\n            --loom_output ${toolParams.scenicOutputLoom}\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "motifLoom",
            "trackLoom"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic'"
        ],
        "when": "",
        "stub": ""
    },
    "APPEND_SCENIC_LOOM": {
        "name_process": "APPEND_SCENIC_LOOM",
        "string_process": "\nprocess APPEND_SCENIC_LOOM {\n\n    container toolParams.container\n    publishDir \"${params.global.outdir}/loom\", mode: 'link', overwrite: true\n    label 'compute_resources__scenic'\n\n    input:\n        tuple val(sampleId), path(scopeLoom), path(scenicLoom)\n\n    output:\n        tuple val(sampleId), path(\"${sampleId}.${toolParams.scenicScopeOutputLoom}\")\n\n    script:\n        \"\"\"\n        ${binDir}append_results_to_existing_loom.py \\\n            --loom_scope ${scopeLoom} \\\n            --loom_scenic ${scenicLoom} \\\n            --loom_output ${sampleId}.${toolParams.scenicScopeOutputLoom}\n        \"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "        \"\"\"\n        ${binDir}append_results_to_existing_loom.py \\\n            --loom_scope ${scopeLoom} \\\n            --loom_scenic ${scenicLoom} \\\n            --loom_output ${sampleId}.${toolParams.scenicScopeOutputLoom}\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "scopeLoom",
            "scenicLoom"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "container toolParams.container",
            "publishDir \"${params.global.outdir}/loom\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic'"
        ],
        "when": "",
        "stub": ""
    },
    "SAVE_MULTI_RUNS_TO_LOOM": {
        "name_process": "SAVE_MULTI_RUNS_TO_LOOM",
        "string_process": "\nprocess SAVE_MULTI_RUNS_TO_LOOM {\n\n    cache 'deep'\n    container toolParams.container\n    publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_looms/\", mode: 'link', overwrite: true\n    label 'compute_resources__scenic_multiruns'\n\n    input:\n\t\ttuple val(sampleId), path(filteredLoom), path(multiRunsAggrRegulons), path(multiRunsAggrRegulonsAUC)\n\t\tval type\n\n    output:\n    \ttuple val(sampleId), path(\"multi_runs_regulons_auc_${type}.loom\")\n\n\tscript:\n\t\t\"\"\"\n\t\t${binDir}save_multi_runs_to_loom.py \\\n\t\t\t$filteredLoom \\\n\t\t\t$multiRunsAggrRegulons \\\n\t\t\t$multiRunsAggrRegulonsAUC \\\n\t\t\t-o \"multi_runs_regulons_auc_${type}.loom\" \\\n\t\t\t--min-genes-regulon ${toolParams.aucell.min_genes_regulon} \\\n\t\t\t--min-regulon-gene-occurrence ${toolParams.aucell.min_regulon_gene_occurrence} \\\n\t\t\t--cell-id-attribute ${toolParams.cell_id_attribute} \\\n\t\t\t--gene-attribute ${toolParams.gene_attribute} \\\n\t\t\t--title \"${sampleId} - pySCENIC (${type})\" \\\n\t\t\t--nomenclature \"${params.utils?.scope.genome}\" \\\n\t\t\t--scope-tree-level-1 \"${params.utils?.scope.tree.level_1}\" \\\n\t\t\t--scope-tree-level-2 \"${params.utils?.scope.tree.level_2}\" \\\n\t\t\t--scope-tree-level-3 \"${params.utils?.scope.tree.level_3}\"\n\t\t\"\"\"\n\n}",
        "nb_lignes_process": 32,
        "string_script": "\t\t\"\"\"\n\t\t${binDir}save_multi_runs_to_loom.py \\\n\t\t\t$filteredLoom \\\n\t\t\t$multiRunsAggrRegulons \\\n\t\t\t$multiRunsAggrRegulonsAUC \\\n\t\t\t-o \"multi_runs_regulons_auc_${type}.loom\" \\\n\t\t\t--min-genes-regulon ${toolParams.aucell.min_genes_regulon} \\\n\t\t\t--min-regulon-gene-occurrence ${toolParams.aucell.min_regulon_gene_occurrence} \\\n\t\t\t--cell-id-attribute ${toolParams.cell_id_attribute} \\\n\t\t\t--gene-attribute ${toolParams.gene_attribute} \\\n\t\t\t--title \"${sampleId} - pySCENIC (${type})\" \\\n\t\t\t--nomenclature \"${params.utils?.scope.genome}\" \\\n\t\t\t--scope-tree-level-1 \"${params.utils?.scope.tree.level_1}\" \\\n\t\t\t--scope-tree-level-2 \"${params.utils?.scope.tree.level_2}\" \\\n\t\t\t--scope-tree-level-3 \"${params.utils?.scope.tree.level_3}\"\n\t\t\"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleId",
            "filteredLoom",
            "multiRunsAggrRegulons",
            "multiRunsAggrRegulonsAUC",
            "type"
        ],
        "nb_inputs": 5,
        "outputs": [
            "sampleId"
        ],
        "nb_outputs": 1,
        "name_workflow": "vib-singlecell-nf__vsn-pipelines",
        "directive": [
            "cache 'deep'",
            "container toolParams.container",
            "publishDir \"${toolParams.scenicoutdir}/${sampleId}/multi_runs_looms/\", mode: 'link', overwrite: true",
            "label 'compute_resources__scenic_multiruns'"
        ],
        "when": "",
        "stub": ""
    }
}