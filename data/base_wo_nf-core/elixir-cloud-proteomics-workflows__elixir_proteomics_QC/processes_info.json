{
    "makeblastdb": {
        "name_process": "makeblastdb",
        "string_process": "\nprocess makeblastdb {\n    storeDir blastdb_folder\n    afterScript(\"chmod 777 ${blastdb_folder}\")\n    tag { genome_id }\n\n    input:\n    set genome_id, fasta_file, internal_dbfile, file(fasta_path) from fasta_desc\n\n    output:\n    set genome_id, internal_dbfile, file (\"*\") into blastdbs, blastdbs_d\n    \n    script:\n    \"\"\"\n     if [ `echo ${fasta_file} | grep 'gz'` ]; then zcat ${fasta_file} > ${internal_dbfile}; else ln -s ${fasta_file} ${internal_dbfile}; fi\n     makeblastdb -dbtype prot -in ${internal_dbfile} -out ${internal_dbfile}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n     if [ `echo ${fasta_file} | grep 'gz'` ]; then zcat ${fasta_file} > ${internal_dbfile}; else ln -s ${fasta_file} ${internal_dbfile}; fi\n     makeblastdb -dbtype prot -in ${internal_dbfile} -out ${internal_dbfile}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_desc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "blastdbs",
            "blastdbs_d"
        ],
        "nb_outputs": 2,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "storeDir blastdb_folder",
            "afterScript(\"chmod 777 ${blastdb_folder}\")",
            "tag { genome_id }"
        ],
        "when": "",
        "stub": ""
    },
    "thermofilerawparser": {
        "name_process": "thermofilerawparser",
        "string_process": "\nprocess thermofilerawparser {\n    label 'thermoconvert'  \n    publishDir \"${out_folder}/${qcode}_${checksum}\", mode: 'copy', pattern: \"*.mzML\"\t   \n    tag { \"${qcode}_${checksum}\" }\n\n    input:\n    set qcode, checksum, file(zipfile) from zipfiles\n\n    output:\n    set val(\"${qcode}_${checksum}\"), qcode, checksum, file(\"${qcode}_${checksum}.mzML\") into mzmlfiles_for_correction\n    \n    script:\n    def filename = zipfile.getBaseName()\n    \"\"\"\n    unzip ${zipfile}\n    ThermoRawFileParser -i=${filename} -f=1 -m=0 -o ./\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    def filename = zipfile.getBaseName()\n    \"\"\"\n    unzip ${zipfile}\n    ThermoRawFileParser -i=${filename} -f=1 -m=0 -o ./\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "ThermoRawFileParser"
        ],
        "tools_url": [
            "https://bio.tools/ThermoRawFileParser"
        ],
        "tools_dico": [
            {
                "name": "ThermoRawFileParser",
                "uri": "https://bio.tools/ThermoRawFileParser",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3695",
                                    "term": "Filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3434",
                                    "term": "Conversion"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak assignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak finding"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0943",
                                "term": "Mass spectrum"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0943",
                                "term": "Mass spectrum"
                            }
                        ]
                    }
                ],
                "description": "Open-source, crossplatform tool that converts Thermo RAW files into open file formats such as MGF and to the HUPO-PSI standard file format mzML",
                "homepage": "https://github.com/compomics/ThermoRawFileParser"
            }
        ],
        "inputs": [
            "zipfiles"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mzmlfiles_for_correction"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "label 'thermoconvert'",
            "publishDir \"${out_folder}/${qcode}_${checksum}\", mode: 'copy', pattern: \"*.mzML\"",
            "tag { \"${qcode}_${checksum}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "correctMzml": {
        "name_process": "correctMzml",
        "string_process": "\nprocess correctMzml {\n   tag { sample_id }\n   \n    input:\n    set sample_id, qcode, checksum, file(mzML_file) from (mzmlfiles_for_correction)\n \n    output:\n    set qcode, sample_id, checksum, file(\"${sample_id}.ok.mzML\") into corrected_mzmlfiles_for_second_step\n\n   \"\"\"  \n    if [ `echo ${mzML_file} | grep 'gz'` ]; then zcat ${mzML_file} > ${sample_id}.mzML; \\\n    sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${sample_id}.mzML > ${sample_id}.ok.mzML; \\\n    else sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${mzML_file} > ${sample_id}.ok.mzML; fi\n   \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"  \n    if [ `echo ${mzML_file} | grep 'gz'` ]; then zcat ${mzML_file} > ${sample_id}.mzML; \\\n    sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${sample_id}.mzML > ${sample_id}.ok.mzML; \\\n    else sed s@'xmlns=\\\"http://psi.hupo.org/ms/mzml\\\"'@@g ${mzML_file} > ${sample_id}.ok.mzML; fi\n   \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mzmlfiles_for_correction"
        ],
        "nb_inputs": 1,
        "outputs": [
            "corrected_mzmlfiles_for_second_step"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }"
        ],
        "when": "",
        "stub": ""
    },
    "run_shotgun": {
        "name_process": "run_shotgun",
        "string_process": "\nprocess run_shotgun {\n    publishDir \"${out_folder}/${sample_id}\", mode: 'copy', pattern: \"*.qcml\"\t   \n    publishDir \"${out_folder}/${sample_id}\", mode: 'copy', pattern: \"*.featureXML\"\t   \n\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun\n    file(workflowfile) from shotgunWF\n    \n    when:\n    analysis_type == 'shotgun'\n\n    output:\n    set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.featureXML\") into shot_featureXMLfiles_for_calc_peptide_area, shot_featureXMLfiles_for_calc_mass_accuracy, shot_featureXMLfiles_for_calc_median_fwhm\n    set sample_id, internal_code, analysis_type, checksum, file(mzML_file) into shot_mzML_file_for_MedianITMS1, shot_mzML_file_for_MedianITMS2, shot_mzML_file_for_tic\n    set sample_id, internal_code, analysis_type, checksum, file(mzML_file), file(fasta_file) into shot_mzML_file_for_check \n    set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.qcml\") into qcmlfiles_for_MS2_spectral_count, qcmlfiles_for_tot_num_uniq_peptides, qcmlfiles_for_tot_num_uniq_proteins, qcmlfiles_for_tot_num_psm\n\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 28,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun",
            "shotgunWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_featureXMLfiles_for_calc_peptide_area",
            "shot_featureXMLfiles_for_calc_mass_accuracy",
            "shot_featureXMLfiles_for_calc_median_fwhm",
            "shot_mzML_file_for_MedianITMS1",
            "shot_mzML_file_for_MedianITMS2",
            "shot_mzML_file_for_tic",
            "shot_mzML_file_for_check",
            "qcmlfiles_for_MS2_spectral_count",
            "qcmlfiles_for_tot_num_uniq_peptides",
            "qcmlfiles_for_tot_num_uniq_proteins",
            "qcmlfiles_for_tot_num_psm"
        ],
        "nb_outputs": 11,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "publishDir \"${out_folder}/${sample_id}\", mode: 'copy', pattern: \"*.qcml\"",
            "publishDir \"${out_folder}/${sample_id}\", mode: 'copy', pattern: \"*.featureXML\"",
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun'",
        "stub": ""
    },
    "run_srm": {
        "name_process": "run_srm",
        "string_process": "\nprocess run_srm {\n      tag { sample_id }\n\n       label 'big_mem'\n        input:\n        set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_srm\n        file(workflowfile) from srmWF\n        file(srmCSV)\n        \n        when:\n        analysis_type == 'srm'\n\n        output:\n        set sample_id, internal_code, analysis_type, checksum, file(\"${sample_id}.featureXML\") into srm_featureXMLfiles_for_calc_peptide_area, srm_featureXMLfiles_for_calc_mass_accuracy, srm_featureXMLfiles_for_calc_median_fwhm\n        set sample_id, internal_code, analysis_type, checksum, file(mzML_file) into srm_mzML_file_for_MedianITMS1, srm_mzML_file_for_MedianITMS2, srm_mzML_file_for_check \n    \n        script:\n        def outfile = \"${sample_id}.featureXML\"\n        def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, ofeatxml:\"${sample_id}.featureXML\", srmCSV:srmCSV)\n        knime.launch()\n}",
        "nb_lignes_process": 20,
        "string_script": "        def outfile = \"${sample_id}.featureXML\"\n        def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, ofeatxml:\"${sample_id}.featureXML\", srmCSV:srmCSV)\n        knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_srm",
            "srmWF",
            "srmCSV"
        ],
        "nb_inputs": 3,
        "outputs": [
            "srm_featureXMLfiles_for_calc_peptide_area",
            "srm_featureXMLfiles_for_calc_mass_accuracy",
            "srm_featureXMLfiles_for_calc_median_fwhm",
            "srm_mzML_file_for_MedianITMS1",
            "srm_mzML_file_for_MedianITMS2",
            "srm_mzML_file_for_check"
        ],
        "nb_outputs": 6,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'"
        ],
        "when": "analysis_type == 'srm'",
        "stub": ""
    },
    "shotgun_qc4l_cid": {
        "name_process": "shotgun_qc4l_cid",
        "string_process": "\nprocess shotgun_qc4l_cid {\n    tag { sample_id }\n    label 'big_mem'\n    \n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_cid\n    file(workflowfile) from shotgun_qc4l_cidWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area, shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm\n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum, file(mzML_file) into shot_qc4l_cid_mzML_file_for_MedianITMS1, shot_qc4l_cid_mzML_file_for_MedianITMS2, shot_qc4l_cid_mzML_file_for_check, shot_qc4l_cid_mzML_file_for_tic \n    set val(\"${sample_id}_cid\"), internal_code, val(\"shotgun_qc4l_cid\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_cid_qcmlfiles_for_tot_num_psm\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 23,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_cid",
            "shotgun_qc4l_cidWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_cid_mzML_file_for_MedianITMS1",
            "shot_qc4l_cid_mzML_file_for_MedianITMS2",
            "shot_qc4l_cid_mzML_file_for_check",
            "shot_qc4l_cid_mzML_file_for_tic",
            "shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_psm"
        ],
        "nb_outputs": 11,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "shotgun_qc4l_hcd": {
        "name_process": "shotgun_qc4l_hcd",
        "string_process": "\nprocess shotgun_qc4l_hcd {\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_hcd\n    file(workflowfile) from shotgun_qc4l_hcdWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_hcd\"), internal_code, val(\"shotgun_qc4l_hcd\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_hcd_featureXMLfiles_for_calc_peptide_area, shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm\n    set val(\"${sample_id}_hcd\"), internal_code, val(\"shotgun_qc4l_hcd\"), checksum, file(mzML_file) into shot_qc4l_hcd_mzML_file_for_MedianITMS1, shot_qc4l_hcd_mzML_file_for_MedianITMS2, shot_qc4l_hcd_mzML_file_for_check, shot_qc4l_hcd_mzML_file_for_tic \n    set val(\"${sample_id}_hcd\"), internal_code, val(\"shotgun_qc4l_hcd\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_hcd_qcmlfiles_for_tot_num_psm\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 23,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_hcd",
            "shotgun_qc4l_hcdWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_hcd_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS1",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS2",
            "shot_qc4l_hcd_mzML_file_for_check",
            "shot_qc4l_hcd_mzML_file_for_tic",
            "shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_psm"
        ],
        "nb_outputs": 11,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "shotgun_qc4l_etcid": {
        "name_process": "shotgun_qc4l_etcid",
        "string_process": "\nprocess shotgun_qc4l_etcid {\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_etcid\n    file(workflowfile) from shotgun_qc4l_etcidWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_etcid\"), internal_code, val(\"shotgun_qc4l_etcid\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area, shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm\n    set val(\"${sample_id}_etcid\"), internal_code, val(\"shotgun_qc4l_etcid\"), checksum, file(mzML_file) into shot_qc4l_etcid_mzML_file_for_MedianITMS1, shot_qc4l_etcid_mzML_file_for_MedianITMS2, shot_qc4l_etcid_mzML_file_for_check, shot_qc4l_etcid_mzML_file_for_tic\n    set val(\"${sample_id}_etcid\"), internal_code, val(\"shotgun_qc4l_etcid\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_etcid_qcmlfiles_for_tot_num_psm\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 23,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_etcid",
            "shotgun_qc4l_etcidWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS1",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS2",
            "shot_qc4l_etcid_mzML_file_for_check",
            "shot_qc4l_etcid_mzML_file_for_tic",
            "shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_psm"
        ],
        "nb_outputs": 11,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "shotgun_qc4l_ethcd": {
        "name_process": "shotgun_qc4l_ethcd",
        "string_process": "\nprocess shotgun_qc4l_ethcd  {\n    tag { sample_id }\n    \n    label 'big_mem'\n    afterScript \"$baseDir/bin/fixQcml.sh\"\n\n    input:\n    set genome_id, internal_code, sample_id, file(mzML_file), analysis_type, checksum, fasta_file, file (\"*\") from input_pipe_complete_first_step_for_shotgun_qc4l_ethcd \n    file(workflowfile) from shotgun_qc4l_ethcdWF\n    \n    when:\n    analysis_type == 'shotgun_qc4l'\n\n    output:\n    set val(\"${sample_id}_ethcd\"), internal_code, val(\"shotgun_qc4l_ethcd\"), checksum, file(\"${sample_id}.featureXML\") into shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area, shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm\n    set val(\"${sample_id}_ethcd\"), internal_code, val(\"shotgun_qc4l_ethcd\"), checksum, file(mzML_file) into shot_qc4l_ethcd_mzML_file_for_MedianITMS1, shot_qc4l_ethcd_mzML_file_for_MedianITMS2, shot_qc4l_ethcd_mzML_file_for_check, shot_qc4l_ethcd_mzML_file_for_tic \n    set val(\"${sample_id}_ethcd\"), internal_code, val(\"shotgun_qc4l_ethcd\"), checksum, file(\"${sample_id}.qcml\") into shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm\n\n    script:\n    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()\n            \n}",
        "nb_lignes_process": 23,
        "string_script": "    def outfiles = \"${sample_id}.featureXML ${sample_id}.qcml ${sample_id}.idXML\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfiles, mem:\"${task.memory.mega-5000}m\", mzml:mzML_file, oqcml:\"${sample_id}.qcml\", ofeatxml:\"${sample_id}.featureXML\", oidxml:\"${sample_id}.idXML\", fasta:fasta_file, psq:\"${fasta_file}.psq\")\n    knime.launch()",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_pipe_complete_first_step_for_shotgun_qc4l_ethcd",
            "shotgun_qc4l_ethcdWF"
        ],
        "nb_inputs": 2,
        "outputs": [
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS1",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS2",
            "shot_qc4l_ethcd_mzML_file_for_check",
            "shot_qc4l_ethcd_mzML_file_for_tic",
            "shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm"
        ],
        "nb_outputs": 11,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "label 'big_mem'",
            "afterScript \"$baseDir/bin/fixQcml.sh\""
        ],
        "when": "analysis_type == 'shotgun_qc4l'",
        "stub": ""
    },
    "calc_MS2_spectral_count": {
        "name_process": "calc_MS2_spectral_count",
        "string_process": "\nprocess calc_MS2_spectral_count {\n    tag { \"${sample_id}-${analysis_type}\" }\n    \n    input:\n    set sample_id, internal_code, val(analysis_type), checksum, file(qcmlfile) from qcmlfiles_for_MS2_spectral_count.mix(shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count, shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count, shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count)\n    file(workflowfile) from getWFFile(baseQCPath, \"MS2specCount\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['MS2specCount'][analysis_type]}.json\") into ms2_spectral_for_delivery\n\n    script:\n    def analysis_id = Correspondence['MS2specCount'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['MS2specCount'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n}",
        "nb_lignes_process": 16,
        "string_script": "    def analysis_id = Correspondence['MS2specCount'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['MS2specCount'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_cid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_hcd_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_etcid_qcmlfiles_for_MS2_spectral_count",
            "shot_qc4l_ethcd_qcmlfiles_for_MS2_spectral_count",
            "baseQCPath",
            "\"MS2specCount\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "ms2_spectral_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_tot_num_uniq_peptides": {
        "name_process": "calc_tot_num_uniq_peptides",
        "string_process": "\nprocess calc_tot_num_uniq_peptides {\n    tag { \"${sample_id}-${analysis_type}\" }\n   \n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(qcmlfile) from qcmlfiles_for_tot_num_uniq_peptides.mix(shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides)\n    file(workflowfile) from getWFFile(baseQCPath, \"totNumOfUniPep\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['totNumOfUniPep'][analysis_type]}.json\") into uni_peptides_for_delivery\n\n    script:\n    def analysis_id = Correspondence['totNumOfUniPep'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniPep'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n}",
        "nb_lignes_process": 16,
        "string_script": "    def analysis_id = Correspondence['totNumOfUniPep'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniPep'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_peptides",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_peptides",
            "baseQCPath",
            "\"totNumOfUniPep\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "uni_peptides_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_tot_num_uniq_proteins": {
        "name_process": "calc_tot_num_uniq_proteins",
        "string_process": "\nprocess calc_tot_num_uniq_proteins {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(qcmlfile) from qcmlfiles_for_tot_num_uniq_proteins.mix(shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins, shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins)\n    file(workflowfile) from getWFFile(baseQCPath, \"totNumOfUniProt\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['totNumOfUniProt'][analysis_type]}.json\") into uni_prots_for_delivery\n\n    script:\n    def analysis_id = Correspondence['totNumOfUniProt'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniProt'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['totNumOfUniProt'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfUniProt'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_uniq_proteins",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_uniq_proteins",
            "baseQCPath",
            "\"totNumOfUniProt\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "uni_prots_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_tot_num_psm": {
        "name_process": "calc_tot_num_psm",
        "string_process": "\nprocess calc_tot_num_psm {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(qcmlfile) from qcmlfiles_for_tot_num_psm.mix(shot_qc4l_cid_qcmlfiles_for_tot_num_psm, shot_qc4l_hcd_qcmlfiles_for_tot_num_psm, shot_qc4l_etcid_qcmlfiles_for_tot_num_psm, shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm)\n    file(workflowfile) from getWFFile(baseQCPath, \"totNumOfPsm\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['totNumOfPsm'][analysis_type]}.json\") into tot_psm_for_delivery\n\n    script:\n    def analysis_id = Correspondence['totNumOfPsm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfPsm'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['totNumOfPsm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['totNumOfPsm'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", qcml:qcmlfile, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qcmlfiles_for_tot_num_psm",
            "shot_qc4l_cid_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_hcd_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_etcid_qcmlfiles_for_tot_num_psm",
            "shot_qc4l_ethcd_qcmlfiles_for_tot_num_psm",
            "baseQCPath",
            "\"totNumOfPsm\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "tot_psm_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_median_IT_MS1": {
        "name_process": "calc_median_IT_MS1",
        "string_process": "\nprocess calc_median_IT_MS1 {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(mzml_file) from shot_mzML_file_for_MedianITMS1.mix(srm_mzML_file_for_MedianITMS1, shot_qc4l_cid_mzML_file_for_MedianITMS1, shot_qc4l_hcd_mzML_file_for_MedianITMS1, shot_qc4l_etcid_mzML_file_for_MedianITMS1, shot_qc4l_ethcd_mzML_file_for_MedianITMS1)\n    file(workflowfile) from getWFFile(baseQCPath, \"medianITMS1\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['medianITMS1'][analysis_type]}.json\") into median_itms1_for_delivery\n\n    script:\n    def analysis_id = Correspondence['medianITMS1'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS1'][analysis_type]}.json\" \n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['medianITMS1'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS1'][analysis_type]}.json\" \n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_mzML_file_for_MedianITMS1",
            "srm_mzML_file_for_MedianITMS1",
            "shot_qc4l_cid_mzML_file_for_MedianITMS1",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS1",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS1",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS1",
            "baseQCPath",
            "\"medianITMS1\""
        ],
        "nb_inputs": 8,
        "outputs": [
            "median_itms1_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_median_IT_MS2": {
        "name_process": "calc_median_IT_MS2",
        "string_process": "\nprocess calc_median_IT_MS2 {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(mzml_file) from shot_mzML_file_for_MedianITMS2.mix(srm_mzML_file_for_MedianITMS2, shot_qc4l_cid_mzML_file_for_MedianITMS2, shot_qc4l_hcd_mzML_file_for_MedianITMS2, shot_qc4l_etcid_mzML_file_for_MedianITMS2, shot_qc4l_ethcd_mzML_file_for_MedianITMS2)\n    file(workflowfile) from getWFFile(baseQCPath, \"medianITMS2\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['medianITMS2'][analysis_type]}.json\") into median_itms2_for_delivery\n\n    script:\n    def analysis_id = Correspondence['medianITMS2'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS2'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile,  empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 17,
        "string_script": "    def analysis_id = Correspondence['medianITMS2'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianITMS2'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile,  empty_out_file:outfile, mem:\"${task.memory.mega-5000}m\", mzml:mzml_file, qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_mzML_file_for_MedianITMS2",
            "srm_mzML_file_for_MedianITMS2",
            "shot_qc4l_cid_mzML_file_for_MedianITMS2",
            "shot_qc4l_hcd_mzML_file_for_MedianITMS2",
            "shot_qc4l_etcid_mzML_file_for_MedianITMS2",
            "shot_qc4l_ethcd_mzML_file_for_MedianITMS2",
            "baseQCPath",
            "\"medianITMS2\""
        ],
        "nb_inputs": 8,
        "outputs": [
            "median_itms2_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_peptide_area": {
        "name_process": "calc_peptide_area",
        "string_process": "\nprocess calc_peptide_area {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, val(internal_code), analysis_type, checksum, file(featxml_file) from shot_featureXMLfiles_for_calc_peptide_area.mix(srm_featureXMLfiles_for_calc_peptide_area)\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from getWFFile(baseQCPath, \"pepArea\")\n\n    output:\n    set sample_id, internal_code, checksum, val(\"${Correspondence['pepArea'][analysis_type]}\"), file(\"${sample_id}_QC_${Correspondence['pepArea'][analysis_type]}.json\") into pep_area_for_check\n\n    script:\n    def analysis_id = Correspondence['pepArea'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n\tdef outfile = \"${sample_id}_QC_${Correspondence['pepArea'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 20,
        "string_script": "    def analysis_id = Correspondence['pepArea'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n\tdef outfile = \"${sample_id}_QC_${Correspondence['pepArea'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_featureXMLfiles_for_calc_peptide_area",
            "srm_featureXMLfiles_for_calc_peptide_area",
            "peptideCSV",
            "peptideCSV_C4L",
            "baseQCPath",
            "\"pepArea\""
        ],
        "nb_inputs": 6,
        "outputs": [
            "pep_area_for_check"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_peptide_area_c4l": {
        "name_process": "calc_peptide_area_c4l",
        "string_process": "\nprocess calc_peptide_area_c4l {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_qc4l_hcd_featureXMLfiles_for_calc_peptide_area\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from getWFFile(baseQCPath, \"pepArea_qc4l\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['pepArea_qc4l'][analysis_type]}.json\") into pep_c4l_for_delivery\n\n    script:\n    def analysis_id = Correspondence['pepArea_qc4l'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['pepArea_qc4l'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\", extrapars:'-workflow.variable=delta_mass,10,double -workflow.variable=delta_rt,250,double -workflow.variable=charge,2,double -workflow.variable=threshold_area,1000000,double')\n    knime.launch()\n    \n}",
        "nb_lignes_process": 20,
        "string_script": "    def analysis_id = Correspondence['pepArea_qc4l'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['pepArea_qc4l'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\", extrapars:'-workflow.variable=delta_mass,10,double -workflow.variable=delta_rt,250,double -workflow.variable=charge,2,double -workflow.variable=threshold_area,1000000,double')\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_qc4l_hcd_featureXMLfiles_for_calc_peptide_area",
            "peptideCSV",
            "peptideCSV_C4L",
            "baseQCPath",
            "\"pepArea_qc4l\""
        ],
        "nb_inputs": 5,
        "outputs": [
            "pep_c4l_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_peptide_area_c4l_fake": {
        "name_process": "calc_peptide_area_c4l_fake",
        "string_process": "\nprocess calc_peptide_area_c4l_fake {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area.mix(shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area, shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area)\n\n    output:\n    set sample_id, val(null) into pep_c4l_for_delivery_fake\n\n    script:\n\t\"\"\"\n\techo \"this is a workaround because of a nextflow problem\"\n\t\"\"\"\n    \n}",
        "nb_lignes_process": 14,
        "string_script": "\t\"\"\"\n\techo \"this is a workaround because of a nextflow problem\"\n\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_qc4l_cid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_peptide_area",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_peptide_area"
        ],
        "nb_inputs": 3,
        "outputs": [
            "pep_c4l_for_delivery_fake"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_tic": {
        "name_process": "calc_tic",
        "string_process": "\nprocess calc_tic {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, val(analysis_type), checksum, file(mzmlfile) from shot_mzML_file_for_tic.mix(shot_qc4l_cid_mzML_file_for_tic, shot_qc4l_hcd_mzML_file_for_tic, shot_qc4l_etcid_mzML_file_for_tic, shot_qc4l_ethcd_mzML_file_for_tic)\n    file(workflowfile) from getWFFile(baseQCPath, \"tic\")\n\n    output:\n    set sample_id, file(\"${sample_id}_QC_${Correspondence['tic'][analysis_type]}.json\") into tic_for_delivery\n\n    script:\n    def analysis_id = Correspondence['tic'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['tic'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mzml:mzmlfile, stype:internal_code, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()   \n}",
        "nb_lignes_process": 16,
        "string_script": "    def analysis_id = Correspondence['tic'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def outfile = \"${sample_id}_QC_${Correspondence['tic'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, mzml:mzmlfile, stype:internal_code, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_mzML_file_for_tic",
            "shot_qc4l_cid_mzML_file_for_tic",
            "shot_qc4l_hcd_mzML_file_for_tic",
            "shot_qc4l_etcid_mzML_file_for_tic",
            "shot_qc4l_ethcd_mzML_file_for_tic",
            "baseQCPath",
            "\"tic\""
        ],
        "nb_inputs": 7,
        "outputs": [
            "tic_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_mass_accuracy": {
        "name_process": "calc_mass_accuracy",
        "string_process": " process calc_mass_accuracy {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_featureXMLfiles_for_calc_mass_accuracy.mix(srm_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy, shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy)\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from getWFFile(baseQCPath, \"massAccuracy\") \n\n    output:\n    set sample_id, internal_code, checksum, val(\"${Correspondence['massAccuracy'][analysis_type]}\"),  file(\"${sample_id}_QC_${Correspondence['massAccuracy'][analysis_type]}.json\") into mass_json_for_check\n\n    script:\n    def analysis_id = Correspondence['massAccuracy'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['massAccuracy'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n\n}",
        "nb_lignes_process": 19,
        "string_script": "    def analysis_id = Correspondence['massAccuracy'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['massAccuracy'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_featureXMLfiles_for_calc_mass_accuracy",
            "srm_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_cid_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_hcd_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_mass_accuracy",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_mass_accuracy",
            "peptideCSV",
            "peptideCSV_C4L",
            "baseQCPath",
            "\"massAccuracy\""
        ],
        "nb_inputs": 10,
        "outputs": [
            "mass_json_for_check"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "calc_median_fwhm": {
        "name_process": "calc_median_fwhm",
        "string_process": " process calc_median_fwhm {\n    tag { \"${sample_id}-${analysis_type}\" }\n\n    input:\n    set sample_id, internal_code, analysis_type, checksum, file(featxml_file) from shot_featureXMLfiles_for_calc_median_fwhm.mix(srm_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm, shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm)\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from getWFFile(baseQCPath, \"medianFwhm\") \n\n    output:\n    set sample_id, internal_code, checksum, val(\"${Correspondence['medianFwhm'][analysis_type]}\"),  file(\"${sample_id}_QC_${Correspondence['medianFwhm'][analysis_type]}.json\") into median_fwhm_for_check\n\n    script:\n    def analysis_id = Correspondence['medianFwhm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianFwhm'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()\n    \n}",
        "nb_lignes_process": 19,
        "string_script": "    def analysis_id = Correspondence['medianFwhm'][analysis_type]\n    def ontology_id = ontology[analysis_id]\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"${sample_id}_QC_${Correspondence['medianFwhm'][analysis_type]}.json\"\n    def knime = new Knime(wf:workflowfile, empty_out_file:outfile, csvpep:csvfile, stype:internal_code, featxml:featxml_file, mem:\"${task.memory.mega-5000}m\", qccv:\"QC_${analysis_id}\", qccvp:\"QC_${ontology_id}\", chksum:checksum, ojid:\"${sample_id}\")\n    knime.launch()",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "shot_featureXMLfiles_for_calc_median_fwhm",
            "srm_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_cid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_hcd_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_etcid_featureXMLfiles_for_calc_median_fwhm",
            "shot_qc4l_ethcd_featureXMLfiles_for_calc_median_fwhm",
            "peptideCSV",
            "peptideCSV_C4L",
            "baseQCPath",
            "\"medianFwhm\""
        ],
        "nb_inputs": 10,
        "outputs": [
            "median_fwhm_for_check"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${analysis_type}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "check_peptides": {
        "name_process": "check_peptides",
        "string_process": " process check_peptides {\n    tag { \"${sample_id}-${process_id}-json_file\" }\n    beforeScript(\"mkdir out\")\n\n    input:\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n\tset sample_id, internal_code, checksum, process_id, file(json_file) from pep_area_for_check\n    file(workflowfile) from chekPeptidesWF\n\n    output:\n    set sample_id, file(\"out/${json_file}\") into pep_checked_for_delivery\n\n    script:\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum, csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()\n}",
        "nb_lignes_process": 17,
        "string_script": "    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum, csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "peptideCSV",
            "peptideCSV_C4L",
            "pep_area_for_check",
            "chekPeptidesWF"
        ],
        "nb_inputs": 4,
        "outputs": [
            "pep_checked_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { \"${sample_id}-${process_id}-json_file\" }",
            "beforeScript(\"mkdir out\")"
        ],
        "when": "",
        "stub": ""
    },
    "check_mass": {
        "name_process": "check_mass",
        "string_process": " process check_mass {\n    tag { sample_id }\n    beforeScript(\"mkdir out\")\n\n    input:\n    set sample_id, internal_code, checksum, process_id, file(json_file) from mass_json_for_check\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n\tfile(workflowfile) from chekPeptidesWF\n\n    output:\n    set sample_id, file(\"out/${json_file}\") into mass_checked_for_delivery\n\n    script:\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()\n}",
        "nb_lignes_process": 17,
        "string_script": "    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mass_json_for_check",
            "peptideCSV",
            "peptideCSV_C4L",
            "chekPeptidesWF"
        ],
        "nb_inputs": 4,
        "outputs": [
            "mass_checked_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "beforeScript(\"mkdir out\")"
        ],
        "when": "",
        "stub": ""
    },
    "check_fwhm": {
        "name_process": "check_fwhm",
        "string_process": " process check_fwhm {\n    tag { sample_id }\n    beforeScript(\"mkdir out\")\n\t\n    input:\n    set sample_id, internal_code, checksum, process_id, file(json_file) from median_fwhm_for_check\n\tfile (\"peptide.csv\") from file (peptideCSV)\n\tfile (\"peptide_C4L.csv\") from file (peptideCSV_C4L)\n    file(workflowfile) from chekPeptidesWF\n\n    output:\n    set sample_id, file(\"out/${json_file}\") into median_checked_for_delivery\n\n    script:\n    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()\n}",
        "nb_lignes_process": 17,
        "string_script": "    def csvfile = peptideCSVs[internal_code]\n    def outfile = \"out/${json_file}\"\n    def knime = new Knime(qccv:\"QC_${process_id}\", empty_out_file:outfile, wf:workflowfile, chksum:checksum,  csvpep:csvfile, stype:internal_code, ijfile:json_file, mem:\"${task.memory.mega-5000}m\", ofolder:\"./out\", ojfile:\"${json_file}\")\n    knime.launch()",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "median_fwhm_for_check",
            "peptideCSV",
            "peptideCSV_C4L",
            "chekPeptidesWF"
        ],
        "nb_inputs": 4,
        "outputs": [
            "median_checked_for_delivery"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "beforeScript(\"mkdir out\")"
        ],
        "when": "",
        "stub": ""
    },
    "MSGFPlus": {
        "name_process": "MSGFPlus",
        "string_process": "\nprocess MSGFPlus {\n    tag { sample_id }\n    publishDir \"${out_folder}/${sample_id}\", mode: 'copy', pattern: \"*.mzid\"\t   \n\n    input:\n    file(MSGFPlus)\n    set sample_id, internal_id, analysis_type, checksum, file(mzML_file), file(fasta) from shot_mzML_file_for_check.mix(srm_mzML_file_for_check, shot_qc4l_cid_mzML_file_for_check, shot_qc4l_hcd_mzML_file_for_check, shot_qc4l_etcid_mzML_file_for_check, shot_qc4l_ethcd_mzML_file_for_check)\n\n    output:\n    set sample_id, internal_id, analysis_type, checksum, file(\"${sample_id}.mzid\") into mZML_params_for_mapping\n\n    script:\n    \"\"\"\n        java -jar ${MSGFPlus} -s ${mzML_file} -o ${sample_id}.mzid -d ${fasta}\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n        java -jar ${MSGFPlus} -s ${mzML_file} -o ${sample_id}.mzid -d ${fasta}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "MSGFPlus",
            "shot_mzML_file_for_check",
            "srm_mzML_file_for_check",
            "shot_qc4l_cid_mzML_file_for_check",
            "shot_qc4l_hcd_mzML_file_for_check",
            "shot_qc4l_etcid_mzML_file_for_check",
            "shot_qc4l_ethcd_mzML_file_for_check"
        ],
        "nb_inputs": 7,
        "outputs": [
            "mZML_params_for_mapping"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "publishDir \"${out_folder}/${sample_id}\", mode: 'copy', pattern: \"*.mzid\""
        ],
        "when": "",
        "stub": ""
    },
    "collectResults": {
        "name_process": "collectResults",
        "string_process": " process collectResults {\n    tag { sample_id }\n    \n    input:\n    set sample_id, internal_code, checksum, file(mzidfile), file(\"*\") from mZML_params_for_delivery.join(jsonToBeSent)\n\n    output:\n    set sample_id, file(\"${sample_id}.json\") into json_to_be_converted\n    \n    script:\n    \"\"\"\n\tjson_merger.sh \\$PWD ${sample_id}.json\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n\tjson_merger.sh \\$PWD ${sample_id}.json\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "mZML_params_for_delivery",
            "jsonToBeSent"
        ],
        "nb_inputs": 2,
        "outputs": [
            "json_to_be_converted"
        ],
        "nb_outputs": 1,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }"
        ],
        "when": "",
        "stub": ""
    },
    "convertResults": {
        "name_process": "convertResults",
        "string_process": " process convertResults {\n    tag { sample_id }\n    label 'mzqcconvert'\n    \n    publishDir \"${out_folder}/${sample_id}\", mode: 'copy'\n\n    input:\n    set sample_id, file(json) from json_to_be_converted\n\n    output:\n    file(\"${sample_id}.mzQC\")\n    \n    script:\n    \"\"\"\n\tqcloud_mzqc_conversion_v0.1.py -input ${json} -output ${sample_id}.mzQC \n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n\tqcloud_mzqc_conversion_v0.1.py -input ${json} -output ${sample_id}.mzQC \n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "json_to_be_converted"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "elixir-cloud-proteomics-workflows__elixir_proteomics_QC",
        "directive": [
            "tag { sample_id }",
            "label 'mzqcconvert'",
            "publishDir \"${out_folder}/${sample_id}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}