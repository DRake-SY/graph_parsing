{
    "cacheJBangScripts": {
        "name_process": "cacheJBangScripts",
        "string_process": "\nprocess cacheJBangScripts {\n\n  input:\n    file ExcelToCsvJava\n\n  output:\n    file \"ExcelToCsv.jar\" into ExcelToCsv\n\n  \"\"\"\n  jbang export portable -O=ExcelToCsv.jar ${ExcelToCsvJava}\n  \"\"\"\n\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n  jbang export portable -O=ExcelToCsv.jar ${ExcelToCsvJava}\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ExcelToCsvJava"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ExcelToCsv"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "downloadPGSCatalogMeta": {
        "name_process": "downloadPGSCatalogMeta",
        "string_process": " process downloadPGSCatalogMeta {\n\n    output:\n      file \"*.xlsx\" into pgs_catalog_excel_file\n\n    \"\"\"\n    wget ${params.pgs_catalog_url}\n    \"\"\"\n\n  }",
        "nb_lignes_process": 8,
        "string_script": "\"\"\"\n    wget ${params.pgs_catalog_url}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "pgs_catalog_excel_file"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "convertPgsCatalogMeta": {
        "name_process": "convertPgsCatalogMeta",
        "string_process": "\nprocess convertPgsCatalogMeta {\n\n  input:\n    file ExcelToCsv\n    file excel_file from pgs_catalog_excel_file\n\n  output:\n    file \"*.csv\" into pgs_catalog_csv_file\n\n  \"\"\"\n  java -jar ${ExcelToCsv} \\\n    --input ${excel_file} \\\n    --sheet Scores \\\n    --output pgs_all_metadata.csv\n  \"\"\"\n\n}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n  java -jar ${ExcelToCsv} \\\n    --input ${excel_file} \\\n    --sheet Scores \\\n    --output pgs_all_metadata.csv\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ExcelToCsv",
            "pgs_catalog_excel_file"
        ],
        "nb_inputs": 2,
        "outputs": [
            "pgs_catalog_csv_file"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "downloadScore": {
        "name_process": "downloadScore",
        "string_process": " process downloadScore {\n\n    publishDir params.output, mode: 'copy'\n\n    input:\n      tuple val(score_id), val(score_ftp_link) from score_rows\n\n    output:\n      tuple val(score_id), file(\"${score_id}.original.txt.gz\") into scores_ch\n\n    \"\"\"\n\n    ##TODO check build and write to log if not same.\n\n    wget ${score_ftp_link} -O ${score_id}.original.txt.gz\n\n    \"\"\"\n  }",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n\n    ##TODO check build and write to log if not same.\n\n    wget ${score_ftp_link} -O ${score_id}.original.txt.gz\n\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "score_rows"
        ],
        "nb_inputs": 1,
        "outputs": [
            "scores_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [
            "publishDir params.output, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "copyScore": {
        "name_process": "copyScore",
        "string_process": " process copyScore {\n\n    publishDir params.output, mode: 'copy'\n\n    input:\n      tuple val(score_id), file(score_file) from score_rows\n\n    output:\n      tuple val(score_id), file(\"${score_id}.original.txt.gz\") into scores_ch\n\n    \"\"\"\n\n    ##TODO check build and write to log if not same.\n\n    cp ${score_file} ${score_id}.original.txt.gz\n\n    \"\"\"\n  }",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n\n    ##TODO check build and write to log if not same.\n\n    cp ${score_file} ${score_id}.original.txt.gz\n\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "score_rows"
        ],
        "nb_inputs": 1,
        "outputs": [
            "scores_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [
            "publishDir params.output, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "resolveScore": {
        "name_process": "resolveScore",
        "string_process": "\nprocess resolveScore {\n\n  publishDir params.output, mode: 'copy'\n\n  input:\n    tuple val(score_id), file(score_file) from scores_ch\n    tuple val(dbsnp_index), file(dbsnp_index_file) from dbsnp_index_ch.collect()\n\n  output:\n    file \"${score_id}.txt.gz\" optional true into prepared_scores_ch\n    file \"${score_id}.log\"\n\n  \"\"\"\n  set +e\n\n  pgs-calc resolve \\\n    --in ${score_file} \\\n    --out ${score_id}.txt.gz \\\n    --dbsnp ${dbsnp_index}.txt.gz > ${score_id}.log\n\n  # ignore pgs-calc status to get log files of failed scores.\n  exit 0\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "\"\"\"\n  set +e\n\n  pgs-calc resolve \\\n    --in ${score_file} \\\n    --out ${score_id}.txt.gz \\\n    --dbsnp ${dbsnp_index}.txt.gz > ${score_id}.log\n\n  # ignore pgs-calc status to get log files of failed scores.\n  exit 0\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scores_ch",
            "dbsnp_index_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prepared_scores_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [
            "publishDir params.output, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "calcChunks": {
        "name_process": "calcChunks",
        "string_process": "\nprocess calcChunks {\n\n  input:\n    tuple val(vcf_filename), path(vcf_file) from vcf_files\n    path scores from prepared_scores_ch.collect()\n\n  output:\n    file \"*.txt\" optional true into score_chunks_ch\n    file \"*.info\" optional true into report_chunks_ch\n    file \"*.log\"\n\n  \"\"\"\n  set +e\n\n  pgs-calc apply ${vcf_filename}.vcf.gz \\\n    --ref ${scores.join(',')} \\\n    --genotypes ${params.genotypes_imputed_dosages} \\\n    --out ${vcf_filename}.scores.txt \\\n    --info ${vcf_filename}.scores.info \\\n    --no-ansi > ${vcf_filename}.scores.log\n\n  # ignore pgs-calc status to get log files of failed scores.\n  exit 0\n  \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "\"\"\"\n  set +e\n\n  pgs-calc apply ${vcf_filename}.vcf.gz \\\n    --ref ${scores.join(',')} \\\n    --genotypes ${params.genotypes_imputed_dosages} \\\n    --out ${vcf_filename}.scores.txt \\\n    --info ${vcf_filename}.scores.info \\\n    --no-ansi > ${vcf_filename}.scores.log\n\n  # ignore pgs-calc status to get log files of failed scores.\n  exit 0\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vcf_files",
            "prepared_scores_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "score_chunks_ch",
            "report_chunks_ch"
        ],
        "nb_outputs": 2,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "mergeScoreChunks": {
        "name_process": "mergeScoreChunks",
        "string_process": "\nprocess mergeScoreChunks {\n\n  publishDir params.output, mode: 'copy'\n\n  input:\n    file(score_chunks) from score_chunks_ch.collect()\n\n  output:\n    file \"*.txt\" into merged_score_files\n\n  \"\"\"\n\n  pgs-calc merge-score ${score_chunks} \\\n    --out ${params.project}.scores.txt\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n\n  pgs-calc merge-score ${score_chunks} \\\n    --out ${params.project}.scores.txt\n\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "score_chunks_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "merged_score_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [
            "publishDir params.output, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "mergeInfoChunks": {
        "name_process": "mergeInfoChunks",
        "string_process": "\nprocess mergeInfoChunks {\n\n  publishDir params.output, mode: 'copy'\n\n  input:\n    file(report_chunks) from report_chunks_ch.collect()\n\n  output:\n    file \"*.info\" into merged_info_files\n\n  \"\"\"\n\n  pgs-calc merge-info ${report_chunks} \\\n    --out ${params.project}.info\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 17,
        "string_script": "\"\"\"\n\n  pgs-calc merge-info ${report_chunks} \\\n    --out ${params.project}.info\n\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "report_chunks_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "merged_info_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [
            "publishDir params.output, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "createHtmlReport": {
        "name_process": "createHtmlReport",
        "string_process": "\nprocess createHtmlReport {\n\n  publishDir params.output, mode: 'copy'\n\n  input:\n    file(merged_score) from merged_score_files\n    file(merged_info) from merged_info_files\n\n\n  output:\n    file \"*.html\"\n    file \"*.coverage.txt\"\n\n  \"\"\"\n\n  wget https://www.pgscatalog.org/rest/score/all -O pgs-catalog.json\n\n  pgs-calc report \\\n    --data ${merged_score} \\\n    --info ${merged_info} \\\n    --meta pgs-catalog.json \\\n    --out ${params.project}.scores.html\n\n  pgs-calc report \\\n    --data ${merged_score} \\\n    --info ${merged_info} \\\n    --meta pgs-catalog.json \\\n    --template txt \\\n    --out ${params.project}.scores.coverage.txt\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 32,
        "string_script": "\"\"\"\n\n  wget https://www.pgscatalog.org/rest/score/all -O pgs-catalog.json\n\n  pgs-calc report \\\n    --data ${merged_score} \\\n    --info ${merged_info} \\\n    --meta pgs-catalog.json \\\n    --out ${params.project}.scores.html\n\n  pgs-calc report \\\n    --data ${merged_score} \\\n    --info ${merged_info} \\\n    --meta pgs-catalog.json \\\n    --template txt \\\n    --out ${params.project}.scores.coverage.txt\n\n  \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "merged_score_files",
            "merged_info_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lukfor__pgs-calc-nf",
        "directive": [
            "publishDir params.output, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}