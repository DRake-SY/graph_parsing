{
    "chrom_chunk": {
        "name_process": "chrom_chunk",
        "string_process": "\nprocess chrom_chunk {\n    publishDir \"${params.outputDir}/chrom\", mode: 'copy'\n    \n    input:\n    file(bedFile) from targets_bed\n    \n    output:\n    file(\"*\") into chrom_chunk_ch\n    \n    script:\n    \"\"\"\n    split-bed-chrom.py \"${bedFile}\"\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    split-bed-chrom.py \"${bedFile}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "targets_bed"
        ],
        "nb_inputs": 1,
        "outputs": [
            "chrom_chunk_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.outputDir}/chrom\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "line_chunk": {
        "name_process": "line_chunk",
        "string_process": "\nprocess line_chunk {\n    publishDir \"${params.outputDir}/line\", mode: 'copy'\n    \n    input:\n    file(bedFile) from targets_bed2\n    \n    output:\n    file('*') into line_chunk_ch\n    \n    script:\n    \"\"\"\n    split-bed-lines.py \"${bedFile}\" \"${params.numLines}\"\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    split-bed-lines.py \"${bedFile}\" \"${params.numLines}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "targets_bed2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "line_chunk_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.outputDir}/line\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "file_chunk": {
        "name_process": "file_chunk",
        "string_process": "\nprocess file_chunk {\n    publishDir \"${params.outputDir}/file\", mode: 'copy'\n    \n    input:\n    file(bedFile) from targets_bed3\n    \n    output:\n    file('*') into file_chunk_ch\n    \n    script:\n    \"\"\"\n    split-bed-files.py \"${bedFile}\" \"${params.numFiles}\"\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    split-bed-files.py \"${bedFile}\" \"${params.numFiles}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "targets_bed3"
        ],
        "nb_inputs": 1,
        "outputs": [
            "file_chunk_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.outputDir}/file\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "use_chrom_chunks": {
        "name_process": "use_chrom_chunks",
        "string_process": "\nprocess use_chrom_chunks {\n    echo true\n\n    input:\n    set file(bedFile), val(chunkLabel), val(chunkType) from chrom_chunk_ch2\n    \n    when:\n    params.splitBy == \"chrom\"\n    \n    output:\n    file(\"${output_file}\") into use_chrom_chunks_ch\n    \n    script:\n    output_file = \"${chunkType}.${chunkLabel}\"\n    \"\"\"\n    touch \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    output_file = \"${chunkType}.${chunkLabel}\"\n    \"\"\"\n    touch \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "chrom_chunk_ch2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "use_chrom_chunks_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "params.splitBy == \"chrom\"",
        "stub": ""
    },
    "use_line_chunks": {
        "name_process": "use_line_chunks",
        "string_process": "\nprocess use_line_chunks {\n    echo true\n\n    input:\n    set file(bedFile), val(chunkLabel), val(chunkType) from line_chunk_ch2\n    \n    when:\n    params.splitBy == \"lines\"\n    \n    output:\n    file(\"${output_file}\") into use_line_chunks_ch\n    \n    script:\n    output_file = \"${chunkType}.${chunkLabel}\"\n    \"\"\"\n    touch \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    output_file = \"${chunkType}.${chunkLabel}\"\n    \"\"\"\n    touch \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "line_chunk_ch2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "use_line_chunks_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "params.splitBy == \"lines\"",
        "stub": ""
    },
    "use_file_chunks": {
        "name_process": "use_file_chunks",
        "string_process": "\nprocess use_file_chunks {\n    echo true\n\n    input:\n    set file(bedFile), val(chunkLabel), val(chunkType) from file_chunk_ch2\n    \n    when:\n    params.splitBy == \"files\"\n    \n    output:\n    file(\"${output_file}\") into use_file_chunks_ch\n    \n    script:\n    output_file = \"${chunkType}.${chunkLabel}\"\n    \"\"\"\n    touch \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    output_file = \"${chunkType}.${chunkLabel}\"\n    \"\"\"\n    touch \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "file_chunk_ch2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "use_file_chunks_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "params.splitBy == \"files\"",
        "stub": ""
    },
    "use_all_results": {
        "name_process": "use_all_results",
        "string_process": "\nprocess use_all_results {\n    echo true\n    input:\n    file('*') from use_chrom_chunks_ch.mix(use_line_chunks_ch, use_file_chunks_ch).collect()\n    \n    script:\n    \"\"\"\n    ls -1\n    \"\"\"\n}",
        "nb_lignes_process": 9,
        "string_script": "    \"\"\"\n    ls -1\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "use_chrom_chunks_ch",
            "use_line_chunks_ch",
            "use_file_chunks_ch"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "create_file": {
        "name_process": "create_file",
        "string_process": "\nprocess create_file {\n                                     \n    tag \"${sampleID}\"\n    echo true\n\n    input:\n    set val(sampleID), val(sampleVal) from sample_values\n\n    output:\n    set val(sampleID), file(\"${output_file}\") into sample_files, sample_files2\n\n    script:\n    output_file = \"${sampleID}.data.txt\"\n    \"\"\"\n    for i in \\$(seq ${sampleVal}); do\n        echo ${sampleID} >> \"${output_file}\"\n    done\n    sleep 1\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    output_file = \"${sampleID}.data.txt\"\n    \"\"\"\n    for i in \\$(seq ${sampleVal}); do\n        echo ${sampleID} >> \"${output_file}\"\n    done\n    sleep 1\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_values"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_files",
            "sample_files2"
        ],
        "nb_outputs": 2,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "create_archive": {
        "name_process": "create_archive",
        "string_process": "\nprocess create_archive {\n                                             \n    tag \"(${params.archiveType}) ${sampleID}\"\n\n    input:\n    set val(sampleID), file(message_txt) from sample_files_filtered\n\n    output:\n    set val(sampleID), val(\"${params.archiveType}\"), file(\"${output_file}\") into archived_messages\n\n    script:\n                                                         \n    if ( \"${params.archiveType}\" == \"zip\" ) {\n        output_file = \"${sampleID}.message.zip\"\n        \"\"\"\n        zip \"${output_file}\" \"${message_txt}\"\n        sleep 1\n        \"\"\"\n    } else if ( \"${params.archiveType}\" == \"tar\" ) {\n        output_file = \"${sampleID}.message.tar.gz\"\n        \"\"\"\n        tar -czf \"${output_file}\" \"${message_txt}\"\n        sleep 1\n        \"\"\"\n    } else {\n        log.error \"Unrecognized archiveType: ${params.archiveType}\"\n    }\n}",
        "nb_lignes_process": 27,
        "string_script": "    if ( \"${params.archiveType}\" == \"zip\" ) {\n        output_file = \"${sampleID}.message.zip\"\n        \"\"\"\n        zip \"${output_file}\" \"${message_txt}\"\n        sleep 1\n        \"\"\"\n    } else if ( \"${params.archiveType}\" == \"tar\" ) {\n        output_file = \"${sampleID}.message.tar.gz\"\n        \"\"\"\n        tar -czf \"${output_file}\" \"${message_txt}\"\n        sleep 1\n        \"\"\"\n    } else {\n        log.error \"Unrecognized archiveType: ${params.archiveType}\"\n    }",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files_filtered"
        ],
        "nb_inputs": 1,
        "outputs": [
            "archived_messages"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"(${params.archiveType}) ${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "please_dont_break": {
        "name_process": "please_dont_break",
        "string_process": "\nprocess please_dont_break {\n    tag \"${sampleID}\"\n    echo true\n    errorStrategy \"ignore\"\n\n    input:\n    set val(sampleID), val(archive_type), file(archive_file) from archived_messages\n\n    output:\n    set val(archive_type), file(archive_file) into successful_messages\n\n    script:\n    \"\"\"\n    if [ \"${sampleID}\" == \"Sample2\" ]; then\n        echo \">>> ERROR: ${sampleID} has failed!\"\n        exit 1\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    if [ \"${sampleID}\" == \"Sample2\" ]; then\n        echo \">>> ERROR: ${sampleID} has failed!\"\n        exit 1\n    fi\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "archived_messages"
        ],
        "nb_inputs": 1,
        "outputs": [
            "successful_messages"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\"",
            "echo true",
            "errorStrategy \"ignore\""
        ],
        "when": "",
        "stub": ""
    },
    "gather_files": {
        "name_process": "gather_files",
        "string_process": "\nprocess gather_files {\n    publishDir \"${params.output_dir}/gather_files\", mode: 'copy', overwrite: true\n\n    input:\n    file(\"*\") from sample_files.collect()\n\n    output:\n    file(\"output.txt\")\n\n    script:\n    \"\"\"\n    cat * > output.txt\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    cat * > output.txt\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}/gather_files\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "make_file": {
        "name_process": "make_file",
        "string_process": "\nprocess make_file {\n    tag { \"${sampleID}\" }\n    echo true\n    publishDir \"${params.output_dir}/make_file\", mode: 'copy', overwrite: true\n\n    input:\n    val(sampleID) from samples\n\n    output:\n    file(\"${sampleID}.txt\") into (sample_files, sample_files2)\n\n    script:\n    \"\"\"\n    echo \"[make_file] ${sampleID}\"\n    echo \"[make_file] ${sampleID}\" > \"${sampleID}.txt\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    echo \"[make_file] ${sampleID}\"\n    echo \"[make_file] ${sampleID}\" > \"${sampleID}.txt\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag { \"${sampleID}\" }",
            "echo true",
            "publishDir \"${params.output_dir}/make_file\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "print_file": {
        "name_process": "print_file",
        "string_process": "\nprocess print_file {\n    echo true\n\n    input:\n    file(list) from file_list\n\n    script:\n    \"\"\"\n    printf \"[print_file]:\\\\n%s\" \"\\$(cat \"${list}\")\"\n    \"\"\"\n}",
        "nb_lignes_process": 10,
        "string_script": "    \"\"\"\n    printf \"[print_file]:\\\\n%s\" \"\\$(cat \"${list}\")\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "file_list"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "test_R": {
        "name_process": "test_R",
        "string_process": "\nprocess test_R {\n    tag \"${sample}\"\n    echo true\n\n    input:\n    val(sample) from samples\n\n    script:\n    \"\"\"\n    echo \"[test_R] \\$(test.R)\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    echo \"[test_R] \\$(test.R)\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sample}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "test_Python": {
        "name_process": "test_Python",
        "string_process": "\nprocess test_Python {\n    tag { \"${sample}\" }\n    echo true\n\n    input:\n    val(sample) from samples2\n\n    script:\n    \"\"\"\n    echo \"[test_Python] \\$(test.py)\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    echo \"[test_Python] \\$(test.py)\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag { \"${sample}\" }",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "Python_inline": {
        "name_process": "Python_inline",
        "string_process": "\nprocess Python_inline {\n    tag \"${sample}\"\n    echo true\n\n    input:\n    val(sample) from samples3\n\n    script:\n    \"\"\"\n    #!/usr/bin/env python\n    import os\n    import sys\n\n    # allow for import 'tools' from Nextflow bin directory, which is prepended to PATH\n    nextflow_bin = os.environ['PATH'].split(os.pathsep)[0]\n    sys.path.insert(0, nextflow_bin)\n    import tools\n\n    x = \"${sample}\"\n    print(\"[Python_inline] the sample is: {}\".format(x))\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    #!/usr/bin/env python\n    import os\n    import sys\n\n    # allow for import 'tools' from Nextflow bin directory, which is prepended to PATH\n    nextflow_bin = os.environ['PATH'].split(os.pathsep)[0]\n    sys.path.insert(0, nextflow_bin)\n    import tools\n\n    x = \"${sample}\"\n    print(\"[Python_inline] the sample is: {}\".format(x))\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples3"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sample}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "Python_args": {
        "name_process": "Python_args",
        "string_process": "\nprocess Python_args {\n    echo true\n\n    input:\n    val(all_samples) from samples4.collect()\n\n    script:\n    \"\"\"\n    python - ${all_samples} <<E0F\nimport sys\nprint(\"[Python_args] {0}\".format(sys.argv))\nE0F\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    python - ${all_samples} <<E0F\nimport sys\nprint(\"[Python_args] {0}\".format(sys.argv))\nE0F\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "tximport"
        ],
        "tools_url": [
            "https://bio.tools/tximport"
        ],
        "tools_dico": [
            {
                "name": "tximport",
                "uri": "https://bio.tools/tximport",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2497",
                                    "term": "Pathway or network analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An R/Bioconductor package that imports transcript-level abundance, estimated counts and transcript lengths, and summarizes into matrices for use with downstream gene-level analysis packages.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/tximport.html"
            }
        ],
        "inputs": [
            "samples4"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "R_inline": {
        "name_process": "R_inline",
        "string_process": "\nprocess R_inline {\n    tag \"${sample}\"\n    echo true\n\n    input:\n    val(sample) from samples5\n\n    script:\n    \"\"\"\n    #!/usr/bin/env Rscript\n\n    # source the 'tools' script in the bin dir\n    tryCatch({\n        source(\"tools.R\")\n    },\n    error=function(cond) {\n        # try to source from PATH\n        path <- Sys.getenv('PATH')\n        bin_dir <- unlist(strsplit(x = path, split = ':'))[1]\n        source(file.path(bin_dir, \"tools.R\"))\n    })\n\n    x <- \"${sample}\"\n    print(sprintf(\"[R_inline] the sample is: %s\", x))\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    #!/usr/bin/env Rscript\n\n    # source the 'tools' script in the bin dir\n    tryCatch({\n        source(\"tools.R\")\n    },\n    error=function(cond) {\n        # try to source from PATH\n        path <- Sys.getenv('PATH')\n        bin_dir <- unlist(strsplit(x = path, split = ':'))[1]\n        source(file.path(bin_dir, \"tools.R\"))\n    })\n\n    x <- \"${sample}\"\n    print(sprintf(\"[R_inline] the sample is: %s\", x))\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples5"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sample}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "R_args": {
        "name_process": "R_args",
        "string_process": "\nprocess R_args {\n    echo true\n\n    input:\n    val(all_samples) from samples6.collect()\n\n    script:\n    \"\"\"\n    Rscript --vanilla - ${all_samples} <<E0F\nprint(sprintf(\"[R_args] %s\", commandArgs(T)))\nE0F\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n    Rscript --vanilla - ${all_samples} <<E0F\nprint(sprintf(\"[R_args] %s\", commandArgs(T)))\nE0F\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples6"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "run_task": {
        "name_process": "run_task",
        "string_process": "\nprocess run_task {\n    echo true\n\n                                                                                           \n    input:\n    val(x)\n\n    script:\n                                                                                            \n                                                                                                                 \n    \"\"\"\n    printf '%s\\n%s\\n%s\\n%s\\n%s\\n\\n' 'x: ${x}' 'task: ${task}' 'workflow: ${workflow}' 'all task properties: ${task.properties.sort{it.key}.collect{it}.findAll{!['class', 'active'].contains(it.key)}.join('\\n')}'\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    printf '%s\\n%s\\n%s\\n%s\\n%s\\n\\n' 'x: ${x}' 'task: ${task}' 'workflow: ${workflow}' 'all task properties: ${task.properties.sort{it.key}.collect{it}.findAll{!['class', 'active'].contains(it.key)}.join('\\n')}'\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "x"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "print_sample": {
        "name_process": "print_sample",
        "string_process": "\nprocess print_sample {\n    input:\n    val(sampleID) from samples2\n\n    script:\n    \"\"\"\n    echo \"[print_sample] ${sampleID}\"\n    \"\"\"\n}",
        "nb_lignes_process": 8,
        "string_script": "    \"\"\"\n    echo \"[print_sample] ${sampleID}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "print_word": {
        "name_process": "print_word",
        "string_process": "\nprocess print_word {\n    tag \"${word}\"\n\n    input:\n    val(word) from words\n\n    output:\n    file(\"texput.pdf\") into pdfs\n\n    script:\n    \"\"\"\n    echo '\\\\shipout\\\\hbox{${word}}\\\\end' | pdftex\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    echo '\\\\shipout\\\\hbox{${word}}\\\\end' | pdftex\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "words"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pdfs"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${word}\""
        ],
        "when": "",
        "stub": ""
    },
    "make_report": {
        "name_process": "make_report",
        "string_process": "\nprocess make_report {\\\n    publishDir \"${params.outputDir}/\"\n\n    input:\n    set file(report), file('fig?.pdf') from reportTex.combine(all_pds)\n\n    output:\n    file(\"report.pdf\")\n\n    script:\n    \"\"\"\n    pdflatex \"${report}\"\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    pdflatex \"${report}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reportTex",
            "all_pds"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.outputDir}/\""
        ],
        "when": "",
        "stub": ""
    },
    "run": {
        "name_process": "run",
        "string_process": "\nprocess run {\n    echo true\n    input:\n    set val(x), val(params) from input_ch3.combine(combined_params)\n\n    script:\n    val1 = params.collect { it[0] }.join('.')\n    val2 = params.collect { it[1] }.join(' ')\n    \"\"\"\n    echo \"${val1}: ${val2}\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    val1 = params.collect { it[0] }.join('.')\n    val2 = params.collect { it[1] }.join(' ')\n    \"\"\"\n    echo \"${val1}: ${val2}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_ch3",
            "combined_params"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "demo": {
        "name_process": "demo",
        "string_process": "process demo {\n    echo true\n    input:\n    val(x) from Channel.from('')\n\n    script:\n    \"\"\"\n    env\n    echo \"NTHREADS is \\${NTHREADS:-not set}\"\n    \"\"\"\n}",
        "nb_lignes_process": 9,
        "string_script": "    \"\"\"\n    env\n    echo \"NTHREADS is \\${NTHREADS:-not set}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "denvax"
        ],
        "tools_url": [
            "https://bio.tools/denvax"
        ],
        "tools_dico": [
            {
                "name": "denvax",
                "uri": "https://bio.tools/denvax",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3379",
                            "term": "Preclinical and clinical studies"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatric medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "https://en.wikipedia.org/wiki/Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0560",
                                    "term": "DNA vaccine design"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Serostatus testing and dengue vaccine cost-benefit thresholds | R package for manuscript \"Serostatus Testing & Dengue Vaccine Cost Benefit Thresholds\"",
                "homepage": "https://cran.r-project.org/web/packages/denvax/index.html"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "create_message": {
        "name_process": "create_message",
        "string_process": "\nprocess create_message {\n    tag \"${sampleID}\"\n\n    input:\n    val(sampleID) from Channel.from(['Sample1', 'Sample2', 'Sample3', 'Sample4'])\n\n    output:\n    set val(sampleID), file(\"${output_file}\") into messages, messages2\n\n    script:\n    output_file = \"message.txt\"\n    \"\"\"\n    jq -n --arg message \"hello this is ${sampleID}\" '{\"message\":\\$message}' > input.json\n    cwl-runner \"${cwl_dir}/echo.cwl\" input.json\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    output_file = \"message.txt\"\n    \"\"\"\n    jq -n --arg message \"hello this is ${sampleID}\" '{\"message\":\\$message}' > input.json\n    cwl-runner \"${cwl_dir}/echo.cwl\" input.json\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "messages",
            "messages2"
        ],
        "nb_outputs": 2,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "print_message": {
        "name_process": "print_message",
        "string_process": "\nprocess print_message {\n    tag \"${sampleID}\"\n    echo true\n\n    input:\n    set val(sampleID), file(message_txt) from messages\n\n    output:\n    set val(sampleID), file(message_txt) into printed_messages\n\n    script:\n    \"\"\"\n    printf \"Got message for sample ${sampleID} from file ${message_txt}: %s\\n\" \"\\$(cat ${message_txt})\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    printf \"Got message for sample ${sampleID} from file ${message_txt}: %s\\n\" \"\\$(cat ${message_txt})\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "messages"
        ],
        "nb_inputs": 1,
        "outputs": [
            "printed_messages"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "zip_message": {
        "name_process": "zip_message",
        "string_process": " process zip_message {\n        tag \"${sampleID}\"\n\n        input:\n        set val(sampleID), file(message_txt) from good_samples\n\n        output:\n        set val(sampleID), val(\"${params.archive_type}\"), file(\"${output_file}\") into archived_messages\n\n        script:\n        output_file = \"${sampleID}.message.zip\"\n                                  \n        \"\"\"\n        jq -n --arg archive_output_file \"${output_file}\" \\\n        --arg archive_input_file \"${message_txt}\" \\\n        '{\"archive_output_file\":\\$archive_output_file, \\\n        \"archive_input_file\": {\"class\": \"File\", \"path\":\\$archive_input_file} }' \\\n        > input.json\n\n        cwl-runner \"${cwl_dir}/zip.cwl\" input.json\n        \"\"\"\n    }",
        "nb_lignes_process": 20,
        "string_script": "        output_file = \"${sampleID}.message.zip\"\n                                  \n        \"\"\"\n        jq -n --arg archive_output_file \"${output_file}\" \\\n        --arg archive_input_file \"${message_txt}\" \\\n        '{\"archive_output_file\":\\$archive_output_file, \\\n        \"archive_input_file\": {\"class\": \"File\", \"path\":\\$archive_input_file} }' \\\n        > input.json\n\n        cwl-runner \"${cwl_dir}/zip.cwl\" input.json\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "good_samples"
        ],
        "nb_inputs": 1,
        "outputs": [
            "archived_messages"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "tar_message": {
        "name_process": "tar_message",
        "string_process": " process tar_message {\n        tag \"${sampleID}\"\n\n        input:\n        set val(sampleID), file(message_txt) from good_samples\n\n        output:\n        set val(sampleID), val(\"${params.archive_type}\"), file(\"${output_file}\") into archived_messages\n\n        script:\n        output_file = \"${sampleID}.message.tar.gz\"\n                                          \n        \"\"\"\n        jq -n --arg archive_output_file \"${output_file}\" \\\n        --arg archive_input_file \"${message_txt}\" \\\n        '{\"archive_output_file\":\\$archive_output_file, \\\n        \"archive_input_file\": {\"class\": \"File\", \"path\":\\$archive_input_file} }' \\\n        > input.json\n\n        cwl-runner \"${cwl_dir}/tar.cwl\" input.json\n        \"\"\"\n    }",
        "nb_lignes_process": 20,
        "string_script": "        output_file = \"${sampleID}.message.tar.gz\"\n                                          \n        \"\"\"\n        jq -n --arg archive_output_file \"${output_file}\" \\\n        --arg archive_input_file \"${message_txt}\" \\\n        '{\"archive_output_file\":\\$archive_output_file, \\\n        \"archive_input_file\": {\"class\": \"File\", \"path\":\\$archive_input_file} }' \\\n        > input.json\n\n        cwl-runner \"${cwl_dir}/tar.cwl\" input.json\n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "good_samples"
        ],
        "nb_inputs": 1,
        "outputs": [
            "archived_messages"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "align": {
        "name_process": "align",
        "string_process": "\nprocess align {\n    publishDir \"${params.output_dir}/${branch}\", mode: \"copy\"\n    tag \"${prefix} - ${branch}\"\n    input:\n    set val(sampleID), file(input_file) from demo_tsvs\n    each param from align_params\n\n    output:\n    set val(branch), val(sampleID), file(output_file) into alignments\n\n    script:\n    prefix = \"${sampleID}\"\n    branch = \"align.${param}\"\n    output_file = \"${prefix}.align.txt\"\n    \"\"\"\n    echo \"${param}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    prefix = \"${sampleID}\"\n    branch = \"align.${param}\"\n    output_file = \"${prefix}.align.txt\"\n    \"\"\"\n    echo \"${param}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "Branch"
        ],
        "tools_url": [
            "https://bio.tools/Branch"
        ],
        "tools_dico": [
            {
                "name": "Branch",
                "uri": "https://bio.tools/Branch",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3408",
                            "term": "Haematology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "Neurology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatric medicine"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3408",
                            "term": "https://en.wikipedia.org/wiki/Hematology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "https://en.wikipedia.org/wiki/Neurology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "https://en.wikipedia.org/wiki/Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatrics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "Splitting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "File splitting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Interactive, web-based tool for testing hypotheses and developing predictive models.",
                "homepage": "https://bitbucket.org/sulab/biobranch/src/default/"
            }
        ],
        "inputs": [
            "demo_tsvs",
            "align_params"
        ],
        "nb_inputs": 2,
        "outputs": [
            "alignments"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}/${branch}\", mode: \"copy\"",
            "tag \"${prefix} - ${branch}\""
        ],
        "when": "",
        "stub": ""
    },
    "dedup": {
        "name_process": "dedup",
        "string_process": "\nprocess dedup {\n    publishDir \"${params.output_dir}/${branch_out}\", mode: \"copy\"\n    tag \"${prefix} - ${branch_out}\"\n\n    input:\n    set val(branch_in), val(sampleID), file(input_file) from alignments\n    each param from dedup_params\n\n    output:\n    set val(branch_out), val(sampleID), file(output_file) into dedups\n\n    script:\n    prefix = \"${sampleID}\"\n    branch_out = \"dedup.${param}/${branch_in}\"\n    output_file = \"${prefix}.dedup.txt\"\n    \"\"\"\n    echo \"${param}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}\"\n    branch_out = \"dedup.${param}/${branch_in}\"\n    output_file = \"${prefix}.dedup.txt\"\n    \"\"\"\n    echo \"${param}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alignments",
            "dedup_params"
        ],
        "nb_inputs": 2,
        "outputs": [
            "dedups"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}/${branch_out}\", mode: \"copy\"",
            "tag \"${prefix} - ${branch_out}\""
        ],
        "when": "",
        "stub": ""
    },
    "peak_calling": {
        "name_process": "peak_calling",
        "string_process": "\nprocess peak_calling {\n    publishDir \"${params.output_dir}/${branch_out}\", mode: \"copy\"\n    tag \"${prefix} - ${branch_out}\"\n\n    input:\n    set val(branch_in), val(sampleID), file(input_file) from dedups\n    each param from peaks_params\n\n    output:\n    set val(branch_out), val(sampleID), file(output_file) into peaks\n\n    script:\n    prefix = \"${sampleID}\"\n    branch_out = \"peaks.${param}/${branch_in}\"\n    output_file = \"${prefix}.peaks.txt\"\n    \"\"\"\n    echo \"${param}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}\"\n    branch_out = \"peaks.${param}/${branch_in}\"\n    output_file = \"${prefix}.peaks.txt\"\n    \"\"\"\n    echo \"${param}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dedups",
            "peaks_params"
        ],
        "nb_inputs": 2,
        "outputs": [
            "peaks"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}/${branch_out}\", mode: \"copy\"",
            "tag \"${prefix} - ${branch_out}\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_files": {
        "name_process": "collect_files",
        "string_process": "\nprocess collect_files {\n    publishDir \"${params.output_dir}/collect_files\", mode: 'copy', overwrite: true\n\n    input:\n    file(files:\"*\") from sample_files.collect()\n\n    output:\n    file(files)\n\n    script:\n    \"\"\"\n    \"\"\"\n\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    \"\"\"",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "files"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}/collect_files\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "each_fastq": {
        "name_process": "each_fastq",
        "string_process": "\nprocess each_fastq {\n    tag \"${fastq}\"\n    echo true\n\n    input:\n    file(fastq) from samples_each_fastq2\n\n    script:\n    \"\"\"\n    echo \"[each_fastq] got file: ${fastq}\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    echo \"[each_fastq] got file: ${fastq}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_each_fastq2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${fastq}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "fastq_pairs": {
        "name_process": "fastq_pairs",
        "string_process": "\nprocess fastq_pairs {\n    tag { \"${sampleID}\" }\n    echo true\n\n    input:\n    set val(sampleID), file(fastqR1: \"*\"), file(fastqR2: \"*\") from samples_R1_R2_2\n\n    script:\n    \"\"\"\n    printf \"[fastq_pairs] sample ${sampleID}\\nR1: ${fastqR1}\\nR2: ${fastqR2}\\n\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    printf \"[fastq_pairs] sample ${sampleID}\\nR1: ${fastqR1}\\nR2: ${fastqR2}\\n\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_R1_R2_2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag { \"${sampleID}\" }",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "use_file": {
        "name_process": "use_file",
        "string_process": "\nprocess use_file {\n    publishDir \"output\", mode: 'copy'\n    echo true\n\n    input:\n    file(txt_file) from input_ch\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"${txt_file}\".replaceFirst(/.txt$/, \".out.txt\")\n    \"\"\"\n    echo \"doing a thing with file ${txt_file} on system \\$(hostname)\"\n    touch \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    output_file = \"${txt_file}\".replaceFirst(/.txt$/, \".out.txt\")\n    \"\"\"\n    echo \"doing a thing with file ${txt_file} on system \\$(hostname)\"\n    touch \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"output\", mode: 'copy'",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "download_pics": {
        "name_process": "download_pics",
        "string_process": "\nprocess download_pics {\n    tag \"${name}\"\n    publishDir \"${params.output_dir}/${name}\", overwrite: true\n\n    input:\n    set val(name), val(url) from people_links\n\n    output:\n    set val(name), val(url), file(\"${output}\") into people_pics\n\n    script:\n    output = \"${name}.jpg\"\n    \"\"\"\n    # download image\n    wget \"${url}\" -O \"${output}\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    output = \"${name}.jpg\"\n    \"\"\"\n    # download image\n    wget \"${url}\" -O \"${output}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "wossoutput"
        ],
        "tools_url": [
            "https://bio.tools/wossoutput"
        ],
        "tools_dico": [
            {
                "name": "wossoutput",
                "uri": "https://bio.tools/wossoutput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM output data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossoutput.html"
            }
        ],
        "inputs": [
            "people_links"
        ],
        "nb_inputs": 1,
        "outputs": [
            "people_pics"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${name}\"",
            "publishDir \"${params.output_dir}/${name}\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "create_db": {
        "name_process": "create_db",
        "string_process": "\nprocess create_db {\n    tag \"${name}\"\n\n    input:\n    val(name) from people_names\n\n    output:\n    set val(name), file(\"${output_db}\") into people_dbs\n\n    script:\n    output_db = \"${name}.sqlite\"\n    \"\"\"\n    # create a new database\n    sqlite3 \"${output_db}\" \"CREATE TABLE TBL1(NAME TEXT, URL TEXT, FILENAME TEXT, PIC BLOB);\"\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    output_db = \"${name}.sqlite\"\n    \"\"\"\n    # create a new database\n    sqlite3 \"${output_db}\" \"CREATE TABLE TBL1(NAME TEXT, URL TEXT, FILENAME TEXT, PIC BLOB);\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "people_names"
        ],
        "nb_inputs": 1,
        "outputs": [
            "people_dbs"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "update_dbs": {
        "name_process": "update_dbs",
        "string_process": "\nprocess update_dbs {\n    tag \"${name}\"\n    publishDir \"${params.output_dir}/${name}\", overwrite: true\n\n    input:\n    set val(name), val(url), file(pic), file(db) from people_db_files\n\n    output:\n    file(\"${db}\") into people_updated_dbs\n\n    script:\n    \"\"\"\n    #!/usr/bin/env python\n    import sqlite3\n    conn = sqlite3.connect(\"${db}\")\n\n    # insert the image file into the database, with metadata\n    with open(\"${pic}\", 'rb') as input_file:\n            blob = input_file.read()\n            sql = '''\n            INSERT INTO TBL1 (NAME, URL, FILENAME, PIC) VALUES(?, ?, ?, ?);\n            '''\n            conn.execute(sql,[\"${name}\", \"${url}\", \"${pic}\", sqlite3.Binary(blob)])\n            conn.commit()\n    conn.close()\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    #!/usr/bin/env python\n    import sqlite3\n    conn = sqlite3.connect(\"${db}\")\n\n    # insert the image file into the database, with metadata\n    with open(\"${pic}\", 'rb') as input_file:\n            blob = input_file.read()\n            sql = '''\n            INSERT INTO TBL1 (NAME, URL, FILENAME, PIC) VALUES(?, ?, ?, ?);\n            '''\n            conn.execute(sql,[\"${name}\", \"${url}\", \"${pic}\", sqlite3.Binary(blob)])\n            conn.commit()\n    conn.close()\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "people_db_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "people_updated_dbs"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${name}\"",
            "publishDir \"${params.output_dir}/${name}\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "concat_dbs": {
        "name_process": "concat_dbs",
        "string_process": "\nprocess concat_dbs {\n    publishDir \"${params.output_dir}\", overwrite: true\n\n    input:\n    file(all_dbs: \"db?\") from sample_dbs.collect()\n\n    output:\n    file(\"${output_sqlite}\") into plots_db\n\n    script:\n    output_sqlite = \"plots.sqlite\"\n    \"\"\"\n    python - ${all_dbs} <<E0F\nimport sys\nimport sqlite3\n\ndbs = sys.argv[1:]\n\n# setup new output db\noutput_db = \"${output_sqlite}\"\nconn = sqlite3.connect(output_db)\nconn.execute(\"CREATE TABLE TBL1(sampleID text, x text, y text, a text, baseplot blob, ggplot blob)\")\n\n# add each input db to the output db\nfor db in dbs:\n    conn.execute('''ATTACH '{0}' as dba'''.format(db))\n    conn.execute(\"BEGIN\")\n    for row in conn.execute('''SELECT * FROM dba.sqlite_master WHERE type=\"table\"'''):\n        combine_sql = \"INSERT INTO \"+ row[1] + \" SELECT * FROM dba.\" + row[1]\n        conn.execute(combine_sql)\n    conn.commit()\n    conn.execute(\"detach database dba\")\nE0F\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    output_sqlite = \"plots.sqlite\"\n    \"\"\"\n    python - ${all_dbs} <<E0F\nimport sys\nimport sqlite3\n\ndbs = sys.argv[1:]\n\n# setup new output db\noutput_db = \"${output_sqlite}\"\nconn = sqlite3.connect(output_db)\nconn.execute(\"CREATE TABLE TBL1(sampleID text, x text, y text, a text, baseplot blob, ggplot blob)\")\n\n# add each input db to the output db\nfor db in dbs:\n    conn.execute('''ATTACH '{0}' as dba'''.format(db))\n    conn.execute(\"BEGIN\")\n    for row in conn.execute('''SELECT * FROM dba.sqlite_master WHERE type=\"table\"'''):\n        combine_sql = \"INSERT INTO \"+ row[1] + \" SELECT * FROM dba.\" + row[1]\n        conn.execute(combine_sql)\n    conn.commit()\n    conn.execute(\"detach database dba\")\nE0F\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "tximport",
            "dbSNP",
            "SyConn"
        ],
        "tools_url": [
            "https://bio.tools/tximport",
            "https://bio.tools/dbsnp",
            "https://bio.tools/syconn"
        ],
        "tools_dico": [
            {
                "name": "tximport",
                "uri": "https://bio.tools/tximport",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2497",
                                    "term": "Pathway or network analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An R/Bioconductor package that imports transcript-level abundance, estimated counts and transcript lengths, and summarizes into matrices for use with downstream gene-level analysis packages.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/tximport.html"
            },
            {
                "name": "dbSNP",
                "uri": "https://bio.tools/dbsnp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3574",
                            "term": "Human genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3661",
                                    "term": "SNP annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_1106",
                                "term": "dbSNP ID"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Database of single nucleotide polymorphism (dbSNP) contains human single nucleotide variations, microsatellites, and small-scale insertions and deletions along with publication, population frequency, molecular consequence, and genomic and RefSeq mapping information for both common variations and clinical mutations.",
                "homepage": "http://www.ncbi.nlm.nih.gov/SNP/"
            },
            {
                "name": "SyConn",
                "uri": "https://bio.tools/syconn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0611",
                            "term": "Electron microscopy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "Neurology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3473",
                            "term": "Data mining"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3334",
                            "term": "https://en.wikipedia.org/wiki/Neurology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3562",
                                    "term": "Network simulation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3443",
                                    "term": "Image analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Automated synaptic connectivity inference for volume electron microscopy",
                "homepage": "https://structuralneurobiologylab.github.io/SyConn/"
            }
        ],
        "inputs": [
            "sample_dbs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "plots_db"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "report": {
        "name_process": "report",
        "string_process": "\nprocess report {\n    publishDir \"${params.output_dir}\", overwrite: true, mode: \"move\"\n\n    input:\n    set file(db), file(report) from plots_db.combine(report_file)\n\n    output:\n    file(\"${html_output}\")\n\n    script:\n    html_output = \"plots.html\"\n    \"\"\"\n    # convert report file symlinks to copies of original files, because knitr wants Rmd to be in pwd\n    for item in *.Rmd; do\n        if [ -L \"\\${item}\" ]; then\n            sourcepath=\"\\$(python -c \"import os; print(os.path.realpath('\\${item}'))\")\"\n            echo \">>> resolving source file: \\${sourcepath}\"\n            rsync -va \"\\${sourcepath}\" \"\\${item}\"\n        fi\n    done\n\n    # compile the report\n    Rscript -e 'rmarkdown::render(input = \"${report}\", params = list(db = \"${db}\"), output_format = \"html_document\", output_file = \"${html_output}\")'\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    html_output = \"plots.html\"\n    \"\"\"\n    # convert report file symlinks to copies of original files, because knitr wants Rmd to be in pwd\n    for item in *.Rmd; do\n        if [ -L \"\\${item}\" ]; then\n            sourcepath=\"\\$(python -c \"import os; print(os.path.realpath('\\${item}'))\")\"\n            echo \">>> resolving source file: \\${sourcepath}\"\n            rsync -va \"\\${sourcepath}\" \"\\${item}\"\n        fi\n    done\n\n    # compile the report\n    Rscript -e 'rmarkdown::render(input = \"${report}\", params = list(db = \"${db}\"), output_format = \"html_document\", output_file = \"${html_output}\")'\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "plots_db",
            "report_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}\", overwrite: true, mode: \"move\""
        ],
        "when": "",
        "stub": ""
    },
    "make_file1": {
        "name_process": "make_file1",
        "string_process": "\nprocess make_file1 {\n    tag \"${sampleID}\"\n\n    input:\n    val(sampleID) from samples\n\n    output:\n    set val(sampleID), file(\"${output_file}\") into sample_file1\n\n    script:\n    output_file = \"${sampleID}.file1.txt\"\n    \"\"\"\n    echo \"[make_file1] ${sampleID}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    output_file = \"${sampleID}.file1.txt\"\n    \"\"\"\n    echo \"[make_file1] ${sampleID}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_file1"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "make_file2": {
        "name_process": "make_file2",
        "string_process": "\nprocess make_file2 {\n    tag \"${sampleID}\"\n\n    input:\n    val(sampleID) from samples2\n\n    output:\n    set val(sampleID), file(\"${output_file}\") into sample_file2\n\n    script:\n    output_file = \"${sampleID}.file2.txt\"\n    \"\"\"\n    echo \"[make_file2] ${sampleID}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    output_file = \"${sampleID}.file2.txt\"\n    \"\"\"\n    echo \"[make_file2] ${sampleID}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_file2"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_all_files": {
        "name_process": "collect_all_files",
        "string_process": "\nprocess collect_all_files {\n    echo true\n\n    input:\n    set val(sampleID), file(sampleFiles: \"*\") from all_samples_files\n\n    script:\n    \"\"\"\n    echo \"[collect_all_files] ${sampleID}: got these files: ${sampleFiles}\"\n\n    # do things with files here\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n    echo \"[collect_all_files] ${sampleID}: got these files: ${sampleFiles}\"\n\n    # do things with files here\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_samples_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "with_tags": {
        "name_process": "with_tags",
        "string_process": "\nprocess with_tags {\n    tag { \"${sampleID}\" }\n\n    input:\n    val(sampleID) from samples3\n\n    script:\n    \"\"\"\n    echo \"[with_tags] ${sampleID}\"\n    \"\"\"\n}",
        "nb_lignes_process": 10,
        "string_script": "    \"\"\"\n    echo \"[with_tags] ${sampleID}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples3"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag { \"${sampleID}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "with_echo": {
        "name_process": "with_echo",
        "string_process": "\nprocess with_echo {\n    tag \"${sampleID}\"\n    echo true\n\n    input:\n    val(sampleID) from samples4\n\n    script:\n    \"\"\"\n    echo \"[with_echo] ${sampleID}\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    echo \"[with_echo] ${sampleID}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples4"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "divide": {
        "name_process": "divide",
        "string_process": "\nprocess divide {\n    echo true\n    container \"python:3\"                    \n\n    input:\n    set val(numerator), val(denominator) from some_values\n\n    script:\n    \"\"\"\n    # check that we are actually inside the container\n    cat /etc/*release\n\n    divide.py \"${numerator}\" \"${denominator}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    # check that we are actually inside the container\n    cat /etc/*release\n\n    divide.py \"${numerator}\" \"${denominator}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "some_values"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true",
            "container \"python:3\""
        ],
        "when": "",
        "stub": ""
    },
    "update_table": {
        "name_process": "update_table",
        "string_process": "\nprocess update_table {\n    tag \"${prefix}\"\n    publishDir \"${params.output_dir}/update_table\", overwrite: true\n\n    input:\n    set caller, sampleID, variants_file from variants\n\n    output:\n    file(\"${output_file}\") into updated_variants\n\n    script:\n    prefix = \"${sampleID}.${caller}\"\n    output_file = \"${prefix}.variants.tsv\"\n    \"\"\"\n    paste-col.py -i \"${variants_file}\" --header Run --value \"${runID}\" | \\\n    paste-col.py --header Sample --value \"${sampleID}\" | \\\n    paste-col.py --header VariantCaller --value \"${caller}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    prefix = \"${sampleID}.${caller}\"\n    output_file = \"${prefix}.variants.tsv\"\n    \"\"\"\n    paste-col.py -i \"${variants_file}\" --header Run --value \"${runID}\" | \\\n    paste-col.py --header Sample --value \"${sampleID}\" | \\\n    paste-col.py --header VariantCaller --value \"${caller}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "variants"
        ],
        "nb_inputs": 1,
        "outputs": [
            "updated_variants"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${prefix}\"",
            "publishDir \"${params.output_dir}/update_table\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "split_combine_search": {
        "name_process": "split_combine_search",
        "string_process": "\nprocess split_combine_search {\n    tag \"${input_tables}\"\n\n    input:\n    set file(input_tables: '*'), file(desired_variants) from split_updated_variants\n\n    output:\n    file(\"combined.variants.tsv\") into combined_variants\n\n    script:\n    \"\"\"\n    concat-tables.py ${input_tables} | head -1 > combined.variants.tsv\n    concat-tables.py ${input_tables} | \\\n    grep -f \"${desired_variants}\" >> combined.variants.tsv\n\n    # simulate a long-running process\n    sleep 10\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    concat-tables.py ${input_tables} | head -1 > combined.variants.tsv\n    concat-tables.py ${input_tables} | \\\n    grep -f \"${desired_variants}\" >> combined.variants.tsv\n\n    # simulate a long-running process\n    sleep 10\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "split_updated_variants"
        ],
        "nb_inputs": 1,
        "outputs": [
            "combined_variants"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${input_tables}\""
        ],
        "when": "",
        "stub": ""
    },
    "final_combine": {
        "name_process": "final_combine",
        "string_process": "\nprocess final_combine {\n    publishDir \"${params.output_dir}/\", overwrite: true\n\n    input:\n    file(input_tables: 'table?') from combined_variants.collect()\n\n    output:\n    file('final.variants.tsv')\n\n    script:\n    \"\"\"\n    concat-tables.py ${input_tables} > final.variants.tsv\n\n    # simulate a long-running process\n    sleep 10\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    concat-tables.py ${input_tables} > final.variants.tsv\n\n    # simulate a long-running process\n    sleep 10\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "combined_variants"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}/\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "make_foo": {
        "name_process": "make_foo",
        "string_process": "\nprocess make_foo {\n    tag \"${x}\"\n    echo true\n    publishDir \"output\", overwrite: true, mode: 'copy'\n\n    input:\n    val(x) from input_ch\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"${x}.txt\"\n    \"\"\"\n    echo \"this is the script for  ${x}\"\n    echo \"${x}\" > \"${output_file}\"\n    \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "    output_file = \"${x}.txt\"\n    \"\"\"\n    echo \"this is the script for  ${x}\"\n    echo \"${x}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${x}\"",
            "echo true",
            "publishDir \"output\", overwrite: true, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "make_files": {
        "name_process": "make_files",
        "string_process": "\nprocess make_files {\n    tag \"${fastq}\"\n    publishDir \"${params.output_dir}/make_files\", mode: 'copy', overwrite: true\n\n    input:\n    val(fastq) from samples_fastqs\n\n    output:\n    set val(fastq), file(output_html), file(output_zip) into sample_files\n\n    script:\n                                                                              \n    output_html = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_zip = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    \"\"\"\n    touch \"${output_html}\"\n    touch \"${output_zip}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    output_html = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_zip = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    \"\"\"\n    touch \"${output_html}\"\n    touch \"${output_zip}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_fastqs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${fastq}\"",
            "publishDir \"${params.output_dir}/make_files\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "get_files": {
        "name_process": "get_files",
        "string_process": "\nprocess get_files {\n    tag \"${fastq}\"\n    echo true\n\n    input:\n    set val(fastq), file(html), file(zip) from sample_files\n\n    script:\n    \"\"\"\n    echo \"[get_files] recieved files: ${html} ${zip}\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    echo \"[get_files] recieved files: ${html} ${zip}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${fastq}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "task1": {
        "name_process": "task1",
        "string_process": "\nprocess task1 {\n    tag \"${sampleID}\"\n    input:\n    val(sampleID) from input_ch\n\n    script:\n    output_bam = \"${sampleID}.${get_outputfile(task)}\"\n    \"\"\"\n    echo \"[task1] ${output_bam}\"\n    touch \"${sampleID}.bam\"\n    \"\"\"\n\n}",
        "nb_lignes_process": 12,
        "string_script": "    output_bam = \"${sampleID}.${get_outputfile(task)}\"\n    \"\"\"\n    echo \"[task1] ${output_bam}\"\n    touch \"${sampleID}.bam\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "task2": {
        "name_process": "task2",
        "string_process": "\nprocess task2 {\n    tag \"${sampleID}\"\n    input:\n    val(sampleID) from input_ch2\n\n    script:\n    output_bam = \"${sampleID}.${get_outputfile(task)}\"\n    tmp_file = get_outputfile(task, key = \"tmpfile\")\n    \"\"\"\n    echo \"[task2] ${output_bam}, ${tmp_file}\"\n    touch \"${sampleID}.bam\"\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    output_bam = \"${sampleID}.${get_outputfile(task)}\"\n    tmp_file = get_outputfile(task, key = \"tmpfile\")\n    \"\"\"\n    echo \"[task2] ${output_bam}, ${tmp_file}\"\n    touch \"${sampleID}.bam\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_ch2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\""
        ],
        "when": "",
        "stub": ""
    },
    "analyze_HapMaps": {
        "name_process": "analyze_HapMaps",
        "string_process": "\nprocess analyze_HapMaps {\n    tag \"${fastq}\"\n    echo true\n\n    input:\n    file(fastq) from input_files\n\n                                                             \n    when:\n    fastq.name.contains(\"HapMap\")\n\n                                                                          \n    script:\n    if( params.mode == 'foo' )\n        \"\"\"\n        echo \"[analyze_HapMaps] running foo script on file: ${fastq}\"\n        \"\"\"\n\n    else if( params.mode == 'bar' )\n        \"\"\"\n        echo \"[analyze_HapMaps] running bar script on file: ${fastq}\"\n        \"\"\"\n\n    else if( params.mode == 'baz' )\n        \"\"\"\n        echo \"[analyze_HapMaps] running baz script on file: ${fastq}\"\n        \"\"\"\n\n    else\n        error \"Invalid mode: ${params.mode}\"\n\n}",
        "nb_lignes_process": 31,
        "string_script": "    if( params.mode == 'foo' )\n        \"\"\"\n        echo \"[analyze_HapMaps] running foo script on file: ${fastq}\"\n        \"\"\"\n\n    else if( params.mode == 'bar' )\n        \"\"\"\n        echo \"[analyze_HapMaps] running bar script on file: ${fastq}\"\n        \"\"\"\n\n    else if( params.mode == 'baz' )\n        \"\"\"\n        echo \"[analyze_HapMaps] running baz script on file: ${fastq}\"\n        \"\"\"\n\n    else\n        error \"Invalid mode: ${params.mode}\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${fastq}\"",
            "echo true"
        ],
        "when": "fastq.name.contains(\"HapMap\")",
        "stub": ""
    },
    "call_variants": {
        "name_process": "call_variants",
        "string_process": "\nprocess call_variants {\n    tag \"${fastq}\"\n    echo true\n\n    input:\n    file(fastq) from input_files2\n    each caller from callers\n\n    output:\n    set val(caller), file(fastq) into variant_calls\n\n    script:\n    if( caller == \"LoFreq\" )\n        \"\"\"\n        echo \"[call_variants] running LoFreq on ${fastq}\"\n        \"\"\"\n    else if( caller == 'HaplotypeCaller' )\n        \"\"\"\n        echo \"[call_variants] running HaplotypeCaller on ${fastq}\"\n        \"\"\"\n    else if( caller == 'MuTect2' )\n        \"\"\"\n        echo \"[call_variants] running MuTect2 on ${fastq}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    if( caller == \"LoFreq\" )\n        \"\"\"\n        echo \"[call_variants] running LoFreq on ${fastq}\"\n        \"\"\"\n    else if( caller == 'HaplotypeCaller' )\n        \"\"\"\n        echo \"[call_variants] running HaplotypeCaller on ${fastq}\"\n        \"\"\"\n    else if( caller == 'MuTect2' )\n        \"\"\"\n        echo \"[call_variants] running MuTect2 on ${fastq}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_files2",
            "callers"
        ],
        "nb_inputs": 2,
        "outputs": [
            "variant_calls"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${fastq}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "annotate_variants": {
        "name_process": "annotate_variants",
        "string_process": "\nprocess annotate_variants {\n    tag \"${fastq}\"\n    echo true\n\n    input:\n    set val(caller), file(fastq) from variant_calls\n\n    script:\n    if( caller == \"LoFreq\" )\n        \"\"\"\n        echo \"[annotate_variants] annotating variants from LoFreq on ${fastq}\"\n        \"\"\"\n    else if( caller == 'HaplotypeCaller' )\n        \"\"\"\n        echo \"[annotate_variants] annotating variants from HaplotypeCaller on ${fastq}\"\n        \"\"\"\n    else if( caller == 'MuTect2' )\n        \"\"\"\n        echo \"[annotate_variants] annotating variants from MuTect2 on ${fastq}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    if( caller == \"LoFreq\" )\n        \"\"\"\n        echo \"[annotate_variants] annotating variants from LoFreq on ${fastq}\"\n        \"\"\"\n    else if( caller == 'HaplotypeCaller' )\n        \"\"\"\n        echo \"[annotate_variants] annotating variants from HaplotypeCaller on ${fastq}\"\n        \"\"\"\n    else if( caller == 'MuTect2' )\n        \"\"\"\n        echo \"[annotate_variants] annotating variants from MuTect2 on ${fastq}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "variant_calls"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${fastq}\"",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "send_file": {
        "name_process": "send_file",
        "string_process": "\nprocess send_file {\n  input:\n  val mail from sample_files2.collect()\n\n  exec:\n  sendMail {\n    from \"${params.email_to}\"\n    to \"${params.email_from}\"\n    subject '[send_file]'\n    attach mail\n    '''\n    Check the attachment\n    '''\n  }\n}",
        "nb_lignes_process": 14,
        "string_script": "  sendMail {\n    from \"${params.email_to}\"\n    to \"${params.email_from}\"\n    subject '[send_file]'\n    attach mail\n    '''\n    Check the attachment\n    '''\n  }",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "FROMP",
            "GTO",
            "iCheck"
        ],
        "tools_url": [
            "https://bio.tools/fromp",
            "https://bio.tools/gto",
            "https://bio.tools/icheck"
        ],
        "tools_dico": [
            {
                "name": "FROMP",
                "uri": "https://bio.tools/fromp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2259",
                            "term": "Systems biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3660",
                                    "term": "Metabolic network modelling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3660",
                                    "term": "http://edamontology.org/Metabolic%20pathway%20modelling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software for mapping and visualizing enzyme annotations onto the Kyoto Encyclopedia of Genes and Genomes (KEGG) metabolic pathways or custom-made pathways and comparing the samples in terms of their Pathway Completeness Scores, their relative Activity Scores or enzyme enrichment odds ratios.",
                "homepage": "https://github.com/LaRocheLab/FROMP"
            },
            {
                "name": "GTO",
                "uri": "https://bio.tools/gto",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A toolkit to unify pipelines in genomic and proteomic research.\n\nGTO is a toolkit to unify pipelines in genomic and proteomic research.\n\nGTO is a toolkit for genomics and proteomics, namely for FASTQ, FASTA and SEQ formats, with many complementary tools. The toolkit is for Unix-based systems, built for ultra-fast computations. GTO supports pipes for easy integration with the sub-programs belonging to GTO as well as external tools. GTO works as LEGOs, since it allows the construction of multiple pipelines with many combinations.",
                "homepage": "http://bioinformatics.ua.pt/gto"
            },
            {
                "name": "iCheck",
                "uri": "https://bio.tools/icheck",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0099",
                            "term": "RNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "QC pipeline and data analysis tools for high-dimensional Illumina mRNA expression data.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/iCheck.html"
            }
        ],
        "inputs": [
            "sample_files2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "make_plot_dbs": {
        "name_process": "make_plot_dbs",
        "string_process": "\nprocess make_plot_dbs {\n    tag \"${sampleID}\"\n    publishDir \"${params.output_dir}/${sampleID}\", overwrite: true\n\n    input:\n    set val(sampleID), val(args) from samples_inputs\n\n    output:\n    file(\"${output_db}\") into sample_dbs\n\n    script:\n    x = args[0]\n    y = args[1]\n    a = args[2]\n    output_db = \"plots.sqlite\"\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(\"ggplot2\")\n    library(\"RSQLite\")\n\n    sampleID <- \"${sampleID}\"\n    x <- as.numeric(\"${x}\")\n    y <- as.numeric(\"${y}\")\n    a <- as.numeric(\"${a}\")\n\n    # create database\n    con <- dbConnect(SQLite(), \"${output_db}\")\n\n    # setup database\n    dbGetQuery(con, 'create table tbl1 (sampleID text, x text, y text, a text, baseplot blob, ggplot blob)')\n\n    # make R plot object with ggplot2\n    g <- ggplot(data = data.frame(x = rnorm(a, 1, x), y = rnorm(a, 1, y)), aes(x = x, y = y)) +\n        geom_point()\n\n    # base R plots cant be saved as object, but can be captured and reused later with R 3.3.0+\n    pdf(\"test.pdf\") # need open graphics device to record plot\n    dev.control(displaylist=\"enable\")\n    plot(data.frame(x = rnorm(50, 1, 6), y = rnorm(50, 1, 8)))\n    p <- serialize(recordPlot(), NULL)\n    dev.off()\n\n    # bundle the data in a dataframe\n    df <- data.frame(a = a,\n                    x = x,\n                    y = y,\n                    sampleID = sampleID,\n                    baseplot = I(list(serialize(p, NULL))),\n                    ggplot = I(list(serialize(g, NULL)))\n                    )\n\n    # insert data into the db\n    dbGetPreparedQuery(con, 'insert into tbl1 (sampleID, x, y, a, baseplot, ggplot) values (:sampleID, :a, :x, :y, :baseplot, :ggplot)',\n                   bind.data=df)\n    \"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "    x = args[0]\n    y = args[1]\n    a = args[2]\n    output_db = \"plots.sqlite\"\n    \"\"\"\n    #!/usr/bin/env Rscript\n    library(\"ggplot2\")\n    library(\"RSQLite\")\n\n    sampleID <- \"${sampleID}\"\n    x <- as.numeric(\"${x}\")\n    y <- as.numeric(\"${y}\")\n    a <- as.numeric(\"${a}\")\n\n    # create database\n    con <- dbConnect(SQLite(), \"${output_db}\")\n\n    # setup database\n    dbGetQuery(con, 'create table tbl1 (sampleID text, x text, y text, a text, baseplot blob, ggplot blob)')\n\n    # make R plot object with ggplot2\n    g <- ggplot(data = data.frame(x = rnorm(a, 1, x), y = rnorm(a, 1, y)), aes(x = x, y = y)) +\n        geom_point()\n\n    # base R plots cant be saved as object, but can be captured and reused later with R 3.3.0+\n    pdf(\"test.pdf\") # need open graphics device to record plot\n    dev.control(displaylist=\"enable\")\n    plot(data.frame(x = rnorm(50, 1, 6), y = rnorm(50, 1, 8)))\n    p <- serialize(recordPlot(), NULL)\n    dev.off()\n\n    # bundle the data in a dataframe\n    df <- data.frame(a = a,\n                    x = x,\n                    y = y,\n                    sampleID = sampleID,\n                    baseplot = I(list(serialize(p, NULL))),\n                    ggplot = I(list(serialize(g, NULL)))\n                    )\n\n    # insert data into the db\n    dbGetPreparedQuery(con, 'insert into tbl1 (sampleID, x, y, a, baseplot, ggplot) values (:sampleID, :a, :x, :y, :baseplot, :ggplot)',\n                   bind.data=df)\n    \"\"\"",
        "nb_lignes_script": 43,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_inputs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_dbs"
        ],
        "nb_outputs": 1,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${sampleID}\"",
            "publishDir \"${params.output_dir}/${sampleID}\", overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n    tag \"${fastq}\"\n    publishDir \"${params.output_dir}/fastqc\", mode: 'copy', overwrite: true\n    echo true\n\n    input:\n    file(fastq) from input_fastqs\n\n    output:\n    file(output_html)\n    file(output_zip)\n\n    script:\n    output_html = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_zip = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    \"\"\"\n    which fastqc\n    fastqc -o . \"${fastq}\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    output_html = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_zip = \"${fastq}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    \"\"\"\n    which fastqc\n    fastqc -o . \"${fastq}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "whichdb",
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/whichdb",
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "whichdb",
                "uri": "https://bio.tools/whichdb",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3077",
                            "term": "Data acquisition"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3077",
                            "term": "Data collection"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0957",
                                "term": "Database metadata"
                            }
                        ]
                    }
                ],
                "description": "Search all sequence databases for an entry and retrieve it.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/whichdb.html"
            },
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "input_fastqs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "output_html",
            "output_zip"
        ],
        "nb_outputs": 2,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "tag \"${fastq}\"",
            "publishDir \"${params.output_dir}/fastqc\", mode: 'copy', overwrite: true",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "gather_files1": {
        "name_process": "gather_files1",
        "string_process": "\nprocess gather_files1 {\n                                                                                     \n    publishDir \"${params.output_dir}\", mode: 'copy'\n\n    input:\n    file(\"*\") from sample_files.collect()\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"output1.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    output_file = \"output1.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gather_files2": {
        "name_process": "gather_files2",
        "string_process": "\nprocess gather_files2 {\n                                                                                 \n    publishDir \"${params.output_dir}\", mode: 'copy', overwrite: true\n\n    input:\n    file(\"*\") from sample_files3.collect()\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"output2.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    output_file = \"output2.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files3"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "gather_files3": {
        "name_process": "gather_files3",
        "string_process": "\nprocess gather_files3 {\n                                                                                        \n    publishDir \"${params.output_dir}\", mode: 'copy'\n\n    input:\n    file(\"*\") from sample_files2.collect()\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"output3.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    echo \"${workflow.sessionId} ${workflow.runName}\" >> \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    output_file = \"output3.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    echo \"${workflow.sessionId} ${workflow.runName}\" >> \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gather_files4": {
        "name_process": "gather_files4",
        "string_process": "\nprocess gather_files4 {\n                                                                                        \n    publishDir \"${params.output_dir}\", mode: 'copy', overwrite: true\n\n    input:\n    file(\"*\") from sample_files4.collect()\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"output4.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    echo \"${workflow.sessionId} ${workflow.runName}\" >> \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    output_file = \"output4.txt\"\n    \"\"\"\n    cat * > \"${output_file}\"\n    echo \"${workflow.sessionId} ${workflow.runName}\" >> \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_files4"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "publishDir \"${params.output_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "print_collected_file": {
        "name_process": "print_collected_file",
        "string_process": "\nprocess print_collected_file {\n    echo true\n\n    input:\n    file(txt) from collected_file\n\n    script:\n    \"\"\"\n    cat \"${txt}\" | sed -e 's|^|[print_collected_file (${txt})]: |'\n    \"\"\"\n}",
        "nb_lignes_process": 10,
        "string_script": "    \"\"\"\n    cat \"${txt}\" | sed -e 's|^|[print_collected_file (${txt})]: |'\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collected_file"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "stevekm__nextflow-demos",
        "directive": [
            "echo true"
        ],
        "when": "",
        "stub": ""
    }
}