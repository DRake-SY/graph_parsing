{
    "build_featmat": {
        "name_process": "build_featmat",
        "string_process": "\nprocess build_featmat {\n\n\n                                            \n  scratch false\n\n  tag { features }\n\n  input:\n  file features\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"featmat\"\n\n  script:\n\n  \"\"\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/build_feature_matrix.py --input_pairs_files $features --store_interval 10 --output_file featmat --sep ','\n\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "  \"\"\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/build_feature_matrix.py --input_pairs_files $features --store_interval 10 --output_file featmat --sep ','\n\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "features"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { features }"
        ],
        "when": "",
        "stub": ""
    },
    "label_featmat": {
        "name_process": "label_featmat",
        "string_process": "\nprocess label_featmat {\n\n                                            \n  scratch false\n\n  tag { featmat_labeling }\n\n  input:\n  path featmat\n  path positives\n  path negatives\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"featmat_labeled\"\n\n  script:\n\n  \"\"\"\n\n  head $positives\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/add_label_chunks.py --input_feature_matrix $featmat --input_positives $positives --input_negatives $negatives --sep , --ppi_sep ' ' --id_column ID --output_file featmat_labeled --fillna 0 --id_sep ' ' --chunksize 100000 \n  \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "  \"\"\"\n\n  head $positives\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/add_label_chunks.py --input_feature_matrix $featmat --input_positives $positives --input_negatives $negatives --sep , --ppi_sep ' ' --id_column ID --output_file featmat_labeled --fillna 0 --id_sep ' ' --chunksize 100000 \n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "featmat",
            "positives",
            "negatives"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { featmat_labeling }"
        ],
        "when": "",
        "stub": ""
    },
    "get_labeled_rows": {
        "name_process": "get_labeled_rows",
        "string_process": "\nprocess get_labeled_rows {\n\n                                            \n  scratch true\n\n  tag { get_labeled_rows }\n\n  input:\n  path featmat_labeled\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"featmat_labeled1\"\n\n  script:\n\n  \"\"\"\n  grep -v ',0.0\\$' $featmat_labeled > featmat_labeled1\n\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  \"\"\"\n  grep -v ',0.0\\$' $featmat_labeled > featmat_labeled1\n\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "featmat_labeled"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch true",
            "tag { get_labeled_rows }"
        ],
        "when": "",
        "stub": ""
    },
    "add_group_column": {
        "name_process": "add_group_column",
        "string_process": "\nprocess add_group_column {\n\n                                            \n  scratch false\n\n  tag { add_group_column }\n\n\n  input:\n  path featmat_labeled1\n  path traincomplexgroups\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"featmat_labeled1\"\n  path \"featmat_labeled1_nogroups\"\n\n  script:\n  \"\"\"\n  cp $featmat_labeled1 featmat_labeled1_nogroups \n\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/build_feature_matrix.py --prev_feature_matrix $featmat_labeled1 --input_pairs_files $traincomplexgroups --output_file featmat_labeled1 --sep ',' --jointype \"left\" --mod_featname False\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 26,
        "string_script": "  \"\"\"\n  cp $featmat_labeled1 featmat_labeled1_nogroups \n\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/build_feature_matrix.py --prev_feature_matrix $featmat_labeled1 --input_pairs_files $traincomplexgroups --output_file featmat_labeled1 --sep ',' --jointype \"left\" --mod_featname False\n\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "featmat_labeled1",
            "traincomplexgroups"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { add_group_column }"
        ],
        "when": "",
        "stub": ""
    },
    "cfmsinfer_eval": {
        "name_process": "cfmsinfer_eval",
        "string_process": "\nprocess cfmsinfer_eval {\n\n                                            \n  scratch true\n\n  tag { eval }\n\n  input:\n  path scored\n  path postrain\n  path negtrain\n  path postest\n  path negtest\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"precisionrecall\"\n  path \"precisionrecall.png\" optional true\n \n  script:\n\n  \"\"\"\n\n      python ${params.protein_complex_maps_dir}/protein_complex_maps/evaluation/plots/prcurve_cfmsflow.py --results_wprob $scored --input_positives $postrain $postest --input_negatives $negtrain $negtest --labels train test --output_file precisionrecall --id_cols 0 --prob_col 1 --ppi_sep ' ' --results_delim \"\\t\" --labels_delim ' ' --header  --plot $params.plot_pr\n   \n  \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "  \"\"\"\n\n      python ${params.protein_complex_maps_dir}/protein_complex_maps/evaluation/plots/prcurve_cfmsflow.py --results_wprob $scored --input_positives $postrain $postest --input_negatives $negtrain $negtest --labels train test --output_file precisionrecall --id_cols 0 --prob_col 1 --ppi_sep ' ' --results_delim \"\\t\" --labels_delim ' ' --header  --plot $params.plot_pr\n   \n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scored",
            "postrain",
            "negtrain",
            "postest",
            "negtest"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch true",
            "tag { eval }"
        ],
        "when": "",
        "stub": ""
    },
    "corr_process": {
        "name_process": "corr_process",
        "string_process": "\nprocess corr_process {\n\n                                      \n  scratch true\n\n  tag { elut_id }\n\n  input:\n  tuple file(elut_id),corr \n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  tuple file(\"${elut_id.baseName}.${corr}.feat\"),corr\n\n  script:\n  \"\"\"\n  if [ $params.added_poisson_reps ]\n  then\n  echo \"Poisson noise added\"\n  echo \"Poisson reps are appropriate for count data\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/ExtractFeatures/canned_scripts/extract_features.py --format csv --normalize row_max -f $corr -o ${elut_id.baseName}.${corr}.feat $elut_id -r poisson_noise -i $params.added_poisson_reps \n  else\n\n      python ${params.protein_complex_maps_dir}/protein_complex_maps/features/ExtractFeatures/canned_scripts/extract_features.py --format csv --normalize row_max -f $corr -o ${elut_id.baseName}.${corr}.feat $elut_id\n  fi\n\n  \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "  \"\"\"\n  if [ $params.added_poisson_reps ]\n  then\n  echo \"Poisson noise added\"\n  echo \"Poisson reps are appropriate for count data\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/ExtractFeatures/canned_scripts/extract_features.py --format csv --normalize row_max -f $corr -o ${elut_id.baseName}.${corr}.feat $elut_id -r poisson_noise -i $params.added_poisson_reps \n  else\n\n      python ${params.protein_complex_maps_dir}/protein_complex_maps/features/ExtractFeatures/canned_scripts/extract_features.py --format csv --normalize row_max -f $corr -o ${elut_id.baseName}.${corr}.feat $elut_id\n  fi\n\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "elut_id"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch true",
            "tag { elut_id }"
        ],
        "when": "",
        "stub": ""
    },
    "rescale_process": {
        "name_process": "rescale_process",
        "string_process": "\nprocess rescale_process {\n\n                                            \n  scratch true\n\n  tag { feat }\n\n  input:\n  tuple file(feat),corr \n    \n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"${feat}.*scaled\" \n\n\n  script:\n  if (corr == \"euclidean\" || corr == \"braycurtis\")\n\n  \"\"\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/normalize_features.py --input_feature_matrix $feat --output_filename ${feat}.rescaled --features $corr --min 0 --sep , --inverse\n\n  \"\"\"\n\n  else\n  \"\"\"\n  mv $feat ${feat}.unscaled\n  \"\"\"\n\n\n}",
        "nb_lignes_process": 30,
        "string_script": "  if (corr == \"euclidean\" || corr == \"braycurtis\")\n\n  \"\"\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/normalize_features.py --input_feature_matrix $feat --output_filename ${feat}.rescaled --features $corr --min 0 --sep , --inverse\n\n  \"\"\"\n\n  else\n  \"\"\"\n  mv $feat ${feat}.unscaled\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "AnCorr"
        ],
        "tools_url": [
            "https://bio.tools/ancorr"
        ],
        "tools_dico": [
            {
                "name": "AnCorr",
                "uri": "https://bio.tools/ancorr",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Webserver/tool for evaluation coordinate and ordinal correlations between genomic tracks and/or expression or protein binding profiles.",
                "homepage": "http://ancorr.eimb.ru"
            }
        ],
        "inputs": [
            "feat"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch true",
            "tag { feat }"
        ],
        "when": "",
        "stub": ""
    },
    "alph_process": {
        "name_process": "alph_process",
        "string_process": "\nprocess alph_process {\n\n                                            \n  scratch true\n\n  tag { feat }\n\n  input:\n  path feat\n  val sep \n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"${feat}.ordered\"  \n\n  script:\n  \"\"\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/alphabetize_pairs_chunks.py --feature_pairs $feat --outfile ${feat}.ordered --sep $sep --chunksize 1000000\n\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  \"\"\"\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/features/alphabetize_pairs_chunks.py --feature_pairs $feat --outfile ${feat}.ordered --sep $sep --chunksize 1000000\n\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "feat",
            "sep"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch true",
            "tag { feat }"
        ],
        "when": "",
        "stub": ""
    },
    "get_fdr_threshold": {
        "name_process": "get_fdr_threshold",
        "string_process": "\nprocess get_fdr_threshold {\n\n                                      \n  scratch false\n\n  tag { getFDRthreshold }\n\n  input:\n  path precisionrecall\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n\n\n  output:\n  stdout()\n  path \"scorethreshold.txt\"\n\n\n  script:\n  \"\"\"\n  # Get the score where FDR is at desired threshold\n  # TODO: Add assert to header here\n\n  # Get column number that contains the FDR\n  fdr_colnum=`head -1 $precisionrecall | tr ',' '\\n' | grep -n \"FDR\" | cut -d':' -f1`\n\n  # Get column number that contains the threshold\n  threshold_colnum=`head -1 $precisionrecall | tr ',' '\\n' | grep -n \"threshold\" | cut -d':' -f1`\n\n  score=`grep 'test' $precisionrecall | awk -F\",\" -v fdr_colnum=\\$fdr_colnum -v threshold_colnum=\\$threshold_colnum '\\$fdr_colnum>=$params.fdr_cutoff {print \\$threshold_colnum}' | tail -1`\n  echo \\$score > scorethreshold.txt \n  printf \\$score\n  \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "  \"\"\"\n  # Get the score where FDR is at desired threshold\n  # TODO: Add assert to header here\n\n  # Get column number that contains the FDR\n  fdr_colnum=`head -1 $precisionrecall | tr ',' '\\n' | grep -n \"FDR\" | cut -d':' -f1`\n\n  # Get column number that contains the threshold\n  threshold_colnum=`head -1 $precisionrecall | tr ',' '\\n' | grep -n \"threshold\" | cut -d':' -f1`\n\n  score=`grep 'test' $precisionrecall | awk -F\",\" -v fdr_colnum=\\$fdr_colnum -v threshold_colnum=\\$threshold_colnum '\\$fdr_colnum>=$params.fdr_cutoff {print \\$threshold_colnum}' | tail -1`\n  echo \\$score > scorethreshold.txt \n  printf \\$score\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "precisionrecall"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { getFDRthreshold }"
        ],
        "when": "",
        "stub": ""
    },
    "cluster": {
        "name_process": "cluster",
        "string_process": "\nprocess cluster {\n\n                                      \n  scratch true\n\n  tag { cluster }\n\n  input:\n\n  path scored\n  val scorethreshold\n  path annotation_file\n  path elution_file\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"clustering.csv\"\n\n\n  script:\n  \"\"\"\n  \n  #Useful if rpy2 is not finding libraries\n  export LD_LIBRARY_PATH=\"\\$(python -m rpy2.situation LD_LIBRARY_PATH)\"\n\n\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/postprocessing_util/diffusion_clustering.py --input_edges $scored --threshold $scorethreshold --method walktrap --use_scores --outfile clustering --header --id_cols ID --id_sep ' ' --weight_col P_1  --steps $params.walktrap_steps --input_elution $elution_file --annotation_file $annotation_file \n\n  \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "  \"\"\"\n  \n  #Useful if rpy2 is not finding libraries\n  export LD_LIBRARY_PATH=\"\\$(python -m rpy2.situation LD_LIBRARY_PATH)\"\n\n\n  python ${params.protein_complex_maps_dir}/protein_complex_maps/postprocessing_util/diffusion_clustering.py --input_edges $scored --threshold $scorethreshold --method walktrap --use_scores --outfile clustering --header --id_cols ID --id_sep ' ' --weight_col P_1  --steps $params.walktrap_steps --input_elution $elution_file --annotation_file $annotation_file \n\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scored",
            "scorethreshold",
            "annotation_file",
            "publishDir",
            "elution_file"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch true",
            "tag { cluster }"
        ],
        "when": "",
        "stub": ""
    },
    "cfmsinfer_scan": {
        "name_process": "cfmsinfer_scan",
        "string_process": "\nprocess cfmsinfer_scan {\n\n                                            \n  scratch false\n\n  tag { scan_parameters }\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  input:\n  path featmat_labeled1\n  path selectors_to_scan\n  path classifiers_to_scan\n\n  output:\n  path \"pipeline.py\"\n  \n\n\n  script:\n\n  \"\"\"\n  SELECTORS_FORMATTED=\\$(cat $selectors_to_scan | tr '\\n' ' ')\n  CLASSIFIERS_FORMATTED=\\$(cat $classifiers_to_scan | tr '\\n' ' ')\n  \n  echo \\$SELECTORS_FORMATTED\n  echo \\$CLASSIFIERS_FORMATTED\n  echo $params.tpot_template\n\n  python $params.tpot_dir/train_TPOT.py --training_data featmat_labeled1 --outfile pipeline.py --template $params.tpot_template --selector_subset \\$SELECTORS_FORMATTED --classifier_subset \\$CLASSIFIERS_FORMATTED --id_cols 0 --n_jobs $params.n_jobs --generations $params.generations --population_size $params.population --labels -1 1 --temp_dir auto --groupcol traincomplexgroups --max_features_to_select $params.max_features_to_select\n\n  \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "  \"\"\"\n  SELECTORS_FORMATTED=\\$(cat $selectors_to_scan | tr '\\n' ' ')\n  CLASSIFIERS_FORMATTED=\\$(cat $classifiers_to_scan | tr '\\n' ' ')\n  \n  echo \\$SELECTORS_FORMATTED\n  echo \\$CLASSIFIERS_FORMATTED\n  echo $params.tpot_template\n\n  python $params.tpot_dir/train_TPOT.py --training_data featmat_labeled1 --outfile pipeline.py --template $params.tpot_template --selector_subset \\$SELECTORS_FORMATTED --classifier_subset \\$CLASSIFIERS_FORMATTED --id_cols 0 --n_jobs $params.n_jobs --generations $params.generations --population_size $params.population --labels -1 1 --temp_dir auto --groupcol traincomplexgroups --max_features_to_select $params.max_features_to_select\n\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "featmat_labeled1",
            "selectors_to_scan",
            "classifiers_to_scan"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { scan_parameters }",
            "publishDir \"${params.output_dir}\", mode: 'link'"
        ],
        "when": "",
        "stub": ""
    },
    "cfmsinfer_train": {
        "name_process": "cfmsinfer_train",
        "string_process": "\nprocess cfmsinfer_train {\n                                  \n\n                                            \n  scratch false\n\n  tag { train_model }\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  input:\n  path pipeline\n  path featmat_labeled1\n\n  output:\n  path \"tpot_fitted_model.p\"\n  path \"tpot_fitted_model.p.txt\"\n  path \"tpot_fitted_model.p.featureimportances\"\n\n  script:\n  \"\"\"\n  python $params.tpot_dir/train_test_model2.py --training_infile $featmat_labeled1 --exported_pipeline $pipeline --id_cols 0 --output_basename tpot --groupcol traincomplexgroups\n\n  \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "  \"\"\"\n  python $params.tpot_dir/train_test_model2.py --training_infile $featmat_labeled1 --exported_pipeline $pipeline --id_cols 0 --output_basename tpot --groupcol traincomplexgroups\n\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pipeline",
            "featmat_labeled1"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { train_model }",
            "publishDir \"${params.output_dir}\", mode: 'link'"
        ],
        "when": "",
        "stub": ""
    },
    "cfmsinfer_score": {
        "name_process": "cfmsinfer_score",
        "string_process": "\nprocess cfmsinfer_score {\n\n                                            \n  scratch false\n\n  tag { apply_model }\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n  input:\n  path model\n  path featmat\n\n  output:\n  path \"scored_interactions\"\n  \n                               \n  script:\n\n  \"\"\"\n  touch tpot_fitted_model.p.txt\n  touch tpot_fitted_model.p.featureimportances\n\n  python $params.tpot_dir/tpot_predict.py --datafile $featmat --serialized_model $model --outfile scored_interactions --id_cols 0\n\n  \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "  \"\"\"\n  touch tpot_fitted_model.p.txt\n  touch tpot_fitted_model.p.featureimportances\n\n  python $params.tpot_dir/tpot_predict.py --datafile $featmat --serialized_model $model --outfile scored_interactions --id_cols 0\n\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "model",
            "featmat"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { apply_model }",
            "publishDir \"${params.output_dir}\", mode: 'link'"
        ],
        "when": "",
        "stub": ""
    },
    "split_traintest": {
        "name_process": "split_traintest",
        "string_process": "\nprocess split_traintest {\n\n                                      \n  scratch false\n\n  input:\n  file goldstandard_complexes\n\n  tag { goldstandard }\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"goldstandard_filt.train_ppis.ordered\", emit: 'postrain'\n  path \"goldstandard_filt.test_ppis.ordered\", emit: 'postest'\n  path \"goldstandard_filt.neg_train_ppis.ordered\", emit: 'negtrain'\n  path \"goldstandard_filt.neg_test_ppis.ordered\", emit: 'negtest'\n  path \"goldstandard_filt.all_train.txt\", emit: 'postraincomplexes'\n  path \"goldstandard_filt.all_test.txt\", emit: 'postestcomplexes'\n \n\n  script:\n  \"\"\"\n   # Filter and organize subcomplexes\n     python $params.protein_complex_maps_dir/protein_complex_maps/preprocessing_util/complexes/complex_merge.py --cluster_filename $goldstandard_complexes --output_filename goldstandard_filt.txt --merge_threshold $params.merge_threshold --complex_size_threshold $params.complex_size_threshold  --remove_largest --remove_large_subcomplexes\n\n   # Split complexes to training and test complexes \n   python $params.protein_complex_maps_dir/protein_complex_maps/preprocessing_util/complexes/split_complexes2.py --input_complexes goldstandard_filt.txt\n\n\n   # Figure out where commas are coming from\n   sep=\" \" \n   for gs in goldstandard_filt.*_ppis.txt;\n   do\n     sed -i 's/\\t/ /' \\$gs\n     python $params.protein_complex_maps_dir/protein_complex_maps/features/alphabetize_pairs_chunks.py --feature_pairs \\$gs --outfile \\${gs%.txt}.ordered --sep \"\\$sep\" --chunksize 1000\n   done\n\n  \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "  \"\"\"\n   # Filter and organize subcomplexes\n     python $params.protein_complex_maps_dir/protein_complex_maps/preprocessing_util/complexes/complex_merge.py --cluster_filename $goldstandard_complexes --output_filename goldstandard_filt.txt --merge_threshold $params.merge_threshold --complex_size_threshold $params.complex_size_threshold  --remove_largest --remove_large_subcomplexes\n\n   # Split complexes to training and test complexes \n   python $params.protein_complex_maps_dir/protein_complex_maps/preprocessing_util/complexes/split_complexes2.py --input_complexes goldstandard_filt.txt\n\n\n   # Figure out where commas are coming from\n   sep=\" \" \n   for gs in goldstandard_filt.*_ppis.txt;\n   do\n     sed -i 's/\\t/ /' \\$gs\n     python $params.protein_complex_maps_dir/protein_complex_maps/features/alphabetize_pairs_chunks.py --feature_pairs \\$gs --outfile \\${gs%.txt}.ordered --sep \"\\$sep\" --chunksize 1000\n   done\n\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "goldstandard_complexes"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false"
        ],
        "when": "",
        "stub": ""
    },
    "get_negatives_from_observed": {
        "name_process": "get_negatives_from_observed",
        "string_process": "\nprocess get_negatives_from_observed {\n\n                                      \n  scratch true\n\n  tag { negative_from_observed }\n\n  input:\n  path featmat\n  path postrain\n  path postest\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n  path \"negtrain.randsort\", emit: 'negtrain'\n  path \"negtest.randsort\", emit: 'negtest'\n\n\n\n  script:\n  \"\"\"\n  # \"all ID pairs from the feature matrix (remove header with tail)\"\n  awk -F',' '{print \\$1}' $featmat |  tail -n +2 > identifiers_infeatmat\n\n  # \"Remove any interactions that are in the positive set\"\n  cat identifiers_infeatmat | grep -vFf $postrain | grep -vFf $postest > neg_pool\n\n  sort -R neg_pool > neg_pool.randsort                            \n\n  split --number=l/2 neg_pool.randsort \n  mv xaa negtrain.randsort \n  mv xab negtest.randsort\n  \n\n  \"\"\"\n\n}",
        "nb_lignes_process": 37,
        "string_script": "  \"\"\"\n  # \"all ID pairs from the feature matrix (remove header with tail)\"\n  awk -F',' '{print \\$1}' $featmat |  tail -n +2 > identifiers_infeatmat\n\n  # \"Remove any interactions that are in the positive set\"\n  cat identifiers_infeatmat | grep -vFf $postrain | grep -vFf $postest > neg_pool\n\n  sort -R neg_pool > neg_pool.randsort                            \n\n  split --number=l/2 neg_pool.randsort \n  mv xaa negtrain.randsort \n  mv xab negtest.randsort\n  \n\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "featmat",
            "postrain",
            "postest"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch true",
            "tag { negative_from_observed }"
        ],
        "when": "",
        "stub": ""
    },
    "limit_negatives": {
        "name_process": "limit_negatives",
        "string_process": "\nprocess limit_negatives {\n\n                                            \n  scratch false\n\n  tag { limit_negatives }\n\n  input:\n  path negtrain\n  path negtest\n   \n  publishDir \"${params.output_dir}\", mode: 'link'\n\n\n  output:\n  path \"negtrain\", emit: 'negtrain'\n  path \"negtest\", emit: 'negtest'\n\n  script:\n  \"\"\"\n  head *    \n\n  sort -R $negtrain | head -$params.negative_limit > negtrain\n  sort -R $negtest | head -$params.negative_limit > negtest\n\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "  \"\"\"\n  head *    \n\n  sort -R $negtrain | head -$params.negative_limit > negtrain\n  sort -R $negtest | head -$params.negative_limit > negtest\n\n\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "negtrain",
            "negtest"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [
            "scratch false",
            "tag { limit_negatives }"
        ],
        "when": "",
        "stub": ""
    },
    "get_cv_groups": {
        "name_process": "get_cv_groups",
        "string_process": "\nprocess get_cv_groups {\n\n  input:\n  path postrain\n  path postraincomplexes\n  path negtrain\n\n  publishDir \"${params.output_dir}\", mode: 'link'\n\n  output:\n    path \"traincomplexgroups\"\n\n  script:\n  \"\"\"\n  echo \"ID1,ID2,Group\" > traincomplexgroups\n \n  #Assign all positive ppi to a complex \n  #This allows GroupKFold cross validation to\n  #  avoid having complex members in different cv sets\n  #If ppi in multiple training complexes, given first complex id\n  while read ppi;\n  do\n  \n    p1=`echo \\$ppi | cut -d' ' -f1`\n    p2=`echo \\$ppi | cut -d' ' -f2`\n  \n    linenum=`grep -n \\$p1 $postraincomplexes | grep \\$p2 | cut -d\":\" -f1 | head -1`\n    echo \"\\$p1,\\$p2,\\$linenum\"  >> traincomplexgroups\n  \n  done < $postrain\n  \n  numcomplexes=`wc -l < $postraincomplexes`\n\n  #Assign all negative ppi a group number \n  #   not overlapping train complex numbers\n  echo \"test\"\n  awk -v n=\\$numcomplexes 'BEGIN { OFS = \",\" }{print \\$1,\\$2,NR+n}' $negtrain >> traincomplexgroups   \n  echo \"trash\"\n  \"\"\"\n \n\n \n}",
        "nb_lignes_process": 42,
        "string_script": "  \"\"\"\n  echo \"ID1,ID2,Group\" > traincomplexgroups\n \n  #Assign all positive ppi to a complex \n  #This allows GroupKFold cross validation to\n  #  avoid having complex members in different cv sets\n  #If ppi in multiple training complexes, given first complex id\n  while read ppi;\n  do\n  \n    p1=`echo \\$ppi | cut -d' ' -f1`\n    p2=`echo \\$ppi | cut -d' ' -f2`\n  \n    linenum=`grep -n \\$p1 $postraincomplexes | grep \\$p2 | cut -d\":\" -f1 | head -1`\n    echo \"\\$p1,\\$p2,\\$linenum\"  >> traincomplexgroups\n  \n  done < $postrain\n  \n  numcomplexes=`wc -l < $postraincomplexes`\n\n  #Assign all negative ppi a group number \n  #   not overlapping train complex numbers\n  echo \"test\"\n  awk -v n=\\$numcomplexes 'BEGIN { OFS = \",\" }{print \\$1,\\$2,NR+n}' $negtrain >> traincomplexgroups   \n  echo \"trash\"\n  \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "postrain",
            "postraincomplexes",
            "negtrain"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "marcottelab__cfmsflow",
        "directive": [],
        "when": "",
        "stub": ""
    }
}