{
    "Trimming": {
        "name_process": "Trimming",
        "string_process": "\nprocess Trimming {\n    container \"docker.io/paulrkcruz/hrv-pipeline:latest\"\n    errorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        file R1                     \n        file ADAPTERS_SE\n        val MINLEN\n        val SETTING\n        val LEADING\n        val TRAILING\n        val SWINDOW\n\n    output:\n        tuple env(base),file(\"*.trimmed.fastq.gz\"), file(\"${R1}_num_trimmed.txt\"),file(\"*summary.csv\")                                    \n\n    publishDir \"${params.outdir}trimmed_fastqs\", mode: 'copy',pattern:'*.trimmed.fastq*'\n\n\n    script:\n    \"\"\"\n    #!/bin/bash\n    base=`basename ${R1} \".fastq.gz\"`\n    echo \\$base\n    /usr/local/miniconda/bin/trimmomatic SE -threads ${task.cpus} ${R1} \\$base.trimmed.fastq.gz \\\n    ILLUMINACLIP:${ADAPTERS_SE}:${SETTING} LEADING:${LEADING} TRAILING:${TRAILING} SLIDINGWINDOW:${SWINDOW} MINLEN:${MINLEN}\n    num_untrimmed=\\$((\\$(gunzip -c ${R1} | wc -l)/4))\n    num_trimmed=\\$((\\$(gunzip -c \\$base'.trimmed.fastq.gz' | wc -l)/4))\n    printf \"\\$num_trimmed\" >> ${R1}_num_trimmed.txt\n    percent_trimmed=\\$((100-\\$((100*num_trimmed/num_untrimmed))))\n    echo Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Release_date, Bioproject> \\$base'_summary.csv'\n    printf \"\\$base,\\$num_untrimmed,\\$num_trimmed,\\$percent_trimmed\" >> \\$base'_summary.csv'\n    ls -latr\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    base=`basename ${R1} \".fastq.gz\"`\n    echo \\$base\n    /usr/local/miniconda/bin/trimmomatic SE -threads ${task.cpus} ${R1} \\$base.trimmed.fastq.gz \\\n    ILLUMINACLIP:${ADAPTERS_SE}:${SETTING} LEADING:${LEADING} TRAILING:${TRAILING} SLIDINGWINDOW:${SWINDOW} MINLEN:${MINLEN}\n    num_untrimmed=\\$((\\$(gunzip -c ${R1} | wc -l)/4))\n    num_trimmed=\\$((\\$(gunzip -c \\$base'.trimmed.fastq.gz' | wc -l)/4))\n    printf \"\\$num_trimmed\" >> ${R1}_num_trimmed.txt\n    percent_trimmed=\\$((100-\\$((100*num_trimmed/num_untrimmed))))\n    echo Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Release_date, Bioproject> \\$base'_summary.csv'\n    printf \"\\$base,\\$num_untrimmed,\\$num_trimmed,\\$percent_trimmed\" >> \\$base'_summary.csv'\n    ls -latr\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "Trimmomatic"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            }
        ],
        "inputs": [
            "R1",
            "ADAPTERS_SE",
            "MINLEN",
            "SETTING",
            "LEADING",
            "TRAILING",
            "SWINDOW"
        ],
        "nb_inputs": 7,
        "outputs": [
            "base"
        ],
        "nb_outputs": 1,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [
            "container \"docker.io/paulrkcruz/hrv-pipeline:latest\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "Aligning": {
        "name_process": "Aligning",
        "string_process": "\nprocess Aligning {\n                                                            \n                            \n                   \n                \n\n    input: \n        tuple val(base), file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_summary.csv\")                   \n        file Reference_rv\n        file Reference_hcov\n        file Reference_hpv\n        file Reference_hpv_14        \n        file Reference_inflb\n        file Reference_hpiv3\n\n    output:\n        tuple val(base), file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"), file(\"${base}_summary2.csv\"), file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),env(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),env(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\")                     \n        tuple val(base), file(\"${base}_map1_histogram.txt\"),file(\"${base}_map2_histogram.txt\")                          \n        tuple val (base), file(\"*\")                    \n\n    publishDir \"${params.outdir}all_ref\", mode: 'copy', pattern:'*all_ref.sam*'\n    publishDir \"${params.outdir}all_ref\", mode: 'copy', pattern:'*all_ref*'    \n    publishDir \"${params.outdir}sam_map2\", mode: 'copy', pattern:'*_map2.sam*'\n    publishDir \"${params.outdir}txt_bbmap_map1_stats\", mode: 'copy', pattern:'*_map1_bbmap_out.txt*'  \n    publishDir \"${params.outdir}txt_bbmap_map1_hist\", mode: 'copy', pattern:'*_map2_histogram.txt*' \n    publishDir \"${params.outdir}txt_bbmap_map2_stats\", mode: 'copy', pattern:'*_map2_bbmap_out.txt*'  \n    publishDir \"${params.outdir}txt_bbmap_map2_hist\", mode: 'copy', pattern:'*_map2_histogram.txt*'\n    publishDir \"${params.outdir}txt_indxstats_mapped_refs\", mode: 'copy', pattern:'*_idxstats.txt*'   \n    publishDir \"${params.outdir}ref_id\", mode: 'copy', pattern:'*_most_mapped_ref.txt*'  \n    publishDir \"${params.outdir}ref_fasta\", mode: 'copy', pattern:'*_mapped_ref_genome.fa*'\n    publishDir \"${params.outdir}ref_size\", mode: 'copy', pattern:'*_most_mapped_ref_size.txt*'\n    publishDir \"${params.outdir}ref_fai_index\", mode: 'copy', pattern:'*_mapped_ref_genome.fa.fai*'\n    publishDir \"${params.outdir}ref_ids\", mode: 'copy', pattern:'*_all_ref_id.txt*'    \n    publishDir \"${params.outdir}ref_ids\", mode: 'copy', pattern:'*_ids.txt*'\n\n    script:\n\n    \"\"\"\n    #!/bin/bash\n\n    cat ${Reference_hpv} ${Reference_rv} ${Reference_inflb} ${Reference_hcov} ${Reference_hpiv3} > ${base}_all_ref.fa\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_all_ref.sam ref=${base}_all_ref.fa threads=${task.cpus} covstats=${base}_all_ref_bbmap_out.txt covhist=${base}_all_ref_histogram.txt local=true interleaved=false -Xmx10g > ${base}_all_ref_stats.txt 2>&1\n\n    samtools view -S -b ${base}_all_ref.sam > ${base}_all_ref.bam\n    samtools sort -@ 4 ${base}_all_ref.bam > ${base}_all_ref.sorted.bam\n    samtools index ${base}_all_ref.sorted.bam\n    samtools idxstats ${base}_all_ref.sorted.bam > ${base}_all_ref_idxstats.txt\n    \n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_all_ref_bbmap_out.txt > ${base}_all_ref_id.txt\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    grep -B 0 \">\" ${Reference_rv} | tr -d \">\" > ${base}_rv_ids.txt\n    grep -B 0 \">\" ${Reference_hpv} | tr -d \">\" > ${base}_hpv_ids.txt\n    grep -B 0 \">\" ${Reference_inflb} | tr -d \">\" > ${base}_inbflb_ids.txt\n    grep -B 0 \">\" ${Reference_hcov} | tr -d \">\" > ${base}_hcov_ids.txt\n    grep -B 0 \">\" ${Reference_hpiv3} | tr -d \">\" > ${base}_hpiv3.txt\n\n\n    # Rhinovirus`s\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\";\n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_rv} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_rv} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. hrv_ref_hpv.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_hpv} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_hpv} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_inflb} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_inflb} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_hcov} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_hcov} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_hpiv3} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_hpiv3} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n    else\n\n    # Not Rhinovirus, HPV, Inlfuenza B, OR Human Coronavirus - Use Regular Mapping Settings\n    \n    # MAP 1    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${base}_all_ref.fa threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${base}_all_ref.fa \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n    fi\n\n    \"\"\"\n}",
        "nb_lignes_process": 257,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    cat ${Reference_hpv} ${Reference_rv} ${Reference_inflb} ${Reference_hcov} ${Reference_hpiv3} > ${base}_all_ref.fa\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_all_ref.sam ref=${base}_all_ref.fa threads=${task.cpus} covstats=${base}_all_ref_bbmap_out.txt covhist=${base}_all_ref_histogram.txt local=true interleaved=false -Xmx10g > ${base}_all_ref_stats.txt 2>&1\n\n    samtools view -S -b ${base}_all_ref.sam > ${base}_all_ref.bam\n    samtools sort -@ 4 ${base}_all_ref.bam > ${base}_all_ref.sorted.bam\n    samtools index ${base}_all_ref.sorted.bam\n    samtools idxstats ${base}_all_ref.sorted.bam > ${base}_all_ref_idxstats.txt\n    \n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_all_ref_bbmap_out.txt > ${base}_all_ref_id.txt\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    grep -B 0 \">\" ${Reference_rv} | tr -d \">\" > ${base}_rv_ids.txt\n    grep -B 0 \">\" ${Reference_hpv} | tr -d \">\" > ${base}_hpv_ids.txt\n    grep -B 0 \">\" ${Reference_inflb} | tr -d \">\" > ${base}_inbflb_ids.txt\n    grep -B 0 \">\" ${Reference_hcov} | tr -d \">\" > ${base}_hcov_ids.txt\n    grep -B 0 \">\" ${Reference_hpiv3} | tr -d \">\" > ${base}_hpiv3.txt\n\n\n    # Rhinovirus`s\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\";\n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_rv} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_rv} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. hrv_ref_hpv.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_hpv} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_hpv} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_inflb} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_inflb} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_hcov} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_hcov} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for mapping.\"\n\n    # MAP 1\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${Reference_hpiv3} threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${Reference_hpiv3} \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=9 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n    else\n\n    # Not Rhinovirus, HPV, Inlfuenza B, OR Human Coronavirus - Use Regular Mapping Settings\n    \n    # MAP 1    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map1.sam ref=${base}_all_ref.fa threads=${task.cpus} covstats=${base}_map1_bbmap_out.txt covhist=${base}_map1_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map1_stats.txt 2>&1\n    samtools view -S -b ${base}_map1.sam > ${base}_map1.bam\n    samtools sort -@ 4 ${base}_map1.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools idxstats ${base}.sorted.bam > ${base}_idxstats.txt\n    awk 'NR == 2 || \\$5 > max {number = \\$1; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref.txt\n    id=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref.txt)\n    ref_coverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_most_mapped_ref.txt)\n    samtools faidx ${base}_all_ref.fa \\$id > ${base}_mapped_ref_genome.fa\n    # MAP 2    \n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map2.sam ref=${base}_mapped_ref_genome.fa threads=${task.cpus} covstats=${base}_map2_bbmap_out.txt covhist=${base}_map2_histogram.txt local=true interleaved=false maxindel=20 strictmaxindel -Xmx6g > ${base}_map2_stats.txt 2>&1\n    head -n 1 ${base}_mapped_ref_genome.fa > ${base}_mapped_ref_genome_edited.fa\n    grep -v \">\" ${base}_mapped_ref_genome.fa | sed 's/U/T/g' >> ${base}_mapped_ref_genome_edited.fa\n    mv ${base}_mapped_ref_genome_edited.fa ${base}_mapped_ref_genome.fa\n    samtools faidx ${base}_mapped_ref_genome.fa\n    awk 'NR == 2 || \\$5 > max {number = \\$3; max = \\$5} END {if (NR) print number, max}' < ${base}_map1_bbmap_out.txt > ${base}_most_mapped_ref_size_out.txt\n    id_ref_size=\\$(awk 'FNR==1{print val,\\$1}' ${base}_most_mapped_ref_size_out.txt)\n    echo \\$id_ref_size >> ${base}_most_mapped_ref_size.txt\n    reads_mapped=\\$(cat ${base}_map2_stats.txt | grep \"mapped:\" | cut -d\\$'\\\\t' -f3)\n    printf \"\\$reads_mapped\" >> ${base}_num_mapped.txt\n    cp ${base}_summary.csv ${base}_summary2.csv\n    printf \",\\$id\" >> ${base}_summary2.csv\n    printf \",\\$id_ref_size\" >> ${base}_summary2.csv\n    printf \",\\$reads_mapped\" >> ${base}_summary2.csv\n    printf \",\\$ref_coverage\" >> ${base}_summary2.csv\n\n    fi\n\n    \"\"\"",
        "nb_lignes_script": 219,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "tmax"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/tmax"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "tmax",
                "uri": "https://bio.tools/tmax",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0283",
                                    "term": "Linkage analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A program for performing association analysis on a set of linked loci within a targeted region.",
                "homepage": "http://wpicr.wpic.pitt.edu/WPICCompGen/tmax.html"
            }
        ],
        "inputs": [
            "base",
            "Reference_rv",
            "Reference_hcov",
            "Reference_hpv",
            "Reference_hpv_14",
            "Reference_inflb",
            "Reference_hpiv3"
        ],
        "nb_inputs": 7,
        "outputs": [
            "base",
            "base",
            "base"
        ],
        "nb_outputs": 3,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Bam_Sorting": {
        "name_process": "Bam_Sorting",
        "string_process": "\nprocess Bam_Sorting {\n                                                           \n                                    \n\terrorStrategy 'ignore'\n                   \n\n    input: \n    tuple val(base), file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"), file(\"${base}_summary2.csv\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\")                     \n    output:\n    tuple val(base), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),env(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"), file(\"${base}_summary.csv\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\")                    \n\n    publishDir \"${params.outdir}bam_map2\", mode: 'copy', pattern:'*.sorted.bam*'  \n    publishDir \"${params.outdir}txt_bam_flagstats-map2\", mode: 'copy', pattern:'*_flagstats.txt*'  \n\n    script:\n    \"\"\"\n    #!/bin/bash\n    samtools view -S -b ${base}_map2.sam > ${base}.bam\n    samtools sort -@ ${task.cpus} ${base}.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools flagstat ${base}.sorted.bam > ${base}_flagstats.txt\n    bedtools genomecov -d -ibam ${base}.sorted.bam > ${base}_coverage.txt\n    \n    awk 'NR == 3 || \\$3 > max {number = \\$3; max = \\$1} END {if (NR) print number, max}' < ${base}_coverage.txt > ${base}_min_coverage.txt\n    awk 'NR == 2 || \\$3 > min {number = \\$1; min = \\$3} END {if (NR) print number, min}' < ${base}_coverage.txt > ${base}_max_coverage.txt\n    \n    meancoverage=\\$(cat ${base}_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n    mincoverage=\\$(awk 'FNR==1{print val,\\$1}' ${base}_min_coverage.txt)\n    maxcoverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_max_coverage.txt)\n    bamsize=\\$((\\$(wc -c ${base}.sorted.bam | awk '{print \\$1'})+0))\n    cp ${base}_summary2.csv ${base}_summary3.csv\n    printf \",\\$mincoverage\" >> ${base}_summary3.csv\n    printf \",\\$meancoverage\" >> ${base}_summary3.csv\n    printf \",\\$maxcoverage\" >> ${base}_summary3.csv\n    printf \",\\$bamsize\" >> ${base}_summary3.csv\n    cp ${base}_summary3.csv ${base}_summary.csv\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    samtools view -S -b ${base}_map2.sam > ${base}.bam\n    samtools sort -@ ${task.cpus} ${base}.bam > ${base}.sorted.bam\n    samtools index ${base}.sorted.bam\n    samtools flagstat ${base}.sorted.bam > ${base}_flagstats.txt\n    bedtools genomecov -d -ibam ${base}.sorted.bam > ${base}_coverage.txt\n    \n    awk 'NR == 3 || \\$3 > max {number = \\$3; max = \\$1} END {if (NR) print number, max}' < ${base}_coverage.txt > ${base}_min_coverage.txt\n    awk 'NR == 2 || \\$3 > min {number = \\$1; min = \\$3} END {if (NR) print number, min}' < ${base}_coverage.txt > ${base}_max_coverage.txt\n    \n    meancoverage=\\$(cat ${base}_coverage.txt | awk '{sum+=\\$3} END { print sum/NR}')\n    mincoverage=\\$(awk 'FNR==1{print val,\\$1}' ${base}_min_coverage.txt)\n    maxcoverage=\\$(awk 'FNR==1{print val,\\$2}' ${base}_max_coverage.txt)\n    bamsize=\\$((\\$(wc -c ${base}.sorted.bam | awk '{print \\$1'})+0))\n    cp ${base}_summary2.csv ${base}_summary3.csv\n    printf \",\\$mincoverage\" >> ${base}_summary3.csv\n    printf \",\\$meancoverage\" >> ${base}_summary3.csv\n    printf \",\\$maxcoverage\" >> ${base}_summary3.csv\n    printf \",\\$bamsize\" >> ${base}_summary3.csv\n    cp ${base}_summary3.csv ${base}_summary.csv\n    \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools",
            "tmax",
            "MIND"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools",
            "https://bio.tools/tmax",
            "https://bio.tools/MIND"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "tmax",
                "uri": "https://bio.tools/tmax",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0283",
                                    "term": "Linkage analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A program for performing association analysis on a set of linked loci within a targeted region.",
                "homepage": "http://wpicr.wpic.pitt.edu/WPICCompGen/tmax.html"
            },
            {
                "name": "MIND",
                "uri": "https://bio.tools/MIND",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3232",
                                    "term": "Gene expression QTL analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3629",
                                    "term": "Deisotoping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3232",
                                    "term": "Gene expression QTL profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3232",
                                    "term": "eQTL profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3232",
                                    "term": "Gene expression quantitative trait loci profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3629",
                                    "term": "Deconvolution"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Using multiple measurements of tissue to estimate subject- and cell-type-specific gene expression | Using Multiple Measurements of Tissue to Estimate Subject- And Cell-Type-Specific Gene Expression via Deconvolution | MIND (Multi-measure INdividual Deconvolution) | MIND is a method to glean insights from bulk gene expression. It borrows information across multiple measurements of the same tissue per subject, such as multiple regions of the brain, using an empirical Bayes approach to estimate subject- and cell-type-specific gene expression via deconvolution",
                "homepage": "https://github.com/randel/MIND"
            }
        ],
        "inputs": [
            "base",
            "id_ref_size",
            "id"
        ],
        "nb_inputs": 3,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [
            "errorStrategy 'ignore'"
        ],
        "when": "",
        "stub": ""
    },
    "Consensus_Generation": {
        "name_process": "Consensus_Generation",
        "string_process": "\nprocess Consensus_Generation {\n                                                                \n                            \n\t                         \n                   \n                \n\n    input:\n    tuple val(base), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"), file(\"${base}_summary.csv\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\")                    \n    \n    output:\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"), file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_final_summary.csv\"),file(\"${base}.consensus_final.fa\")                          \n\n    publishDir \"${params.outdir}consensus-final\", mode: 'copy', pattern:'*.consensus_final.fa*' \n    publishDir \"${params.outdir}consensus_mpileup\", mode: 'copy', pattern:'*.mpileup*' \n    \n    script:\n    \"\"\"\n    #!/bin/bash\n\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. hrv_ref_hpv.fa will be used for mapping.\"\n\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n    else\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n    fi\n\n    \"\"\"\n}",
        "nb_lignes_process": 279,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. hrv_ref_hpv.fa will be used for mapping.\"\n\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for mapping.\"\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n    else\n\n    samtools mpileup \\\\\n        --count-orphans \\\\\n        --no-BAQ \\\\\n        --max-depth 50000 \\\\\n        --fasta-ref ${base}_mapped_ref_genome.fa \\\\\n        --min-BQ 15 \\\\\n        --output ${base}.mpileup \\\\\n        ${base}.sorted.bam\n    cat ${base}.mpileup | ivar consensus -q 15 -t 0.6 -m 3 -n N -p ${base}.consensus_final\n    bedtools genomecov \\\\\n        -bga \\\\\n        -ibam ${base}.sorted.bam \\\\\n        -g ${base}_mapped_ref_genome.fa \\\\\n        | awk '\\$4 < 10' | bedtools merge > ${base}.mask.bed\n    \n    bedtools maskfasta \\\\\n        -fi ${base}.consensus_final.fa \\\\\n        -bed ${base}.mask.bed \\\\\n        -fo ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.masked.consensus/' ${base}.consensus.masked.fa\n    sed -i 's/>.*/>${base}.ivar.consensus/' ${base}.consensus_final.fa\n\n    awk '/^>/{if (l!=\"\") print l; print; l=0; next}{l+=length(\\$0)}END{print l}' ${base}.consensus_final.fa > bases.txt\n    num_bases=\\$(awk 'FNR==2{print val,\\$1}' bases.txt)\n    seqkit -is replace -p \"^n+|n+\\$\" -r \"\" ${base}.consensus_final.fa > ${base}.consensusfinal.fa\n\n    sed 's/>.*/>${base}/' ${base}.consensusfinal.fa > ${base}.consensusfinal-renamed-header.fa\n    grep -v \"^>\" ${base}.consensusfinal-renamed-header.fa | tr -cd N | wc -c > N.txt\n    cp ${base}.consensusfinal-renamed-header.fa ${base}.consensus_final.fa\n    \n    num_ns=\\$(awk 'FNR==1{print val,\\$1}' N.txt)\n    echo \"\\$num_ns/\\$num_bases*100\" | bc -l > n_percent.txt\n    percent_n=\\$(awk 'FNR==1{print val,\\$1}' n_percent.txt)\n    printf \",\\$num_bases\" >> ${base}_summary.csv\n    printf \",\\$percent_n\" >> ${base}_summary.csv\n    cp ${base}_summary.csv ${base}_final_summary.csv\n\n    fi\n\n    \"\"\"",
        "nb_lignes_script": 261,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "AIVAR",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/AIVAR",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "AIVAR",
                "uri": "https://bio.tools/AIVAR",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Targeted exome capture"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "WES"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Whole exome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome capture"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3461",
                                    "term": "Virulence prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3225",
                                    "term": "Variant classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3461",
                                    "term": "Pathogenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Assessing concordance among human, in silico predictions and functional assays on genetic variant classification.",
                "homepage": "https://github.com/TopGene/AIvar"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "base",
            "bamsize",
            "id_ref_size",
            "id"
        ],
        "nb_inputs": 4,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Aligning_Final": {
        "name_process": "Aligning_Final",
        "string_process": "\nprocess Aligning_Final {\n                                                                \n                             \n    errorStrategy 'ignore'\n                   \n                \n\n    input:\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"), file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_final_summary.csv\"),file(\"${base}.consensus_final.fa\")                          \n\n    output:\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_summary.csv\"),file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\")                                             \n\n    publishDir \"${params.outdir}bam_map3\", mode: 'copy', pattern:'*_map3.sorted.bam*'\n    publishDir \"${params.outdir}sam_map3\", mode: 'copy', pattern:'*_map3.sam*'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n    # FINAL MAPPING - MAP3\n\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. hrv_ref_hpv.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n    else\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n    fi\n\n    \"\"\"  \n}",
        "nb_lignes_process": 105,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    # FINAL MAPPING - MAP3\n\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. hrv_ref_hpv.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for mapping.\"\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n    else\n\n    ${BBMAP_PATH}bbmap.sh in=${base}.trimmed.fastq.gz outm=${base}_map3.sam ref=${base}.consensus_final.fa threads=${task.cpus} local=true interleaved=false maxindel=9 -Xmx6g > ${base}_final_mapping_stats_map3.txt 2>&1\n\n    samtools view -S -b ${base}_map3.sam > ${base}_map3.bam\n    samtools sort -@ 4 ${base}_map3.bam > ${base}_map3.sorted.bam\n    samtools index ${base}_map3.sorted.bam\n    # Rename summary file to retain file caching/-resume functionality\n    cp ${base}_final_summary.csv ${base}_summary.csv\n\n    fi\n\n    \"\"\"",
        "nb_lignes_script": 87,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "base",
            "bamsize",
            "id_ref_size",
            "id"
        ],
        "nb_inputs": 4,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [
            "errorStrategy 'ignore'"
        ],
        "when": "",
        "stub": ""
    },
    "Summary_Generation": {
        "name_process": "Summary_Generation",
        "string_process": "\nprocess Summary_Generation {\n                                                           \n    errorStrategy 'retry'        \n                             \n                   \n                \n\n    input:\n    file SAMPLE_LIST from METADATA\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_summary.csv\"),file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\")                        \n    \n    output:\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_sample_id.txt\"), file(\"${base}_pcr_ct.txt\"), file(\"${base}_method.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\"),file(\"${base}_sample_stats.csv\")                                 \n    tuple val(base), fisle(\"${base}_final_summary.csv\")                                         \n\n    publishDir \"${params.outdir}summary_withMetadata\", mode: 'copy', pattern:'*_final_summary.csv*'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    csvgrep -c sample_id -r \\$NCBI_Name ${SAMPLE_LIST} > ${base}_sample_stats.csv\n    csvcut -c 1 ${base}_sample_stats.csv > ${base}_sample_id.txt\n    csvcut -c 2 ${base}_sample_stats.csv > ${base}_pcr_ct.txt\n    csvcut -c 3 ${base}_sample_stats.csv > ${base}_method.txt\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    pcr_ct=\\$(cat ${base}_pcr_ct.txt | sed -n '2 p')\n    method=\\$(cat ${base}_method.txt | sed -n '2 p')\n    reads_mapped=\\$(cat ${base}_num_mapped.txt | tr -d \" \\t\\n\\r\" | sed -n '1 p')\n    num_trimmed=\\$(cat ${base}_num_trimmed.txt | tr -d \" \\t\\n\\r\" | sed -n '1 p')\n    echo \"\\$reads_mapped/\\$num_trimmed*100\" | bc -l > reads-on-t_percent.txt\n    Reads_On_Target=\\$(awk 'FNR==1{print val,\\$1}' reads-on-t_percent.txt)\n    printf \",\\$Reads_On_Target\" >> ${base}_summary.csv\n    printf \",\\$pcr_ct\" >> ${base}_summary.csv\n    printf \",\\$method\" >> ${base}_summary.csv\n    printf \",\\$NCBI_Name\" >> ${base}_summary.csv \n    cp ${base}_summary.csv ${base}_final_summary.csv\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    csvgrep -c sample_id -r \\$NCBI_Name ${SAMPLE_LIST} > ${base}_sample_stats.csv\n    csvcut -c 1 ${base}_sample_stats.csv > ${base}_sample_id.txt\n    csvcut -c 2 ${base}_sample_stats.csv > ${base}_pcr_ct.txt\n    csvcut -c 3 ${base}_sample_stats.csv > ${base}_method.txt\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    pcr_ct=\\$(cat ${base}_pcr_ct.txt | sed -n '2 p')\n    method=\\$(cat ${base}_method.txt | sed -n '2 p')\n    reads_mapped=\\$(cat ${base}_num_mapped.txt | tr -d \" \\t\\n\\r\" | sed -n '1 p')\n    num_trimmed=\\$(cat ${base}_num_trimmed.txt | tr -d \" \\t\\n\\r\" | sed -n '1 p')\n    echo \"\\$reads_mapped/\\$num_trimmed*100\" | bc -l > reads-on-t_percent.txt\n    Reads_On_Target=\\$(awk 'FNR==1{print val,\\$1}' reads-on-t_percent.txt)\n    printf \",\\$Reads_On_Target\" >> ${base}_summary.csv\n    printf \",\\$pcr_ct\" >> ${base}_summary.csv\n    printf \",\\$method\" >> ${base}_summary.csv\n    printf \",\\$NCBI_Name\" >> ${base}_summary.csv \n    cp ${base}_summary.csv ${base}_final_summary.csv\n    \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "METADATA",
            "base",
            "bamsize",
            "id_ref_size",
            "id"
        ],
        "nb_inputs": 5,
        "outputs": [
            "id",
            "base"
        ],
        "nb_outputs": 2,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [
            "errorStrategy 'retry'"
        ],
        "when": "",
        "stub": ""
    },
    "Serotyping": {
        "name_process": "Serotyping",
        "string_process": "\nprocess Serotyping {\n                                                                   \n                              \n                   \n                \n\n    input:\n        tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_sample_id.txt\"), file(\"${base}_pcr_ct.txt\"), file(\"${base}_method.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\"),file(\"${base}_sample_stats.csv\")                                 \n        tuple val(base), file(\"${base}_final_summary.csv\")                                         \n        file METADATA_INFO from METADATA\n        file BLASTDB_VP1_1 from BLAST_DB_VP1_1\n        file BLASTDB_VP1_2 from BLAST_DB_VP1_2\n        file BLASTDB_VP1_3 from BLAST_DB_VP1_3\n        file BLASTDB_VP1_4 from BLAST_DB_VP1_4\n        file BLASTDB_VP1_5 from BLAST_DB_VP1_5\n        file BLASTDB_VP1_6 from BLAST_DB_VP1_6\n        file BLASTDB_VP1_7 from BLAST_DB_VP1_7\n        file BLASTDB_VP1_8 from BLAST_DB_VP1_8\n        file BLASTDB_ALL_1 from BLAST_DB_ALL_1\n        file BLASTDB_ALL_2 from BLAST_DB_ALL_2\n        file BLASTDB_ALL_3 from BLAST_DB_ALL_3\n        file BLASTDB_ALL_4 from BLAST_DB_ALL_4\n        file BLASTDB_ALL_5 from BLAST_DB_ALL_5\n        file BLASTDB_ALL_6 from BLAST_DB_ALL_6\n        file BLASTDB_ALL_7 from BLAST_DB_ALL_7\n        file BLASTDB_ALL_8 from BLAST_DB_ALL_8\n        file BLASTDB_ALL_9 from BLAST_DB_ALL_9\n        file BLASTDB_ALL_10 from BLAST_DB_ALL_10\n\n    output:\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_sample_id.txt\"), file(\"${base}_pcr_ct.txt\"), file(\"${base}_method.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\"),file(\"${base}_sample_stats.csv\"), file(\"${base}_collection_year.txt\"), file(\"${base}_country_collected.txt\"), file(\"${base}_blast_db_vp1.txt\"), file(\"${base}_blast_db_all_ref.txt\"), file(\"${base}_sample_stats.csv\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_nomen.txt\")                   \n    tuple val(base), file(\"${base}_summary_final.csv\")                      \n\n    publishDir \"${params.outdir}blast_serotype\", mode: 'copy', pattern:'*_blast_db_vp1.txt*'\n    publishDir \"${params.outdir}blast_ref_genome\", mode: 'copy', pattern:'*_blast_db_all_ref.txt*'    \n    publishDir \"${params.outdir}sample_Stats\", mode: 'copy', pattern:'*_sample_stats.csv*'\n    publishDir \"${params.outdir}sample_Stats\", mode: 'copy', pattern:'*.txt*'       \n    publishDir \"${params.outdir}sample_Stats\", mode: 'copy', pattern:'*_collection_year.txt*'\n    publishDir \"${params.outdir}sample_Stats\", mode: 'copy', pattern:'*_country_collected.txt*'\n    publishDir \"${params.outdir}sample_Stats\", mode: 'copy', pattern:'*_nomen.txt*'\n    publishDir \"${params.outdir}summary_withserotype\", mode: 'copy', pattern:'*_summary_final.csv*'\n\n    script:\n\n    \"\"\"\n    #!/bin/bash\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    SAMPLEName=\\${R1:2:14}\n    char_edit=\\$(echo \"\\${R1//_R1}\")\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\";\n    then\n    echo \"< Accession found in Rhinovirus multifasta file; RV typing.\"\n\n    csvgrep -c sample_id -r \\$NCBI_Name ${METADATA_INFO} > ${base}_sample_stats.csv\n    csvcut -c 1 ${base}_sample_stats.csv > ${base}_sample_id.txt\n    csvcut -c 4 ${base}_sample_stats.csv > ${base}_collection_year.txt\n    csvcut -c 5 ${base}_sample_stats.csv > ${base}_country_collected.txt\n    csvcut -c 6 ${base}_sample_stats.csv > ${base}_biosample_name.txt\n    csvcut -c 7 ${base}_sample_stats.csv > ${base}_biosample_accession.txt\n    csvcut -c 8 ${base}_sample_stats.csv > ${base}_sra_accession.txt\n    csvcut -c 10 ${base}_sample_stats.csv > ${base}_release_date.txt\n    csvcut -c 9 ${base}_sample_stats.csv > ${base}_bioproject.txt\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Rv'\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n    \n    \n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file; HPV typing.\"\n    \n    csvgrep -c sample_id -r \\$NCBI_Name ${METADATA_INFO} > ${base}_sample_stats.csv\n    csvcut -c 1 ${base}_sample_stats.csv > ${base}_sample_id.txt\n    csvcut -c 4 ${base}_sample_stats.csv > ${base}_collection_year.txt\n    csvcut -c 5 ${base}_sample_stats.csv > ${base}_country_collected.txt\n    csvcut -c 6 ${base}_sample_stats.csv > ${base}_biosample_name.txt\n    csvcut -c 7 ${base}_sample_stats.csv > ${base}_biosample_accession.txt\n    csvcut -c 8 ${base}_sample_stats.csv > ${base}_sra_accession.txt\n    csvcut -c 10 ${base}_sample_stats.csv > ${base}_release_date.txt\n    csvcut -c 9 ${base}_sample_stats.csv > ${base}_bioproject.txt\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Human Papilloma Virus '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Human Coronavirus '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n    \n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file; IFB typing.\"\n\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Influenza B '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file; HPIV3 typing.\"\n\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='HPIV3 '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n    else\n\n    echo \"Accession NOT found; using ALL_REF for typing\"\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv=''\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n    fi\n\n    \"\"\"\n}",
        "nb_lignes_process": 385,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    SAMPLEName=\\${R1:2:14}\n    char_edit=\\$(echo \"\\${R1//_R1}\")\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\";\n    then\n    echo \"< Accession found in Rhinovirus multifasta file; RV typing.\"\n\n    csvgrep -c sample_id -r \\$NCBI_Name ${METADATA_INFO} > ${base}_sample_stats.csv\n    csvcut -c 1 ${base}_sample_stats.csv > ${base}_sample_id.txt\n    csvcut -c 4 ${base}_sample_stats.csv > ${base}_collection_year.txt\n    csvcut -c 5 ${base}_sample_stats.csv > ${base}_country_collected.txt\n    csvcut -c 6 ${base}_sample_stats.csv > ${base}_biosample_name.txt\n    csvcut -c 7 ${base}_sample_stats.csv > ${base}_biosample_accession.txt\n    csvcut -c 8 ${base}_sample_stats.csv > ${base}_sra_accession.txt\n    csvcut -c 10 ${base}_sample_stats.csv > ${base}_release_date.txt\n    csvcut -c 9 ${base}_sample_stats.csv > ${base}_bioproject.txt\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Rv'\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n    \n    \n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file; HPV typing.\"\n    \n    csvgrep -c sample_id -r \\$NCBI_Name ${METADATA_INFO} > ${base}_sample_stats.csv\n    csvcut -c 1 ${base}_sample_stats.csv > ${base}_sample_id.txt\n    csvcut -c 4 ${base}_sample_stats.csv > ${base}_collection_year.txt\n    csvcut -c 5 ${base}_sample_stats.csv > ${base}_country_collected.txt\n    csvcut -c 6 ${base}_sample_stats.csv > ${base}_biosample_name.txt\n    csvcut -c 7 ${base}_sample_stats.csv > ${base}_biosample_accession.txt\n    csvcut -c 8 ${base}_sample_stats.csv > ${base}_sra_accession.txt\n    csvcut -c 10 ${base}_sample_stats.csv > ${base}_release_date.txt\n    csvcut -c 9 ${base}_sample_stats.csv > ${base}_bioproject.txt\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Human Papilloma Virus '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n\n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for mapping.\"\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Human Coronavirus '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n    \n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file; IFB typing.\"\n\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='Influenza B '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file; HPIV3 typing.\"\n\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv='HPIV3 '\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n    else\n\n    echo \"Accession NOT found; using ALL_REF for typing\"\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n\n    blastn -out ${base}_blast_db_vp1.txt -query ${base}.consensus_final.fa -db ${BLASTDB_VP1_1} -outfmt 6 -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    serotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    rv=''\n    serotype_parse=\"\\${rv} \\${serotype_parsed}\"\n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    blastn -out ${base}_blast_db_all_ref.txt -query ${base}.consensus_final.fa -db ${BLASTDB_ALL_1} -outfmt \"5 std qlen\" -task blastn -max_target_seqs 1 -evalue 1e-5\n\n    awk 'NR==31' ${base}_blast_db_all_ref.txt > ${base}_strain.txt\n    sed -i -e 's/<Hit_def>//g'  ${base}_strain.txt\n    awk -F'</Hit_def>' '{print \\$1}' ${base}_strain.txt | xargs > ${base}_strain-parsed.txt\n    Reference_Name=\\$(head -n 1 ${base}_strain-parsed.txt)\n    biosample_name=\\$(cat ${base}_biosample_name.txt | sed -n '2 p')\n    biosample_accession=\\$(cat ${base}_biosample_accession.txt | sed -n '2 p')\n    sra_accession=\\$(cat ${base}_sra_accession.txt | sed -n '2 p')\n    release_date=\\$(cat ${base}_release_date.txt | sed -n '2 p')\n    bioproject=\\$(cat ${base}_bioproject.txt | sed -n '2 p')\n    \n    printf \",\\$serots\" >> ${base}_final_summary.csv\n    printf \",\\$nomen\" >> ${base}_final_summary.csv\n    printf \",\\$Reference_Name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_name\" >> ${base}_final_summary.csv\n    printf \",\\$biosample_accession\" >> ${base}_final_summary.csv\n    printf \",\\$sra_accession\" >> ${base}_final_summary.csv\n    printf \",\\$release_date\" >> ${base}_final_summary.csv\n    printf \",\\$bioproject\" >> ${base}_final_summary.csv\n    cp ${base}_final_summary.csv ${base}_summary_final.csv\n\n    fi\n\n    \"\"\"",
        "nb_lignes_script": 340,
        "language_script": "bash",
        "tools": [
            "RVS",
            "G-BLASTN",
            "HPViewer"
        ],
        "tools_url": [
            "https://bio.tools/rvs",
            "https://bio.tools/g-blastn",
            "https://bio.tools/hpviewer"
        ],
        "tools_dico": [
            {
                "name": "RVS",
                "uri": "https://bio.tools/rvs",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A novel likelihood-based method for genetic association with NGS data from external control groups. The tool substitutes genotype calls by their expected values given observed sequence data and implements a robust variance estimate for the score statistic.",
                "homepage": "http://strug.ccb.sickkids.ca/rvs/index.html"
            },
            {
                "name": "G-BLASTN",
                "uri": "https://bio.tools/g-blastn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0346",
                                    "term": "Sequence similarity search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2976",
                                "term": "Protein sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0857",
                                "term": "Sequence search results"
                            }
                        ]
                    }
                ],
                "description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "homepage": "http://www.comp.hkbu.edu.hk/~chxw/software/G-BLASTN.html"
            },
            {
                "name": "HPViewer",
                "uri": "https://bio.tools/hpviewer",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2815",
                            "term": "Human biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0781",
                            "term": "Virology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2815",
                            "term": "Humans"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Sensitive and specific genotyping of human papillomavirus in metagenomic DNA.",
                "homepage": "https://github.com/yuhanH/HPViewer/"
            }
        ],
        "inputs": [
            "base",
            "bamsize",
            "id_ref_size",
            "id",
            "base",
            "METADATA",
            "BLAST_DB_VP1_1",
            "BLAST_DB_VP1_2",
            "BLAST_DB_VP1_3",
            "BLAST_DB_VP1_4",
            "BLAST_DB_VP1_5",
            "BLAST_DB_VP1_6",
            "BLAST_DB_VP1_7",
            "BLAST_DB_VP1_8",
            "BLAST_DB_ALL_1",
            "BLAST_DB_ALL_2",
            "BLAST_DB_ALL_3",
            "BLAST_DB_ALL_4",
            "BLAST_DB_ALL_5",
            "BLAST_DB_ALL_6",
            "BLAST_DB_ALL_7",
            "BLAST_DB_ALL_8",
            "BLAST_DB_ALL_9",
            "BLAST_DB_ALL_10"
        ],
        "nb_inputs": 24,
        "outputs": [
            "id",
            "base"
        ],
        "nb_outputs": 2,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "Final_Processing": {
        "name_process": "Final_Processing",
        "string_process": "\nprocess Final_Processing {\n                                                                   \n                            \n    errorStrategy 'ignore'\n                   \n                \n\n    input:\n    file '*.csv' from Summary_cat_ch.collect()\n    tuple val(base), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_summary.csv\"),file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\")                           \n\n    output:\n    file(\"Run_Summary_Final_cat.csv\") into Final_summary_out_ch\n    tuple val(base), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_summary.csv\"),file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\")                               \n\n    publishDir \"${params.outdir}summary_withserotype_cat\", mode: 'copy', pattern:'*Run_Summary_Final_cat.csv*'\n\n    script:\n    \"\"\"\n    #!/bin/bash\n    cp ${params.outdir}/ref_ids/${base}_all_ref_id.txt ${base}_all_ref_id.txt\n    cp ${params.outdir}/ref_ids/${base}_rv_ids.txt ${base}_rv_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_hpv_ids.txt ${base}_hpv_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_inbflb_ids.txt ${base}_inbflb_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_hcov_ids.txt ${base}_hcov_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_hpiv3.txt ${base}_hpiv3.txt\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    SAMPLEName=\\${R1:2:5}\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n    \n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n    \n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. HPV final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n    \n    \n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n    \n    \n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n\n\n    else\n\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 84,
        "string_script": "    \"\"\"\n    #!/bin/bash\n    cp ${params.outdir}/ref_ids/${base}_all_ref_id.txt ${base}_all_ref_id.txt\n    cp ${params.outdir}/ref_ids/${base}_rv_ids.txt ${base}_rv_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_hpv_ids.txt ${base}_hpv_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_inbflb_ids.txt ${base}_inbflb_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_hcov_ids.txt ${base}_hcov_ids.txt\n    cp ${params.outdir}/ref_ids/${base}_hpiv3.txt ${base}_hpiv3.txt\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    SAMPLEName=\\${R1:2:5}\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n    \n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n    \n\n    # HPV\n    elif grep -q \\$all_ref_id \"${base}_hpv_ids.txt\";\n    then\n    echo \"< Accession found in HPV multifasta file. HPV final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n\n\n    # Influenza B\n    elif grep -q \\$all_ref_id \"${base}_inbflb_ids.txt\";\n    then\n    echo \"< Accession found in Influenza B multifasta file. hrv_ref_Influenza_b.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n    \n    \n    # Human Coronavirus\n    elif grep -q \\$all_ref_id \"${base}_hcov_ids.txt\";\n    then\n    echo \"Accession found in HCoVs multifasta file. hrv_ref_hcov.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n    \n    \n    # HPIV3 - Human parainfluenza virus 3\n    elif grep -q \\$all_ref_id \"${base}_hpiv3.txt\";\n    then\n    echo \"Accession found in HPIV3 multifasta file. hrv_ref_hpiv3.fa will be used for final processing.\"\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n\n\n    else\n\n    awk '(NR == 1) || (FNR > 1)' *.csv >  Run_Summary_cat.csv\n    sed '1d' Run_Summary_cat.csv > Run_Summary_catted.csv\n    echo -e \"Sample_Name,Raw_Reads,Trimmed_Reads,Percent_Trimmed,Reference_Genome,Reference_Length,Mapped_Reads,Percent_Ref_Coverage,Min_Coverage,Mean_Coverage,Max_Coverage,Bam_Size,Consensus_Length,Percent_N,%_Reads_On_Target, PCR_CT,Method, NCBI_Name, Serotype, Nomenclature, Reference_Name, Reference_Genome, Biosample_name, Biosample_accession, SRA_Accession, Bioproject,  Release_date\" | cat - Run_Summary_catted.csv > Run_Summary_Final_cat.csv\n\n    fi\n    \"\"\"",
        "nb_lignes_script": 65,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "Summary_cat_ch",
            "base",
            "bamsize",
            "id_ref_size",
            "id"
        ],
        "nb_inputs": 5,
        "outputs": [
            "Final_summary_out_ch",
            "id"
        ],
        "nb_outputs": 2,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [
            "errorStrategy 'ignore'"
        ],
        "when": "",
        "stub": ""
    },
    "Vapid_Annotation": {
        "name_process": "Vapid_Annotation",
        "string_process": "\nprocess Vapid_Annotation {\n                                                       \n                                 \n                            \n                   \n    \n    input:\n    file VAPID_DB_ALL_1\n    file VAPID_DB_ALL_2\n    file VAPID_DB_ALL_3\n    file VAPID_DB_ALL_4\n    file VAPID_DB_ALL_5\n    file VAPID_DB_ALL_6\n    file VAPID_DB_ALL_7\n    file VAPID_DB_ALL_8\n    file tbl2asn\n    file vapid_python_main from vapid_python\n    file vapid_python_main3 from vapid_python3\n    file vapid_rhinovirus_sbt\n\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_sample_id.txt\"), file(\"${base}_pcr_ct.txt\"), file(\"${base}_method.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\"),file(\"${base}_sample_stats.csv\"), file(\"${base}_collection_year.txt\"), file(\"${base}_country_collected.txt\"), file(\"${base}_blast_db_vp1.txt\"), file(\"${base}_blast_db_all_ref.txt\"), file(\"${base}_sample_stats.csv\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}_nomen.txt\")                   \n    output:\n    tuple val(base), file(\"${base}.mpileup\"), file(\"${base}.bam\"), file(\"${base}.sorted.bam\"),file(\"${base}_flagstats.txt\"),val(bamsize),file(\"${base}_map2.sam\"), file(\"${base}_most_mapped_ref.txt\"),file(\"${base}_most_mapped_ref_size.txt\"),file(\"${base}_most_mapped_ref_size_out.txt\"),val(id_ref_size),file(\"${base}_idxstats.txt\"),file(\"${base}_mapped_ref_genome.fa\"),val(id),file(\"${base}_map1_bbmap_out.txt\"),file(\"${base}_map2_bbmap_out.txt\"),file(\"${base}_map1_stats.txt\"),file(\"${base}_map2_stats.txt\"),file(\"${base}_mapped_ref_genome.fa.fai\"),file(\"${base}.trimmed.fastq.gz\"), file(\"${base}_num_trimmed.txt\"), file(\"${base}_num_mapped.txt\"), file(\"${base}_sample_id.txt\"), file(\"${base}_pcr_ct.txt\"), file(\"${base}_method.txt\"), file(\"${base}_rv_ids.txt\"), file(\"${base}_hpv_ids.txt\"), file(\"${base}_inbflb_ids.txt\"), file(\"${base}_hcov_ids.txt\"), file(\"${base}_hpiv3.txt\"), file(\"${base}_all_ref_id.txt\"), file(\"${base}.consensus_final.fa\"),file(\"${base}_map3.sam\"),file(\"${base}_map3.sorted.bam\"),file(\"${base}_sample_stats.csv\"), file(\"${base}_collection_year.txt\"), file(\"${base}_country_collected.txt\"), file(\"${base}_blast_db_vp1.txt\"), file(\"${base}_blast_db_all_ref.txt\"), file(\"${base}_nomen.txt\"), file (\"${base}_vapid_metadata.csv\")                    \n\n                                                                                                      \n                                                                                                  \n                                                                                            \n                                                                                                     \n                                                                                              \n                                                                                            \n                                                                                            \n                                                                                            \n                                                                                            \n                                                                                            \n                                                                                            \n                                                                                                        \n                                                                                                \n    publishDir \"${params.outdir}summary_vapid_metadata\", mode: 'copy', pattern:'*_vapid_metadata.csv*'       \n\n    script:\n\n    \"\"\"\n    #!/bin/bash\n\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    SAMPLEName=\\${R1:1:6}\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n\n    # VIRAL ANNOTATION\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    coverage=\"\"\n    echo strain, collection_date, country, coverage, full_name> ${base}_vapid_metadata.csv\n    name=${base}\n    printf \"\\$NCBI_Name, \\$collection_year, \\$country_collected, \\$coverage, \\$NCBI_Name\" >> ${base}_vapid_metadata.csv\n\n    cp ${base}.consensus_final.fa \\${NCBI_Name}.final_consensus.fa\n    \n    seqkit replace -p '.+' -r \\$NCBI_Name \\${NCBI_Name}.final_consensus.fa > \\${NCBI_Name}.fa\n\n    reference_name=\\$(grep -e \">\" ${base}_mapped_ref_genome.fa > ${base}_ref_name.txt)\n    ref_name_edit=\\$(sed 's/>//g' ${base}_ref_name.txt > ${base}_ref_name_edit.txt)\n    ref=\\$(awk 'FNR==1{print val,\\$1}' ${base}_ref_name_edit.txt)\n\n    python3 ${vapid_python_main3} \\${NCBI_Name}.fa ${vapid_rhinovirus_sbt} --metadata_loc ${base}_vapid_metadata.csv --output_location ${params.outdir}\n\n\tserotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    serotype_parse=\"\\${serotype_parsed}\" \n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    serots_adj=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt  | xargs)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    cp ${params.outdir}/summary_vapid_output/\\${NCBI_Name}.sqn ${params.outdir}/summary_vapid_output/\\${NCBI_Name}.txt\n\n    # Edit Line:95 - taxname\n    quote='\"'\n    rhino=\"rhinovirus \\$serots_adj\"\n    taxname=\"              taxname \\$quote\"\\$rhino\"\\$quote ,\"\n    sed \"95s/.*/\\$taxname/\" ${params.outdir}/summary_vapid_output/\\${NCBI_Name}.txt > ${params.outdir}/summary_vapid_output/\\${NCBI_Name}_95.txt\n    \n    # Edit Line:100 - subname\n    subname_1=\"\\$quote\\$nomen\\$quote\"\n    subname_2=\"                   subname \\$subname_1 }",
        "nb_lignes_process": 105,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    R1=${base}\n    NCBI_Name=\\${R1:4:6}\n    SAMPLEName=\\${R1:1:6}\n    all_ref_id=\\$(awk '{print \\$1}' ${base}_all_ref_id.txt)\n\n\n    # VIRAL ANNOTATION\n\n    # Rhinovirus\n    if grep -q \\$all_ref_id \"${base}_rv_ids.txt\"; \n    then\n    echo \"< Accession found in Rhinovirus multifasta file. hrv_ref_rhinovirus.fa will be used for mapping.\"\n\n    sample_id=\\$(cat ${base}_sample_id.txt | sed -n '2 p')\n    collection_year=\\$(cat ${base}_collection_year.txt | sed -n '2 p')\n    country_collected=\\$(cat ${base}_country_collected.txt | sed -n '2 p')\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    coverage=\"\"\n    echo strain, collection_date, country, coverage, full_name> ${base}_vapid_metadata.csv\n    name=${base}\n    printf \"\\$NCBI_Name, \\$collection_year, \\$country_collected, \\$coverage, \\$NCBI_Name\" >> ${base}_vapid_metadata.csv\n\n    cp ${base}.consensus_final.fa \\${NCBI_Name}.final_consensus.fa\n    \n    seqkit replace -p '.+' -r \\$NCBI_Name \\${NCBI_Name}.final_consensus.fa > \\${NCBI_Name}.fa\n\n    reference_name=\\$(grep -e \">\" ${base}_mapped_ref_genome.fa > ${base}_ref_name.txt)\n    ref_name_edit=\\$(sed 's/>//g' ${base}_ref_name.txt > ${base}_ref_name_edit.txt)\n    ref=\\$(awk 'FNR==1{print val,\\$1}' ${base}_ref_name_edit.txt)\n\n    python3 ${vapid_python_main3} \\${NCBI_Name}.fa ${vapid_rhinovirus_sbt} --metadata_loc ${base}_vapid_metadata.csv --output_location ${params.outdir}\n\n\tserotype=\\$(awk 'FNR==1{print val,\\$2}' ${base}_blast_db_vp1.txt)\n    cut -d \"-\" -f2- <<< \"\\$serotype\" > ${base}_serotype-parse.txt\n    serotype_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serotype-parse.txt)\n    serotype_parse=\"\\${serotype_parsed}\" \n    echo \\$serotype_parse > ${base}_sero.txt\n    cat ${base}_sero.txt | tr -d \" \\t\\n\\r\" > ${base}_serot.txt\n    serotype_parsed2=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serot.txt)\n    space='/'\n    nomenclature=\"\\${serotype_parsed2} \\${space} \\${country_collected} \\${space} \\${collection_year} \\${space} \\${NCBI_Name}\" \n    echo \\$nomenclature > ${base}_nomenclature.txt\n    cat ${base}_nomenclature.txt | tr -d \" \\t\\n\\r\" > ${base}_nomenclature_parsed.txt\n    nomenclature_parsed=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomenclature_parsed.txt)\t\n    echo \\$serotype_parsed2 | xargs > ${base}_serots.txt\n    echo \\$nomenclature_parsed | xargs > ${base}_nomen.txt\n    serots=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt)\t\n    serots_adj=\\$(awk 'FNR==1{print val,\\$1}' ${base}_serots.txt  | xargs)\t\n    nomen=\\$(awk 'FNR==1{print val,\\$1}' ${base}_nomen.txt)\t\n\n    cp ${params.outdir}/summary_vapid_output/\\${NCBI_Name}.sqn ${params.outdir}/summary_vapid_output/\\${NCBI_Name}.txt\n\n    # Edit Line:95 - taxname\n    quote='\"'\n    rhino=\"rhinovirus \\$serots_adj\"\n    taxname=\"              taxname \\$quote\"\\$rhino\"\\$quote ,\"\n    sed \"95s/.*/\\$taxname/\" ${params.outdir}/summary_vapid_output/\\${NCBI_Name}.txt > ${params.outdir}/summary_vapid_output/\\${NCBI_Name}_95.txt\n    \n    # Edit Line:100 - subname\n    subname_1=\"\\$quote\\$nomen\\$quote\"\n    subname_2=\"                   subname \\$subname_1",
        "nb_lignes_script": 64,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "VAPID_DB_ALL_1",
            "VAPID_DB_ALL_2",
            "VAPID_DB_ALL_3",
            "VAPID_DB_ALL_4",
            "VAPID_DB_ALL_5",
            "VAPID_DB_ALL_6",
            "VAPID_DB_ALL_7",
            "VAPID_DB_ALL_8",
            "tbl2asn",
            "vapid_python",
            "vapid_python3",
            "vapid_rhinovirus_sbt",
            "base",
            "bamsize",
            "id_ref_size",
            "id"
        ],
        "nb_inputs": 16,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "FastQC": {
        "name_process": "FastQC",
        "string_process": "\nprocess FastQC {\n    container \"docker.io/paulrkcruz/hrv-pipeline:latest\"\n\terrorStrategy 'retry'\n    maxRetries 3\n\n    input:\n        file R1                          \n\n    output:\n\tfile '*_fastqc.{zip,html}'                         \n\n    publishDir \"${params.outdir}fastqc_results\", mode: 'copy', pattern:'*_fastqc.{zip,html}*'  \n\n    script:\n    \"\"\"\n    #!/bin/bash\n\n    /usr/local/bin/fastqc --quiet --threads ${task.cpus} ${base}.trimmed.fastq.gz\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    #!/bin/bash\n\n    /usr/local/bin/fastqc --quiet --threads ${task.cpus} ${base}.trimmed.fastq.gz\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "R1"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "Paul-rk-cruz__HRV_Pipeline",
        "directive": [
            "container \"docker.io/paulrkcruz/hrv-pipeline:latest\"",
            "errorStrategy 'retry'",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    }
}