{
    "fetch_from_ena": {
        "name_process": "fetch_from_ena",
        "string_process": " process fetch_from_ena {\n    tag { accession_number }\n    \n    publishDir \"${output_dir}/fastqs\",\n      mode: 'copy',\n      saveAs: { file -> file.split('\\\\/')[-1] }\n\n    input:\n    val accession_number from accession_numbers\n\n    output:\n    set accession_number, file(\"${accession_number}/*.fastq.gz\") into raw_fastqs\n\n    \"\"\"\n    enaDataGet -f fastq -as /home/bio/.aspera/aspera.ini ${accession_number}\n    \"\"\"\n  }",
        "nb_lignes_process": 15,
        "string_script": "\"\"\"\n    enaDataGet -f fastq -as /home/bio/.aspera/aspera.ini ${accession_number}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "accession_numbers"
        ],
        "nb_inputs": 1,
        "outputs": [
            "raw_fastqs"
        ],
        "nb_outputs": 1,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { accession_number }",
            "publishDir \"${output_dir}/fastqs\" , mode: 'copy' , saveAs: { file -> file.split(' /')[-1] }"
        ],
        "when": "",
        "stub": ""
    },
    "determine_min_read_length": {
        "name_process": "determine_min_read_length",
        "string_process": "\nprocess determine_min_read_length {\n  tag { pair_id }\n\n  input:\n  set pair_id, file(file_pair) from raw_fastqs_for_length_assessment\n\n  output:\n  set pair_id, stdout into min_read_length_for_trimming, min_read_length_for_assembly\n\n\n  \"\"\"\n  gzip -cd ${file_pair[0]} | head -n 400000 | printf \"%.0f\" \\$(awk 'NR%4==2{sum+=length(\\$0)}END{print sum/(NR/4)/3}')\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n  gzip -cd ${file_pair[0]} | head -n 400000 | printf \"%.0f\" \\$(awk 'NR%4==2{sum+=length(\\$0)}END{print sum/(NR/4)/3}')\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "raw_fastqs_for_length_assessment"
        ],
        "nb_inputs": 1,
        "outputs": [
            "min_read_length_for_trimming",
            "min_read_length_for_assembly"
        ],
        "nb_outputs": 2,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }"
        ],
        "when": "",
        "stub": ""
    },
    "qc_pre_trimming": {
        "name_process": "qc_pre_trimming",
        "string_process": "\nprocess qc_pre_trimming {\n  tag { pair_id }\n  \n  publishDir \"${output_dir}/fastqc/pre_trimming\",\n    mode: 'copy',\n    pattern: \"*.html\"\n\n  input:\n  set pair_id, file(file_pair) from raw_fastqs_for_qc\n\n  output:\n  file('*.html')\n\n  \"\"\"\n  fastqc ${file_pair[0]} ${file_pair[1]}\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n  fastqc ${file_pair[0]} ${file_pair[1]}\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "raw_fastqs_for_qc"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }",
            "publishDir \"${output_dir}/fastqc/pre_trimming\" , mode: 'copy' , pattern: \"*.html\""
        ],
        "when": "",
        "stub": ""
    },
    "trimming": {
        "name_process": "trimming",
        "string_process": "\nprocess trimming {\n  memory '4 GB'\n  \n  tag { pair_id }\n  \n  input:\n  set pair_id, min_read_length, file(file_pair) from min_read_length_and_raw_fastqs\n  file('adapter_file.fas') from adapter_file\n\n  output:\n  set pair_id, file('trimmed_fastqs/*.fastq.gz') into trimmed_fastqs_for_qc, trimmed_fastqs_for_correction, trimmed_fastqs_for_genome_size_estimation, trimmed_fastqs_for_base_counting\n\n  \"\"\"\n  mkdir trimmed_fastqs\n  trimmomatic PE -threads 1 -phred33 ${file_pair[0]} ${file_pair[1]} trimmed_fastqs/${file_pair[0]} /dev/null trimmed_fastqs/${file_pair[1]} /dev/null ILLUMINACLIP:adapter_file.fas:2:30:10 SLIDINGWINDOW:4:20 LEADING:25 TRAILING:25 MINLEN:${min_read_length}  \n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n  mkdir trimmed_fastqs\n  trimmomatic PE -threads 1 -phred33 ${file_pair[0]} ${file_pair[1]} trimmed_fastqs/${file_pair[0]} /dev/null trimmed_fastqs/${file_pair[1]} /dev/null ILLUMINACLIP:adapter_file.fas:2:30:10 SLIDINGWINDOW:4:20 LEADING:25 TRAILING:25 MINLEN:${min_read_length}  \n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "Trimmomatic"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            }
        ],
        "inputs": [
            "min_read_length_and_raw_fastqs",
            "adapter_file"
        ],
        "nb_inputs": 2,
        "outputs": [
            "trimmed_fastqs_for_qc",
            "trimmed_fastqs_for_correction",
            "trimmed_fastqs_for_genome_size_estimation",
            "trimmed_fastqs_for_base_counting"
        ],
        "nb_outputs": 4,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "memory '4 GB'",
            "tag { pair_id }"
        ],
        "when": "",
        "stub": ""
    },
    "qc_post_trimming": {
        "name_process": "qc_post_trimming",
        "string_process": "\nprocess qc_post_trimming {\n  tag { pair_id }\n\n  publishDir \"${output_dir}/fastqc/post_trimming\",\n    mode: 'copy',\n    pattern: \"*.html\"\n  \n  input:\n  set pair_id, file(file_pair)  from trimmed_fastqs_for_qc\n\n  output:\n  file('*.html')\n  set pair_id, file(\"${pair_id}_R1_fastqc.txt\"), file(\"${pair_id}_R2_fastqc.txt\") into qc_post_trimming_files\n  set file(\"${r1_prefix}_fastqc\"), file(\"${r2_prefix}_fastqc\") into fastqc_directories\n\n  script:\n  r1_prefix = file_pair[0].baseName.split('\\\\.')[0]\n  r2_prefix = file_pair[1].baseName.split('\\\\.')[0]\n  \"\"\"\n  fastqc ${file_pair[0]} ${file_pair[1]} --extract\n  mv ${r1_prefix}_fastqc/summary.txt ${pair_id}_R1_fastqc.txt\n  mv ${r2_prefix}_fastqc/summary.txt ${pair_id}_R2_fastqc.txt\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "  r1_prefix = file_pair[0].baseName.split('\\\\.')[0]\n  r2_prefix = file_pair[1].baseName.split('\\\\.')[0]\n  \"\"\"\n  fastqc ${file_pair[0]} ${file_pair[1]} --extract\n  mv ${r1_prefix}_fastqc/summary.txt ${pair_id}_R1_fastqc.txt\n  mv ${r2_prefix}_fastqc/summary.txt ${pair_id}_R2_fastqc.txt\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "trimmed_fastqs_for_qc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "qc_post_trimming_files",
            "fastqc_directories"
        ],
        "nb_outputs": 2,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }",
            "publishDir \"${output_dir}/fastqc/post_trimming\" , mode: 'copy' , pattern: \"*.html\""
        ],
        "when": "",
        "stub": ""
    },
    "fastqc_multiqc": {
        "name_process": "fastqc_multiqc",
        "string_process": "\nprocess fastqc_multiqc {\n  tag { 'multiqc for fastqc' }\n\n  publishDir \"${output_dir}/quality_reports\",\n    mode: 'copy',\n    pattern: \"multiqc_report.html\",\n    saveAs: { \"fastqc_multiqc_report.html\" }\n\n  input:\n  file(fastqc_directories) from fastqc_directories.collect { it }\n\n  output:\n  file(\"multiqc_report.html\")\n\n  script:\n  \"\"\"\n  multiqc .\n  \"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  multiqc .\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastqc_directories"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { 'multiqc for fastqc' }",
            "publishDir \"${output_dir}/quality_reports\" , mode: 'copy' , pattern: \"multiqc_report.html\" , saveAs: { \"fastqc_multiqc_report.html\" }"
        ],
        "when": "",
        "stub": ""
    },
    "genome_size_estimation": {
        "name_process": "genome_size_estimation",
        "string_process": "\nprocess genome_size_estimation {\n  tag { pair_id }\n  \n  input:\n  set pair_id, file(file_pair)  from trimmed_fastqs_for_genome_size_estimation\n\n  output:\n  set pair_id, file('mash_stats.out') into mash_output\n\n  \"\"\"\n  mash sketch -o /tmp/sketch_${pair_id}  -k 32 -m 3 -r ${file_pair[0]}  2> mash_stats.out\n  \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n  mash sketch -o /tmp/sketch_${pair_id}  -k 32 -m 3 -r ${file_pair[0]}  2> mash_stats.out\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Mash"
        ],
        "tools_url": [
            "https://bio.tools/mash"
        ],
        "tools_dico": [
            {
                "name": "Mash",
                "uri": "https://bio.tools/mash",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2533",
                            "term": "DNA mutation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance matrix generation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Phylogenetic distance matrix generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0289",
                                    "term": "Sequence distance matrix construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Fast genome and metagenome distance estimation using MinHash.",
                "homepage": "https://github.com/marbl/mash"
            }
        ],
        "inputs": [
            "trimmed_fastqs_for_genome_size_estimation"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mash_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }"
        ],
        "when": "",
        "stub": ""
    },
    "read_correction": {
        "name_process": "read_correction",
        "string_process": "\nprocess read_correction {\n  tag { pair_id }\n  \n  publishDir \"${output_dir}\",\n    mode: 'copy',\n    pattern: \"corrected_fastqs/*.fastq.gz\"\n\n  input:\n  set pair_id, file(file_pair), genome_size from trimmed_fastqs_and_genome_size\n\n  output:\n  set pair_id, file('lighter.out') into read_correction_output\n  set pair_id, file('corrected_fastqs/*.fastq.gz') into corrected_fastqs_for_merging, corrected_fastqs_for_contamination_check\n\n  \"\"\"\n  lighter -od corrected_fastqs -r  ${file_pair[0]} -r  ${file_pair[1]} -K 32 ${genome_size}  -maxcor 1 2> lighter.out\n  for file in corrected_fastqs/*.cor.fq.gz\n  do\n      new_file=\\${file%.cor.fq.gz}.fastq.gz\n      mv \\${file} \\${new_file}\n  done\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "\"\"\"\n  lighter -od corrected_fastqs -r  ${file_pair[0]} -r  ${file_pair[1]} -K 32 ${genome_size}  -maxcor 1 2> lighter.out\n  for file in corrected_fastqs/*.cor.fq.gz\n  do\n      new_file=\\${file%.cor.fq.gz}.fastq.gz\n      mv \\${file} \\${new_file}\n  done\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Lighter"
        ],
        "tools_url": [
            "https://bio.tools/lighter"
        ],
        "tools_dico": [
            {
                "name": "Lighter",
                "uri": "https://bio.tools/lighter",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3195",
                                    "term": "Sequencing error detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3195",
                                    "term": "Short-read error correction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3195",
                                    "term": "Short read error correction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Kmer-based error correction method for whole genome sequencing data. Lighter uses sampling (rather than counting) to obtain a set of kmers that are likely from the genome. Using this information, Lighter can correct the reads containing sequence errors.",
                "homepage": "https://github.com/mourisl/Lighter"
            }
        ],
        "inputs": [
            "trimmed_fastqs_and_genome_size"
        ],
        "nb_inputs": 1,
        "outputs": [
            "read_correction_output",
            "corrected_fastqs_for_merging",
            "corrected_fastqs_for_contamination_check"
        ],
        "nb_outputs": 3,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }",
            "publishDir \"${output_dir}\" , mode: 'copy' , pattern: \"corrected_fastqs/*.fastq.gz\""
        ],
        "when": "",
        "stub": ""
    },
    "check_for_contamination": {
        "name_process": "check_for_contamination",
        "string_process": "\nprocess check_for_contamination {\n  tag {pair_id}\n\n  publishDir \"${output_dir}/confindr\",\n    mode: 'copy',\n    saveAs: { file -> \"${pair_id}_${file}\"}\n\n  input:\n  set pair_id, file(file_pair) from corrected_fastqs_for_contamination_check\n\n  output:\n  set pair_id, file('confindr_report.csv') into confindr_files\n\n  script:\n  if (file_pair[0] =~ /_R1/){                          \n    \"\"\"\n    confindr.py -i . -o . -d ${confindr_db_path} -t 1 -bf 0.025 -b 2 -Xmx 1500m\n    \"\"\"\n  } else {                        \n    \"\"\"\n    confindr.py -i . -o . -d ${confindr_db_path} -t 1 -bf 0.025 -b 2 -Xmx 1500m -fid _1 -rid _2\n    \"\"\"  \n  }\n\n}",
        "nb_lignes_process": 24,
        "string_script": "  if (file_pair[0] =~ /_R1/){                          \n    \"\"\"\n    confindr.py -i . -o . -d ${confindr_db_path} -t 1 -bf 0.025 -b 2 -Xmx 1500m\n    \"\"\"\n  } else {                        \n    \"\"\"\n    confindr.py -i . -o . -d ${confindr_db_path} -t 1 -bf 0.025 -b 2 -Xmx 1500m -fid _1 -rid _2\n    \"\"\"  \n  }",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "corrected_fastqs_for_contamination_check"
        ],
        "nb_inputs": 1,
        "outputs": [
            "confindr_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag {pair_id}",
            "publishDir \"${output_dir}/confindr\" , mode: 'copy' , saveAs: { file -> \"${pair_id}_${file}\"}"
        ],
        "when": "",
        "stub": ""
    },
    "count_number_of_bases": {
        "name_process": "count_number_of_bases",
        "string_process": "\nprocess count_number_of_bases {\n  tag { pair_id }\n  \n  input:\n  set pair_id, file(file_pair) from trimmed_fastqs_for_base_counting\n\n  output:\n  set pair_id, file('seqtk_fqchk.out') into seqtk_fqchk_output\n\n  \"\"\"\n  seqtk fqchk -q 25 ${file_pair[0]} > seqtk_fqchk.out\n  \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n  seqtk fqchk -q 25 ${file_pair[0]} > seqtk_fqchk.out\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "seqtk"
        ],
        "tools_url": [
            "https://bio.tools/seqtk"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            }
        ],
        "inputs": [
            "trimmed_fastqs_for_base_counting"
        ],
        "nb_inputs": 1,
        "outputs": [
            "seqtk_fqchk_output"
        ],
        "nb_outputs": 1,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }"
        ],
        "when": "",
        "stub": ""
    },
    "merge_reads": {
        "name_process": "merge_reads",
        "string_process": "\nprocess merge_reads{\n  tag { pair_id }\n\n  publishDir \"${output_dir}\",\n    mode: 'copy',\n    pattern: \"merged_fastqs/*.fastq.gz\"\n  \n  input:\n  set pair_id, file(file_pair), genome_size, base_count from corrected_fastqs_and_genome_size_and_base_count\n\n  output:\n  set pair_id, file('merged_fastqs/*.fastq.gz') into merged_fastqs\n\n  script:\n  \n  if (depth_cutoff  && base_count/genome_size > depth_cutoff.toInteger()){\n    downsampling_factor = depth_cutoff.toInteger()/(base_count/genome_size)\n    \"\"\"\n    mkdir downsampled_fastqs\n    seqtk sample  ${file_pair[0]} ${downsampling_factor} | gzip > downsampled_fastqs/${file_pair[0]}\n    seqtk sample  ${file_pair[1]} ${downsampling_factor} | gzip > downsampled_fastqs/${file_pair[1]}\n    flash -m 20 -M 100 -d merged_fastqs -o ${pair_id} -z downsampled_fastqs/${file_pair[0]} downsampled_fastqs/${file_pair[1]} \n    \"\"\"\n  } else {\n    \"\"\"\n    flash -m 20 -M 100 -d merged_fastqs -o ${pair_id} -z ${file_pair[0]} ${file_pair[1]} \n    \"\"\"\n  }\n\n}",
        "nb_lignes_process": 29,
        "string_script": "  if (depth_cutoff  && base_count/genome_size > depth_cutoff.toInteger()){\n    downsampling_factor = depth_cutoff.toInteger()/(base_count/genome_size)\n    \"\"\"\n    mkdir downsampled_fastqs\n    seqtk sample  ${file_pair[0]} ${downsampling_factor} | gzip > downsampled_fastqs/${file_pair[0]}\n    seqtk sample  ${file_pair[1]} ${downsampling_factor} | gzip > downsampled_fastqs/${file_pair[1]}\n    flash -m 20 -M 100 -d merged_fastqs -o ${pair_id} -z downsampled_fastqs/${file_pair[0]} downsampled_fastqs/${file_pair[1]} \n    \"\"\"\n  } else {\n    \"\"\"\n    flash -m 20 -M 100 -d merged_fastqs -o ${pair_id} -z ${file_pair[0]} ${file_pair[1]} \n    \"\"\"\n  }",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "seqtk",
            "FLASH"
        ],
        "tools_url": [
            "https://bio.tools/seqtk",
            "https://bio.tools/flash"
        ],
        "tools_dico": [
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            },
            {
                "name": "FLASH",
                "uri": "https://bio.tools/flash",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3219",
                                    "term": "Sequence read pre-processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Identifies paired-end reads which overlap in the middle, converting them to single long reads",
                "homepage": "http://ccb.jhu.edu/software/FLASH/"
            }
        ],
        "inputs": [
            "corrected_fastqs_and_genome_size_and_base_count"
        ],
        "nb_inputs": 1,
        "outputs": [
            "merged_fastqs"
        ],
        "nb_outputs": 1,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }",
            "publishDir \"${output_dir}\" , mode: 'copy' , pattern: \"merged_fastqs/*.fastq.gz\""
        ],
        "when": "",
        "stub": ""
    },
    "spades_assembly": {
        "name_process": "spades_assembly",
        "string_process": "\nprocess spades_assembly {\n  memory '4 GB'\n  \n  tag { pair_id }\n\n  input:\n  set pair_id, min_read_length, file(file_triplet) from min_read_length_and_raw_fastqs\n\n\n  output:\n  set pair_id, file(\"scaffolds.fasta\") into scaffolds\n\n  script:\n  if (min_read_length.toInteger() < 27 ) {\n    kmers = '21,33,43,53'\n  } else {\n    kmers = '21,33,43,53,63,75'\n  }\n\n  \"\"\"\n  spades.py --pe1-1 ${file_triplet[1]} --pe1-2 ${file_triplet[2]} --pe1-m ${file_triplet[0]} --only-assembler  -o . --tmp-dir /tmp/${pair_id}_assembly -k ${kmers} --threads 1 --memory 4\n\n  \"\"\"\n\n}",
        "nb_lignes_process": 24,
        "string_script": "  if (min_read_length.toInteger() < 27 ) {\n    kmers = '21,33,43,53'\n  } else {\n    kmers = '21,33,43,53,63,75'\n  }\n\n  \"\"\"\n  spades.py --pe1-1 ${file_triplet[1]} --pe1-2 ${file_triplet[2]} --pe1-m ${file_triplet[0]} --only-assembler  -o . --tmp-dir /tmp/${pair_id}_assembly -k ${kmers} --threads 1 --memory 4\n\n  \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "KmerStream"
        ],
        "tools_url": [
            "https://bio.tools/kmerstream"
        ],
        "tools_dico": [
            {
                "name": "KmerStream",
                "uri": "https://bio.tools/kmerstream",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Streaming algorithm for estimating the number of distinct k-mers present in high throughput sequencing data.",
                "homepage": "https://github.com/pmelsted/KmerStream"
            }
        ],
        "inputs": [
            "min_read_length_and_raw_fastqs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "scaffolds"
        ],
        "nb_outputs": 1,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "memory '4 GB'",
            "tag { pair_id }"
        ],
        "when": "",
        "stub": ""
    },
    "filter_scaffolds": {
        "name_process": "filter_scaffolds",
        "string_process": "\nprocess filter_scaffolds {\n  tag { pair_id }\n\n  input:\n  set pair_id, file(scaffold_file) from scaffolds\n\n  output:\n  set pair_id, file(\"${pair_id}_scaffolds.fasta\") into scaffolds_for_single_analysis, scaffolds_for_qc\n  file(\"${pair_id}_scaffolds.fasta\") into scaffolds_for_combined_analysis\n  \n  \"\"\"\n  contig-tools filter -l ${minimum_scaffold_length} -c ${minimum_scaffold_depth} -f ${scaffold_file}\n  ln -s scaffolds.filter_gt_${minimum_scaffold_length}bp_gt_${minimum_scaffold_depth}.0cov.fasta ${pair_id}_scaffolds.fasta\n  \"\"\"\n\n}",
        "nb_lignes_process": 15,
        "string_script": "\"\"\"\n  contig-tools filter -l ${minimum_scaffold_length} -c ${minimum_scaffold_depth} -f ${scaffold_file}\n  ln -s scaffolds.filter_gt_${minimum_scaffold_length}bp_gt_${minimum_scaffold_depth}.0cov.fasta ${pair_id}_scaffolds.fasta\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffolds"
        ],
        "nb_inputs": 1,
        "outputs": [
            "scaffolds_for_single_analysis",
            "scaffolds_for_qc",
            "scaffolds_for_combined_analysis"
        ],
        "nb_outputs": 3,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }"
        ],
        "when": "",
        "stub": ""
    },
    "quast": {
        "name_process": "quast",
        "string_process": "\nprocess quast {\n  tag { pair_id }\n    \n  publishDir \"${output_dir}/quast\",\n    mode: 'copy',\n    pattern: \"report.tsv\",\n    saveAs: { file -> \"${pair_id}_quast_\" + file.split('\\\\/')[-1] }\n\n  input:\n  set pair_id, file(contig_file) from scaffolds_for_single_analysis\n\n  output:\n  set pair_id, file(\"${pair_id}\") into quast_files_for_multiqc\n  set pair_id, file(\"${pair_id}/report.tsv\") into quast_files_for_qualifyr\n\n  \"\"\"\n  quast.py ${contig_file} -o .\n  mkdir ${pair_id}\n  ln -s \\$PWD/report.tsv ${pair_id}/report.tsv\n  \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "\"\"\"\n  quast.py ${contig_file} -o .\n  mkdir ${pair_id}\n  ln -s \\$PWD/report.tsv ${pair_id}/report.tsv\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffolds_for_single_analysis"
        ],
        "nb_inputs": 1,
        "outputs": [
            "quast_files_for_multiqc",
            "quast_files_for_qualifyr"
        ],
        "nb_outputs": 2,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }",
            "publishDir \"${output_dir}/quast\" , mode: 'copy' , pattern: \"report.tsv\" , saveAs: { file -> \"${pair_id}_quast_\" + file.split(' /')[-1] }"
        ],
        "when": "",
        "stub": ""
    },
    "quast_summary": {
        "name_process": "quast_summary",
        "string_process": "\nprocess quast_summary {\n  tag { 'quast summary' }\n  memory '4 GB'\n  \n  publishDir \"${output_dir}/quast\",\n    mode: 'copy',\n    pattern: \"*report.tsv\",\n    saveAs: { file -> \"combined_${file}\"}\n\n  input:\n  file(contig_files) from scaffolds_for_combined_analysis.toSortedList{ it.getBaseName() }\n\n  output:\n  file(\"*report.tsv\")\n\n  \"\"\"\n  quast.py ${contig_files} -o .\n  \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "\"\"\"\n  quast.py ${contig_files} -o .\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffolds_for_combined_analysis"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { 'quast summary' }",
            "memory '4 GB'",
            "publishDir \"${output_dir}/quast\" , mode: 'copy' , pattern: \"*report.tsv\" , saveAs: { file -> \"combined_${file}\"}"
        ],
        "when": "",
        "stub": ""
    },
    "quast_multiqc": {
        "name_process": "quast_multiqc",
        "string_process": "\nprocess quast_multiqc {\n  tag { 'multiqc for quast' }\n\n  publishDir \"${output_dir}/quality_reports\",\n    mode: 'copy',\n    pattern: \"multiqc_report.html\",\n    saveAs: { \"quast_multiqc_report.html\" }\n\n  input:\n  file(quast_reports) from quast_files_for_multiqc.collect { it }\n\n  output:\n  file(\"multiqc_report.html\")\n\n  script:\n  \"\"\"\n  multiqc .\n  \"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  multiqc .\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "quast_files_for_multiqc"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { 'multiqc for quast' }",
            "publishDir \"${output_dir}/quality_reports\" , mode: 'copy' , pattern: \"multiqc_report.html\" , saveAs: { \"quast_multiqc_report.html\" }"
        ],
        "when": "",
        "stub": ""
    },
    "overall_quality": {
        "name_process": "overall_quality",
        "string_process": " process overall_quality {\n    tag { pair_id }\n\n\n    publishDir \"${output_dir}/assemblies/pass\",\n      mode: 'copy',\n      pattern: 'assemblies/pass/*',\n      saveAs: { file -> file.split('\\\\/')[-1] }\n\n    publishDir \"${output_dir}/assemblies/warning\",\n      mode: 'copy',\n      pattern: 'assemblies/warning/*',\n      saveAs: { file -> file.split('\\\\/')[-1] }\n    \n    publishDir \"${output_dir}/assemblies/failure\",\n      mode: 'copy',\n      pattern: 'assemblies/failure/*',\n      saveAs: { file -> file.split('\\\\/')[-1] }\n\n    input:\n    file(qc_conditions_yml)\n    set pair_id, file(fastqc_report_r1), file(fastqc_report_r2), file(confindr_report), file(quast_report), file(scaffold_file) from quality_files\n\n    output:\n    file('assemblies/**/*')\n    file(\"${pair_id}.qualifyr.json\") into qualifyr_json_files\n\n\n    \"\"\"\n    result=`qualifyr check -y ${qc_conditions_yml} -f ${fastqc_report_r1} ${fastqc_report_r2} -c ${confindr_report}  -q ${quast_report} -s ${pair_id} 2> ERR`\n    return_code=\\$?\n    if [[ \\$return_code -ne 0 ]]; then\n      exit 1;\n    else\n      if [[ \\$result == \"PASS\" ]]; then\n        qc_level=\"pass\"\n      elif [[ \\$result == \"WARNING\" ]]; then\n        qc_level=\"warning\"\n      elif [[ \\$result == \"FAILURE\" ]]; then\n        qc_level=\"failure\"\n      fi\n      mkdir -p assemblies/\\${qc_level}\n      mv ${scaffold_file} assemblies/\\${qc_level}/\n\n      if [[ \\$result != \"PASS\" ]]; then\n        mv ERR assemblies/\\${qc_level}/${pair_id}_qc_result.tsv\n      fi\n    fi\n    # make json file\n    qualifyr check -y ${qc_conditions_yml} -f ${fastqc_report_r1} ${fastqc_report_r2} -c ${confindr_report}  -q ${quast_report} -s ${pair_id} -j -o .\n    \"\"\"\n  }",
        "nb_lignes_process": 50,
        "string_script": "\"\"\"\n    result=`qualifyr check -y ${qc_conditions_yml} -f ${fastqc_report_r1} ${fastqc_report_r2} -c ${confindr_report}  -q ${quast_report} -s ${pair_id} 2> ERR`\n    return_code=\\$?\n    if [[ \\$return_code -ne 0 ]]; then\n      exit 1;\n    else\n      if [[ \\$result == \"PASS\" ]]; then\n        qc_level=\"pass\"\n      elif [[ \\$result == \"WARNING\" ]]; then\n        qc_level=\"warning\"\n      elif [[ \\$result == \"FAILURE\" ]]; then\n        qc_level=\"failure\"\n      fi\n      mkdir -p assemblies/\\${qc_level}\n      mv ${scaffold_file} assemblies/\\${qc_level}/\n\n      if [[ \\$result != \"PASS\" ]]; then\n        mv ERR assemblies/\\${qc_level}/${pair_id}_qc_result.tsv\n      fi\n    fi\n    # make json file\n    qualifyr check -y ${qc_conditions_yml} -f ${fastqc_report_r1} ${fastqc_report_r2} -c ${confindr_report}  -q ${quast_report} -s ${pair_id} -j -o .\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qc_conditions_yml",
            "quality_files"
        ],
        "nb_inputs": 2,
        "outputs": [
            "qualifyr_json_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }",
            "publishDir \"${output_dir}/assemblies/pass\" , mode: 'copy' , pattern: 'assemblies/pass/*' , saveAs: { file -> file.split(' /')[-1] }",
            "publishDir \"${output_dir}/assemblies/warning\" , mode: 'copy' , pattern: 'assemblies/warning/*' , saveAs: { file -> file.split(' /')[-1] }",
            "publishDir \"${output_dir}/assemblies/failure\" , mode: 'copy' , pattern: 'assemblies/failure/*' , saveAs: { file -> file.split(' /')[-1] }"
        ],
        "when": "",
        "stub": ""
    },
    "write_assembly_to_dir": {
        "name_process": "write_assembly_to_dir",
        "string_process": " process write_assembly_to_dir {\n    tag { pair_id }\n\n    publishDir \"${output_dir}\",\n      mode: 'copy'\n\n    input:\n    set pair_id, file(scaffold_file) from scaffolds_for_qc\n\n    output:\n    file(\"assemblies/${scaffold_file}\")\n\n    \"\"\"\n    mkdir assemblies\n    mv ${scaffold_file} assemblies/\n    \"\"\"\n\n  }",
        "nb_lignes_process": 16,
        "string_script": "\"\"\"\n    mkdir assemblies\n    mv ${scaffold_file} assemblies/\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scaffolds_for_qc"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { pair_id }",
            "publishDir \"${output_dir}\" , mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "qualifyr_report": {
        "name_process": "qualifyr_report",
        "string_process": "\nprocess qualifyr_report {\n  tag { 'qualifyr report' }\n\n  publishDir \"${output_dir}/quality_reports\",\n    mode: 'copy',\n    pattern: \"qualifyr_report.html\"\n\n  input:\n  \n  file(json_files) from qualifyr_json_files.collect { it }\n\n  output:\n  file(\"qualifyr_report.html\")\n\n  script:\n  \"\"\"\n  qualifyr report -i . -c 'quast.N50,quast.# contigs (>= 1000 bp),confindr.contam_status'\n  \"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  qualifyr report -i . -c 'quast.N50,quast.# contigs (>= 1000 bp),confindr.contam_status'\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qualifyr_json_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "antunderwood__nextflow-aws-batch-issue-1024",
        "directive": [
            "tag { 'qualifyr report' }",
            "publishDir \"${output_dir}/quality_reports\" , mode: 'copy' , pattern: \"qualifyr_report.html\""
        ],
        "when": "",
        "stub": ""
    }
}