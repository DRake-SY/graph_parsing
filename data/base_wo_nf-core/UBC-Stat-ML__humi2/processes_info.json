{
    "buildCode": {
        "name_process": "buildCode",
        "string_process": "\nprocess buildCode {\n  cache true \n  input:\n    val gitRepoName from 'nowellpack'\n    val gitUser from 'UBC-Stat-ML'\n    val codeRevision from '5b84c0aa2255c4cb932517bf16b52656e0a1eadc'\n    val snapshotPath from \"${System.getProperty('user.home')}/w/nowellpack\"\n  output:\n    file 'code' into code\n  script:\n    template 'buildRepo.sh' \n}",
        "nb_lignes_process": 11,
        "string_script": "    template 'buildRepo.sh'",
        "nb_lignes_script": 0,
        "language_script": "bash",
        "tools": [
            "docxtemplate"
        ],
        "tools_url": [
            "https://bio.tools/docxtemplate"
        ],
        "tools_dico": [
            {
                "name": "docxtemplate",
                "uri": "https://bio.tools/docxtemplate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3314",
                            "term": "Chemistry"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0322",
                                    "term": "Molecular model refinement"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Phenix', 'restraints', 'Amber', 'refinement' | Improved chemistry restraints for crystallographic refinement by integrating the Amber force field into Phenix | Word templates and tools for Windows | The IUCr Word templates utilize the content management features and document styles of Word to format your manuscript and to store essential details for submission of your manuscript",
                "homepage": "http://journals.iucr.org/services/docxtemplate/"
            }
        ],
        "inputs": [
            "'nowellpack'",
            "'UBC-Stat-ML'",
            "'5b84c0aa2255c4cb932517bf16b52656e0a1eadc'",
            "\"${System"
        ],
        "nb_inputs": 4,
        "outputs": [
            "code"
        ],
        "nb_outputs": 1,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [
            "cache true"
        ],
        "when": "",
        "stub": ""
    },
    "pullDockerImages": {
        "name_process": "pullDockerImages",
        "string_process": "\nprocess pullDockerImages {\n  container 'cgrlab/tidyverse'\n  executor 'local'\n  scratch false\n  \"\"\"\n  echo OK\n  \"\"\"\n}",
        "nb_lignes_process": 7,
        "string_script": "\"\"\"\n  echo OK\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [
            "container 'cgrlab/tidyverse'",
            "executor 'local'",
            "scratch false"
        ],
        "when": "",
        "stub": ""
    },
    "run": {
        "name_process": "run",
        "string_process": "\nprocess run {\n\n                                 \n           \n                   \n                  \n               \n\n  input:\n    file code\n    each model from models\n    each expSize from expSizes\n  output:\n    file \"${model}_${expSize}\" into runs\n  publishDir runsDir, mode: 'link'\n\"\"\"\n  java -cp code/lib/\\\\* -Xmx5g $model   \\\n           --model.initialPopCounts.dataSource $pwd/data/$params.dataset/initial.csv \\\n           --model.initialPopCounts.name counts  \\\n           --model.data.source $pwd/data/$params.dataset/final.csv \\\n           --model.data.genes.name gene     \\\n           --model.data.targets.name sgRNA     \\\n           --model.data.targets.maxSize $params.nTargets \\\n           --model.data.experiments.name dataset     \\\n           --model.data.experiments.maxSize $expSize \\\n           --model.data.histograms.name histogram     \\\n           --engine.nScans $params.nScans   \\\n           --engine.nChains 1 \\\n           --engine.nPassesPerScan 1     \\\n           --engine.nThreads Fixed     \\\n           --engine.nThreads.number 1 \\\n           --engine.scmInit.nParticles $params.nInitParticles \\\n           --engine.scmInit.temperatureSchedule.threshold 0.9 \\\n           --engine.scmInit.nThreads Fixed \\\n           --engine.scmInit.nThreads.number 1 \\\n           --postProcessor humi.HumiPostProcessor \\\n           --postProcessor.data.targets.name sgRNA \\\n           --postProcessor.data.genes.name gene \\\n           --postProcessor.data.experiments.name dataset \\\n           --postProcessor.data.histograms.name histogram \\\n           --postProcessor.runPxviz false\n  mv results/all/`ls results/all` ${model}_${expSize}\n  \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "\"\"\"\n  java -cp code/lib/\\\\* -Xmx5g $model   \\\n           --model.initialPopCounts.dataSource $pwd/data/$params.dataset/initial.csv \\\n           --model.initialPopCounts.name counts  \\\n           --model.data.source $pwd/data/$params.dataset/final.csv \\\n           --model.data.genes.name gene     \\\n           --model.data.targets.name sgRNA     \\\n           --model.data.targets.maxSize $params.nTargets \\\n           --model.data.experiments.name dataset     \\\n           --model.data.experiments.maxSize $expSize \\\n           --model.data.histograms.name histogram     \\\n           --engine.nScans $params.nScans   \\\n           --engine.nChains 1 \\\n           --engine.nPassesPerScan 1     \\\n           --engine.nThreads Fixed     \\\n           --engine.nThreads.number 1 \\\n           --engine.scmInit.nParticles $params.nInitParticles \\\n           --engine.scmInit.temperatureSchedule.threshold 0.9 \\\n           --engine.scmInit.nThreads Fixed \\\n           --engine.scmInit.nThreads.number 1 \\\n           --postProcessor humi.HumiPostProcessor \\\n           --postProcessor.data.targets.name sgRNA \\\n           --postProcessor.data.genes.name gene \\\n           --postProcessor.data.experiments.name dataset \\\n           --postProcessor.data.histograms.name histogram \\\n           --postProcessor.runPxviz false\n  mv results/all/`ls results/all` ${model}_${expSize}\n  \"\"\"",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "code",
            "models",
            "expSizes"
        ],
        "nb_inputs": 3,
        "outputs": [
            "runs publishDir runsDir",
            "mode"
        ],
        "nb_outputs": 2,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "analysisCode": {
        "name_process": "analysisCode",
        "string_process": "\nprocess analysisCode {\n  input:\n    val gitRepoName from 'nedry'\n    val gitUser from 'alexandrebouchard'\n    val codeRevision from 'cf1a17574f19f22c4caf6878669df921df27c868'\n    val snapshotPath from \"${System.getProperty('user.home')}/w/nedry\"\n  output:\n    file 'code' into analysisCode\n  script:\n    template 'buildRepo.sh'\n}",
        "nb_lignes_process": 10,
        "string_script": "    template 'buildRepo.sh'",
        "nb_lignes_script": 0,
        "language_script": "bash",
        "tools": [
            "docxtemplate"
        ],
        "tools_url": [
            "https://bio.tools/docxtemplate"
        ],
        "tools_dico": [
            {
                "name": "docxtemplate",
                "uri": "https://bio.tools/docxtemplate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3314",
                            "term": "Chemistry"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0322",
                                    "term": "Molecular model refinement"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Phenix', 'restraints', 'Amber', 'refinement' | Improved chemistry restraints for crystallographic refinement by integrating the Amber force field into Phenix | Word templates and tools for Windows | The IUCr Word templates utilize the content management features and document styles of Word to format your manuscript and to store essential details for submission of your manuscript",
                "homepage": "http://journals.iucr.org/services/docxtemplate/"
            }
        ],
        "inputs": [
            "'nedry'",
            "'alexandrebouchard'",
            "'cf1a17574f19f22c4caf6878669df921df27c868'",
            "\"${System"
        ],
        "nb_inputs": 4,
        "outputs": [
            "analysisCode"
        ],
        "nb_outputs": 1,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "aggregate": {
        "name_process": "aggregate",
        "string_process": "\nprocess aggregate {\n  input:\n    file analysisCode\n    file 'exec_*' from runs.toList()\n  output:\n    file 'results/latest/aggregated' into aggregated\n  \"\"\"\n  code/bin/aggregate \\\n    --dataPathInEachExecFolder gof.csv \\\n    --keys \\\n      model.data.experiments.maxSize as nExperiments \\\n      model \\\n        from arguments.tsv\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\n  code/bin/aggregate \\\n    --dataPathInEachExecFolder gof.csv \\\n    --keys \\\n      model.data.experiments.maxSize as nExperiments \\\n      model \\\n        from arguments.tsv\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "MoDEL",
            "FROMP"
        ],
        "tools_url": [
            "https://bio.tools/model",
            "https://bio.tools/fromp"
        ],
        "tools_dico": [
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            },
            {
                "name": "FROMP",
                "uri": "https://bio.tools/fromp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2259",
                            "term": "Systems biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3660",
                                    "term": "Metabolic network modelling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3660",
                                    "term": "http://edamontology.org/Metabolic%20pathway%20modelling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software for mapping and visualizing enzyme annotations onto the Kyoto Encyclopedia of Genes and Genomes (KEGG) metabolic pathways or custom-made pathways and comparing the samples in terms of their Pathway Completeness Scores, their relative Activity Scores or enzyme enrichment odds ratios.",
                "homepage": "https://github.com/LaRocheLab/FROMP"
            }
        ],
        "inputs": [
            "analysisCode",
            "runs"
        ],
        "nb_inputs": 2,
        "outputs": [
            "aggregated"
        ],
        "nb_outputs": 1,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "plot": {
        "name_process": "plot",
        "string_process": "\nprocess plot {\n  input:\n    file aggregated\n    env SPARK_HOME from \"${System.getProperty('user.home')}/bin/spark-2.1.0-bin-hadoop2.7\"\n  output:\n    file '*.csv'\n    file '*.pdf'\n  publishDir deliverableDir, mode: 'copy', overwrite: true\n  afterScript 'rm -r metastore_db; rm derby.log'\n  \"\"\"\n  #!/usr/bin/env Rscript\n  require(\"ggplot2\")\n  require(\"stringr\")\n  library(SparkR, lib.loc = c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\")))\n  sparkR.session(master = \"local[*]\", sparkConfig = list(spark.driver.memory = \"4g\"))\n\n  data <- read.df(\"$aggregated\", \"csv\", header=\"true\", inferSchema=\"true\")\n  data <- collect(data)\n  \n  require(\"dplyr\")\n  \n  data\\$model <- str_replace_all(data\\$model, \"[\\$].*\", \"\")\n  data\\$model <- str_replace_all(data\\$model, \"humi[.]models[.]\", \"\")\n  \n  write.csv(data, file=\"gd-data.csv\")\n  \n  data <- data %>%\n    filter(gofStatistic != \"visibleCloneNumbers\") %>%\n    filter(referenceDataset == \"${params.lastDataset}\")\n    \n  p <- ggplot(data, aes(x=nExperiments, y=actualCoverage, colour = model, group = model)) + \n    geom_line() +\n    facet_grid(gofStatistic ~ ., scales=\"free\") + \n    geom_hline(yintercept=0.95) + \n    theme_bw() \n\n  ggsave(plot=p, file=\"generalization-coverage.pdf\")\n \n\n  p <- ggplot(data, aes(x=nExperiments, y=width, , colour = model, group = model)) + \n    geom_line() +\n    facet_grid(gofStatistic ~ ., scales=\"free\") + \n    theme_bw() \n\n  ggsave(plot=p, file=\"generalization-width.pdf\")  \n  \"\"\"\n}",
        "nb_lignes_process": 46,
        "string_script": "\"\"\"\n  #!/usr/bin/env Rscript\n  require(\"ggplot2\")\n  require(\"stringr\")\n  library(SparkR, lib.loc = c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\", \"lib\")))\n  sparkR.session(master = \"local[*]\", sparkConfig = list(spark.driver.memory = \"4g\"))\n\n  data <- read.df(\"$aggregated\", \"csv\", header=\"true\", inferSchema=\"true\")\n  data <- collect(data)\n  \n  require(\"dplyr\")\n  \n  data\\$model <- str_replace_all(data\\$model, \"[\\$].*\", \"\")\n  data\\$model <- str_replace_all(data\\$model, \"humi[.]models[.]\", \"\")\n  \n  write.csv(data, file=\"gd-data.csv\")\n  \n  data <- data %>%\n    filter(gofStatistic != \"visibleCloneNumbers\") %>%\n    filter(referenceDataset == \"${params.lastDataset}\")\n    \n  p <- ggplot(data, aes(x=nExperiments, y=actualCoverage, colour = model, group = model)) + \n    geom_line() +\n    facet_grid(gofStatistic ~ ., scales=\"free\") + \n    geom_hline(yintercept=0.95) + \n    theme_bw() \n\n  ggsave(plot=p, file=\"generalization-coverage.pdf\")\n \n\n  p <- ggplot(data, aes(x=nExperiments, y=width, , colour = model, group = model)) + \n    geom_line() +\n    facet_grid(gofStatistic ~ ., scales=\"free\") + \n    theme_bw() \n\n  ggsave(plot=p, file=\"generalization-width.pdf\")  \n  \"\"\"",
        "nb_lignes_script": 36,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "aggregated",
            "\"${System"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "posets": {
        "name_process": "posets",
        "string_process": "\nprocess posets {\n  input:\n    file code\n    file 'exec_*' from runs.toList()\n  output:\n    file \"*.dot\"\n  publishDir posetsDir, mode: 'copy', overwrite: true\n  \"\"\"\n  nDirectories=`ls | grep exec | wc -l`\n  for ((i = 1 ; i <= \\$nDirectories ; i++))  \n  do\n    exec1=exec_\\$i\n    cond1=`ls \\$exec1 | grep condition | sed 's/condition[_]//'`\n    java -cp code/lib/\\\\* -Xmx1g humi.posets.Intervals2Poset \\\n      --intervalsCSVFile \\$exec1/estimates.csv\n    mv results/latest/hasse.dot \\$cond1.dot\n    for ((j = \\$i + 1 ; j <= \\$nDirectories ; j++))\n    do\n      exec2=exec_\\$j\n      cond2=`ls \\$exec2 | grep condition | sed 's/condition[_]//'`\n      java -cp code/lib/\\\\* -Xmx1g humi.posets.ComparePosets \\\n        --condition1.intervalsCSVFile \\$exec1/estimates.csv \\\n        --condition2.intervalsCSVFile \\$exec2/estimates.csv \\\n        --condition1Label \\$cond1 \\\n        --condition2Label \\$cond2\n      mv results/latest/\\$cond1.dot compare_\\${cond1}_\\${cond2}_\\$cond1.dot\n      mv results/latest/\\$cond2.dot compare_\\${cond1}_\\${cond2}_\\$cond2.dot\n    done\n  done\n  \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "\"\"\"\n  nDirectories=`ls | grep exec | wc -l`\n  for ((i = 1 ; i <= \\$nDirectories ; i++))  \n  do\n    exec1=exec_\\$i\n    cond1=`ls \\$exec1 | grep condition | sed 's/condition[_]//'`\n    java -cp code/lib/\\\\* -Xmx1g humi.posets.Intervals2Poset \\\n      --intervalsCSVFile \\$exec1/estimates.csv\n    mv results/latest/hasse.dot \\$cond1.dot\n    for ((j = \\$i + 1 ; j <= \\$nDirectories ; j++))\n    do\n      exec2=exec_\\$j\n      cond2=`ls \\$exec2 | grep condition | sed 's/condition[_]//'`\n      java -cp code/lib/\\\\* -Xmx1g humi.posets.ComparePosets \\\n        --condition1.intervalsCSVFile \\$exec1/estimates.csv \\\n        --condition2.intervalsCSVFile \\$exec2/estimates.csv \\\n        --condition1Label \\$cond1 \\\n        --condition2Label \\$cond2\n      mv results/latest/\\$cond1.dot compare_\\${cond1}_\\${cond2}_\\$cond1.dot\n      mv results/latest/\\$cond2.dot compare_\\${cond1}_\\${cond2}_\\$cond2.dot\n    done\n  done\n  \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "code",
            "runs"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "summarizePipeline": {
        "name_process": "summarizePipeline",
        "string_process": "\nprocess summarizePipeline {\n  cache false \n  output:\n      file 'pipeline-info.txt'\n  publishDir deliverableDir, mode: 'copy', overwrite: true\n  \"\"\"\n  echo 'scriptName: $workflow.scriptName' >> pipeline-info.txt\n  echo 'start: $workflow.start' >> pipeline-info.txt\n  echo 'runName: $workflow.runName' >> pipeline-info.txt\n  echo 'nextflow.version: $workflow.nextflow.version' >> pipeline-info.txt\n  \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "\"\"\"\n  echo 'scriptName: $workflow.scriptName' >> pipeline-info.txt\n  echo 'start: $workflow.start' >> pipeline-info.txt\n  echo 'runName: $workflow.runName' >> pipeline-info.txt\n  echo 'nextflow.version: $workflow.nextflow.version' >> pipeline-info.txt\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "UBC-Stat-ML__humi2",
        "directive": [
            "cache false"
        ],
        "when": "",
        "stub": ""
    }
}