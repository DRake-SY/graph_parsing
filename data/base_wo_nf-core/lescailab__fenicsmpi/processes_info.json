{
    "FENICS_COMPUTE": {
        "name_process": "FENICS_COMPUTE",
        "string_process": "\nprocess FENICS_COMPUTE {\n    tag \"${inputs.name}\"\n    label 'process_high'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"conda-forge::fenics\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"library://nibscles/default/unipv:fenicsproject\"\n    } else {\n        container \"quay.io/fenicsproject/stable:latest\"\n    }\n\n                    \n\n    input:\n    val(inputs)\n\n    output:\n                            \"./images/*/*.h5\"                           \n    path(\"${params.outdir}/*.xdmf\"), emit: xdmf\n    path(\"*.out\"), emit: results\n\n    script:\n    def prefix   = \"${inputs.name}\"                                                  \n\n    \"\"\"\n    #!/bin/bash\n\n    sh ${moduleDir}/simulate_and_clean.sh ${inputs.cores} ${moduleDir} ${inputs.degree} ${inputs.method} ${inputs.stress} ${params.mesh} ${params.outdir} ${prefix}.out\n    \"\"\"\n    \n      \"\"\"\n//    OUTFILE=${prefix}.out\n//    mpirun -np ${inputs.cores} python3 ${moduleDir}/Mechanics.py \"${inputs.degree}\" \"${inputs.method}\" \"${inputs.stress}\" \"${params.mesh}\" \"${params.outdir}\" > TEMP\n//\n//    //DOFS=\\$(grep 'Dofs' TEMP | sed -E 's/.*Dofs = ([0-9]+).*/\\1/g')\n//    //grep 'nonlinear' TEMP | sed -E 's/.*in ([0-9]+) nonlinear.*/\\1/g' > NL_ITS\n//    //grep 'nonlinear' TEMP | sed -E 's/.* ([0-9]+\\.[0-9]+)s.*/\\1/g' > TIMES\n//    //NL_IT=\\$(python3 ${moduleDir}/column_average.py NL_ITS)\n//    //TIME=\\$(python3 ${moduleDir}/column_average.py TIMES)\n//    //echo \\$DOFS,\\$NL_IT,\\$TIME > \\$OUTFILE\n//    //rm TEMP DOFS NL_ITS TIMES\n//    \"\"\"\n\n\n}",
        "nb_lignes_process": 47,
        "string_script": "    def prefix   = \"${inputs.name}\"                                                  \n\n    \"\"\"\n    #!/bin/bash\n\n    sh ${moduleDir}/simulate_and_clean.sh ${inputs.cores} ${moduleDir} ${inputs.degree} ${inputs.method} ${inputs.stress} ${params.mesh} ${params.outdir} ${prefix}.out\n    \"\"\"\n    \n      \"\"\"\n//    OUTFILE=${prefix}.out\n//    mpirun -np ${inputs.cores} python3 ${moduleDir}/Mechanics.py \"${inputs.degree}\" \"${inputs.method}\" \"${inputs.stress}\" \"${params.mesh}\" \"${params.outdir}\" > TEMP\n//\n//    //DOFS=\\$(grep 'Dofs' TEMP | sed -E 's/.*Dofs = ([0-9]+).*/\\1/g')\n//    //grep 'nonlinear' TEMP | sed -E 's/.*in ([0-9]+) nonlinear.*/\\1/g' > NL_ITS\n//    //grep 'nonlinear' TEMP | sed -E 's/.* ([0-9]+\\.[0-9]+)s.*/\\1/g' > TIMES\n//    //NL_IT=\\$(python3 ${moduleDir}/column_average.py NL_ITS)\n//    //TIME=\\$(python3 ${moduleDir}/column_average.py TIMES)\n//    //echo \\$DOFS,\\$NL_IT,\\$TIME > \\$OUTFILE\n//    //rm TEMP DOFS NL_ITS TIMES\n//    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "RASH",
            "TEMP",
            "TimeScape"
        ],
        "tools_url": [
            "https://bio.tools/RASH",
            "https://bio.tools/temp",
            "https://bio.tools/timescape"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            },
            {
                "name": "TEMP",
                "uri": "https://bio.tools/temp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0427",
                                    "term": "Transposon prediction"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A software package for detecting transposable elements (TEs) insertions and excisions from pooled high-throughput sequencing data.",
                "homepage": "https://github.com/JialiUMassWengLab/TEMP"
            },
            {
                "name": "TimeScape",
                "uri": "https://bio.tools/timescape",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0567",
                                    "term": "Phylogenetic tree visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2497",
                                    "term": "Pathway or network analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0567",
                                    "term": "Phylogenetic tree rendering"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0920",
                                "term": "Genotype/phenotype report"
                            },
                            {
                                "uri": "http://edamontology.org/data_2523",
                                "term": "Phylogenetic data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2884",
                                "term": "Plot"
                            }
                        ]
                    }
                ],
                "description": "a tool from E-scape suite for visualizing clonal dynamics over time.",
                "homepage": "https://bioconductor.org/packages/release/bioc/html/timescape.html"
            }
        ],
        "inputs": [
            "inputs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lescailab__fenicsmpi",
        "directive": [
            "tag \"${inputs.name}\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"conda-forge::fenics\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"library://nibscles/default/unipv:fenicsproject\" } else { container \"quay.io/fenicsproject/stable:latest\" }"
        ],
        "when": "",
        "stub": ""
    },
    "FENICS_REPORT": {
        "name_process": "FENICS_REPORT",
        "string_process": "\nprocess FENICS_REPORT {\n    tag \"$inputs.name\"\n    label 'process_low'\n    publishDir \"${params.outdir}\",\n        mode: params.publish_dir_mode,\n        saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }\n\n    conda (params.enable_conda ? \"conda-forge::fenics\" : null)\n    if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) {\n        container \"library://nibscles/default/unipv:fenicsproject\"\n    } else {\n        container \"quay.io/fenicsproject/stable:latest\"\n    }\n\n    input:\n    val inputs\n    path results\n                \n\n             \n\n    script:\n    def prefix = inputs.name\n                              \n                                \n\n\n    \"\"\"\n    python ${moduleDir}/filter_csv.py \"${results}\"  \"${projectDir}/results\"\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    def prefix = inputs.name\n                              \n                                \n\n\n    \"\"\"\n    python ${moduleDir}/filter_csv.py \"${results}\"  \"${projectDir}/results\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "inputs",
            "results"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lescailab__fenicsmpi",
        "directive": [
            "tag \"$inputs.name\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}\" , mode: params.publish_dir_mode , saveAs: { filename -> saveFiles(filename:filename, options:params.options, publish_dir:getSoftwareName(task.process), meta:meta, publish_by_meta:['id']) }",
            "conda (params.enable_conda ? \"conda-forge::fenics\" : null) if (workflow.containerEngine == 'singularity' && !params.singularity_pull_docker_container) { container \"library://nibscles/default/unipv:fenicsproject\" } else { container \"quay.io/fenicsproject/stable:latest\" }"
        ],
        "when": "",
        "stub": ""
    }
}