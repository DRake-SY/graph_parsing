{
    "makeBED12": {
        "name_process": "makeBED12",
        "string_process": "\nprocess makeBED12 {\n    label 'build_index'\n    tag \"gtf2bed12\"\n    publishDir path: { params.saveReference ? \"${params.outdir}/Genome/reference_genome\" : params.outdir },\n                saveAs: { params.saveReference ? it : null }, mode: 'copy'\n\n    when:\n    !params.skip_qc && !params.skip_rseqc\n\n    input:\n    file gtf\n    \n    output:\n    file \"${gtf.baseName}.bed\" into bed12file\n\n    shell:      \n    '''\n    gtf_file=!{gtf}\n    gtfToGenePred -ignoreGroupsWithoutExons -genePredExt -geneNameAsName2 $gtf_file ${gtf_file/.gtf/.tmp}\n    genePredToBed ${gtf_file/.gtf/.tmp} ${gtf_file/.gtf/.bed}\n    '''\n}",
        "nb_lignes_process": 21,
        "string_script": "    '''\n    gtf_file=!{gtf}\n    gtfToGenePred -ignoreGroupsWithoutExons -genePredExt -geneNameAsName2 $gtf_file ${gtf_file/.gtf/.tmp}\n    genePredToBed ${gtf_file/.gtf/.tmp} ${gtf_file/.gtf/.bed}\n    '''",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gtf"
        ],
        "nb_inputs": 1,
        "outputs": [
            "bed12file"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'build_index'",
            "tag \"gtf2bed12\"",
            "publishDir path: { params.saveReference ? \"${params.outdir}/Genome/reference_genome\" : params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "!params.skip_qc && !params.skip_rseqc",
        "stub": ""
    },
    "MakeTophat2Index": {
        "name_process": "MakeTophat2Index",
        "string_process": " process MakeTophat2Index {\n        label 'build_index'\n        tag \"tophat2_index\"\n        publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\": params.outdir },\n                   saveAs: { params.saveReference ? it : null }, mode: 'copy'\n        input:\n        file fasta\n\n        output:\n        file \"Tophat2Index/*\" into tophat2_index\n\n        when:\n        aligner == \"tophat2\"\n\n        script:\n        tophat2_index = \"Tophat2Index/\" + fasta.baseName.toString()\n        \"\"\"\n        mkdir Tophat2Index\n        ln $fasta Tophat2Index\n        bowtie2-build -f $fasta $tophat2_index\n        \"\"\"\n    }",
        "nb_lignes_process": 20,
        "string_script": "        tophat2_index = \"Tophat2Index/\" + fasta.baseName.toString()\n        \"\"\"\n        mkdir Tophat2Index\n        ln $fasta Tophat2Index\n        bowtie2-build -f $fasta $tophat2_index\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tophat2_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'build_index'",
            "tag \"tophat2_index\"",
            "publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\": params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "aligner == \"tophat2\"",
        "stub": ""
    },
    "MakeHisat2Index": {
        "name_process": "MakeHisat2Index",
        "string_process": " process MakeHisat2Index {\n        label 'build_index'\n        tag \"hisat2_index\"\n        publishDir path: { params.saveReference ? \"${params.outdir}/Genome/ \" : params.outdir },\n                   saveAs: { params.saveReference ? it : null }, mode: 'copy'        \n        input:\n        file fasta\n        file gtf\n\n        output:\n        file \"Hisat2Index/*\" into hisat2_index\n\n        when:\n        aligner == \"hisat2\"\n        \n        script:\n        \"\"\"\n        mkdir Hisat2Index\n        hisat2_extract_exons.py $gtf > Hisat2Index/${fasta.baseName}.exon\n        hisat2_extract_splice_sites.py $gtf > Hisat2Index/${fasta.baseName}.ss\n        hisat2-build -p ${task.cpus} -f $fasta --exon Hisat2Index/${fasta.baseName}.exon --ss Hisat2Index/${fasta.baseName}.ss Hisat2Index/${fasta.baseName}\n        \"\"\"\n    }",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        mkdir Hisat2Index\n        hisat2_extract_exons.py $gtf > Hisat2Index/${fasta.baseName}.exon\n        hisat2_extract_splice_sites.py $gtf > Hisat2Index/${fasta.baseName}.ss\n        hisat2-build -p ${task.cpus} -f $fasta --exon Hisat2Index/${fasta.baseName}.exon --ss Hisat2Index/${fasta.baseName}.ss Hisat2Index/${fasta.baseName}\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "gtf"
        ],
        "nb_inputs": 2,
        "outputs": [
            "hisat2_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'build_index'",
            "tag \"hisat2_index\"",
            "publishDir path: { params.saveReference ? \"${params.outdir}/Genome/ \" : params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "aligner == \"hisat2\"",
        "stub": ""
    },
    "MakeBWAIndex": {
        "name_process": "MakeBWAIndex",
        "string_process": " process MakeBWAIndex {\n        label 'build_index'\n        tag \"bwa_index\"\n        publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\" : params.outdir },\n                   saveAs: { params.saveReference ? it : null }, mode: 'copy'\n\n        input:\n        file fasta\n\n        output:\n        file \"BWAIndex/*\" into bwa_index\n\n        when:\n        aligner == \"bwa\"\n     \n        script:\n        \"\"\"\n        mkdir BWAIndex\n        cd BWAIndex/\n        bwa index -p ${fasta.baseName} -a bwtsw ../$fasta\n        cd ../\n        \"\"\"\n    }",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        mkdir BWAIndex\n        cd BWAIndex/\n        bwa index -p ${fasta.baseName} -a bwtsw ../$fasta\n        cd ../\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "BWA"
        ],
        "tools_url": [
            "https://bio.tools/bwa"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            }
        ],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [
            "bwa_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'build_index'",
            "tag \"bwa_index\"",
            "publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\" : params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "aligner == \"bwa\"",
        "stub": ""
    },
    "MakeStarIndex": {
        "name_process": "MakeStarIndex",
        "string_process": " process MakeStarIndex {\n        label 'build_index'\n        tag \"star_index\"\n        publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\" : params.outdir },\n                   saveAs: { params.saveReference ? it : null }, mode: 'copy'\n        input:\n        file fasta\n        file gtf\n\n        output:\n        file \"StarIndex\" into star_index\n\n        when:\n        aligner == \"star\"\n\n        script:\n        readLength = 50\n        overhang = readLength - 1\n        \"\"\"\n        mkdir StarIndex\n        STAR --runThreadN ${task.cpus} \\\n        --runMode genomeGenerate \\\n        --genomeDir StarIndex \\\n        --genomeFastaFiles $fasta \\\n        --sjdbGTFfile $gtf \\\n        --sjdbOverhang $overhang \n        \"\"\"\n    }",
        "nb_lignes_process": 26,
        "string_script": "        readLength = 50\n        overhang = readLength - 1\n        \"\"\"\n        mkdir StarIndex\n        STAR --runThreadN ${task.cpus} \\\n        --runMode genomeGenerate \\\n        --genomeDir StarIndex \\\n        --genomeFastaFiles $fasta \\\n        --sjdbGTFfile $gtf \\\n        --sjdbOverhang $overhang \n        \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "fasta",
            "gtf"
        ],
        "nb_inputs": 2,
        "outputs": [
            "star_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'build_index'",
            "tag \"star_index\"",
            "publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\" : params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "aligner == \"star\"",
        "stub": ""
    },
    "MakerRNAindex": {
        "name_process": "MakerRNAindex",
        "string_process": "\nprocess MakerRNAindex {\n    label 'build_index'\n    tag \"rRNA_index\"\n    publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\" : params.outdir },\n                saveAs: { params.saveReference ? it : null }, mode: 'copy'\n    input:\n    file rRNA_fasta from rRNA_fasta\n\n    output:\n    file \"rRNAindex/*\" into rRNA_index\n\n    when:\n    params.rRNA_fasta && !params.skip_filterrRNA\n\n    script:\n    \"\"\"\n    mkdir rRNAindex\n    hisat2-build -p ${task.cpus} -f $rRNA_fasta rRNAindex/${rRNA_fasta.baseName}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir rRNAindex\n    hisat2-build -p ${task.cpus} -f $rRNA_fasta rRNAindex/${rRNA_fasta.baseName}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "rRNA_fasta"
        ],
        "nb_inputs": 1,
        "outputs": [
            "rRNA_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'build_index'",
            "tag \"rRNA_index\"",
            "publishDir path: { params.saveReference ? \"${params.outdir}/Genome/\" : params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "params.rRNA_fasta && !params.skip_filterrRNA",
        "stub": ""
    },
    "Fastp": {
        "name_process": "Fastp",
        "string_process": "\nprocess Fastp{\n    tag \"$sample_name\"\n                            \n    publishDir path: { params.skip_fastp ? params.outdir : \"${params.outdir}/QC/fastp\" },\n             saveAs: { params.skip_fastp ? null : it }, mode: 'link'\n        \n    input:\n    set sample_name, file(reads) from raw_data\n\n    output:\n    val sample_name into pair_id_fastqc, pair_id_tophat2, pair_id_hisat2, pair_id_bwa, pair_id_star, pair_id_rRNA\n    file \"*_aligners.fastq\" into fastqc_reads ,tophat2_reads, hisat2_reads, bwa_reads, star_reads, rRNA_reads\n    file \"*.{html,json}\" into fastp_results\n\n    when:\n    aligner != \"none\"\n\n    shell:\n    skip_fastp = params.skip_fastp\n    gzip = params.gzip\n    if ( params.single_end ){\n        filename = reads.toString() - ~/(\\.fq)?(\\.fastq)?(\\.gz)?$/\n        sample_name = filename\n        add_aligners = sample_name + \"_aligners.fastq\"\n        \"\"\"\n        if [ \\$(ls ${sample_name}*.gz | wc -w) -gt 0 && $gzip == \"false\" ]; \n            then echo \"Please check whether your data is compressed and add '--gzip' for running pipeline\"; \n            exit 1;\n        fi \n        if [ $gzip == \"true\" ]; then\n            zcat ${reads} > ${sample_name}.fastq\n        fi\n        if [ $skip_fastp == \"false\" ]; then\n            fastp -i ${sample_name}.fastq -o ${add_aligners} -j ${sample_name}_fastp.json -h ${sample_name}_fastp.html -w ${task.cpus}\n        else\n            mv ${sample_name}.fastq ${add_aligners}\n        fi\n        \"\"\"\n    } else {\n        filename = reads[0].toString() - ~/(_R[0-9])?(_[0-9])?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n        sample_name = filename\n        add_aligners_1 = sample_name + \"_1_aligners.fastq\"\n        add_aligners_2 = sample_name + \"_2_aligners.fastq\"\n        \"\"\"\n        if [ \\$(ls ${sample_name}*.gz | wc -w) -gt 0 && $gzip == \"false\" ];\n            then echo \"Please check whether your data is compressed and add '--gzip' for running pipeline\"; \n            exit 1;\n        fi \n        if [ $gzip == \"true\" ]; then\n            zcat ${reads[0]} > ${sample_name}_1.fastq\n            zcat ${reads[1]} > ${sample_name}_2.fastq\n        fi\n        if [ $skip_fastp == \"false\" ]; then  \n            fastp -i ${sample_name}*1.fastq -o ${add_aligners_1} -I ${sample_name}*2.fastq -O ${add_aligners_2} -j ${sample_name}_fastp.json -h ${sample_name}_fastp.html -w ${task.cpus}\n        else\n            mv ${sample_name}*1.fastq ${add_aligners_1}\n            mv ${sample_name}*2.fastq ${add_aligners_2}\n        fi\n        \"\"\"\n    } \n}",
        "nb_lignes_process": 60,
        "string_script": "    skip_fastp = params.skip_fastp\n    gzip = params.gzip\n    if ( params.single_end ){\n        filename = reads.toString() - ~/(\\.fq)?(\\.fastq)?(\\.gz)?$/\n        sample_name = filename\n        add_aligners = sample_name + \"_aligners.fastq\"\n        \"\"\"\n        if [ \\$(ls ${sample_name}*.gz | wc -w) -gt 0 && $gzip == \"false\" ]; \n            then echo \"Please check whether your data is compressed and add '--gzip' for running pipeline\"; \n            exit 1;\n        fi \n        if [ $gzip == \"true\" ]; then\n            zcat ${reads} > ${sample_name}.fastq\n        fi\n        if [ $skip_fastp == \"false\" ]; then\n            fastp -i ${sample_name}.fastq -o ${add_aligners} -j ${sample_name}_fastp.json -h ${sample_name}_fastp.html -w ${task.cpus}\n        else\n            mv ${sample_name}.fastq ${add_aligners}\n        fi\n        \"\"\"\n    } else {\n        filename = reads[0].toString() - ~/(_R[0-9])?(_[0-9])?(\\.fq)?(\\.fastq)?(\\.gz)?$/\n        sample_name = filename\n        add_aligners_1 = sample_name + \"_1_aligners.fastq\"\n        add_aligners_2 = sample_name + \"_2_aligners.fastq\"\n        \"\"\"\n        if [ \\$(ls ${sample_name}*.gz | wc -w) -gt 0 && $gzip == \"false\" ];\n            then echo \"Please check whether your data is compressed and add '--gzip' for running pipeline\"; \n            exit 1;\n        fi \n        if [ $gzip == \"true\" ]; then\n            zcat ${reads[0]} > ${sample_name}_1.fastq\n            zcat ${reads[1]} > ${sample_name}_2.fastq\n        fi\n        if [ $skip_fastp == \"false\" ]; then  \n            fastp -i ${sample_name}*1.fastq -o ${add_aligners_1} -I ${sample_name}*2.fastq -O ${add_aligners_2} -j ${sample_name}_fastp.json -h ${sample_name}_fastp.html -w ${task.cpus}\n        else\n            mv ${sample_name}*1.fastq ${add_aligners_1}\n            mv ${sample_name}*2.fastq ${add_aligners_2}\n        fi\n        \"\"\"\n    }",
        "nb_lignes_script": 41,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "raw_data"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pair_id_fastqc",
            "pair_id_tophat2",
            "pair_id_hisat2",
            "pair_id_bwa",
            "pair_id_star",
            "pair_id_rRNA",
            "fastqc_reads",
            "tophat2_reads",
            "hisat2_reads",
            "bwa_reads",
            "star_reads",
            "rRNA_reads",
            "fastp_results"
        ],
        "nb_outputs": 13,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "tag \"$sample_name\"",
            "publishDir path: { params.skip_fastp ? params.outdir : \"${params.outdir}/QC/fastp\" } , saveAs: { params.skip_fastp ? null : it }, mode: 'link'"
        ],
        "when": "aligner != \"none\"",
        "stub": ""
    },
    "Fastqc": {
        "name_process": "Fastqc",
        "string_process": "\nprocess Fastqc{\n    tag \"$sample_name\"\n    publishDir path: { params.skip_fastqc ? params.outdir : \"${params.outdir}/QC\" },\n             saveAs: { params.skip_fastqc ? null : it }, mode: 'link'\n\n    input:\n    val sample_name from pair_id_fastqc\n    file(reads) from fastqc_reads\n\n    output:\n    file \"fastqc/*\" into fastqc_results\n\n    when:\n    aligner != \"none\" && !params.skip_fastqc\n\n    shell:\n    skip_fastqc = params.skip_fastqc\n    if ( params.single_end ){\n        \"\"\"\n        mkdir fastqc\n        fastqc -o fastqc --noextract ${reads}\n        \"\"\"       \n    } else {\n        \"\"\"\n        mkdir fastqc   \n        fastqc -o fastqc --noextract ${reads[0]}\n        fastqc -o fastqc --noextract ${reads[1]}\n        \"\"\"      \n    }\n}",
        "nb_lignes_process": 29,
        "string_script": "    skip_fastqc = params.skip_fastqc\n    if ( params.single_end ){\n        \"\"\"\n        mkdir fastqc\n        fastqc -o fastqc --noextract ${reads}\n        \"\"\"       \n    } else {\n        \"\"\"\n        mkdir fastqc   \n        fastqc -o fastqc --noextract ${reads[0]}\n        fastqc -o fastqc --noextract ${reads[1]}\n        \"\"\"      \n    }",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "pair_id_fastqc",
            "fastqc_reads"
        ],
        "nb_inputs": 2,
        "outputs": [
            "fastqc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "tag \"$sample_name\"",
            "publishDir path: { params.skip_fastqc ? params.outdir : \"${params.outdir}/QC\" } , saveAs: { params.skip_fastqc ? null : it }, mode: 'link'"
        ],
        "when": "aligner != \"none\" && !params.skip_fastqc",
        "stub": ""
    },
    "Tophat2Align": {
        "name_process": "Tophat2Align",
        "string_process": "\nprocess Tophat2Align {\n    label 'aligners'\n    tag \"$sample_name\"\n    publishDir \"${params.outdir}/alignment/tophat2\", mode: 'link', overwrite: true\n\n    input:\n    val sample_name from pair_id_tophat2\n    file(reads) from tophat2_reads\n    file index from tophat2_index.collect()\n    file gtf\n\n    output:\n    file \"*_tophat2.bam\" into tophat2_bam\n    file \"*_log.txt\" into tophat2_log\n    \n    when:\n    aligner == \"tophat2\"\n\n    script:\n    index_base = index[0].toString() - ~/(\\.rev)?(\\.\\d)?(\\.fa)?(\\.bt2)?$/\n    strand_info = params.stranded == \"no\" ? \"fr-unstranded\" : params.stranded == \"reverse\" ? \"fr-secondstrand\" : \"fr-firststrand\"\n    if (params.single_end) {\n        \"\"\"\n        tophat  -p ${task.cpus} \\\n                -G $gtf \\\n                -o $sample_name \\\n                --no-novel-juncs \\\n                --library-type $strand_info \\\n                $index_base \\\n                $reads > ${sample_name}_log.txt\n        mv $sample_name/accepted_hits.bam ${sample_name}_tophat2.bam\n        \"\"\"\n    } else {\n        \"\"\"\n        tophat -p ${task.cpus} \\\n                -G $gtf \\\n                -o $sample_name \\\n                --no-novel-juncs \\\n                --library-type $strand_info \\\n                $index_base \\\n                ${reads[0]} ${reads[1]} > ${sample_name}_log.txt\n        mv $sample_name/accepted_hits.bam ${sample_name}_tophat2.bam\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 44,
        "string_script": "    index_base = index[0].toString() - ~/(\\.rev)?(\\.\\d)?(\\.fa)?(\\.bt2)?$/\n    strand_info = params.stranded == \"no\" ? \"fr-unstranded\" : params.stranded == \"reverse\" ? \"fr-secondstrand\" : \"fr-firststrand\"\n    if (params.single_end) {\n        \"\"\"\n        tophat  -p ${task.cpus} \\\n                -G $gtf \\\n                -o $sample_name \\\n                --no-novel-juncs \\\n                --library-type $strand_info \\\n                $index_base \\\n                $reads > ${sample_name}_log.txt\n        mv $sample_name/accepted_hits.bam ${sample_name}_tophat2.bam\n        \"\"\"\n    } else {\n        \"\"\"\n        tophat -p ${task.cpus} \\\n                -G $gtf \\\n                -o $sample_name \\\n                --no-novel-juncs \\\n                --library-type $strand_info \\\n                $index_base \\\n                ${reads[0]} ${reads[1]} > ${sample_name}_log.txt\n        mv $sample_name/accepted_hits.bam ${sample_name}_tophat2.bam\n        \"\"\"\n    }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "TopHat"
        ],
        "tools_url": [
            "https://bio.tools/tophat"
        ],
        "tools_dico": [
            {
                "name": "TopHat",
                "uri": "https://bio.tools/tophat",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0433",
                                    "term": "Splice site prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0433",
                                    "term": "Splice prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_1234",
                                "term": "Sequence set (nucleic acid)"
                            },
                            {
                                "uri": "http://edamontology.org/data_2749",
                                "term": "Genome identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3002",
                                "term": "Annotation track"
                            }
                        ]
                    }
                ],
                "description": "Program that aligns RNA-Seq reads to a genome in order to identify exon-exon splice junctions. It is built on the ultrafast short read mapping program Bowtie. A stable SAMtools version is now packaged with the program.",
                "homepage": "http://ccb.jhu.edu/software/tophat/index.shtml"
            }
        ],
        "inputs": [
            "pair_id_tophat2",
            "tophat2_reads",
            "tophat2_index",
            "gtf"
        ],
        "nb_inputs": 4,
        "outputs": [
            "tophat2_bam",
            "tophat2_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'aligners'",
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/alignment/tophat2\", mode: 'link', overwrite: true"
        ],
        "when": "aligner == \"tophat2\"",
        "stub": ""
    },
    "Hisat2Align": {
        "name_process": "Hisat2Align",
        "string_process": "\nprocess Hisat2Align {\n    label 'aligners'\n    tag \"$sample_name\"\n    publishDir \"${params.outdir}/alignment/hisat2\", mode: 'link', overwrite: true\n\n    input:\n    val sample_name from pair_id_hisat2\n    file(reads) from hisat2_reads\n    file index from hisat2_index.collect()\n\n    output:\n    file \"*_hisat2.bam\" into hisat2_bam\n    file \"*_summary.txt\" into hisat2_log\n\n    when:\n    aligner == \"hisat2\"\n\n    script:\n    index_base = index[0].toString() - ~/(\\.exon)?(\\.\\d)?(\\.fa)?(\\.gtf)?(\\.ht2)?$/\n    if (params.single_end) {\n        \"\"\"\n        hisat2  --summary-file ${sample_name}_hisat2_summary.txt\\\n                -p ${task.cpus} --dta \\\n                -x $index_base \\\n                -U $reads | \\\n                samtools view -@ ${task.cpus} -hbS - > ${sample_name}_hisat2.bam \n        \"\"\"\n    } else {\n        \"\"\"\n        hisat2  --summary-file ${sample_name}_hisat2_summary.txt \\\n                -p ${task.cpus} --dta \\\n                -x $index_base \\\n                -1 ${reads[0]} -2 ${reads[1]} | \\\n                samtools view -@ ${task.cpus} -hbS - > ${sample_name}_hisat2.bam\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 36,
        "string_script": "    index_base = index[0].toString() - ~/(\\.exon)?(\\.\\d)?(\\.fa)?(\\.gtf)?(\\.ht2)?$/\n    if (params.single_end) {\n        \"\"\"\n        hisat2  --summary-file ${sample_name}_hisat2_summary.txt\\\n                -p ${task.cpus} --dta \\\n                -x $index_base \\\n                -U $reads | \\\n                samtools view -@ ${task.cpus} -hbS - > ${sample_name}_hisat2.bam \n        \"\"\"\n    } else {\n        \"\"\"\n        hisat2  --summary-file ${sample_name}_hisat2_summary.txt \\\n                -p ${task.cpus} --dta \\\n                -x $index_base \\\n                -1 ${reads[0]} -2 ${reads[1]} | \\\n                samtools view -@ ${task.cpus} -hbS - > ${sample_name}_hisat2.bam\n        \"\"\"\n    }",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "HISAT2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/hisat2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "HISAT2",
                "uri": "https://bio.tools/hisat2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).",
                "homepage": "https://ccb.jhu.edu/software/hisat2/index.shtml"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "pair_id_hisat2",
            "hisat2_reads",
            "hisat2_index"
        ],
        "nb_inputs": 3,
        "outputs": [
            "hisat2_bam",
            "hisat2_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'aligners'",
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/alignment/hisat2\", mode: 'link', overwrite: true"
        ],
        "when": "aligner == \"hisat2\"",
        "stub": ""
    },
    "BWAAlign": {
        "name_process": "BWAAlign",
        "string_process": "\nprocess BWAAlign{\n    label 'aligners'\n    tag \"$sample_name\"\n    publishDir \"${params.outdir}/alignment/bwa\", mode: 'link', overwrite: true\n    \n    input:\n    val sample_name from pair_id_bwa\n    file(reads) from bwa_reads\n    file index from bwa_index.collect()\n\n    output:\n    file \"*_bwa.bam\" into bwa_bam\n    file \"*\" into bwa_result\n\n    when:\n    aligner == \"bwa\"\n\n    script:\n    index_base = index[0].toString() - ~/(\\.pac)?(\\.bwt)?(\\.ann)?(\\.amb)?(\\.sa)?(\\.fa)?$/\n    if (params.single_end) {\n        \"\"\"\n        bwa aln -t ${task.cpus} \\\n                -f ${reads.baseName}.sai \\\n                $index_base \\\n                $reads\n        bwa samse -f ${sample_name}_bwa.sam \\\n                $index_base \\\n                ${reads.baseName}.sai \\\n                $reads > ${sample_name}_log.txt\n        samtools view -@ ${task.cpus} -h -bS ${sample_name}_bwa.sam > ${sample_name}_bwa.bam\n        rm *.sam\n        \"\"\"\n    } else {\n        \"\"\"\n        bwa aln -t ${task.cpus} \\\n                -f ${reads[0].baseName}.sai \\\n                $index_base \\\n                ${reads[0]}\n        bwa aln -t ${task.cpus} \\\n                -f ${reads[1].baseName}.sai \\\n                $index_base \\\n                ${reads[1]}\n        bwa sampe -f ${sample_name}_bwa.sam \\\n                $index_base \\\n                ${reads[0].baseName}.sai ${reads[1].baseName}.sai \\\n                ${reads[0]} ${reads[1]} > ${sample_name}_log.txt\n        samtools view -@ ${task.cpus} -h -bS ${sample_name}_bwa.sam > ${sample_name}_bwa.bam\n        rm *.sam\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 50,
        "string_script": "    index_base = index[0].toString() - ~/(\\.pac)?(\\.bwt)?(\\.ann)?(\\.amb)?(\\.sa)?(\\.fa)?$/\n    if (params.single_end) {\n        \"\"\"\n        bwa aln -t ${task.cpus} \\\n                -f ${reads.baseName}.sai \\\n                $index_base \\\n                $reads\n        bwa samse -f ${sample_name}_bwa.sam \\\n                $index_base \\\n                ${reads.baseName}.sai \\\n                $reads > ${sample_name}_log.txt\n        samtools view -@ ${task.cpus} -h -bS ${sample_name}_bwa.sam > ${sample_name}_bwa.bam\n        rm *.sam\n        \"\"\"\n    } else {\n        \"\"\"\n        bwa aln -t ${task.cpus} \\\n                -f ${reads[0].baseName}.sai \\\n                $index_base \\\n                ${reads[0]}\n        bwa aln -t ${task.cpus} \\\n                -f ${reads[1].baseName}.sai \\\n                $index_base \\\n                ${reads[1]}\n        bwa sampe -f ${sample_name}_bwa.sam \\\n                $index_base \\\n                ${reads[0].baseName}.sai ${reads[1].baseName}.sai \\\n                ${reads[0]} ${reads[1]} > ${sample_name}_log.txt\n        samtools view -@ ${task.cpus} -h -bS ${sample_name}_bwa.sam > ${sample_name}_bwa.bam\n        rm *.sam\n        \"\"\"\n    }",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "pair_id_bwa",
            "bwa_reads",
            "bwa_index"
        ],
        "nb_inputs": 3,
        "outputs": [
            "bwa_bam",
            "bwa_result"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'aligners'",
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/alignment/bwa\", mode: 'link', overwrite: true"
        ],
        "when": "aligner == \"bwa\"",
        "stub": ""
    },
    "StarAlign": {
        "name_process": "StarAlign",
        "string_process": "\nprocess StarAlign {\n    label 'aligners'\n    tag \"$sample_name\"\n    publishDir \"${params.outdir}/alignment/star\", mode: 'link', overwrite: true\n    \n    input:\n    val sample_name from pair_id_star\n    file(reads) from star_reads\n    file star_index from star_index.collect()\n\n    output:\n    file \"*_star.bam\" into star_bam\n    file \"*.final.out\" into star_log\n\n    when:\n    aligner == \"star\"\n\n    script:\n    if (params.single_end) {\n        \"\"\"\n        STAR --runThreadN ${task.cpus} \\\n            --twopassMode Basic \\\n            --genomeDir $star_index \\\n            --readFilesIn $reads  \\\n            --outSAMtype BAM Unsorted \\\n            --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \\\n            --outFilterIntronMotifs RemoveNoncanonical \\\n            --outFilterMultimapNmax 20 \\\n            --alignIntronMin 20 \\\n            --alignIntronMax 100000 \\\n            --alignMatesGapMax 1000000 \\\n            --outFileNamePrefix ${sample_name}  > ${sample_name}_log.txt\n        mv ${sample_name}Aligned.out.bam ${sample_name}_star.bam\n        \"\"\"\n    } else {\n        \"\"\"\n        STAR --runThreadN ${task.cpus} \\\n            --twopassMode Basic \\\n            --genomeDir $star_index \\\n            --readFilesIn ${reads[0]} ${reads[1]}  \\\n            --outSAMtype BAM Unsorted \\\n            --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \\\n            --outFilterIntronMotifs RemoveNoncanonical \\\n            --outFilterMultimapNmax 20 \\\n            --alignIntronMin 20 \\\n            --alignIntronMax 1000000 \\\n            --alignMatesGapMax 1000000 \\\n            --outFileNamePrefix ${sample_name} > ${sample_name}_log.txt\n        mv ${sample_name}Aligned.out.bam ${sample_name}_star.bam\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 51,
        "string_script": "    if (params.single_end) {\n        \"\"\"\n        STAR --runThreadN ${task.cpus} \\\n            --twopassMode Basic \\\n            --genomeDir $star_index \\\n            --readFilesIn $reads  \\\n            --outSAMtype BAM Unsorted \\\n            --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \\\n            --outFilterIntronMotifs RemoveNoncanonical \\\n            --outFilterMultimapNmax 20 \\\n            --alignIntronMin 20 \\\n            --alignIntronMax 100000 \\\n            --alignMatesGapMax 1000000 \\\n            --outFileNamePrefix ${sample_name}  > ${sample_name}_log.txt\n        mv ${sample_name}Aligned.out.bam ${sample_name}_star.bam\n        \"\"\"\n    } else {\n        \"\"\"\n        STAR --runThreadN ${task.cpus} \\\n            --twopassMode Basic \\\n            --genomeDir $star_index \\\n            --readFilesIn ${reads[0]} ${reads[1]}  \\\n            --outSAMtype BAM Unsorted \\\n            --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \\\n            --outFilterIntronMotifs RemoveNoncanonical \\\n            --outFilterMultimapNmax 20 \\\n            --alignIntronMin 20 \\\n            --alignIntronMax 1000000 \\\n            --alignMatesGapMax 1000000 \\\n            --outFileNamePrefix ${sample_name} > ${sample_name}_log.txt\n        mv ${sample_name}Aligned.out.bam ${sample_name}_star.bam\n        \"\"\"\n    }",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "STAR"
        ],
        "tools_url": [
            "https://bio.tools/star"
        ],
        "tools_dico": [
            {
                "name": "STAR",
                "uri": "https://bio.tools/star",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Ultrafast universal RNA-seq aligner",
                "homepage": "http://code.google.com/p/rna-star/"
            }
        ],
        "inputs": [
            "pair_id_star",
            "star_reads",
            "star_index"
        ],
        "nb_inputs": 3,
        "outputs": [
            "star_bam",
            "star_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'aligners'",
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/alignment/star\", mode: 'link', overwrite: true"
        ],
        "when": "aligner == \"star\"",
        "stub": ""
    },
    "FilterrRNA": {
        "name_process": "FilterrRNA",
        "string_process": "\nprocess FilterrRNA {\n    label 'aligners'\n    tag \"$sample_name\"\n    publishDir \"${params.outdir}/alignment/rRNA_dup\", mode: 'link', overwrite: true\n    \n    input:\n    val sample_name from pair_id_rRNA\n    file(reads) from rRNA_reads\n    file index from rRNA_index.collect()\n\n    output:\n    file \"*_rRNA_sort.bam\" into rRNA_bam\n    file \"*_summary.txt\" into rRNA_log\n\n    when:\n    params.rRNA_fasta && !params.skip_filterrRNA\n\n    script:\n    index_base = index[0].toString() - ~/(\\.exon)?(\\.\\d)?(\\.fa)?(\\.gtf)?(\\.ht2)?$/\n    if (params.single_end) {\n        \"\"\"\n        hisat2 --summary-file ${sample_name}_rRNA_summary.txt \\\n            --no-spliced-alignment --no-softclip --norc --no-unal \\\n            -p ${task.cpus} --dta \\\n            -x $index_base \\\n            -U $reads | \\\n            samtools view -@ ${task.cpus} -Shub - | \\\n            samtools sort  -@ ${task.cpus} -o ${sample_name}_rRNA_sort.bam -\n        picard MarkDuplicates I=${sample_name}_rRNA_sort.bam \\\n\t        O=${sample_name}_mDuprRNA_sort.bam \\\n            M=${sample_name}_mDuprRNA_sort.dupmark.log \\\n\t        VALIDATION_STRINGENCY=LENIENT ASSUME_SORTED=true REMOVE_DUPLICATES=false\n        \"\"\"\n    } else {\n        \"\"\"\n        hisat2 --summary-file ${sample_name}_rRNA_summary.txt \\\n            --no-spliced-alignment --no-softclip --norc --no-unal \\\n            -p ${task.cpus} --dta \\\n            -x $index_base \\\n            -1 ${reads[0]} -2 ${reads[1]} | \\\n            samtools view -@ ${task.cpus} -Shub - | \\\n            samtools sort  -@ ${task.cpus} -o ${sample_name}_rRNA_sort.bam -\n        picard MarkDuplicates I=${sample_name}_rRNA_sort.bam \\\n\t        O=${sample_name}_mDuprRNA_sort.bam \\\n            M=${sample_name}_mDuprRNA_sort.dupmark.log \\\n\t        VALIDATION_STRINGENCY=LENIENT ASSUME_SORTED=true REMOVE_DUPLICATES=false\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 48,
        "string_script": "    index_base = index[0].toString() - ~/(\\.exon)?(\\.\\d)?(\\.fa)?(\\.gtf)?(\\.ht2)?$/\n    if (params.single_end) {\n        \"\"\"\n        hisat2 --summary-file ${sample_name}_rRNA_summary.txt \\\n            --no-spliced-alignment --no-softclip --norc --no-unal \\\n            -p ${task.cpus} --dta \\\n            -x $index_base \\\n            -U $reads | \\\n            samtools view -@ ${task.cpus} -Shub - | \\\n            samtools sort  -@ ${task.cpus} -o ${sample_name}_rRNA_sort.bam -\n        picard MarkDuplicates I=${sample_name}_rRNA_sort.bam \\\n\t        O=${sample_name}_mDuprRNA_sort.bam \\\n            M=${sample_name}_mDuprRNA_sort.dupmark.log \\\n\t        VALIDATION_STRINGENCY=LENIENT ASSUME_SORTED=true REMOVE_DUPLICATES=false\n        \"\"\"\n    } else {\n        \"\"\"\n        hisat2 --summary-file ${sample_name}_rRNA_summary.txt \\\n            --no-spliced-alignment --no-softclip --norc --no-unal \\\n            -p ${task.cpus} --dta \\\n            -x $index_base \\\n            -1 ${reads[0]} -2 ${reads[1]} | \\\n            samtools view -@ ${task.cpus} -Shub - | \\\n            samtools sort  -@ ${task.cpus} -o ${sample_name}_rRNA_sort.bam -\n        picard MarkDuplicates I=${sample_name}_rRNA_sort.bam \\\n\t        O=${sample_name}_mDuprRNA_sort.bam \\\n            M=${sample_name}_mDuprRNA_sort.dupmark.log \\\n\t        VALIDATION_STRINGENCY=LENIENT ASSUME_SORTED=true REMOVE_DUPLICATES=false\n        \"\"\"\n    }",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [
            "HISAT2",
            "SAMtools",
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/hisat2",
            "https://bio.tools/samtools",
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "HISAT2",
                "uri": "https://bio.tools/hisat2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).",
                "homepage": "https://ccb.jhu.edu/software/hisat2/index.shtml"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "pair_id_rRNA",
            "rRNA_reads",
            "rRNA_index"
        ],
        "nb_inputs": 3,
        "outputs": [
            "rRNA_bam",
            "rRNA_log"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'aligners'",
            "tag \"$sample_name\"",
            "publishDir \"${params.outdir}/alignment/rRNA_dup\", mode: 'link', overwrite: true"
        ],
        "when": "params.rRNA_fasta && !params.skip_filterrRNA",
        "stub": ""
    },
    "Sort": {
        "name_process": "Sort",
        "string_process": "\nprocess Sort {\n    tag \"$sample_name\"\n\n    input:\n    file bam_file from merge_bam_file\n\n    output:\n    file \"*_sort*.{bam,bai}\" into rename_bam_file\n    file \"*.bam\" into bam_results\n\n    script:\n    sample_name = bam_file.toString() - ~/(\\.bam)?$/\n    output = sample_name + \"_sort.bam\"\n    mapq_cutoff = (params.mapq_cutoff).toInteger() \n    if (!params.skip_sort){\n        \"\"\"\n        if [ \"$mapq_cutoff\" -gt \"0\" ]; then\n            samtools view -hubq $mapq_cutoff $bam_file | samtools sort -@ ${task.cpus} -O BAM -o $output -\n        else\n            samtools sort -@ ${task.cpus} -O BAM -o $output $bam_file\n        fi\n        samtools index -@ ${task.cpus} $output\n        \"\"\"\n    } else {\n        \"\"\"\n        for bam_file in *.bam\n        do\n        {\n            if [ \"$mapq_cutoff\" -gt \"0\" ]; then\n                samtools view -hubq $mapq_cutoff $bam_file > $output\n            else\n                mv $bam_file $output\n            fi\n            samtools index -@ ${task.cpus} $output\n        }\n        done\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 38,
        "string_script": "    sample_name = bam_file.toString() - ~/(\\.bam)?$/\n    output = sample_name + \"_sort.bam\"\n    mapq_cutoff = (params.mapq_cutoff).toInteger() \n    if (!params.skip_sort){\n        \"\"\"\n        if [ \"$mapq_cutoff\" -gt \"0\" ]; then\n            samtools view -hubq $mapq_cutoff $bam_file | samtools sort -@ ${task.cpus} -O BAM -o $output -\n        else\n            samtools sort -@ ${task.cpus} -O BAM -o $output $bam_file\n        fi\n        samtools index -@ ${task.cpus} $output\n        \"\"\"\n    } else {\n        \"\"\"\n        for bam_file in *.bam\n        do\n        {\n            if [ \"$mapq_cutoff\" -gt \"0\" ]; then\n                samtools view -hubq $mapq_cutoff $bam_file > $output\n            else\n                mv $bam_file $output\n            fi\n            samtools index -@ ${task.cpus} $output\n        }\n        done\n        \"\"\"\n    }",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [
            "wossoutput",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/wossoutput",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "wossoutput",
                "uri": "https://bio.tools/wossoutput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM output data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossoutput.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "merge_bam_file"
        ],
        "nb_inputs": 1,
        "outputs": [
            "rename_bam_file",
            "bam_results"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "tag \"$sample_name\""
        ],
        "when": "",
        "stub": ""
    },
    "RenameByDesignfile": {
        "name_process": "RenameByDesignfile",
        "string_process": "\nprocess RenameByDesignfile{\n    publishDir \"${params.outdir}/alignment/samtoolsSort/\", mode: 'link', overwrite: true\n\n    input:\n    file (reads) from rename_bam_file.collect()\n    file designfile                                                 \n    file comparefile\n\n    output:\n    file \"*.{input,ip}_*.{bam,bai}\" into sort_bam\n    file (\"formatted_designfile.txt\") into formatted_designfile\n    file \"*\" into rename_results\n\n    script:\n    println LikeletUtils.print_purple(\"Rename the files for downstream analysis\")\n    aligners_name =  aligner\n    \"\"\"\n    # Windows and linux newline ^M conversion\n    cat $designfile | dos2unix |sed '1s/.*/Sample_ID,input_FileName,ip_FileName,Group/g' |awk NF > formatted_designfile.txt\n    # Check the consistency of designfile and comparefile\n    if [ \"$comparefile\" != \"false\" ]; then \n        ## get groups' name in comparefile\n        cat $comparefile | dos2unix | awk -F \"_vs_\" '{print \\$1\"\\\\n\"\\$2}' | sort | uniq > tmp.compare.group\n        ## get groups' name in designfile\n        awk -F, 'NR>1{print \\$4}' formatted_designfile.txt | sort | uniq > tmp.design.group\n        intersection_num=\\$(join tmp.compare.group tmp.design.group | wc -l)\n        if [[ \\$intersection_num  != \\$(cat tmp.compare.group| wc -l) ]] ;then \n            echo \"The groups' name of comparefile and designfile are inconsistent.\"\n            echo \"Please check your comparefile: \"$comparefile\n            echo \"The groups' name of comparefile in designfile: \"\\$(join tmp.compare.group tmp.design.group)\n            exit 1\n        fi\n        rm tmp.compare.group tmp.design.group\n    fi\n    bash $baseDir/bin/rename.sh $aligners_name formatted_designfile.txt\n    bash $baseDir/bin/rename_for_resume.sh formatted_designfile.txt\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    println LikeletUtils.print_purple(\"Rename the files for downstream analysis\")\n    aligners_name =  aligner\n    \"\"\"\n    # Windows and linux newline ^M conversion\n    cat $designfile | dos2unix |sed '1s/.*/Sample_ID,input_FileName,ip_FileName,Group/g' |awk NF > formatted_designfile.txt\n    # Check the consistency of designfile and comparefile\n    if [ \"$comparefile\" != \"false\" ]; then \n        ## get groups' name in comparefile\n        cat $comparefile | dos2unix | awk -F \"_vs_\" '{print \\$1\"\\\\n\"\\$2}' | sort | uniq > tmp.compare.group\n        ## get groups' name in designfile\n        awk -F, 'NR>1{print \\$4}' formatted_designfile.txt | sort | uniq > tmp.design.group\n        intersection_num=\\$(join tmp.compare.group tmp.design.group | wc -l)\n        if [[ \\$intersection_num  != \\$(cat tmp.compare.group| wc -l) ]] ;then \n            echo \"The groups' name of comparefile and designfile are inconsistent.\"\n            echo \"Please check your comparefile: \"$comparefile\n            echo \"The groups' name of comparefile in designfile: \"\\$(join tmp.compare.group tmp.design.group)\n            exit 1\n        fi\n        rm tmp.compare.group tmp.design.group\n    fi\n    bash $baseDir/bin/rename.sh $aligners_name formatted_designfile.txt\n    bash $baseDir/bin/rename_for_resume.sh formatted_designfile.txt\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "rename_bam_file",
            "designfile",
            "comparefile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sort_bam",
            "formatted_designfile",
            "rename_results"
        ],
        "nb_outputs": 3,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/alignment/samtoolsSort/\", mode: 'link', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "RSeQC": {
        "name_process": "RSeQC",
        "string_process": "\nprocess RSeQC {\n    publishDir \"${params.outdir}/QC/rseqc\" , mode: 'copy', overwrite: true,\n        saveAs: {filename ->\n                 if (filename.indexOf(\"bam_stat.txt\") > 0)                      \"bam_stat/$filename\"\n            else if (filename.indexOf(\"infer_experiment.txt\") > 0)              \"infer_experiment/$filename\"\n            else if (filename.indexOf(\"read_distribution.txt\") > 0)             \"read_distribution/$filename\"\n            else if (filename.indexOf(\"read_duplication.DupRate_plot.pdf\") > 0) \"read_duplication/$filename\"\n            else if (filename.indexOf(\"read_duplication.DupRate_plot.r\") > 0)   \"read_duplication/rscripts/$filename\"\n            else if (filename.indexOf(\"read_duplication.pos.DupRate.xls\") > 0)  \"read_duplication/dup_pos/$filename\"\n            else if (filename.indexOf(\"read_duplication.seq.DupRate.xls\") > 0)  \"read_duplication/dup_seq/$filename\"\n            else if (filename.indexOf(\"inner_distance.txt\") > 0)                \"inner_distance/$filename\"\n            else if (filename.indexOf(\"inner_distance_freq.txt\") > 0)           \"inner_distance/data/$filename\"\n            else if (filename.indexOf(\"inner_distance_plot.r\") > 0)             \"inner_distance/rscripts/$filename\"\n            else if (filename.indexOf(\"inner_distance_plot.pdf\") > 0)           \"inner_distance/plots/$filename\"\n            else if (filename.indexOf(\"junction_plot.r\") > 0)                   \"junction_annotation/rscripts/$filename\"\n            else if (filename.indexOf(\"junction.xls\") > 0)                      \"junction_annotation/data/$filename\"\n            else if (filename.indexOf(\"splice_events.pdf\") > 0)                 \"junction_annotation/events/$filename\"\n            else if (filename.indexOf(\"splice_junction.pdf\") > 0)               \"junction_annotation/junctions/$filename\"\n            else if (filename.indexOf(\"junctionSaturation_plot.pdf\") > 0)       \"junction_saturation/$filename\"\n            else if (filename.indexOf(\"junctionSaturation_plot.r\") > 0)         \"junction_saturation/rscripts/$filename\"\n            else filename\n        }    \n    when:\n    !params.skip_qc && !params.skip_rseqc\n\n    input:\n    file bam_rseqc from sort_bam.collect()\n    file bed12 from bed12file.collect()\n\n    output:\n    file \"*\" into rseqc_results\n    file \"*.bam_stat.txt\" into bam_stat_for_normlization\n    script:\n\n    \"\"\"    \n    bash $baseDir/bin/rseqc.sh $bed12 ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"    \n    bash $baseDir/bin/rseqc.sh $bed12 ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam",
            "bed12file"
        ],
        "nb_inputs": 2,
        "outputs": [
            "rseqc_results",
            "bam_stat_for_normlization"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/QC/rseqc\" , mode: 'copy', overwrite: true , saveAs: {filename -> if (filename.indexOf(\"bam_stat.txt\") > 0) \"bam_stat/$filename\" else if (filename.indexOf(\"infer_experiment.txt\") > 0) \"infer_experiment/$filename\" else if (filename.indexOf(\"read_distribution.txt\") > 0) \"read_distribution/$filename\" else if (filename.indexOf(\"read_duplication.DupRate_plot.pdf\") > 0) \"read_duplication/$filename\" else if (filename.indexOf(\"read_duplication.DupRate_plot.r\") > 0) \"read_duplication/rscripts/$filename\" else if (filename.indexOf(\"read_duplication.pos.DupRate.xls\") > 0) \"read_duplication/dup_pos/$filename\" else if (filename.indexOf(\"read_duplication.seq.DupRate.xls\") > 0) \"read_duplication/dup_seq/$filename\" else if (filename.indexOf(\"inner_distance.txt\") > 0) \"inner_distance/$filename\" else if (filename.indexOf(\"inner_distance_freq.txt\") > 0) \"inner_distance/data/$filename\" else if (filename.indexOf(\"inner_distance_plot.r\") > 0) \"inner_distance/rscripts/$filename\" else if (filename.indexOf(\"inner_distance_plot.pdf\") > 0) \"inner_distance/plots/$filename\" else if (filename.indexOf(\"junction_plot.r\") > 0) \"junction_annotation/rscripts/$filename\" else if (filename.indexOf(\"junction.xls\") > 0) \"junction_annotation/data/$filename\" else if (filename.indexOf(\"splice_events.pdf\") > 0) \"junction_annotation/events/$filename\" else if (filename.indexOf(\"splice_junction.pdf\") > 0) \"junction_annotation/junctions/$filename\" else if (filename.indexOf(\"junctionSaturation_plot.pdf\") > 0) \"junction_saturation/$filename\" else if (filename.indexOf(\"junctionSaturation_plot.r\") > 0) \"junction_saturation/rscripts/$filename\" else filename }"
        ],
        "when": "!params.skip_qc && !params.skip_rseqc",
        "stub": ""
    },
    "CreateBedgraph": {
        "name_process": "CreateBedgraph",
        "string_process": "\nprocess CreateBedgraph{\n    publishDir \"${params.outdir}/QC/rseqc/\", mode: 'link', overwrite: true ,\n        saveAs: {filename ->\n            if (filename.indexOf(\"bedgraph\") > 0) \"bedgraph/$filename\"\n        }\n\n    input:\n    file bam from sort_bam.collect()\n\n    output:\n    file \"*.bedgraph\" into bedgraph_for_genebody\n\n    when:\n    !params.skip_createbedgraph\n\n    script:\n    \"\"\"\n    bash $baseDir/bin/create_bedgraph.sh ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    bash $baseDir/bin/create_bedgraph.sh ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam"
        ],
        "nb_inputs": 1,
        "outputs": [
            "bedgraph_for_genebody"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/QC/rseqc/\", mode: 'link', overwrite: true , saveAs: {filename -> if (filename.indexOf(\"bedgraph\") > 0) \"bedgraph/$filename\" }"
        ],
        "when": "!params.skip_createbedgraph",
        "stub": ""
    },
    "GenebodyCoverage": {
        "name_process": "GenebodyCoverage",
        "string_process": "\nprocess GenebodyCoverage {\n    publishDir \"${params.outdir}/QC/rseqc\" , mode: 'link', overwrite: true, \n        saveAs: {filename ->\n            if (filename.indexOf(\"geneBodyCoverage.curves.pdf\") > 0)       \"geneBodyCoverage/$filename\"\n            else if (filename.indexOf(\"geneBodyCoverage.r\") > 0)           \"geneBodyCoverage/rscripts/$filename\"\n            else if (filename.indexOf(\"geneBodyCoverage.txt\") > 0)         \"geneBodyCoverage/data/$filename\"\n            else if (filename.indexOf(\"log.txt\") > -1) false\n            else filename\n        }\n\n    when:\n    !params.skip_rseqc && !params.skip_genebody_coverage\n\n    input:\n    file bedgraph from bedgraph_for_genebody\n    file bed12 from bed12file.collect()\n\n    output:\n    file \"*.{txt,pdf,r}\" into genebody_coverage_results\n\n    script:\n    \"\"\"\n    bash $baseDir/bin/geneBody_coverage2.sh $bed12 ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    bash $baseDir/bin/geneBody_coverage2.sh $bed12 ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bedgraph_for_genebody",
            "bed12file"
        ],
        "nb_inputs": 2,
        "outputs": [
            "genebody_coverage_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/QC/rseqc\" , mode: 'link', overwrite: true , saveAs: {filename -> if (filename.indexOf(\"geneBodyCoverage.curves.pdf\") > 0) \"geneBodyCoverage/$filename\" else if (filename.indexOf(\"geneBodyCoverage.r\") > 0) \"geneBodyCoverage/rscripts/$filename\" else if (filename.indexOf(\"geneBodyCoverage.txt\") > 0) \"geneBodyCoverage/data/$filename\" else if (filename.indexOf(\"log.txt\") > -1) false else filename }"
        ],
        "when": "!params.skip_rseqc && !params.skip_genebody_coverage",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc{\n    publishDir \"${params.outdir}/Report/QCReadsReport\" , mode: 'link', overwrite: true\n    \n    when:\n    !params.skip_qc\n\n    input:\n    file arranged_qc from arranged_qc.collect()\n\n    output:\n    file \"multiqc*\" into multiqc_results\n\n    script:\n    \"\"\"\n    multiqc -n multiqc_$aligner .\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    multiqc -n multiqc_$aligner .\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "arranged_qc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "multiqc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/Report/QCReadsReport\" , mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_qc",
        "stub": ""
    },
    "Metpeak": {
        "name_process": "Metpeak",
        "string_process": "\nprocess Metpeak {\n    label 'peak_calling'\n    publishDir \"${params.outdir}/peakCalling/metpeak\", mode: 'link', overwrite: true\n\n    input:\n    file bam_bai_file from sort_bam.collect()\n    file gtf\n    file formatted_designfile from formatted_designfile.collect()\n\n    output:\n    file \"*\" into metpeak_results\n    file \"metpeak*_normalized.bed\" into metpeak_nomarlized_bed\n\n    when:\n    !params.skip_metpeak && !params.skip_peakCalling\n\n    script: \n    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by MeTPeak in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by MeTPeak in independent mode\")\n    }\n    \"\"\"\n    Rscript $baseDir/bin/MeTPeak.R $formatted_designfile $gtf ${task.cpus} $flag_peakCallingbygroup;\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by MeTPeak in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by MeTPeak in independent mode\")\n    }\n    \"\"\"\n    Rscript $baseDir/bin/MeTPeak.R $formatted_designfile $gtf ${task.cpus} $flag_peakCallingbygroup;\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam",
            "gtf",
            "formatted_designfile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "metpeak_results",
            "metpeak_nomarlized_bed"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'peak_calling'",
            "publishDir \"${params.outdir}/peakCalling/metpeak\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_metpeak && !params.skip_peakCalling",
        "stub": ""
    },
    "Macs2": {
        "name_process": "Macs2",
        "string_process": "\nprocess Macs2{\n    label 'peak_calling'\n    publishDir \"${params.outdir}/peakCalling/macs2\", mode: 'link', overwrite: true\n\n    input:\n    file fasta\n    file bam_bai_file from sort_bam.collect()\n    file formatted_designfile from formatted_designfile.collect()\n\n    output:\n    file \"macs2*.{xls,narrowPeak,summits}\" into macs2_results\n    file \"macs2*_normalized.bed\" into macs2_nomarlized_bed\n\n    when:\n    !params.skip_macs2 && !params.skip_peakCalling\n\n    script:\n    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by Macs2 in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by Macs2 in independent mode\")\n    }\n    \"\"\"\n    genome_size=\\$(faCount $fasta | tail -1 | awk '{print \\$2-\\$7}')\n    bash $baseDir/bin/macs2.sh $formatted_designfile \\$genome_size $flag_peakCallingbygroup ${task.cpus};\n    \"\"\" \n}",
        "nb_lignes_process": 27,
        "string_script": "    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by Macs2 in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by Macs2 in independent mode\")\n    }\n    \"\"\"\n    genome_size=\\$(faCount $fasta | tail -1 | awk '{print \\$2-\\$7}')\n    bash $baseDir/bin/macs2.sh $formatted_designfile \\$genome_size $flag_peakCallingbygroup ${task.cpus};\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "sort_bam",
            "formatted_designfile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "macs2_results",
            "macs2_nomarlized_bed"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'peak_calling'",
            "publishDir \"${params.outdir}/peakCalling/macs2\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_macs2 && !params.skip_peakCalling",
        "stub": ""
    },
    "MATKpeakCalling": {
        "name_process": "MATKpeakCalling",
        "string_process": "\nprocess MATKpeakCalling {\n    label 'peak_calling'\n    publishDir \"${params.outdir}/peakCalling/MATK\", mode: 'link', overwrite: true\n\n    input:\n    file bam_bai_file from sort_bam.collect()\n    file gtf\n    file formatted_designfile from formatted_designfile.collect()\n\n    output:\n    file \"*\" into matk_results\n    file \"MATK*_normalized.bed\" into matk_nomarlized_bed\n\n    when:\n    !params.skip_matk && !params.skip_peakCalling\n\n    script:\n    matk_jar = params.matk_jar\n    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by MATK in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by MATK in independent mode\")\n    }\n    \"\"\"\n    export OMP_NUM_THREADS=${task.cpus}\n    bash $baseDir/bin/MATK_peakCalling.sh $matk_jar $formatted_designfile $flag_peakCallingbygroup\n    \"\"\"    \n}",
        "nb_lignes_process": 28,
        "string_script": "    matk_jar = params.matk_jar\n    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by MATK in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by MATK in independent mode\")\n    }\n    \"\"\"\n    export OMP_NUM_THREADS=${task.cpus}\n    bash $baseDir/bin/MATK_peakCalling.sh $matk_jar $formatted_designfile $flag_peakCallingbygroup\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam",
            "gtf",
            "formatted_designfile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "matk_results",
            "matk_nomarlized_bed"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'peak_calling'",
            "publishDir \"${params.outdir}/peakCalling/MATK\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_matk && !params.skip_peakCalling",
        "stub": ""
    },
    "MeyerPrepration": {
        "name_process": "MeyerPrepration",
        "string_process": " process MeyerPrepration{\n        label 'build_index'\n        tag \"MeyerPrepration\"\n        publishDir path: { params.saveReference ? \"${params.outdir}/Genome/meyerPrepration\" : params.outdir },\n                saveAs: { params.saveReference ? it : null }, mode: 'copy'       \n\n        input:\n        file fasta\n\n        output:\n        file \"chromsizes.file\" into chromsizesfile\n        file \"chrName.txt\" into chrNamefile\n        file \"genome.bin25.bed\" into bin25file\n        file \"genomebin\" into genomebin\n\n        when:\n        !params.skip_meyer && !params.skip_peakCalling\n\n        shell:\n        '''\n        #cat !{fasta} | awk 'BEGIN{len=\"\"}{if($0~\">\"){split($0,ID,\"[> ]\");printf len\"ABC\"ID[2]\"\\\\t\";len=0}else{len=len+length($0)}}END{print len}' |sed 's/ABC/\\\\n/g' |awk NF > chromsizes.file\n        samtools faidx !{fasta}\n        cut -f1,2 !{fasta}.fai > chromsizes.file\n        awk '{print $1}' chromsizes.file > chrName.txt\n        mkdir genomebin\n        bedtools makewindows -g chromsizes.file -w 25 > genome.bin25.bed\n        awk '{print \"cat genome.bin25.bed | grep \"$1\" > genomebin/\"$1\".bin25.bed\"}' chrName.txt | xargs -iCMD -P!{task.cpus} bash -c CMD\n        '''\n    }",
        "nb_lignes_process": 27,
        "string_script": "        '''\n        #cat !{fasta} | awk 'BEGIN{len=\"\"}{if($0~\">\"){split($0,ID,\"[> ]\");printf len\"ABC\"ID[2]\"\\\\t\";len=0}else{len=len+length($0)}}END{print len}' |sed 's/ABC/\\\\n/g' |awk NF > chromsizes.file\n        samtools faidx !{fasta}\n        cut -f1,2 !{fasta}.fai > chromsizes.file\n        awk '{print $1}' chromsizes.file > chrName.txt\n        mkdir genomebin\n        bedtools makewindows -g chromsizes.file -w 25 > genome.bin25.bed\n        awk '{print \"cat genome.bin25.bed | grep \"$1\" > genomebin/\"$1\".bin25.bed\"}' chrName.txt | xargs -iCMD -P!{task.cpus} bash -c CMD\n        '''",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [
            "chromsizesfile",
            "chrNamefile",
            "bin25file",
            "genomebin"
        ],
        "nb_outputs": 4,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'build_index'",
            "tag \"MeyerPrepration\"",
            "publishDir path: { params.saveReference ? \"${params.outdir}/Genome/meyerPrepration\" : params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "!params.skip_meyer && !params.skip_peakCalling",
        "stub": ""
    },
    "Meyer": {
        "name_process": "Meyer",
        "string_process": "\nprocess Meyer{\n    label 'peak_calling'\n    publishDir \"${params.outdir}/peakCalling/meyer\", mode: 'link', overwrite: true\n\n    input:\n    file bam_bai_file from sort_bam.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file chrNamefile from chrNamefile\n    file bin25file from bin25file\n    file genomebin from genomebin\n\n    output:\n    file \"meyer*.bed\" into meyer_results\n    file \"meyer*_normalized.bed\" into meyer_nomarlized_bed\n\n    when:\n    !params.skip_meyer && !params.skip_peakCalling\n\n    shell:\n    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by Meyer in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by Meyer in independent mode\")\n    }\n    '''\n    cp !{baseDir}/bin/meyer.py ./\n    peak_windows_number=$(wc -l !{bin25file}| cut -d \" \" -f 1)\n    bash !{baseDir}/bin/meyer_peakCalling.sh !{formatted_designfile} !{chrNamefile} genomebin/ ${peak_windows_number} !{task.cpus} !{flag_peakCallingbygroup}\n    ''' \n}",
        "nb_lignes_process": 30,
        "string_script": "    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    if( flag_peakCallingbygroup ){\n        println LikeletUtils.print_purple(\"Peak Calling performed by Meyer in group mode\")\n    }else{\n        println LikeletUtils.print_purple(\"Peak Calling performed by Meyer in independent mode\")\n    }\n    '''\n    cp !{baseDir}/bin/meyer.py ./\n    peak_windows_number=$(wc -l !{bin25file}| cut -d \" \" -f 1)\n    bash !{baseDir}/bin/meyer_peakCalling.sh !{formatted_designfile} !{chrNamefile} genomebin/ ${peak_windows_number} !{task.cpus} !{flag_peakCallingbygroup}\n    '''",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam",
            "formatted_designfile",
            "chrNamefile",
            "bin25file",
            "genomebin"
        ],
        "nb_inputs": 5,
        "outputs": [
            "meyer_results",
            "meyer_nomarlized_bed"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'peak_calling'",
            "publishDir \"${params.outdir}/peakCalling/meyer\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_meyer && !params.skip_peakCalling",
        "stub": ""
    },
    "HtseqCountNewToYou": {
        "name_process": "HtseqCountNewToYou",
        "string_process": "\nprocess HtseqCountNewToYou{\n    container 'quay.io/biocontainers/htseq:0.13.5--py39h70b41aa_1'\n                                                                                          \n                                                  \n    \n    label 'analysis'\n    publishDir \"${params.outdir}/expressionAnalysis/htseq-count\", mode: 'link', overwrite: true\n\n    input:\n    file bam_bai_file from sort_bam.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file gtf\n\n    output:\n    file \"*.bam.txt\" into htseq_counts\n    \n    when:\n    !params.skip_expression\n\n    script:\n    println LikeletUtils.print_purple(\"Generate gene counts with htseq-count\")\n    strand_info = params.stranded == \"no\" ? \"no\" : params.stranded == \"reverse\" ? \"reverse\" : \"yes\"\n                                                   \n    \"\"\"\n    bash $baseDir/bin/htseq_count.sh $gtf $strand_info ${task.cpus}\n    #Rscript $baseDir/bin/get_htseq_matrix.R $formatted_designfile ${task.cpus} \n    # Rscript $baseDir/bin/feature_count.R $formatted_designfile $gtf $strand_info ${task.cpus}\n    \"\"\" \n}",
        "nb_lignes_process": 28,
        "string_script": "    println LikeletUtils.print_purple(\"Generate gene counts with htseq-count\")\n    strand_info = params.stranded == \"no\" ? \"no\" : params.stranded == \"reverse\" ? \"reverse\" : \"yes\"\n                                                   \n    \"\"\"\n    bash $baseDir/bin/htseq_count.sh $gtf $strand_info ${task.cpus}\n    #Rscript $baseDir/bin/get_htseq_matrix.R $formatted_designfile ${task.cpus} \n    # Rscript $baseDir/bin/feature_count.R $formatted_designfile $gtf $strand_info ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam",
            "formatted_designfile",
            "gtf"
        ],
        "nb_inputs": 3,
        "outputs": [
            "htseq_counts"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "container 'quay.io/biocontainers/htseq:0.13.5--py39h70b41aa_1'",
            "label 'analysis'",
            "publishDir \"${params.outdir}/expressionAnalysis/htseq-count\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_expression",
        "stub": ""
    },
    "HtseqMatrixNew": {
        "name_process": "HtseqMatrixNew",
        "string_process": "\nprocess HtseqMatrixNew{\n    label 'analysis'\n    publishDir \"${params.outdir}/expressionAnalysis/htseq-count\", mode: 'link', overwrite: true\n\n    input:\n    file bam_bai_file from sort_bam.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file gtf\n    file htseqcounts from htseq_counts.collect()\n\n    output:\n    file \"expression.matrix\" into htseq_results\n    file \"*input*.count\" into htseq_count_input, htseq_count_input_to_arrange\n\n\n    when:\n    !params.skip_expression\n\n    script:\n    println LikeletUtils.print_purple(\"Generate gene expression matrix by htseq-count and Rscript\")\n    strand_info = params.stranded == \"no\" ? \"no\" : params.stranded == \"reverse\" ? \"reverse\" : \"yes\"\n                                                   \n    \"\"\"\n    #bash $baseDir/bin/htseq_count.sh $gtf $strand_info ${task.cpus}\n    Rscript $baseDir/bin/get_htseq_matrix.R $formatted_designfile ${task.cpus} \n    # Rscript $baseDir/bin/feature_count.R $formatted_designfile $gtf $strand_info ${task.cpus}\n    \"\"\" \n}",
        "nb_lignes_process": 27,
        "string_script": "    println LikeletUtils.print_purple(\"Generate gene expression matrix by htseq-count and Rscript\")\n    strand_info = params.stranded == \"no\" ? \"no\" : params.stranded == \"reverse\" ? \"reverse\" : \"yes\"\n                                                   \n    \"\"\"\n    #bash $baseDir/bin/htseq_count.sh $gtf $strand_info ${task.cpus}\n    Rscript $baseDir/bin/get_htseq_matrix.R $formatted_designfile ${task.cpus} \n    # Rscript $baseDir/bin/feature_count.R $formatted_designfile $gtf $strand_info ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam",
            "formatted_designfile",
            "gtf",
            "htseq_counts"
        ],
        "nb_inputs": 4,
        "outputs": [
            "htseq_results",
            "htseq_count_input",
            "htseq_count_input_to_arrange"
        ],
        "nb_outputs": 3,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "publishDir \"${params.outdir}/expressionAnalysis/htseq-count\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_expression",
        "stub": ""
    },
    "DESeq2": {
        "name_process": "DESeq2",
        "string_process": "\nprocess DESeq2{\n    label 'analysis'\n    tag \"$compare_str\"\n\n    publishDir \"${params.outdir}/expressionAnalysis/DESeq2\", mode: 'link', overwrite: true\n\n    input:\n    file reads_count_input from htseq_count_input.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    val compare_str from compareLines_for_DESeq2\n\n    output:\n    file \"DESeq2*.csv\" into deseq2_results\n    \n    when:\n    !params.skip_deseq2 && !params.skip_expression\n    \n    script:\n    println LikeletUtils.print_purple(\"Differential expression analysis performed by DESeq2 ($compare_str)\")\n    \"\"\"\n    Rscript $baseDir/bin/DESeq2.R $formatted_designfile $compare_str\n    \"\"\" \n}",
        "nb_lignes_process": 22,
        "string_script": "    println LikeletUtils.print_purple(\"Differential expression analysis performed by DESeq2 ($compare_str)\")\n    \"\"\"\n    Rscript $baseDir/bin/DESeq2.R $formatted_designfile $compare_str\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "htseq_count_input",
            "formatted_designfile",
            "compareLines_for_DESeq2"
        ],
        "nb_inputs": 3,
        "outputs": [
            "deseq2_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "tag \"$compare_str\"",
            "publishDir \"${params.outdir}/expressionAnalysis/DESeq2\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_deseq2 && !params.skip_expression",
        "stub": ""
    },
    "EdgeR": {
        "name_process": "EdgeR",
        "string_process": "\nprocess EdgeR{\n    label 'analysis'\n    tag \"$compare_str\"\n    publishDir \"${params.outdir}/expressionAnalysis/edgeR\", mode: 'link', overwrite: true\n\n    input:\n    file reads_count_input from htseq_count_input.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    val compare_str from compareLines_for_edgeR\n\n    output:\n    file \"edgeR*.csv\" into edgeR_results\n    \n    when:\n    !params.skip_edger && !params.skip_expression\n\n    script:\n    println LikeletUtils.print_purple(\"Differential expression analysis performed by EdgeR ($compare_str)\")\n    \"\"\"\n    Rscript $baseDir/bin/edgeR.R $formatted_designfile $compare_str\n    \"\"\" \n}",
        "nb_lignes_process": 21,
        "string_script": "    println LikeletUtils.print_purple(\"Differential expression analysis performed by EdgeR ($compare_str)\")\n    \"\"\"\n    Rscript $baseDir/bin/edgeR.R $formatted_designfile $compare_str\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "htseq_count_input",
            "formatted_designfile",
            "compareLines_for_edgeR"
        ],
        "nb_inputs": 3,
        "outputs": [
            "edgeR_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "tag \"$compare_str\"",
            "publishDir \"${params.outdir}/expressionAnalysis/edgeR\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_edger && !params.skip_expression",
        "stub": ""
    },
    "Cufflinks": {
        "name_process": "Cufflinks",
        "string_process": "\nprocess Cufflinks{\n    label 'analysis'\n    publishDir \"${params.outdir}/expressionAnalysis/cufflinks\", mode: 'link', overwrite: true\n\n    input:\n    file bam_bai_file from sort_bam.collect()\n    file gtf\n    file formatted_designfile from formatted_designfile.collect()\n\n    output:\n    file \"cuffdiff*\" into cufflinks_results\n\n    when:\n    !params.skip_cufflinks && !params.skip_expression\n\n    script:\n    println LikeletUtils.print_purple(\"Differential expression analysis performed by Cufflinks\")\n    \"\"\"\n    bash $baseDir/bin/cufflinks.sh $formatted_designfile $gtf ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    println LikeletUtils.print_purple(\"Differential expression analysis performed by Cufflinks\")\n    \"\"\"\n    bash $baseDir/bin/cufflinks.sh $formatted_designfile $gtf ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sort_bam",
            "gtf",
            "formatted_designfile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "cufflinks_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "publishDir \"${params.outdir}/expressionAnalysis/cufflinks\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_cufflinks && !params.skip_expression",
        "stub": ""
    },
    "PeakMerge": {
        "name_process": "PeakMerge",
        "string_process": "\nprocess PeakMerge {\n    label 'analysis'\n    publishDir \"${params.outdir}/peakCalling/mergedBed\", mode: 'link', overwrite: true,\n        saveAs: {filename ->\n            if (filename.indexOf(\"bed\") > 0) \"$filename\"\n        }\n    \n    input:\n    file peak_bed from merged_bed.collect()\n    file formatted_designfile from formatted_designfile.collect()\n\n    output:\n    file \"*merged*.bed\" into merge_result\n    file \"*merged_group*.bed\" into group_merged_bed\n    file \"*_merged_allpeaks.bed\" into all_merged_bed\n\n    script:\n    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    peakCalling_tools_count = (params.skip_metpeak ? 0 : 1).toInteger() + (params.skip_macs2 ? 0 : 1).toInteger() + (params.skip_matk ? 0 : 1).toInteger() + (params.skip_meyer ? 0 : 1).toInteger()\n    peakMerged_mode = params.peakMerged_mode\n    if ( peakMerged_mode == \"rank\" )  \n        println LikeletUtils.print_purple(\"Start merge peaks by RobustRankAggreg\")\n    else if ( peakMerged_mode == \"mspc\" )  \n        println LikeletUtils.print_purple(\"Start merge peaks by MSPC\")\n    else\n        println LikeletUtils.print_purple(\"Start merge peaks by \" + peakMerged_mode )\n    \"\"\"\n    cp ${baseDir}/bin/normalize_peaks.py ./\n    if [ ${peakMerged_mode} == \"rank\" ]; then \n        cp $baseDir/bin/merge_peaks_by_rank.R ./\n        bash $baseDir/bin/merge_peaks_by_rank.sh $formatted_designfile ${task.cpus} $flag_peakCallingbygroup $peakCalling_tools_count\n    elif [ ${peakMerged_mode} == \"mspc\" ]; then\n        bash $baseDir/bin/merge_peaks_by_mspc.sh $formatted_designfile ${task.cpus} $flag_peakCallingbygroup $peakCalling_tools_count mspc_results\n    elif [ ${peakMerged_mode} == \"macs2\" ]||[ ${peakMerged_mode} == \"metpeak\" ]||[ ${peakMerged_mode} == \"MATK\" ]||[ ${peakMerged_mode} == \"meyer\" ]; then \n        bash $baseDir/bin/merge_peaks_by_bedtools.sh $formatted_designfile ${task.cpus} $flag_peakCallingbygroup $peakCalling_tools_count $peakMerged_mode\n    else\n        echo -e \"Please check your value of peakMerged_mode: $peakMerged_mode\"\n    fi\n    whether_nopeaks=\\$(wc -l *merged*.bed | awk '\\$1==0{print \"error\"}' | uniq)\n    if [[ \\$whether_nopeaks == \"error\" ]] ;then \n        echo \"There is no peaks in one of the merged peaks files\" 1>&2\n        echo \"Merge Peaks by \"${peakMerged_mode}\" may not be suitable for your data.\" 1>&2\n        exit 1\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "    flag_peakCallingbygroup = params.peakCalling_mode == \"group\" ? 1 : 0\n    peakCalling_tools_count = (params.skip_metpeak ? 0 : 1).toInteger() + (params.skip_macs2 ? 0 : 1).toInteger() + (params.skip_matk ? 0 : 1).toInteger() + (params.skip_meyer ? 0 : 1).toInteger()\n    peakMerged_mode = params.peakMerged_mode\n    if ( peakMerged_mode == \"rank\" )  \n        println LikeletUtils.print_purple(\"Start merge peaks by RobustRankAggreg\")\n    else if ( peakMerged_mode == \"mspc\" )  \n        println LikeletUtils.print_purple(\"Start merge peaks by MSPC\")\n    else\n        println LikeletUtils.print_purple(\"Start merge peaks by \" + peakMerged_mode )\n    \"\"\"\n    cp ${baseDir}/bin/normalize_peaks.py ./\n    if [ ${peakMerged_mode} == \"rank\" ]; then \n        cp $baseDir/bin/merge_peaks_by_rank.R ./\n        bash $baseDir/bin/merge_peaks_by_rank.sh $formatted_designfile ${task.cpus} $flag_peakCallingbygroup $peakCalling_tools_count\n    elif [ ${peakMerged_mode} == \"mspc\" ]; then\n        bash $baseDir/bin/merge_peaks_by_mspc.sh $formatted_designfile ${task.cpus} $flag_peakCallingbygroup $peakCalling_tools_count mspc_results\n    elif [ ${peakMerged_mode} == \"macs2\" ]||[ ${peakMerged_mode} == \"metpeak\" ]||[ ${peakMerged_mode} == \"MATK\" ]||[ ${peakMerged_mode} == \"meyer\" ]; then \n        bash $baseDir/bin/merge_peaks_by_bedtools.sh $formatted_designfile ${task.cpus} $flag_peakCallingbygroup $peakCalling_tools_count $peakMerged_mode\n    else\n        echo -e \"Please check your value of peakMerged_mode: $peakMerged_mode\"\n    fi\n    whether_nopeaks=\\$(wc -l *merged*.bed | awk '\\$1==0{print \"error\"}' | uniq)\n    if [[ \\$whether_nopeaks == \"error\" ]] ;then \n        echo \"There is no peaks in one of the merged peaks files\" 1>&2\n        echo \"Merge Peaks by \"${peakMerged_mode}\" may not be suitable for your data.\" 1>&2\n        exit 1\n    fi\n    \"\"\"",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "merged_bed",
            "formatted_designfile"
        ],
        "nb_inputs": 2,
        "outputs": [
            "merge_result",
            "group_merged_bed",
            "all_merged_bed"
        ],
        "nb_outputs": 3,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "publishDir \"${params.outdir}/peakCalling/mergedBed\", mode: 'link', overwrite: true , saveAs: {filename -> if (filename.indexOf(\"bed\") > 0) \"$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "BedAnnotated": {
        "name_process": "BedAnnotated",
        "string_process": "\nprocess BedAnnotated{\n    label 'analysis'\n    publishDir \"${params.outdir}/m6AAnalysis/AnnotatedPeaks\", mode: 'link', overwrite: true\n    \n    input:\n    file all_bed from bed_for_annotation.collect()\n    file annotate_file from annotate_collection.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file fasta\n    file gtf\n\n    output:\n    file \"annotatedby{xy,homer}/*\" into annotation_results,annotation_results_2\n    file \"annotatedbyxy/*merged_allpeaks.anno.txt\" into methylation_annotaion_file\n    \n    when:\n    !params.skip_annotation\n\n    script:\n    annotated_script_dir = baseDir + \"/bin\"\n                                     \n    \"\"\"\n    # Annotation Peaks\n    cp ${annotated_script_dir}/intersec.pl ./\n    cp ${annotated_script_dir}/m6A_annotate_forGTF_xingyang2.pl ./\n    bash ${baseDir}/bin/annotation.sh ${fasta} ${gtf} ${task.cpus}  \n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    annotated_script_dir = baseDir + \"/bin\"\n                                     \n    \"\"\"\n    # Annotation Peaks\n    cp ${annotated_script_dir}/intersec.pl ./\n    cp ${annotated_script_dir}/m6A_annotate_forGTF_xingyang2.pl ./\n    bash ${baseDir}/bin/annotation.sh ${fasta} ${gtf} ${task.cpus}  \n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bed_for_annotation",
            "annotate_collection",
            "formatted_designfile",
            "fasta",
            "gtf"
        ],
        "nb_inputs": 5,
        "outputs": [
            "annotation_results",
            "annotation_results_2",
            "methylation_annotaion_file"
        ],
        "nb_outputs": 3,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "publishDir \"${params.outdir}/m6AAnalysis/AnnotatedPeaks\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_annotation",
        "stub": ""
    },
    "MotifSearching": {
        "name_process": "MotifSearching",
        "string_process": "\nprocess MotifSearching {\n    label 'analysis'\n    publishDir \"${params.outdir}/m6AAnalysis/motif\", mode: 'link', overwrite: true\n    \n    input:\n    file group_bed from motif_collection.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file bed12 from bed12file.collect()\n    file fasta\n    file gtf\n\n    output:\n    file \"*_{dreme,homer}\" into motif_results,motif_results_2\n\n    when:\n    !params.skip_motif\n\n    script:\n    motif_file_dir = baseDir + \"/bin\"\n    println LikeletUtils.print_purple(\"Motif analysis is going on by DREME and Homer\")\n    \"\"\"\n    cp ${motif_file_dir}/m6A_motif.meme ./\n    bash $baseDir/bin/motif_searching.sh $fasta $gtf $bed12 m6A_motif.meme ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    motif_file_dir = baseDir + \"/bin\"\n    println LikeletUtils.print_purple(\"Motif analysis is going on by DREME and Homer\")\n    \"\"\"\n    cp ${motif_file_dir}/m6A_motif.meme ./\n    bash $baseDir/bin/motif_searching.sh $fasta $gtf $bed12 m6A_motif.meme ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "motif_collection",
            "formatted_designfile",
            "bed12file",
            "fasta",
            "gtf"
        ],
        "nb_inputs": 5,
        "outputs": [
            "motif_results",
            "motif_results_2"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "publishDir \"${params.outdir}/m6AAnalysis/motif\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_motif",
        "stub": ""
    },
    "QCPeaksReport": {
        "name_process": "QCPeaksReport",
        "string_process": "\nprocess QCPeaksReport {\n    publishDir \"${params.outdir}/Report/QCPeaksReport\", mode: 'link', overwrite: true\n    \n    input:\n    file motif from motif_results.collect()\n    file annotation_files from annotation_results.collect()\n    file formatted_designfile from formatted_designfile.collect()\n\n    output:\n    file \"*.{html,pdf}\" into qcPeaksReport\n\n    script:\n    peakMerged_mode = params.peakMerged_mode \n    peakCalling_mode = params.peakCalling_mode\n    qcPeaksRData = \"QCPeakPlot.RData\"\n    \"\"\"\n    cp $baseDir/bin/QC_Peaks_Report.rmd ./\n    Rscript $baseDir/bin/QC_Peaks_Report.R $formatted_designfile $peakMerged_mode $peakCalling_mode $qcPeaksRData\n    R -e \"load(\\\\\"$qcPeaksRData\\\\\");rmarkdown::render('QC_Peaks_Report.rmd',output_file='QC_Peaks_Report_${peakMerged_mode}.html')\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    peakMerged_mode = params.peakMerged_mode \n    peakCalling_mode = params.peakCalling_mode\n    qcPeaksRData = \"QCPeakPlot.RData\"\n    \"\"\"\n    cp $baseDir/bin/QC_Peaks_Report.rmd ./\n    Rscript $baseDir/bin/QC_Peaks_Report.R $formatted_designfile $peakMerged_mode $peakCalling_mode $qcPeaksRData\n    R -e \"load(\\\\\"$qcPeaksRData\\\\\");rmarkdown::render('QC_Peaks_Report.rmd',output_file='QC_Peaks_Report_${peakMerged_mode}.html')\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "motif_results",
            "annotation_results",
            "formatted_designfile"
        ],
        "nb_inputs": 3,
        "outputs": [
            "qcPeaksReport"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/Report/QCPeaksReport\", mode: 'link', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "PeaksQuantification": {
        "name_process": "PeaksQuantification",
        "string_process": "\nprocess PeaksQuantification{\n    label 'analysis'\n    publishDir \"${params.outdir}/m6AAnalysis/m6AQuantification\", mode: 'link', overwrite: true\n    \n    input:\n    file merged_bed from all_merged_bed.collect()\n    file htseq_count_file from htseq_count_input.collect()\n    file bam_bai_file from sort_bam.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file annotation_file from methylation_annotaion_file.collect()\n    file gtf\n\n    output:\n    file \"*.{matrix,count}\" into quantification_results, quantification_matrix\n\n    when:\n    !params.skip_peakCalling\n\n    script:\n    matk_jar = params.matk_jar\n    methylation_analysis_mode = params.methylation_analysis_mode\n    if ( methylation_analysis_mode == \"Wilcox-test\" )  \n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by bedtools\")\n    else if ( methylation_analysis_mode == \"QNB\" )  \n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by QNB\")\n    else if ( methylation_analysis_mode == \"MATK\" )\n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by MATK\")\n    else if ( methylation_analysis_mode == \"edgeR\" )  \n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by edgeR\")\n    else if ( methylation_analysis_mode == \"DESeq2\" )\n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by DESeq2\")\n    \"\"\"\n    if [ ${methylation_analysis_mode} == \"DESeq2\" ]||[ ${methylation_analysis_mode} == \"edgeR\" ]; then \n        # PeaksQuantification by LRT\n        bash $baseDir/bin/bed_count.sh ${formatted_designfile} ${task.cpus} ${merged_bed} bam_stat_summary.txt\n        Rscript $baseDir/bin/bedtools_quantification.R $formatted_designfile bam_stat_summary.txt\n        head -1 *_quantification.matrix |sed 's/^\\\\t//'  |awk -F \"\\\\t\" '{print \"ID\\\\tGene_symbol\\\\t\"\\$0}' > tmp.header.file\n        sed '1d' *_quantification.matrix | sort > tmp.quantification.file\n        awk 'BEGIN{FS=\"\\\\t\";OFS=\"\\\\t\"}{print \\$4,\\$15,\\$11}' ${annotation_file} | sort | join -t \\$'\\t' -e 'NA' -a1 -o 1.1 -o 2.2 -o 2.3 tmp.quantification.file - >  tmp.annotation.file\n        join -t \\$'\\t' tmp.annotation.file tmp.quantification.file | cat tmp.header.file - > *_quantification.matrix \n    else\n        case ${methylation_analysis_mode} in \n        Wilcox-test)\n            bash $baseDir/bin/bed_count.sh ${formatted_designfile} ${task.cpus} ${merged_bed} bam_stat_summary.txt\n            Rscript $baseDir/bin/bedtools_quantification.R $formatted_designfile bam_stat_summary.txt\n            ;;\n        QNB|MeTDiff)\n            bash $baseDir/bin/bed_count.sh ${formatted_designfile} ${task.cpus} ${merged_bed} bam_stat_summary.txt\n            Rscript $baseDir/bin/QNB_quantification.R $formatted_designfile ${task.cpus}\n            ;;\n        MATK)\n            export OMP_NUM_THREADS=${task.cpus}\n            bash $baseDir/bin/MATK_quantification.sh $matk_jar $gtf $formatted_designfile ${merged_bed} 1\n            ;;\n        *)\n            echo ${methylation_analysis_mode}\" is not Wilcox-test, QNB, MATK, DESeq2 or edgeR\"\n            exit 1\n            ;;\n        esac\n        head -1 *_quantification.matrix |sed 's/^\\\\t//'  |awk -F \"\\\\t\" '{print \"ID\\\\tGene_symbol\\\\t\"\\$0}' > tmp.header.file\n        sed '1d' *_quantification.matrix | sort > tmp.quantification.file\n        awk 'BEGIN{FS=\"\\\\t\";OFS=\"\\\\t\"}{print \\$4,\\$15,\\$11}' ${annotation_file} | sort | join -t \\$'\\t' -e 'NA' -a1 -o 1.1 -o 2.2 -o 2.3 tmp.quantification.file - >  tmp.annotation.file\n        join -t \\$'\\t' tmp.annotation.file tmp.quantification.file | cat tmp.header.file - > *_quantification.matrix \n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 65,
        "string_script": "    matk_jar = params.matk_jar\n    methylation_analysis_mode = params.methylation_analysis_mode\n    if ( methylation_analysis_mode == \"Wilcox-test\" )  \n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by bedtools\")\n    else if ( methylation_analysis_mode == \"QNB\" )  \n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by QNB\")\n    else if ( methylation_analysis_mode == \"MATK\" )\n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by MATK\")\n    else if ( methylation_analysis_mode == \"edgeR\" )  \n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by edgeR\")\n    else if ( methylation_analysis_mode == \"DESeq2\" )\n        println LikeletUtils.print_purple(\"Generate m6A quantification matrix by DESeq2\")\n    \"\"\"\n    if [ ${methylation_analysis_mode} == \"DESeq2\" ]||[ ${methylation_analysis_mode} == \"edgeR\" ]; then \n        # PeaksQuantification by LRT\n        bash $baseDir/bin/bed_count.sh ${formatted_designfile} ${task.cpus} ${merged_bed} bam_stat_summary.txt\n        Rscript $baseDir/bin/bedtools_quantification.R $formatted_designfile bam_stat_summary.txt\n        head -1 *_quantification.matrix |sed 's/^\\\\t//'  |awk -F \"\\\\t\" '{print \"ID\\\\tGene_symbol\\\\t\"\\$0}' > tmp.header.file\n        sed '1d' *_quantification.matrix | sort > tmp.quantification.file\n        awk 'BEGIN{FS=\"\\\\t\";OFS=\"\\\\t\"}{print \\$4,\\$15,\\$11}' ${annotation_file} | sort | join -t \\$'\\t' -e 'NA' -a1 -o 1.1 -o 2.2 -o 2.3 tmp.quantification.file - >  tmp.annotation.file\n        join -t \\$'\\t' tmp.annotation.file tmp.quantification.file | cat tmp.header.file - > *_quantification.matrix \n    else\n        case ${methylation_analysis_mode} in \n        Wilcox-test)\n            bash $baseDir/bin/bed_count.sh ${formatted_designfile} ${task.cpus} ${merged_bed} bam_stat_summary.txt\n            Rscript $baseDir/bin/bedtools_quantification.R $formatted_designfile bam_stat_summary.txt\n            ;;\n        QNB|MeTDiff)\n            bash $baseDir/bin/bed_count.sh ${formatted_designfile} ${task.cpus} ${merged_bed} bam_stat_summary.txt\n            Rscript $baseDir/bin/QNB_quantification.R $formatted_designfile ${task.cpus}\n            ;;\n        MATK)\n            export OMP_NUM_THREADS=${task.cpus}\n            bash $baseDir/bin/MATK_quantification.sh $matk_jar $gtf $formatted_designfile ${merged_bed} 1\n            ;;\n        *)\n            echo ${methylation_analysis_mode}\" is not Wilcox-test, QNB, MATK, DESeq2 or edgeR\"\n            exit 1\n            ;;\n        esac\n        head -1 *_quantification.matrix |sed 's/^\\\\t//'  |awk -F \"\\\\t\" '{print \"ID\\\\tGene_symbol\\\\t\"\\$0}' > tmp.header.file\n        sed '1d' *_quantification.matrix | sort > tmp.quantification.file\n        awk 'BEGIN{FS=\"\\\\t\";OFS=\"\\\\t\"}{print \\$4,\\$15,\\$11}' ${annotation_file} | sort | join -t \\$'\\t' -e 'NA' -a1 -o 1.1 -o 2.2 -o 2.3 tmp.quantification.file - >  tmp.annotation.file\n        join -t \\$'\\t' tmp.annotation.file tmp.quantification.file | cat tmp.header.file - > *_quantification.matrix \n    fi\n    \"\"\"",
        "nb_lignes_script": 45,
        "language_script": "bash",
        "tools": [
            "joineRML",
            "CASE"
        ],
        "tools_url": [
            "https://bio.tools/joinerml",
            "https://bio.tools/CASE"
        ],
        "tools_dico": [
            {
                "name": "joineRML",
                "uri": "https://bio.tools/joinerml",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3569",
                            "term": "Applied mathematics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Joint Modelling of Multivariate Longitudinal Data and Time-to-Event Outcomes.",
                "homepage": "https://cran.r-project.org/web/packages/joineRML/"
            },
            {
                "name": "CASE",
                "uri": "https://bio.tools/CASE",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3559",
                                    "term": "Ontology visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3559",
                                    "term": "Ontology browsing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Advancing Coordinated Cyber-investigations and Tool Interoperability using a Community Developed Specification Language.\n\nSource files for the CASE website.\n\nAPI used for instantiating CASE objects (includes ontological verification and type checking).\n\nCyber-investigation Analysis Standard Expression (CASE).\n\nRead the CASE Wiki tab to learn everything you need to know about the Cyber-investigation Analysis Standard Expression (CASE) ontology. For learning about the Unified Cyber Ontology, CASE's parent, see UCO.\n\n\"@vocab\": \"http://case.example.org/core#\",.\n\nDET ER DINE PENGER DET DREIER SEG OM...\n\nVi er ikke st\ufffdrst, men garanterer effektiv behandling.\n\nLast ned v\ufffdr brosjyre i PDF format.\n\n||| COMMON LINK WITH (PUB. & NAME DIFFERENT) bio.tools/pymzml (GITHUB.COM).\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'UCO', 'cyber-investigation', 'cyber-investigations', 'plaso'",
                "homepage": "http://CASE.as"
            }
        ],
        "inputs": [
            "all_merged_bed",
            "htseq_count_input",
            "sort_bam",
            "formatted_designfile",
            "methylation_annotaion_file",
            "gtf"
        ],
        "nb_inputs": 6,
        "outputs": [
            "quantification_results",
            "quantification_matrix"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "publishDir \"${params.outdir}/m6AAnalysis/m6AQuantification\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_peakCalling",
        "stub": ""
    },
    "diffm6APeak": {
        "name_process": "diffm6APeak",
        "string_process": "\nprocess diffm6APeak{\n    label 'analysis'\n    tag \"$compare_str\"\n    publishDir \"${params.outdir}/m6AAnalysis/diffm6A\", mode: 'link', overwrite: true\n    \n    input:\n                                                   \n    file merged_bed from all_merged_bed.collect()\n    file bam_bai_file from sort_bam.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file count_matrix from quantification_matrix.collect()\n    file exp_matrix from htseq_results.collect()\n    file gtf\n    val compare_str from compareLines_for_diffm6A\n\n    output:\n    file \"*diffm6A*.txt\" into diffm6A_results\n\n    when:\n    !params.skip_diffpeakCalling && params.comparefile\n\n    script:\n    matk_jar = params.matk_jar\n    methylation_analysis_mode = params.methylation_analysis_mode\n    if ( methylation_analysis_mode == \"Wilcox-test\" )  \n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by bedtools\")\n    else if ( methylation_analysis_mode == \"QNB\" )  \n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by QNB\")\n    else if ( methylation_analysis_mode == \"MATK\" )\n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by MATK\")\n    else if ( methylation_analysis_mode == \"edgeR\" )  \n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by edgeR\")\n    else if ( methylation_analysis_mode == \"DESeq2\" )\n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by DESeq2\")\n    \"\"\"\n    case ${methylation_analysis_mode} in \n        Wilcox-test)\n            Rscript $baseDir/bin/bedtools_diffm6A.R $formatted_designfile bedtools_quantification.matrix $compare_str\n            ;;\n        QNB)\n            Rscript $baseDir/bin/QNB_diffm6A.R $formatted_designfile ${merged_bed} $compare_str   \n            ;;\n        MeTDiff)\n            Rscript $baseDir/bin/MeTDiff_diffm6A.R $formatted_designfile $compare_str \n            ;;\n        MATK)\n            export OMP_NUM_THREADS=${task.cpus}\n            bash $baseDir/bin/MATK_diffm6A.sh $matk_jar $formatted_designfile $gtf $compare_str $merged_bed\n            ;;\n        edgeR)\n            Rscript $baseDir/bin/GLM_edgeR_DM.R $formatted_designfile $compare_str bedtools_quantification.matrix $exp_matrix   \n            ;;\n        DESeq2)\n            Rscript $baseDir/bin/GLM_DESeq2_DM.R $formatted_designfile $compare_str ${task.cpus} bedtools_quantification.matrix $exp_matrix \n            ;;\n        *)\n            echo ${methylation_analysis_mode}\" is not Wilcox-test, QNB, MeTDiff, MATK, DESeq2 or edgeR\"\n            exit 1\n            ;;\n    esac   \n    \"\"\" \n}",
        "nb_lignes_process": 61,
        "string_script": "    matk_jar = params.matk_jar\n    methylation_analysis_mode = params.methylation_analysis_mode\n    if ( methylation_analysis_mode == \"Wilcox-test\" )  \n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by bedtools\")\n    else if ( methylation_analysis_mode == \"QNB\" )  \n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by QNB\")\n    else if ( methylation_analysis_mode == \"MATK\" )\n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by MATK\")\n    else if ( methylation_analysis_mode == \"edgeR\" )  \n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by edgeR\")\n    else if ( methylation_analysis_mode == \"DESeq2\" )\n        println LikeletUtils.print_purple(\"Differential m6A analysis is going on by DESeq2\")\n    \"\"\"\n    case ${methylation_analysis_mode} in \n        Wilcox-test)\n            Rscript $baseDir/bin/bedtools_diffm6A.R $formatted_designfile bedtools_quantification.matrix $compare_str\n            ;;\n        QNB)\n            Rscript $baseDir/bin/QNB_diffm6A.R $formatted_designfile ${merged_bed} $compare_str   \n            ;;\n        MeTDiff)\n            Rscript $baseDir/bin/MeTDiff_diffm6A.R $formatted_designfile $compare_str \n            ;;\n        MATK)\n            export OMP_NUM_THREADS=${task.cpus}\n            bash $baseDir/bin/MATK_diffm6A.sh $matk_jar $formatted_designfile $gtf $compare_str $merged_bed\n            ;;\n        edgeR)\n            Rscript $baseDir/bin/GLM_edgeR_DM.R $formatted_designfile $compare_str bedtools_quantification.matrix $exp_matrix   \n            ;;\n        DESeq2)\n            Rscript $baseDir/bin/GLM_DESeq2_DM.R $formatted_designfile $compare_str ${task.cpus} bedtools_quantification.matrix $exp_matrix \n            ;;\n        *)\n            echo ${methylation_analysis_mode}\" is not Wilcox-test, QNB, MeTDiff, MATK, DESeq2 or edgeR\"\n            exit 1\n            ;;\n    esac   \n    \"\"\"",
        "nb_lignes_script": 38,
        "language_script": "bash",
        "tools": [
            "CASE"
        ],
        "tools_url": [
            "https://bio.tools/CASE"
        ],
        "tools_dico": [
            {
                "name": "CASE",
                "uri": "https://bio.tools/CASE",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3559",
                                    "term": "Ontology visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3559",
                                    "term": "Ontology browsing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Advancing Coordinated Cyber-investigations and Tool Interoperability using a Community Developed Specification Language.\n\nSource files for the CASE website.\n\nAPI used for instantiating CASE objects (includes ontological verification and type checking).\n\nCyber-investigation Analysis Standard Expression (CASE).\n\nRead the CASE Wiki tab to learn everything you need to know about the Cyber-investigation Analysis Standard Expression (CASE) ontology. For learning about the Unified Cyber Ontology, CASE's parent, see UCO.\n\n\"@vocab\": \"http://case.example.org/core#\",.\n\nDET ER DINE PENGER DET DREIER SEG OM...\n\nVi er ikke st\ufffdrst, men garanterer effektiv behandling.\n\nLast ned v\ufffdr brosjyre i PDF format.\n\n||| COMMON LINK WITH (PUB. & NAME DIFFERENT) bio.tools/pymzml (GITHUB.COM).\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'UCO', 'cyber-investigation', 'cyber-investigations', 'plaso'",
                "homepage": "http://CASE.as"
            }
        ],
        "inputs": [
            "all_merged_bed",
            "sort_bam",
            "formatted_designfile",
            "quantification_matrix",
            "htseq_results",
            "gtf",
            "compareLines_for_diffm6A"
        ],
        "nb_inputs": 7,
        "outputs": [
            "diffm6A_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "tag \"$compare_str\"",
            "publishDir \"${params.outdir}/m6AAnalysis/diffm6A\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_diffpeakCalling && params.comparefile",
        "stub": ""
    },
    "SingleNucleotidePrediction": {
        "name_process": "SingleNucleotidePrediction",
        "string_process": "\nprocess SingleNucleotidePrediction{\n    label 'analysis'\n    publishDir \"${params.outdir}/m6AAnalysis/m6APredictionSites\", mode: 'link', overwrite: true\n    \n    input:\n    file peak_bed from group_merged_bed.collect()\n    file group_bed from all_merged_bed.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    file bam_bai_file from sort_bam.collect()\n    file fasta\n    file gtf\n\n    output:\n    file \"m6A_sites*.bed\" into prediction_results\n\n    when:\n    !params.skip_m6Aprediction\n\n    script:\n    matk_jar = params.matk_jar\n    println LikeletUtils.print_purple(\"SignleNucleotide Prediction analysis is going on by MATK\")\n    \"\"\"\n    export OMP_NUM_THREADS=${task.cpus}\n    bash $baseDir/bin/m6Aprediction.sh $matk_jar $formatted_designfile $fasta $gtf\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    matk_jar = params.matk_jar\n    println LikeletUtils.print_purple(\"SignleNucleotide Prediction analysis is going on by MATK\")\n    \"\"\"\n    export OMP_NUM_THREADS=${task.cpus}\n    bash $baseDir/bin/m6Aprediction.sh $matk_jar $formatted_designfile $fasta $gtf\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "group_merged_bed",
            "all_merged_bed",
            "formatted_designfile",
            "sort_bam",
            "fasta",
            "gtf"
        ],
        "nb_inputs": 6,
        "outputs": [
            "prediction_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "label 'analysis'",
            "publishDir \"${params.outdir}/m6AAnalysis/m6APredictionSites\", mode: 'link', overwrite: true"
        ],
        "when": "!params.skip_m6Aprediction",
        "stub": ""
    },
    "DiffReport": {
        "name_process": "DiffReport",
        "string_process": "\nprocess DiffReport {\n    publishDir \"${params.outdir}/Report\" , mode: 'link', overwrite: true,\n        saveAs: {filename ->\n                 if (filename.indexOf(\".html\") > 0)  \"diffReport/$filename\"\n                 else if (filename.indexOf(\".pdf\") > 0)  \"diffReport/$filename\"\n                 else \"ReportRData/$filename\"\n        }        \n    input:\n    file results from results_arrange.collect()\n    file formatted_designfile from formatted_designfile.collect()\n    val compare_info from compareLines_for_arranged_result.collect()\n    \n    output:\n    file \"*.m6APipe\" into m6APipe_result\n    file \"*.{html,pdf}\" into diffReport_result\n\n    when:\n    !params.skip_annotation && !params.skip_expression && !params.skip_diffpeakCalling && !params.skip_peakCalling\n    \n    script:\n    methylation_analysis_mode = params.methylation_analysis_mode\n    expression_analysis_mode = params.expression_analysis_mode\n    peakMerged_mode = params.peakMerged_mode\n    diffReportRData = \"DiffReport.RData\"\n    \"\"\"\n    cp $baseDir/bin/DiffReport.rmd ./\n    if [ \"$compare_info\" != \"[two_group]\" ]; then\n        echo $compare_info | sed 's/^\\\\[//g' | sed 's/\\\\]\\$//g' | sed s/[[:space:]]//g > compare_info\n    else\n        echo \\$(awk 'BEGIN{FS=\",\"}NR>1{print \\$4}' $formatted_designfile |sort|uniq|awk 'NR==1{printf \\$0\"_vs_\"}NR==2{print \\$0}') > compare_info\n    fi\n    Rscript $baseDir/bin/arranged_results.R $formatted_designfile compare_info $methylation_analysis_mode $expression_analysis_mode $peakMerged_mode\n    Rscript $baseDir/bin/DiffReport.R *.m6APipe $diffReportRData\n    R -e \"load(\\\\\"$diffReportRData\\\\\");rmarkdown::render('DiffReport.rmd',output_file='DiffReport_${peakMerged_mode}_${methylation_analysis_mode}_${expression_analysis_mode}.html')\"\n    rm Rplots.pdf\n    \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "    methylation_analysis_mode = params.methylation_analysis_mode\n    expression_analysis_mode = params.expression_analysis_mode\n    peakMerged_mode = params.peakMerged_mode\n    diffReportRData = \"DiffReport.RData\"\n    \"\"\"\n    cp $baseDir/bin/DiffReport.rmd ./\n    if [ \"$compare_info\" != \"[two_group]\" ]; then\n        echo $compare_info | sed 's/^\\\\[//g' | sed 's/\\\\]\\$//g' | sed s/[[:space:]]//g > compare_info\n    else\n        echo \\$(awk 'BEGIN{FS=\",\"}NR>1{print \\$4}' $formatted_designfile |sort|uniq|awk 'NR==1{printf \\$0\"_vs_\"}NR==2{print \\$0}') > compare_info\n    fi\n    Rscript $baseDir/bin/arranged_results.R $formatted_designfile compare_info $methylation_analysis_mode $expression_analysis_mode $peakMerged_mode\n    Rscript $baseDir/bin/DiffReport.R *.m6APipe $diffReportRData\n    R -e \"load(\\\\\"$diffReportRData\\\\\");rmarkdown::render('DiffReport.rmd',output_file='DiffReport_${peakMerged_mode}_${methylation_analysis_mode}_${expression_analysis_mode}.html')\"\n    rm Rplots.pdf\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "results_arrange",
            "formatted_designfile",
            "compareLines_for_arranged_result"
        ],
        "nb_inputs": 3,
        "outputs": [
            "m6APipe_result",
            "diffReport_result"
        ],
        "nb_outputs": 2,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/Report\" , mode: 'link', overwrite: true , saveAs: {filename -> if (filename.indexOf(\".html\") > 0) \"diffReport/$filename\" else if (filename.indexOf(\".pdf\") > 0) \"diffReport/$filename\" else \"ReportRData/$filename\" }"
        ],
        "when": "!params.skip_annotation && !params.skip_expression && !params.skip_diffpeakCalling && !params.skip_peakCalling",
        "stub": ""
    },
    "CreateIGVjs": {
        "name_process": "CreateIGVjs",
        "string_process": "\nprocess CreateIGVjs {\n    publishDir \"${params.outdir}/Report\" , mode: 'link', overwrite: true,\n        saveAs: {filename ->\n                 if (filename.indexOf(\".html\") > 0)  \"Igv_js/$filename\"\n                 else if (filename.indexOf(\".pdf\") > 0)  \"Igv_js/$filename\"\n                 else \"Igv_js/$filename\"\n        }        \n    input:\n    file m6APipe_result from m6APipe_result\n    file fasta \n    file gtf\n    file formatted_designfile from formatted_designfile.collect()\n    file group_bed from group_merged_bed.collect()\n    file all_bed from all_merged_bed.collect()\n    file bedgraph from bedgraph_for_genebody.collect()\n    \n    output:\n    file \"*\" into igv_js\n\n    script:    \n    igv_fasta = fasta.baseName.toString() + \".igv.fa\"\n    igv_gtf = gtf.baseName.toString() + \".igv.gtf\"\n    merged_allpeaks_igvfile = all_bed.baseName.toString() + \".igv.bed\"\n    \"\"\"\n    ls -l $fasta | awk -F \"> \" '{print \"ln -s \"\\$2\" ./'$igv_fasta'\"}' | bash\n    ls -l $gtf | awk -F \"> \" '{print \"ln -s \"\\$2\" ./'$igv_gtf'\"}' | bash\n    ls -l $m6APipe_result | awk '{print \"ln -s \"\\$11\" initial.m6APipe\"}' | bash\n    ls -l $group_bed $all_bed | awk '{sub(\".bed\\$\",\".igv.bed\",\\$9);print \"ln -s \"\\$11,\\$9}' | bash\n    ls -l $bedgraph | awk '{sub(\".bedgraph\\$\",\".igv.bedgraph\",\\$9);print \"ln -s \"\\$11,\\$9}' | bash\n    samtools faidx $igv_fasta\n    bash $baseDir/bin/create_IGV_js.sh $igv_fasta $igv_gtf $merged_allpeaks_igvfile $formatted_designfile\n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    igv_fasta = fasta.baseName.toString() + \".igv.fa\"\n    igv_gtf = gtf.baseName.toString() + \".igv.gtf\"\n    merged_allpeaks_igvfile = all_bed.baseName.toString() + \".igv.bed\"\n    \"\"\"\n    ls -l $fasta | awk -F \"> \" '{print \"ln -s \"\\$2\" ./'$igv_fasta'\"}' | bash\n    ls -l $gtf | awk -F \"> \" '{print \"ln -s \"\\$2\" ./'$igv_gtf'\"}' | bash\n    ls -l $m6APipe_result | awk '{print \"ln -s \"\\$11\" initial.m6APipe\"}' | bash\n    ls -l $group_bed $all_bed | awk '{sub(\".bed\\$\",\".igv.bed\",\\$9);print \"ln -s \"\\$11,\\$9}' | bash\n    ls -l $bedgraph | awk '{sub(\".bedgraph\\$\",\".igv.bedgraph\",\\$9);print \"ln -s \"\\$11,\\$9}' | bash\n    samtools faidx $igv_fasta\n    bash $baseDir/bin/create_IGV_js.sh $igv_fasta $igv_gtf $merged_allpeaks_igvfile $formatted_designfile\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "m6APipe_result",
            "fasta",
            "gtf",
            "formatted_designfile",
            "group_merged_bed",
            "all_merged_bed",
            "bedgraph_for_genebody"
        ],
        "nb_inputs": 7,
        "outputs": [
            "igv_js"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/Report\" , mode: 'link', overwrite: true , saveAs: {filename -> if (filename.indexOf(\".html\") > 0) \"Igv_js/$filename\" else if (filename.indexOf(\".pdf\") > 0) \"Igv_js/$filename\" else \"Igv_js/$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n    publishDir \"${params.outdir}/pipeline_info\", mode: 'copy',\n        saveAs: { filename ->\n            if (filename.indexOf(\".csv\") > 0) filename\n            else null\n        }\n\n    output:\n    file 'software_versions_mqc.yaml' into software_versions_yaml\n    file \"software_versions.csv\"\n\n    script:\n                                                                     \n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    multiqc --version > v_multiqc.txt\n    python ${baseDir}/bin/scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    multiqc --version > v_multiqc.txt\n    python ${baseDir}/bin/scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "FastQC",
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc",
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "software_versions_yaml"
        ],
        "nb_outputs": 1,
        "name_workflow": "leipzig__m6a",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: 'copy' , saveAs: { filename -> if (filename.indexOf(\".csv\") > 0) filename else null }"
        ],
        "when": "",
        "stub": ""
    }
}