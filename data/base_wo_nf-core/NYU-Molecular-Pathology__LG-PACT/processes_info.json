{
    "git": {
        "name_process": "git",
        "string_process": "\nprocess git {\n                           \n    publishDir \"${params.outputDir}\", mode: 'copy'\n    output:\n    file(\"${output_file}\") into git_json_ch\n\n    script:\n    output_file = \"${git_json}\"\n    \"\"\"\n    git.py --dir \"${workflow.projectDir}\" -o \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    output_file = \"${git_json}\"\n    \"\"\"\n    git.py --dir \"${workflow.projectDir}\" -o \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "git_json_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "copy_samplesheet": {
        "name_process": "copy_samplesheet",
        "string_process": "\nprocess copy_samplesheet {\n                                                             \n                                                         \n    publishDir \"${params.outputDir}\", mode: 'copy'\n    executor \"local\"\n\n    input:\n    file(input_sheet: \"input_samplesheet.tsv\") from samples_analysis_sheet\n\n    output:\n    file(\"${samplesheet_output_file}\") into samplesheet_output_file_ch\n    val(\"\") into done_copy_samplesheet\n\n    script:\n    \"\"\"\n    cp \"${input_sheet}\" \"${samplesheet_output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    cp \"${input_sheet}\" \"${samplesheet_output_file}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_analysis_sheet"
        ],
        "nb_inputs": 1,
        "outputs": [
            "samplesheet_output_file_ch",
            "done_copy_samplesheet"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'",
            "executor \"local\""
        ],
        "when": "",
        "stub": ""
    },
    "print_metadata": {
        "name_process": "print_metadata",
        "string_process": "\nprocess print_metadata {\n                                                           \n    publishDir \"${params.outputDir}\", mode: 'copy'\n    executor \"local\"\n\n    input:\n    val(x) from Channel.from('')\n\n    output:\n    file(\"${output_file}\") into metadata_ch\n    val(\"\") into done_print_metadata\n\n    script:\n    output_file = \"meta.tsv\"\n    \"\"\"\n    printf \"Run\\tTime\\tSession\\tWorkflow\\tLocation\\tSystem\\tOutputPath\\tUsername\\n\" > \"${output_file}\"\n    printf \"${runID}\\t${workflowTimestamp}\\t${workflow.sessionId}\\t${workflow.runName}\\t${workflow.projectDir}\\t${localhostname}\\t${outputDirPath}\\t${username}\\n\" >> \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    output_file = \"meta.tsv\"\n    \"\"\"\n    printf \"Run\\tTime\\tSession\\tWorkflow\\tLocation\\tSystem\\tOutputPath\\tUsername\\n\" > \"${output_file}\"\n    printf \"${runID}\\t${workflowTimestamp}\\t${workflow.sessionId}\\t${workflow.runName}\\t${workflow.projectDir}\\t${localhostname}\\t${outputDirPath}\\t${username}\\n\" >> \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "metadata_ch",
            "done_print_metadata"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'",
            "executor \"local\""
        ],
        "when": "",
        "stub": ""
    },
    "targets_zip": {
        "name_process": "targets_zip",
        "string_process": "\nprocess targets_zip {\n    input:\n    file(targets_bed) from targets_bed13\n\n    output:\n    set file(\"${output_bgz}\"), file(\"${output_index}\") into targets_zipped, targets_zipped2\n\n    script:\n    output_bgz = \"targets.bed.bgz\"\n    output_index = \"targets.bed.bgz.tbi\"\n    \"\"\"\n    sort -V -k1,1 -k2,2 \"${targets_bed}\" > targets.sorted.bed\n    bgzip -c targets.sorted.bed > \"${output_bgz}\"\n    tabix -p bed \"${output_bgz}\"\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    output_bgz = \"targets.bed.bgz\"\n    output_index = \"targets.bed.bgz.tbi\"\n    \"\"\"\n    sort -V -k1,1 -k2,2 \"${targets_bed}\" > targets.sorted.bed\n    bgzip -c targets.sorted.bed > \"${output_bgz}\"\n    tabix -p bed \"${output_bgz}\"\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "targets_bed13"
        ],
        "nb_inputs": 1,
        "outputs": [
            "targets_zipped",
            "targets_zipped2"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "targets_metrics": {
        "name_process": "targets_metrics",
        "string_process": "\nprocess targets_metrics {\n                                      \n    publishDir \"${params.outputDir}/metrics/targets\", mode: 'copy', pattern: \"*.bed\"\n    publishDir \"${params.outputDir}\", mode: 'copy', pattern: \"*${targets_metrics}\"\n    executor \"local\"\n\n    input:\n    file(targets) from targets_bed9\n\n    output:\n    file(\"${targets_metrics}\") into targets_metrics_ch\n\n    script:\n    targets_sorted = \"targets.sorted.bed\"\n    targets_merged = \"targets.merged.bed\"\n    targets_metrics = \"targets.metrics.tsv\"\n    \"\"\"\n    num_targets=\"\\$(cat \"${targets}\" | wc -l)\"\n    targets_md5=\"\\$(python -c \"import hashlib; print(hashlib.md5(open('${targets}', 'rb').read()).hexdigest())\")\"\n\n    # check if there are strands in the targets\n    if [ \"\\$(bed.py \"${targets}\" hasStrands)\" == \"True\" ]; then\n        sort -k 1,1 -k2,2n \"${targets}\" > \"${targets_sorted}\"\n        bedtools merge -s -i \"${targets_sorted}\" > \"${targets_merged}\"\n    else\n        sort -k 1,1 -k2,2n \"${targets}\" > \"${targets_sorted}\"\n        bedtools merge -i \"${targets_sorted}\" > \"${targets_merged}\"\n    fi\n\n    num_merged_targets=\"\\$(cat \"${targets_merged}\" | wc -l)\"\n\n    targets_coverage_bp=\"\\$(bed.py \"${targets}\" breadthOfCoverage)\"\n    targets_coverage_Mbp=\"\\$(python -c \"print( \\${targets_coverage_bp} / float((10**6)) )\")\"\n\n    targets_filename=\"\\$(python -c \"import os; print(os.path.basename(os.path.realpath('${targets}')))\")\"\n\n    printf 'Targets File\\tNumber of Targets\\tNumber of Merged Targets\\tBreadth Of Coverage (Mbp)\\tBreadth Of Coverage (bp)\\tmd5\\n' > \"${targets_metrics}\"\n    printf \"\\${targets_filename}\\t\\${num_targets}\\t\\${num_merged_targets}\\t\\${targets_coverage_Mbp}\\t\\${targets_coverage_bp}\\t\\${targets_md5}\\n\" >> \"${targets_metrics}\"\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    targets_sorted = \"targets.sorted.bed\"\n    targets_merged = \"targets.merged.bed\"\n    targets_metrics = \"targets.metrics.tsv\"\n    \"\"\"\n    num_targets=\"\\$(cat \"${targets}\" | wc -l)\"\n    targets_md5=\"\\$(python -c \"import hashlib; print(hashlib.md5(open('${targets}', 'rb').read()).hexdigest())\")\"\n\n    # check if there are strands in the targets\n    if [ \"\\$(bed.py \"${targets}\" hasStrands)\" == \"True\" ]; then\n        sort -k 1,1 -k2,2n \"${targets}\" > \"${targets_sorted}\"\n        bedtools merge -s -i \"${targets_sorted}\" > \"${targets_merged}\"\n    else\n        sort -k 1,1 -k2,2n \"${targets}\" > \"${targets_sorted}\"\n        bedtools merge -i \"${targets_sorted}\" > \"${targets_merged}\"\n    fi\n\n    num_merged_targets=\"\\$(cat \"${targets_merged}\" | wc -l)\"\n\n    targets_coverage_bp=\"\\$(bed.py \"${targets}\" breadthOfCoverage)\"\n    targets_coverage_Mbp=\"\\$(python -c \"print( \\${targets_coverage_bp} / float((10**6)) )\")\"\n\n    targets_filename=\"\\$(python -c \"import os; print(os.path.basename(os.path.realpath('${targets}')))\")\"\n\n    printf 'Targets File\\tNumber of Targets\\tNumber of Merged Targets\\tBreadth Of Coverage (Mbp)\\tBreadth Of Coverage (bp)\\tmd5\\n' > \"${targets_metrics}\"\n    printf \"\\${targets_filename}\\t\\${num_targets}\\t\\${num_merged_targets}\\t\\${targets_coverage_Mbp}\\t\\${targets_coverage_bp}\\t\\${targets_md5}\\n\" >> \"${targets_metrics}\"\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "targets_bed9"
        ],
        "nb_inputs": 1,
        "outputs": [
            "targets_metrics_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/metrics/targets\", mode: 'copy', pattern: \"*.bed\"",
            "publishDir \"${params.outputDir}\", mode: 'copy', pattern: \"*${targets_metrics}\"",
            "executor \"local\""
        ],
        "when": "",
        "stub": ""
    },
    "annotate_targets": {
        "name_process": "annotate_targets",
        "string_process": "\nprocess annotate_targets {\n                                      \n    input:\n    set file(targets_bed), file(annovar_db_dir) from targets_bed11.combine(annovar_db_dir4)\n\n    output:\n    file(\"${output_file}\") into annotated_targets\n\n    script:\n    prefix = \"targets\"\n    interval_tmp = \"${prefix}.intervals.tmp\"\n    remainder_tsv = \"${prefix}.remainder.tsv\"\n    avinput_file = \"${prefix}.avinput\"\n    annovar_output_txt = \"${prefix}.${target_ANNOVAR_BUILD_VERSION}_multianno.txt\"\n    output_file = \"${targets_annotations_file}\"\n    \"\"\"\n    # convert table to ANNOVAR format for annotation; http://annovar.openbioinformatics.org/en/latest/user-guide/input/\n    # add '0' cols for ref and alt\n    cut -f1-3 \"${targets_bed}\" > \"${avinput_file}\"\n    sed -e 's|\\$|\\t0|' -i \"${avinput_file}\"\n    sed -e 's|\\$|\\t0|' -i \"${avinput_file}\"\n\n    # annotate\n    table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n    --buildver \"${target_ANNOVAR_BUILD_VERSION}\" \\\n    --remove \\\n    --protocol \"${target_ANNOVAR_PROTOCOL}\" \\\n    --operation \"${target_ANNOVAR_OPERATION}\" \\\n    --nastring . \\\n    --outfile \"${prefix}\"\n\n    mv \"${annovar_output_txt}\" \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    prefix = \"targets\"\n    interval_tmp = \"${prefix}.intervals.tmp\"\n    remainder_tsv = \"${prefix}.remainder.tsv\"\n    avinput_file = \"${prefix}.avinput\"\n    annovar_output_txt = \"${prefix}.${target_ANNOVAR_BUILD_VERSION}_multianno.txt\"\n    output_file = \"${targets_annotations_file}\"\n    \"\"\"\n    # convert table to ANNOVAR format for annotation; http://annovar.openbioinformatics.org/en/latest/user-guide/input/\n    # add '0' cols for ref and alt\n    cut -f1-3 \"${targets_bed}\" > \"${avinput_file}\"\n    sed -e 's|\\$|\\t0|' -i \"${avinput_file}\"\n    sed -e 's|\\$|\\t0|' -i \"${avinput_file}\"\n\n    # annotate\n    table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n    --buildver \"${target_ANNOVAR_BUILD_VERSION}\" \\\n    --remove \\\n    --protocol \"${target_ANNOVAR_PROTOCOL}\" \\\n    --operation \"${target_ANNOVAR_OPERATION}\" \\\n    --nastring . \\\n    --outfile \"${prefix}\"\n\n    mv \"${annovar_output_txt}\" \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "wossinput"
        ],
        "tools_url": [
            "https://bio.tools/wossinput"
        ],
        "tools_dico": [
            {
                "name": "wossinput",
                "uri": "https://bio.tools/wossinput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM input data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossinput.html"
            }
        ],
        "inputs": [
            "targets_bed11",
            "annovar_db_dir4"
        ],
        "nb_inputs": 2,
        "outputs": [
            "annotated_targets"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "fastq_merge": {
        "name_process": "fastq_merge",
        "string_process": "\nprocess fastq_merge {\n                                                                                         \n    input:\n    set val(sampleID), file(fastq_r1: \"*\"), file(fastq_r2: \"*\") from samples_R1_R2\n\n    output:\n    set val(sampleID), file(\"${merged_fastq_R1}\"), file(\"${merged_fastq_R2}\") into samples_fastq_merged\n    file(\"${num_reads_R1}\")\n    file(\"${num_reads_R2}\")\n    file(\"${num_reads}\")\n    val(sampleID) into done_fastq_merge\n\n    script:\n    prefix = \"${sampleID}\"\n    merged_fastq_R1 = \"${prefix}_R1.fastq.gz\"\n    merged_fastq_R2 = \"${prefix}_R2.fastq.gz\"\n    num_reads = \"${prefix}.reads.txt\"\n    num_reads_R1 = \"${prefix}_R1.reads.txt\"\n    num_reads_R2 = \"${prefix}_R2.reads.txt\"\n    \"\"\"\n    cat ${fastq_r1} > \"${merged_fastq_R1}\"\n    cat ${fastq_r2} > \"${merged_fastq_R2}\"\n\n    # get the number of reads\n    zcat \"${merged_fastq_R1}\" | awk '{s++}END{print s/4}' > \"${num_reads}\"\n    cp \"${num_reads}\" \"${num_reads_R1}\"\n    zcat \"${merged_fastq_R2}\" | awk '{s++}END{print s/4}' > \"${num_reads_R2}\"\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    prefix = \"${sampleID}\"\n    merged_fastq_R1 = \"${prefix}_R1.fastq.gz\"\n    merged_fastq_R2 = \"${prefix}_R2.fastq.gz\"\n    num_reads = \"${prefix}.reads.txt\"\n    num_reads_R1 = \"${prefix}_R1.reads.txt\"\n    num_reads_R2 = \"${prefix}_R2.reads.txt\"\n    \"\"\"\n    cat ${fastq_r1} > \"${merged_fastq_R1}\"\n    cat ${fastq_r2} > \"${merged_fastq_R2}\"\n\n    # get the number of reads\n    zcat \"${merged_fastq_R1}\" | awk '{s++}END{print s/4}' > \"${num_reads}\"\n    cp \"${num_reads}\" \"${num_reads_R1}\"\n    zcat \"${merged_fastq_R2}\" | awk '{s++}END{print s/4}' > \"${num_reads_R2}\"\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_R1_R2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "samples_fastq_merged",
            "done_fastq_merge"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "trimmomatic": {
        "name_process": "trimmomatic",
        "string_process": "\nprocess trimmomatic {\n                                        \n    publishDir \"${params.outputDir}/reads/trimmed\", mode: 'copy', pattern: \"*${fastq_R1_trimmed}\"\n    publishDir \"${params.outputDir}/reads/trimmed\", mode: 'copy', pattern: \"*${fastq_R2_trimmed}\"\n    publishDir \"${params.outputDir}/reads/stats\", mode: 'copy', pattern: \"*.txt\"\n\n    input:\n    set val(sampleID), file(read1), file(read2), file(trimmomatic_contaminant_fa) from samples_fastq_merged.combine(trimmomatic_contaminant_fa)\n\n    output:\n    set val(sampleID), file(\"${fastq_R1_trimmed}\"), file(\"${fastq_R2_trimmed}\") into samples_fastq_trimmed, samples_fastq_trimmed2\n    file(\"${num_reads_trim}\")\n    file(\"${num_reads_trim_R1}\")\n    file(\"${num_reads_trim_R2}\")\n    file(\"${num_reads_unpaired_R1}\")\n    file(\"${num_reads_unpaired_R2}\")\n    val(sampleID) into done_trimmomatic\n\n    script:\n    prefix = \"${sampleID}\"\n    fastq_R1_trimmed = \"${prefix}_R1.trim.fastq.gz\"\n    fastq_R2_trimmed = \"${prefix}_R2.trim.fastq.gz\"\n    fastq_R1_unpaired = \"${prefix}_R1.unpaired.fastq.gz\"\n    fastq_R2_unpaired = \"${prefix}_R2.unpaired.fastq.gz\"\n    num_reads_trim = \"${prefix}.trim.reads.txt\"\n    num_reads_trim_R1 = \"${prefix}_R1.trim.reads.txt\"\n    num_reads_trim_R2 = \"${prefix}_R2.trim.reads.txt\"\n    num_reads_unpaired_R1 = \"${prefix}_R1.unpaired.reads.txt\"\n    num_reads_unpaired_R2 = \"${prefix}_R2.unpaired.reads.txt\"\n    \"\"\"\n    trimmomatic.sh PE -threads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    \"${read1}\" \"${read2}\" \\\n    \"${fastq_R1_trimmed}\" \"${fastq_R1_unpaired}\" \\\n    \"${fastq_R2_trimmed}\" \"${fastq_R2_unpaired}\" \\\n    ILLUMINACLIP:${trimmomatic_contaminant_fa}:2:30:10:1:true TRAILING:5 SLIDINGWINDOW:4:15 MINLEN:35\n\n    # get the number of reads\n    zcat \"${fastq_R1_trimmed}\" | awk '{s++}END{print s/4}' > \"${num_reads_trim}\"\n    cp \"${num_reads_trim}\" \"${num_reads_trim_R1}\"\n    zcat \"${fastq_R2_trimmed}\" | awk '{s++}END{print s/4}' > \"${num_reads_trim_R2}\"\n    zcat \"${fastq_R1_unpaired}\" | awk '{s++}END{print s/4}' > \"${num_reads_unpaired_R1}\"\n    zcat \"${fastq_R2_unpaired}\" | awk '{s++}END{print s/4}' > \"${num_reads_unpaired_R2}\"\n    \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "    prefix = \"${sampleID}\"\n    fastq_R1_trimmed = \"${prefix}_R1.trim.fastq.gz\"\n    fastq_R2_trimmed = \"${prefix}_R2.trim.fastq.gz\"\n    fastq_R1_unpaired = \"${prefix}_R1.unpaired.fastq.gz\"\n    fastq_R2_unpaired = \"${prefix}_R2.unpaired.fastq.gz\"\n    num_reads_trim = \"${prefix}.trim.reads.txt\"\n    num_reads_trim_R1 = \"${prefix}_R1.trim.reads.txt\"\n    num_reads_trim_R2 = \"${prefix}_R2.trim.reads.txt\"\n    num_reads_unpaired_R1 = \"${prefix}_R1.unpaired.reads.txt\"\n    num_reads_unpaired_R2 = \"${prefix}_R2.unpaired.reads.txt\"\n    \"\"\"\n    trimmomatic.sh PE -threads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    \"${read1}\" \"${read2}\" \\\n    \"${fastq_R1_trimmed}\" \"${fastq_R1_unpaired}\" \\\n    \"${fastq_R2_trimmed}\" \"${fastq_R2_unpaired}\" \\\n    ILLUMINACLIP:${trimmomatic_contaminant_fa}:2:30:10:1:true TRAILING:5 SLIDINGWINDOW:4:15 MINLEN:35\n\n    # get the number of reads\n    zcat \"${fastq_R1_trimmed}\" | awk '{s++}END{print s/4}' > \"${num_reads_trim}\"\n    cp \"${num_reads_trim}\" \"${num_reads_trim_R1}\"\n    zcat \"${fastq_R2_trimmed}\" | awk '{s++}END{print s/4}' > \"${num_reads_trim_R2}\"\n    zcat \"${fastq_R1_unpaired}\" | awk '{s++}END{print s/4}' > \"${num_reads_unpaired_R1}\"\n    zcat \"${fastq_R2_unpaired}\" | awk '{s++}END{print s/4}' > \"${num_reads_unpaired_R2}\"\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_fastq_merged",
            "trimmomatic_contaminant_fa"
        ],
        "nb_inputs": 2,
        "outputs": [
            "samples_fastq_trimmed",
            "samples_fastq_trimmed2",
            "done_trimmomatic"
        ],
        "nb_outputs": 3,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/reads/trimmed\", mode: 'copy', pattern: \"*${fastq_R1_trimmed}\"",
            "publishDir \"${params.outputDir}/reads/trimmed\", mode: 'copy', pattern: \"*${fastq_R2_trimmed}\"",
            "publishDir \"${params.outputDir}/reads/stats\", mode: 'copy', pattern: \"*.txt\""
        ],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n                                           \n    publishDir \"${params.outputDir}/qc/fastqc\", mode: 'copy'\n\n    input:\n    set val(sampleID),  file(fastq_R1), file(fastq_R2) from samples_fastq_trimmed2\n\n    output:\n    file(output_R1_html)\n    file(output_R1_zip)\n    file(output_R2_html)\n    file(output_R2_zip)\n    val(sampleID) into done_fastqc_trim\n\n    script:\n    output_R1_html = \"${fastq_R1}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_R1_zip = \"${fastq_R1}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    output_R2_html = \"${fastq_R2}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_R2_zip = \"${fastq_R2}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    \"\"\"\n    fastqc -o . \"${fastq_R1}\"\n    fastqc -o . \"${fastq_R2}\"\n    \"\"\"\n\n}",
        "nb_lignes_process": 24,
        "string_script": "    output_R1_html = \"${fastq_R1}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_R1_zip = \"${fastq_R1}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    output_R2_html = \"${fastq_R2}\".replaceFirst(/.fastq.gz$/, \"_fastqc.html\")\n    output_R2_zip = \"${fastq_R2}\".replaceFirst(/.fastq.gz$/, \"_fastqc.zip\")\n    \"\"\"\n    fastqc -o . \"${fastq_R1}\"\n    fastqc -o . \"${fastq_R2}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "samples_fastq_trimmed2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "output_R1_html",
            "output_R1_zip",
            "output_R2_html",
            "output_R2_zip",
            "done_fastqc_trim"
        ],
        "nb_outputs": 5,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/qc/fastqc\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "alignment": {
        "name_process": "alignment",
        "string_process": "\nprocess alignment {\n                                    \n    publishDir \"${params.outputDir}/alignments/raw\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(fastq_R1_trim), file(fastq_R2_trim), file(ref_fa_bwa_dir) from samples_fastq_trimmed.combine(ref_fa_bwa_dir)\n\n    output:\n    set val(sampleID), file(\"${bam_file}\") into samples_bam, samples_bam2, samples_bam3, samples_bam4\n    val(sampleID) into done_alignment\n\n    script:\n    prefix = \"${sampleID}\"\n    bam_file = \"${prefix}.bam\"\n    \"\"\"\n    bwa mem \\\n    -M -v 1 \\\n    -t \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -R '@RG\\\\tID:${sampleID}\\\\tSM:${sampleID}\\\\tLB:${sampleID}\\\\tPL:ILLUMINA' \\\n    \"${ref_fa_bwa_dir}/genome.fa\" \\\n    \"${fastq_R1_trim}\" \"${fastq_R2_trim}\" | \\\n    sambamba view \\\n    --sam-input \\\n    --nthreads=\\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --filter='mapping_quality>=10' \\\n    --format=bam \\\n    --compression-level=0 \\\n    /dev/stdin | \\\n    sambamba sort \\\n    --nthreads=\\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --out=\"${bam_file}\" /dev/stdin\n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    prefix = \"${sampleID}\"\n    bam_file = \"${prefix}.bam\"\n    \"\"\"\n    bwa mem \\\n    -M -v 1 \\\n    -t \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -R '@RG\\\\tID:${sampleID}\\\\tSM:${sampleID}\\\\tLB:${sampleID}\\\\tPL:ILLUMINA' \\\n    \"${ref_fa_bwa_dir}/genome.fa\" \\\n    \"${fastq_R1_trim}\" \"${fastq_R2_trim}\" | \\\n    sambamba view \\\n    --sam-input \\\n    --nthreads=\\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --filter='mapping_quality>=10' \\\n    --format=bam \\\n    --compression-level=0 \\\n    /dev/stdin | \\\n    sambamba sort \\\n    --nthreads=\\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --out=\"${bam_file}\" /dev/stdin\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "BWA",
            "Sambamba"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/sambamba"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "Sambamba",
                "uri": "https://bio.tools/sambamba",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This tool is a high performance modern robust and fast tool (and library), written in the D programming language, for working with SAM, BAM and CRAM formats.",
                "homepage": "http://www.open-bio.org/wiki/Sambamba"
            }
        ],
        "inputs": [
            "samples_fastq_trimmed",
            "ref_fa_bwa_dir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "samples_bam",
            "samples_bam2",
            "samples_bam3",
            "samples_bam4",
            "done_alignment"
        ],
        "nb_outputs": 5,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/raw\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "samtools_flagstat": {
        "name_process": "samtools_flagstat",
        "string_process": "\nprocess samtools_flagstat {\n                      \n    publishDir \"${params.outputDir}/alignments/stats\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam) from samples_bam\n\n    output:\n    set val(sampleID), file(\"${flagstat}\") into flagstats\n    val(sampleID) into done_sambamba_flagstat\n\n    script:\n    prefix = \"${sampleID}\"\n    flagstat = \"${prefix}.flagstat.txt\"\n    \"\"\"\n    samtools flagstat \"${sample_bam}\" > \"${flagstat}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    prefix = \"${sampleID}\"\n    flagstat = \"${prefix}.flagstat.txt\"\n    \"\"\"\n    samtools flagstat \"${sample_bam}\" > \"${flagstat}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_bam"
        ],
        "nb_inputs": 1,
        "outputs": [
            "flagstats",
            "done_sambamba_flagstat"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "samtools_flagstat_table": {
        "name_process": "samtools_flagstat_table",
        "string_process": "\nprocess samtools_flagstat_table {\n                                              \n    publishDir \"${params.outputDir}/alignments/stats\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(flagstat) from flagstats\n\n    output:\n    file(\"${output_file}\") into sambamba_flagstat_tables\n    val(sampleID) into done_sambamba_flagstat_table\n\n    script:\n    prefix = \"${sampleID}\"\n    output_file = \"${prefix}.flagstat.tsv\"\n    \"\"\"\n    flagstat2table.R \"${flagstat}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}\"\n    output_file = \"${prefix}.flagstat.tsv\"\n    \"\"\"\n    flagstat2table.R \"${flagstat}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "flagstats"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sambamba_flagstat_tables",
            "done_sambamba_flagstat_table"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_samtools_flagstat_table": {
        "name_process": "update_samtools_flagstat_table",
        "string_process": "\nprocess update_samtools_flagstat_table {\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from sambamba_flagstat_table_collected\n\n    output:\n    file(\"${output_file}\") into samtools_flagstat_table_ch\n    val('') into done_samtools_flagstat_table_update\n\n    script:\n    output_file = \"flagstat.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    output_file = \"flagstat.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sambamba_flagstat_table_collected"
        ],
        "nb_inputs": 1,
        "outputs": [
            "samtools_flagstat_table_ch",
            "done_samtools_flagstat_table_update"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "sambamba_dedup": {
        "name_process": "sambamba_dedup",
        "string_process": "\nprocess sambamba_dedup {\n                             \n    publishDir \"${params.outputDir}/alignments/deduplicated\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam) from samples_bam2\n\n    output:\n    set val(sampleID), file(\"${bam_file}\") into samples_dd_bam, samples_dd_bam2\n    set val(sampleID), file(\"${bam_file}\"), file(\"${bai_file}\") into samples_dd_bam3, samples_dd_bam4, samples_dd_bam5\n    set val(sampleID), file(\"${log_file}\") into sambamba_dedup_logs\n    val(sampleID) into done_sambamba_dedup\n\n    script:\n    prefix = \"${sampleID}\"\n    bam_file = \"${prefix}.dd.bam\"\n    bai_file = \"${prefix}.dd.bam.bai\"\n    log_file = \"${prefix}.dd.log\"\n    \"\"\"\n    sambamba markdup \\\n    --remove-duplicates \\\n    --nthreads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --hash-table-size 525000 \\\n    --overflow-list-size 525000 \\\n    \"${sample_bam}\" \"${bam_file}\"\n\n    # make a copy of the .command.err Nextflow log file for parsing\n    cat .command.err > \"${log_file}\"\n\n    samtools index \"${bam_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    prefix = \"${sampleID}\"\n    bam_file = \"${prefix}.dd.bam\"\n    bai_file = \"${prefix}.dd.bam.bai\"\n    log_file = \"${prefix}.dd.log\"\n    \"\"\"\n    sambamba markdup \\\n    --remove-duplicates \\\n    --nthreads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --hash-table-size 525000 \\\n    --overflow-list-size 525000 \\\n    \"${sample_bam}\" \"${bam_file}\"\n\n    # make a copy of the .command.err Nextflow log file for parsing\n    cat .command.err > \"${log_file}\"\n\n    samtools index \"${bam_file}\"\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "Sambamba",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/sambamba",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Sambamba",
                "uri": "https://bio.tools/sambamba",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This tool is a high performance modern robust and fast tool (and library), written in the D programming language, for working with SAM, BAM and CRAM formats.",
                "homepage": "http://www.open-bio.org/wiki/Sambamba"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_bam2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "samples_dd_bam",
            "samples_dd_bam2",
            "samples_dd_bam3",
            "samples_dd_bam4",
            "samples_dd_bam5",
            "sambamba_dedup_logs",
            "done_sambamba_dedup"
        ],
        "nb_outputs": 7,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/deduplicated\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "sambamba_dedup_log_table": {
        "name_process": "sambamba_dedup_log_table",
        "string_process": "\nprocess sambamba_dedup_log_table {\n                                               \n    publishDir \"${params.outputDir}/alignment-stats\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(log_file) from sambamba_dedup_logs\n\n    output:\n    file(\"${output_file}\") into sambamba_dedup_log_tables\n    val(sampleID) into done_sambamba_dedup_log_table\n\n    script:\n    prefix = \"${sampleID}\"\n    output_file = \"${prefix}.dd.tsv\"\n    \"\"\"\n    dedup-log2table.R \"${log_file}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}\"\n    output_file = \"${prefix}.dd.tsv\"\n    \"\"\"\n    dedup-log2table.R \"${log_file}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sambamba_dedup_logs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sambamba_dedup_log_tables",
            "done_sambamba_dedup_log_table"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignment-stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_sambamba_dedup_log_table": {
        "name_process": "update_sambamba_dedup_log_table",
        "string_process": "\nprocess update_sambamba_dedup_log_table{\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from sambamba_dedup_log_tables_collected\n\n    output:\n    file(\"${output_file}\") into sambamba_dedup_log_table_ch\n    val('') into done_update_sambamba_dedup_log_table\n\n    script:\n    output_file = \"reads.dedup.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    output_file = \"reads.dedup.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sambamba_dedup_log_tables_collected"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sambamba_dedup_log_table_ch",
            "done_update_sambamba_dedup_log_table"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "samtools_dedup_flagstat": {
        "name_process": "samtools_dedup_flagstat",
        "string_process": "\nprocess samtools_dedup_flagstat {\n                            \n    publishDir \"${params.outputDir}/alignment-stats\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam) from samples_dd_bam2\n\n    output:\n    set val(sampleID), file(\"${flagstat}\") into dedup_flagstats\n    val(sampleID) into done_sambamba_dedup_flagstat\n\n    script:\n    prefix = \"${sampleID}\"\n    flagstat = \"${prefix}.dd.flagstat.txt\"\n    \"\"\"\n    samtools flagstat \"${sample_bam}\" > \"${flagstat}\"\n    \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}\"\n    flagstat = \"${prefix}.dd.flagstat.txt\"\n    \"\"\"\n    samtools flagstat \"${sample_bam}\" > \"${flagstat}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_dd_bam2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "dedup_flagstats",
            "done_sambamba_dedup_flagstat"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignment-stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "samtools_dedup_flagstat_table": {
        "name_process": "samtools_dedup_flagstat_table",
        "string_process": "\nprocess samtools_dedup_flagstat_table {\n                                          \n    publishDir \"${params.outputDir}/alignment-stats\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(flagstat) from dedup_flagstats\n\n    output:\n    file(\"${output_file}\") into sambamba_dedup_flagstat_tables\n    val(sampleID) into done_sambamba_dedup_flagstat_table\n\n    script:\n    prefix = \"${sampleID}\"\n    output_file = \"${prefix}.dd.flagstat.tsv\"\n    \"\"\"\n    flagstat2table.R \"${flagstat}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}\"\n    output_file = \"${prefix}.dd.flagstat.tsv\"\n    \"\"\"\n    flagstat2table.R \"${flagstat}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dedup_flagstats"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sambamba_dedup_flagstat_tables",
            "done_sambamba_dedup_flagstat_table"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignment-stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_samtools_dedup_flagstat_table": {
        "name_process": "update_samtools_dedup_flagstat_table",
        "string_process": "\nprocess update_samtools_dedup_flagstat_table {\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from sambamba_dedup_flagstat_tables_collected\n\n    output:\n    file(\"${output_file}\") into samtools_dedup_flagstat_table_ch\n    val('') into done_update_samtools_dedup_flagstat_table\n\n    script:\n    output_file = \"flagstat.dedup.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    output_file = \"flagstat.dedup.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sambamba_dedup_flagstat_tables_collected"
        ],
        "nb_inputs": 1,
        "outputs": [
            "samtools_dedup_flagstat_table_ch",
            "done_update_samtools_dedup_flagstat_table"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gatk_RealignerTargetCreator": {
        "name_process": "gatk_RealignerTargetCreator",
        "string_process": "\nprocess gatk_RealignerTargetCreator {\n                                                                    \n    publishDir \"${params.outputDir}/alignment-stats\", pattern: \"${intervals_file}\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file), file(gatk_1000G_phase1_indels_vcf), file(gatk_1000G_phase1_indels_vcf_idx), file(mills_and_1000G_gold_standard_indels_vcf), file(mills_and_1000G_gold_standard_indels_vcf_idx), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx) from samples_dd_bam_ref_gatk\n\n    output:\n    set val(sampleID), file(\"${intervals_file}\"), file(sample_bam) into realigned_intervals_tables\n    val(sampleID) into done_gatk_RealignerTargetCreator\n\n    script:\n    prefix = \"${sampleID}\"\n    intervals_file = \"${prefix}.RealignerTargetCreator.intervals\"\n    \"\"\"\n    gatk.sh -T RealignerTargetCreator \\\n    -dt NONE \\\n    --logging_level ERROR \\\n    -nt \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -known \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -known \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${sample_bam}\" \\\n    --out \"${intervals_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    prefix = \"${sampleID}\"\n    intervals_file = \"${prefix}.RealignerTargetCreator.intervals\"\n    \"\"\"\n    gatk.sh -T RealignerTargetCreator \\\n    -dt NONE \\\n    --logging_level ERROR \\\n    -nt \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -known \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -known \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${sample_bam}\" \\\n    --out \"${intervals_file}\"\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_dd_bam_ref_gatk"
        ],
        "nb_inputs": 1,
        "outputs": [
            "realigned_intervals_tables",
            "done_gatk_RealignerTargetCreator"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignment-stats\", pattern: \"${intervals_file}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gatk_IndelRealigner": {
        "name_process": "gatk_IndelRealigner",
        "string_process": "\nprocess gatk_IndelRealigner {\n                                                                    \n    publishDir \"${params.outputDir}/alignments/realigned\", pattern: \"*.dd.ra.bam*\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(intervals_file), file(sample_bam), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file), file(gatk_1000G_phase1_indels_vcf), file(gatk_1000G_phase1_indels_vcf_idx), file(mills_and_1000G_gold_standard_indels_vcf), file(mills_and_1000G_gold_standard_indels_vcf_idx), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx) from realigned_intervals_tables_comb\n\n    output:\n    set val(sampleID), file(\"${ra_bam_file}\"), file(\"${ra_bai_file}\") into realigned_intervals_bams\n    val(sampleID) into done_gatk_IndelRealigner\n\n    script:\n    prefix = \"${sampleID}\"\n    ra_bam_file = \"${prefix}.dd.ra.bam\"\n    ra_bai_file = \"${prefix}.dd.ra.bam.bai\"\n    \"\"\"\n    samtools index \"${sample_bam}\"\n\n    gatk.sh -T IndelRealigner \\\n    -dt NONE \\\n    --logging_level ERROR \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --maxReadsForRealignment 50000 \\\n    -known \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -known \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    -targetIntervals \"${intervals_file}\" \\\n    --input_file \"${sample_bam}\" \\\n    --out \"${ra_bam_file}\"\n\n    samtools index \"${ra_bam_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    prefix = \"${sampleID}\"\n    ra_bam_file = \"${prefix}.dd.ra.bam\"\n    ra_bai_file = \"${prefix}.dd.ra.bam.bai\"\n    \"\"\"\n    samtools index \"${sample_bam}\"\n\n    gatk.sh -T IndelRealigner \\\n    -dt NONE \\\n    --logging_level ERROR \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --maxReadsForRealignment 50000 \\\n    -known \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -known \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    -targetIntervals \"${intervals_file}\" \\\n    --input_file \"${sample_bam}\" \\\n    --out \"${ra_bam_file}\"\n\n    samtools index \"${ra_bam_file}\"\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "realigned_intervals_tables_comb"
        ],
        "nb_inputs": 1,
        "outputs": [
            "realigned_intervals_bams",
            "done_gatk_IndelRealigner"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/realigned\", pattern: \"*.dd.ra.bam*\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gatk_BaseRecalibrator": {
        "name_process": "gatk_BaseRecalibrator",
        "string_process": "\nprocess gatk_BaseRecalibrator {\n                                                                    \n    publishDir \"${params.outputDir}/alignments/stats\", pattern: \"*.table1.txt\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(ra_bam_file), file(ra_bai_file), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file), file(gatk_1000G_phase1_indels_vcf), file(gatk_1000G_phase1_indels_vcf_idx), file(mills_and_1000G_gold_standard_indels_vcf), file(mills_and_1000G_gold_standard_indels_vcf_idx), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx) from realigned_intervals_bams_comb\n\n    output:\n    set val(sampleID), file(\"${table1}\"), file(ra_bam_file), file(ra_bai_file) into recalibrated_bases_table1\n    val(sampleID) into done_gatk_BaseRecalibrator\n\n    script:\n    prefix = \"${sampleID}\"\n    table1 = \"${prefix}.BaseRecalibrator.table1.txt\"\n    \"\"\"\n    gatk.sh -T BaseRecalibrator \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -rf BadCigar \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -knownSites \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -knownSites \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    -knownSites \"${dbsnp_ref_vcf}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${ra_bam_file}\" \\\n    --out \"${table1}\"\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    prefix = \"${sampleID}\"\n    table1 = \"${prefix}.BaseRecalibrator.table1.txt\"\n    \"\"\"\n    gatk.sh -T BaseRecalibrator \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -rf BadCigar \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -knownSites \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -knownSites \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    -knownSites \"${dbsnp_ref_vcf}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${ra_bam_file}\" \\\n    --out \"${table1}\"\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "realigned_intervals_bams_comb"
        ],
        "nb_inputs": 1,
        "outputs": [
            "recalibrated_bases_table1",
            "done_gatk_BaseRecalibrator"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/stats\", pattern: \"*.table1.txt\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gatk_BaseRecalibratorBQSR": {
        "name_process": "gatk_BaseRecalibratorBQSR",
        "string_process": "\nprocess gatk_BaseRecalibratorBQSR {\n                                                                    \n    publishDir \"${params.outputDir}/alignments/stats\", pattern: \"${table2}\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(table1), file(ra_bam_file), file(ra_bai_file), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file), file(gatk_1000G_phase1_indels_vcf), file(gatk_1000G_phase1_indels_vcf_idx), file(mills_and_1000G_gold_standard_indels_vcf), file(mills_and_1000G_gold_standard_indels_vcf_idx), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx) from recalibrated_bases_table1_comb\n\n    output:\n    set val(sampleID), file(table1), file(\"${table2}\"), file(ra_bam_file), file(ra_bai_file) into recalibrated_bases_table2\n    val(sampleID) into done_gatk_BaseRecalibratorBQSR\n\n    script:\n    prefix = \"${sampleID}\"\n    table2 = \"${prefix}.BaseRecalibrator.table2.txt\"\n    \"\"\"\n    gatk.sh -T BaseRecalibrator \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -rf BadCigar \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -knownSites \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -knownSites \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    -knownSites \"${dbsnp_ref_vcf}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${ra_bam_file}\" \\\n    -BQSR \"${table1}\" \\\n    --out \"${table2}\"\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    prefix = \"${sampleID}\"\n    table2 = \"${prefix}.BaseRecalibrator.table2.txt\"\n    \"\"\"\n    gatk.sh -T BaseRecalibrator \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -rf BadCigar \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -knownSites \"${gatk_1000G_phase1_indels_vcf}\" \\\n    -knownSites \"${mills_and_1000G_gold_standard_indels_vcf}\" \\\n    -knownSites \"${dbsnp_ref_vcf}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${ra_bam_file}\" \\\n    -BQSR \"${table1}\" \\\n    --out \"${table2}\"\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "recalibrated_bases_table1_comb"
        ],
        "nb_inputs": 1,
        "outputs": [
            "recalibrated_bases_table2",
            "done_gatk_BaseRecalibratorBQSR"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/stats\", pattern: \"${table2}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gatk_AnalyzeCovariates": {
        "name_process": "gatk_AnalyzeCovariates",
        "string_process": "\nprocess gatk_AnalyzeCovariates {\n                                                                    \n    publishDir \"${params.outputDir}/alignments/stats\", mode: 'copy'\n                                              \n                                                                                         \n                                                                                \n    errorStrategy = \"ignore\"\n\n    input:\n    set val(sampleID), file(table1), file(table2), file(ra_bam_file), file(ra_bai_file), file(ref_fasta), file(ref_fai), file(ref_dict) from recalibrated_bases_table2_comb\n\n    output:\n    file(\"${csv_file}\")\n    file(\"${pdf_file}\")\n\n    script:\n    prefix = \"${sampleID}\"\n    csv_file = \"${prefix}.AnalyzeCovariates.csv\"\n    pdf_file = \"${prefix}.AnalyzeCovariates.pdf\"\n    \"\"\"\n    gatk.sh -T AnalyzeCovariates \\\n    --logging_level ERROR \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -before \"${table1}\" \\\n    -after \"${table2}\" \\\n    -csv \"${csv_file}\" \\\n    -plots \"${pdf_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    prefix = \"${sampleID}\"\n    csv_file = \"${prefix}.AnalyzeCovariates.csv\"\n    pdf_file = \"${prefix}.AnalyzeCovariates.pdf\"\n    \"\"\"\n    gatk.sh -T AnalyzeCovariates \\\n    --logging_level ERROR \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -before \"${table1}\" \\\n    -after \"${table2}\" \\\n    -csv \"${csv_file}\" \\\n    -plots \"${pdf_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "recalibrated_bases_table2_comb"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/stats\", mode: 'copy'",
            "errorStrategy = \"ignore\""
        ],
        "when": "",
        "stub": ""
    },
    "gatk_PrintReads": {
        "name_process": "gatk_PrintReads",
        "string_process": "\nprocess gatk_PrintReads {\n                                                                    \n    publishDir \"${params.outputDir}/alignments/recalibrated\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(table1), file(ra_bam_file), file(ra_bai_file), file(ref_fasta), file(ref_fai), file(ref_dict) from recalibrated_bases_table1_ref\n\n    output:\n    set val(sampleID), file(\"${ra_rc_bam_file}\"), file(\"${ra_rc_bai_file}\") into samples_dd_ra_rc_bam, samples_dd_ra_rc_bam2, samples_dd_ra_rc_bam3, samples_dd_ra_rc_bam4, samples_dd_ra_rc_bam5\n    val(sampleID) into done_gatk_PrintReads\n\n    script:\n    prefix = \"${sampleID}\"\n    ra_rc_bam_file = \"${prefix}.dd.ra.rc.bam\"\n    ra_rc_bai_file = \"${prefix}.dd.ra.rc.bam.bai\"\n    \"\"\"\n    gatk.sh -T PrintReads \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -rf BadCigar \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -BQSR \"${table1}\" \\\n    --input_file \"${ra_bam_file}\" \\\n    --out \"${ra_rc_bam_file}\"\n\n    samtools index \"${ra_rc_bam_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    prefix = \"${sampleID}\"\n    ra_rc_bam_file = \"${prefix}.dd.ra.rc.bam\"\n    ra_rc_bai_file = \"${prefix}.dd.ra.rc.bam.bai\"\n    \"\"\"\n    gatk.sh -T PrintReads \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -rf BadCigar \\\n    --reference_sequence \"${ref_fasta}\" \\\n    -BQSR \"${table1}\" \\\n    --input_file \"${ra_bam_file}\" \\\n    --out \"${ra_rc_bam_file}\"\n\n    samtools index \"${ra_rc_bam_file}\"\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "recalibrated_bases_table1_ref"
        ],
        "nb_inputs": 1,
        "outputs": [
            "samples_dd_ra_rc_bam",
            "samples_dd_ra_rc_bam2",
            "samples_dd_ra_rc_bam3",
            "samples_dd_ra_rc_bam4",
            "samples_dd_ra_rc_bam5",
            "done_gatk_PrintReads"
        ],
        "nb_outputs": 6,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/alignments/recalibrated\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "qc_target_reads_gatk_genome": {
        "name_process": "qc_target_reads_gatk_genome",
        "string_process": "\nprocess qc_target_reads_gatk_genome {\n                                                        \n    publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict) from samples_dd_ra_rc_bam_ref_nointervals\n\n    output:\n    set val(sampleID), val(mode), file(\"${sample_summary}\") into qc_target_reads_gatk_genomes\n    file(\"${sample_statistics}\")\n    val(sampleID) into done_qc_target_reads_gatk_genome\n\n    script:\n    mode = \"genome\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_summary = \"${prefix}.sample_summary\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    -nt \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --logging_level ERROR \\\n    --omitIntervalStatistics \\\n    --omitLocusTable \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "    mode = \"genome\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_summary = \"${prefix}.sample_summary\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    -nt \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --logging_level ERROR \\\n    --omitIntervalStatistics \\\n    --omitLocusTable \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [
            "MoDEL"
        ],
        "tools_url": [
            "https://bio.tools/model"
        ],
        "tools_dico": [
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref_nointervals"
        ],
        "nb_inputs": 1,
        "outputs": [
            "qc_target_reads_gatk_genomes",
            "done_qc_target_reads_gatk_genome"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "qc_target_reads_gatk_pad500": {
        "name_process": "qc_target_reads_gatk_pad500",
        "string_process": "\nprocess qc_target_reads_gatk_pad500 {\n                                                                \n    publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file) from samples_dd_ra_rc_bam_ref2\n\n    output:\n    set val(sampleID), val(mode), file(\"${sample_summary}\") into qc_target_reads_gatk_pad500s\n    file(\"${sample_statistics}\")\n    val(sampleID) into done_qc_target_reads_gatk_pad500\n\n    script:\n    mode = \"pad500\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_summary = \"${prefix}.sample_summary\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    --logging_level ERROR \\\n    --omitIntervalStatistics \\\n    --omitLocusTable \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 500 \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "    mode = \"pad500\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_summary = \"${prefix}.sample_summary\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    --logging_level ERROR \\\n    --omitIntervalStatistics \\\n    --omitLocusTable \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 500 \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [
            "MoDEL"
        ],
        "tools_url": [
            "https://bio.tools/model"
        ],
        "tools_dico": [
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "qc_target_reads_gatk_pad500s",
            "done_qc_target_reads_gatk_pad500"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "qc_target_reads_gatk_pad100": {
        "name_process": "qc_target_reads_gatk_pad100",
        "string_process": "\nprocess qc_target_reads_gatk_pad100 {\n                                                                \n    publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file) from samples_dd_ra_rc_bam_ref3\n\n    output:\n    set val(sampleID), val(mode), file(\"${sample_summary}\") into qc_target_reads_gatk_pad100s\n    file(\"${sample_statistics}\")\n    val(sampleID) into done_qc_target_reads_gatk_pad100\n\n    script:\n    mode = \"pad100\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_summary = \"${prefix}.sample_summary\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    --logging_level ERROR \\\n    --omitIntervalStatistics \\\n    --omitLocusTable \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 100 \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "    mode = \"pad100\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_summary = \"${prefix}.sample_summary\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    --logging_level ERROR \\\n    --omitIntervalStatistics \\\n    --omitLocusTable \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 100 \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [
            "MoDEL"
        ],
        "tools_url": [
            "https://bio.tools/model"
        ],
        "tools_dico": [
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref3"
        ],
        "nb_inputs": 1,
        "outputs": [
            "qc_target_reads_gatk_pad100s",
            "done_qc_target_reads_gatk_pad100"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "qc_target_reads_gatk_bed": {
        "name_process": "qc_target_reads_gatk_bed",
        "string_process": "\nprocess qc_target_reads_gatk_bed {\n                                                                         \n    publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file) from samples_dd_ra_rc_bam_ref5\n\n    output:\n    set val(sampleID), val(mode), file(\"${sample_summary}\") into qc_target_reads_gatk_beds\n    set val(sampleID), val(mode), file(\"${sample_interval_summary}\") into qc_target_reads_gatk_beds_intervals\n    val(sampleID) into done_qc_target_reads_gatk_bed\n\n    script:\n    mode = \"bed\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_summary = \"${prefix}.sample_summary\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_interval_summary = \"${prefix}.sample_interval_summary\"\n    sample_interval_statistics = \"${prefix}.sample_interval_statistics\"\n    sample_cumulative_coverage_proportions = \"${prefix}.sample_cumulative_coverage_proportions\"\n    sample_cumulative_coverage_counts = \"${prefix}.sample_cumulative_coverage_counts\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    --logging_level ERROR \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --nBins 999 \\\n    --start 1 \\\n    --stop 1000 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"\n                                                                   \n}",
        "nb_lignes_process": 46,
        "string_script": "    mode = \"bed\"\n    prefix = \"${sampleID}.${mode}\"\n    sample_summary = \"${prefix}.sample_summary\"\n    sample_statistics = \"${prefix}.sample_statistics\"\n    sample_interval_summary = \"${prefix}.sample_interval_summary\"\n    sample_interval_statistics = \"${prefix}.sample_interval_statistics\"\n    sample_cumulative_coverage_proportions = \"${prefix}.sample_cumulative_coverage_proportions\"\n    sample_cumulative_coverage_counts = \"${prefix}.sample_cumulative_coverage_counts\"\n    \"\"\"\n    gatk.sh -T DepthOfCoverage \\\n    -dt NONE \\\n    -rf BadCigar \\\n    --logging_level ERROR \\\n    --omitDepthOutputAtEachBase \\\n    -ct 10 \\\n    -ct 50 \\\n    -ct 100 \\\n    -ct 200 \\\n    -ct 300 \\\n    -ct 400 \\\n    -ct 500 \\\n    --minBaseQuality 20 \\\n    --minMappingQuality 20 \\\n    --nBins 999 \\\n    --start 1 \\\n    --stop 1000 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --input_file \"${sample_bam}\" \\\n    --outputFormat csv \\\n    --out \"${prefix}\"\n    \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "MoDEL"
        ],
        "tools_url": [
            "https://bio.tools/model"
        ],
        "tools_dico": [
            {
                "name": "MoDEL",
                "uri": "https://bio.tools/model",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2426",
                                    "term": "Modelling and simulation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0842",
                                "term": "Identifier"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2080",
                                "term": "Database search results"
                            }
                        ]
                    }
                ],
                "description": "Database of protein Molecular Dynamics simulations, with 1800 trajectories representing different structural clusters of the PDB.",
                "homepage": "http://mmb.irbbarcelona.org/MoDEL"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref5"
        ],
        "nb_inputs": 1,
        "outputs": [
            "qc_target_reads_gatk_beds",
            "qc_target_reads_gatk_beds_intervals",
            "done_qc_target_reads_gatk_bed"
        ],
        "nb_outputs": 3,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_coverage_tables": {
        "name_process": "update_coverage_tables",
        "string_process": "\nprocess update_coverage_tables {\n                                                         \n    publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'\n\n    input:\n    set val(sampleID), val(mode), file(sample_summary) from qc_target_reads_gatk_beds.concat(qc_target_reads_gatk_pad100s, qc_target_reads_gatk_pad500s, qc_target_reads_gatk_genomes)\n\n    output:\n    file(\"${output_file}\") into updated_coverage_tables\n    val(sampleID) into done_update_coverage_tables\n\n    script:\n    prefix = \"${sampleID}.${mode}\"\n    output_file = \"${prefix}.sample_summary.tsv\"\n    \"\"\"\n    sample-summary2table.R \"${sample_summary}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Mode\" -v \"${mode}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}.${mode}\"\n    output_file = \"${prefix}.sample_summary.tsv\"\n    \"\"\"\n    sample-summary2table.R \"${sample_summary}\" tmp.tsv\n    paste-col.py -i tmp.tsv --header \"Mode\" -v \"${mode}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qc_target_reads_gatk_beds",
            "qc_target_reads_gatk_pad100s",
            "qc_target_reads_gatk_pad500s",
            "qc_target_reads_gatk_genomes"
        ],
        "nb_inputs": 4,
        "outputs": [
            "updated_coverage_tables",
            "done_update_coverage_tables"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_updated_coverage_tables_collected": {
        "name_process": "update_updated_coverage_tables_collected",
        "string_process": "\nprocess update_updated_coverage_tables_collected {\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from updated_coverage_tables_collected\n\n    output:\n    file(\"${output_file}\") into sample_coverage_file_ch\n    val('') into done_update_updated_coverage_tables_collected\n\n    script:\n    output_file = \"${sample_coverage_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    output_file = \"${sample_coverage_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "updated_coverage_tables_collected"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_coverage_file_ch",
            "done_update_updated_coverage_tables_collected"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "coverage_intervals_to_table": {
        "name_process": "coverage_intervals_to_table",
        "string_process": "\nprocess coverage_intervals_to_table {\n                                                                                      \n    input:\n    set val(sampleID), val(mode), file(sample_interval_summary) from qc_target_reads_gatk_beds_intervals\n\n    output:\n    set val(sampleID), val(mode), file(\"${output_file}\") into updated_coverage_interval_tables\n\n    script:\n    prefix = \"${sampleID}.${mode}\"\n    output_file = \"${prefix}.sample_interval_summary.table.tsv\"\n    \"\"\"\n    sample-interval-summary2table.R \"${sample_interval_summary}\" \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    prefix = \"${sampleID}.${mode}\"\n    output_file = \"${prefix}.sample_interval_summary.table.tsv\"\n    \"\"\"\n    sample-interval-summary2table.R \"${sample_interval_summary}\" \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qc_target_reads_gatk_beds_intervals"
        ],
        "nb_inputs": 1,
        "outputs": [
            "updated_coverage_interval_tables"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "annotate_coverage_intervals": {
        "name_process": "annotate_coverage_intervals",
        "string_process": "\nprocess annotate_coverage_intervals {\n                                          \n    input:\n    set val(sampleID), val(mode), file(interval_table), file(annovar_db_dir) from updated_coverage_interval_tables.combine(annovar_db_dir3)\n\n    output:\n    set val(sampleID), val(mode), file(\"${annotations_tsv}\") into annotated_interval_tables\n\n    script:\n    prefix = \"${sampleID}.${mode}.sample_interval_summary\"\n    noHeader_tsv = \"${prefix}.noHeader.tsv\"\n    interval_tmp = \"${prefix}.intervals.tmp\"\n    remainder_tsv = \"${prefix}.remainder.tsv\"\n    avinput_file = \"${prefix}.avinput\"\n                                            \n    annovar_output_txt = \"${prefix}.${cov_ANNOVAR_BUILD_VERSION}_multianno.txt\"\n                                                                             \n    annotations_tsv = \"${prefix}.annotations.tsv\"\n    \"\"\"\n    # convert table to ANNOVAR format for annotation; http://annovar.openbioinformatics.org/en/latest/user-guide/input/\n    # strip headers and add '0' cols for ref and alt\n    tail -n +2 \"${interval_table}\" > \"${noHeader_tsv}\"\n    cut -f1-3 \"${noHeader_tsv}\" > \"${interval_tmp}\"\n    cut -f4- \"${noHeader_tsv}\" > \"${remainder_tsv}\"\n    sed -e 's|\\$|\\t0|' -i \"${interval_tmp}\"\n    sed -e 's|\\$|\\t0|' -i \"${interval_tmp}\"\n    paste \"${interval_tmp}\" \"${remainder_tsv}\" > \"${avinput_file}\"\n\n    # annotate\n    table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n    --buildver \"${cov_ANNOVAR_BUILD_VERSION}\" \\\n    --remove \\\n    --protocol \"${cov_ANNOVAR_PROTOCOL}\" \\\n    --operation \"${cov_ANNOVAR_OPERATION}\" \\\n    --nastring . \\\n    --outfile \"${prefix}\"\n\n    merge-interval-tables.R \"${interval_table}\" \"${annovar_output_txt}\" \"${avinput_file}\" \"${annotations_tsv}\"\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    prefix = \"${sampleID}.${mode}.sample_interval_summary\"\n    noHeader_tsv = \"${prefix}.noHeader.tsv\"\n    interval_tmp = \"${prefix}.intervals.tmp\"\n    remainder_tsv = \"${prefix}.remainder.tsv\"\n    avinput_file = \"${prefix}.avinput\"\n                                            \n    annovar_output_txt = \"${prefix}.${cov_ANNOVAR_BUILD_VERSION}_multianno.txt\"\n                                                                             \n    annotations_tsv = \"${prefix}.annotations.tsv\"\n    \"\"\"\n    # convert table to ANNOVAR format for annotation; http://annovar.openbioinformatics.org/en/latest/user-guide/input/\n    # strip headers and add '0' cols for ref and alt\n    tail -n +2 \"${interval_table}\" > \"${noHeader_tsv}\"\n    cut -f1-3 \"${noHeader_tsv}\" > \"${interval_tmp}\"\n    cut -f4- \"${noHeader_tsv}\" > \"${remainder_tsv}\"\n    sed -e 's|\\$|\\t0|' -i \"${interval_tmp}\"\n    sed -e 's|\\$|\\t0|' -i \"${interval_tmp}\"\n    paste \"${interval_tmp}\" \"${remainder_tsv}\" > \"${avinput_file}\"\n\n    # annotate\n    table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n    --buildver \"${cov_ANNOVAR_BUILD_VERSION}\" \\\n    --remove \\\n    --protocol \"${cov_ANNOVAR_PROTOCOL}\" \\\n    --operation \"${cov_ANNOVAR_OPERATION}\" \\\n    --nastring . \\\n    --outfile \"${prefix}\"\n\n    merge-interval-tables.R \"${interval_table}\" \"${annovar_output_txt}\" \"${avinput_file}\" \"${annotations_tsv}\"\n    \"\"\"",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [
            "wossinput"
        ],
        "tools_url": [
            "https://bio.tools/wossinput"
        ],
        "tools_dico": [
            {
                "name": "wossinput",
                "uri": "https://bio.tools/wossinput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM input data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossinput.html"
            }
        ],
        "inputs": [
            "updated_coverage_interval_tables",
            "annovar_db_dir3"
        ],
        "nb_inputs": 2,
        "outputs": [
            "annotated_interval_tables"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "update_interval_tables": {
        "name_process": "update_interval_tables",
        "string_process": "\nprocess update_interval_tables {\n                                                            \n    publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'\n\n    input:\n    set val(sampleID), val(mode), file(sample_interval_summary) from annotated_interval_tables\n\n    output:\n    file(\"${output_file}\") into updated_annotated_interval_tables\n    val(sampleID) into done_update_interval_tables\n\n    script:\n    prefix = \"${sampleID}.${mode}\"\n    output_file = \"${prefix}.sample_interval_summary.tsv\"\n    \"\"\"\n    paste-col.py -i \"${sample_interval_summary}\" --header \"Mode\" -v \"${mode}\" | \\\n    paste-col.py --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}.${mode}\"\n    output_file = \"${prefix}.sample_interval_summary.tsv\"\n    \"\"\"\n    paste-col.py -i \"${sample_interval_summary}\" --header \"Mode\" -v \"${mode}\" | \\\n    paste-col.py --header \"Sample\" -v \"${sampleID}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotated_interval_tables"
        ],
        "nb_inputs": 1,
        "outputs": [
            "updated_annotated_interval_tables",
            "done_update_interval_tables"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/metrics/coverage/${mode}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_updated_coverage_interval_tables_collected": {
        "name_process": "update_updated_coverage_interval_tables_collected",
        "string_process": "\nprocess update_updated_coverage_interval_tables_collected {\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from updated_coverage_interval_tables_collected\n\n    output:\n    file(\"${output_file}\") into interval_coverage_file_ch\n    val('') into done_update_updated_coverage_interval_tables_collected\n\n    script:\n    output_file = \"${interval_coverage_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    output_file = \"${interval_coverage_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "updated_coverage_interval_tables_collected"
        ],
        "nb_inputs": 1,
        "outputs": [
            "interval_coverage_file_ch",
            "done_update_updated_coverage_interval_tables_collected"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "lofreq": {
        "name_process": "lofreq",
        "string_process": "\nprocess lofreq {\n                                                                  \n                                                                                              \n    publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_file}\"\n    publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\"\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file) from samples_dd_ra_rc_bam_ref6\n\n    output:\n    set val(caller), val(type), val(sampleID), file(\"${norm_vcf}\") into lofreq_norm_vcfs\n    file(\"${vcf_file}\")\n    file(\"${norm_vcf}\")\n    file(\"${multiallelics_stats}\")\n    file(\"${realign_stats}\")\n    val(sampleID) into done_lofreq\n\n    script:\n    caller = \"LoFreq\"\n    type = \"NA\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    vcf_file = \"${prefix}.vcf\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    \"\"\"\n    lofreq call-parallel \\\n    --call-indels \\\n    --pp-threads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --ref \"${ref_fasta}\" \\\n    --bed \"${targets_bed_file}\" \\\n    --out \"${vcf_file}\" \\\n    \"${sample_bam}\"\n\n    cat ${vcf_file} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "    caller = \"LoFreq\"\n    type = \"NA\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    vcf_file = \"${prefix}.vcf\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    \"\"\"\n    lofreq call-parallel \\\n    --call-indels \\\n    --pp-threads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --ref \"${ref_fasta}\" \\\n    --bed \"${targets_bed_file}\" \\\n    --out \"${vcf_file}\" \\\n    \"${sample_bam}\"\n\n    cat ${vcf_file} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "ScType",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/ScType",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "ScType",
                "uri": "https://bio.tools/ScType",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "ScType is a tool for fully-automated cell type identification from single-cell RNA-seq data. ScType provides a complete pipeline for single-cell RNA-seq data analysis (including data processing, normalization and clustering) and cell-type annotation.",
                "homepage": "http://session.asuscomm.com:8080/"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref6"
        ],
        "nb_inputs": 1,
        "outputs": [
            "lofreq_norm_vcfs",
            "done_lofreq"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_file}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\""
        ],
        "when": "",
        "stub": ""
    },
    "gatk_hc": {
        "name_process": "gatk_hc",
        "string_process": "\nprocess gatk_hc {\n                      \n    publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_file}\"\n    publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\"\n                                                                                                     \n                                                                                                         \n                                                                                                              \n\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx) from samples_dd_ra_rc_bam_ref_dbsnp2\n\n    output:\n    set val(caller), val(type), val(sampleID), file(\"${norm_vcf}\") into sample_vcf_hc\n    file(\"${vcf_file}\")\n    file(\"${multiallelics_stats}\")\n    file(\"${realign_stats}\")\n    file(\"${norm_vcf}\")\n    val(sampleID) into done_gatk_hc\n\n    script:\n    caller = \"HaplotypeCaller\"\n    type = \"NA\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    vcf_file = \"${prefix}.vcf\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    \"\"\"\n    gatk.sh -T HaplotypeCaller \\\n    -dt NONE \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --max_alternate_alleles 3 \\\n    --standard_min_confidence_threshold_for_calling 50 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${sample_bam}\" \\\n    --out \"${vcf_file}\"\n\n    cat ${vcf_file} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"\n}",
        "nb_lignes_process": 48,
        "string_script": "    caller = \"HaplotypeCaller\"\n    type = \"NA\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    vcf_file = \"${prefix}.vcf\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    \"\"\"\n    gatk.sh -T HaplotypeCaller \\\n    -dt NONE \\\n    --logging_level ERROR \\\n    -nct \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    --max_alternate_alleles 3 \\\n    --standard_min_confidence_threshold_for_calling 50 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --intervals \"${targets_bed_file}\" \\\n    --interval_padding 10 \\\n    --input_file \"${sample_bam}\" \\\n    --out \"${vcf_file}\"\n\n    cat ${vcf_file} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "ScType",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/ScType",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "ScType",
                "uri": "https://bio.tools/ScType",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "ScType is a tool for fully-automated cell type identification from single-cell RNA-seq data. ScType provides a complete pipeline for single-cell RNA-seq data analysis (including data processing, normalization and clustering) and cell-type annotation.",
                "homepage": "http://session.asuscomm.com:8080/"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref_dbsnp2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_vcf_hc",
            "done_gatk_hc"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_file}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\""
        ],
        "when": "",
        "stub": ""
    },
    "varscan_snp": {
        "name_process": "varscan_snp",
        "string_process": "\nprocess varscan_snp {\n                                                                                                  \n                                        \n    publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_snp_output}\"\n    publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\"\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file) from samples_dd_ra_rc_bam_ref9\n\n    output:\n    file(\"${vcf_snp_output}\")\n    file(\"${multiallelics_stats}\")\n    file(\"${realign_stats}\")\n    set val(caller), val(type), val(sampleID), file(\"${norm_vcf}\") into varscan_snp_vcfs\n\n    when:\n    disable_varscan2 != true\n\n    script:\n    caller = \"VarScan2\"\n    type = \"snp\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    vcf_snp_output = \"${prefix}.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    vcf_sample_list = \"vcf-sample-list.txt\"\n    \"\"\"\n    # make vcf-sample-list\n    echo \"${sampleID}\" > \"${vcf_sample_list}\"\n\n    # VarScan2 with default settings\n    samtools mpileup \\\n    --no-BAQ \\\n    --positions \"${targets_bed_file}\" \\\n    --fasta-ref \"${ref_fasta}\" \\\n    \"${sample_bam}\" | \\\n    varscan.sh mpileup2snp \\\n    --min-coverage 8 \\\n    --min-reads2 2 \\\n    --min-avg-qual 15 \\\n    --min-var-freq 0.01 \\\n    --min-freq-for-hom 0.75 \\\n    --p-value 0.99 \\\n    --strand-filter 1 \\\n    --vcf-sample-list \"${vcf_sample_list}\" \\\n    --output-vcf > \"${vcf_snp_output}\"\n\n    # normalize and split vcf entries\n    cat ${vcf_snp_output} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"\n\n}",
        "nb_lignes_process": 57,
        "string_script": "    caller = \"VarScan2\"\n    type = \"snp\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    vcf_snp_output = \"${prefix}.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    vcf_sample_list = \"vcf-sample-list.txt\"\n    \"\"\"\n    # make vcf-sample-list\n    echo \"${sampleID}\" > \"${vcf_sample_list}\"\n\n    # VarScan2 with default settings\n    samtools mpileup \\\n    --no-BAQ \\\n    --positions \"${targets_bed_file}\" \\\n    --fasta-ref \"${ref_fasta}\" \\\n    \"${sample_bam}\" | \\\n    varscan.sh mpileup2snp \\\n    --min-coverage 8 \\\n    --min-reads2 2 \\\n    --min-avg-qual 15 \\\n    --min-var-freq 0.01 \\\n    --min-freq-for-hom 0.75 \\\n    --p-value 0.99 \\\n    --strand-filter 1 \\\n    --vcf-sample-list \"${vcf_sample_list}\" \\\n    --output-vcf > \"${vcf_snp_output}\"\n\n    # normalize and split vcf entries\n    cat ${vcf_snp_output} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"",
        "nb_lignes_script": 34,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "ScType",
            "SAMtools",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/ScType",
            "https://bio.tools/samtools",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "ScType",
                "uri": "https://bio.tools/ScType",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "ScType is a tool for fully-automated cell type identification from single-cell RNA-seq data. ScType provides a complete pipeline for single-cell RNA-seq data analysis (including data processing, normalization and clustering) and cell-type annotation.",
                "homepage": "http://session.asuscomm.com:8080/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref9"
        ],
        "nb_inputs": 1,
        "outputs": [
            "varscan_snp_vcfs"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_snp_output}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\""
        ],
        "when": "disable_varscan2 != true",
        "stub": ""
    },
    "varscan_indel": {
        "name_process": "varscan_indel",
        "string_process": "\nprocess varscan_indel {\n    publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_indel_output}\"\n    publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\"\n\n    input:\n    set val(sampleID), file(sample_bam), file(sample_bai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed_file) from samples_dd_ra_rc_bam_ref10\n\n    output:\n    file(\"${vcf_indel_output}\")\n    file(\"${multiallelics_stats}\")\n    file(\"${realign_stats}\")\n    set val(caller), val(type), val(sampleID), file(\"${norm_vcf}\") into varscan_indel_vcfs\n\n    when:\n    disable_varscan2 != true\n\n    script:\n    caller = \"VarScan2\"\n    type = \"indel\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    samtools_mpileup_output = \"${prefix}.mpileup\"\n    vcf_indel_output = \"${prefix}.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    vcf_sample_list = \"vcf-sample-list.txt\"\n    \"\"\"\n    # make vcf-sample-list\n    echo \"${sampleID}\" > \"${vcf_sample_list}\"\n\n    # VarScan2 with default settings\n    samtools mpileup \\\n    --no-BAQ \\\n    --positions \"${targets_bed_file}\" \\\n    --fasta-ref \"${ref_fasta}\" \\\n    \"${sample_bam}\" | \\\n    varscan.sh mpileup2indel \\\n    --min-coverage 8 \\\n    --min-reads2 2 \\\n    --min-avg-qual 15 \\\n    --min-var-freq 0.01 \\\n    --min-freq-for-hom 0.75 \\\n    --p-value 0.99 \\\n    --strand-filter 1 \\\n    --vcf-sample-list \"${vcf_sample_list}\" \\\n    --output-vcf > \"${vcf_indel_output}\"\n\n    # normalize and split vcf entries\n    cat ${vcf_indel_output} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "    caller = \"VarScan2\"\n    type = \"indel\"\n    prefix = \"${sampleID}.${caller}.${type}\"\n    samtools_mpileup_output = \"${prefix}.mpileup\"\n    vcf_indel_output = \"${prefix}.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    vcf_sample_list = \"vcf-sample-list.txt\"\n    \"\"\"\n    # make vcf-sample-list\n    echo \"${sampleID}\" > \"${vcf_sample_list}\"\n\n    # VarScan2 with default settings\n    samtools mpileup \\\n    --no-BAQ \\\n    --positions \"${targets_bed_file}\" \\\n    --fasta-ref \"${ref_fasta}\" \\\n    \"${sample_bam}\" | \\\n    varscan.sh mpileup2indel \\\n    --min-coverage 8 \\\n    --min-reads2 2 \\\n    --min-avg-qual 15 \\\n    --min-var-freq 0.01 \\\n    --min-freq-for-hom 0.75 \\\n    --p-value 0.99 \\\n    --strand-filter 1 \\\n    --vcf-sample-list \"${vcf_sample_list}\" \\\n    --output-vcf > \"${vcf_indel_output}\"\n\n    # normalize and split vcf entries\n    cat ${vcf_indel_output} | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"",
        "nb_lignes_script": 35,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "ScType",
            "SAMtools",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/ScType",
            "https://bio.tools/samtools",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "ScType",
                "uri": "https://bio.tools/ScType",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3680",
                                    "term": "RNA-Seq analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "ScType is a tool for fully-automated cell type identification from single-cell RNA-seq data. ScType provides a complete pipeline for single-cell RNA-seq data analysis (including data processing, normalization and clustering) and cell-type annotation.",
                "homepage": "http://session.asuscomm.com:8080/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_ref10"
        ],
        "nb_inputs": 1,
        "outputs": [
            "varscan_indel_vcfs"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_indel_output}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\""
        ],
        "when": "disable_varscan2 != true",
        "stub": ""
    },
    "filter_vcf": {
        "name_process": "filter_vcf",
        "string_process": "\nprocess filter_vcf {\n                        \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/variants/${caller}/filtered\", mode: 'copy', pattern: \"*${filtered_vcf}\"\n\n    input:\n    set val(caller), val(type), val(sampleID), file(vcf), file(ref_fasta), file(ref_fai), file(ref_dict) from unpaired_vcfs_ref\n\n    output:\n    set val(caller), val(type), val(sampleID), file(\"${filtered_vcf}\") into (filtered_vcfs, filtered_vcfs2, filtered_vcfs3)          \n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    filtered_vcf = \"${prefix}.filtered.vcf\"\n    if ( caller == \"VarScan2\" )\n        \"\"\"\n        # do not report if frequency is less than 1%\n        # automatically filters only PASS variants\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"FREQ > 0.01\"  \\\n        # > \"${filtered_vcf}\"\n\n        # skip filtering of VarScan2 because it reports the 'FREQ' as a % in the .vcf; \"100%\", etc.\n        # TODO: come up with a filtering method for this\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if ( caller == \"LoFreq\" )\n        \"\"\"\n        # do not report if:\n        # - frequency is less than 1%, greater than 99%\n        # - depth less than 200\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"AF > 0.01\"  \\\n        # -select \"AF < 0.99\"  \\\n        # -select \"DP > 100\"  \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if ( caller == \"HaplotypeCaller\" )\n        \"\"\"\n        # report if\n        # alternate allele freq (allele depth / depth) greater than 0.05 ; 5%\n        # more than 5 variant call supporting reads\n        # quality reads present (reported depth >0)\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # --sample_name \"${sampleID}\" \\\n        # -select \"vc.getGenotype('${sampleID}').getAD().1 / vc.getGenotype('${sampleID}').getDP() > 0.05\" \\\n        # -select \"vc.getGenotype('${sampleID}').getAD().1 > 5\" \\\n        # -select \"vc.getGenotype('${sampleID}').getDP() > 100\" \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 72,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    filtered_vcf = \"${prefix}.filtered.vcf\"\n    if ( caller == \"VarScan2\" )\n        \"\"\"\n        # do not report if frequency is less than 1%\n        # automatically filters only PASS variants\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"FREQ > 0.01\"  \\\n        # > \"${filtered_vcf}\"\n\n        # skip filtering of VarScan2 because it reports the 'FREQ' as a % in the .vcf; \"100%\", etc.\n        # TODO: come up with a filtering method for this\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if ( caller == \"LoFreq\" )\n        \"\"\"\n        # do not report if:\n        # - frequency is less than 1%, greater than 99%\n        # - depth less than 200\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"AF > 0.01\"  \\\n        # -select \"AF < 0.99\"  \\\n        # -select \"DP > 100\"  \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if ( caller == \"HaplotypeCaller\" )\n        \"\"\"\n        # report if\n        # alternate allele freq (allele depth / depth) greater than 0.05 ; 5%\n        # more than 5 variant call supporting reads\n        # quality reads present (reported depth >0)\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # --sample_name \"${sampleID}\" \\\n        # -select \"vc.getGenotype('${sampleID}').getAD().1 / vc.getGenotype('${sampleID}').getDP() > 0.05\" \\\n        # -select \"vc.getGenotype('${sampleID}').getAD().1 > 5\" \\\n        # -select \"vc.getGenotype('${sampleID}').getDP() > 100\" \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 59,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "unpaired_vcfs_ref"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/filtered\", mode: 'copy', pattern: \"*${filtered_vcf}\""
        ],
        "when": "",
        "stub": ""
    },
    "vcf_to_tsv": {
        "name_process": "vcf_to_tsv",
        "string_process": "\nprocess vcf_to_tsv {\n                           \n                                            \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${tsv_file}\"\n    publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${reformat_tsv}\"\n\n    input:\n    set val(caller), val(type), val(sampleID), file(vcf), file(ref_fasta), file(ref_fai), file(ref_dict) from filtered_vcfs.combine(ref_fasta15).combine(ref_fai15).combine(ref_dict15)\n\n    output:\n    set val(caller), val(type), val(sampleID), file(vcf), file(\"${reformat_tsv}\") into (vcf_tsvs, vcf_tsvs2)                 \n    set val(caller), val(type), val(sampleID), file(\"${reformat_tsv}\") into vcf_tsvs3\n\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    tsv_file = \"${prefix}.tsv\"\n    reformat_tsv = \"${prefix}.reformat.tsv\"\n    if ( caller == \"VarScan2\" )\n        \"\"\"\n        # NOTE: The output columns here need to correspond to the columns used in 'reformat-vcf-table.py' !!\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F QUAL \\\n        -F FILTER \\\n        -GF DP \\\n        -GF AD \\\n        -GF RD \\\n        -GF FREQ \\\n        -GF RBQ \\\n        -GF ABQ \\\n        -o \"${tsv_file}\"\n\n        # reformat and adjust the TSV table for consistency downstream\n        reformat-vcf-table.py -c VarScan2 -s \"${sampleID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${sampleID}\"  | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n        \"\"\"\n                               \n                            \n                                                                                                                       \n                                                                                                            \n                                                                                                            \n                                                                                                          \n                                                                                          \n                                                                                                                     \n                                                                                                     \n                                                                       \n                                                                                \n                                                                                                       \n                                                                                                                  \n                                                                                                            \n                                                                                                          \n                                                                                         \n                                                                                                 \n                                                                                                                      \n                                                                                                                    \n                                                                                                                                   \n                                                                                                                                    \n                                                                                                                                 \n                                                                                                                                  \n                                                                                          \n                                                                                                                                                                                                           \n    else if ( caller == \"LoFreq\" )\n        \"\"\"\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F QUAL \\\n        -F FILTER \\\n        -F DP \\\n        -F AF \\\n        -F SB \\\n        -F INDEL \\\n        -F CONSVAR \\\n        -F HRUN \\\n        -o \"${tsv_file}\"\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c LoFreq -s \"${sampleID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${sampleID}\"  | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n        \"\"\"\n                                                              \n                                                                       \n                                                                            \n                                                                                                       \n                                                                                                                                           \n                                                                                                     \n                                                                                                                                                          \n                                                                                                                        \n                                                                                    \n                                                                                        \n                                                                    \n                                                                                                                  \n                                                                                    \n                                                                                        \n    else if ( caller == \"HaplotypeCaller\" )\n        \"\"\"\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F FILTER \\\n        -F QUAL \\\n        -F AC \\\n        -F AN \\\n        -GF AD \\\n        -GF DP \\\n        -o \"${tsv_file}\"\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c HaplotypeCaller -s \"${sampleID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${sampleID}\" | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 142,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    tsv_file = \"${prefix}.tsv\"\n    reformat_tsv = \"${prefix}.reformat.tsv\"\n    if ( caller == \"VarScan2\" )\n        \"\"\"\n        # NOTE: The output columns here need to correspond to the columns used in 'reformat-vcf-table.py' !!\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F QUAL \\\n        -F FILTER \\\n        -GF DP \\\n        -GF AD \\\n        -GF RD \\\n        -GF FREQ \\\n        -GF RBQ \\\n        -GF ABQ \\\n        -o \"${tsv_file}\"\n\n        # reformat and adjust the TSV table for consistency downstream\n        reformat-vcf-table.py -c VarScan2 -s \"${sampleID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${sampleID}\"  | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n        \"\"\"\n                               \n                            \n                                                                                                                       \n                                                                                                            \n                                                                                                            \n                                                                                                          \n                                                                                          \n                                                                                                                     \n                                                                                                     \n                                                                       \n                                                                                \n                                                                                                       \n                                                                                                                  \n                                                                                                            \n                                                                                                          \n                                                                                         \n                                                                                                 \n                                                                                                                      \n                                                                                                                    \n                                                                                                                                   \n                                                                                                                                    \n                                                                                                                                 \n                                                                                                                                  \n                                                                                          \n                                                                                                                                                                                                           \n    else if ( caller == \"LoFreq\" )\n        \"\"\"\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F QUAL \\\n        -F FILTER \\\n        -F DP \\\n        -F AF \\\n        -F SB \\\n        -F INDEL \\\n        -F CONSVAR \\\n        -F HRUN \\\n        -o \"${tsv_file}\"\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c LoFreq -s \"${sampleID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${sampleID}\"  | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n        \"\"\"\n                                                              \n                                                                       \n                                                                            \n                                                                                                       \n                                                                                                                                           \n                                                                                                     \n                                                                                                                                                          \n                                                                                                                        \n                                                                                    \n                                                                                        \n                                                                    \n                                                                                                                  \n                                                                                    \n                                                                                        \n    else if ( caller == \"HaplotypeCaller\" )\n        \"\"\"\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F FILTER \\\n        -F QUAL \\\n        -F AC \\\n        -F AN \\\n        -GF AD \\\n        -GF DP \\\n        -o \"${tsv_file}\"\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c HaplotypeCaller -s \"${sampleID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${sampleID}\" | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 125,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filtered_vcfs",
            "ref_fasta15",
            "ref_fai15",
            "ref_dict15"
        ],
        "nb_inputs": 4,
        "outputs": [
            "",
            "vcf_tsvs3"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${tsv_file}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${reformat_tsv}\""
        ],
        "when": "",
        "stub": ""
    },
    "eval_sample_vcf": {
        "name_process": "eval_sample_vcf",
        "string_process": "\nprocess eval_sample_vcf {\n                                \n                                                                                                                  \n                                                          \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${eval_file}\"\n\n    input:\n    set val(caller), val(type), val(sampleID), file(sample_vcf), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx), file(ref_fasta), file(ref_fai), file(ref_dict4) from samples_filtered_vcfs\n\n    output:\n    file(\"${eval_file}\")\n    val(\"${sampleID}\") into done_eval_sample_vcf\n\n    when:\n    disable_eval_sample_vcf != true\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    eval_file = \"${prefix}.eval.grp\"\n    \"\"\"\n    gatk.sh -T VariantEval \\\n    -R \"${ref_fasta}\" \\\n    -o \"${eval_file}\" \\\n    --dbsnp \"${dbsnp_ref_vcf}\" \\\n    --eval \"${sample_vcf}\"\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    eval_file = \"${prefix}.eval.grp\"\n    \"\"\"\n    gatk.sh -T VariantEval \\\n    -R \"${ref_fasta}\" \\\n    -o \"${eval_file}\" \\\n    --dbsnp \"${dbsnp_ref_vcf}\" \\\n    --eval \"${sample_vcf}\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_filtered_vcfs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "done_eval_sample_vcf"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${eval_file}\""
        ],
        "when": "disable_eval_sample_vcf != true",
        "stub": ""
    },
    "line_chunk": {
        "name_process": "line_chunk",
        "string_process": "\nprocess line_chunk {\n                                                                             \n    input:\n    file(bedFile) from targets_bed10\n\n    output:\n    file('*') into line_chunk_ch\n\n    script:\n    \"\"\"\n    split-bed-lines.py \"${bedFile}\" \"${numTargetSplitLines}\"\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n    split-bed-lines.py \"${bedFile}\" \"${numTargetSplitLines}\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "targets_bed10"
        ],
        "nb_inputs": 1,
        "outputs": [
            "line_chunk_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "msisensor": {
        "name_process": "msisensor",
        "string_process": "\nprocess msisensor {\n                                                      \n                                                                   \n                             \n                                                                             \n                                                                                                                   \n    errorStrategy 'ignore'\n    publishDir \"${params.outputDir}/microsatellites\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), file(tumorBam), file(tumorBai), val(normalID), file(normalBam), file(normalBai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed), file(microsatellites) from samples_dd_ra_rc_bam_pairs_ref_msi\n\n    output:\n    file \"${msisensor_output}\"\n    file \"${msisensor_dis}\"\n    file \"${msisensor_germline}\"\n    file \"${msisensor_somatic}\"\n    val(comparisonID) into done_msisensor\n\n    when:\n    disable_msisensor != true\n\n    script:\n    prefix = \"${comparisonID}\"\n    msisensor_output = \"${prefix}.msisensor\"\n    msisensor_dis = \"${prefix}.msisensor_dis\"\n    msisensor_germline = \"${prefix}.msisensor_germline\"\n    msisensor_somatic = \"${prefix}.msisensor_somatic\"\n    \"\"\"\n    msisensor msi -d \"${microsatellites}\" -n \"${normalBam}\" -t \"${tumorBam}\" -e \"${targets_bed}\" -o \"${msisensor_output}\" -l 1 -q 1 -b \\${NSLOTS:-\\${NTHREADS:-1}}\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    prefix = \"${comparisonID}\"\n    msisensor_output = \"${prefix}.msisensor\"\n    msisensor_dis = \"${prefix}.msisensor_dis\"\n    msisensor_germline = \"${prefix}.msisensor_germline\"\n    msisensor_somatic = \"${prefix}.msisensor_somatic\"\n    \"\"\"\n    msisensor msi -d \"${microsatellites}\" -n \"${normalBam}\" -t \"${tumorBam}\" -e \"${targets_bed}\" -o \"${msisensor_output}\" -l 1 -q 1 -b \\${NSLOTS:-\\${NTHREADS:-1}}\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "MSIsensor"
        ],
        "tools_url": [
            "https://bio.tools/msisensor"
        ],
        "tools_dico": [
            {
                "name": "MSIsensor",
                "uri": "https://bio.tools/msisensor",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Nucleic acid feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Sequence feature detection (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "C++ program for automatically detecting somatic and germline variants at microsatellite regions. It computes length distributions of microsatellites per site in paired tumor and normal sequence data, subsequently using these to statistically compare observed distributions in both samples.",
                "homepage": "https://github.com/ding-lab/msisensor"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_pairs_ref_msi"
        ],
        "nb_inputs": 1,
        "outputs": [
            "done_msisensor"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "errorStrategy 'ignore'",
            "publishDir \"${params.outputDir}/microsatellites\", mode: 'copy'"
        ],
        "when": "disable_msisensor != true",
        "stub": ""
    },
    "mutect2": {
        "name_process": "mutect2",
        "string_process": "\nprocess mutect2 {\n                                          \n                                                                                                   \n    publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_file}\"\n    publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\"\n\n\n    input:\n    set val(comparisonID), val(tumorID), file(tumorBam), file(tumorBai), val(normalID), file(normalBam), file(normalBai), file(ref_fasta), file(ref_fai), file(ref_dict), file(\"targets.bed\"), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx), file(cosmic_ref_vcf), file(cosmic_ref_vcf_idx), val(chunkLabel) from samples_dd_ra_rc_bam_pairs_ref_gatk_chrom\n\n    output:\n    set val(caller), val(\"${callerType}\"), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${norm_vcf}\") into vcfs_mutect2\n    set val(caller), val(\"${callerType}\"), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${norm_vcf}\") into samples_mutect3\n    file(\"${vcf_file}\")\n    file(\"${norm_vcf}\")\n    file(\"${multiallelics_stats}\")\n    file(\"${realign_stats}\")\n    val(comparisonID) into done_mutect2\n\n    script:\n    caller = \"MuTect2\"\n    callerType = \"NA\"\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    vcf_file = \"${prefix}.vcf\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    filtered_vcf = \"${prefix}.filtered.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    tsv_file = \"${prefix}.tsv\"\n    reformat_tsv = \"${prefix}.reformat.tsv\"\n    \"\"\"\n    # variant calling\n    gatk.sh -T MuTect2 \\\n    -dt NONE \\\n    --logging_level WARN \\\n    --standard_min_confidence_threshold_for_calling 30 \\\n    --max_alt_alleles_in_normal_count 10 \\\n    --max_alt_allele_in_normal_fraction 0.05 \\\n    --max_alt_alleles_in_normal_qscore_sum 40 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --dbsnp \"${dbsnp_ref_vcf}\" \\\n    --cosmic \"${cosmic_ref_vcf}\" \\\n    --intervals \"targets.bed\" \\\n    --interval_padding 10 \\\n    --input_file:tumor \"${tumorBam}\" \\\n    --input_file:normal \"${normalBam}\" \\\n    --out \"${vcf_file}\"\n\n    # normalize and split vcf entries\n    cat \"${vcf_file}\" | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"\n                                                           \n                                                                         \n}",
        "nb_lignes_process": 58,
        "string_script": "    caller = \"MuTect2\"\n    callerType = \"NA\"\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    vcf_file = \"${prefix}.vcf\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n    filtered_vcf = \"${prefix}.filtered.vcf\"\n    multiallelics_stats = \"${prefix}.bcftools.multiallelics.stats.txt\"\n    realign_stats = \"${prefix}.bcftools.realign.stats.txt\"\n    tsv_file = \"${prefix}.tsv\"\n    reformat_tsv = \"${prefix}.reformat.tsv\"\n    \"\"\"\n    # variant calling\n    gatk.sh -T MuTect2 \\\n    -dt NONE \\\n    --logging_level WARN \\\n    --standard_min_confidence_threshold_for_calling 30 \\\n    --max_alt_alleles_in_normal_count 10 \\\n    --max_alt_allele_in_normal_fraction 0.05 \\\n    --max_alt_alleles_in_normal_qscore_sum 40 \\\n    --reference_sequence \"${ref_fasta}\" \\\n    --dbsnp \"${dbsnp_ref_vcf}\" \\\n    --cosmic \"${cosmic_ref_vcf}\" \\\n    --intervals \"targets.bed\" \\\n    --interval_padding 10 \\\n    --input_file:tumor \"${tumorBam}\" \\\n    --input_file:normal \"${normalBam}\" \\\n    --out \"${vcf_file}\"\n\n    # normalize and split vcf entries\n    cat \"${vcf_file}\" | \\\n    bcftools norm --multiallelics -both --output-type v - 2>\"${multiallelics_stats}\" | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - 2>\"${realign_stats}\" > \\\n    \"${norm_vcf}\"\n    \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_pairs_ref_gatk_chrom"
        ],
        "nb_inputs": 1,
        "outputs": [
            "vcfs_mutect2",
            "samples_mutect3",
            "done_mutect2"
        ],
        "nb_outputs": 3,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy', pattern: \"*${vcf_file}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy', pattern: \"*${norm_vcf}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${multiallelics_stats}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${realign_stats}\""
        ],
        "when": "",
        "stub": ""
    },
    "lofreq_somatic": {
        "name_process": "lofreq_somatic",
        "string_process": "\nprocess lofreq_somatic {\n                                                              \n    publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_snvs_vcf_norm}\"\n    publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_indels_vcf_norm}\"\n    publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_minus_dbsnp_snvs_vcf_norm}\"\n    publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_minus_dbsnp_indels_vcf_norm}\"\n\n    input:\n    set val(comparisonID), val(tumorID), file(tumorBam), file(tumorBai), val(normalID), file(normalBam), file(normalBai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bed), file(dbsnp_ref_vcf_gz), file(dbsnp_ref_vcf_gz_tbi) from samples_dd_ra_rc_bam_pairs_ref_dbsnp\n\n    output:\n    file(\"${final_snvs_vcf_gz}\")\n    file(\"${final_indels_vcf_gz}\")\n                                               \n                                                 \n    set val(\"${caller}\"), val(\"snvs\"), val(comparisonID), val(tumorID), val(normalID), val(\"${chunkLabel}\"), file(\"${final_snvs_vcf_norm}\") into vcfs_lofreq_somatic_snvs_vcf_norm\n    set val(\"${caller}\"), val(\"indels\"), val(comparisonID), val(tumorID), val(normalID), val(\"${chunkLabel}\"), file(\"${final_indels_vcf_norm}\") into vcfs_lofreq_somatic_indels_vcf_norm\n                                                                                                                                                                                                                         \n                                                                                                                                                                                                                             \n\n    script:\n    caller = \"LoFreqSomatic\"\n    chunkLabel = \"NA\"\n    prefix = \"${comparisonID}.${caller}\"\n    lofreq_prefix = \"${prefix}.\"\n\n    final_snvs_vcf_gz = \"${lofreq_prefix}somatic_final.snvs.vcf.gz\"\n    final_indels_vcf_gz = \"${lofreq_prefix}somatic_final.indels.vcf.gz\"\n    final_minus_dbsnp_snvs_vcf_gz = \"${lofreq_prefix}somatic_final_minus-dbsnp.snvs.vcf.gz\"\n    final_minus_dbsnp_indels_vcf_gz = \"${lofreq_prefix}somatic_final_minus-dbsnp.indels.vcf.gz\"\n\n    final_snvs_vcf_norm = \"${lofreq_prefix}somatic_final.snvs.norm.vcf\"\n    final_indels_vcf_norm = \"${lofreq_prefix}somatic_final.indels.norm.vcf\"\n    final_minus_dbsnp_snvs_vcf_norm = \"${lofreq_prefix}somatic_final_minus-dbsnp.snvs.norm.vcf\"\n    final_minus_dbsnp_indels_vcf_norm = \"${lofreq_prefix}somatic_final_minus-dbsnp.indels.norm.vcf\"\n    \"\"\"\n    # paired tumor-normal somatic variant calling with LoFreq\n    lofreq somatic \\\n    --call-indels \\\n    -n \"${normalBam}\" \\\n    -t \"${tumorBam}\" \\\n    -f \"${ref_fasta}\" \\\n    --threads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -o \"${lofreq_prefix}\" \\\n    -d \"${dbsnp_ref_vcf_gz}\" \\\n    -l \"${targets_bed}\"\n\n    # split multi-allelic entries and left normalize\n    zcat ${final_snvs_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_snvs_vcf_norm}\"\n\n    zcat ${final_indels_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_indels_vcf_norm}\"\n\n    zcat ${final_minus_dbsnp_snvs_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_minus_dbsnp_snvs_vcf_norm}\"\n\n    zcat ${final_minus_dbsnp_indels_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_minus_dbsnp_indels_vcf_norm}\"\n    \"\"\"\n}",
        "nb_lignes_process": 68,
        "string_script": "    caller = \"LoFreqSomatic\"\n    chunkLabel = \"NA\"\n    prefix = \"${comparisonID}.${caller}\"\n    lofreq_prefix = \"${prefix}.\"\n\n    final_snvs_vcf_gz = \"${lofreq_prefix}somatic_final.snvs.vcf.gz\"\n    final_indels_vcf_gz = \"${lofreq_prefix}somatic_final.indels.vcf.gz\"\n    final_minus_dbsnp_snvs_vcf_gz = \"${lofreq_prefix}somatic_final_minus-dbsnp.snvs.vcf.gz\"\n    final_minus_dbsnp_indels_vcf_gz = \"${lofreq_prefix}somatic_final_minus-dbsnp.indels.vcf.gz\"\n\n    final_snvs_vcf_norm = \"${lofreq_prefix}somatic_final.snvs.norm.vcf\"\n    final_indels_vcf_norm = \"${lofreq_prefix}somatic_final.indels.norm.vcf\"\n    final_minus_dbsnp_snvs_vcf_norm = \"${lofreq_prefix}somatic_final_minus-dbsnp.snvs.norm.vcf\"\n    final_minus_dbsnp_indels_vcf_norm = \"${lofreq_prefix}somatic_final_minus-dbsnp.indels.norm.vcf\"\n    \"\"\"\n    # paired tumor-normal somatic variant calling with LoFreq\n    lofreq somatic \\\n    --call-indels \\\n    -n \"${normalBam}\" \\\n    -t \"${tumorBam}\" \\\n    -f \"${ref_fasta}\" \\\n    --threads \\${NSLOTS:-\\${NTHREADS:-1}} \\\n    -o \"${lofreq_prefix}\" \\\n    -d \"${dbsnp_ref_vcf_gz}\" \\\n    -l \"${targets_bed}\"\n\n    # split multi-allelic entries and left normalize\n    zcat ${final_snvs_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_snvs_vcf_norm}\"\n\n    zcat ${final_indels_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_indels_vcf_norm}\"\n\n    zcat ${final_minus_dbsnp_snvs_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_minus_dbsnp_snvs_vcf_norm}\"\n\n    zcat ${final_minus_dbsnp_indels_vcf_gz} | \\\n    bcftools norm --multiallelics -both --output-type v - | \\\n    bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n    \"${final_minus_dbsnp_indels_vcf_norm}\"\n    \"\"\"",
        "nb_lignes_script": 46,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samples_dd_ra_rc_bam_pairs_ref_dbsnp"
        ],
        "nb_inputs": 1,
        "outputs": [
            "vcfs_lofreq_somatic_snvs_vcf_norm",
            "vcfs_lofreq_somatic_indels_vcf_norm"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_snvs_vcf_norm}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_indels_vcf_norm}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_minus_dbsnp_snvs_vcf_norm}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/norm\", mode: 'copy', pattern: \"*${final_minus_dbsnp_indels_vcf_norm}\""
        ],
        "when": "",
        "stub": ""
    },
    "manta": {
        "name_process": "manta",
        "string_process": "\nprocess manta {\n    publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), file(tumorBam), file(tumorBai), val(normalID), file(normalBam), file(normalBai), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bgz), file(targets_tbi) from samples_dd_bam_noHapMap_pairs_ref.combine(targets_zipped)\n\n    output:\n    set val(\"${caller}\"), val(\"${callerType}\"), val(comparisonID), val(tumorID), val(normalID), val(\"${chunkLabel}\"), file(\"${candidateSmallIndels_gz}\"), file(\"${candidateSmallIndels_tbi}\") into mantaToStrelka\n    file(\"${candidateSV}\")\n    file(\"${diploidSV}\")\n    file(\"${somaticSV}\")\n    file(\"${candidateSmallIndels}\")\n                                                                                                                                                                                                                                                                                                                                                                  \n\n    script:\n    caller = \"Manta\"\n    chunkLabel = \"NA\"\n    callerType = \"NA\"\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    runDir = \"${prefix}.Manta\"\n    candidateSmallIndels = \"${prefix}.candidateSmallIndels.vcf\"\n    candidateSmallIndels_gz = \"${prefix}.candidateSmallIndels.vcf.gz\"\n    candidateSmallIndels_tbi = \"${prefix}.candidateSmallIndels.vcf.gz.tbi\"\n    candidateSV = \"${prefix}.candidateSV.vcf\"\n    candidateSV_gz = \"${prefix}.candidateSV.vcf.gz\"\n    candidateSV_tbi = \"${prefix}.candidateSV.vcf.gz.tbi\"\n    diploidSV = \"${prefix}.diploidSV.vcf\"\n    diploidSV_gz = \"${prefix}.diploidSV.vcf.gz\"\n    diploidSV_tbi = \"${prefix}.diploidSV.vcf.gz.tbi\"\n    somaticSV = \"${prefix}.somaticSV.vcf\"\n    somaticSV_gz = \"${prefix}.somaticSV.vcf.gz\"\n    somaticSV_tbi = \"${prefix}.somaticSV.vcf.gz.tbi\"\n    \"\"\"\n    configManta.py \\\n    --normalBam \"${normalBam}\" \\\n    --tumorBam \"${tumorBam}\" \\\n    --referenceFasta \"${ref_fasta}\" \\\n    --runDir \"${runDir}\" \\\n    --callRegions \"${targets_bgz}\" \\\n    --exome\n\n    python ${runDir}/runWorkflow.py \\\n    -m local \\\n    -j \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    # needed for Strelka\n    mv ${runDir}/results/variants/candidateSmallIndels.vcf.gz \\\n    \"${candidateSmallIndels_gz}\"\n    gunzip -c \"${candidateSmallIndels_gz}\" > \"${candidateSmallIndels}\"\n    mv ${runDir}/results/variants/candidateSmallIndels.vcf.gz.tbi \\\n    \"${candidateSmallIndels_tbi}\"\n\n    mv ${runDir}/results/variants/candidateSV.vcf.gz \\\n    \"${candidateSV_gz}\"\n    gunzip -c \"${candidateSV_gz}\" > \"${candidateSV}\"\n\n    mv ${runDir}/results/variants/diploidSV.vcf.gz \\\n    \"${diploidSV_gz}\"\n    gunzip -c \"${diploidSV_gz}\" > \"${diploidSV}\"\n\n    mv ${runDir}/results/variants/somaticSV.vcf.gz \\\n    \"${somaticSV_gz}\"\n    gunzip -c \"${somaticSV_gz}\" > \"${somaticSV}\"\n    \"\"\"\n}",
        "nb_lignes_process": 64,
        "string_script": "    caller = \"Manta\"\n    chunkLabel = \"NA\"\n    callerType = \"NA\"\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    runDir = \"${prefix}.Manta\"\n    candidateSmallIndels = \"${prefix}.candidateSmallIndels.vcf\"\n    candidateSmallIndels_gz = \"${prefix}.candidateSmallIndels.vcf.gz\"\n    candidateSmallIndels_tbi = \"${prefix}.candidateSmallIndels.vcf.gz.tbi\"\n    candidateSV = \"${prefix}.candidateSV.vcf\"\n    candidateSV_gz = \"${prefix}.candidateSV.vcf.gz\"\n    candidateSV_tbi = \"${prefix}.candidateSV.vcf.gz.tbi\"\n    diploidSV = \"${prefix}.diploidSV.vcf\"\n    diploidSV_gz = \"${prefix}.diploidSV.vcf.gz\"\n    diploidSV_tbi = \"${prefix}.diploidSV.vcf.gz.tbi\"\n    somaticSV = \"${prefix}.somaticSV.vcf\"\n    somaticSV_gz = \"${prefix}.somaticSV.vcf.gz\"\n    somaticSV_tbi = \"${prefix}.somaticSV.vcf.gz.tbi\"\n    \"\"\"\n    configManta.py \\\n    --normalBam \"${normalBam}\" \\\n    --tumorBam \"${tumorBam}\" \\\n    --referenceFasta \"${ref_fasta}\" \\\n    --runDir \"${runDir}\" \\\n    --callRegions \"${targets_bgz}\" \\\n    --exome\n\n    python ${runDir}/runWorkflow.py \\\n    -m local \\\n    -j \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    # needed for Strelka\n    mv ${runDir}/results/variants/candidateSmallIndels.vcf.gz \\\n    \"${candidateSmallIndels_gz}\"\n    gunzip -c \"${candidateSmallIndels_gz}\" > \"${candidateSmallIndels}\"\n    mv ${runDir}/results/variants/candidateSmallIndels.vcf.gz.tbi \\\n    \"${candidateSmallIndels_tbi}\"\n\n    mv ${runDir}/results/variants/candidateSV.vcf.gz \\\n    \"${candidateSV_gz}\"\n    gunzip -c \"${candidateSV_gz}\" > \"${candidateSV}\"\n\n    mv ${runDir}/results/variants/diploidSV.vcf.gz \\\n    \"${diploidSV_gz}\"\n    gunzip -c \"${diploidSV_gz}\" > \"${diploidSV}\"\n\n    mv ${runDir}/results/variants/somaticSV.vcf.gz \\\n    \"${somaticSV_gz}\"\n    gunzip -c \"${somaticSV_gz}\" > \"${somaticSV}\"\n    \"\"\"",
        "nb_lignes_script": 48,
        "language_script": "bash",
        "tools": [
            "SCcaller"
        ],
        "tools_url": [
            "https://bio.tools/sccaller"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            }
        ],
        "inputs": [
            "samples_dd_bam_noHapMap_pairs_ref",
            "targets_zipped"
        ],
        "nb_inputs": 2,
        "outputs": [
            "mantaToStrelka"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "strelka": {
        "name_process": "strelka",
        "string_process": "\nprocess strelka {\n    publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), file(tumorBam), file(tumorBai), val(normalID), file(normalBam), file(normalBai), file(small_indels), file(small_indels_tbi), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_bgz), file(targets_tbi) from samples_dd_bam_noHapMap_pairs_manta.combine(targets_zipped2)\n\n    output:\n    set val(\"${caller}\"), val(\"snvs\"), val(comparisonID), val(tumorID), val(normalID), val(\"${chunkLabel}\"), file(\"${somatic_snvs}\") into strelka_snvs\n    set val(\"${caller}\"), val(\"indel\"), val(comparisonID), val(tumorID), val(normalID), val(\"${chunkLabel}\"), file(\"${somatic_indels}\") into strelka_indels\n\n    script:\n    caller = \"Strelka\"\n    chunkLabel = \"NA\"\n    callerType = \"NA\"\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    runDir = \"${prefix}.Strelka\"\n    somatic_indels = \"${prefix}.somatic.indels.vcf\"\n    somatic_indels_gz = \"${prefix}.somatic.indels.vcf.gz\"\n    somatic_indels_tbi = \"${prefix}.somatic.indels.vcf.gz.tbi\"\n    somatic_snvs = \"${prefix}.somatic.snvs.vcf\"\n    somatic_snvs_gz = \"${prefix}.somatic.snvs.vcf.gz\"\n    somatic_snvs_tbi = \"${prefix}.somatic.snvs.vcf.gz.tbi\"\n    \"\"\"\n    configureStrelkaSomaticWorkflow.py \\\n    --normalBam \"${normalBam}\" \\\n    --tumorBam \"${tumorBam}\" \\\n    --referenceFasta \"${ref_fasta}\" \\\n    --indelCandidates \"${small_indels}\" \\\n    --runDir ${runDir} \\\n    --callRegions \"${targets_bgz}\" \\\n    --exome\n\n    python ${runDir}/runWorkflow.py \\\n    -m local \\\n    -j \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    mv ${runDir}/results/variants/somatic.indels.vcf.gz \\\n    \"${somatic_indels_gz}\"\n    gunzip -c \"${somatic_indels_gz}\" > \"${somatic_indels}\"\n\n    mv ${runDir}/results/variants/somatic.snvs.vcf.gz \\\n    \"${somatic_snvs_gz}\"\n    gunzip -c \"${somatic_snvs_gz}\" > \"${somatic_snvs}\"\n    \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "    caller = \"Strelka\"\n    chunkLabel = \"NA\"\n    callerType = \"NA\"\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    runDir = \"${prefix}.Strelka\"\n    somatic_indels = \"${prefix}.somatic.indels.vcf\"\n    somatic_indels_gz = \"${prefix}.somatic.indels.vcf.gz\"\n    somatic_indels_tbi = \"${prefix}.somatic.indels.vcf.gz.tbi\"\n    somatic_snvs = \"${prefix}.somatic.snvs.vcf\"\n    somatic_snvs_gz = \"${prefix}.somatic.snvs.vcf.gz\"\n    somatic_snvs_tbi = \"${prefix}.somatic.snvs.vcf.gz.tbi\"\n    \"\"\"\n    configureStrelkaSomaticWorkflow.py \\\n    --normalBam \"${normalBam}\" \\\n    --tumorBam \"${tumorBam}\" \\\n    --referenceFasta \"${ref_fasta}\" \\\n    --indelCandidates \"${small_indels}\" \\\n    --runDir ${runDir} \\\n    --callRegions \"${targets_bgz}\" \\\n    --exome\n\n    python ${runDir}/runWorkflow.py \\\n    -m local \\\n    -j \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    mv ${runDir}/results/variants/somatic.indels.vcf.gz \\\n    \"${somatic_indels_gz}\"\n    gunzip -c \"${somatic_indels_gz}\" > \"${somatic_indels}\"\n\n    mv ${runDir}/results/variants/somatic.snvs.vcf.gz \\\n    \"${somatic_snvs_gz}\"\n    gunzip -c \"${somatic_snvs_gz}\" > \"${somatic_snvs}\"\n    \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "SCcaller"
        ],
        "tools_url": [
            "https://bio.tools/sccaller"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            }
        ],
        "inputs": [
            "samples_dd_bam_noHapMap_pairs_manta",
            "targets_zipped2"
        ],
        "nb_inputs": 2,
        "outputs": [
            "strelka_snvs",
            "strelka_indels"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/raw\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "normalize_vcfs_pairs": {
        "name_process": "normalize_vcfs_pairs",
        "string_process": "\nprocess normalize_vcfs_pairs {\n    publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy'\n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(vcf), file(ref_fasta), file(ref_fai), file(ref_dict) from raw_vcfs_pairs.combine(ref_fasta21).combine(ref_fai21).combine(ref_dict21)\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${norm_vcf}\") into norm_vcfs_pairs\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n        \"\"\"\n        cat ${vcf} | \\\n        bcftools norm --multiallelics -both --output-type v - | \\\n        bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n        \"${norm_vcf}\"\n        \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    norm_vcf = \"${prefix}.norm.vcf\"\n        \"\"\"\n        cat ${vcf} | \\\n        bcftools norm --multiallelics -both --output-type v - | \\\n        bcftools norm --fasta-ref \"${ref_fasta}\" --output-type v - > \\\n        \"${norm_vcf}\"\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "raw_vcfs_pairs",
            "ref_fasta21",
            "ref_fai21",
            "ref_dict21"
        ],
        "nb_inputs": 4,
        "outputs": [
            "norm_vcfs_pairs"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/variants/${caller}/normalized\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "filter_vcf_pairs": {
        "name_process": "filter_vcf_pairs",
        "string_process": "\nprocess filter_vcf_pairs {\n                                             \n                                                                                                                                                  \n    tag \"${caller}.${chunkLabel}\"\n    publishDir \"${params.outputDir}/variants/${caller}/filtered\", mode: 'copy', pattern: \"*${filtered_vcf}\"\n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(vcf), file(ref_fasta), file(ref_fai), file(ref_dict) from vcfs_pairs.combine(ref_fasta17).combine(ref_fai17).combine(ref_dict17)\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${filtered_vcf}\") into filtered_vcf_pairs          \n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    filtered_vcf = \"${prefix}.filtered.vcf\"\n    if( caller == 'MuTect2' )\n        \"\"\"\n        # filter VCF\n        # report if:\n        # only keep 'PASS' entries\n\n        # get the header\n        # grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        # grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n\n        # old method\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select 'vc.isNotFiltered()' \\\n        # > \"${filtered_vcf}\"\n\n        # other criteria:\n\n        # T frequency is more than 3%\n        # ( Tumor Allelic depth alt / (Tumor Allelic depth ref + Tumor Allelic depth alt ) )  > 0.03\n        # -select \"(vc.getGenotype('TUMOR').getAD().1 / (vc.getGenotype('TUMOR').getAD().0 + vc.getGenotype('TUMOR').getAD().1) )  > 0.03\" \\\n\n        # N frequency is less than 5%\n        # ( Normal Allelic depth alt / ( Normal Allelic depth ref + Normal Allelic depth alt ) )  < 0.05\n        # -select \"(vc.getGenotype('NORMAL').getAD().1 / (vc.getGenotype('NORMAL').getAD().0 + vc.getGenotype('NORMAL').getAD().1) )  < 0.05\" \\\n\n        # at least 5 variant call supporting reads\n        # Tumor Allelic depth alt > 5\n        # -select \"vc.getGenotype('TUMOR').getAD().1 > 5\" \\\n\n        # T frequency is sufficiently higher (5x) than N frequency\n        # \"we recommend applying post-processing filters, e.g. by hard-filtering calls with low minor allele frequencies\"\n        # ( Tumor Allelic depth alt / ( Tumor Allelic depth ref + Tumor Allelic depth alt ) ) > ( Normal Allelic depth alt / ( Normal Allelic depth ref + Normal Allelic depth alt ) ) * 5\n        # -select \"(vc.getGenotype('TUMOR').getAD().1 / (vc.getGenotype('TUMOR').getAD().0 + vc.getGenotype('TUMOR').getAD().1) ) > (vc.getGenotype('NORMAL').getAD().1 / (vc.getGenotype('NORMAL').getAD().0 + vc.getGenotype('NORMAL').getAD().1) ) * 5\" \\\n\n        # vc.getGenotype('TUMOR').getAD().0 ; Tumor Allelic depth ref\n        # vc.getGenotype('TUMOR').getAD().1 ; Tumor Allelic depth alt\n        # vc.getGenotype('NORMAL').getAD().0 ; Normal Allelic depth ref\n        # vc.getGenotype('NORMAL').getAD().1 ; Normal Allelic depth alt\n\n        # example variant format:\n        ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n        # CHROM\tchr7\n        # POS\t2946342\n        # ID\t.\n        # REF\tA\n        # ALT\tG\n        # QUAL\t.\n        # FILTER\tclustered_events;homologous_mapping_event\n        # INFO\tECNT=16;HCNT=3;MAX_ED=65;MIN_ED=5;NLOD=33.41;TLOD=23.04\n        # FORMAT\tGT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:PGT:PID:QSS:REF_F1R2:REF_F2R1\n        # TUMOR\t0/1:1333,17:0.013:7:10:0.588:0|1:2946342_A_G:40125,535:641:689\n        # NORMAL\t0/0:137,0:0.00:0:0:.:0|1:2946342_A_G:3959,0:53:80\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if( caller == 'LoFreqSomatic' )\n        \"\"\"\n        # do not report if:\n        # - frequency is less than 1%, greater than 99%\n        # - depth less than 200\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"AF > 0.01\"  \\\n        # -select \"AF < 0.99\"  \\\n        # -select \"DP > 100\"  \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if( caller == 'Strelka' )\n        \"\"\"\n        # only keep 'PASS' entries\n        # filter out TQSS_NT=2 https://github.com/Illumina/strelka/issues/65\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"TQSS_NT != 2\"  \\\n        # --excludeFiltered \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n                                                              \n                                                                                                                                                                                                     \n                                                                                             \n                                                                                                                                                                           \n                                                                                                                                            \n                                                                                                   \n                                                                                                                        \n                                                                                \n                                                                                           \n                                                                               \n                                                                                               \n                                                                                                                                                     \n                                                                                           \n                                                                                                                             \n                                                                                                                                                \n                                                                                                                                                                                                 \n                                                                                                    \n                                                                                                                                \n                                                                                                                           \n                                                                                                                                                 \n                                                                                                       \n                                                                                                       \n                                                                                                       \n                                                                                                       \n                                                                                                             \n                                                                                                          \n\n                                                              \n                                                                                                                   \n                                                                                                                                   \n                                                                                                     \n                                                                                                                                    \n                                                                                                                 \n                                                                                           \n                                                                                                                  \n                                                                                                                                                      \n                                                                       \n                                                                                                                     \n                                                                                                                \n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 151,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    filtered_vcf = \"${prefix}.filtered.vcf\"\n    if( caller == 'MuTect2' )\n        \"\"\"\n        # filter VCF\n        # report if:\n        # only keep 'PASS' entries\n\n        # get the header\n        # grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        # grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n\n        # old method\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select 'vc.isNotFiltered()' \\\n        # > \"${filtered_vcf}\"\n\n        # other criteria:\n\n        # T frequency is more than 3%\n        # ( Tumor Allelic depth alt / (Tumor Allelic depth ref + Tumor Allelic depth alt ) )  > 0.03\n        # -select \"(vc.getGenotype('TUMOR').getAD().1 / (vc.getGenotype('TUMOR').getAD().0 + vc.getGenotype('TUMOR').getAD().1) )  > 0.03\" \\\n\n        # N frequency is less than 5%\n        # ( Normal Allelic depth alt / ( Normal Allelic depth ref + Normal Allelic depth alt ) )  < 0.05\n        # -select \"(vc.getGenotype('NORMAL').getAD().1 / (vc.getGenotype('NORMAL').getAD().0 + vc.getGenotype('NORMAL').getAD().1) )  < 0.05\" \\\n\n        # at least 5 variant call supporting reads\n        # Tumor Allelic depth alt > 5\n        # -select \"vc.getGenotype('TUMOR').getAD().1 > 5\" \\\n\n        # T frequency is sufficiently higher (5x) than N frequency\n        # \"we recommend applying post-processing filters, e.g. by hard-filtering calls with low minor allele frequencies\"\n        # ( Tumor Allelic depth alt / ( Tumor Allelic depth ref + Tumor Allelic depth alt ) ) > ( Normal Allelic depth alt / ( Normal Allelic depth ref + Normal Allelic depth alt ) ) * 5\n        # -select \"(vc.getGenotype('TUMOR').getAD().1 / (vc.getGenotype('TUMOR').getAD().0 + vc.getGenotype('TUMOR').getAD().1) ) > (vc.getGenotype('NORMAL').getAD().1 / (vc.getGenotype('NORMAL').getAD().0 + vc.getGenotype('NORMAL').getAD().1) ) * 5\" \\\n\n        # vc.getGenotype('TUMOR').getAD().0 ; Tumor Allelic depth ref\n        # vc.getGenotype('TUMOR').getAD().1 ; Tumor Allelic depth alt\n        # vc.getGenotype('NORMAL').getAD().0 ; Normal Allelic depth ref\n        # vc.getGenotype('NORMAL').getAD().1 ; Normal Allelic depth alt\n\n        # example variant format:\n        ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n        # CHROM\tchr7\n        # POS\t2946342\n        # ID\t.\n        # REF\tA\n        # ALT\tG\n        # QUAL\t.\n        # FILTER\tclustered_events;homologous_mapping_event\n        # INFO\tECNT=16;HCNT=3;MAX_ED=65;MIN_ED=5;NLOD=33.41;TLOD=23.04\n        # FORMAT\tGT:AD:AF:ALT_F1R2:ALT_F2R1:FOXOG:PGT:PID:QSS:REF_F1R2:REF_F2R1\n        # TUMOR\t0/1:1333,17:0.013:7:10:0.588:0|1:2946342_A_G:40125,535:641:689\n        # NORMAL\t0/0:137,0:0.00:0:0:.:0|1:2946342_A_G:3959,0:53:80\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if( caller == 'LoFreqSomatic' )\n        \"\"\"\n        # do not report if:\n        # - frequency is less than 1%, greater than 99%\n        # - depth less than 200\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"AF > 0.01\"  \\\n        # -select \"AF < 0.99\"  \\\n        # -select \"DP > 100\"  \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n    else if( caller == 'Strelka' )\n        \"\"\"\n        # only keep 'PASS' entries\n        # filter out TQSS_NT=2 https://github.com/Illumina/strelka/issues/65\n        # gatk.sh -T SelectVariants \\\n        # -R \"${ref_fasta}\" \\\n        # -V \"${vcf}\" \\\n        # -select \"TQSS_NT != 2\"  \\\n        # --excludeFiltered \\\n        # > \"${filtered_vcf}\"\n\n        # get the header\n        grep '^#' \"${vcf}\" > \"${filtered_vcf}\"\n        # get the 'PASS' entries\n        grep -v '^#' \"${vcf}\" | grep 'PASS' >> \"${filtered_vcf}\" || :\n        \"\"\"\n                                                              \n                                                                                                                                                                                                     \n                                                                                             \n                                                                                                                                                                           \n                                                                                                                                            \n                                                                                                   \n                                                                                                                        \n                                                                                \n                                                                                           \n                                                                               \n                                                                                               \n                                                                                                                                                     \n                                                                                           \n                                                                                                                             \n                                                                                                                                                \n                                                                                                                                                                                                 \n                                                                                                    \n                                                                                                                                \n                                                                                                                           \n                                                                                                                                                 \n                                                                                                       \n                                                                                                       \n                                                                                                       \n                                                                                                       \n                                                                                                             \n                                                                                                          \n\n                                                              \n                                                                                                                   \n                                                                                                                                   \n                                                                                                     \n                                                                                                                                    \n                                                                                                                 \n                                                                                           \n                                                                                                                  \n                                                                                                                                                      \n                                                                       \n                                                                                                                     \n                                                                                                                \n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 137,
        "language_script": "bash",
        "tools": [
            "TumorHPD",
            "NOrMAL"
        ],
        "tools_url": [
            "https://bio.tools/tumorhpd",
            "https://bio.tools/normal"
        ],
        "tools_dico": [
            {
                "name": "TumorHPD",
                "uri": "https://bio.tools/tumorhpd",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0128",
                            "term": "Protein interactions"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Protein sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3092",
                                    "term": "Protein feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2479",
                                    "term": "Sequence analysis (protein)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3092",
                                    "term": "Protein feature prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3092",
                                    "term": "Protein feature recognition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Web server for predicting and designing tumor homing peptides. This server is extremely useful for the researchers working in the field of therapeutic peptides.",
                "homepage": "http://crdd.osdd.net/raghava/tumorhpd/"
            },
            {
                "name": "NOrMAL",
                "uri": "https://bio.tools/normal",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3176",
                            "term": "DNA packaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NOrMAL (NucleOsome Mapping ALgorithm) is a command line tool for accurate placing of the nucleosomes. It was designed to resolve overlapping nucleosomes and extract extra information (\u201cfuzziness\u201d, probability, etc.) of nucleosome placement.",
                "homepage": "http://www.cs.ucr.edu/~polishka/"
            }
        ],
        "inputs": [
            "vcfs_pairs",
            "ref_fasta17",
            "ref_fai17",
            "ref_dict17"
        ],
        "nb_inputs": 4,
        "outputs": [
            "filtered_vcf_pairs"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${chunkLabel}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/filtered\", mode: 'copy', pattern: \"*${filtered_vcf}\""
        ],
        "when": "",
        "stub": ""
    },
    "vcf_to_tsv_pairs": {
        "name_process": "vcf_to_tsv_pairs",
        "string_process": "\nprocess vcf_to_tsv_pairs {\n    tag \"${caller}.${chunkLabel}\"\n    publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${tsv_file}\"\n    publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${reformat_tsv}\"\n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(vcf), file(ref_fasta), file(ref_fai), file(ref_dict) from filtered_vcf_pairs.combine(ref_fasta18).combine(ref_fai18).combine(ref_dict18)\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(vcf), file(\"${reformat_tsv}\") into vcf_tsv_pairs                 \n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${reformat_tsv}\") into vcf_tsv_pairs2\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    tsv_file = \"${prefix}.tsv\"\n    reformat_tsv = \"${prefix}.reformat.tsv\"\n    if( caller == 'MuTect2' )\n        \"\"\"\n        # convert VCF to TSV\n        # NOTE: automatically filters for only PASS entries\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM -F POS -F ID -F REF -F ALT -F FILTER -F QUAL -F AC -F AN -F NLOD -F TLOD \\\n        -GF AD -GF DP -GF AF \\\n        -o \"${tsv_file}\"\n\n        # .vcf field descriptions:\n        ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n        ##FORMAT=<ID=AF,Number=1,Type=Float,Description=\"Allele fraction of the event in the tumor\">\n        ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n        ##INFO=<ID=NLOD,Number=1,Type=String,Description=\"Normal LOD score\">\n        ##INFO=<ID=TLOD,Number=1,Type=String,Description=\"Tumor LOD score\">\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c MuTect2 -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${tumorID}\"  | \\\n        paste-col.py --header \"Tumor\" -v \"${tumorID}\"  | \\\n        paste-col.py --header \"Normal\" -v \"${normalID}\"  | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n\n        # make sure that the input and output tables have the same number of rows\n        if [ \"\\$(wc -l < \"${tsv_file}\" )\" -ne \"\\$( wc -l < \"${reformat_tsv}\" )\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n        \"\"\"\n    else if( caller == 'LoFreqSomatic' )\n        \"\"\"\n        # convert to tsv format\n        # NOTE: automatically filters for only PASS entries\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F QUAL \\\n        -F FILTER \\\n        -F DP \\\n        -F DP4 \\\n        -F AF \\\n        -F SB \\\n        -F UQ \\\n        -F CONSVAR \\\n        -F AN \\\n        -F AC \\\n        -F HRUN \\\n        -F INDEL \\\n        -F UNIQ \\\n        -F SOMATIC \\\n        -o \"${tsv_file}\"\n\n        # .vcf field descriptions:\n        ##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes, for each ALT allele, in the same order as listed\">\n        ##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\">\n        ##INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\">\n        ##INFO=<ID=CONSVAR,Number=0,Type=Flag,Description=\"Indicates that the variant is a consensus variant (as opposed to a low frequency variant).\">\n        ##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth; some reads may have been filtered\">\n        ##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Raw Depth\">\n        ##INFO=<ID=DP4,Number=4,Type=Integer,Description=\"Counts for ref-forward bases, ref-reverse, alt-forward and alt-reverse bases\">\n        ##INFO=<ID=HRUN,Number=1,Type=Integer,Description=\"Homopolymer length to the right of report indel position\">\n        ##INFO=<ID=INDEL,Number=0,Type=Flag,Description=\"Indicates that the variant is an INDEL.\">\n        ##INFO=<ID=SB,Number=1,Type=Float,Description=\"Strand Bias\">\n        ##INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic event\">\n        ##INFO=<ID=UNIQ,Number=0,Type=Flag,Description=\"Unique, i.e. not detectable in paired sample\">\n        ##INFO=<ID=UQ,Number=1,Type=Integer,Description=\"Phred-scaled uniq score at this position\">\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c LoFreq -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n        paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n        paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n\n        # make sure that the input and output tables have the same number of rows\n        if [ \"\\$(wc -l < \"${tsv_file}\" )\" -ne \"\\$( wc -l < \"${reformat_tsv}\" )\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n        \"\"\"\n    else if( caller == 'Strelka' )\n        if ( callerType == \"snvs\" )\n            \"\"\"\n            # convert to tsv format\n            # NOTE: automatically filters for only PASS entries\n            gatk.sh -T VariantsToTable \\\n            -R \"${ref_fasta}\" \\\n            -V \"${vcf}\" \\\n            -F CHROM \\\n            -F POS \\\n            -F ID \\\n            -F REF \\\n            -F ALT \\\n            -F FILTER \\\n            -F DP \\\n            -F SOMATIC \\\n            -F QSS \\\n            -F MQ \\\n            -F SNVSB \\\n            -F SomaticEVS \\\n            -GF DP \\\n            -GF AU \\\n            -GF TU \\\n            -GF CU \\\n            -GF GU \\\n            -o \"${tsv_file}\"\n\n            # vcf header example for Strelka SNVs\n            ##fileformat=VCFv4.1\n            ##FILTER=<ID=PASS,Description=\"All filters passed\">\n            ##source=strelka\n            ##source_version=2.9.10\n            ##content=strelka somatic snv calls\n            ##priorSomaticSnvRate=0.0001\n            ##INFO=<ID=QSS,Number=1,Type=Integer,Description=\"Quality score for any somatic snv, ie. for the ALT allele to be present at a significantly different frequency in the tumor and normal\">\n            ##INFO=<ID=TQSS,Number=1,Type=Integer,Description=\"Data tier used to compute QSS\">\n            ##INFO=<ID=NT,Number=1,Type=String,Description=\"Genotype of the normal in all data tiers, as used to classify somatic variants. One of {ref,het,hom,conflict}.\">\n            ##INFO=<ID=QSS_NT,Number=1,Type=Integer,Description=\"Quality score reflecting the joint probability of a somatic variant and NT\">\n            ##INFO=<ID=TQSS_NT,Number=1,Type=Integer,Description=\"Data tier used to compute QSS_NT\">\n            ##INFO=<ID=SGT,Number=1,Type=String,Description=\"Most likely somatic genotype excluding normal noise states\">\n            ##INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic mutation\">\n            ##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Combined depth across samples\">\n            ##INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">\n            ##INFO=<ID=MQ0,Number=1,Type=Integer,Description=\"Total Mapping Quality Zero Reads\">\n            ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt Vs. Ref read-position in the tumor\">\n            ##INFO=<ID=SNVSB,Number=1,Type=Float,Description=\"Somatic SNV site strand bias\">\n            ##INFO=<ID=PNOISE,Number=1,Type=Float,Description=\"Fraction of panel containing non-reference noise at this site\">\n            ##INFO=<ID=PNOISE2,Number=1,Type=Float,Description=\"Fraction of panel containing more than one non-reference noise obs at this site\">\n            ##INFO=<ID=SomaticEVS,Number=1,Type=Float,Description=\"Somatic Empirical Variant Score (EVS) expressing the phred-scaled probability of the call being a false positive observation.\">\n            ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read depth for tier1 (used+filtered)\">\n            ##FORMAT=<ID=FDP,Number=1,Type=Integer,Description=\"Number of basecalls filtered from original read depth for tier1\">\n            ##FORMAT=<ID=SDP,Number=1,Type=Integer,Description=\"Number of reads with deletions spanning this site at tier1\">\n            ##FORMAT=<ID=SUBDP,Number=1,Type=Integer,Description=\"Number of reads below tier1 mapping quality threshold aligned across this site\">\n            ##FORMAT=<ID=AU,Number=2,Type=Integer,Description=\"Number of 'A' alleles used in tiers 1,2\">\n            ##FORMAT=<ID=CU,Number=2,Type=Integer,Description=\"Number of 'C' alleles used in tiers 1,2\">\n            ##FORMAT=<ID=GU,Number=2,Type=Integer,Description=\"Number of 'G' alleles used in tiers 1,2\">\n            ##FORMAT=<ID=TU,Number=2,Type=Integer,Description=\"Number of 'T' alleles used in tiers 1,2\">\n            ##FILTER=<ID=LowEVS,Description=\"Somatic Empirical Variant Score (SomaticEVS) is below threshold\">\n            ##FILTER=<ID=LowDepth,Description=\"Tumor or normal sample read depth at this locus is below 2\">\n\n            # reformat and adjust the TSV table for consistency downstream\n            # add extra columns to the VCF TSV file for downstream\n            reformat-vcf-table.py -c StrelkaSomaticSNV -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n            paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n            paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n            paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n            \"${reformat_tsv}\"\n\n            # make sure that the input and output tables have the same number of rows\n            tsv_lines=\"\\$(wc -l < \"${tsv_file}\" )\"\n            reformat_lines=\"\\$( wc -l < \"${reformat_tsv}\" )\"\n            if [ \"\\$tsv_lines\" -ne \"\\$reformat_lines\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n\n            vcf_lines=\"\\$(grep -v '^##' ${vcf} | wc -l)\"\n            if [ \"\\$vcf_lines\" -ne \"\\$reformat_lines\" ]; then echo \"ERROR: reformat table has different number of entries than vcf file!\"; exit 1; fi\n            \"\"\"\n        else if( callerType == 'indel' )\n            \"\"\"\n            # convert to tsv format\n            # NOTE: automatically filters for only PASS entries\n            gatk.sh -T VariantsToTable \\\n            -R \"${ref_fasta}\" \\\n            -V \"${vcf}\" \\\n            -F CHROM \\\n            -F POS \\\n            -F ID \\\n            -F REF \\\n            -F ALT \\\n            -F FILTER \\\n            -F SOMATIC \\\n            -F MQ \\\n            -F SomaticEVS \\\n            -F QSI \\\n            -GF DP \\\n            -GF TAR \\\n            -GF TIR \\\n            -GF TOR \\\n            -o \"${tsv_file}\"\n\n            # vcf header example for Strelka indels\n            ##fileformat=VCFv4.1\n            ##FILTER=<ID=PASS,Description=\"All filters passed\">\n            ##source=strelka\n            ##source_version=2.9.10\n            ##content=strelka somatic indel calls\n            ##priorSomaticIndelRate=1e-06\n            ##INFO=<ID=QSI,Number=1,Type=Integer,Description=\"Quality score for any somatic variant, ie. for the ALT haplotype to be present at a significantly different frequency in the tumor and normal\">\n            ##INFO=<ID=TQSI,Number=1,Type=Integer,Description=\"Data tier used to compute QSI\">\n            ##INFO=<ID=NT,Number=1,Type=String,Description=\"Genotype of the normal in all data tiers, as used to classify somatic variants. One of {ref,het,hom,conflict}.\">\n            ##INFO=<ID=QSI_NT,Number=1,Type=Integer,Description=\"Quality score reflecting the joint probability of a somatic variant and NT\">\n            ##INFO=<ID=TQSI_NT,Number=1,Type=Integer,Description=\"Data tier used to compute QSI_NT\">\n            ##INFO=<ID=SGT,Number=1,Type=String,Description=\"Most likely somatic genotype excluding normal noise states\">\n            ##INFO=<ID=RU,Number=1,Type=String,Description=\"Smallest repeating sequence unit in inserted or deleted sequence\">\n            ##INFO=<ID=RC,Number=1,Type=Integer,Description=\"Number of times RU repeats in the reference allele\">\n            ##INFO=<ID=IC,Number=1,Type=Integer,Description=\"Number of times RU repeats in the indel allele\">\n            ##INFO=<ID=IHP,Number=1,Type=Integer,Description=\"Largest reference interrupted homopolymer length intersecting with the indel\">\n            ##INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">\n            ##INFO=<ID=MQ0,Number=1,Type=Integer,Description=\"Total Mapping Quality Zero Reads\">\n            ##INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic mutation\">\n            ##INFO=<ID=OVERLAP,Number=0,Type=Flag,Description=\"Somatic indel possibly overlaps a second indel.\">\n            ##INFO=<ID=SomaticEVS,Number=1,Type=Float,Description=\"Somatic Empirical Variant Score (EVS) expressing the phred-scaled probability of the call being a false positive observation.\">\n            ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read depth for tier1\">\n            ##FORMAT=<ID=DP2,Number=1,Type=Integer,Description=\"Read depth for tier2\">\n            ##FORMAT=<ID=TAR,Number=2,Type=Integer,Description=\"Reads strongly supporting alternate allele for tiers 1,2\">\n            ##FORMAT=<ID=TIR,Number=2,Type=Integer,Description=\"Reads strongly supporting indel allele for tiers 1,2\">\n            ##FORMAT=<ID=TOR,Number=2,Type=Integer,Description=\"Other reads (weak support or insufficient indel breakpoint overlap) for tiers 1,2\">\n            ##FORMAT=<ID=DP50,Number=1,Type=Float,Description=\"Average tier1 read depth within 50 bases\">\n            ##FORMAT=<ID=FDP50,Number=1,Type=Float,Description=\"Average tier1 number of basecalls filtered from original read depth within 50 bases\">\n            ##FORMAT=<ID=SUBDP50,Number=1,Type=Float,Description=\"Average number of reads below tier1 mapping quality threshold aligned across sites within 50 bases\">\n            ##FORMAT=<ID=BCN50,Number=1,Type=Float,Description=\"Fraction of filtered reads within 50 bases of the indel.\">\n            ##FILTER=<ID=LowEVS,Description=\"Somatic Empirical Variant Score (SomaticEVS) is below threshold\">\n            ##FILTER=<ID=LowDepth,Description=\"Tumor or normal sample read depth at this locus is below 2\">\n\n            reformat-vcf-table.py -c StrelkaSomaticIndel -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n            paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n            paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n            paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n            \"${reformat_tsv}\"\n\n            # make sure that the input and output tables have the same number of rows\n            if [ \"\\$(wc -l < \"${tsv_file}\" )\" -ne \"\\$( wc -l < \"${reformat_tsv}\" )\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n            \"\"\"\n        else\n            error \"Invalid Strelka callerType: ${callerType}\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 253,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    tsv_file = \"${prefix}.tsv\"\n    reformat_tsv = \"${prefix}.reformat.tsv\"\n    if( caller == 'MuTect2' )\n        \"\"\"\n        # convert VCF to TSV\n        # NOTE: automatically filters for only PASS entries\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM -F POS -F ID -F REF -F ALT -F FILTER -F QUAL -F AC -F AN -F NLOD -F TLOD \\\n        -GF AD -GF DP -GF AF \\\n        -o \"${tsv_file}\"\n\n        # .vcf field descriptions:\n        ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths for the ref and alt alleles in the order listed\">\n        ##FORMAT=<ID=AF,Number=1,Type=Float,Description=\"Allele fraction of the event in the tumor\">\n        ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth (reads with MQ=255 or with bad mates are filtered)\">\n        ##INFO=<ID=NLOD,Number=1,Type=String,Description=\"Normal LOD score\">\n        ##INFO=<ID=TLOD,Number=1,Type=String,Description=\"Tumor LOD score\">\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c MuTect2 -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${tumorID}\"  | \\\n        paste-col.py --header \"Tumor\" -v \"${tumorID}\"  | \\\n        paste-col.py --header \"Normal\" -v \"${normalID}\"  | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n\n        # make sure that the input and output tables have the same number of rows\n        if [ \"\\$(wc -l < \"${tsv_file}\" )\" -ne \"\\$( wc -l < \"${reformat_tsv}\" )\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n        \"\"\"\n    else if( caller == 'LoFreqSomatic' )\n        \"\"\"\n        # convert to tsv format\n        # NOTE: automatically filters for only PASS entries\n        gatk.sh -T VariantsToTable \\\n        -R \"${ref_fasta}\" \\\n        -V \"${vcf}\" \\\n        -F CHROM \\\n        -F POS \\\n        -F ID \\\n        -F REF \\\n        -F ALT \\\n        -F QUAL \\\n        -F FILTER \\\n        -F DP \\\n        -F DP4 \\\n        -F AF \\\n        -F SB \\\n        -F UQ \\\n        -F CONSVAR \\\n        -F AN \\\n        -F AC \\\n        -F HRUN \\\n        -F INDEL \\\n        -F UNIQ \\\n        -F SOMATIC \\\n        -o \"${tsv_file}\"\n\n        # .vcf field descriptions:\n        ##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Allele count in genotypes, for each ALT allele, in the same order as listed\">\n        ##INFO=<ID=AF,Number=A,Type=Float,Description=\"Allele Frequency, for each ALT allele, in the same order as listed\">\n        ##INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\">\n        ##INFO=<ID=CONSVAR,Number=0,Type=Flag,Description=\"Indicates that the variant is a consensus variant (as opposed to a low frequency variant).\">\n        ##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Approximate read depth; some reads may have been filtered\">\n        ##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Raw Depth\">\n        ##INFO=<ID=DP4,Number=4,Type=Integer,Description=\"Counts for ref-forward bases, ref-reverse, alt-forward and alt-reverse bases\">\n        ##INFO=<ID=HRUN,Number=1,Type=Integer,Description=\"Homopolymer length to the right of report indel position\">\n        ##INFO=<ID=INDEL,Number=0,Type=Flag,Description=\"Indicates that the variant is an INDEL.\">\n        ##INFO=<ID=SB,Number=1,Type=Float,Description=\"Strand Bias\">\n        ##INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic event\">\n        ##INFO=<ID=UNIQ,Number=0,Type=Flag,Description=\"Unique, i.e. not detectable in paired sample\">\n        ##INFO=<ID=UQ,Number=1,Type=Integer,Description=\"Phred-scaled uniq score at this position\">\n\n        # reformat and adjust the TSV table for consistency downstream\n        # add extra columns to the VCF TSV file for downstream\n        reformat-vcf-table.py -c LoFreq -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n        paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n        paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n        paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n        paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n        paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n        \"${reformat_tsv}\"\n\n        # make sure that the input and output tables have the same number of rows\n        if [ \"\\$(wc -l < \"${tsv_file}\" )\" -ne \"\\$( wc -l < \"${reformat_tsv}\" )\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n        \"\"\"\n    else if( caller == 'Strelka' )\n        if ( callerType == \"snvs\" )\n            \"\"\"\n            # convert to tsv format\n            # NOTE: automatically filters for only PASS entries\n            gatk.sh -T VariantsToTable \\\n            -R \"${ref_fasta}\" \\\n            -V \"${vcf}\" \\\n            -F CHROM \\\n            -F POS \\\n            -F ID \\\n            -F REF \\\n            -F ALT \\\n            -F FILTER \\\n            -F DP \\\n            -F SOMATIC \\\n            -F QSS \\\n            -F MQ \\\n            -F SNVSB \\\n            -F SomaticEVS \\\n            -GF DP \\\n            -GF AU \\\n            -GF TU \\\n            -GF CU \\\n            -GF GU \\\n            -o \"${tsv_file}\"\n\n            # vcf header example for Strelka SNVs\n            ##fileformat=VCFv4.1\n            ##FILTER=<ID=PASS,Description=\"All filters passed\">\n            ##source=strelka\n            ##source_version=2.9.10\n            ##content=strelka somatic snv calls\n            ##priorSomaticSnvRate=0.0001\n            ##INFO=<ID=QSS,Number=1,Type=Integer,Description=\"Quality score for any somatic snv, ie. for the ALT allele to be present at a significantly different frequency in the tumor and normal\">\n            ##INFO=<ID=TQSS,Number=1,Type=Integer,Description=\"Data tier used to compute QSS\">\n            ##INFO=<ID=NT,Number=1,Type=String,Description=\"Genotype of the normal in all data tiers, as used to classify somatic variants. One of {ref,het,hom,conflict}.\">\n            ##INFO=<ID=QSS_NT,Number=1,Type=Integer,Description=\"Quality score reflecting the joint probability of a somatic variant and NT\">\n            ##INFO=<ID=TQSS_NT,Number=1,Type=Integer,Description=\"Data tier used to compute QSS_NT\">\n            ##INFO=<ID=SGT,Number=1,Type=String,Description=\"Most likely somatic genotype excluding normal noise states\">\n            ##INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic mutation\">\n            ##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Combined depth across samples\">\n            ##INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">\n            ##INFO=<ID=MQ0,Number=1,Type=Integer,Description=\"Total Mapping Quality Zero Reads\">\n            ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=\"Z-score from Wilcoxon rank sum test of Alt Vs. Ref read-position in the tumor\">\n            ##INFO=<ID=SNVSB,Number=1,Type=Float,Description=\"Somatic SNV site strand bias\">\n            ##INFO=<ID=PNOISE,Number=1,Type=Float,Description=\"Fraction of panel containing non-reference noise at this site\">\n            ##INFO=<ID=PNOISE2,Number=1,Type=Float,Description=\"Fraction of panel containing more than one non-reference noise obs at this site\">\n            ##INFO=<ID=SomaticEVS,Number=1,Type=Float,Description=\"Somatic Empirical Variant Score (EVS) expressing the phred-scaled probability of the call being a false positive observation.\">\n            ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read depth for tier1 (used+filtered)\">\n            ##FORMAT=<ID=FDP,Number=1,Type=Integer,Description=\"Number of basecalls filtered from original read depth for tier1\">\n            ##FORMAT=<ID=SDP,Number=1,Type=Integer,Description=\"Number of reads with deletions spanning this site at tier1\">\n            ##FORMAT=<ID=SUBDP,Number=1,Type=Integer,Description=\"Number of reads below tier1 mapping quality threshold aligned across this site\">\n            ##FORMAT=<ID=AU,Number=2,Type=Integer,Description=\"Number of 'A' alleles used in tiers 1,2\">\n            ##FORMAT=<ID=CU,Number=2,Type=Integer,Description=\"Number of 'C' alleles used in tiers 1,2\">\n            ##FORMAT=<ID=GU,Number=2,Type=Integer,Description=\"Number of 'G' alleles used in tiers 1,2\">\n            ##FORMAT=<ID=TU,Number=2,Type=Integer,Description=\"Number of 'T' alleles used in tiers 1,2\">\n            ##FILTER=<ID=LowEVS,Description=\"Somatic Empirical Variant Score (SomaticEVS) is below threshold\">\n            ##FILTER=<ID=LowDepth,Description=\"Tumor or normal sample read depth at this locus is below 2\">\n\n            # reformat and adjust the TSV table for consistency downstream\n            # add extra columns to the VCF TSV file for downstream\n            reformat-vcf-table.py -c StrelkaSomaticSNV -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n            paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n            paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n            paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n            \"${reformat_tsv}\"\n\n            # make sure that the input and output tables have the same number of rows\n            tsv_lines=\"\\$(wc -l < \"${tsv_file}\" )\"\n            reformat_lines=\"\\$( wc -l < \"${reformat_tsv}\" )\"\n            if [ \"\\$tsv_lines\" -ne \"\\$reformat_lines\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n\n            vcf_lines=\"\\$(grep -v '^##' ${vcf} | wc -l)\"\n            if [ \"\\$vcf_lines\" -ne \"\\$reformat_lines\" ]; then echo \"ERROR: reformat table has different number of entries than vcf file!\"; exit 1; fi\n            \"\"\"\n        else if( callerType == 'indel' )\n            \"\"\"\n            # convert to tsv format\n            # NOTE: automatically filters for only PASS entries\n            gatk.sh -T VariantsToTable \\\n            -R \"${ref_fasta}\" \\\n            -V \"${vcf}\" \\\n            -F CHROM \\\n            -F POS \\\n            -F ID \\\n            -F REF \\\n            -F ALT \\\n            -F FILTER \\\n            -F SOMATIC \\\n            -F MQ \\\n            -F SomaticEVS \\\n            -F QSI \\\n            -GF DP \\\n            -GF TAR \\\n            -GF TIR \\\n            -GF TOR \\\n            -o \"${tsv_file}\"\n\n            # vcf header example for Strelka indels\n            ##fileformat=VCFv4.1\n            ##FILTER=<ID=PASS,Description=\"All filters passed\">\n            ##source=strelka\n            ##source_version=2.9.10\n            ##content=strelka somatic indel calls\n            ##priorSomaticIndelRate=1e-06\n            ##INFO=<ID=QSI,Number=1,Type=Integer,Description=\"Quality score for any somatic variant, ie. for the ALT haplotype to be present at a significantly different frequency in the tumor and normal\">\n            ##INFO=<ID=TQSI,Number=1,Type=Integer,Description=\"Data tier used to compute QSI\">\n            ##INFO=<ID=NT,Number=1,Type=String,Description=\"Genotype of the normal in all data tiers, as used to classify somatic variants. One of {ref,het,hom,conflict}.\">\n            ##INFO=<ID=QSI_NT,Number=1,Type=Integer,Description=\"Quality score reflecting the joint probability of a somatic variant and NT\">\n            ##INFO=<ID=TQSI_NT,Number=1,Type=Integer,Description=\"Data tier used to compute QSI_NT\">\n            ##INFO=<ID=SGT,Number=1,Type=String,Description=\"Most likely somatic genotype excluding normal noise states\">\n            ##INFO=<ID=RU,Number=1,Type=String,Description=\"Smallest repeating sequence unit in inserted or deleted sequence\">\n            ##INFO=<ID=RC,Number=1,Type=Integer,Description=\"Number of times RU repeats in the reference allele\">\n            ##INFO=<ID=IC,Number=1,Type=Integer,Description=\"Number of times RU repeats in the indel allele\">\n            ##INFO=<ID=IHP,Number=1,Type=Integer,Description=\"Largest reference interrupted homopolymer length intersecting with the indel\">\n            ##INFO=<ID=MQ,Number=1,Type=Float,Description=\"RMS Mapping Quality\">\n            ##INFO=<ID=MQ0,Number=1,Type=Integer,Description=\"Total Mapping Quality Zero Reads\">\n            ##INFO=<ID=SOMATIC,Number=0,Type=Flag,Description=\"Somatic mutation\">\n            ##INFO=<ID=OVERLAP,Number=0,Type=Flag,Description=\"Somatic indel possibly overlaps a second indel.\">\n            ##INFO=<ID=SomaticEVS,Number=1,Type=Float,Description=\"Somatic Empirical Variant Score (EVS) expressing the phred-scaled probability of the call being a false positive observation.\">\n            ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\"Read depth for tier1\">\n            ##FORMAT=<ID=DP2,Number=1,Type=Integer,Description=\"Read depth for tier2\">\n            ##FORMAT=<ID=TAR,Number=2,Type=Integer,Description=\"Reads strongly supporting alternate allele for tiers 1,2\">\n            ##FORMAT=<ID=TIR,Number=2,Type=Integer,Description=\"Reads strongly supporting indel allele for tiers 1,2\">\n            ##FORMAT=<ID=TOR,Number=2,Type=Integer,Description=\"Other reads (weak support or insufficient indel breakpoint overlap) for tiers 1,2\">\n            ##FORMAT=<ID=DP50,Number=1,Type=Float,Description=\"Average tier1 read depth within 50 bases\">\n            ##FORMAT=<ID=FDP50,Number=1,Type=Float,Description=\"Average tier1 number of basecalls filtered from original read depth within 50 bases\">\n            ##FORMAT=<ID=SUBDP50,Number=1,Type=Float,Description=\"Average number of reads below tier1 mapping quality threshold aligned across sites within 50 bases\">\n            ##FORMAT=<ID=BCN50,Number=1,Type=Float,Description=\"Fraction of filtered reads within 50 bases of the indel.\">\n            ##FILTER=<ID=LowEVS,Description=\"Somatic Empirical Variant Score (SomaticEVS) is below threshold\">\n            ##FILTER=<ID=LowDepth,Description=\"Tumor or normal sample read depth at this locus is below 2\">\n\n            reformat-vcf-table.py -c StrelkaSomaticIndel -s \"${tumorID}\" -i \"${tsv_file}\" | \\\n            paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n            paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n            paste-col.py --header \"VariantCallerType\" -v \"${callerType}\"  | \\\n            paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \\\n            \"${reformat_tsv}\"\n\n            # make sure that the input and output tables have the same number of rows\n            if [ \"\\$(wc -l < \"${tsv_file}\" )\" -ne \"\\$( wc -l < \"${reformat_tsv}\" )\" ]; then echo \"ERROR: reformat table has different number of rows!\"; exit 1; fi\n            \"\"\"\n        else\n            error \"Invalid Strelka callerType: ${callerType}\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 239,
        "language_script": "bash",
        "tools": [
            "SomeNA"
        ],
        "tools_url": [
            "https://bio.tools/somena"
        ],
        "tools_dico": [
            {
                "name": "SomeNA",
                "uri": "https://bio.tools/somena",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_1775",
                            "term": "Function analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_1775",
                            "term": "Functional analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Protein DNA/RNA binding predictor.",
                "homepage": "https://github.com/Rostlab/someNA"
            }
        ],
        "inputs": [
            "filtered_vcf_pairs",
            "ref_fasta18",
            "ref_fai18",
            "ref_dict18"
        ],
        "nb_inputs": 4,
        "outputs": [
            "vcf_tsv_pairs",
            "vcf_tsv_pairs2"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${chunkLabel}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${tsv_file}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/tsv\", mode: 'copy', pattern: \"*${reformat_tsv}\""
        ],
        "when": "",
        "stub": ""
    },
    "eval_pair_vcf": {
        "name_process": "eval_pair_vcf",
        "string_process": "\nprocess eval_pair_vcf {\n                              \n    tag \"${caller}.${chunkLabel}\"\n    publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${eval_file}\"\n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(pairs_vcf), file(dbsnp_ref_vcf), file(dbsnp_ref_vcf_idx), file(ref_fasta), file(ref_fai), file(ref_dict4) from pairs_filtered_vcfs\n\n    output:\n    file(\"${eval_file}\")\n    val(\"${comparisonID}\") into done_eval_pair_vcf\n\n    when:\n    disable_eval_pair_vcf != true\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    eval_file = \"${prefix}.eval.grp\"\n    \"\"\"\n    gatk.sh -T VariantEval \\\n    -R \"${ref_fasta}\" \\\n    -o \"${eval_file}\" \\\n    --dbsnp \"${dbsnp_ref_vcf}\" \\\n    --eval \"${pairs_vcf}\"\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    eval_file = \"${prefix}.eval.grp\"\n    \"\"\"\n    gatk.sh -T VariantEval \\\n    -R \"${ref_fasta}\" \\\n    -o \"${eval_file}\" \\\n    --dbsnp \"${dbsnp_ref_vcf}\" \\\n    --eval \"${pairs_vcf}\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pairs_filtered_vcfs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "done_eval_pair_vcf"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${chunkLabel}\"",
            "publishDir \"${params.outputDir}/variants/${caller}/stats\", mode: 'copy', pattern: \"*${eval_file}\""
        ],
        "when": "disable_eval_pair_vcf != true",
        "stub": ""
    },
    "annotate": {
        "name_process": "annotate",
        "string_process": "\nprocess annotate {\n                        \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/annotations/${caller}\", mode: 'copy', pattern: \"*${annotations_tsv}\"\n\n    input:\n    set val(caller), val(type), val(sampleID), file(sample_vcf), file(sample_tsv), file(annovar_db_dir) from samples_vcfs_tsvs_good.combine(annovar_db_dir)\n\n    output:\n    file(\"${annotations_tsv}\") into annotations_tables\n    set val(sampleID), val(caller), val(type), file(\"${annotations_tsv}\") into annotations_annovar_tables\n    set val(caller), val(type), val(sampleID), file(\"${annotations_tsv}\") into (annotations_annovar_tables2, annotations_annovar_tables3, annotations_annovar_tables4, annotations_annovar_tables5)\n    file(\"${avinput_file}\")\n    file(\"${avinput_tsv}\")\n    val(sampleID) into done_annotate\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    avinput_file = \"${prefix}.avinput\"\n    avinput_tsv = \"${prefix}.avinput.tsv\"\n    annovar_output_txt = \"${prefix}.${params.ANNOVAR_BUILD_VERSION}_multianno.txt\"\n    annovar_output_vcf = \"${prefix}.${params.ANNOVAR_BUILD_VERSION}_multianno.vcf\"\n    annotations_tsv = \"${prefix}.annotations.tsv\"\n    if( caller == 'HaplotypeCaller' )\n        \"\"\"\n        # convert to ANNOVAR format\n        convert2annovar.pl \\\n        -includeinfo \\\n        -format vcf4 \\\n        \"${sample_vcf}\" > \\\n        \"${avinput_file}\"\n\n        # annovate\n        table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --outfile \"${prefix}\"\n\n        # add headers to the avinput, just the first columns\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-10 \"${avinput_file}\" >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == 'LoFreq' )\n        \"\"\"\n        # convert to ANNOVAR format\n        convert2annovar.pl \\\n        -includeinfo \\\n        -format vcf4 \\\n        \"${sample_vcf}\" > \\\n        \"${avinput_file}\"\n\n        table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --outfile \"${prefix}\"\n\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-10 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == 'VarScan2' )\n        \"\"\"\n        # convert to ANNOVAR format\n        convert2annovar.pl \\\n        -includeinfo \\\n        -format vcf4 \\\n        \"${sample_vcf}\" > \\\n        \"${avinput_file}\"\n\n        table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --outfile \"${prefix}\"\n\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-10 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 94,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    avinput_file = \"${prefix}.avinput\"\n    avinput_tsv = \"${prefix}.avinput.tsv\"\n    annovar_output_txt = \"${prefix}.${params.ANNOVAR_BUILD_VERSION}_multianno.txt\"\n    annovar_output_vcf = \"${prefix}.${params.ANNOVAR_BUILD_VERSION}_multianno.vcf\"\n    annotations_tsv = \"${prefix}.annotations.tsv\"\n    if( caller == 'HaplotypeCaller' )\n        \"\"\"\n        # convert to ANNOVAR format\n        convert2annovar.pl \\\n        -includeinfo \\\n        -format vcf4 \\\n        \"${sample_vcf}\" > \\\n        \"${avinput_file}\"\n\n        # annovate\n        table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --outfile \"${prefix}\"\n\n        # add headers to the avinput, just the first columns\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-10 \"${avinput_file}\" >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == 'LoFreq' )\n        \"\"\"\n        # convert to ANNOVAR format\n        convert2annovar.pl \\\n        -includeinfo \\\n        -format vcf4 \\\n        \"${sample_vcf}\" > \\\n        \"${avinput_file}\"\n\n        table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --outfile \"${prefix}\"\n\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-10 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == 'VarScan2' )\n        \"\"\"\n        # convert to ANNOVAR format\n        convert2annovar.pl \\\n        -includeinfo \\\n        -format vcf4 \\\n        \"${sample_vcf}\" > \\\n        \"${avinput_file}\"\n\n        table_annovar.pl \"${avinput_file}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --outfile \"${prefix}\"\n\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-10 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 76,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_vcfs_tsvs_good",
            "annovar_db_dir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "annotations_tables",
            "annotations_annovar_tables",
            "",
            "done_annotate"
        ],
        "nb_outputs": 4,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/annotations/${caller}\", mode: 'copy', pattern: \"*${annotations_tsv}\""
        ],
        "when": "",
        "stub": ""
    },
    "annotate_pairs": {
        "name_process": "annotate_pairs",
        "string_process": "\nprocess annotate_pairs {\n                        \n    tag \"${caller}.${chunkLabel}\"\n    publishDir \"${params.outputDir}/annotations/${caller}\", mode: 'copy', pattern: \"*${annotations_tsv}\"\n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(sample_vcf), file(sample_tsv), file(annovar_db_dir) from pairs_vcfs_tsvs_good.combine(annovar_db_dir2)\n\n    output:\n    file(\"${annotations_tsv}\") into annotations_tables_pairs\n    val(comparisonID) into done_annotate_pairs\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    avinput_file = \"${prefix}.avinput\"\n    avinput_tsv = \"${prefix}.avinput.tsv\"\n    annovar_output_txt = \"${prefix}.${params.ANNOVAR_BUILD_VERSION}_multianno.txt\"\n    annotations_tsv = \"${prefix}.annotations.tsv\"\n    vcf_gt_mod = \"${sample_vcf}.GTmod.vcf\"                         \n    if( caller == 'MuTect2' )\n        \"\"\"\n        # annotate .vcf\n        table_annovar.pl \"${sample_vcf}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --vcfinput \\\n        --outfile \"${prefix}\"\n\n        # get values from .avinput file\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-5,9-13 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == \"LoFreqSomatic\" )\n        \"\"\"\n        # annotate .vcf\n        table_annovar.pl \"${sample_vcf}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --vcfinput \\\n        --outfile \"${prefix}\"\n\n        # get values from .avinput file\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-5,9-13 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == \"Strelka\" )\n        \"\"\"\n        # need to add the GT field to Strelka .vcf files\n        vcf-GT-mod.py \"${sample_vcf}\" \"${vcf_gt_mod}\"\n\n        # annotate .vcf\n        table_annovar.pl \"${vcf_gt_mod}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --vcfinput \\\n        --outfile \"${prefix}\"\n\n        # get values from .avinput file\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-5,9-13 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 81,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    avinput_file = \"${prefix}.avinput\"\n    avinput_tsv = \"${prefix}.avinput.tsv\"\n    annovar_output_txt = \"${prefix}.${params.ANNOVAR_BUILD_VERSION}_multianno.txt\"\n    annotations_tsv = \"${prefix}.annotations.tsv\"\n    vcf_gt_mod = \"${sample_vcf}.GTmod.vcf\"                         \n    if( caller == 'MuTect2' )\n        \"\"\"\n        # annotate .vcf\n        table_annovar.pl \"${sample_vcf}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --vcfinput \\\n        --outfile \"${prefix}\"\n\n        # get values from .avinput file\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-5,9-13 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == \"LoFreqSomatic\" )\n        \"\"\"\n        # annotate .vcf\n        table_annovar.pl \"${sample_vcf}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --vcfinput \\\n        --outfile \"${prefix}\"\n\n        # get values from .avinput file\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-5,9-13 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else if( caller == \"Strelka\" )\n        \"\"\"\n        # need to add the GT field to Strelka .vcf files\n        vcf-GT-mod.py \"${sample_vcf}\" \"${vcf_gt_mod}\"\n\n        # annotate .vcf\n        table_annovar.pl \"${vcf_gt_mod}\" \"${annovar_db_dir}\" \\\n        --buildver \"${params.ANNOVAR_BUILD_VERSION}\" \\\n        --remove \\\n        --protocol \"${params.ANNOVAR_PROTOCOL}\" \\\n        --operation \"${params.ANNOVAR_OPERATION}\" \\\n        --nastring . \\\n        --vcfinput \\\n        --outfile \"${prefix}\"\n\n        # get values from .avinput file\n        printf \"Chr\\tStart\\tEnd\\tRef\\tAlt\\tCHROM\\tPOS\\tID\\tREF\\tALT\\n\" > \"${avinput_tsv}\"\n        cut -f1-5,9-13 ${avinput_file} >>  \"${avinput_tsv}\"\n\n        # merge the tables together\n        merge-vcf-tables.R \"${sample_tsv}\" \"${annovar_output_txt}\" \"${avinput_tsv}\" \"${annotations_tsv}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 67,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pairs_vcfs_tsvs_good",
            "annovar_db_dir2"
        ],
        "nb_inputs": 2,
        "outputs": [
            "annotations_tables_pairs",
            "done_annotate_pairs"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${chunkLabel}\"",
            "publishDir \"${params.outputDir}/annotations/${caller}\", mode: 'copy', pattern: \"*${annotations_tsv}\""
        ],
        "when": "",
        "stub": ""
    },
    "collect_annotation_tables": {
        "name_process": "collect_annotation_tables",
        "string_process": "\nprocess collect_annotation_tables {\n                                               \n\n    input:\n    file('t*') from annotations_tables.concat(annotations_tables_pairs).collect()\n\n    output:\n    file(\"${output_file}\") into collected_annotation_tables\n    val('') into done_collect_annotation_tables\n\n    script:\n    output_file = \"all_annotations.tmp.tsv\"\n    \"\"\"\n    concat-tables.py t* > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    output_file = \"all_annotations.tmp.tsv\"\n    \"\"\"\n    concat-tables.py t* > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotations_tables",
            "annotations_tables_pairs"
        ],
        "nb_inputs": 2,
        "outputs": [
            "collected_annotation_tables",
            "done_collect_annotation_tables"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "filter_annotation_table": {
        "name_process": "filter_annotation_table",
        "string_process": "\nprocess filter_annotation_table {\n                                                                                               \n    input:\n    file(tsv) from collected_annotation_tables\n\n    output:\n    file(\"${output_file}\") into filtered_annotation_table\n\n    script:\n    output_file = \"annotations.filtered.tsv\"\n    \"\"\"\n    filter-annotation-table.py -i \"${tsv}\" -o \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    output_file = \"annotations.filtered.tsv\"\n    \"\"\"\n    filter-annotation-table.py -i \"${tsv}\" -o \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collected_annotation_tables"
        ],
        "nb_inputs": 1,
        "outputs": [
            "filtered_annotation_table"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "update_collect_annotation_tables": {
        "name_process": "update_collect_annotation_tables",
        "string_process": "\nprocess update_collect_annotation_tables {\n                                                  \n                                                     \n\n    input:\n    file(table) from filtered_annotation_table\n\n    output:\n    file(\"${output_file}\") into (all_annotations_file_ch, all_annotations_file_ch2, all_annotations_file_ch3, all_annotations_file_ch4)\n    val('') into done_update_collect_annotation_tables\n\n    script:\n    output_file = \"${all_annotations_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    output_file = \"${all_annotations_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filtered_annotation_table"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "done_update_collect_annotation_tables"
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "split_annotation_table_caller": {
        "name_process": "split_annotation_table_caller",
        "string_process": "\nprocess split_annotation_table_caller {\n                                                                      \n    publishDir \"${params.outputDir}/annotations\", mode: 'copy'\n\n    input:\n    file(\".annotations.tsv\") from all_annotations_file_ch2\n\n    output:\n    file(\"*\")\n\n    script:\n    \"\"\"\n    split-annotation-table-callers.py \".annotations.tsv\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    split-annotation-table-callers.py \".annotations.tsv\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_annotations_file_ch2"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/annotations\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "extract_hapmap_pool_annotations": {
        "name_process": "extract_hapmap_pool_annotations",
        "string_process": "\nprocess extract_hapmap_pool_annotations {\n                                                                                  \n    publishDir \"${params.outputDir}/annotations\", mode: 'copy'\n\n    input:\n    file(tsv) from all_annotations_file_ch3\n\n    output:\n    file(\"${output_file}\") into hapmap_pool_annotations\n\n    script:\n    output_file = \"${all_HapMapPool_annotations_file}\"\n    \"\"\"\n    head -1 \"${tsv}\" > \"${output_file}\"\n    grep -i 'HapMap-Pool' \"${tsv}\" >> \"${output_file}\" || :\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    output_file = \"${all_HapMapPool_annotations_file}\"\n    \"\"\"\n    head -1 \"${tsv}\" > \"${output_file}\"\n    grep -i 'HapMap-Pool' \"${tsv}\" >> \"${output_file}\" || :\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_annotations_file_ch3"
        ],
        "nb_inputs": 1,
        "outputs": [
            "hapmap_pool_annotations"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/annotations\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "split_annotation_table_paired": {
        "name_process": "split_annotation_table_paired",
        "string_process": "\nprocess split_annotation_table_paired {\n                                                      \n                               \n                                                                     \n                                                                  \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(\"annotations.tsv\") from all_annotations_file_ch4\n\n    output:\n    file(\"${output_paired}\") into anno_tab_by_caller\n    file(\"${output_unpaired}\")\n\n    script:\n    output_paired = \"annotations.paired.tsv\"\n    output_unpaired = \"annotations.unpaired.tsv\"\n    \"\"\"\n    split-annotation-table-pairs.py \"annotations.tsv\" \"${output_paired}.tmp\" \"${output_unpaired}.tmp\"\n\n    annotation-table-drop-cols.py -i \"${output_paired}.tmp\" -o \"${output_paired}\" --type paired\n    annotation-table-drop-cols.py -i \"${output_unpaired}.tmp\" -o \"${output_unpaired}\" --type unpaired\n\n    # make sure that the output table number of records matches the input\n    num_original_annotations=\"\\$(( \\$(wc -l < annotations.tsv) -1 ))\"\n    num_paired_annotations=\"\\$(( \\$(wc -l < \"${output_paired}\") -1 ))\"\n    num_unpaired_annotations=\"\\$(( \\$(wc -l < \"${output_unpaired}\") -1 ))\"\n    num_total_annotations=\"\\$(( \\$num_paired_annotations + \\$num_unpaired_annotations ))\"\n    if [ \\$num_total_annotations -ne \\$num_original_annotations ]; then echo \"ERROR: annotation table has different number of rows!\"; exit 1; fi\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    output_paired = \"annotations.paired.tsv\"\n    output_unpaired = \"annotations.unpaired.tsv\"\n    \"\"\"\n    split-annotation-table-pairs.py \"annotations.tsv\" \"${output_paired}.tmp\" \"${output_unpaired}.tmp\"\n\n    annotation-table-drop-cols.py -i \"${output_paired}.tmp\" -o \"${output_paired}\" --type paired\n    annotation-table-drop-cols.py -i \"${output_unpaired}.tmp\" -o \"${output_unpaired}\" --type unpaired\n\n    # make sure that the output table number of records matches the input\n    num_original_annotations=\"\\$(( \\$(wc -l < annotations.tsv) -1 ))\"\n    num_paired_annotations=\"\\$(( \\$(wc -l < \"${output_paired}\") -1 ))\"\n    num_unpaired_annotations=\"\\$(( \\$(wc -l < \"${output_unpaired}\") -1 ))\"\n    num_total_annotations=\"\\$(( \\$num_paired_annotations + \\$num_unpaired_annotations ))\"\n    if [ \\$num_total_annotations -ne \\$num_original_annotations ]; then echo \"ERROR: annotation table has different number of rows!\"; exit 1; fi\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "all_annotations_file_ch4"
        ],
        "nb_inputs": 1,
        "outputs": [
            "anno_tab_by_caller"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "gatk_CallableLoci": {
        "name_process": "gatk_CallableLoci",
        "string_process": "\nprocess gatk_CallableLoci {\n    publishDir \"${params.outputDir}/loci\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(bamfile), file(baifile), file(genomeFa), file(genomeFai), file(genomeDict), file(targets_bed) from samples_bam_ref\n\n    output:\n    set val(\"${sampleID}\"), file(\"${output_summary}\") into called_loci\n    file(\"${output_summary}\")\n    file(\"${output_bed}\")\n    file(\"${output_bed_pass}\")\n\n    script:\n    prefix = \"${sampleID}\"\n    output_summary = \"${prefix}.CallableLoci.summary.txt\"\n    output_bed = \"${prefix}.CallableLoci.bed\"\n    output_bed_pass = \"${prefix}.CallableLoci.pass.bed\"\n    \"\"\"\n    # minDepth 500 = NGS580 call threshold\n    # minMappingQuality, minBaseQuality 20 = NGS580 DepthOfCoverage threshold\n    gatk.sh \\\n    -T CallableLoci \\\n    -R \"${genomeFa}\" \\\n    -I \"${bamfile}\" \\\n    -summary \"${output_summary}\" \\\n    --minMappingQuality 20 \\\n    --minBaseQuality 20 \\\n    --minDepth 500 \\\n    --intervals \"${targets_bed}\" \\\n    -o \"${output_bed}\"\n\n    grep -E 'CALLABLE|PASS' \"${output_bed}\" > \"${output_bed_pass}\" || touch \"${output_bed_pass}\" # exit code 1 if no matches\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    prefix = \"${sampleID}\"\n    output_summary = \"${prefix}.CallableLoci.summary.txt\"\n    output_bed = \"${prefix}.CallableLoci.bed\"\n    output_bed_pass = \"${prefix}.CallableLoci.pass.bed\"\n    \"\"\"\n    # minDepth 500 = NGS580 call threshold\n    # minMappingQuality, minBaseQuality 20 = NGS580 DepthOfCoverage threshold\n    gatk.sh \\\n    -T CallableLoci \\\n    -R \"${genomeFa}\" \\\n    -I \"${bamfile}\" \\\n    -summary \"${output_summary}\" \\\n    --minMappingQuality 20 \\\n    --minBaseQuality 20 \\\n    --minDepth 500 \\\n    --intervals \"${targets_bed}\" \\\n    -o \"${output_bed}\"\n\n    grep -E 'CALLABLE|PASS' \"${output_bed}\" > \"${output_bed_pass}\" || touch \"${output_bed_pass}\" # exit code 1 if no matches\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "PASS"
        ],
        "tools_url": [
            "https://bio.tools/pass"
        ],
        "tools_dico": [
            {
                "name": "PASS",
                "uri": "https://bio.tools/pass",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "PASS: a program to align short sequences",
                "homepage": "http://pass.cribi.unipd.it/cgi-bin/pass.pl"
            }
        ],
        "inputs": [
            "samples_bam_ref"
        ],
        "nb_inputs": 1,
        "outputs": [
            "called_loci"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/loci\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "callable_loci_table": {
        "name_process": "callable_loci_table",
        "string_process": "\nprocess callable_loci_table {\n    publishDir \"${params.outputDir}/loci\", mode: 'copy'\n\n    input:\n    set val(sampleID), file(summary) from called_loci\n\n    output:\n    file(\"${output_summary}\") into loci_tables\n    set val(sampleID), file(\"${output_summary}\"), file(\"${output_txt}\") into loci_tables2\n    set file(\"${loci_output_txt}\") into callable_locations\n\n    script:\n    prefix = \"${sampleID}\"\n    output_summary = \"${prefix}.CallableLoci.summary.tsv\"\n    output_txt = \"${prefix}.CallableLoci.txt\"\n    loci_output_txt = \"${prefix}.callable_loci.out\"\n    tmpFile = \"tmp\"\n    \"\"\"\n    callable-loci-table.py \"${summary}\" \"${tmpFile}\"\n    paste-col.py -i \"${tmpFile}\" --header \"Sample\" -v \"${sampleID}\" > \"${output_summary}\"\n    grep 'CALLABLE' \"${tmpFile}\" | cut -f2 > \"${output_txt}\"\n    grep 'CALLABLE' \"${output_summary}\" | cut -f2,3 > \"${loci_output_txt}\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    prefix = \"${sampleID}\"\n    output_summary = \"${prefix}.CallableLoci.summary.tsv\"\n    output_txt = \"${prefix}.CallableLoci.txt\"\n    loci_output_txt = \"${prefix}.callable_loci.out\"\n    tmpFile = \"tmp\"\n    \"\"\"\n    callable-loci-table.py \"${summary}\" \"${tmpFile}\"\n    paste-col.py -i \"${tmpFile}\" --header \"Sample\" -v \"${sampleID}\" > \"${output_summary}\"\n    grep 'CALLABLE' \"${tmpFile}\" | cut -f2 > \"${output_txt}\"\n    grep 'CALLABLE' \"${output_summary}\" | cut -f2,3 > \"${loci_output_txt}\"\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "called_loci"
        ],
        "nb_inputs": 1,
        "outputs": [
            "loci_tables",
            "loci_tables2",
            "callable_locations"
        ],
        "nb_outputs": 3,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/loci\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "caller_variants_tmb": {
        "name_process": "caller_variants_tmb",
        "string_process": "\nprocess caller_variants_tmb {\n    publishDir \"${params.outputDir}/\", mode: 'copy'\n\n    input:\n    set file(anno_tsv) from anno_tab_by_caller\n    set file(sample_loci) from sample_loci_collected\n    set file(sample_sheet) from demux_sample_sheet\n\n    output:\n    file(\"${tmb_tsv}\")\n\n    script:\n                             \n    tmb_tsv = \"annotations.paired.tmb.tsv\"\n    \"\"\"\n    calculate_TMB.py -l \"${sample_loci}\" -i \"${anno_tsv}\" -o \"${tmb_tsv}\" -s \"${sample_sheet}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    tmb_tsv = \"annotations.paired.tmb.tsv\"\n    \"\"\"\n    calculate_TMB.py -l \"${sample_loci}\" -i \"${anno_tsv}\" -o \"${tmb_tsv}\" -s \"${sample_sheet}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "anno_tab_by_caller",
            "sample_loci_collected",
            "demux_sample_sheet"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "tmb_filter_variants": {
        "name_process": "tmb_filter_variants",
        "string_process": "\nprocess tmb_filter_variants {\n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/tmb/${caller}/annotations\", mode: 'copy', pattern: \"*${output_variants}\"\n\n    input:\n    set val(sampleID), val(caller), val(type), file(anno_tsv) from annotations_annovar_tables_filtered\n\n    output:\n    set val(sampleID), val(caller), val(type), file(\"${output_variants}\") into tmb_filtered_variants2\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    output_variants = \"${prefix}.annotations.tmb.filtered.tsv\"\n    \"\"\"\n    tmb-variant-filter.py -c \"${caller}\" -i \"${anno_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${sampleID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${output_variants}\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    output_variants = \"${prefix}.annotations.tmb.filtered.tsv\"\n    \"\"\"\n    tmb-variant-filter.py -c \"${caller}\" -i \"${anno_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${sampleID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${output_variants}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotations_annovar_tables_filtered"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tmb_filtered_variants2"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/tmb/${caller}/annotations\", mode: 'copy', pattern: \"*${output_variants}\""
        ],
        "when": "",
        "stub": ""
    },
    "calculate_tmb": {
        "name_process": "calculate_tmb",
        "string_process": "\nprocess calculate_tmb {\n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/tmb/${caller}/values\", mode: 'copy', pattern: \"*${output_tmb}\"\n\n    input:\n    set val(sampleID), val(caller), val(type), val(loci), val(variants) from loci_annotations\n\n    output:\n    file(\"${output_tmb}\") into tmbs\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    output_tmb = \"${prefix}.tmb.tsv\"\n    \"\"\"\n    tmb=\\$( calc-tmb.py ${variants} ${loci} )\n    printf 'SampleID\\tVariantCaller\\tVariantCallerType\\tnBases\\tnVariants\\tTMB\\n' > \"${output_tmb}\"\n    printf \"${sampleID}\\t${caller}\\t${type}\\t${loci}\\t${variants}\\t\\${tmb}\\n\" >> \"${output_tmb}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    output_tmb = \"${prefix}.tmb.tsv\"\n    \"\"\"\n    tmb=\\$( calc-tmb.py ${variants} ${loci} )\n    printf 'SampleID\\tVariantCaller\\tVariantCallerType\\tnBases\\tnVariants\\tTMB\\n' > \"${output_tmb}\"\n    printf \"${sampleID}\\t${caller}\\t${type}\\t${loci}\\t${variants}\\t\\${tmb}\\n\" >> \"${output_tmb}\"\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "loci_annotations"
        ],
        "nb_inputs": 1,
        "outputs": [
            "tmbs"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/tmb/${caller}/values\", mode: 'copy', pattern: \"*${output_tmb}\""
        ],
        "when": "",
        "stub": ""
    },
    "signatures_variant_filter": {
        "name_process": "signatures_variant_filter",
        "string_process": "\nprocess signatures_variant_filter {\n                                                                                                        \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/signatures/${caller}/annotations\", mode: 'copy', pattern: \"*${output_file}\"\n\n    input:\n    set val(caller), val(type), val(sampleID), file(tsv) from annotations_annovar_tables2\n\n    output:\n    set val(caller), val(type), val(sampleID), file(\"${output_file}\") into filtered_signatures_tsvs\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    output_file = \"${prefix}.filtered.tsv\"\n    if ( caller == \"VarScan2\" )\n        \"\"\"\n        signatures-variant-filter.py -c VarScan2 -i \"${tsv}\" -o \"${output_file}\"\n        \"\"\"\n    else if ( caller == \"HaplotypeCaller\" )\n        \"\"\"\n        signatures-variant-filter.py -c HaplotypeCaller -i \"${tsv}\" -o \"${output_file}\"\n        \"\"\"\n    else if ( caller == \"LoFreq\" )\n        \"\"\"\n        signatures-variant-filter.py -c LoFreq -i \"${tsv}\" -o \"${output_file}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    output_file = \"${prefix}.filtered.tsv\"\n    if ( caller == \"VarScan2\" )\n        \"\"\"\n        signatures-variant-filter.py -c VarScan2 -i \"${tsv}\" -o \"${output_file}\"\n        \"\"\"\n    else if ( caller == \"HaplotypeCaller\" )\n        \"\"\"\n        signatures-variant-filter.py -c HaplotypeCaller -i \"${tsv}\" -o \"${output_file}\"\n        \"\"\"\n    else if ( caller == \"LoFreq\" )\n        \"\"\"\n        signatures-variant-filter.py -c LoFreq -i \"${tsv}\" -o \"${output_file}\"\n        \"\"\"\n    else\n        error \"Invalid caller: ${caller}\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotations_annovar_tables2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "filtered_signatures_tsvs"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/signatures/${caller}/annotations\", mode: 'copy', pattern: \"*${output_file}\""
        ],
        "when": "",
        "stub": ""
    },
    "deconstructSigs_signatures": {
        "name_process": "deconstructSigs_signatures",
        "string_process": "\nprocess deconstructSigs_signatures {\n                                     \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/signatures/${caller}/Rds\", mode: 'copy', pattern: \"*.Rds\"\n    publishDir \"${params.outputDir}/signatures/${caller}/pdf\", mode: 'copy', pattern: \"*.pdf\"\n\n    input:\n    set val(caller), val(type), val(sampleID), file(sample_vcf) from sample_sig_good_filtered\n\n    output:\n    file(\"${signatures_rds}\")\n    file(\"${signatures_plot_Rds}\")\n    file(\"${signatures_pieplot_Rds}\")\n    file(\"${signatures_plot_pdf}\") into signatures_plots\n    file(\"${signatures_pieplot_pdf}\") into signatures_pie_plots\n    set val(\"${caller}\"), val(\"${type}\"), file(\"${signatures_plot_pdf}\") into signatures_plots_caller\n    set val(\"${caller}\"), val(\"${type}\"), file(\"${signatures_pieplot_pdf}\") into signatures_pieplots_caller\n    set val(caller), val(type), val(sampleID), file(\"${signatures_weights_tsv}\") into signatures_weights\n    set val(sampleID), file(\"${signatures_rds}\"), file(\"${signatures_plot_Rds}\"), file(\"${signatures_pieplot_Rds}\") into sample_signatures\n    val(sampleID) into done_deconstructSigs_signatures\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    signatures_weights_tsv = \"${prefix}.signatures.weights.tmp\"\n    signatures_rds = \"${prefix}.${filemap['deconstructSigs']['suffix']['signatures_Rds']}\"\n    signatures_plot_pdf = \"${prefix}.signatures.plot.pdf\"\n    signatures_plot_Rds = \"${prefix}.${filemap['deconstructSigs']['suffix']['signatures_plot_Rds']}\"\n    signatures_pieplot_pdf = \"${prefix}.signatures.pieplot.pdf\"\n    signatures_pieplot_Rds = \"${prefix}.${filemap['deconstructSigs']['suffix']['signatures_pieplot_Rds']}\"\n    \"\"\"\n    deconstructSigs_make_signatures.R \\\n    \"${sampleID}\" \\\n    \"${sample_vcf}\" \\\n    \"${signatures_rds}\" \\\n    \"${signatures_plot_pdf}\" \\\n    \"${signatures_plot_Rds}\" \\\n    \"${signatures_pieplot_pdf}\" \\\n    \"${signatures_pieplot_Rds}\" \\\n    \"${signatures_weights_tsv}\"\n    \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    signatures_weights_tsv = \"${prefix}.signatures.weights.tmp\"\n    signatures_rds = \"${prefix}.${filemap['deconstructSigs']['suffix']['signatures_Rds']}\"\n    signatures_plot_pdf = \"${prefix}.signatures.plot.pdf\"\n    signatures_plot_Rds = \"${prefix}.${filemap['deconstructSigs']['suffix']['signatures_plot_Rds']}\"\n    signatures_pieplot_pdf = \"${prefix}.signatures.pieplot.pdf\"\n    signatures_pieplot_Rds = \"${prefix}.${filemap['deconstructSigs']['suffix']['signatures_pieplot_Rds']}\"\n    \"\"\"\n    deconstructSigs_make_signatures.R \\\n    \"${sampleID}\" \\\n    \"${sample_vcf}\" \\\n    \"${signatures_rds}\" \\\n    \"${signatures_plot_pdf}\" \\\n    \"${signatures_plot_Rds}\" \\\n    \"${signatures_pieplot_pdf}\" \\\n    \"${signatures_pieplot_Rds}\" \\\n    \"${signatures_weights_tsv}\"\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_sig_good_filtered"
        ],
        "nb_inputs": 1,
        "outputs": [
            "signatures_plots",
            "signatures_pie_plots",
            "signatures_plots_caller",
            "signatures_pieplots_caller",
            "signatures_weights",
            "sample_signatures",
            "done_deconstructSigs_signatures"
        ],
        "nb_outputs": 7,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/signatures/${caller}/Rds\", mode: 'copy', pattern: \"*.Rds\"",
            "publishDir \"${params.outputDir}/signatures/${caller}/pdf\", mode: 'copy', pattern: \"*.pdf\""
        ],
        "when": "",
        "stub": ""
    },
    "update_signatures_weights": {
        "name_process": "update_signatures_weights",
        "string_process": "\nprocess update_signatures_weights {\n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/signatures/${caller}/weights\", mode: 'copy'\n\n    input:\n    set val(caller), val(type), val(sampleID), file(weights_tsv) from signatures_weights\n\n    output:\n    file(\"${output_tsv}\") into updated_signatures_weights\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    output_tsv = \"${prefix}.signatures.weights.tsv\"\n    \"\"\"\n    cat \"${weights_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${sampleID}\"  | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${output_tsv}\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    output_tsv = \"${prefix}.signatures.weights.tsv\"\n    \"\"\"\n    cat \"${weights_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${sampleID}\"  | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\"  | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${output_tsv}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "signatures_weights"
        ],
        "nb_inputs": 1,
        "outputs": [
            "updated_signatures_weights"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/signatures/${caller}/weights\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_update_signatures_weights_collected": {
        "name_process": "update_update_signatures_weights_collected",
        "string_process": "\nprocess update_update_signatures_weights_collected {\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from updated_signatures_weights_collected\n\n    output:\n    file(\"${output_file}\") into all_signatures_weights\n\n    script:\n    output_file = \"${signatures_weights_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    output_file = \"${signatures_weights_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "updated_signatures_weights_collected"
        ],
        "nb_inputs": 1,
        "outputs": [
            "all_signatures_weights"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "merge_signatures_plots": {
        "name_process": "merge_signatures_plots",
        "string_process": "\nprocess merge_signatures_plots {\n                                                     \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/signatures\", mode: 'copy'\n\n    input:\n    set val(caller), val(type), file(input_files:'*') from signatures_plots_caller_grouped\n                                                           \n\n    output:\n    file(\"${output_file}\")\n    val(\"${output_file}\") into done_merge_signatures_plots\n\n    when:\n    input_files.size() > 0\n\n    script:\n    prefix = \"${caller}.${type}\"\n    output_file=\"signatures.${prefix}.pdf\"\n    \"\"\"\n    gs -dBATCH -dNOPAUSE -q -dAutoRotatePages=/None -sDEVICE=pdfwrite -sOutputFile=\"${output_file}\" ${input_files}\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    prefix = \"${caller}.${type}\"\n    output_file=\"signatures.${prefix}.pdf\"\n    \"\"\"\n    gs -dBATCH -dNOPAUSE -q -dAutoRotatePages=/None -sDEVICE=pdfwrite -sOutputFile=\"${output_file}\" ${input_files}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "GS3"
        ],
        "tools_url": [
            "https://bio.tools/gs3"
        ],
        "tools_dico": [
            {
                "name": "GS3",
                "uri": "https://bio.tools/gs3",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "GS3 (Genomic Selection / Gibbs Sampling / Gauss Seidel) is a program that estimates fixed and random effects, breeding values and SNP effects for genomic selection. It includes normal, mixture, or double exponential distributions for SNP effects, i.e. GBLUP, the so-called BayesCPi, and the Bayesian Lasso. It allows estimation of the variances and effects of SNPs, polygenic and environmental effects, and also the inclusion of heterogeneous variances as for the analysis of DYD\u2019s",
                "homepage": "https://github.com/alegarra/gs3"
            }
        ],
        "inputs": [
            "signatures_plots_caller_grouped"
        ],
        "nb_inputs": 1,
        "outputs": [
            "done_merge_signatures_plots"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/signatures\", mode: 'copy'"
        ],
        "when": "input_files.size() > 0",
        "stub": ""
    },
    "merge_signatures_pie_plots": {
        "name_process": "merge_signatures_pie_plots",
        "string_process": "\nprocess merge_signatures_pie_plots {\n                                                     \n    tag \"${caller}.${type}\"\n    publishDir \"${params.outputDir}/signatures\", mode: 'copy'\n\n    input:\n    set val(caller), val(type), file(input_files:'*') from signatures_pieplots_caller_grouped\n\n    output:\n    file(\"${output_file}\")\n    val(output_file) into done_merge_signatures_pie_plots\n\n    when:\n    input_files.size() > 0\n\n    script:\n    prefix = \"${caller}.${type}\"\n    output_file=\"signatures.pie.${prefix}.pdf\"\n    \"\"\"\n    gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=\"${output_file}\" ${input_files}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    prefix = \"${caller}.${type}\"\n    output_file=\"signatures.pie.${prefix}.pdf\"\n    \"\"\"\n    gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=\"${output_file}\" ${input_files}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "GS3"
        ],
        "tools_url": [
            "https://bio.tools/gs3"
        ],
        "tools_dico": [
            {
                "name": "GS3",
                "uri": "https://bio.tools/gs3",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2945",
                                    "term": "Analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "GS3 (Genomic Selection / Gibbs Sampling / Gauss Seidel) is a program that estimates fixed and random effects, breeding values and SNP effects for genomic selection. It includes normal, mixture, or double exponential distributions for SNP effects, i.e. GBLUP, the so-called BayesCPi, and the Bayesian Lasso. It allows estimation of the variances and effects of SNPs, polygenic and environmental effects, and also the inclusion of heterogeneous variances as for the analysis of DYD\u2019s",
                "homepage": "https://github.com/alegarra/gs3"
            }
        ],
        "inputs": [
            "signatures_pieplots_caller_grouped"
        ],
        "nb_inputs": 1,
        "outputs": [
            "done_merge_signatures_pie_plots"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${caller}.${type}\"",
            "publishDir \"${params.outputDir}/signatures\", mode: 'copy'"
        ],
        "when": "input_files.size() > 0",
        "stub": ""
    },
    "cnvkit": {
        "name_process": "cnvkit",
        "string_process": "\nprocess cnvkit {\n                                            \n    publishDir \"${params.outputDir}/cnv\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), file(tumorBam), val(normalID), file(normalBam), file(ref_fasta), file(ref_fai), file(ref_dict), file(targets_annotated_bed_file) from samples_bam_ref_targets\n\n    output:\n    file(\"${output_cns}\")\n    file(\"${output_finalcnr}\")\n    set val(comparisonID), val(tumorID), val(normalID), file(\"${output_cnr}\"), file(\"${output_call_cns}\"), file(\"${segment_gainloss}\") into sample_cnvs\n\n    script:\n    prefix = \"${comparisonID}\"\n    tumorBamID = \"${tumorBam}\".replaceFirst(/.bam$/, \"\")\n    normal_reference = \"normal_reference.cnn\"\n    tmp_cns = \"${tumorBamID}.cns\"\n    tmp_cnr = \"${tumorBamID}.cnr\"\n    output_cns = \"${prefix}.cns\"\n    output_cnr = \"${prefix}.cnr\"\n    output_finalcnr = \"${prefix}.final.cnr\"\n    output_call_cns = \"${prefix}.call.cns\"\n    segment_gainloss = \"${prefix}.segment-gainloss.txt\"\n    \"\"\"\n    # running cnvkit pipeline on paried tumor/normal bams using batch mode, required tumorBam, normalBam, reference fasta and bed.\n    cnvkit.py batch \"${tumorBam}\" \\\n    --normal \"${normalBam}\" \\\n    --targets \"${targets_annotated_bed_file}\" \\\n    --fasta \"${ref_fasta}\" \\\n    --output-reference \"${normal_reference}\" \\\n    -p \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    # Produces ${tmp_cns} and ${tmp_cnr}, rename to ${output_cns} and ${output_cnr}\n    mv ${tmp_cns} ${output_cns}\n    mv ${tmp_cnr} ${output_cnr}\n\n    # Given segmented log2 ratio estimates (.cns), derive each segment\u2019s absolute integer copy number.\n    cnvkit.py call --filter cn \"${output_cns}\"\n\n    # Identify targeted genes with copy number gain or loss above or below a threshold, -t :threshold and -m:number of bins\n    cnvkit.py gainloss \"${output_cnr}\" -s \"${output_call_cns}\" -t 0.3 -m 5 > \"${segment_gainloss}\"\n    cnvkit.py gainloss \"${output_cnr}\" -t 0.3 -m 5 > \"${output_finalcnr}\"\n\n    \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "    prefix = \"${comparisonID}\"\n    tumorBamID = \"${tumorBam}\".replaceFirst(/.bam$/, \"\")\n    normal_reference = \"normal_reference.cnn\"\n    tmp_cns = \"${tumorBamID}.cns\"\n    tmp_cnr = \"${tumorBamID}.cnr\"\n    output_cns = \"${prefix}.cns\"\n    output_cnr = \"${prefix}.cnr\"\n    output_finalcnr = \"${prefix}.final.cnr\"\n    output_call_cns = \"${prefix}.call.cns\"\n    segment_gainloss = \"${prefix}.segment-gainloss.txt\"\n    \"\"\"\n    # running cnvkit pipeline on paried tumor/normal bams using batch mode, required tumorBam, normalBam, reference fasta and bed.\n    cnvkit.py batch \"${tumorBam}\" \\\n    --normal \"${normalBam}\" \\\n    --targets \"${targets_annotated_bed_file}\" \\\n    --fasta \"${ref_fasta}\" \\\n    --output-reference \"${normal_reference}\" \\\n    -p \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    # Produces ${tmp_cns} and ${tmp_cnr}, rename to ${output_cns} and ${output_cnr}\n    mv ${tmp_cns} ${output_cns}\n    mv ${tmp_cnr} ${output_cnr}\n\n    # Given segmented log2 ratio estimates (.cns), derive each segment\u2019s absolute integer copy number.\n    cnvkit.py call --filter cn \"${output_cns}\"\n\n    # Identify targeted genes with copy number gain or loss above or below a threshold, -t :threshold and -m:number of bins\n    cnvkit.py gainloss \"${output_cnr}\" -s \"${output_call_cns}\" -t 0.3 -m 5 > \"${segment_gainloss}\"\n    cnvkit.py gainloss \"${output_cnr}\" -t 0.3 -m 5 > \"${output_finalcnr}\"\n\n    \"\"\"",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_bam_ref_targets"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_cnvs"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "cnvkit_pooled_reference": {
        "name_process": "cnvkit_pooled_reference",
        "string_process": "\nprocess cnvkit_pooled_reference {\n                                                  \n    publishDir \"${params.outputDir}/cnv\", mode: 'copy'\n\n    input:\n    set val(new_comparisonID), val(sampleID), file(bam), val(cnv_poolID), file(cnv_pool_file) from samples_cnv_pool_ch\n\n    output:\n    file(\"${output_cns}\")\n    file(\"${output_finalcnr}\")\n    set val(new_comparisonID), val(sampleID), val(cnv_poolID), file(\"${output_cnr}\"), file(\"${output_call_cns}\"), file(\"${segment_gainloss}\") into sample_cnvs_pooledreference\n\n    script:\n    prefix = \"${new_comparisonID}\"\n    tumorBamID = \"${bam}\".replaceFirst(/.bam$/, \"\")\n    tmp_cns = \"${tumorBamID}.cns\"\n    tmp_cnr = \"${tumorBamID}.cnr\"\n    output_cns = \"${prefix}.cns\"\n    output_cnr = \"${prefix}.cnr\"\n    output_finalcnr = \"${prefix}.final.cnr\"\n    output_call_cns = \"${prefix}.call.cns\"\n    segment_gainloss = \"${prefix}.segment-gainloss.txt\"\n    \"\"\"\n    # running cnvkit pipeline on tumor/pooled_normal reference using batch mode, required tumorBam, pooledReference.cnn.\n    cnvkit.py batch \"${bam}\" \\\n    -r \"${cnv_pool_file}\" \\\n    -p \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    # Produces ${tmp_cns} and ${tmp_cnr}, rename to ${output_cns} and ${output_cnr}\n    mv ${tmp_cns} ${output_cns}\n    mv ${tmp_cnr} ${output_cnr}\n\n    # Given segmented log2 ratio estimates (.cns), derive each segment\u2019s absolute integer copy number.\n    cnvkit.py call --filter cn \"${output_cns}\"\n\n    # Identify targeted genes with copy number gain or loss above or below a threshold, -t :threshold and -m:number of bins\n    cnvkit.py gainloss \"${output_cnr}\" -s \"${output_call_cns}\" -t 0.3 -m 5 > \"${segment_gainloss}\"\n    cnvkit.py gainloss \"${output_cnr}\" -t 0.3 -m 5 > \"${output_finalcnr}\"\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    prefix = \"${new_comparisonID}\"\n    tumorBamID = \"${bam}\".replaceFirst(/.bam$/, \"\")\n    tmp_cns = \"${tumorBamID}.cns\"\n    tmp_cnr = \"${tumorBamID}.cnr\"\n    output_cns = \"${prefix}.cns\"\n    output_cnr = \"${prefix}.cnr\"\n    output_finalcnr = \"${prefix}.final.cnr\"\n    output_call_cns = \"${prefix}.call.cns\"\n    segment_gainloss = \"${prefix}.segment-gainloss.txt\"\n    \"\"\"\n    # running cnvkit pipeline on tumor/pooled_normal reference using batch mode, required tumorBam, pooledReference.cnn.\n    cnvkit.py batch \"${bam}\" \\\n    -r \"${cnv_pool_file}\" \\\n    -p \\${NSLOTS:-\\${NTHREADS:-1}}\n\n    # Produces ${tmp_cns} and ${tmp_cnr}, rename to ${output_cns} and ${output_cnr}\n    mv ${tmp_cns} ${output_cns}\n    mv ${tmp_cnr} ${output_cnr}\n\n    # Given segmented log2 ratio estimates (.cns), derive each segment\u2019s absolute integer copy number.\n    cnvkit.py call --filter cn \"${output_cns}\"\n\n    # Identify targeted genes with copy number gain or loss above or below a threshold, -t :threshold and -m:number of bins\n    cnvkit.py gainloss \"${output_cnr}\" -s \"${output_call_cns}\" -t 0.3 -m 5 > \"${segment_gainloss}\"\n    cnvkit.py gainloss \"${output_cnr}\" -t 0.3 -m 5 > \"${output_finalcnr}\"\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samples_cnv_pool_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_cnvs_pooledreference"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "cnvkit_gene_segments": {
        "name_process": "cnvkit_gene_segments",
        "string_process": "\nprocess cnvkit_gene_segments {\n                                                                                                                                              \n    publishDir \"${params.outputDir}/cnv\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), val(normalID), file(cnr), file(call_cns), file(segment_gainloss) from sample_cnvs_filtered\n\n    output:\n    set val(comparisonID), val(tumorID), val(normalID), file(segment_gainloss), file(\"${trusted_genes}\") into sample_cnv_gene_segments\n\n    script:\n    prefix = \"${comparisonID}\"\n    segment_genes = \"${prefix}.segment-genes.txt\"\n    ratio_genes = \"${prefix}.ratio-genes.txt\"\n    trusted_genes = \"${prefix}.trusted-genes.txt\"\n    \"\"\"\n    # Generate segment genes (from .cns) and ratio genes (from .cnr) by applying threshold\n    cnvkit.py gainloss \"${cnr}\" -s \"${call_cns}\" -t 0.3 -m 5 | tail -n+2 | cut -f1 | sort > \"${segment_genes}\"\n    cnvkit.py gainloss \"${cnr}\" -t 0.3 -m 5 | tail -n+2 | cut -f1 | sort > \"${ratio_genes}\"\n\n    # Take intersection of segment and ratio as trusted genes (final set of cnv genes)\n    comm -12 \"${ratio_genes}\" \"${segment_genes}\" > \"${trusted_genes}\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    prefix = \"${comparisonID}\"\n    segment_genes = \"${prefix}.segment-genes.txt\"\n    ratio_genes = \"${prefix}.ratio-genes.txt\"\n    trusted_genes = \"${prefix}.trusted-genes.txt\"\n    \"\"\"\n    # Generate segment genes (from .cns) and ratio genes (from .cnr) by applying threshold\n    cnvkit.py gainloss \"${cnr}\" -s \"${call_cns}\" -t 0.3 -m 5 | tail -n+2 | cut -f1 | sort > \"${segment_genes}\"\n    cnvkit.py gainloss \"${cnr}\" -t 0.3 -m 5 | tail -n+2 | cut -f1 | sort > \"${ratio_genes}\"\n\n    # Take intersection of segment and ratio as trusted genes (final set of cnv genes)\n    comm -12 \"${ratio_genes}\" \"${segment_genes}\" > \"${trusted_genes}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "COMMA"
        ],
        "tools_url": [
            "https://bio.tools/comma"
        ],
        "tools_dico": [
            {
                "name": "COMMA",
                "uri": "https://bio.tools/comma",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2275",
                            "term": "Molecular modelling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "COMMA (COMmunication MApping) is a method to dissect proteins dynamical architectures.",
                "homepage": "http://www.lcqb.upmc.fr/COMMA/COMMA.html"
            }
        ],
        "inputs": [
            "sample_cnvs_filtered"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_cnv_gene_segments"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "cnvkit_extract_trusted_genes": {
        "name_process": "cnvkit_extract_trusted_genes",
        "string_process": "\nprocess cnvkit_extract_trusted_genes {\n                                                    \n    publishDir \"${params.outputDir}/cnv\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), val(normalID), file(segment_gainloss), file(trusted_genes) from sample_cnv_gene_segments_filtered\n\n    output:\n    set val(tumorID), val(normalID), file(\"${output_final_cns}\") into cnvs_cns\n    set val(comparisonID), val(tumorID), val(normalID), file(\"${output_final_cns}\") into (cnvs_cns2, cnvs_cns3)\n\n\n    script:\n    prefix = \"${comparisonID}\"\n    trusted_genes = \"${prefix}.trusted-genes.txt\"\n    output_final_cns = \"${prefix}.${filemap['cnvkit']['suffix']['final_cns']}\"                            \n    \"\"\"\n    # Get the trusted genes and their segment gain loss info from segment_gainloss file and write to final.cns\n    cat \"${segment_gainloss}\" | head -n +1 > \"${output_final_cns}\"\n    grep -w -f \"${trusted_genes}\" \"${segment_gainloss}\" >> \"${output_final_cns}\"\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    prefix = \"${comparisonID}\"\n    trusted_genes = \"${prefix}.trusted-genes.txt\"\n    output_final_cns = \"${prefix}.${filemap['cnvkit']['suffix']['final_cns']}\"                            \n    \"\"\"\n    # Get the trusted genes and their segment gain loss info from segment_gainloss file and write to final.cns\n    cat \"${segment_gainloss}\" | head -n +1 > \"${output_final_cns}\"\n    grep -w -f \"${trusted_genes}\" \"${segment_gainloss}\" >> \"${output_final_cns}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_cnv_gene_segments_filtered"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cnvs_cns",
            ""
        ],
        "nb_outputs": 2,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "cnvkit_extract_trusted_genes_update": {
        "name_process": "cnvkit_extract_trusted_genes_update",
        "string_process": "\nprocess cnvkit_extract_trusted_genes_update {\n                                              \n    publishDir \"${params.outputDir}/cnv\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), val(normalID), file(cns) from cnvs_cns2\n\n    output:\n    file(\"${output_file}\") into cnvkit_extract_trusted_genes_updated\n\n\n    script:\n    prefix = \"${comparisonID}\"\n    output_file = \"${prefix}.${filemap['cnvkit']['suffix']['final_cns']}.sample.tsv\"\n    \"\"\"\n    paste-col.py -i \"${cns}\" --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"Comparison\" -v \"${comparisonID}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    prefix = \"${comparisonID}\"\n    output_file = \"${prefix}.${filemap['cnvkit']['suffix']['final_cns']}.sample.tsv\"\n    \"\"\"\n    paste-col.py -i \"${cns}\" --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"Comparison\" -v \"${comparisonID}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cnvs_cns2"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cnvkit_extract_trusted_genes_updated"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_cnvkit_extract_trusted_genes_collected": {
        "name_process": "update_cnvkit_extract_trusted_genes_collected",
        "string_process": "\nprocess update_cnvkit_extract_trusted_genes_collected {\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from cnvkit_extract_trusted_genes_collected\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"cnv.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n }",
        "nb_lignes_process": 23,
        "string_script": "    output_file = \"cnv.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cnvkit_extract_trusted_genes_collected"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "cnvkit_plotly": {
        "name_process": "cnvkit_plotly",
        "string_process": "\nprocess cnvkit_plotly {\n\n    publishDir \"${params.outputDir}/cnv/cnvkit_plot\", mode: 'copy'\n\n    input:\n    set val(comparisonID), val(tumorID), val(normalID), file(cns) from cnvs_cns3\n\n    output:\n    file(\"${output_html}\")\n    file(\"${output_pdf}\")\n\n    script:\n    output_html = \"${comparisonID}.cnvkit.plotly.html\"\n    output_pdf = \"${comparisonID}.cnvkit.plotly.pdf\"\n    \"\"\"\n    cnvplot.R \"${cns}\" \"${output_html}\" \"${output_pdf}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    output_html = \"${comparisonID}.cnvkit.plotly.html\"\n    output_pdf = \"${comparisonID}.cnvkit.plotly.pdf\"\n    \"\"\"\n    cnvplot.R \"${cns}\" \"${output_html}\" \"${output_pdf}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cnvs_cns3"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv/cnvkit_plot\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "snp_pileup": {
        "name_process": "snp_pileup",
        "string_process": "\nprocess snp_pileup {\n    publishDir \"${params.outputDir}/cnv/FACETS\", mode: 'copy'                           \n\n    input:\n    set val(comparisonID), val(tumorID), file(tumorBam), file(tumorBai), val(normalID), file(normalBam), file(normalBai), file(snp_vcf), file(snp_vcf_tbi) from samples_dd_bam_noHapMap_pairs2.combine(common_snp_vcf).combine(common_snp_vcf_tbi)\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), file(output_cnvsnp) into snp_pileup\n\n    script:\n    caller = \"FACETS\"\n    callerType = \"cnv\"\n    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    output_cnvsnp = \"${prefix}.snp_pileup.txt\"\n    \"\"\"\n    snp-pileup \\\n    -g \\\n    -q15 \\\n    -Q20 \\\n    -P100 \\\n    -r25,0 \\\n    \"${snp_vcf}\" \\\n    tmp.gz \\\n    \"${normalBam}\" \\\n    \"${tumorBam}\"\n\n    # need to remove 'chr' from the table to resolve bugs in facets\n    zcat tmp.gz | sed 's|chr||g' > \"${output_cnvsnp}\"\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    caller = \"FACETS\"\n    callerType = \"cnv\"\n    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    output_cnvsnp = \"${prefix}.snp_pileup.txt\"\n    \"\"\"\n    snp-pileup \\\n    -g \\\n    -q15 \\\n    -Q20 \\\n    -P100 \\\n    -r25,0 \\\n    \"${snp_vcf}\" \\\n    tmp.gz \\\n    \"${normalBam}\" \\\n    \"${tumorBam}\"\n\n    # need to remove 'chr' from the table to resolve bugs in facets\n    zcat tmp.gz | sed 's|chr||g' > \"${output_cnvsnp}\"\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "SCcaller",
            "SynChr"
        ],
        "tools_url": [
            "https://bio.tools/sccaller",
            "https://bio.tools/synchr"
        ],
        "tools_dico": [
            {
                "name": "SCcaller",
                "uri": "https://bio.tools/sccaller",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "Single nucleotide polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0484",
                                    "term": "SNP calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "A tool for Identifying single nucleotide variations (SNVs) and short insertions and deletions (INDELs) from single cell sequencing data.",
                "homepage": "https://github.com/biosinodx/SCcaller/"
            },
            {
                "name": "SynChr",
                "uri": "https://bio.tools/synchr",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0283",
                                    "term": "Linkage analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A Fast and Easy Tool to Reconstruct and Visualize Synteny Blocks along Eukaryotic Chromosomes.",
                "homepage": "http://www.lcqb.upmc.fr/CHROnicle/SynChro.html"
            }
        ],
        "inputs": [
            "samples_dd_bam_noHapMap_pairs2",
            "common_snp_vcf",
            "common_snp_vcf_tbi"
        ],
        "nb_inputs": 3,
        "outputs": [
            "snp_pileup"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv/FACETS\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "snp_pileup_check_variance": {
        "name_process": "snp_pileup_check_variance",
        "string_process": "\nprocess snp_pileup_check_variance {\n                                                                                    \n                                                                          \n                           \n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), file(snp_pileup_txt) from snp_pileup_good\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), file(snp_pileup_txt), file(\"${output_file}\") into snp_pileup_variances\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    output_file = \"${prefix}.variance.txt\"\n    \"\"\"\n    facets-check-variance.R \"${snp_pileup_txt}\" \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    output_file = \"${prefix}.variance.txt\"\n    \"\"\"\n    facets-check-variance.R \"${snp_pileup_txt}\" \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "snp_pileup_good"
        ],
        "nb_inputs": 1,
        "outputs": [
            "snp_pileup_variances"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "facets": {
        "name_process": "facets",
        "string_process": "\nprocess facets {\n    publishDir \"${params.outputDir}/cnv/FACETS\", mode: 'copy'\n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), file(snp_pileup_txt), file(snp_pileup_variance) from snp_pileup_variance_good\n\n    output:\n                                \n    set val(comparisonID), val(tumorID), val(normalID), file(\"${output_segment}\") into (facets_segment_files,facets_segment_files2)\n    file(\"${output_pdf}\")\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    output_segment = \"${prefix}.segment.tsv\"\n    output_pdf = \"${prefix}.plot.pdf\"\n    \"\"\"\n    facets.R \"${snp_pileup_txt}\" \"${output_pdf}\" \"${output_segment}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    output_segment = \"${prefix}.segment.tsv\"\n    output_pdf = \"${prefix}.plot.pdf\"\n    \"\"\"\n    facets.R \"${snp_pileup_txt}\" \"${output_pdf}\" \"${output_segment}\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "snp_pileup_variance_good"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv/FACETS\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "segment_files_updated": {
        "name_process": "segment_files_updated",
        "string_process": "\nprocess segment_files_updated {\n  publishDir \"${params.outputDir}/cnv/FACETS\", mode: 'copy'\n\n  input:\n  set val(comparisonID), val(tumorID), val(normalID), file(output_segment) from facets_segment_files\n\n  output:\n  file(\"${segment_output_file}\") into facets_segment_files_updated\n\n  script:\n  prefix = \"${comparisonID}\"\n  segment_output_file = \"${prefix}.segment.tsv\"\n  \"\"\"\n    paste-col.py -i \"${output_segment}\" --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"Comparison\" -v \"${comparisonID}\" > \\\n    \"${segment_output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "  prefix = \"${comparisonID}\"\n  segment_output_file = \"${prefix}.segment.tsv\"\n  \"\"\"\n    paste-col.py -i \"${output_segment}\" --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"Comparison\" -v \"${comparisonID}\" > \\\n    \"${segment_output_file}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "facets_segment_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "facets_segment_files_updated"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/cnv/FACETS\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "facets_summary": {
        "name_process": "facets_summary",
        "string_process": "\nprocess facets_summary {\n  publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from facets_segment_files_collected\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"FACETS.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n }",
        "nb_lignes_process": 22,
        "string_script": "    output_file = \"FACETS.tsv\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "facets_segment_files_collected"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "overlap_snp_filter": {
        "name_process": "overlap_snp_filter",
        "string_process": "\nprocess overlap_snp_filter {\n                                                                    \n    publishDir \"${params.outputDir}/snp_overlap/${caller}/filtered\", mode: 'copy'\n\n    input:\n    set val(caller), val(type), val(comparisonID), val(tumorID), file(tumor_tsv), val(normalID), file(normal_tsv) from annotations_tables_paired\n\n    output:\n    set val(caller), val(type), val(comparisonID), val(tumorID), file(\"${tumor_output}\"), val(normalID), file(\"${normal_output}\") into annotations_tables_paired_filtered\n\n    script:\n    tumor_prefix = \"${tumorID}.${caller}.${type}\"\n    tumor_output = \"${tumor_prefix}.snp-overlap.filtered.tsv\"\n    normal_prefix = \"${normalID}.${caller}.${type}\"\n    normal_output = \"${normal_prefix}.snp-overlap.filtered.tsv\"\n    \"\"\"\n    snp-overlap-filter.py -c \"${caller}\" -i \"${tumor_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${tumor_output}\"\n\n    snp-overlap-filter.py -c \"${caller}\" -i \"${normal_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${normalID}\" | \\\n    paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${normal_output}\"\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    tumor_prefix = \"${tumorID}.${caller}.${type}\"\n    tumor_output = \"${tumor_prefix}.snp-overlap.filtered.tsv\"\n    normal_prefix = \"${normalID}.${caller}.${type}\"\n    normal_output = \"${normal_prefix}.snp-overlap.filtered.tsv\"\n    \"\"\"\n    snp-overlap-filter.py -c \"${caller}\" -i \"${tumor_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${tumor_output}\"\n\n    snp-overlap-filter.py -c \"${caller}\" -i \"${normal_tsv}\" | \\\n    paste-col.py --header \"Sample\" -v \"${normalID}\" | \\\n    paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${normal_output}\"\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotations_tables_paired"
        ],
        "nb_inputs": 1,
        "outputs": [
            "annotations_tables_paired_filtered"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/snp_overlap/${caller}/filtered\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "overlap_snps": {
        "name_process": "overlap_snps",
        "string_process": "\nprocess overlap_snps {\n    publishDir \"${params.outputDir}/snp_overlap/${caller}/final\", mode: 'copy'\n    input:\n    set val(caller), val(type), val(comparisonID), val(tumorID), file(tumor_tsv), val(normalID), file(normal_tsv) from annotations_tables_paired_filtered_good\n\n    output:\n    set val(caller), val(type), val(comparisonID), val(tumorID), val(normalID), file(\"${output_aggr_table}\") into sample_snp_overlap_aggr\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${type}\"\n    output_matrix = \"${prefix}.snp-overlap.matrix.tsv\"\n    output_table = \"${prefix}.snp-overlap.tsv\"\n    output_aggr_table = \"${prefix}.snp-overlap.aggregate.tsv\"\n    output_plot = \"${prefix}.snp-overlap.pdf\"\n    \"\"\"\n    snp-overlap.R \\\n    \"${tumor_tsv}\" \\\n    \"${normal_tsv}\" \\\n    \"${output_matrix}\" \\\n    \"${output_table}\" \\\n    \"${output_aggr_table}\" \\\n    \"${output_plot}\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${type}\"\n    output_matrix = \"${prefix}.snp-overlap.matrix.tsv\"\n    output_table = \"${prefix}.snp-overlap.tsv\"\n    output_aggr_table = \"${prefix}.snp-overlap.aggregate.tsv\"\n    output_plot = \"${prefix}.snp-overlap.pdf\"\n    \"\"\"\n    snp-overlap.R \\\n    \"${tumor_tsv}\" \\\n    \"${normal_tsv}\" \\\n    \"${output_matrix}\" \\\n    \"${output_table}\" \\\n    \"${output_aggr_table}\" \\\n    \"${output_plot}\"\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annotations_tables_paired_filtered_good"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sample_snp_overlap_aggr"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/snp_overlap/${caller}/final\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_overlap_snp_table": {
        "name_process": "update_overlap_snp_table",
        "string_process": "\nprocess update_overlap_snp_table {\n    publishDir \"${params.outputDir}/snp_overlap/${caller}\", mode: 'copy'\n    input:\n    set val(caller), val(type), val(comparisonID), val(tumorID), val(normalID), file(tsv) from sample_snp_overlap_aggr\n\n    output:\n    file(\"${output_file}\") into updated_snp_overlap_aggr\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${type}\"\n    output_file = \"${prefix}.snp-overlap.aggregate.updated.tsv\"\n    \"\"\"\n    cat \"${tsv}\" | \\\n    paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${type}\"\n    output_file = \"${prefix}.snp-overlap.aggregate.updated.tsv\"\n    \"\"\"\n    cat \"${tsv}\" | \\\n    paste-col.py --header \"Tumor\" -v \"${tumorID}\" | \\\n    paste-col.py --header \"Normal\" -v \"${normalID}\" | \\\n    paste-col.py --header \"VariantCallerType\" -v \"${type}\" | \\\n    paste-col.py --header \"VariantCaller\" -v \"${caller}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_snp_overlap_aggr"
        ],
        "nb_inputs": 1,
        "outputs": [
            "updated_snp_overlap_aggr"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/snp_overlap/${caller}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "update_snp_overlap_collected": {
        "name_process": "update_snp_overlap_collected",
        "string_process": "\nprocess update_snp_overlap_collected {\n                                        \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(table) from snp_overlap_collected\n\n    output:\n    file(\"${output_file}\") into snp_overlap_collected_updated\n\n    script:\n    output_file = \"${snp_overlap_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n }",
        "nb_lignes_process": 23,
        "string_script": "    output_file = \"${snp_overlap_file}\"\n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "snp_overlap_collected"
        ],
        "nb_inputs": 1,
        "outputs": [
            "snp_overlap_collected_updated"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "filter_seracare_selected_variants": {
        "name_process": "filter_seracare_selected_variants",
        "string_process": "\nprocess filter_seracare_selected_variants {\n                                                                                 \n    input:\n    set val(caller), val(type), val(sampleID), file(tsv), file(selected_tsv) from seracare_annotations\n\n    output:\n    set val(caller), val(type), val(sampleID), file(\"${output_file}\") into seracare_variants\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    output_file = \"${prefix}.seracare-selected.tsv\"\n    \"\"\"\n    seracare-selected-variant-filter.py -i \"${tsv}\" -o \"${output_file}\" --seracare \"${selected_tsv}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    output_file = \"${prefix}.seracare-selected.tsv\"\n    \"\"\"\n    seracare-selected-variant-filter.py -i \"${tsv}\" -o \"${output_file}\" --seracare \"${selected_tsv}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seracare_annotations"
        ],
        "nb_inputs": 1,
        "outputs": [
            "seracare_variants"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "confidence_intervals_seracare": {
        "name_process": "confidence_intervals_seracare",
        "string_process": "\nprocess confidence_intervals_seracare {\n                                                                                                            \n    input:\n    set val(caller), val(type), val(sampleID), file(tsv) from seracare_variants\n\n    output:\n    file(\"${output_file}\") into seracare_variants_ci\n\n    script:\n    prefix = \"${sampleID}.${caller}.${type}\"\n    output_file = \"${prefix}.seracare-selected.ci.tsv\"\n    \"\"\"\n    variant-confidence-intervals.R \"${tsv}\" \"${output_file}\" \"${SeraCareErrorRate}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    prefix = \"${sampleID}.${caller}.${type}\"\n    output_file = \"${prefix}.seracare-selected.ci.tsv\"\n    \"\"\"\n    variant-confidence-intervals.R \"${tsv}\" \"${output_file}\" \"${SeraCareErrorRate}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seracare_variants"
        ],
        "nb_inputs": 1,
        "outputs": [
            "seracare_variants_ci"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "collect_seracare_annotation_tables": {
        "name_process": "collect_seracare_annotation_tables",
        "string_process": "\nprocess collect_seracare_annotation_tables {\n                                               \n\n    input:\n    file('t*') from seracare_variants_ci.collect()\n\n    output:\n    file(\"${output_file}\") into collected_seracare_variants\n\n    script:\n    output_file = \"all_seracare_annotations.tmp.tsv\"\n    \"\"\"\n    concat-tables.py t* > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    output_file = \"all_seracare_annotations.tmp.tsv\"\n    \"\"\"\n    concat-tables.py t* > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seracare_variants_ci"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_seracare_variants"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "update_collect_seracare_annotation_tables": {
        "name_process": "update_collect_seracare_annotation_tables",
        "string_process": "\nprocess update_collect_seracare_annotation_tables {\n                                        \n    publishDir \"${params.outputDir}/annotations\", mode: 'copy'\n\n    input:\n    file(table) from collected_seracare_variants\n\n    output:\n    file(\"${output_file}\") into collected_updated_seracare_variants\n\n    script:\n    output_file = \"${all_seracare_annotations_file}\"                            \n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    output_file = \"${all_seracare_annotations_file}\"                            \n    \"\"\"\n    paste-col.py -i \"${table}\" --header \"Run\" -v \"${runID}\" | \\\n    paste-col.py --header \"Time\" -v \"${workflowTimestamp}\" | \\\n    paste-col.py --header \"Session\" -v \"${workflow.sessionId}\" | \\\n    paste-col.py --header \"Workflow\" -v \"${workflow.runName}\" | \\\n    paste-col.py --header \"Location\" -v \"${workflow.projectDir}\" | \\\n    paste-col.py --header \"System\" -v \"${localhostname}\" | \\\n    paste-col.py --header \"GitBranch\" -v \"${params.GIT_CURRENT_BRANCH}\" | \\\n    paste-col.py --header \"GitTag\" -v \"${params.GIT_CURRENT_TAG}\" > \\\n    \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "collected_seracare_variants"
        ],
        "nb_inputs": 1,
        "outputs": [
            "collected_updated_seracare_variants"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/annotations\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "igv_filter_variant": {
        "name_process": "igv_filter_variant",
        "string_process": "\nprocess igv_filter_variant {\n                                                                \n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(tsv) from vcf_tsv_pairs_filtered\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${output_file}\") into igv_filtered_variants\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    output_file = \"${prefix}.igv-annotations.tsv\"\n    \"\"\"\n    igv-variant-filter.py -c \"${caller}\" -i \"${tsv}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    output_file = \"${prefix}.igv-annotations.tsv\"\n    \"\"\"\n    igv-variant-filter.py -c \"${caller}\" -i \"${tsv}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vcf_tsv_pairs_filtered"
        ],
        "nb_inputs": 1,
        "outputs": [
            "igv_filtered_variants"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "igv_tsv_to_bed": {
        "name_process": "igv_tsv_to_bed",
        "string_process": "\nprocess igv_tsv_to_bed {\n                                                     \n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(tsv) from igv_refiltered_variants\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${output_file}\") into igv_regions\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    output_file = \"${prefix}.igv-regions.bed\"\n    \"\"\"\n    variant-tsv2bed.py -i \"${tsv}\" -o \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    output_file = \"${prefix}.igv-regions.bed\"\n    \"\"\"\n    variant-tsv2bed.py -i \"${tsv}\" -o \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "igv_refiltered_variants"
        ],
        "nb_inputs": 1,
        "outputs": [
            "igv_regions"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "igv_bed_line_chunk": {
        "name_process": "igv_bed_line_chunk",
        "string_process": "\nprocess igv_bed_line_chunk {\n                                                                             \n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(bed) from igv_regions\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file('*') into igv_regions_split\n\n    script:\n    numLines = 30                                                                         \n    \"\"\"\n    split-bed-lines.py \"${bed}\" \"${numTargetSplitLines}\"\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    numLines = 30                                                                         \n    \"\"\"\n    split-bed-lines.py \"${bed}\" \"${numTargetSplitLines}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "igv_regions"
        ],
        "nb_inputs": 1,
        "outputs": [
            "igv_regions_split"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "igv_snapshot": {
        "name_process": "igv_snapshot",
        "string_process": "\nprocess igv_snapshot {\n                                           \n\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(bed), val(bedChunkLabel), file(tumorBam), file(tumorBai), file(normalBam), file(normalBai) from igv_regions_bams\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), val(bedChunkLabel), file(\"${snapshotDirectory}\") into igv_snaphots\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}.${bedChunkLabel}\"\n    batchscript = \"snapshots.bat\"\n    snapshotDirectory = \"${prefix}\"\n    image_height = 750\n    genome = 'hg19'\n    \"\"\"\n    mkdir \"${snapshotDirectory}\"\n\n    # make IGV snapshot batch script\n    make-igv-batchscript.py \\\n    \"${tumorBam}\" \"${normalBam}\" \\\n    -r \"${bed}\" \\\n    -d \"${snapshotDirectory}\" \\\n    -b \"${batchscript}\" \\\n    --height \"${image_height}\" \\\n    --genome \"${genome}\"\n\n    # run IGV headlessly with xvfb\n    xvfb-run \\\n    --auto-servernum \\\n    --server-num=1 \\\n    igv.sh \\\n    -b \"${batchscript}\"\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}.${bedChunkLabel}\"\n    batchscript = \"snapshots.bat\"\n    snapshotDirectory = \"${prefix}\"\n    image_height = 750\n    genome = 'hg19'\n    \"\"\"\n    mkdir \"${snapshotDirectory}\"\n\n    # make IGV snapshot batch script\n    make-igv-batchscript.py \\\n    \"${tumorBam}\" \"${normalBam}\" \\\n    -r \"${bed}\" \\\n    -d \"${snapshotDirectory}\" \\\n    -b \"${batchscript}\" \\\n    --height \"${image_height}\" \\\n    --genome \"${genome}\"\n\n    # run IGV headlessly with xvfb\n    xvfb-run \\\n    --auto-servernum \\\n    --server-num=1 \\\n    igv.sh \\\n    -b \"${batchscript}\"\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "Mgenome"
        ],
        "tools_url": [
            "https://bio.tools/mgenome"
        ],
        "tools_dico": [
            {
                "name": "Mgenome",
                "uri": "https://bio.tools/mgenome",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2451",
                                    "term": "Sequence comparison"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Designed to find the optimal trees for multiple genome rearrangement by signed reversals. The problem is modeled as: For a given collection of genomes represented by signed permutations on genes, find a tree to connect the given genomes by reversal paths such that the number of all signed reversals is minimized.",
                "homepage": "http://xungulab.com/software/mgenome/mgenome.html"
            }
        ],
        "inputs": [
            "igv_regions_bams"
        ],
        "nb_inputs": 1,
        "outputs": [
            "igv_snaphots"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "aggregate_snapshots_bedChunkLabels": {
        "name_process": "aggregate_snapshots_bedChunkLabels",
        "string_process": "\nprocess aggregate_snapshots_bedChunkLabels {\n    stageInMode \"copy\"\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), val(bedChunkLabels), file(\"*\") from igv_snaphots_grouped\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabel), file(\"${snapshotDirectory}\") into aggregated_snapshots\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    snapshotDirectory = \"${prefix}\"\n    \"\"\"\n    mkdir \"${snapshotDirectory}\"\n    find . -type f -name \"*.png\" -exec mv {} \"${snapshotDirectory}/\" \\\\;\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}.${chunkLabel}\"\n    snapshotDirectory = \"${prefix}\"\n    \"\"\"\n    mkdir \"${snapshotDirectory}\"\n    find . -type f -name \"*.png\" -exec mv {} \"${snapshotDirectory}/\" \\\\;\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "igv_snaphots_grouped"
        ],
        "nb_inputs": 1,
        "outputs": [
            "aggregated_snapshots"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "stageInMode \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "aggregate_snapshots_chunkLabels": {
        "name_process": "aggregate_snapshots_chunkLabels",
        "string_process": "\nprocess aggregate_snapshots_chunkLabels {\n    stageInMode \"copy\"\n    publishDir \"${params.outputDir}/igv-snapshots\", mode: 'copy'\n    input:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), val(chunkLabels), file(\"*\") from reaggregated_snapshots\n\n    output:\n    set val(caller), val(callerType), val(comparisonID), val(tumorID), val(normalID), file(\"${snapshotDirectory}\")\n\n    script:\n    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    snapshotDirectory = \"${prefix}\"\n    \"\"\"\n    mkdir \"${snapshotDirectory}\"\n    find . -type f -name \"*.png\" -exec mv {} \"${snapshotDirectory}/\" \\\\;\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    prefix = \"${comparisonID}.${caller}.${callerType}\"\n    snapshotDirectory = \"${prefix}\"\n    \"\"\"\n    mkdir \"${snapshotDirectory}\"\n    find . -type f -name \"*.png\" -exec mv {} \"${snapshotDirectory}/\" \\\\;\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reaggregated_snapshots"
        ],
        "nb_inputs": 1,
        "outputs": [
            "normalID"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "stageInMode \"copy\"",
            "publishDir \"${params.outputDir}/igv-snapshots\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "custom_analysis_report": {
        "name_process": "custom_analysis_report",
        "string_process": "\nprocess custom_analysis_report {\n                                                            \n    publishDir \"${params.outputDir}\", mode: 'copy'\n    stageInMode \"copy\"\n\n    input:\n    file(report_items: '*') from analysis_report_files.collect()\n    file(all_annotations_file) from all_annotations_file_ch\n    file(samplesheet_output_file) from samplesheet_output_file_ch\n    file(sample_coverage_file) from sample_coverage_file_ch\n    file(interval_coverage_file) from interval_coverage_file_ch\n    file(meta_file) from metadata_ch\n    file(reads_dedup_table) from sambamba_dedup_log_table_ch\n    file(flagstat_table) from samtools_flagstat_table_ch\n    file(dedup_flagstat_table) from samtools_dedup_flagstat_table_ch\n    file(targets_metrics_table) from targets_metrics_ch\n    file(failed_log) from failed_log_ch\n    file(failed_pairs_log) from failed_pairs_log_ch\n    file(targets_annotations_file) from annotated_targets\n    file(signatures_weights) from all_signatures_weights\n    file(tmb_file) from tmbs_collected\n    file(git_json) from git_json_ch\n    file(extra_report_inputs: \"*\") from report_inputs.collect()\n\n    output:\n    file(\"${html_output}\")\n\n    script:\n    prefix = \"${runID}\"\n    html_output = \"${prefix}.report.html\"\n    \"\"\"\n    # convert report file symlinks to copies of original files, because knitr doesnt work well unless all report files are in pwd\n    for item in *.Rmd *.css *.bib; do\n        if [ -L \"\\${item}\" ]; then\n            sourcepath=\"\\$(python -c \"import os; print(os.path.realpath('\\${item}'))\")\"\n            echo \">>> resolving source file: \\${sourcepath}\"\n            rsync -va \"\\${sourcepath}\" \"\\${item}\"\n        fi\n    done\n\n    R --vanilla <<E0F\n    rmarkdown::render(input = \"main.Rmd\",\n    params = list(\n        annotations_file = \"${all_annotations_file}\",\n        samplesheet_file = \"${samplesheet_output_file}\",\n        sample_coverage_file = \"${sample_coverage_file}\",\n        interval_coverage_file = \"${interval_coverage_file}\",\n        meta_file = \"${meta_file}\",\n        reads_dedup_table = \"${reads_dedup_table}\",\n        flagstat_table = \"${flagstat_table}\",\n        dedup_flagstat_table = \"${dedup_flagstat_table}\",\n        targets_metrics_table = \"${targets_metrics_table}\",\n        failed_log = \"${failed_log}\",\n        failed_pairs_log = \"${failed_pairs_log}\",\n        targets_annotations_file = \"${targets_annotations_file}\",\n        signatures_weights_file = \"${signatures_weights}\",\n        git_json_file = \"${git_json}\",\n        snp_overlap_file = \"${snp_overlap_file}\",\n        seracare_annotations_file = \"${all_seracare_annotations_file}\",\n        seracare_selected_variants = \"${SeraCareSelectedTsvFile}\"\n        ),\n    output_format = \"html_document\",\n    output_file = \"${html_output}\")\n    E0F\n    \"\"\"\n}",
        "nb_lignes_process": 65,
        "string_script": "    prefix = \"${runID}\"\n    html_output = \"${prefix}.report.html\"\n    \"\"\"\n    # convert report file symlinks to copies of original files, because knitr doesnt work well unless all report files are in pwd\n    for item in *.Rmd *.css *.bib; do\n        if [ -L \"\\${item}\" ]; then\n            sourcepath=\"\\$(python -c \"import os; print(os.path.realpath('\\${item}'))\")\"\n            echo \">>> resolving source file: \\${sourcepath}\"\n            rsync -va \"\\${sourcepath}\" \"\\${item}\"\n        fi\n    done\n\n    R --vanilla <<E0F\n    rmarkdown::render(input = \"main.Rmd\",\n    params = list(\n        annotations_file = \"${all_annotations_file}\",\n        samplesheet_file = \"${samplesheet_output_file}\",\n        sample_coverage_file = \"${sample_coverage_file}\",\n        interval_coverage_file = \"${interval_coverage_file}\",\n        meta_file = \"${meta_file}\",\n        reads_dedup_table = \"${reads_dedup_table}\",\n        flagstat_table = \"${flagstat_table}\",\n        dedup_flagstat_table = \"${dedup_flagstat_table}\",\n        targets_metrics_table = \"${targets_metrics_table}\",\n        failed_log = \"${failed_log}\",\n        failed_pairs_log = \"${failed_pairs_log}\",\n        targets_annotations_file = \"${targets_annotations_file}\",\n        signatures_weights_file = \"${signatures_weights}\",\n        git_json_file = \"${git_json}\",\n        snp_overlap_file = \"${snp_overlap_file}\",\n        seracare_annotations_file = \"${all_seracare_annotations_file}\",\n        seracare_selected_variants = \"${SeraCareSelectedTsvFile}\"\n        ),\n    output_format = \"html_document\",\n    output_file = \"${html_output}\")\n    E0F\n    \"\"\"",
        "nb_lignes_script": 36,
        "language_script": "bash",
        "tools": [
            "PDEparams"
        ],
        "tools_url": [
            "https://bio.tools/PDEparams"
        ],
        "tools_dico": [
            {
                "name": "PDEparams",
                "uri": "https://bio.tools/PDEparams",
                "topic": [
                    [],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parameter fitting toolbox for partial differential equations in Python.",
                "homepage": "http://github.com/systemsmedicine/PDE_params"
            }
        ],
        "inputs": [
            "analysis_report_files",
            "all_annotations_file_ch",
            "samplesheet_output_file_ch",
            "sample_coverage_file_ch",
            "interval_coverage_file_ch",
            "metadata_ch",
            "sambamba_dedup_log_table_ch",
            "samtools_flagstat_table_ch",
            "samtools_dedup_flagstat_table_ch",
            "targets_metrics_ch",
            "failed_log_ch",
            "failed_pairs_log_ch",
            "annotated_targets",
            "all_signatures_weights",
            "tmbs_collected",
            "git_json_ch",
            "report_inputs"
        ],
        "nb_inputs": 17,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'",
            "stageInMode \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "custom_sample_report": {
        "name_process": "custom_sample_report",
        "string_process": "\nprocess custom_sample_report {\n                                \n    publishDir \"${params.outputDir}/reports\", mode: 'copy'\n\n    input:\n    set val(tumorID), val(normalID), file(tumorNormalFiles: \"*\"), file(sampleFiles: \"*\"), file(report_items: '*') from sample_pairs_output_files2.combine(samples_report_files)\n\n    output:\n    file(\"${html_output}\")\n\n    script:\n    prefix = \"${tumorID}\"\n    html_output = \"${prefix}.report.html\"\n    \"\"\"\n    # convert report file symlinks to copies of original files, because knitr doesnt work well unless all report files are in pwd\n    for item in *.Rmd *.css *.bib; do\n        if [ -L \"\\${item}\" ]; then\n            sourcepath=\"\\$(python -c \"import os; print(os.path.realpath('\\${item}'))\")\"\n            echo \">>> resolving source file: \\${sourcepath}\"\n            rsync -va \"\\${sourcepath}\" \"\\${item}\"\n        fi\n    done\n\n    R --vanilla <<E0F\n    rmarkdown::render(input = \"main.Rmd\",\n    params = list(\n        sampleID = \"${tumorID}\",\n        signatures_Rds = \"${filemap['deconstructSigs']['suffix']['signatures_Rds']}\",\n        signatures_plot_Rds = \"${filemap['deconstructSigs']['suffix']['signatures_plot_Rds']}\",\n        signatures_pieplot_Rds = \"${filemap['deconstructSigs']['suffix']['signatures_pieplot_Rds']}\",\n        paired_normal = \"${normalID}\"\n        ),\n    output_format = \"html_document\",\n    output_file = \"${html_output}\")\n    E0F\n    \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "    prefix = \"${tumorID}\"\n    html_output = \"${prefix}.report.html\"\n    \"\"\"\n    # convert report file symlinks to copies of original files, because knitr doesnt work well unless all report files are in pwd\n    for item in *.Rmd *.css *.bib; do\n        if [ -L \"\\${item}\" ]; then\n            sourcepath=\"\\$(python -c \"import os; print(os.path.realpath('\\${item}'))\")\"\n            echo \">>> resolving source file: \\${sourcepath}\"\n            rsync -va \"\\${sourcepath}\" \"\\${item}\"\n        fi\n    done\n\n    R --vanilla <<E0F\n    rmarkdown::render(input = \"main.Rmd\",\n    params = list(\n        sampleID = \"${tumorID}\",\n        signatures_Rds = \"${filemap['deconstructSigs']['suffix']['signatures_Rds']}\",\n        signatures_plot_Rds = \"${filemap['deconstructSigs']['suffix']['signatures_plot_Rds']}\",\n        signatures_pieplot_Rds = \"${filemap['deconstructSigs']['suffix']['signatures_pieplot_Rds']}\",\n        paired_normal = \"${normalID}\"\n        ),\n    output_format = \"html_document\",\n    output_file = \"${html_output}\")\n    E0F\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "PDEparams"
        ],
        "tools_url": [
            "https://bio.tools/PDEparams"
        ],
        "tools_dico": [
            {
                "name": "PDEparams",
                "uri": "https://bio.tools/PDEparams",
                "topic": [
                    [],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parameter fitting toolbox for partial differential equations in Python.",
                "homepage": "http://github.com/systemsmedicine/PDE_params"
            }
        ],
        "inputs": [
            "sample_pairs_output_files2",
            "samples_report_files"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/reports\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc {\n                                                                                                  \n    publishDir \"${params.outputDir}/qc\", mode: 'copy'\n\n    input:\n    val(all_vals) from all_done.collect()\n    file(output_dir) from output_dir_ch\n\n    output:\n    file(\"${output_html}\")\n    file(\"${output_data}\")\n\n    when:\n    disable_multiqc != true\n\n    script:\n    prefix = \"${runID}\"\n    multiqc_html = \"multiqc_report.html\"\n    multiqc_data = \"multiqc_data\"\n    output_html = \"${prefix}.multiqc.html\"\n    output_data = \"multiqc-data\"\n    \"\"\"\n    multiqc \"${output_dir}\"\n    mv \"${multiqc_html}\" \"${output_html}\"\n    mv \"${multiqc_data}\" \"${output_data}\"\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    prefix = \"${runID}\"\n    multiqc_html = \"multiqc_report.html\"\n    multiqc_data = \"multiqc_data\"\n    output_html = \"${prefix}.multiqc.html\"\n    output_data = \"multiqc-data\"\n    \"\"\"\n    multiqc \"${output_dir}\"\n    mv \"${multiqc_html}\" \"${output_html}\"\n    mv \"${multiqc_data}\" \"${output_data}\"\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "all_done",
            "output_dir_ch"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}/qc\", mode: 'copy'"
        ],
        "when": "disable_multiqc != true",
        "stub": ""
    },
    "fix_header": {
        "name_process": "fix_header",
        "string_process": "\nprocess fix_header {\n    stageInMode \"copy\"\n    input:\n    set val(sampleID), file(bam) from samplesIDs_bams\n\n    output:\n    file(\"${output_file}\") into fixed_header_bams\n\n    script:\n    output_file = \"${sampleID}.fixed.bam\"\n    \"\"\"\n    # need to fix the headers in each .bam file; change the sample name to \"HapMap-pool\"\n    # https://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups\n    samtools view -H \"${bam}\" | \\\n    sed 's|\\\\(^@RG.*\\\\)\\\\(SM:[^\\\\s]*\\\\)\\\\(.*\\$\\\\)|\\\\1SM:${params.outputBamName}\\\\3|' | \\\n    samtools reheader - \"${bam}\" > \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    output_file = \"${sampleID}.fixed.bam\"\n    \"\"\"\n    # need to fix the headers in each .bam file; change the sample name to \"HapMap-pool\"\n    # https://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups\n    samtools view -H \"${bam}\" | \\\n    sed 's|\\\\(^@RG.*\\\\)\\\\(SM:[^\\\\s]*\\\\)\\\\(.*\\$\\\\)|\\\\1SM:${params.outputBamName}\\\\3|' | \\\n    samtools reheader - \"${bam}\" > \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "changename",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/changename",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "changename",
                "uri": "https://bio.tools/changename",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0361",
                                    "term": "Sequence annotation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "Change the chromosome name or gene name of a singla fasta, gff or sam file. For this tool, it can not treat mutiple-chromosome, gene files.",
                "homepage": "https://urgi.versailles.inra.fr/Tools/REPET"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "samplesIDs_bams"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fixed_header_bams"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "stageInMode \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "bam_merge": {
        "name_process": "bam_merge",
        "string_process": "\nprocess bam_merge {\n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    file(\"*\") from fixed_header_bams.collect()\n\n    output:\n    file(\"${output_bam}\")\n    file(\"${output_bai}\")\n\n    script:\n    output_bam = \"${params.outputBamName}.bam\"\n    output_bai = \"${output_bam}.bai\"\n    \"\"\"\n    samtools merge --threads=\\${NSLOTS:-\\${NTHREADS:-1}} - *.bam | \\\n    samtools sort --threads=\\${NSLOTS:-\\${NTHREADS:-1}} > \"${output_bam}\"\n    samtools index \"${output_bam}\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    output_bam = \"${params.outputBamName}.bam\"\n    output_bai = \"${output_bam}.bai\"\n    \"\"\"\n    samtools merge --threads=\\${NSLOTS:-\\${NTHREADS:-1}} - *.bam | \\\n    samtools sort --threads=\\${NSLOTS:-\\${NTHREADS:-1}} > \"${output_bam}\"\n    samtools index \"${output_bam}\"\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fixed_header_bams"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "make_ref": {
        "name_process": "make_ref",
        "string_process": "\nprocess make_ref {\n    echo true\n    storeDir \"${params.ref_dir}\"\n\n    input:\n    val(foo) from input_channel\n\n    output:\n    file(\"iGenomes/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/genome.fa\")\n    file(\"iGenomes/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/genome.dict\")\n    file(\"iGenomes/Homo_sapiens/UCSC/hg19/Sequence/WholeGenomeFasta/genome.fa.fai\")\n    file(\"BWA/hg19\")\n    file(\"Illumina/hg19/chrom.sizes\")\n    file(\"msisensor/hg19/microsatellites.list\")\n    file(\"contaminants/trimmomatic.fa\")\n    file(\"gatk-bundle/1000G_phase1.indels.hg19.vcf\")\n    file(\"gatk-bundle/1000G_phase1.indels.hg19.vcf.idx\")\n    file(\"gatk-bundle/Mills_and_1000G_gold_standard.indels.hg19.vcf\")\n    file(\"gatk-bundle/Mills_and_1000G_gold_standard.indels.hg19.vcf.idx\")\n    file(\"gatk-bundle/dbsnp_138.hg19.vcf\")\n    file(\"gatk-bundle/dbsnp_138.hg19.vcf.idx\")\n    file(\"gatk-bundle/dbsnp_138.hg19.vcf.gz\")\n    file(\"gatk-bundle/dbsnp_138.hg19.vcf.gz.tbi\")\n    file(\"hg19/CosmicCodingMuts_v73.hg19.vcf\")\n    file(\"hg19/CosmicCodingMuts_v73.hg19.vcf.idx\")\n    file(\"hg19/common_all_20170710.vcf.gz.tbi\")\n    file(\"hg19/common_all_20170710.vcf.gz\")\n\n    script:\n    \"\"\"\n    wget https://genome.med.nyu.edu/results/external/NYU/snuderllab/ref.tar.gz\n\ttar -xvzf ref.tar.gz\n\trm -f ref.tar.gz\n    mv ref/* .\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    \"\"\"\n    wget https://genome.med.nyu.edu/results/external/NYU/snuderllab/ref.tar.gz\n\ttar -xvzf ref.tar.gz\n\trm -f ref.tar.gz\n    mv ref/* .\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_channel"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "echo true",
            "storeDir \"${params.ref_dir}\""
        ],
        "when": "",
        "stub": ""
    },
    "make_ANNOVAR_db": {
        "name_process": "make_ANNOVAR_db",
        "string_process": "\nprocess make_ANNOVAR_db {\n    tag \"${downdb_param}-${protocol_param}\"\n    echo true\n\n    storeDir \"${params.ANNOVAR_DB_DIR}\"\n\n    input:\n    set val(downdb_param), val(output_file), val(protocol_param), file(annovar_db_dir) from annovar_params.combine(annovar_db_dir)\n\n    output:\n    file(output_name)\n\n    script:\n    output_name = \"${params.ANNOVAR_BUILD_VERSION}_${output_file}\"\n    \"\"\"\n    annotate_variation.pl \\\n    -downdb \\\n    -buildver ${params.ANNOVAR_BUILD_VERSION} \\\n    -webfrom annovar \\\n    \"${downdb_param}\" \\\n    \"${annovar_db_dir}\"\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    output_name = \"${params.ANNOVAR_BUILD_VERSION}_${output_file}\"\n    \"\"\"\n    annotate_variation.pl \\\n    -downdb \\\n    -buildver ${params.ANNOVAR_BUILD_VERSION} \\\n    -webfrom annovar \\\n    \"${downdb_param}\" \\\n    \"${annovar_db_dir}\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "annovar_params",
            "annovar_db_dir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "output_name"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "tag \"${downdb_param}-${protocol_param}\"",
            "echo true",
            "storeDir \"${params.ANNOVAR_DB_DIR}\""
        ],
        "when": "",
        "stub": ""
    },
    "compare_report": {
        "name_process": "compare_report",
        "string_process": "\nprocess compare_report {\n    publishDir \"${outputDirPath}\", mode: 'copy'\n    stageInMode \"copy\"\n\n    input:\n    set file(\"old.unpaired.annot.tsv\"),\n        file(\"new.unpaired.annot.tsv\"),\n        file(\"old.paired.annot.tsv\"),\n        file(\"new.paired.annot.tsv\"),\n        val(old_unpaired_annot_path),\n        val(new_unpaired_annot_path),\n        val(old_paired_annot_path),\n        val(new_paired_annot_path) from old_unpaired_annotations_ch.combine(new_unpaired_annotations_ch)\n                                                .combine(old_paired_annotations_ch)\n                                                .combine(new_paired_annotations_ch)\n                                                .combine(old_unpaired_annotations_path_ch)\n                                                .combine(new_unpaired_annotations_path_ch)\n                                                .combine(old_paired_annotations_path_ch)\n                                                .combine(new_paired_annotations_path_ch)\n    file(report_items: '*') from report_files.collect()\n\n    output:\n    file(\"${html_output}\")\n    file(\"old.unpaired.annot.tsv\")\n    file(\"new.unpaired.annot.tsv\")\n    file(\"old.paired.annot.tsv\")\n    file(\"new.paired.annot.tsv\")\n    file(\"*.tsv\")\n\n    script:\n    html_output = \"comparison.html\"\n    \"\"\"\n    R --vanilla <<E0F\n    rmarkdown::render(\n        input = \"compare.Rmd\",\n    params = list(\n        old_unpaired_annot = \"old.unpaired.annot.tsv\",\n        new_unpaired_annot = \"new.unpaired.annot.tsv\",\n        old_paired_annot = \"old.paired.annot.tsv\",\n        new_paired_annot = \"new.paired.annot.tsv\",\n        old_unpaired_annot_path = \"${old_unpaired_annot_path}\",\n        new_unpaired_annot_path = \"${new_unpaired_annot_path}\",\n        old_paired_annot_path = \"${old_paired_annot_path}\",\n        new_paired_annot_path = \"${new_paired_annot_path}\"\n    ),\n    output_format = \"html_document\",\n    output_file = \"${html_output}\"\n    )\n    E0F\n    \"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "    html_output = \"comparison.html\"\n    \"\"\"\n    R --vanilla <<E0F\n    rmarkdown::render(\n        input = \"compare.Rmd\",\n    params = list(\n        old_unpaired_annot = \"old.unpaired.annot.tsv\",\n        new_unpaired_annot = \"new.unpaired.annot.tsv\",\n        old_paired_annot = \"old.paired.annot.tsv\",\n        new_paired_annot = \"new.paired.annot.tsv\",\n        old_unpaired_annot_path = \"${old_unpaired_annot_path}\",\n        new_unpaired_annot_path = \"${new_unpaired_annot_path}\",\n        old_paired_annot_path = \"${old_paired_annot_path}\",\n        new_paired_annot_path = \"${new_paired_annot_path}\"\n    ),\n    output_format = \"html_document\",\n    output_file = \"${html_output}\"\n    )\n    E0F\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "wossinput",
            "PDEparams"
        ],
        "tools_url": [
            "https://bio.tools/wossinput",
            "https://bio.tools/PDEparams"
        ],
        "tools_dico": [
            {
                "name": "wossinput",
                "uri": "https://bio.tools/wossinput",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0219",
                            "term": "Data submission, annotation and curation"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0958",
                                "term": "Tool metadata"
                            }
                        ]
                    }
                ],
                "description": "Find programs by EDAM input data.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/wossinput.html"
            },
            {
                "name": "PDEparams",
                "uri": "https://bio.tools/PDEparams",
                "topic": [
                    [],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parameter fitting toolbox for partial differential equations in Python.",
                "homepage": "http://github.com/systemsmedicine/PDE_params"
            }
        ],
        "inputs": [
            "old_unpaired_annotations_ch",
            "new_unpaired_annotations_ch",
            "old_paired_annotations_ch",
            "new_paired_annotations_ch",
            "old_unpaired_annotations_path_ch",
            "new_unpaired_annotations_path_ch",
            "old_paired_annotations_path_ch",
            "new_paired_annotations_path_ch",
            "report_files"
        ],
        "nb_inputs": 9,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${outputDirPath}\", mode: 'copy'",
            "stageInMode \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "cnv_reference": {
        "name_process": "cnv_reference",
        "string_process": "\nprocess cnv_reference {\n                                                            \n                                                                     \n    input:\n    set file(bam), file(bed), file(ref_fasta), file(ref_fai), file(ref_dict) from sample_cnv_inputs\n\n    output:\n    file(\"${output_file}\") into cnns_ch\n\n    script:\n    output_file = \"${bam}.cnn\"\n    \"\"\"\n    cnvkit.py batch \\\n    -n \"${bam}\" \\\n    --output-reference \"${output_file}\" \\\n    --targets \"${bed}\" \\\n    --fasta \"${ref_fasta}\" \\\n    -p \\${NSLOTS:-\\${NTHREADS:-1}}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    output_file = \"${bam}.cnn\"\n    \"\"\"\n    cnvkit.py batch \\\n    -n \"${bam}\" \\\n    --output-reference \"${output_file}\" \\\n    --targets \"${bed}\" \\\n    --fasta \"${ref_fasta}\" \\\n    -p \\${NSLOTS:-\\${NTHREADS:-1}}\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_cnv_inputs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "cnns_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "cnv_pooledreference": {
        "name_process": "cnv_pooledreference",
        "string_process": "\nprocess cnv_pooledreference {\n                                              \n    publishDir \"${params.outputDir}\", mode: 'copy'\n\n    input:\n    set file(\"*\"), file(ref_fasta), file(ref_fai), file(ref_dict) from cnn_ref_ch\n\n    output:\n    file(\"${output_file}\")\n\n    script:\n    output_file = \"${params.outputFileName}.cnn\"\n    \"\"\"\n    cnvkit.py reference *.cnn -f \"${ref_fasta}\" -o \"${output_file}\"\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    output_file = \"${params.outputFileName}.cnn\"\n    \"\"\"\n    cnvkit.py reference *.cnn -f \"${ref_fasta}\" -o \"${output_file}\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "cnn_ref_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NYU-Molecular-Pathology__LG-PACT",
        "directive": [
            "publishDir \"${params.outputDir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}