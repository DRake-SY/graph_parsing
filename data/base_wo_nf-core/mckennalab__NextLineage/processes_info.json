{
    "CreateCutSitesFile": {
        "name_process": "CreateCutSitesFile",
        "string_process": "\nprocess CreateCutSitesFile {\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/01_cutSites\"\n\n    input:\n    set sampleId, reference, targets, reads from sample_table_cutsites\n\n    output:\n    set sampleId, \"${sampleId}.fa\", targets, reads, \"${sampleId}.fa.cutSites\", \"${sampleId}.fa.primers\" into reference_pack\n    \n    script:\n    \n    \"\"\"\n    cp ${reference} ${sampleId}.fa\n\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/fasta_to_cutsites.py \\\n        --reference ${sampleId}.fa \\\n        --sites ${targets} \\\n        --forward_primer ${params.primer5} \\\n        --reverse_primer ${params.primer3} \\\n        --CRISPR_type ${params.crispr}\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    cp ${reference} ${sampleId}.fa\n\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/fasta_to_cutsites.py \\\n        --reference ${sampleId}.fa \\\n        --sites ${targets} \\\n        --forward_primer ${params.primer5} \\\n        --reverse_primer ${params.primer3} \\\n        --CRISPR_type ${params.crispr}\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_table_cutsites"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reference_pack"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/01_cutSites\""
        ],
        "when": "",
        "stub": ""
    },
    "FastqcReport": {
        "name_process": "FastqcReport",
        "string_process": "\nprocess FastqcReport {\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/02_fastqc\"\n\n    input:\n    set sampleId, reference, targets, read1, read2 from sample_table_fastqc\n    \n    output:\n    set sampleId, reference, targets, read1, read2, \"${sampleId}_fastqc\" into fastqc_results\n    \n    script:\n    \n    \"\"\"\n    mkdir ${sampleId}_fastqc\n    /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/tools/FastQC/fastqc -o ${sampleId}_fastqc ${read1} ${read2}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    mkdir ${sampleId}_fastqc\n    /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/tools/FastQC/fastqc -o ${sampleId}_fastqc ${read1} ${read2}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "sample_table_fastqc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_results"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/02_fastqc\""
        ],
        "when": "",
        "stub": ""
    },
    "MergeUmis": {
        "name_process": "MergeUmis",
        "string_process": "\nprocess MergeUmis {\n    memory '20 GB'\n    beforeScript 'chmod o+rw .'\n                            \n    publishDir \"$results_path/03_umi_collapse\"\n\n    when:\n    params.umiLength\n\n    input:\n    set sampleId, reference, targets, read1, read2, cutsites, primers from reference_pack\n\n    output:\n    set sampleId, reference, targets, \"${sampleId}_read1.fq.gz\", \"${sampleId}_read2.fq.gz\", cutsites, primers into extracted_umis\n    tuple sampleId, \"${sampleId}_read1.fq.gz\", \"${sampleId}_read2.fq.gz\", \"${sampleId}.umiCounts\" into extracted_umis_stats\n\n    script:\n\n    \"\"\"\n    \n    java -jar -Xmx16g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/bin/MergeAndCall.jar \\\n    UMIMerge \\\n    -inputReads1=${read1} \\\n    -inputReads2=${read2} \\\n    -umiStart=${params.umiStart} \\\n    -minimumUMIReads=${params.minUMIReadCount} \\\n    -umiLength=${params.umiLength} \\\n    -umiStatsFile=${sampleId}.umiCounts \\\n    -primers=${primers} \\\n    -primersToCheck=${params.primersToCheck} \\\n    -primerMismatches=${params.primerMismatchCount} \\\n    -outputReads1=${sampleId}_read1.fq.gz \\\n    -outputReads2=${sampleId}_read2.fq.gz\n\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    \"\"\"\n    \n    java -jar -Xmx16g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/bin/MergeAndCall.jar \\\n    UMIMerge \\\n    -inputReads1=${read1} \\\n    -inputReads2=${read2} \\\n    -umiStart=${params.umiStart} \\\n    -minimumUMIReads=${params.minUMIReadCount} \\\n    -umiLength=${params.umiLength} \\\n    -umiStatsFile=${sampleId}.umiCounts \\\n    -primers=${primers} \\\n    -primersToCheck=${params.primersToCheck} \\\n    -primerMismatches=${params.primerMismatchCount} \\\n    -outputReads1=${sampleId}_read1.fq.gz \\\n    -outputReads2=${sampleId}_read2.fq.gz\n\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reference_pack"
        ],
        "nb_inputs": 1,
        "outputs": [
            "extracted_umis",
            "extracted_umis_stats"
        ],
        "nb_outputs": 2,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "memory '20 GB'",
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/03_umi_collapse\""
        ],
        "when": "params.umiLength",
        "stub": ""
    },
    "MergeReads": {
        "name_process": "MergeReads",
        "string_process": "\nprocess MergeReads {\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/03_ng_trim\"\n\n    input:\n    set sampleId, umi, umiLength, reference, targets, fwd, rev, read1, read2 from sample_table_filter\n    \n    output:\n    set sampleId, \"${sampleId}_merged.fastq.gz\", \"${sampleId}_single_1.fastq.gz\", \"${sampleId}_single_2.fastq.gz\" into merged_reads\n    \n    script:\n    \n    \"\"\"\n    /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/tools/NGmerge-0.3/NGmerge \\\n    -1 ${read1} -2 ${read2} -o ${sampleId}_merged.fastq -f ${sampleId}_single\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/tools/NGmerge-0.3/NGmerge \\\n    -1 ${read1} -2 ${read2} -o ${sampleId}_merged.fastq -f ${sampleId}_single\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_table_filter"
        ],
        "nb_inputs": 1,
        "outputs": [
            "merged_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/03_ng_trim\""
        ],
        "when": "",
        "stub": ""
    },
    "InterleaveUnmergedReads": {
        "name_process": "InterleaveUnmergedReads",
        "string_process": "\nprocess InterleaveUnmergedReads {\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/04_interleaved\"\n\n    input:\n    set sampleId, merged, read1, read2 from merged_reads\n    \n    output:\n    set sampleId, merged, \"${sampleId}_interleaved.fq.gz\" into merged_and_interleaved_reads\n    \n    script:\n    \n    \"\"\"\n    scala /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/zip_two_read_files.scala \\\n    ${read1} ${read2} ${sampleId}_interleaved.fq _ _\n    gzip ${sampleId}_interleaved.fq\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    scala /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/zip_two_read_files.scala \\\n    ${read1} ${read2} ${sampleId}_interleaved.fq _ _\n    gzip ${sampleId}_interleaved.fq\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "merged_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "merged_and_interleaved_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/04_interleaved\""
        ],
        "when": "",
        "stub": ""
    },
    "AlignReads": {
        "name_process": "AlignReads",
        "string_process": "\nprocess AlignReads {\n    memory '12 GB'\n    time '12h'\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/02_alignment\"\n    \n    input:\n    set sampleId, reference, targets, mergedReads, cutsites, primers from reference_pack\n    \n    output:\n    set sampleId, reference, targets, \"${sampleId}.merged.fasta.gz\", cutsites, primers into aligned_reads\n    \n    script:\n\n    \"\"\"\n    cp ${mergedReads} merged.fastq.gz\n    gunzip merged.fastq.gz\n\n    scala -J-Xmx8g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/align_merged_reads.scala \\\n    /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/resources/EDNAFULL.Ns_are_zero \\\n    ${params.aligner} \\\n    merged.fastq \\\n    ${reference} \\\n    ${sampleId}.merged.fasta \\\n    10 \\\n    0.5 \\\n    FALSE \n\n\n    gzip ${sampleId}.merged.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    cp ${mergedReads} merged.fastq.gz\n    gunzip merged.fastq.gz\n\n    scala -J-Xmx8g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/align_merged_reads.scala \\\n    /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/resources/EDNAFULL.Ns_are_zero \\\n    ${params.aligner} \\\n    merged.fastq \\\n    ${reference} \\\n    ${sampleId}.merged.fasta \\\n    10 \\\n    0.5 \\\n    FALSE \n\n\n    gzip ${sampleId}.merged.fasta\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reference_pack"
        ],
        "nb_inputs": 1,
        "outputs": [
            "aligned_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "memory '12 GB'",
            "time '12h'",
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/02_alignment\""
        ],
        "when": "",
        "stub": ""
    },
    "CallEvents": {
        "name_process": "CallEvents",
        "string_process": "\nprocess CallEvents {\n    memory '12 GB'\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/03_event_calls\"\n\n    input:\n    set sampleId, reference, targets, merged_aligned_reads, cutsites, primers from aligned_reads\n    \n    \n    output:\n    set sampleId, reference, targets, \"${sampleId}.stats.gz\", cutsites, primers into(stats_output,stats_for_base_calls)\n    path \"${sampleId}.stats.gz\" into stats_file_eval\n\n    script:\n\n    \"\"\"\n    cp ${merged_aligned_reads} merged.fasta.gz\n    gunzip merged.fasta.gz\n\n    java -jar -Xmx11g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/bin/MergeAndCall.jar \\\n    DeepSeq \\\n    -inputMerged=merged.fasta \\\n    -cutSites=${cutsites} \\\n    -outputStats=${sampleId}.stats \\\n    -primersEachEnd=${primers} \\\n    -primerMismatches=${params.primerMismatchCount} \\\n    -primersToCheck=${params.primersToCheck} \\\n    -requiredMatchingProp=${params.alignmentThreshold} \\\n    -requiredRemainingBases=${params.minimumReadLength} \\\n    -cutsiteWindow=5\n\n    rm merged.fasta\n\n    gzip ${sampleId}.stats\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    \"\"\"\n    cp ${merged_aligned_reads} merged.fasta.gz\n    gunzip merged.fasta.gz\n\n    java -jar -Xmx11g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/bin/MergeAndCall.jar \\\n    DeepSeq \\\n    -inputMerged=merged.fasta \\\n    -cutSites=${cutsites} \\\n    -outputStats=${sampleId}.stats \\\n    -primersEachEnd=${primers} \\\n    -primerMismatches=${params.primerMismatchCount} \\\n    -primersToCheck=${params.primersToCheck} \\\n    -requiredMatchingProp=${params.alignmentThreshold} \\\n    -requiredRemainingBases=${params.minimumReadLength} \\\n    -cutsiteWindow=5\n\n    rm merged.fasta\n\n    gzip ${sampleId}.stats\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "DeepSeqPanII"
        ],
        "tools_url": [
            "https://bio.tools/DeepSeqPanII"
        ],
        "tools_dico": [
            {
                "name": "DeepSeqPanII",
                "uri": "https://bio.tools/DeepSeqPanII",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2830",
                            "term": "Immunoproteins and antigens"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3439",
                                    "term": "Pathway or network prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0416",
                                    "term": "Epitope mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Peptide immunogenicity prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0416",
                                    "term": "Antibody epitope prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0416",
                                    "term": "Epitope prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Immunogenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Antigenicity prediction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An interpretable recurrent neural network model with attention mechanism for peptide-HLA class II binding prediction. A sequence-based pan model for peptide-MHC II binding affinity prediction.",
                "homepage": "https://github.com/pcpLiu/DeepSeqPanII"
            }
        ],
        "inputs": [
            "aligned_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "sampleId",
            "stats_file_eval"
        ],
        "nb_outputs": 2,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "memory '12 GB'",
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/03_event_calls\""
        ],
        "when": "",
        "stub": ""
    },
    "BreakdownFiles": {
        "name_process": "BreakdownFiles",
        "string_process": "\nprocess BreakdownFiles {\n    beforeScript 'chmod o+rw .'\n    errorStrategy 'ignore'\n    publishDir \"$results_path/04_breakdown_files\"\n\n    input:\n    set sampleId, reference, targets, stats, cutsites, primers from stats_output\n    \n    output:\n    tuple sampleId, reference, targets, \"${sampleId}.perBase\", \"${sampleId}.topReadEvents\", \"${sampleId}.topReadEventsNew\", \"${sampleId}.topReadCounts\", \"${sampleId}.allReadCounts\", cutsites into breakdown_files\n    \n    script:\n\n    \"\"\"\n    cp ${stats} ./sample.stats.gz\n    gunzip ./sample.stats.gz\n\n    scala -J-Xmx4g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/stats_to_javascript_tables.scala \\\n    sample.stats \\\n    ${sampleId}.perBase \\\n    ${sampleId}.topReadEvents \\\n    ${sampleId}.topReadCounts \\\n    ${sampleId}.allReadCounts \\\n    ${cutsites} \\\n    ${sampleId}.topReadEventsNew \\\n    ${params.convert_unknown_to_none} \\\n    ${reference}\n\n    rm sample.stats\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    cp ${stats} ./sample.stats.gz\n    gunzip ./sample.stats.gz\n\n    scala -J-Xmx4g /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/stats_to_javascript_tables.scala \\\n    sample.stats \\\n    ${sampleId}.perBase \\\n    ${sampleId}.topReadEvents \\\n    ${sampleId}.topReadCounts \\\n    ${sampleId}.allReadCounts \\\n    ${cutsites} \\\n    ${sampleId}.topReadEventsNew \\\n    ${params.convert_unknown_to_none} \\\n    ${reference}\n\n    rm sample.stats\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "stats_output"
        ],
        "nb_inputs": 1,
        "outputs": [
            "breakdown_files"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "beforeScript 'chmod o+rw .'",
            "errorStrategy 'ignore'",
            "publishDir \"$results_path/04_breakdown_files\""
        ],
        "when": "",
        "stub": ""
    },
    "StatsAssessment": {
        "name_process": "StatsAssessment",
        "string_process": "\nprocess StatsAssessment {\n    publishDir \"$results_path/05_stats_assessment\"\n\n    input:\n    file stats from stats_file_eval.toList()\n\n    output:\n    path \"stat_meta_qc_assessment_mqc.tsv\" into stats_assessment_qc\n    path \"target_assessment_mqc.tsv\" into stats_assessment_targets\n    \n    script:\n\n    \"\"\"\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/stats_qc.py \\\n    --stats ${stats.collect().join(\",\")} \\\n    --output_edits target_assessment_mqc.tsv \\\n    --output_stats stat_meta_qc_assessment_mqc.tsv\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/stats_qc.py \\\n    --stats ${stats.collect().join(\",\")} \\\n    --output_edits target_assessment_mqc.tsv \\\n    --output_stats stat_meta_qc_assessment_mqc.tsv\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "stats_file_eval"
        ],
        "nb_inputs": 1,
        "outputs": [
            "stats_assessment_qc",
            "stats_assessment_targets"
        ],
        "nb_outputs": 2,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "publishDir \"$results_path/05_stats_assessment\""
        ],
        "when": "",
        "stub": ""
    },
    "CreateSamplePlot": {
        "name_process": "CreateSamplePlot",
        "string_process": "\nprocess CreateSamplePlot {\n    publishDir \"$results_path/06_sample_plot\"\n\n    input:\n    tuple sample, reference, targets, perBase, topReadEvents, topReadEventsNew, topReadCounts, allReadCounts, cutsites from breakdown_files\n\n    output:\n    path \"${sample}/read_editing_mutlihistogram.html\" into html_file\n    path \"${sample}/read_editing_mutlihistogram.js\" into js_file\n    path \"${sample}/JS_files.js\" into js_vars\n    tuple \"${sample}/${sample}.perBase\", \"${sample}/${sample}.topReadEvents\", \"${sample}/${sample}.topReadEventsNew\", \"${sample}/${sample}.topReadCounts\", \"${sample}/${sample}.allReadCounts\", \"${sample}/${sample}.cutSites\" into per_base_info\n    tuple sample, \"${sample}/\" into sample_dir\n    \n    script:\n    \"\"\"\n\n    mkdir ${sample}\n    cp /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/resources/plots/cas12a/read_editing_mutlihistogram.html ./${sample}/\n    cp /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/resources/plots/cas12a/read_editing_mutlihistogram.js ./${sample}/\n\n    cp ${perBase} ${sample}/${sample}.perBase\n    cp ${topReadEvents} ${sample}/${sample}.topReadEvents\n    cp ${topReadEventsNew} ${sample}/${sample}.topReadEventsNew\n    cp ${topReadCounts} ${sample}/${sample}.topReadCounts\n    cp ${allReadCounts} ${sample}/${sample}.allReadCounts\n    cp ${cutsites} ${sample}/${sample}.cutSites\n\n    echo var occurance_file = \\\\\"${sample}.topReadCounts\\\\\" >> ${sample}/JS_files.js\n    echo var top_read_melted_to_base = \\\\\"${sample}.topReadEventsNew\\\\\" >> ${sample}/JS_files.js\n    echo var per_base_histogram_data = \\\\\"${sample}.perBase\\\\\" >> ${sample}/JS_files.js\n    echo var cut_site_file = \\\\\"${sample}.cutSites\\\\\" >> ${sample}/JS_files.js\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/copy_to_web.py --input_dir ./${sample}/ --sample ${sample} --project ${params.project} --webdir ${params.webdir}\n\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n\n    mkdir ${sample}\n    cp /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/resources/plots/cas12a/read_editing_mutlihistogram.html ./${sample}/\n    cp /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/resources/plots/cas12a/read_editing_mutlihistogram.js ./${sample}/\n\n    cp ${perBase} ${sample}/${sample}.perBase\n    cp ${topReadEvents} ${sample}/${sample}.topReadEvents\n    cp ${topReadEventsNew} ${sample}/${sample}.topReadEventsNew\n    cp ${topReadCounts} ${sample}/${sample}.topReadCounts\n    cp ${allReadCounts} ${sample}/${sample}.allReadCounts\n    cp ${cutsites} ${sample}/${sample}.cutSites\n\n    echo var occurance_file = \\\\\"${sample}.topReadCounts\\\\\" >> ${sample}/JS_files.js\n    echo var top_read_melted_to_base = \\\\\"${sample}.topReadEventsNew\\\\\" >> ${sample}/JS_files.js\n    echo var per_base_histogram_data = \\\\\"${sample}.perBase\\\\\" >> ${sample}/JS_files.js\n    echo var cut_site_file = \\\\\"${sample}.cutSites\\\\\" >> ${sample}/JS_files.js\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/copy_to_web.py --input_dir ./${sample}/ --sample ${sample} --project ${params.project} --webdir ${params.webdir}\n\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "breakdown_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "html_file",
            "js_file",
            "js_vars",
            "per_base_info",
            "sample_dir"
        ],
        "nb_outputs": 5,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "publishDir \"$results_path/06_sample_plot\""
        ],
        "when": "",
        "stub": ""
    },
    "FilterGenomicReads": {
        "name_process": "FilterGenomicReads",
        "string_process": "\nprocess FilterGenomicReads {    \n    memory '32 GB'\n    errorStrategy 'ignore'\n    cpus params.cpu_count\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/03_filter_genomic_reads\"\n\n    input:\n    set sampleId, reference, targets, read, barcode, umi, cutsites, primers from reference_pack\n    \n    output:\n    set sampleId, reference, targets, \"${sampleId}.read.fq.gz\", \"${sampleId}.barcode.fq.gz\", cutsites, primers into filtered_reads\n    file \"${sampleId}_pre_post_reads.txt\" into filtered_reads_analysis\n    \n    script:\n    \n    umi_string = \"--umi \" + umi\n    fl = file(umi)\n    if (!fl.exists()) {\n        umi_string = \"\"\n    }\n\n    \"\"\"\n    zcat ${read}| wc > ${sampleId}.pre.reads.txt\n\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/filter_by_alignment.py \\\n    --reference_genome ${params.organism_reference} \\\n    --reference_gestalt_name ${params.bait_seq_name} \\\n    --read1 ${read} \\\n    --cpus ${params.cpu_count} \\\n    --barcode ${barcode} \\\n    --output_sample_prefix ${sampleId} \\\n    ${umi_string}\n\n    rm temp.sam\n    zcat ${sampleId}.read.fq.gz | wc > ${sampleId}.post.reads.txt\n    cat ${sampleId}.pre.reads.txt ${sampleId}.post.reads.txt > ${sampleId}_pre_post_reads.txt\n    \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "    umi_string = \"--umi \" + umi\n    fl = file(umi)\n    if (!fl.exists()) {\n        umi_string = \"\"\n    }\n\n    \"\"\"\n    zcat ${read}| wc > ${sampleId}.pre.reads.txt\n\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/filter_by_alignment.py \\\n    --reference_genome ${params.organism_reference} \\\n    --reference_gestalt_name ${params.bait_seq_name} \\\n    --read1 ${read} \\\n    --cpus ${params.cpu_count} \\\n    --barcode ${barcode} \\\n    --output_sample_prefix ${sampleId} \\\n    ${umi_string}\n\n    rm temp.sam\n    zcat ${sampleId}.read.fq.gz | wc > ${sampleId}.post.reads.txt\n    cat ${sampleId}.pre.reads.txt ${sampleId}.post.reads.txt > ${sampleId}_pre_post_reads.txt\n    \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "FLS"
        ],
        "tools_url": [
            "https://bio.tools/FLS"
        ],
        "tools_dico": [
            {
                "name": "FLS",
                "uri": "https://bio.tools/FLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3407",
                            "term": "Endocrinology and metabolism"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatric medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3390",
                            "term": "Nutritional science"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3407",
                            "term": "https://en.wikipedia.org/wiki/Endocrinology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "https://en.wikipedia.org/wiki/Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3390",
                            "term": "Nutrition science"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3390",
                            "term": "Nutrition"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3503",
                                    "term": "Incident curve plotting"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> LOW CONFIDENCE! | > HOMEPAGE MISSING! | Fracture liaison service and mortality in elderly hip fracture patients | Osteoporosis is a metabolic disorder that results in increased bone fragility and risk of fractures. Hip fracture is the most important fragility fracture. Fracture Liaison Service (FLS) is a secondary prevention model which identifies patients at risk for fragility fractures. The introduction of an intensive FLS model could decrease 1-year-mortality of hip fracture patients. INTRODUCTION:Hip fractures are a clinical manifestation of osteoporosis, and these patients are at risk of premature death and suffering subsequent fractures. FLS is an approach for secondary facture prevention by identifying patients with fragility fractures and initiating the appropriate treatment. Our objective is to analyze the effect of the FLS model over the first-year mortality rates following a hip fracture",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31511912"
            }
        ],
        "inputs": [
            "reference_pack"
        ],
        "nb_inputs": 1,
        "outputs": [
            "filtered_reads",
            "filtered_reads_analysis"
        ],
        "nb_outputs": 2,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "memory '32 GB'",
            "errorStrategy 'ignore'",
            "cpus params.cpu_count",
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/03_filter_genomic_reads\""
        ],
        "when": "",
        "stub": ""
    },
    "MoveFirstRead": {
        "name_process": "MoveFirstRead",
        "string_process": "\nprocess MoveFirstRead {\n    memory '8 GB'\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/04_collapse_to_sequence\"\n\n    input:\n    set sampleId, reference, targets, read, barcode, cutsites, primers from filtered_reads\n    \n    output:\n    set sampleId, reference, targets, \"${sampleId}.umiMerged.fastq.gz\", cutsites, primers into combined_reads\n\n    script:\n    \"\"\"\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/attach_read_UMIs.py --read1 ${read} --barcode ${barcode} --trimbases ${params.trim_read_bases} --outputfastq ${sampleId}.umiMerged.fastq.gz\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/attach_read_UMIs.py --read1 ${read} --barcode ${barcode} --trimbases ${params.trim_read_bases} --outputfastq ${sampleId}.umiMerged.fastq.gz\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filtered_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "combined_reads"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "memory '8 GB'",
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/04_collapse_to_sequence\""
        ],
        "when": "",
        "stub": ""
    },
    "ExtractUmis": {
        "name_process": "ExtractUmis",
        "string_process": "\nprocess ExtractUmis {\n    memory '20 GB'\n    beforeScript 'chmod o+rw .'\n                            \n    publishDir \"$results_path/05_umi_collapse\"\n\n    input:\n    set sampleId, reference, targets, combined_reads, cutsites, primers from combined_reads\n\n    output:\n    set sampleId, reference, targets, \"${sampleId}.fasta\", cutsites, primers into extracted_umis\n    tuple sampleId, \"${sampleId}.fasta\", \"${sampleId}.umiCounts\" into extracted_umis_stats\n\n    script:\n\n    \"\"\"\n    \n    java -jar -Xmx16g /dartfs/rc/lab/M/McKennaLab/resources/GESTALT/SingleCellLineage/UMIMerge/target/scala-2.12/MergeAndCall.jar \\\n    UMIMerge \\\n    -inputReads1=${combined_reads} \\\n    -umiStart=${params.umiStart} \\\n    -minimumUMIReads=${params.minUMIReadCount} \\\n    -umiLength=${params.umiLength} \\\n    -umiStatsFile=${sampleId}.umiCounts \\\n    -primers=${primers} \\\n    -primersToCheck=${params.primersToCheck} \\\n    -primerMismatches=${params.primerMismatchCount} \\\n    -outputReads1=${sampleId}.fasta\n\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    \n    java -jar -Xmx16g /dartfs/rc/lab/M/McKennaLab/resources/GESTALT/SingleCellLineage/UMIMerge/target/scala-2.12/MergeAndCall.jar \\\n    UMIMerge \\\n    -inputReads1=${combined_reads} \\\n    -umiStart=${params.umiStart} \\\n    -minimumUMIReads=${params.minUMIReadCount} \\\n    -umiLength=${params.umiLength} \\\n    -umiStatsFile=${sampleId}.umiCounts \\\n    -primers=${primers} \\\n    -primersToCheck=${params.primersToCheck} \\\n    -primerMismatches=${params.primerMismatchCount} \\\n    -outputReads1=${sampleId}.fasta\n\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "combined_reads"
        ],
        "nb_inputs": 1,
        "outputs": [
            "extracted_umis",
            "extracted_umis_stats"
        ],
        "nb_outputs": 2,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "memory '20 GB'",
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/05_umi_collapse\""
        ],
        "when": "",
        "stub": ""
    },
    "ReadFilterQC": {
        "name_process": "ReadFilterQC",
        "string_process": "\nprocess ReadFilterQC {\n    memory '4 GB'\n    beforeScript 'chmod o+rw .'\n\n    publishDir \"$results_path/09_read_filter_assessment\"\n\n    input:\n    file pre_post from filtered_reads_analysis.toList()\n    \n    output:\n    path \"genome_filter_assessment_mqc.tsv\" into read_filter_assessment\n    \n    script:\n\n    \"\"\"\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/read_qc.py \\\n    --pre_post_stats ${pre_post.collect().join(\",\")} \\\n    --output genome_filter_assessment_mqc.tsv\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    python /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/read_qc.py \\\n    --pre_post_stats ${pre_post.collect().join(\",\")} \\\n    --output genome_filter_assessment_mqc.tsv\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "filtered_reads_analysis"
        ],
        "nb_inputs": 1,
        "outputs": [
            "read_filter_assessment"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "memory '4 GB'",
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/09_read_filter_assessment\""
        ],
        "when": "",
        "stub": ""
    },
    "CallBaseEdits": {
        "name_process": "CallBaseEdits",
        "string_process": "\nprocess CallBaseEdits {\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/07_base_editing\"\n\n    input:\n    tuple sampleId, reference, targets, stats, cutsites, primers from stats_for_base_calls\n    \n    output:\n    tuple sampleId, \"${sampleId}.baseEditCalls\" into basecalls\n    \n    script:\n\n    \"\"\"\n    cp ${stats} ./sample.stats.gz\n    gunzip ./sample.stats.gz\n\n    bash /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/base_editing_multi_target_analysis.sh \\\n    sample.stats \\\n    ${sampleId} \\\n    ${sampleId}.baseEditCalls \\\n    ${cutsites}\n\n    rm sample.stats\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    cp ${stats} ./sample.stats.gz\n    gunzip ./sample.stats.gz\n\n    bash /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/base_editing_multi_target_analysis.sh \\\n    sample.stats \\\n    ${sampleId} \\\n    ${sampleId}.baseEditCalls \\\n    ${cutsites}\n\n    rm sample.stats\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "stats_for_base_calls"
        ],
        "nb_inputs": 1,
        "outputs": [
            "basecalls"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/07_base_editing\""
        ],
        "when": "",
        "stub": ""
    },
    "BaseEditingSummary": {
        "name_process": "BaseEditingSummary",
        "string_process": "\nprocess BaseEditingSummary {\n    beforeScript 'chmod o+rw .'\n    publishDir \"$results_path/08_base_summary\"\n\n    input:\n    tuple sampleId, baseEditing from basecalls\n    \n    output:\n    tuple sampleId, \"${sampleId}_editing_summary.txt\", \"${sampleId}_editing_positions.txt\" into baseEditingSummary\n    \n    script:\n\n    \"\"\"\n    Rscript /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/base_editing_summary.R \\\n    ${sampleId} \\\n    ${baseEditing}\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    Rscript /dartfs/rc/lab/M/McKennaLab/projects/nextflow_lineage/src/base_editing_summary.R \\\n    ${sampleId} \\\n    ${baseEditing}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "basecalls"
        ],
        "nb_inputs": 1,
        "outputs": [
            "baseEditingSummary"
        ],
        "nb_outputs": 1,
        "name_workflow": "mckennalab__NextLineage",
        "directive": [
            "beforeScript 'chmod o+rw .'",
            "publishDir \"$results_path/08_base_summary\""
        ],
        "when": "",
        "stub": ""
    }
}