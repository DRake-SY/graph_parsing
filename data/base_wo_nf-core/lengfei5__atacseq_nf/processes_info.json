{
    "splitfastq": {
        "name_process": "splitfastq",
        "string_process": "\nprocess splitfastq {\n    tag \"Channel: ${name}\"\n\n    publishDir \"${params.outdir}/FASTQs\", mode: 'copy', pattern: '*.fastq'\n\n    input:\n        set val(name), file(bam) from read_files\n\n    output:\n        set name, file(\"*.fastq\") into fastq_split\n        set name, file(\"cntTotal.txt\") into cnt_total\n    script:\n    \"\"\"\n        module load bedtools/2.25.0-foss-2018b\n        ml load samtools/1.10-foss-2018b\n        samtools view -c ${bam} > cntTotal.txt\n        bamToFastq -i ${bam} -fq ${name}.fastq\n\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n        module load bedtools/2.25.0-foss-2018b\n        ml load samtools/1.10-foss-2018b\n        samtools view -c ${bam} > cntTotal.txt\n        bamToFastq -i ${bam} -fq ${name}.fastq\n\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "MLC",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/MLC",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "MLC",
                "uri": "https://bio.tools/MLC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Expression correlation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3766",
                                    "term": "Weighted correlation network analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Over-representation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Co-expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3766",
                                    "term": "WGCNA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3766",
                                    "term": "Weighted gene co-expression network analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Metric Learning on Expression Data for Gene Function Prediction.",
                "homepage": "http://www.github.com/stamakro/MLC"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "read_files"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastq_split",
            "cnt_total"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/FASTQs\", mode: 'copy', pattern: '*.fastq'"
        ],
        "when": "",
        "stub": ""
    },
    "cutadapt": {
        "name_process": "cutadapt",
        "string_process": "\nprocess  cutadapt {\n    tag \"Channel: ${name}\"\n\n    publishDir \"${params.outdir}/cutadapt\", mode: 'copy', pattern: '*.err'\n\n    input:\n        set val(name), file(fastq) from fastq_split\n\n    output:\n        set name, file(\"cutadapt.fastq\") into fastq_cutadapt, fastq_cutadapt2\n        set name, file(\"cutadapt.${name}.err\") into stat_cutadapt\n        set name, file(\"cnt_cutadapt.txt\") into cnt_cutadapt\n\n    script:\n    \"\"\"\n        PYTHON_EGG_CACHE=`pwd` #cutadapt wants to write into home FIXME\n        export PYTHON_EGG_CACHE\n        perl ${baseDir}/scripts/extract.unaligned.pl -b ${bam} -f ${fastq} > cleanReads.fastq\n        samtools view -c ${bam} > cntTotal.txt\n        bamToFastq -i ${bam} -fq /dev/stdout |\\\n            cutadapt -e ${params.adapterER} -a ${params.adapter} -f fastq -o cutadapt.fastq -O ${params.adapterMin} --discard-untrimmed - > cutadapt.${name}.err\n\n        cat cutadapt.fastq | paste - - - - | wc -l > cnt_cutadapt.txt\n\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n        PYTHON_EGG_CACHE=`pwd` #cutadapt wants to write into home FIXME\n        export PYTHON_EGG_CACHE\n        perl ${baseDir}/scripts/extract.unaligned.pl -b ${bam} -f ${fastq} > cleanReads.fastq\n        samtools view -c ${bam} > cntTotal.txt\n        bamToFastq -i ${bam} -fq /dev/stdout |\\\n            cutadapt -e ${params.adapterER} -a ${params.adapter} -f fastq -o cutadapt.fastq -O ${params.adapterMin} --discard-untrimmed - > cutadapt.${name}.err\n\n        cat cutadapt.fastq | paste - - - - | wc -l > cnt_cutadapt.txt\n\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "Cutadapt"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/cutadapt"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "Cutadapt",
                "uri": "https://bio.tools/cutadapt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3495",
                                "term": "RNA sequence"
                            }
                        ]
                    }
                ],
                "description": "Find and remove adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads.",
                "homepage": "https://pypi.python.org/pypi/cutadapt"
            }
        ],
        "inputs": [
            "fastq_split"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastq_cutadapt",
            "fastq_cutadapt2",
            "stat_cutadapt",
            "cnt_cutadapt"
        ],
        "nb_outputs": 4,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"Channel: ${name}\"",
            "publishDir \"${params.outdir}/cutadapt\", mode: 'copy', pattern: '*.err'"
        ],
        "when": "",
        "stub": ""
    },
    "CHECK_DESIGN": {
        "name_process": "CHECK_DESIGN",
        "string_process": "\nprocess CHECK_DESIGN {\n    tag \"$design\"\n    publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode\n\n    input:\n    path design from ch_input\n\n    output:\n    path '*.csv' into ch_design_reads_csv\n\n    script:                                                                      \n    \"\"\"\n    check_design.py $design design_reads.csv\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    check_design.py $design design_reads.csv\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_input"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_design_reads_csv"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$design\"",
            "publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "BWA_INDEX": {
        "name_process": "BWA_INDEX",
        "string_process": " process BWA_INDEX {\n        tag \"$fasta\"\n        label 'process_high'\n        publishDir path: { params.save_reference ? \"${params.outdir}/genome\" : params.outdir },\n            saveAs: { params.save_reference ? it : null }, mode: params.publish_dir_mode\n\n        input:\n        path fasta from ch_fasta\n\n        output:\n        path 'BWAIndex' into ch_bwa_index\n\n        script:\n        \"\"\"\n        bwa index -a bwtsw $fasta\n        mkdir BWAIndex && mv ${fasta}* BWAIndex\n        \"\"\"\n    }",
        "nb_lignes_process": 16,
        "string_script": "        \"\"\"\n        bwa index -a bwtsw $fasta\n        mkdir BWAIndex && mv ${fasta}* BWAIndex\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "BWA"
        ],
        "tools_url": [
            "https://bio.tools/bwa"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            }
        ],
        "inputs": [
            "ch_fasta"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_bwa_index"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$fasta\"",
            "label 'process_high'",
            "publishDir path: { params.save_reference ? \"${params.outdir}/genome\" : params.outdir } , saveAs: { params.save_reference ? it : null }, mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "MAKE_GENE_BED": {
        "name_process": "MAKE_GENE_BED",
        "string_process": " process MAKE_GENE_BED {\n        tag \"$gtf\"\n        label 'process_low'\n        publishDir \"${params.outdir}/genome\", mode: params.publish_dir_mode\n\n        input:\n        path gtf from ch_gtf\n\n        output:\n        path '*.bed' into ch_gene_bed\n\n        script:                                                                     \n        \"\"\"\n        gtf2bed $gtf > ${gtf.baseName}.bed\n        \"\"\"\n    }",
        "nb_lignes_process": 14,
        "string_script": "        \"\"\"\n        gtf2bed $gtf > ${gtf.baseName}.bed\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_gtf"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_gene_bed"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$gtf\"",
            "label 'process_low'",
            "publishDir \"${params.outdir}/genome\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "MAKE_TSS_BED": {
        "name_process": "MAKE_TSS_BED",
        "string_process": " process MAKE_TSS_BED {\n        tag \"$bed\"\n        publishDir \"${params.outdir}/genome\", mode: params.publish_dir_mode\n\n        input:\n        path bed from ch_gene_bed\n\n        output:\n        path '*.bed' into ch_tss_bed\n\n        script:\n        \"\"\"\n        cat $bed | awk -v FS='\\t' -v OFS='\\t' '{ if(\\$6==\"+\") \\$3=\\$2+1; else \\$2=\\$3-1; print \\$1, \\$2, \\$3, \\$4, \\$5, \\$6;}' > ${bed.baseName}.tss.bed\n        \"\"\"\n    }",
        "nb_lignes_process": 13,
        "string_script": "        \"\"\"\n        cat $bed | awk -v FS='\\t' -v OFS='\\t' '{ if(\\$6==\"+\") \\$3=\\$2+1; else \\$2=\\$3-1; print \\$1, \\$2, \\$3, \\$4, \\$5, \\$6;}' > ${bed.baseName}.tss.bed\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_gene_bed"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_tss_bed"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$bed\"",
            "publishDir \"${params.outdir}/genome\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "MAKE_GENOME_FILTER": {
        "name_process": "MAKE_GENOME_FILTER",
        "string_process": "\nprocess MAKE_GENOME_FILTER {\n    tag \"$fasta\"\n    publishDir \"${params.outdir}/genome\", mode: params.publish_dir_mode\n\n    input:\n    path fasta from ch_fasta\n    path blacklist from ch_blacklist.ifEmpty([])\n\n    output:\n    path \"$fasta\"                                                           \n    path '*.fai'                                                                        \n    path '*.bed' into ch_genome_filter_regions                                                                                   \n    path '*.txt' into ch_genome_autosomes                                                                                \n    path '*.sizes' into ch_genome_sizes_mlib_bigwig,                                        \n                        ch_genome_sizes_mrep_bigwig\n\n    script:\n    blacklist_filter = params.blacklist ? \"sortBed -i $blacklist -g ${fasta}.sizes | complementBed -i stdin -g ${fasta}.sizes\" : \"awk '{print \\$1, '0' , \\$2}' OFS='\\t' ${fasta}.sizes\"\n    name_filter = params.mito_name ? \"| awk '\\$1 !~ /${params.mito_name}/ {print \\$0}'\": ''\n    mito_filter = params.keep_mito ? '' : name_filter\n    \"\"\"\n    samtools faidx $fasta\n    get_autosomes.py ${fasta}.fai ${fasta}.autosomes.txt\n    cut -f 1,2 ${fasta}.fai > ${fasta}.sizes\n    $blacklist_filter $mito_filter > ${fasta}.include_regions.bed\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    blacklist_filter = params.blacklist ? \"sortBed -i $blacklist -g ${fasta}.sizes | complementBed -i stdin -g ${fasta}.sizes\" : \"awk '{print \\$1, '0' , \\$2}' OFS='\\t' ${fasta}.sizes\"\n    name_filter = params.mito_name ? \"| awk '\\$1 !~ /${params.mito_name}/ {print \\$0}'\": ''\n    mito_filter = params.keep_mito ? '' : name_filter\n    \"\"\"\n    samtools faidx $fasta\n    get_autosomes.py ${fasta}.fai ${fasta}.autosomes.txt\n    cut -f 1,2 ${fasta}.fai > ${fasta}.sizes\n    $blacklist_filter $mito_filter > ${fasta}.include_regions.bed\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_fasta",
            "ch_blacklist"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_genome_filter_regions",
            "ch_genome_autosomes",
            "ch_genome_sizes_mlib_bigwig",
            "ch_genome_sizes_mrep_bigwig"
        ],
        "nb_outputs": 4,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$fasta\"",
            "publishDir \"${params.outdir}/genome\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    },
    "FASTQC": {
        "name_process": "FASTQC",
        "string_process": "\nprocess FASTQC {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/fastqc\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      filename.endsWith('.zip') ? \"zips/$filename\" : filename\n                }\n\n    when:\n    !params.skip_fastqc\n\n    input:\n    tuple val(name), path(reads) from ch_raw_reads_fastqc\n\n    output:\n    path '*.{zip,html}' into ch_fastqc_reports_mqc\n\n    script:\n                                                                           \n    if (params.single_end) {\n        \"\"\"\n        [ ! -f  ${name}.fastq.gz ] && ln -s $reads ${name}.fastq.gz\n        fastqc -q -t $task.cpus ${name}.fastq.gz\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${name}_1.fastq.gz ] && ln -s ${reads[0]} ${name}_1.fastq.gz\n        [ ! -f  ${name}_2.fastq.gz ] && ln -s ${reads[1]} ${name}_2.fastq.gz\n        fastqc -q -t $task.cpus ${name}_1.fastq.gz\n        fastqc -q -t $task.cpus ${name}_2.fastq.gz\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 32,
        "string_script": "    if (params.single_end) {\n        \"\"\"\n        [ ! -f  ${name}.fastq.gz ] && ln -s $reads ${name}.fastq.gz\n        fastqc -q -t $task.cpus ${name}.fastq.gz\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${name}_1.fastq.gz ] && ln -s ${reads[0]} ${name}_1.fastq.gz\n        [ ! -f  ${name}_2.fastq.gz ] && ln -s ${reads[1]} ${name}_2.fastq.gz\n        fastqc -q -t $task.cpus ${name}_1.fastq.gz\n        fastqc -q -t $task.cpus ${name}_2.fastq.gz\n        \"\"\"\n    }",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "ch_raw_reads_fastqc"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_fastqc_reports_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/fastqc\", mode: params.publish_dir_mode , saveAs: { filename -> filename.endsWith('.zip') ? \"zips/$filename\" : filename }"
        ],
        "when": "!params.skip_fastqc",
        "stub": ""
    },
    "TRIMGALORE": {
        "name_process": "TRIMGALORE",
        "string_process": " process TRIMGALORE {\n        tag \"$name\"\n        label 'process_high'\n        publishDir \"${params.outdir}/trim_galore\", mode: params.publish_dir_mode,\n            saveAs: { filename ->\n                          if (filename.endsWith('.html')) \"fastqc/$filename\"\n                          else if (filename.endsWith('.zip')) \"fastqc/zips/$filename\"\n                          else if (filename.endsWith('trimming_report.txt')) \"logs/$filename\"\n                          else params.save_trimmed ? filename : null\n                    }\n\n        input:\n        tuple val(name), path(reads) from ch_raw_reads_trimgalore\n\n        output:\n        tuple val(name), path('*.fq.gz') into ch_trimmed_reads\n        path '*.txt' into ch_trimgalore_results_mqc\n        path '*.{zip,html}' into ch_trimgalore_fastqc_reports_mqc\n\n        script:\n                                                                                 \n                                                                                                                     \n                                                          \n        def cores = 1\n        if (task.cpus) {\n            cores = (task.cpus as int) - 4\n            if (params.single_end) cores = (task.cpus as int) - 3\n            if (cores < 1) cores = 1\n            if (cores > 4) cores = 4\n        }\n\n                                                                               \n        c_r1 = params.clip_r1 > 0 ? \"--clip_r1 ${params.clip_r1}\" : ''\n        c_r2 = params.clip_r2 > 0 ? \"--clip_r2 ${params.clip_r2}\" : ''\n        tpc_r1 = params.three_prime_clip_r1 > 0 ? \"--three_prime_clip_r1 ${params.three_prime_clip_r1}\" : ''\n        tpc_r2 = params.three_prime_clip_r2 > 0 ? \"--three_prime_clip_r2 ${params.three_prime_clip_r2}\" : ''\n        nextseq = params.trim_nextseq > 0 ? \"--nextseq ${params.trim_nextseq}\" : ''\n\n                                                                               \n        if (params.single_end) {\n            \"\"\"\n            [ ! -f  ${name}.fastq.gz ] && ln -s $reads ${name}.fastq.gz\n            trim_galore --cores $cores --fastqc --gzip $c_r1 $tpc_r1 $nextseq ${name}.fastq.gz\n            \"\"\"\n        } else {\n            \"\"\"\n            [ ! -f  ${name}_1.fastq.gz ] && ln -s ${reads[0]} ${name}_1.fastq.gz\n            [ ! -f  ${name}_2.fastq.gz ] && ln -s ${reads[1]} ${name}_2.fastq.gz\n            trim_galore --cores $cores --paired --fastqc --gzip $c_r1 $c_r2 $tpc_r1 $tpc_r2 $nextseq ${name}_1.fastq.gz ${name}_2.fastq.gz\n            \"\"\"\n        }\n    }",
        "nb_lignes_process": 50,
        "string_script": "        def cores = 1\n        if (task.cpus) {\n            cores = (task.cpus as int) - 4\n            if (params.single_end) cores = (task.cpus as int) - 3\n            if (cores < 1) cores = 1\n            if (cores > 4) cores = 4\n        }\n\n                                                                               \n        c_r1 = params.clip_r1 > 0 ? \"--clip_r1 ${params.clip_r1}\" : ''\n        c_r2 = params.clip_r2 > 0 ? \"--clip_r2 ${params.clip_r2}\" : ''\n        tpc_r1 = params.three_prime_clip_r1 > 0 ? \"--three_prime_clip_r1 ${params.three_prime_clip_r1}\" : ''\n        tpc_r2 = params.three_prime_clip_r2 > 0 ? \"--three_prime_clip_r2 ${params.three_prime_clip_r2}\" : ''\n        nextseq = params.trim_nextseq > 0 ? \"--nextseq ${params.trim_nextseq}\" : ''\n\n                                                                               \n        if (params.single_end) {\n            \"\"\"\n            [ ! -f  ${name}.fastq.gz ] && ln -s $reads ${name}.fastq.gz\n            trim_galore --cores $cores --fastqc --gzip $c_r1 $tpc_r1 $nextseq ${name}.fastq.gz\n            \"\"\"\n        } else {\n            \"\"\"\n            [ ! -f  ${name}_1.fastq.gz ] && ln -s ${reads[0]} ${name}_1.fastq.gz\n            [ ! -f  ${name}_2.fastq.gz ] && ln -s ${reads[1]} ${name}_2.fastq.gz\n            trim_galore --cores $cores --paired --fastqc --gzip $c_r1 $c_r2 $tpc_r1 $tpc_r2 $nextseq ${name}_1.fastq.gz ${name}_2.fastq.gz\n            \"\"\"\n        }",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [
            "CoreSlicer"
        ],
        "tools_url": [
            "https://bio.tools/CoreSlicer"
        ],
        "tools_dico": [
            {
                "name": "CoreSlicer",
                "uri": "https://bio.tools/CoreSlicer",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3384",
                            "term": "Medical imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "Tomography"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "MRI"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "CT"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "Computed tomography"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3452",
                            "term": "TDM"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "Nuclear magnetic resonance imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "Magnetic resonance imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "MRT"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "Magnetic resonance tomography"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3444",
                            "term": "NMRI"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Enables extraction of morphomic markers from CT images by non-technically skilled clinicians.",
                "homepage": "https://coreslicer.com/"
            }
        ],
        "inputs": [
            "ch_raw_reads_trimgalore"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_trimmed_reads",
            "ch_trimgalore_results_mqc",
            "ch_trimgalore_fastqc_reports_mqc"
        ],
        "nb_outputs": 3,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}/trim_galore\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.html')) \"fastqc/$filename\" else if (filename.endsWith('.zip')) \"fastqc/zips/$filename\" else if (filename.endsWith('trimming_report.txt')) \"logs/$filename\" else params.save_trimmed ? filename : null }"
        ],
        "when": "",
        "stub": ""
    },
    "BWA_MEM": {
        "name_process": "BWA_MEM",
        "string_process": "\nprocess BWA_MEM {\n    tag \"$name\"\n    label 'process_high'\n\n    input:\n    tuple val(name), path(reads) from ch_trimmed_reads\n    path index from ch_bwa_index.collect()\n\n    output:\n    tuple val(name), path('*.bam') into ch_bwa_bam\n\n    script:\n    prefix = \"${name}.Lb\"\n    rg = \"\\'@RG\\\\tID:${name}\\\\tSM:${name.split('_')[0..-2].join('_')}\\\\tPL:ILLUMINA\\\\tLB:${name}\\\\tPU:1\\'\"\n    if (params.seq_center) {\n        rg = \"\\'@RG\\\\tID:${name}\\\\tSM:${name.split('_')[0..-2].join('_')}\\\\tPL:ILLUMINA\\\\tLB:${name}\\\\tPU:1\\\\tCN:${params.seq_center}\\'\"\n    }\n    score = params.bwa_min_score ? \"-T ${params.bwa_min_score}\" : ''\n    \"\"\"\n    bwa mem \\\\\n        -t $task.cpus \\\\\n        -M \\\\\n        -R $rg \\\\\n        $score \\\\\n        ${index}/${bwa_base} \\\\\n        $reads \\\\\n        | samtools view -@ $task.cpus -b -h -F 0x0100 -O BAM -o ${prefix}.bam -\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    prefix = \"${name}.Lb\"\n    rg = \"\\'@RG\\\\tID:${name}\\\\tSM:${name.split('_')[0..-2].join('_')}\\\\tPL:ILLUMINA\\\\tLB:${name}\\\\tPU:1\\'\"\n    if (params.seq_center) {\n        rg = \"\\'@RG\\\\tID:${name}\\\\tSM:${name.split('_')[0..-2].join('_')}\\\\tPL:ILLUMINA\\\\tLB:${name}\\\\tPU:1\\\\tCN:${params.seq_center}\\'\"\n    }\n    score = params.bwa_min_score ? \"-T ${params.bwa_min_score}\" : ''\n    \"\"\"\n    bwa mem \\\\\n        -t $task.cpus \\\\\n        -M \\\\\n        -R $rg \\\\\n        $score \\\\\n        ${index}/${bwa_base} \\\\\n        $reads \\\\\n        | samtools view -@ $task.cpus -b -h -F 0x0100 -O BAM -o ${prefix}.bam -\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "org",
            "score",
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/org",
            "https://bio.tools/score",
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "org",
                "uri": "https://bio.tools/org",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3659",
                                    "term": "Regression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Expression correlation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set enrichment analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3463",
                                    "term": "Co-expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "GSEA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Functional enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2436",
                                    "term": "Gene-set over-represenation analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Genome-wide mutation profiling and related risk signature for prognosis of papillary renal cell carcinoma.\n\nBackground:The papillary renal cell carcinoma (pRCC) is a rare subtype of renal cell carcinoma with limited investigation. Our study aimed to explore a robust signature to predict the prognosis of pRCC from the perspective of mutation profiles. Methods:In this study, we downloaded the simple nucleotide variation data of 288 pRCC samples from The Cancer Genome Atlas (TCGA) database. \"GenVisR\" package was utilized to visualize gene mutation profiles in pRCC. The PPI network was conducted based on the STRING database and the modification was performed via Cytoscape software (Version 3.7.1). Top 50 mutant genes were selected and Cox regression method was conducted to identify the hub prognostic mutant signature in pRCC using \"survival\" package.\n\n||| HOMEPAGE BROKEN!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'pRCC', 'GenVisR' (bio.tools/genvisr)",
                "homepage": "http://org.Hs.eg.db"
            },
            {
                "name": "score",
                "uri": "https://bio.tools/score",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0659",
                            "term": "Functional, regulatory and non-coding RNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3794",
                            "term": "RNA immunoprecipitation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3794",
                            "term": "RIP"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3792",
                                    "term": "miRNA expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0463",
                                    "term": "miRNA target prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3792",
                                    "term": "miRNA expression profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0463",
                                    "term": "microRNA target detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0463",
                                    "term": "miRNA prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0463",
                                    "term": "microRNA detection"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Comprehensive Analysis of Human microRNA-mRNA Interactome.\n\nOur services require cookies to keep track of your submissions and find your results. Submissions expire after 24 hours.",
                "homepage": "http://score.generesearch.ru/services/mirna/"
            },
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_trimmed_reads",
            "ch_bwa_index"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_bwa_bam"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'"
        ],
        "when": "",
        "stub": ""
    },
    "SORT_BAM": {
        "name_process": "SORT_BAM",
        "string_process": "\nprocess SORT_BAM {\n    tag \"$name\"\n    label 'process_medium'\n    if (params.save_align_intermeds) {\n        publishDir path: \"${params.outdir}/bwa/library\", mode: params.publish_dir_mode,\n            saveAs: { filename ->\n                          if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.stats')) \"samtools_stats/$filename\"\n                          else filename\n                    }\n    }\n\n    input:\n    tuple val(name), path(bam) from ch_bwa_bam\n\n    output:\n    tuple val(name), path('*.sorted.{bam,bam.bai}') into ch_sort_bam_merge\n    path '*.{flagstat,idxstats,stats}' into ch_sort_bam_flagstat_mqc\n\n    script:\n    prefix = \"${name}.Lb\"\n    \"\"\"\n    samtools sort -@ $task.cpus -o ${prefix}.sorted.bam -T $name $bam\n    samtools index ${prefix}.sorted.bam\n    samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n    samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n    samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    prefix = \"${name}.Lb\"\n    \"\"\"\n    samtools sort -@ $task.cpus -o ${prefix}.sorted.bam -T $name $bam\n    samtools index ${prefix}.sorted.bam\n    samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n    samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n    samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_bwa_bam"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_sort_bam_merge",
            "ch_sort_bam_flagstat_mqc"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium' if (params.save_align_intermeds) { publishDir path: \"${params.outdir}/bwa/library\", mode: params.publish_dir_mode, saveAs: { filename -> if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\" else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\" else if (filename.endsWith('.stats')) \"samtools_stats/$filename\" else filename } }"
        ],
        "when": "",
        "stub": ""
    },
    "MERGED_LIB_BAM": {
        "name_process": "MERGED_LIB_BAM",
        "string_process": "\nprocess MERGED_LIB_BAM {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\"\n                      else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\"\n                      else if (filename.endsWith('.stats')) \"samtools_stats/$filename\"\n                      else if (filename.endsWith('.metrics.txt')) \"picard_metrics/$filename\"\n                      else params.save_align_intermeds ? filename : null\n                }\n\n    input:\n    tuple val(name), path(bams) from ch_sort_bam_merge\n\n    output:\n    tuple val(name), path(\"*${prefix}.sorted.{bam,bam.bai}\") into ch_mlib_bam_filter,\n                                                                  ch_mlib_bam_preseq,\n                                                                  ch_mlib_bam_ataqv\n    path '*.{flagstat,idxstats,stats}' into ch_mlib_bam_stats_mqc\n    path '*.txt' into ch_mlib_bam_metrics_mqc\n\n    script:\n    prefix = \"${name}.mLb.mkD\"\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    def avail_mem = 3\n    if (!task.memory) {\n        log.info '[Picard MarkDuplicates] Available memory not known - defaulting to 3GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.toGiga()\n    }\n    if (bam_files.size() > 1) {\n        \"\"\"\n        picard -Xmx${avail_mem}g MergeSamFiles \\\\\n            ${'INPUT='+bam_files.join(' INPUT=')} \\\\\n            OUTPUT=${name}.sorted.bam \\\\\n            SORT_ORDER=coordinate \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n        samtools index ${name}.sorted.bam\n\n        picard -Xmx${avail_mem}g MarkDuplicates \\\\\n            INPUT=${name}.sorted.bam \\\\\n            OUTPUT=${prefix}.sorted.bam \\\\\n            ASSUME_SORTED=true \\\\\n            REMOVE_DUPLICATES=false \\\\\n            METRICS_FILE=${prefix}.MarkDuplicates.metrics.txt \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n\n        samtools index ${prefix}.sorted.bam\n        samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n        samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n        samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n        \"\"\"\n    } else {\n      \"\"\"\n      picard -Xmx${avail_mem}g MarkDuplicates \\\\\n          INPUT=${bam_files[0]} \\\\\n          OUTPUT=${prefix}.sorted.bam \\\\\n          ASSUME_SORTED=true \\\\\n          REMOVE_DUPLICATES=false \\\\\n          METRICS_FILE=${prefix}.MarkDuplicates.metrics.txt \\\\\n          VALIDATION_STRINGENCY=LENIENT \\\\\n          TMP_DIR=tmp\n\n      samtools index ${prefix}.sorted.bam\n      samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n      samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n      samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n      \"\"\"\n    }\n}",
        "nb_lignes_process": 72,
        "string_script": "    prefix = \"${name}.mLb.mkD\"\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    def avail_mem = 3\n    if (!task.memory) {\n        log.info '[Picard MarkDuplicates] Available memory not known - defaulting to 3GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.toGiga()\n    }\n    if (bam_files.size() > 1) {\n        \"\"\"\n        picard -Xmx${avail_mem}g MergeSamFiles \\\\\n            ${'INPUT='+bam_files.join(' INPUT=')} \\\\\n            OUTPUT=${name}.sorted.bam \\\\\n            SORT_ORDER=coordinate \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n        samtools index ${name}.sorted.bam\n\n        picard -Xmx${avail_mem}g MarkDuplicates \\\\\n            INPUT=${name}.sorted.bam \\\\\n            OUTPUT=${prefix}.sorted.bam \\\\\n            ASSUME_SORTED=true \\\\\n            REMOVE_DUPLICATES=false \\\\\n            METRICS_FILE=${prefix}.MarkDuplicates.metrics.txt \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n\n        samtools index ${prefix}.sorted.bam\n        samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n        samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n        samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n        \"\"\"\n    } else {\n      \"\"\"\n      picard -Xmx${avail_mem}g MarkDuplicates \\\\\n          INPUT=${bam_files[0]} \\\\\n          OUTPUT=${prefix}.sorted.bam \\\\\n          ASSUME_SORTED=true \\\\\n          REMOVE_DUPLICATES=false \\\\\n          METRICS_FILE=${prefix}.MarkDuplicates.metrics.txt \\\\\n          VALIDATION_STRINGENCY=LENIENT \\\\\n          TMP_DIR=tmp\n\n      samtools index ${prefix}.sorted.bam\n      samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n      samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n      samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n      \"\"\"\n    }",
        "nb_lignes_script": 48,
        "language_script": "bash",
        "tools": [
            "Picard",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_sort_bam_merge"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_mlib_bam_filter",
            "ch_mlib_bam_preseq",
            "ch_mlib_bam_ataqv",
            "ch_mlib_bam_stats_mqc",
            "ch_mlib_bam_metrics_mqc"
        ],
        "nb_outputs": 5,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\" else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\" else if (filename.endsWith('.stats')) \"samtools_stats/$filename\" else if (filename.endsWith('.metrics.txt')) \"picard_metrics/$filename\" else params.save_align_intermeds ? filename : null }"
        ],
        "when": "",
        "stub": ""
    },
    "MERGED_LIB_BAM_FILTER": {
        "name_process": "MERGED_LIB_BAM_FILTER",
        "string_process": "\nprocess MERGED_LIB_BAM_FILTER {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir path: \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (params.single_end || params.save_align_intermeds) {\n                          if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.stats')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.sorted.bam')) filename\n                          else if (filename.endsWith('.sorted.bam.bai')) filename\n                          else null\n                      }\n                }\n\n    input:\n    tuple val(name), path(bam) from ch_mlib_bam_filter\n    path bed from ch_genome_filter_regions.collect()\n    path bamtools_filter_config from ch_bamtools_filter_config\n\n    output:\n    tuple val(name), path('*.{bam,bam.bai}') into ch_mlib_filter_bam\n    tuple val(name), path('*.flagstat') into ch_mlib_filter_bam_flagstat\n    path '*.{idxstats,stats}' into ch_mlib_filter_bam_stats_mqc\n\n    script:\n    prefix = params.single_end ? \"${name}.mLb.clN\" : \"${name}.mLb.flT\"\n    filter_params = params.single_end ? '-F 0x004' : '-F 0x004 -F 0x0008 -f 0x001'\n    dup_params = params.keep_dups ? '' : '-F 0x0400'\n    multimap_params = params.keep_multi_map ? '' : '-q 1'\n    blacklist_params = params.blacklist ? \"-L $bed\" : ''\n    name_sort_bam = params.single_end ? '' : \"samtools sort -n -@ $task.cpus -o ${prefix}.bam -T $prefix ${prefix}.sorted.bam\"\n    \"\"\"\n    samtools view \\\\\n        $filter_params \\\\\n        $dup_params \\\\\n        $multimap_params \\\\\n        $blacklist_params \\\\\n        -b ${bam[0]} \\\\\n        | bamtools filter \\\\\n            -out ${prefix}.sorted.bam \\\\\n            -script $bamtools_filter_config\n\n    samtools index ${prefix}.sorted.bam\n    samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n    samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n    samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n\n    $name_sort_bam\n    \"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "    prefix = params.single_end ? \"${name}.mLb.clN\" : \"${name}.mLb.flT\"\n    filter_params = params.single_end ? '-F 0x004' : '-F 0x004 -F 0x0008 -f 0x001'\n    dup_params = params.keep_dups ? '' : '-F 0x0400'\n    multimap_params = params.keep_multi_map ? '' : '-q 1'\n    blacklist_params = params.blacklist ? \"-L $bed\" : ''\n    name_sort_bam = params.single_end ? '' : \"samtools sort -n -@ $task.cpus -o ${prefix}.bam -T $prefix ${prefix}.sorted.bam\"\n    \"\"\"\n    samtools view \\\\\n        $filter_params \\\\\n        $dup_params \\\\\n        $multimap_params \\\\\n        $blacklist_params \\\\\n        -b ${bam[0]} \\\\\n        | bamtools filter \\\\\n            -out ${prefix}.sorted.bam \\\\\n            -script $bamtools_filter_config\n\n    samtools index ${prefix}.sorted.bam\n    samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n    samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n    samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n\n    $name_sort_bam\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BamTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bamtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BamTools",
                "uri": "https://bio.tools/bamtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BamTools provides a fast, flexible C++ API & toolkit for reading, writing, and managing BAM files.",
                "homepage": "https://github.com/pezmaster31/bamtools"
            }
        ],
        "inputs": [
            "ch_mlib_bam_filter",
            "ch_genome_filter_regions",
            "ch_bamtools_filter_config"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mlib_filter_bam",
            "ch_mlib_filter_bam_flagstat",
            "ch_mlib_filter_bam_stats_mqc"
        ],
        "nb_outputs": 3,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir path: \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode , saveAs: { filename -> if (params.single_end || params.save_align_intermeds) { if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\" else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\" else if (filename.endsWith('.stats')) \"samtools_stats/$filename\" else if (filename.endsWith('.sorted.bam')) filename else if (filename.endsWith('.sorted.bam.bai')) filename else null } }"
        ],
        "when": "",
        "stub": ""
    },
    "MERGED_LIB_BAM_REMOVE_ORPHAN": {
        "name_process": "MERGED_LIB_BAM_REMOVE_ORPHAN",
        "string_process": " process MERGED_LIB_BAM_REMOVE_ORPHAN {\n        tag \"$name\"\n        label 'process_medium'\n        publishDir path: \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode,\n            saveAs: { filename ->\n                          if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.stats')) \"samtools_stats/$filename\"\n                          else if (filename.endsWith('.sorted.bam')) filename\n                          else if (filename.endsWith('.sorted.bam.bai')) filename\n                          else null\n                    }\n\n        input:\n        tuple val(name), path(bam) from ch_mlib_filter_bam\n\n        output:\n        tuple val(name), path('*.sorted.{bam,bam.bai}') into ch_mlib_rm_orphan_bam_metrics,\n                                                             ch_mlib_rm_orphan_bam_bigwig,\n                                                             ch_mlib_rm_orphan_bam_macs,\n                                                             ch_mlib_rm_orphan_bam_plotfingerprint,\n                                                             ch_mlib_rm_orphan_bam_mrep\n        tuple val(name), path(\"${prefix}.bam\") into ch_mlib_name_bam_mlib_counts,\n                                                    ch_mlib_name_bam_mrep_counts\n        tuple val(name), path('*.flagstat') into ch_mlib_rm_orphan_flagstat_bigwig,\n                                                 ch_mlib_rm_orphan_flagstat_macs,\n                                                 ch_mlib_rm_orphan_flagstat_mqc\n        path '*.{idxstats,stats}' into ch_mlib_rm_orphan_stats_mqc\n\n        script:                                                                     \n        prefix = \"${name}.mLb.clN\"\n        \"\"\"\n        bampe_rm_orphan.py ${bam[0]} ${prefix}.bam --only_fr_pairs\n\n        samtools sort -@ $task.cpus -o ${prefix}.sorted.bam -T $prefix ${prefix}.bam\n        samtools index ${prefix}.sorted.bam\n        samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n        samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n        samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n        \"\"\"\n    }",
        "nb_lignes_process": 39,
        "string_script": "        prefix = \"${name}.mLb.clN\"\n        \"\"\"\n        bampe_rm_orphan.py ${bam[0]} ${prefix}.bam --only_fr_pairs\n\n        samtools sort -@ $task.cpus -o ${prefix}.sorted.bam -T $prefix ${prefix}.bam\n        samtools index ${prefix}.sorted.bam\n        samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n        samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n        samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_mlib_filter_bam"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_mlib_rm_orphan_bam_metrics",
            "ch_mlib_rm_orphan_bam_bigwig",
            "ch_mlib_rm_orphan_bam_macs",
            "ch_mlib_rm_orphan_bam_plotfingerprint",
            "ch_mlib_rm_orphan_bam_mrep",
            "ch_mlib_name_bam_mlib_counts",
            "ch_mlib_name_bam_mrep_counts",
            "ch_mlib_rm_orphan_flagstat_bigwig",
            "ch_mlib_rm_orphan_flagstat_macs",
            "ch_mlib_rm_orphan_flagstat_mqc",
            "ch_mlib_rm_orphan_stats_mqc"
        ],
        "nb_outputs": 11,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir path: \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\" else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\" else if (filename.endsWith('.stats')) \"samtools_stats/$filename\" else if (filename.endsWith('.sorted.bam')) filename else if (filename.endsWith('.sorted.bam.bai')) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "MERGED_LIB_PRESEQ": {
        "name_process": "MERGED_LIB_PRESEQ",
        "string_process": "\nprocess MERGED_LIB_PRESEQ {\n    tag \"$name\"\n    label 'process_low'\n    label 'error_ignore'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/preseq\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_preseq\n\n    input:\n    tuple val(name), path(bam) from ch_mlib_bam_preseq\n\n    output:\n    path '*.ccurve.txt' into ch_mlib_preseq_mqc\n    path '*.log'\n\n    script:\n    prefix = \"${name}.mLb.mkD\"\n    pe = params.single_end ? '' : '-pe'\n    \"\"\"\n    preseq lc_extrap \\\\\n        -output ${prefix}.ccurve.txt \\\\\n        -verbose \\\\\n        -bam \\\\\n        $pe \\\\\n        -seed 1 \\\\\n        ${bam[0]}\n    cp .command.err ${prefix}.command.log\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    prefix = \"${name}.mLb.mkD\"\n    pe = params.single_end ? '' : '-pe'\n    \"\"\"\n    preseq lc_extrap \\\\\n        -output ${prefix}.ccurve.txt \\\\\n        -verbose \\\\\n        -bam \\\\\n        $pe \\\\\n        -seed 1 \\\\\n        ${bam[0]}\n    cp .command.err ${prefix}.command.log\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "PEC",
            "preseq"
        ],
        "tools_url": [
            "https://bio.tools/PEC",
            "https://bio.tools/preseq"
        ],
        "tools_dico": [
            {
                "name": "PEC",
                "uri": "https://bio.tools/PEC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3384",
                            "term": "Medical imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Medicine"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Experimental medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Clinical medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3303",
                            "term": "Biomedical research"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A novel approach to the program evaluation committee.\n\nBACKGROUND:The Accreditation Council for Graduate Medical Education requires each residency program to have a Program Evaluation Committee (PEC) but does not specify how the PEC should be designed. We sought to develop a PEC that promotes resident leadership and provides actionable feedback. METHODS:Participants were residents and faculty in the Traditional Internal Medicine residency program at Yale School of Medicine (YSM). One resident and one faculty member facilitated a 1-h structured group discussion to obtain resident feedback on each rotation. PEC co-facilitators summarized the feedback in written form, then met with faculty Firm Chiefs overseeing each rotation and with residency program leadership to discuss feedback and generate action plans. This PEC process was implemented in all inpatient and outpatient rotations over a 4-year period.\n\n||| HOMEPAGE MISSING!",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31842868"
            },
            {
                "name": "preseq",
                "uri": "https://bio.tools/preseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package is aimed at predicting and number of distinct reads and how many will be expected from additional sequencing using an initial sequencing experiment. The estimates can then be used to examine the utility of further sequencing, optimize the sequencing depth, or to screen multiple libraries to avoid low complexity samples.",
                "homepage": "http://smithlabresearch.org/software/preseq/"
            }
        ],
        "inputs": [
            "ch_mlib_bam_preseq"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_mlib_preseq_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_low'",
            "label 'error_ignore'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/preseq\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_preseq",
        "stub": ""
    },
    "MERGED_LIB_PICARD_METRICS": {
        "name_process": "MERGED_LIB_PICARD_METRICS",
        "string_process": "\nprocess MERGED_LIB_PICARD_METRICS {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir path: \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('_metrics')) \"picard_metrics/$filename\"\n                      else if (filename.endsWith('.pdf')) \"picard_metrics/pdf/$filename\"\n                      else null\n                }\n\n    when:\n    !params.skip_picard_metrics\n\n    input:\n    tuple val(name), path(bam) from ch_mlib_rm_orphan_bam_metrics\n    path fasta from ch_fasta\n\n    output:\n    path '*_metrics' into ch_mlib_collectmetrics_mqc\n    path '*.pdf'\n\n    script:\n    prefix = \"${name}.mLb.clN\"\n    def avail_mem = 3\n    if (!task.memory) {\n        log.info '[Picard MarkDuplicates] Available memory not known - defaulting to 3GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.toGiga()\n    }\n    \"\"\"\n    picard -Xmx${avail_mem}g CollectMultipleMetrics \\\\\n        INPUT=${bam[0]} \\\\\n        OUTPUT=${prefix}.CollectMultipleMetrics \\\\\n        REFERENCE_SEQUENCE=$fasta \\\\\n        VALIDATION_STRINGENCY=LENIENT \\\\\n        TMP_DIR=tmp\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    prefix = \"${name}.mLb.clN\"\n    def avail_mem = 3\n    if (!task.memory) {\n        log.info '[Picard MarkDuplicates] Available memory not known - defaulting to 3GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.toGiga()\n    }\n    \"\"\"\n    picard -Xmx${avail_mem}g CollectMultipleMetrics \\\\\n        INPUT=${bam[0]} \\\\\n        OUTPUT=${prefix}.CollectMultipleMetrics \\\\\n        REFERENCE_SEQUENCE=$fasta \\\\\n        VALIDATION_STRINGENCY=LENIENT \\\\\n        TMP_DIR=tmp\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "ch_mlib_rm_orphan_bam_metrics",
            "ch_fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_mlib_collectmetrics_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir path: \"${params.outdir}/bwa/mergedLibrary\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('_metrics')) \"picard_metrics/$filename\" else if (filename.endsWith('.pdf')) \"picard_metrics/pdf/$filename\" else null }"
        ],
        "when": "!params.skip_picard_metrics",
        "stub": ""
    },
    "MERGED_LIB_BIGWIG": {
        "name_process": "MERGED_LIB_BIGWIG",
        "string_process": "\nprocess MERGED_LIB_BIGWIG {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/bigwig\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('scale_factor.txt')) \"scale/$filename\"\n                      else if (filename.endsWith('.bigWig')) filename\n                      else null\n                }\n\n    input:\n    tuple val(name), path(bam), path(flagstat) from ch_mlib_rm_orphan_bam_bigwig.join(ch_mlib_rm_orphan_flagstat_bigwig, by: [0])\n    path sizes from ch_genome_sizes_mlib_bigwig.collect()\n\n    output:\n    tuple val(name), path('*.bigWig') into ch_mlib_bigwig_plotprofile\n    path '*igv.txt' into ch_mlib_bigwig_igv\n    path '*scale_factor.txt'\n\n    script:\n    prefix = \"${name}.mLb.clN\"\n    pe_fragment = params.single_end ? '' : '-pc'\n    extend = (params.single_end && params.fragment_size > 0) ? \"-fs ${params.fragment_size}\" : ''\n    \"\"\"\n    SCALE_FACTOR=\\$(grep 'mapped (' $flagstat | awk '{print 1000000/\\$1}')\n    echo \\$SCALE_FACTOR > ${prefix}.scale_factor.txt\n    genomeCoverageBed -ibam ${bam[0]} -bg -scale \\$SCALE_FACTOR $pe_fragment $extend | sort -T '.' -k1,1 -k2,2n >  ${prefix}.bedGraph\n\n    bedGraphToBigWig ${prefix}.bedGraph $sizes ${prefix}.bigWig\n\n    find * -type f -name \"*.bigWig\" -exec echo -e \"bwa/mergedLibrary/bigwig/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}.bigWig.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    prefix = \"${name}.mLb.clN\"\n    pe_fragment = params.single_end ? '' : '-pc'\n    extend = (params.single_end && params.fragment_size > 0) ? \"-fs ${params.fragment_size}\" : ''\n    \"\"\"\n    SCALE_FACTOR=\\$(grep 'mapped (' $flagstat | awk '{print 1000000/\\$1}')\n    echo \\$SCALE_FACTOR > ${prefix}.scale_factor.txt\n    genomeCoverageBed -ibam ${bam[0]} -bg -scale \\$SCALE_FACTOR $pe_fragment $extend | sort -T '.' -k1,1 -k2,2n >  ${prefix}.bedGraph\n\n    bedGraphToBigWig ${prefix}.bedGraph $sizes ${prefix}.bigWig\n\n    find * -type f -name \"*.bigWig\" -exec echo -e \"bwa/mergedLibrary/bigwig/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}.bigWig.igv.txt\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "GOExtender",
            "bedGraphToBigWig"
        ],
        "tools_url": [
            "https://bio.tools/goextender",
            "https://bio.tools/bedgraphtobigwig"
        ],
        "tools_dico": [
            {
                "name": "GOExtender",
                "uri": "https://bio.tools/goextender",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3439",
                                    "term": "Pathway or network prediction"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "New algorithm to efficiently identify all the connected gene pairs labeled by the same parent Gene Ontology (GO) terms.",
                "homepage": "https://www.msu.edu/~jinchen/GOExtender/"
            },
            {
                "name": "bedGraphToBigWig",
                "uri": "https://bio.tools/bedgraphtobigwig",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Convert bedGraph to bigWig file.",
                "homepage": "https://www.encodeproject.org/software/bedgraphtobigwig/"
            }
        ],
        "inputs": [
            "ch_mlib_rm_orphan_bam_bigwig",
            "ch_genome_sizes_mlib_bigwig"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_mlib_bigwig_plotprofile",
            "ch_mlib_bigwig_igv"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/bigwig\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('scale_factor.txt')) \"scale/$filename\" else if (filename.endsWith('.bigWig')) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "MERGED_LIB_PLOTPROFILE": {
        "name_process": "MERGED_LIB_PLOTPROFILE",
        "string_process": "\nprocess MERGED_LIB_PLOTPROFILE {\n    tag \"$name\"\n    label 'process_high'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/deepTools/plotProfile\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_plot_profile\n\n    input:\n    tuple val(name), path(bigwig) from ch_mlib_bigwig_plotprofile\n    path bed from ch_gene_bed\n\n    output:\n    path '*.plotProfile.tab' into ch_mlib_plotprofile_mqc\n    path '*.{gz,pdf,mat.tab}'\n\n    script:\n    prefix = \"${name}.mLb.clN\"\n    \"\"\"\n    computeMatrix scale-regions \\\\\n        --regionsFileName $bed \\\\\n        --scoreFileName $bigwig \\\\\n        --outFileName ${prefix}.computeMatrix.mat.gz \\\\\n        --outFileNameMatrix ${prefix}.computeMatrix.vals.mat.tab \\\\\n        --regionBodyLength 1000 \\\\\n        --beforeRegionStartLength 3000 \\\\\n        --afterRegionStartLength 3000 \\\\\n        --skipZeros \\\\\n        --smartLabels \\\\\n        --numberOfProcessors $task.cpus\n\n    plotProfile --matrixFile ${prefix}.computeMatrix.mat.gz \\\\\n        --outFileName ${prefix}.plotProfile.pdf \\\\\n        --outFileNameData ${prefix}.plotProfile.tab\n\n    plotHeatmap --matrixFile ${prefix}.computeMatrix.mat.gz \\\\\n        --outFileName ${prefix}.plotHeatmap.pdf \\\\\n        --outFileNameMatrix ${prefix}.plotHeatmap.mat.tab\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    prefix = \"${name}.mLb.clN\"\n    \"\"\"\n    computeMatrix scale-regions \\\\\n        --regionsFileName $bed \\\\\n        --scoreFileName $bigwig \\\\\n        --outFileName ${prefix}.computeMatrix.mat.gz \\\\\n        --outFileNameMatrix ${prefix}.computeMatrix.vals.mat.tab \\\\\n        --regionBodyLength 1000 \\\\\n        --beforeRegionStartLength 3000 \\\\\n        --afterRegionStartLength 3000 \\\\\n        --skipZeros \\\\\n        --smartLabels \\\\\n        --numberOfProcessors $task.cpus\n\n    plotProfile --matrixFile ${prefix}.computeMatrix.mat.gz \\\\\n        --outFileName ${prefix}.plotProfile.pdf \\\\\n        --outFileNameData ${prefix}.plotProfile.tab\n\n    plotHeatmap --matrixFile ${prefix}.computeMatrix.mat.gz \\\\\n        --outFileName ${prefix}.plotHeatmap.pdf \\\\\n        --outFileNameMatrix ${prefix}.plotHeatmap.mat.tab\n    \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mlib_bigwig_plotprofile",
            "ch_gene_bed"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_mlib_plotprofile_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/deepTools/plotProfile\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_plot_profile",
        "stub": ""
    },
    "MERGED_LIB_PLOTFINGERPRINT": {
        "name_process": "MERGED_LIB_PLOTFINGERPRINT",
        "string_process": "\nprocess MERGED_LIB_PLOTFINGERPRINT {\n    tag \"$name\"\n    label 'process_high'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/deepTools/plotFingerprint\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_plot_fingerprint\n\n    input:\n    tuple val(name), path(bam) from ch_mlib_rm_orphan_bam_plotfingerprint\n\n    output:\n    path '*.raw.txt' into ch_mlib_plotfingerprint_mqc\n    path '*.{txt,pdf}'\n\n    script:\n    prefix = \"${name}.mLb.clN\"\n    extend = (params.single_end && params.fragment_size > 0) ? \"--extendReads ${params.fragment_size}\" : ''\n    \"\"\"\n    plotFingerprint \\\\\n        --bamfiles ${bam[0]} \\\\\n        --plotFile ${prefix}.plotFingerprint.pdf \\\\\n        $extend \\\\\n        --labels $prefix \\\\\n        --outRawCounts ${prefix}.plotFingerprint.raw.txt \\\\\n        --outQualityMetrics ${prefix}.plotFingerprint.qcmetrics.txt \\\\\n        --skipZeros \\\\\n        --numberOfProcessors $task.cpus \\\\\n        --numberOfSamples $params.fingerprint_bins\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    prefix = \"${name}.mLb.clN\"\n    extend = (params.single_end && params.fragment_size > 0) ? \"--extendReads ${params.fragment_size}\" : ''\n    \"\"\"\n    plotFingerprint \\\\\n        --bamfiles ${bam[0]} \\\\\n        --plotFile ${prefix}.plotFingerprint.pdf \\\\\n        $extend \\\\\n        --labels $prefix \\\\\n        --outRawCounts ${prefix}.plotFingerprint.raw.txt \\\\\n        --outQualityMetrics ${prefix}.plotFingerprint.qcmetrics.txt \\\\\n        --skipZeros \\\\\n        --numberOfProcessors $task.cpus \\\\\n        --numberOfSamples $params.fingerprint_bins\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "GOExtender"
        ],
        "tools_url": [
            "https://bio.tools/goextender"
        ],
        "tools_dico": [
            {
                "name": "GOExtender",
                "uri": "https://bio.tools/goextender",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3439",
                                    "term": "Pathway or network prediction"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "New algorithm to efficiently identify all the connected gene pairs labeled by the same parent Gene Ontology (GO) terms.",
                "homepage": "https://www.msu.edu/~jinchen/GOExtender/"
            }
        ],
        "inputs": [
            "ch_mlib_rm_orphan_bam_plotfingerprint"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_mlib_plotfingerprint_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/deepTools/plotFingerprint\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_plot_fingerprint",
        "stub": ""
    },
    "MERGED_LIB_MACS2": {
        "name_process": "MERGED_LIB_MACS2",
        "string_process": "\nprocess MERGED_LIB_MACS2 {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.tsv')) \"qc/$filename\"\n                      else if (filename.endsWith('.igv.txt')) null\n                      else filename\n                }\n\n    when:\n    params.macs_gsize\n\n    input:\n    tuple val(name), path(bam), path(flagstat) from ch_mlib_rm_orphan_bam_macs.join(ch_mlib_rm_orphan_flagstat_macs, by: [0])\n    path mlib_peak_count_header from ch_mlib_peak_count_header\n    path mlib_frip_score_header from ch_mlib_frip_score_header\n\n    output:\n    tuple val(name), path(\"*$PEAK_TYPE\") into ch_mlib_macs_homer,\n                                              ch_mlib_macs_qc,\n                                              ch_mlib_macs_consensus,\n                                              ch_mlib_macs_ataqv\n    path '*igv.txt' into ch_mlib_macs_igv\n    path '*_mqc.tsv' into ch_mlib_macs_mqc\n    path '*.{bed,xls,gappedPeak,bdg}'\n\n    script:\n    prefix = \"${name}.mLb.clN\"\n    broad = params.narrow_peak ? '' : \"--broad --broad-cutoff ${params.broad_cutoff}\"\n    format = params.single_end ? 'BAM' : 'BAMPE'\n    pileup = params.save_macs_pileup ? '-B --SPMR' : ''\n    fdr = params.macs_fdr ? \"--qvalue ${params.macs_fdr}\" : ''\n    pvalue = params.macs_pvalue ? \"--pvalue ${params.macs_pvalue}\" : ''\n    \"\"\"\n    macs2 callpeak \\\\\n        -t ${bam[0]} \\\\\n        $broad \\\\\n        -f $format \\\\\n        -g $params.macs_gsize \\\\\n        -n $prefix \\\\\n        $pileup \\\\\n        $fdr \\\\\n        $pvalue \\\\\n        --keep-dup all \\\\\n        --nomodel\n\n    cat ${prefix}_peaks.${PEAK_TYPE} | wc -l | awk -v OFS='\\t' '{ print \"${name}\", \\$1 }' | cat $mlib_peak_count_header - > ${prefix}_peaks.count_mqc.tsv\n\n    READS_IN_PEAKS=\\$(intersectBed -a ${bam[0]} -b ${prefix}_peaks.${PEAK_TYPE} -bed -c -f 0.20 | awk -F '\\t' '{sum += \\$NF} END {print sum}')\n    grep 'mapped (' $flagstat | awk -v a=\"\\$READS_IN_PEAKS\" -v OFS='\\t' '{print \"${name}\", a/\\$1}' | cat $mlib_frip_score_header - > ${prefix}_peaks.FRiP_mqc.tsv\n\n    find * -type f -name \"*.${PEAK_TYPE}\" -exec echo -e \"bwa/mergedLibrary/macs/${PEAK_TYPE}/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}_peaks.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 54,
        "string_script": "    prefix = \"${name}.mLb.clN\"\n    broad = params.narrow_peak ? '' : \"--broad --broad-cutoff ${params.broad_cutoff}\"\n    format = params.single_end ? 'BAM' : 'BAMPE'\n    pileup = params.save_macs_pileup ? '-B --SPMR' : ''\n    fdr = params.macs_fdr ? \"--qvalue ${params.macs_fdr}\" : ''\n    pvalue = params.macs_pvalue ? \"--pvalue ${params.macs_pvalue}\" : ''\n    \"\"\"\n    macs2 callpeak \\\\\n        -t ${bam[0]} \\\\\n        $broad \\\\\n        -f $format \\\\\n        -g $params.macs_gsize \\\\\n        -n $prefix \\\\\n        $pileup \\\\\n        $fdr \\\\\n        $pvalue \\\\\n        --keep-dup all \\\\\n        --nomodel\n\n    cat ${prefix}_peaks.${PEAK_TYPE} | wc -l | awk -v OFS='\\t' '{ print \"${name}\", \\$1 }' | cat $mlib_peak_count_header - > ${prefix}_peaks.count_mqc.tsv\n\n    READS_IN_PEAKS=\\$(intersectBed -a ${bam[0]} -b ${prefix}_peaks.${PEAK_TYPE} -bed -c -f 0.20 | awk -F '\\t' '{sum += \\$NF} END {print sum}')\n    grep 'mapped (' $flagstat | awk -v a=\"\\$READS_IN_PEAKS\" -v OFS='\\t' '{print \"${name}\", a/\\$1}' | cat $mlib_frip_score_header - > ${prefix}_peaks.FRiP_mqc.tsv\n\n    find * -type f -name \"*.${PEAK_TYPE}\" -exec echo -e \"bwa/mergedLibrary/macs/${PEAK_TYPE}/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}_peaks.igv.txt\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "BroadPeak",
            "DEFormats",
            "mpileup",
            "FDR"
        ],
        "tools_url": [
            "https://bio.tools/broadpeak",
            "https://bio.tools/deformats",
            "https://bio.tools/mpileup",
            "https://bio.tools/FDR"
        ],
        "tools_dico": [
            {
                "name": "BroadPeak",
                "uri": "https://bio.tools/broadpeak",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3222",
                                    "term": "Peak calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3222",
                                    "term": "Protein binding peak detection"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Algorithm for the identification of broad peaks from diffuse ChIP-seq datasets.",
                "homepage": "http://jordan.biology.gatech.edu/page/software/broadpeak/index.html"
            },
            {
                "name": "DEFormats",
                "uri": "https://bio.tools/deformats",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Covert between different data formats used by differential gene expression analysis tools.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/DEFormats.html"
            },
            {
                "name": "mpileup",
                "uri": "https://bio.tools/mpileup",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3695",
                                    "term": "Filtering"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Filter bam file using mpileup on coverage and SNPs.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "FDR",
                "uri": "https://bio.tools/FDR",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3384",
                            "term": "Medical imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3318",
                            "term": "Physics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A comparison of random-field-theory and false-discovery-rate inference results in the analysis of registered one-dimensional biomechanical datasets.\n\nFalse discovery rate (FDR) inferences for one-dimensional (1d) data.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'RFT', 'RFT FDR', 'biomechanical', 'random-field-theory'",
                "homepage": "https://github.com/0todd0000/fdr1d"
            }
        ],
        "inputs": [
            "ch_mlib_rm_orphan_bam_macs",
            "ch_mlib_peak_count_header",
            "ch_mlib_frip_score_header"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mlib_macs_homer",
            "ch_mlib_macs_qc",
            "ch_mlib_macs_consensus",
            "ch_mlib_macs_ataqv",
            "ch_mlib_macs_igv",
            "ch_mlib_macs_mqc"
        ],
        "nb_outputs": 6,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.tsv')) \"qc/$filename\" else if (filename.endsWith('.igv.txt')) null else filename }"
        ],
        "when": "params.macs_gsize",
        "stub": ""
    },
    "MERGED_LIB_MACS2_ANNOTATE": {
        "name_process": "MERGED_LIB_MACS2_ANNOTATE",
        "string_process": "\nprocess MERGED_LIB_MACS2_ANNOTATE {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode\n\n    when:\n    params.macs_gsize && !params.skip_peak_annotation\n\n    input:\n    tuple val(name), path(peak) from ch_mlib_macs_homer\n    path fasta from ch_fasta\n    path gtf from ch_gtf\n\n    output:\n    path '*.txt' into ch_mlib_macs_annotate\n\n    script:\n    prefix = \"${name}.mLb.clN\"\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $peak \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}_peaks.annotatePeaks.txt\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    prefix = \"${name}.mLb.clN\"\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $peak \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}_peaks.annotatePeaks.txt\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mlib_macs_homer",
            "ch_fasta",
            "ch_gtf"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mlib_macs_annotate"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode"
        ],
        "when": "params.macs_gsize && !params.skip_peak_annotation",
        "stub": ""
    },
    "MERGED_LIB_MACS2_QC": {
        "name_process": "MERGED_LIB_MACS2_QC",
        "string_process": "\nprocess MERGED_LIB_MACS2_QC {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/qc\", mode: params.publish_dir_mode\n\n    when:\n    params.macs_gsize && !params.skip_peak_annotation && !params.skip_peak_qc\n\n    input:\n    path peaks from ch_mlib_macs_qc.collect{ it[1] }\n    path annos from ch_mlib_macs_annotate.collect()\n    path mlib_peak_annotation_header from ch_mlib_peak_annotation_header\n\n    output:\n    path '*.tsv' into ch_mlib_peak_qc_mqc\n    path '*.{txt,pdf}'\n\n    script:                                                                      \n    suffix = 'mLb.clN'\n    \"\"\"\n    plot_macs_qc.r \\\\\n        -i ${peaks.join(',')} \\\\\n        -s ${peaks.join(',').replaceAll(\".${suffix}_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_peak.${suffix}\n\n    plot_homer_annotatepeaks.r \\\\\n        -i ${annos.join(',')} \\\\\n        -s ${annos.join(',').replaceAll(\".${suffix}_peaks.annotatePeaks.txt\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_annotatePeaks.${suffix}\n\n    cat $mlib_peak_annotation_header macs_annotatePeaks.${suffix}.summary.txt > macs_annotatePeaks.${suffix}.summary_mqc.tsv\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    suffix = 'mLb.clN'\n    \"\"\"\n    plot_macs_qc.r \\\\\n        -i ${peaks.join(',')} \\\\\n        -s ${peaks.join(',').replaceAll(\".${suffix}_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_peak.${suffix}\n\n    plot_homer_annotatepeaks.r \\\\\n        -i ${annos.join(',')} \\\\\n        -s ${annos.join(',').replaceAll(\".${suffix}_peaks.annotatePeaks.txt\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_annotatePeaks.${suffix}\n\n    cat $mlib_peak_annotation_header macs_annotatePeaks.${suffix}.summary.txt > macs_annotatePeaks.${suffix}.summary_mqc.tsv\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mlib_macs_qc",
            "ch_mlib_macs_annotate",
            "ch_mlib_peak_annotation_header"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mlib_peak_qc_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/qc\", mode: params.publish_dir_mode"
        ],
        "when": "params.macs_gsize && !params.skip_peak_annotation && !params.skip_peak_qc",
        "stub": ""
    },
    "MERGED_LIB_CONSENSUS": {
        "name_process": "MERGED_LIB_CONSENSUS",
        "string_process": "\nprocess MERGED_LIB_CONSENSUS {\n    label 'process_long'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.igv.txt')) null\n                      else filename\n                }\n\n    when:\n    params.macs_gsize && (replicatesExist || multipleGroups) && !params.skip_consensus_peaks\n\n    input:\n    path peaks from ch_mlib_macs_consensus.collect{ it[1] }\n\n    output:\n    path '*.bed' into ch_mlib_macs_consensus_bed\n    path '*.saf' into ch_mlib_macs_consensus_saf\n    path '*.boolean.txt' into ch_mlib_macs_consensus_bool\n    path '*igv.txt' into ch_mlib_macs_consensus_igv\n    path '*.intersect.{txt,plot.pdf}'\n\n    script:                                                                  \n    suffix = 'mLb.clN'\n    prefix = \"consensus_peaks.${suffix}\"\n    mergecols = params.narrow_peak ? (2..10).join(',') : (2..9).join(',')\n    collapsecols = params.narrow_peak ? (['collapse']*9).join(',') : (['collapse']*8).join(',')\n    expandparam = params.narrow_peak ? '--is_narrow_peak' : ''\n    \"\"\"\n    sort -T '.' -k1,1 -k2,2n ${peaks.collect{it.toString()}.sort().join(' ')} \\\\\n        | mergeBed -c $mergecols -o $collapsecols > ${prefix}.txt\n\n    macs2_merged_expand.py \\\\\n        ${prefix}.txt \\\\\n        ${peaks.collect{it.toString()}.sort().join(',').replaceAll(\"_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        ${prefix}.boolean.txt \\\\\n        --min_replicates $params.min_reps_consensus \\\\\n        $expandparam\n\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$1, \\$2, \\$3, \\$4, \"0\", \"+\" }' ${prefix}.boolean.txt > ${prefix}.bed\n\n    echo -e \"GeneID\\tChr\\tStart\\tEnd\\tStrand\" > ${prefix}.saf\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$4, \\$1, \\$2, \\$3,  \"+\" }' ${prefix}.boolean.txt >> ${prefix}.saf\n\n    sed -i 's/.${suffix}//g' ${prefix}.boolean.intersect.txt\n    plot_peak_intersect.r -i ${prefix}.boolean.intersect.txt -o ${prefix}.boolean.intersect.plot.pdf\n\n    find * -type f -name \"${prefix}.bed\" -exec echo -e \"bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus/\"{}\"\\\\t0,0,0\" \\\\; > ${prefix}.bed.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 48,
        "string_script": "    suffix = 'mLb.clN'\n    prefix = \"consensus_peaks.${suffix}\"\n    mergecols = params.narrow_peak ? (2..10).join(',') : (2..9).join(',')\n    collapsecols = params.narrow_peak ? (['collapse']*9).join(',') : (['collapse']*8).join(',')\n    expandparam = params.narrow_peak ? '--is_narrow_peak' : ''\n    \"\"\"\n    sort -T '.' -k1,1 -k2,2n ${peaks.collect{it.toString()}.sort().join(' ')} \\\\\n        | mergeBed -c $mergecols -o $collapsecols > ${prefix}.txt\n\n    macs2_merged_expand.py \\\\\n        ${prefix}.txt \\\\\n        ${peaks.collect{it.toString()}.sort().join(',').replaceAll(\"_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        ${prefix}.boolean.txt \\\\\n        --min_replicates $params.min_reps_consensus \\\\\n        $expandparam\n\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$1, \\$2, \\$3, \\$4, \"0\", \"+\" }' ${prefix}.boolean.txt > ${prefix}.bed\n\n    echo -e \"GeneID\\tChr\\tStart\\tEnd\\tStrand\" > ${prefix}.saf\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$4, \\$1, \\$2, \\$3,  \"+\" }' ${prefix}.boolean.txt >> ${prefix}.saf\n\n    sed -i 's/.${suffix}//g' ${prefix}.boolean.intersect.txt\n    plot_peak_intersect.r -i ${prefix}.boolean.intersect.txt -o ${prefix}.boolean.intersect.plot.pdf\n\n    find * -type f -name \"${prefix}.bed\" -exec echo -e \"bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus/\"{}\"\\\\t0,0,0\" \\\\; > ${prefix}.bed.igv.txt\n    \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mlib_macs_consensus"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_mlib_macs_consensus_bed",
            "ch_mlib_macs_consensus_saf",
            "ch_mlib_macs_consensus_bool",
            "ch_mlib_macs_consensus_igv"
        ],
        "nb_outputs": 4,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_long'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.igv.txt')) null else filename }"
        ],
        "when": "params.macs_gsize && (replicatesExist || multipleGroups) && !params.skip_consensus_peaks",
        "stub": ""
    },
    "MERGED_LIB_CONSENSUS_ANNOTATE": {
        "name_process": "MERGED_LIB_CONSENSUS_ANNOTATE",
        "string_process": "\nprocess MERGED_LIB_CONSENSUS_ANNOTATE {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode\n\n    when:\n    params.macs_gsize && (replicatesExist || multipleGroups) && !params.skip_consensus_peaks && !params.skip_peak_annotation\n\n    input:\n    path bed from ch_mlib_macs_consensus_bed\n    path bool from ch_mlib_macs_consensus_bool\n    path fasta from ch_fasta\n    path gtf from ch_gtf\n\n    output:\n    path '*.annotatePeaks.txt'\n\n    script:\n    prefix = 'consensus_peaks.mLb.clN'\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $bed \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}.annotatePeaks.txt\n\n    cut -f2- ${prefix}.annotatePeaks.txt | awk 'NR==1; NR > 1 {print \\$0 | \"sort -T '.' -k1,1 -k2,2n\"}' | cut -f6- > tmp.txt\n    paste $bool tmp.txt > ${prefix}.boolean.annotatePeaks.txt\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    prefix = 'consensus_peaks.mLb.clN'\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $bed \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}.annotatePeaks.txt\n\n    cut -f2- ${prefix}.annotatePeaks.txt | awk 'NR==1; NR > 1 {print \\$0 | \"sort -T '.' -k1,1 -k2,2n\"}' | cut -f6- > tmp.txt\n    paste $bool tmp.txt > ${prefix}.boolean.annotatePeaks.txt\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mlib_macs_consensus_bed",
            "ch_mlib_macs_consensus_bool",
            "ch_fasta",
            "ch_gtf"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode"
        ],
        "when": "params.macs_gsize && (replicatesExist || multipleGroups) && !params.skip_consensus_peaks && !params.skip_peak_annotation",
        "stub": ""
    },
    "MERGED_LIB_CONSENSUS_COUNTS": {
        "name_process": "MERGED_LIB_CONSENSUS_COUNTS",
        "string_process": "\nprocess MERGED_LIB_CONSENSUS_COUNTS {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode\n\n    when:\n    params.macs_gsize && (replicatesExist || multipleGroups) && !params.skip_consensus_peaks\n\n    input:\n    path bams from ch_mlib_name_bam_mlib_counts.collect{ it[1] }\n    path saf from ch_mlib_macs_consensus_saf.collect()\n\n    output:\n    path '*featureCounts.txt' into ch_mlib_macs_consensus_counts\n    path '*featureCounts.txt.summary' into ch_mlib_macs_consensus_counts_mqc\n\n    script:\n    prefix = 'consensus_peaks.mLb.clN'\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    pe_params = params.single_end ? '' : '-p --donotsort'\n    \"\"\"\n    featureCounts \\\\\n        -F SAF \\\\\n        -O \\\\\n        --fracOverlap 0.2 \\\\\n        -T $task.cpus \\\\\n        $pe_params \\\\\n        -a $saf \\\\\n        -o ${prefix}.featureCounts.txt \\\\\n        ${bam_files.join(' ')}\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    prefix = 'consensus_peaks.mLb.clN'\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    pe_params = params.single_end ? '' : '-p --donotsort'\n    \"\"\"\n    featureCounts \\\\\n        -F SAF \\\\\n        -O \\\\\n        --fracOverlap 0.2 \\\\\n        -T $task.cpus \\\\\n        $pe_params \\\\\n        -a $saf \\\\\n        -o ${prefix}.featureCounts.txt \\\\\n        ${bam_files.join(' ')}\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "FeatureCounts"
        ],
        "tools_url": [
            "https://bio.tools/featurecounts"
        ],
        "tools_dico": [
            {
                "name": "FeatureCounts",
                "uri": "https://bio.tools/featurecounts",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3793",
                                    "term": "Read summarisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "featureCounts is a very efficient read quantifier. It can be used to summarize RNA-seq reads and gDNA-seq reads to a variety of genomic features such as genes, exons, promoters, gene bodies and genomic bins. It is included in the Bioconductor Rsubread package and also in the SourceForge Subread package.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rsubread.html"
            }
        ],
        "inputs": [
            "ch_mlib_name_bam_mlib_counts",
            "ch_mlib_macs_consensus_saf"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_mlib_macs_consensus_counts",
            "ch_mlib_macs_consensus_counts_mqc"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode"
        ],
        "when": "params.macs_gsize && (replicatesExist || multipleGroups) && !params.skip_consensus_peaks",
        "stub": ""
    },
    "MERGED_LIB_CONSENSUS_DESEQ2": {
        "name_process": "MERGED_LIB_CONSENSUS_DESEQ2",
        "string_process": "\nprocess MERGED_LIB_CONSENSUS_DESEQ2 {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus/deseq2\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.igv.txt')) null\n                      else filename\n                }\n\n    when:\n    params.macs_gsize && replicatesExist && multipleGroups && !params.skip_consensus_peaks && !params.skip_diff_analysis\n\n    input:\n    path counts from ch_mlib_macs_consensus_counts\n    path mlib_deseq2_pca_header from ch_mlib_deseq2_pca_header\n    path mlib_deseq2_clustering_header from ch_mlib_deseq2_clustering_header\n\n    output:\n    path '*.tsv' into ch_mlib_macs_consensus_deseq_mqc\n    path '*igv.txt' into ch_mlib_macs_consensus_deseq_comp_igv\n    path '*.{RData,results.txt,pdf,log}'\n    path 'sizeFactors'\n    path '*vs*/*.{pdf,txt}'\n    path '*vs*/*.bed'\n\n    script:\n    prefix = 'consensus_peaks.mLb.clN'\n    bam_ext = params.single_end ? '.mLb.clN.sorted.bam' : '.mLb.clN.bam'\n    vst = params.deseq2_vst ? '--vst TRUE' : ''\n    \"\"\"\n    featurecounts_deseq2.r \\\\\n        --featurecount_file $counts \\\\\n        --bam_suffix '$bam_ext' \\\\\n        --outdir ./ \\\\\n        --outprefix $prefix \\\\\n        --outsuffix .mLb.clN \\\\\n        --cores $task.cpus \\\\\n        $vst \\\\\n\n    cat $mlib_deseq2_pca_header ${prefix}.pca.vals.txt > ${prefix}.pca.vals_mqc.tsv\n    cat $mlib_deseq2_clustering_header ${prefix}.sample.dists.txt > ${prefix}.sample.dists_mqc.tsv\n\n    find * -type f -name \"*.FDR0.05.results.bed\" -exec echo -e \"bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus/deseq2/\"{}\"\\\\t255,0,0\" \\\\; > ${prefix}.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "    prefix = 'consensus_peaks.mLb.clN'\n    bam_ext = params.single_end ? '.mLb.clN.sorted.bam' : '.mLb.clN.bam'\n    vst = params.deseq2_vst ? '--vst TRUE' : ''\n    \"\"\"\n    featurecounts_deseq2.r \\\\\n        --featurecount_file $counts \\\\\n        --bam_suffix '$bam_ext' \\\\\n        --outdir ./ \\\\\n        --outprefix $prefix \\\\\n        --outsuffix .mLb.clN \\\\\n        --cores $task.cpus \\\\\n        $vst \\\\\n\n    cat $mlib_deseq2_pca_header ${prefix}.pca.vals.txt > ${prefix}.pca.vals_mqc.tsv\n    cat $mlib_deseq2_clustering_header ${prefix}.sample.dists.txt > ${prefix}.sample.dists_mqc.tsv\n\n    find * -type f -name \"*.FDR0.05.results.bed\" -exec echo -e \"bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus/deseq2/\"{}\"\\\\t255,0,0\" \\\\; > ${prefix}.igv.txt\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mlib_macs_consensus_counts",
            "ch_mlib_deseq2_pca_header",
            "ch_mlib_deseq2_clustering_header"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mlib_macs_consensus_deseq_mqc",
            "ch_mlib_macs_consensus_deseq_comp_igv"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/macs/${PEAK_TYPE}/consensus/deseq2\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.igv.txt')) null else filename }"
        ],
        "when": "params.macs_gsize && replicatesExist && multipleGroups && !params.skip_consensus_peaks && !params.skip_diff_analysis",
        "stub": ""
    },
    "MERGED_LIB_ATAQV": {
        "name_process": "MERGED_LIB_ATAQV",
        "string_process": "\nprocess MERGED_LIB_ATAQV {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/ataqv/${PEAK_TYPE}\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_ataqv\n\n    input:\n    tuple val(name), path(bam), path(peak) from ch_mlib_bam_ataqv.join(ch_mlib_macs_ataqv, by: [0])\n    path autosomes from ch_genome_autosomes.collect()\n    path tss_bed from ch_tss_bed\n\n    output:\n    path '*.json' into ch_mlib_ataqv\n\n    script:\n    suffix = 'mLb.clN'\n    peak_param = params.macs_gsize ? \"--peak-file ${peak}\" : ''\n    mito_param = params.mito_name ? \"--mitochondrial-reference-name ${params.mito_name}\" : ''\n    \"\"\"\n    ataqv \\\\\n        --threads $task.cpus \\\\\n        $peak_param  \\\\\n        --tss-file $tss_bed \\\\\n        --metrics-file  ${name}.${suffix}.ataqv.json \\\\\n        --name $name \\\\\n        --ignore-read-groups \\\\\n        --autosomal-reference-file $autosomes \\\\\n        $mito_param \\\\\n        NA \\\\\n        ${bam[0]}\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    suffix = 'mLb.clN'\n    peak_param = params.macs_gsize ? \"--peak-file ${peak}\" : ''\n    mito_param = params.mito_name ? \"--mitochondrial-reference-name ${params.mito_name}\" : ''\n    \"\"\"\n    ataqv \\\\\n        --threads $task.cpus \\\\\n        $peak_param  \\\\\n        --tss-file $tss_bed \\\\\n        --metrics-file  ${name}.${suffix}.ataqv.json \\\\\n        --name $name \\\\\n        --ignore-read-groups \\\\\n        --autosomal-reference-file $autosomes \\\\\n        $mito_param \\\\\n        NA \\\\\n        ${bam[0]}\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "DNA"
        ],
        "tools_url": [
            "https://bio.tools/DNA"
        ],
        "tools_dico": [
            {
                "name": "DNA",
                "uri": "https://bio.tools/DNA",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3295",
                            "term": "Epigenetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatric medicine"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "https://en.wikipedia.org/wiki/Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatrics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Over-representation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'non-blood' | Improved precision of epigenetic clock estimates across tissues and its implication for biological ageing | A chronological age predictor based on DNA methylation | input_file: a R object file which contains the DNA methylation information for individuals (N * M matrix). N is the number of individuals and M is the number of CpG sites. Beta value is used as DNA methylation measurement",
                "homepage": "https://github.com/qzhang314/DNAm-based-age-predictor"
            }
        ],
        "inputs": [
            "ch_mlib_bam_ataqv",
            "ch_genome_autosomes",
            "ch_tss_bed"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mlib_ataqv"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/ataqv/${PEAK_TYPE}\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_ataqv",
        "stub": ""
    },
    "MERGED_LIB_ATAQV_MKARV": {
        "name_process": "MERGED_LIB_ATAQV_MKARV",
        "string_process": "\nprocess MERGED_LIB_ATAQV_MKARV {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedLibrary/ataqv/${PEAK_TYPE}\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_ataqv\n\n    input:\n    path json from ch_mlib_ataqv.collect()\n\n    output:\n    path 'html'\n\n    script:\n    \"\"\"\n    mkarv \\\\\n        --concurrency $task.cpus \\\\\n        --force \\\\\n        ./html/ \\\\\n        ${json.join(' ')}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    mkarv \\\\\n        --concurrency $task.cpus \\\\\n        --force \\\\\n        ./html/ \\\\\n        ${json.join(' ')}\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "nohtml"
        ],
        "tools_url": [
            "https://bio.tools/nohtml"
        ],
        "tools_dico": [
            {
                "name": "nohtml",
                "uri": "https://bio.tools/nohtml",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "Remove mark-up (e.g. HTML tags) from an ASCII text file.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/nohtml.html"
            }
        ],
        "inputs": [
            "ch_mlib_ataqv"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedLibrary/ataqv/${PEAK_TYPE}\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_ataqv",
        "stub": ""
    },
    "MERGED_REP_BAM": {
        "name_process": "MERGED_REP_BAM",
        "string_process": "\nprocess MERGED_REP_BAM {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\"\n                      else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\"\n                      else if (filename.endsWith('.stats')) \"samtools_stats/$filename\"\n                      else if (filename.endsWith('.metrics.txt')) \"picard_metrics/$filename\"\n                      else filename\n                }\n\n    input:\n    tuple val(name), path(bams) from ch_mlib_rm_orphan_bam_mrep\n\n    output:\n    tuple val(name), path(\"*${prefix}.sorted.{bam,bam.bai}\") into ch_mrep_bam_bigwig,\n                                                                  ch_mrep_bam_macs\n    tuple val(name), path('*.flagstat') into ch_mrep_bam_flagstat_bigwig,\n                                             ch_mrep_bam_flagstat_macs,\n                                             ch_mrep_bam_flagstat_mqc\n    path '*.{idxstats,stats}' into ch_mrep_bam_stats_mqc\n    path '*.txt' into ch_mrep_bam_metrics_mqc\n\n    when:\n    !params.skip_merge_replicates && replicatesExist\n\n    script:\n    prefix = \"${name}.mRp.clN\"\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    def avail_mem = 3\n    if (!task.memory) {\n        log.info '[Picard MarkDuplicates] Available memory not known - defaulting to 3GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.toGiga()\n    }\n    if (bam_files.size() > 1) {\n        \"\"\"\n        picard -Xmx${avail_mem}g MergeSamFiles \\\\\n            ${'INPUT='+bam_files.join(' INPUT=')} \\\\\n            OUTPUT=${name}.sorted.bam \\\\\n            SORT_ORDER=coordinate \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n        samtools index ${name}.sorted.bam\n\n        picard -Xmx${avail_mem}g MarkDuplicates \\\\\n            INPUT=${name}.sorted.bam \\\\\n            OUTPUT=${prefix}.sorted.bam \\\\\n            ASSUME_SORTED=true \\\\\n            REMOVE_DUPLICATES=true \\\\\n            METRICS_FILE=${prefix}.MarkDuplicates.metrics.txt \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n\n        samtools index ${prefix}.sorted.bam\n        samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n        samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n        samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n        \"\"\"\n    } else {\n      \"\"\"\n      ln -s ${bams[0]} ${prefix}.sorted.bam\n      ln -s ${bams[1]} ${prefix}.sorted.bam.bai\n      touch ${prefix}.MarkDuplicates.metrics.txt\n      samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n      samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n      samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n      \"\"\"\n    }\n}",
        "nb_lignes_process": 70,
        "string_script": "    prefix = \"${name}.mRp.clN\"\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    def avail_mem = 3\n    if (!task.memory) {\n        log.info '[Picard MarkDuplicates] Available memory not known - defaulting to 3GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.toGiga()\n    }\n    if (bam_files.size() > 1) {\n        \"\"\"\n        picard -Xmx${avail_mem}g MergeSamFiles \\\\\n            ${'INPUT='+bam_files.join(' INPUT=')} \\\\\n            OUTPUT=${name}.sorted.bam \\\\\n            SORT_ORDER=coordinate \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n        samtools index ${name}.sorted.bam\n\n        picard -Xmx${avail_mem}g MarkDuplicates \\\\\n            INPUT=${name}.sorted.bam \\\\\n            OUTPUT=${prefix}.sorted.bam \\\\\n            ASSUME_SORTED=true \\\\\n            REMOVE_DUPLICATES=true \\\\\n            METRICS_FILE=${prefix}.MarkDuplicates.metrics.txt \\\\\n            VALIDATION_STRINGENCY=LENIENT \\\\\n            TMP_DIR=tmp\n\n        samtools index ${prefix}.sorted.bam\n        samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n        samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n        samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n        \"\"\"\n    } else {\n      \"\"\"\n      ln -s ${bams[0]} ${prefix}.sorted.bam\n      ln -s ${bams[1]} ${prefix}.sorted.bam.bai\n      touch ${prefix}.MarkDuplicates.metrics.txt\n      samtools flagstat ${prefix}.sorted.bam > ${prefix}.sorted.bam.flagstat\n      samtools idxstats ${prefix}.sorted.bam > ${prefix}.sorted.bam.idxstats\n      samtools stats ${prefix}.sorted.bam > ${prefix}.sorted.bam.stats\n      \"\"\"\n    }",
        "nb_lignes_script": 41,
        "language_script": "bash",
        "tools": [
            "Picard",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_mlib_rm_orphan_bam_mrep"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_mrep_bam_bigwig",
            "ch_mrep_bam_macs",
            "ch_mrep_bam_flagstat_bigwig",
            "ch_mrep_bam_flagstat_macs",
            "ch_mrep_bam_flagstat_mqc",
            "ch_mrep_bam_stats_mqc",
            "ch_mrep_bam_metrics_mqc"
        ],
        "nb_outputs": 7,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.flagstat')) \"samtools_stats/$filename\" else if (filename.endsWith('.idxstats')) \"samtools_stats/$filename\" else if (filename.endsWith('.stats')) \"samtools_stats/$filename\" else if (filename.endsWith('.metrics.txt')) \"picard_metrics/$filename\" else filename }"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist",
        "stub": ""
    },
    "MERGED_REP_BIGWIG": {
        "name_process": "MERGED_REP_BIGWIG",
        "string_process": "\nprocess MERGED_REP_BIGWIG {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/bigwig\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('scale_factor.txt')) \"scale/$filename\"\n                      else if (filename.endsWith('.bigWig')) filename\n                      else null\n                }\n\n    when:\n    !params.skip_merge_replicates && replicatesExist\n\n    input:\n    tuple val(name), path(bam), path(flagstat) from ch_mrep_bam_bigwig.join(ch_mrep_bam_flagstat_bigwig, by: [0])\n    path sizes from ch_genome_sizes_mrep_bigwig.collect()\n\n    output:\n    tuple val(name), path('*.bigWig') into ch_mrep_bigwig\n    path '*igv.txt' into ch_mrep_bigwig_igv\n    path '*scale_factor.txt'\n\n    script:\n    prefix = \"${name}.mRp.clN\"\n    pe_fragment = params.single_end ? '' : '-pc'\n    extend = (params.single_end && params.fragment_size > 0) ? \"-fs ${params.fragment_size}\" : ''\n    \"\"\"\n    SCALE_FACTOR=\\$(grep 'mapped (' $flagstat | awk '{print 1000000/\\$1}')\n    echo \\$SCALE_FACTOR > ${prefix}.scale_factor.txt\n    genomeCoverageBed -ibam ${bam[0]} -bg -scale \\$SCALE_FACTOR $pe_fragment $extend | sort -T '.' -k1,1 -k2,2n >  ${prefix}.bedGraph\n\n    bedGraphToBigWig ${prefix}.bedGraph $sizes ${prefix}.bigWig\n\n    find * -type f -name \"*.bigWig\" -exec echo -e \"bwa/mergedReplicate/bigwig/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}.bigWig.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    prefix = \"${name}.mRp.clN\"\n    pe_fragment = params.single_end ? '' : '-pc'\n    extend = (params.single_end && params.fragment_size > 0) ? \"-fs ${params.fragment_size}\" : ''\n    \"\"\"\n    SCALE_FACTOR=\\$(grep 'mapped (' $flagstat | awk '{print 1000000/\\$1}')\n    echo \\$SCALE_FACTOR > ${prefix}.scale_factor.txt\n    genomeCoverageBed -ibam ${bam[0]} -bg -scale \\$SCALE_FACTOR $pe_fragment $extend | sort -T '.' -k1,1 -k2,2n >  ${prefix}.bedGraph\n\n    bedGraphToBigWig ${prefix}.bedGraph $sizes ${prefix}.bigWig\n\n    find * -type f -name \"*.bigWig\" -exec echo -e \"bwa/mergedReplicate/bigwig/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}.bigWig.igv.txt\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "GOExtender",
            "bedGraphToBigWig"
        ],
        "tools_url": [
            "https://bio.tools/goextender",
            "https://bio.tools/bedgraphtobigwig"
        ],
        "tools_dico": [
            {
                "name": "GOExtender",
                "uri": "https://bio.tools/goextender",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3439",
                                    "term": "Pathway or network prediction"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "New algorithm to efficiently identify all the connected gene pairs labeled by the same parent Gene Ontology (GO) terms.",
                "homepage": "https://www.msu.edu/~jinchen/GOExtender/"
            },
            {
                "name": "bedGraphToBigWig",
                "uri": "https://bio.tools/bedgraphtobigwig",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Convert bedGraph to bigWig file.",
                "homepage": "https://www.encodeproject.org/software/bedgraphtobigwig/"
            }
        ],
        "inputs": [
            "ch_mrep_bam_bigwig",
            "ch_genome_sizes_mrep_bigwig"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_mrep_bigwig",
            "ch_mrep_bigwig_igv"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/bigwig\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('scale_factor.txt')) \"scale/$filename\" else if (filename.endsWith('.bigWig')) filename else null }"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist",
        "stub": ""
    },
    "MERGED_REP_MACS2": {
        "name_process": "MERGED_REP_MACS2",
        "string_process": "\nprocess MERGED_REP_MACS2 {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.tsv')) \"qc/$filename\"\n                      else if (filename.endsWith('.igv.txt')) null\n                      else filename\n                }\n\n    when:\n    !params.skip_merge_replicates && replicatesExist && params.macs_gsize\n\n    input:\n    tuple val(name), path(bam), path(flagstat) from ch_mrep_bam_macs.join(ch_mrep_bam_flagstat_macs, by: [0])\n    path mrep_peak_count_header from ch_mrep_peak_count_header\n    path mrep_frip_score_header from ch_mrep_frip_score_header\n\n    output:\n    tuple val(name), path(\"*$PEAK_TYPE\") into ch_mrep_macs_homer,\n                                              ch_mrep_macs_qc,\n                                              ch_mrep_macs_consensus\n    path '*igv.txt' into ch_mrep_macs_igv\n    path '*_mqc.tsv' into ch_mrep_macs_mqc\n    path '*.{bed,xls,gappedPeak,bdg}'\n\n    script:\n    prefix = \"${name}.mRp.clN\"\n    broad = params.narrow_peak ? '' : \"--broad --broad-cutoff ${params.broad_cutoff}\"\n    format = params.single_end ? 'BAM' : 'BAMPE'\n    pileup = params.save_macs_pileup ? '-B --SPMR' : ''\n    \"\"\"\n    macs2 callpeak \\\\\n        -t ${bam[0]} \\\\\n        $broad \\\\\n        -f $format \\\\\n        -g $params.macs_gsize \\\\\n        -n $prefix \\\\\n        $pileup \\\\\n        --keep-dup all \\\\\n        --nomodel\n\n    cat ${prefix}_peaks.${PEAK_TYPE} | wc -l | awk -v OFS='\\t' '{ print \"${name}\", \\$1 }' | cat $mrep_peak_count_header - > ${prefix}_peaks.count_mqc.tsv\n\n    READS_IN_PEAKS=\\$(intersectBed -a ${bam[0]} -b ${prefix}_peaks.${PEAK_TYPE} -bed -c -f 0.20 | awk -F '\\t' '{sum += \\$NF} END {print sum}')\n    grep 'mapped (' $flagstat | awk -v a=\"\\$READS_IN_PEAKS\" -v OFS='\\t' '{print \"${name}\", a/\\$1}' | cat $mrep_frip_score_header - > ${prefix}_peaks.FRiP_mqc.tsv\n\n    find * -type f -name \"*.${PEAK_TYPE}\" -exec echo -e \"bwa/mergedReplicate/macs/${PEAK_TYPE}/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}_peaks.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 49,
        "string_script": "    prefix = \"${name}.mRp.clN\"\n    broad = params.narrow_peak ? '' : \"--broad --broad-cutoff ${params.broad_cutoff}\"\n    format = params.single_end ? 'BAM' : 'BAMPE'\n    pileup = params.save_macs_pileup ? '-B --SPMR' : ''\n    \"\"\"\n    macs2 callpeak \\\\\n        -t ${bam[0]} \\\\\n        $broad \\\\\n        -f $format \\\\\n        -g $params.macs_gsize \\\\\n        -n $prefix \\\\\n        $pileup \\\\\n        --keep-dup all \\\\\n        --nomodel\n\n    cat ${prefix}_peaks.${PEAK_TYPE} | wc -l | awk -v OFS='\\t' '{ print \"${name}\", \\$1 }' | cat $mrep_peak_count_header - > ${prefix}_peaks.count_mqc.tsv\n\n    READS_IN_PEAKS=\\$(intersectBed -a ${bam[0]} -b ${prefix}_peaks.${PEAK_TYPE} -bed -c -f 0.20 | awk -F '\\t' '{sum += \\$NF} END {print sum}')\n    grep 'mapped (' $flagstat | awk -v a=\"\\$READS_IN_PEAKS\" -v OFS='\\t' '{print \"${name}\", a/\\$1}' | cat $mrep_frip_score_header - > ${prefix}_peaks.FRiP_mqc.tsv\n\n    find * -type f -name \"*.${PEAK_TYPE}\" -exec echo -e \"bwa/mergedReplicate/macs/${PEAK_TYPE}/\"{}\"\\\\t0,0,178\" \\\\; > ${prefix}_peaks.igv.txt\n    \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "BroadPeak",
            "DEFormats",
            "mpileup"
        ],
        "tools_url": [
            "https://bio.tools/broadpeak",
            "https://bio.tools/deformats",
            "https://bio.tools/mpileup"
        ],
        "tools_dico": [
            {
                "name": "BroadPeak",
                "uri": "https://bio.tools/broadpeak",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3222",
                                    "term": "Peak calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3222",
                                    "term": "Protein binding peak detection"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Algorithm for the identification of broad peaks from diffuse ChIP-seq datasets.",
                "homepage": "http://jordan.biology.gatech.edu/page/software/broadpeak/index.html"
            },
            {
                "name": "DEFormats",
                "uri": "https://bio.tools/deformats",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Covert between different data formats used by differential gene expression analysis tools.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/DEFormats.html"
            },
            {
                "name": "mpileup",
                "uri": "https://bio.tools/mpileup",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3695",
                                    "term": "Filtering"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Filter bam file using mpileup on coverage and SNPs.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ch_mrep_bam_macs",
            "ch_mrep_peak_count_header",
            "ch_mrep_frip_score_header"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mrep_macs_homer",
            "ch_mrep_macs_qc",
            "ch_mrep_macs_consensus",
            "ch_mrep_macs_igv",
            "ch_mrep_macs_mqc"
        ],
        "nb_outputs": 5,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.tsv')) \"qc/$filename\" else if (filename.endsWith('.igv.txt')) null else filename }"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist && params.macs_gsize",
        "stub": ""
    },
    "MERGED_REP_MACS2_ANNOTATE": {
        "name_process": "MERGED_REP_MACS2_ANNOTATE",
        "string_process": "\nprocess MERGED_REP_MACS2_ANNOTATE {\n    tag \"$name\"\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_merge_replicates && replicatesExist && params.macs_gsize && !params.skip_peak_annotation\n\n    input:\n    tuple val(name), path(peak) from ch_mrep_macs_homer\n    path fasta from ch_fasta\n    path gtf from ch_gtf\n\n    output:\n    path '*.txt' into ch_mrep_macs_annotate\n\n    script:\n    prefix = \"${name}.mRp.clN\"\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $peak \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}_peaks.annotatePeaks.txt\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    prefix = \"${name}.mRp.clN\"\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $peak \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}_peaks.annotatePeaks.txt\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mrep_macs_homer",
            "ch_fasta",
            "ch_gtf"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mrep_macs_annotate"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "tag \"$name\"",
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist && params.macs_gsize && !params.skip_peak_annotation",
        "stub": ""
    },
    "MERGED_REP_MACS2_QC": {
        "name_process": "MERGED_REP_MACS2_QC",
        "string_process": "\nprocess MERGED_REP_MACS2_QC {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/qc\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_merge_replicates && replicatesExist && params.macs_gsize && !params.skip_peak_qc && !params.skip_peak_annotation\n\n    input:\n    path peaks from ch_mrep_macs_qc.collect{ it[1] }\n    path annos from ch_mrep_macs_annotate.collect()\n    path mrep_peak_annotation_header from ch_mrep_peak_annotation_header\n\n    output:\n    path '*.tsv' into ch_mrep_peak_qc_mqc\n    path '*.{txt,pdf}'\n\n    script:                                                                      \n    suffix = 'mRp.clN'\n    \"\"\"\n    plot_macs_qc.r \\\\\n        -i ${peaks.join(',')} \\\\\n        -s ${peaks.join(',').replaceAll(\".${suffix}_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_peak.${suffix}\n\n    plot_homer_annotatepeaks.r \\\\\n        -i ${annos.join(',')} \\\\\n        -s ${annos.join(',').replaceAll(\".${suffix}_peaks.annotatePeaks.txt\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_annotatePeaks.${suffix}\n\n    cat $mrep_peak_annotation_header macs_annotatePeaks.${suffix}.summary.txt > macs_annotatePeaks.${suffix}.summary_mqc.tsv\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    suffix = 'mRp.clN'\n    \"\"\"\n    plot_macs_qc.r \\\\\n        -i ${peaks.join(',')} \\\\\n        -s ${peaks.join(',').replaceAll(\".${suffix}_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_peak.${suffix}\n\n    plot_homer_annotatepeaks.r \\\\\n        -i ${annos.join(',')} \\\\\n        -s ${annos.join(',').replaceAll(\".${suffix}_peaks.annotatePeaks.txt\",\"\")} \\\\\n        -o ./ \\\\\n        -p macs_annotatePeaks.${suffix}\n\n    cat $mrep_peak_annotation_header macs_annotatePeaks.${suffix}.summary.txt > macs_annotatePeaks.${suffix}.summary_mqc.tsv\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mrep_macs_qc",
            "ch_mrep_macs_annotate",
            "ch_mrep_peak_annotation_header"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mrep_peak_qc_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/qc\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist && params.macs_gsize && !params.skip_peak_qc && !params.skip_peak_annotation",
        "stub": ""
    },
    "MERGED_REP_CONSENSUS": {
        "name_process": "MERGED_REP_CONSENSUS",
        "string_process": "\nprocess MERGED_REP_CONSENSUS {\n    label 'process_long'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.igv.txt')) null\n                      else filename\n                }\n\n    when:\n    !params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks\n\n    input:\n    path peaks from ch_mrep_macs_consensus.collect{ it[1] }\n\n    output:\n    path '*.bed' into ch_mrep_macs_consensus_bed\n    path '*.saf' into ch_mrep_macs_consensus_saf\n    path '*.boolean.txt' into ch_mrep_macs_consensus_bool\n    path '*igv.txt' into ch_mrep_macs_consensus_igv\n    path '*.intersect.{txt,plot.pdf}'\n\n    script:                                                                  \n    suffix = 'mRp.clN'\n    prefix = \"consensus_peaks.${suffix}\"\n    mergecols = params.narrow_peak ? (2..10).join(',') : (2..9).join(',')\n    collapsecols = params.narrow_peak ? (['collapse']*9).join(',') : (['collapse']*8).join(',')\n    expandparam = params.narrow_peak ? '--is_narrow_peak' : ''\n    \"\"\"\n    sort -T '.' -k1,1 -k2,2n ${peaks.collect{it.toString()}.sort().join(' ')} \\\\\n        | mergeBed -c $mergecols -o $collapsecols > ${prefix}.txt\n\n    macs2_merged_expand.py \\\\\n        ${prefix}.txt \\\\\n        ${peaks.collect{it.toString()}.sort().join(',').replaceAll(\"_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        ${prefix}.boolean.txt \\\\\n        $expandparam\n\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$1, \\$2, \\$3, \\$4, \"0\", \"+\" }' ${prefix}.boolean.txt > ${prefix}.bed\n\n    echo -e \"GeneID\\tChr\\tStart\\tEnd\\tStrand\" > ${prefix}.saf\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$4, \\$1, \\$2, \\$3,  \"+\" }' ${prefix}.boolean.txt >> ${prefix}.saf\n\n    sed -i 's/.${suffix}//g' ${prefix}.boolean.intersect.txt\n    plot_peak_intersect.r -i ${prefix}.boolean.intersect.txt -o ${prefix}.boolean.intersect.plot.pdf\n\n    find * -type f -name \"${prefix}.bed\" -exec echo -e \"bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus/\"{}\"\\\\t0,0,0\" \\\\; > ${prefix}.bed.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "    suffix = 'mRp.clN'\n    prefix = \"consensus_peaks.${suffix}\"\n    mergecols = params.narrow_peak ? (2..10).join(',') : (2..9).join(',')\n    collapsecols = params.narrow_peak ? (['collapse']*9).join(',') : (['collapse']*8).join(',')\n    expandparam = params.narrow_peak ? '--is_narrow_peak' : ''\n    \"\"\"\n    sort -T '.' -k1,1 -k2,2n ${peaks.collect{it.toString()}.sort().join(' ')} \\\\\n        | mergeBed -c $mergecols -o $collapsecols > ${prefix}.txt\n\n    macs2_merged_expand.py \\\\\n        ${prefix}.txt \\\\\n        ${peaks.collect{it.toString()}.sort().join(',').replaceAll(\"_peaks.${PEAK_TYPE}\",\"\")} \\\\\n        ${prefix}.boolean.txt \\\\\n        $expandparam\n\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$1, \\$2, \\$3, \\$4, \"0\", \"+\" }' ${prefix}.boolean.txt > ${prefix}.bed\n\n    echo -e \"GeneID\\tChr\\tStart\\tEnd\\tStrand\" > ${prefix}.saf\n    awk -v FS='\\t' -v OFS='\\t' 'FNR > 1 { print \\$4, \\$1, \\$2, \\$3,  \"+\" }' ${prefix}.boolean.txt >> ${prefix}.saf\n\n    sed -i 's/.${suffix}//g' ${prefix}.boolean.intersect.txt\n    plot_peak_intersect.r -i ${prefix}.boolean.intersect.txt -o ${prefix}.boolean.intersect.plot.pdf\n\n    find * -type f -name \"${prefix}.bed\" -exec echo -e \"bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus/\"{}\"\\\\t0,0,0\" \\\\; > ${prefix}.bed.igv.txt\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mrep_macs_consensus"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_mrep_macs_consensus_bed",
            "ch_mrep_macs_consensus_saf",
            "ch_mrep_macs_consensus_bool",
            "ch_mrep_macs_consensus_igv"
        ],
        "nb_outputs": 4,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_long'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.igv.txt')) null else filename }"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks",
        "stub": ""
    },
    "MERGED_REP_CONSENSUS_ANNOTATE": {
        "name_process": "MERGED_REP_CONSENSUS_ANNOTATE",
        "string_process": "\nprocess MERGED_REP_CONSENSUS_ANNOTATE {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks && !params.skip_peak_annotation\n\n    input:\n    path bed from ch_mrep_macs_consensus_bed\n    path bool from ch_mrep_macs_consensus_bool\n    path fasta from ch_fasta\n    path gtf from ch_gtf\n\n    output:\n    path '*.annotatePeaks.txt'\n\n    script:\n    prefix = 'consensus_peaks.mRp.clN'\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $bed \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}.annotatePeaks.txt\n\n    cut -f2- ${prefix}.annotatePeaks.txt | awk 'NR==1; NR > 1 {print \\$0 | \"sort -T '.' -k1,1 -k2,2n\"}' | cut -f6- > tmp.txt\n    paste $bool tmp.txt > ${prefix}.boolean.annotatePeaks.txt\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    prefix = 'consensus_peaks.mRp.clN'\n    \"\"\"\n    annotatePeaks.pl \\\\\n        $bed \\\\\n        $fasta \\\\\n        -gid \\\\\n        -gtf $gtf \\\\\n        -cpu $task.cpus \\\\\n        > ${prefix}.annotatePeaks.txt\n\n    cut -f2- ${prefix}.annotatePeaks.txt | awk 'NR==1; NR > 1 {print \\$0 | \"sort -T '.' -k1,1 -k2,2n\"}' | cut -f6- > tmp.txt\n    paste $bool tmp.txt > ${prefix}.boolean.annotatePeaks.txt\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mrep_macs_consensus_bed",
            "ch_mrep_macs_consensus_bool",
            "ch_fasta",
            "ch_gtf"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks && !params.skip_peak_annotation",
        "stub": ""
    },
    "MERGED_REP_CONSENSUS_COUNTS": {
        "name_process": "MERGED_REP_CONSENSUS_COUNTS",
        "string_process": "\nprocess MERGED_REP_CONSENSUS_COUNTS {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks\n\n    input:\n    path bams from ch_mlib_name_bam_mrep_counts.collect{ it[1] }\n    path saf from ch_mrep_macs_consensus_saf.collect()\n\n    output:\n    path '*featureCounts.txt' into ch_mrep_macs_consensus_counts\n    path '*featureCounts.txt.summary' into ch_mrep_macs_consensus_counts_mqc\n\n    script:\n    prefix = 'consensus_peaks.mRp.clN'\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    pe_params = params.single_end ? '' : '-p --donotsort'\n    \"\"\"\n    featureCounts \\\\\n        -F SAF \\\\\n        -O \\\\\n        --fracOverlap 0.2 \\\\\n        -T $task.cpus \\\\\n        $pe_params \\\\\n        -a $saf \\\\\n        -o ${prefix}.featureCounts.txt \\\\\n        ${bam_files.join(' ')}\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    prefix = 'consensus_peaks.mRp.clN'\n    bam_files = bams.findAll { it.toString().endsWith('.bam') }.sort()\n    pe_params = params.single_end ? '' : '-p --donotsort'\n    \"\"\"\n    featureCounts \\\\\n        -F SAF \\\\\n        -O \\\\\n        --fracOverlap 0.2 \\\\\n        -T $task.cpus \\\\\n        $pe_params \\\\\n        -a $saf \\\\\n        -o ${prefix}.featureCounts.txt \\\\\n        ${bam_files.join(' ')}\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "FeatureCounts"
        ],
        "tools_url": [
            "https://bio.tools/featurecounts"
        ],
        "tools_dico": [
            {
                "name": "FeatureCounts",
                "uri": "https://bio.tools/featurecounts",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3793",
                                    "term": "Read summarisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "featureCounts is a very efficient read quantifier. It can be used to summarize RNA-seq reads and gDNA-seq reads to a variety of genomic features such as genes, exons, promoters, gene bodies and genomic bins. It is included in the Bioconductor Rsubread package and also in the SourceForge Subread package.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rsubread.html"
            }
        ],
        "inputs": [
            "ch_mlib_name_bam_mrep_counts",
            "ch_mrep_macs_consensus_saf"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_mrep_macs_consensus_counts",
            "ch_mrep_macs_consensus_counts_mqc"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks",
        "stub": ""
    },
    "MERGED_REP_CONSENSUS_DESEQ2": {
        "name_process": "MERGED_REP_CONSENSUS_DESEQ2",
        "string_process": "\nprocess MERGED_REP_CONSENSUS_DESEQ2 {\n    label 'process_medium'\n    publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus/deseq2\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.endsWith('.igv.txt')) null\n                      else filename\n                }\n\n    when:\n    !params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks && !params.skip_diff_analysis\n\n    input:\n    path counts from ch_mrep_macs_consensus_counts\n    path mrep_deseq2_pca_header from ch_mrep_deseq2_pca_header\n    path mrep_deseq2_clustering_header from ch_mrep_deseq2_clustering_header\n\n    output:\n    path '*.tsv' into ch_mrep_macs_consensus_deseq_mqc\n    path '*igv.txt' into ch_mrep_macs_consensus_deseq_comp_igv\n    path '*.{RData,results.txt,pdf,log}'\n    path 'sizeFactors'\n    path '*vs*/*.{pdf,txt}'\n    path '*vs*/*.bed'\n\n    script:\n    prefix = 'consensus_peaks.mRp.clN'\n    bam_ext = params.single_end ? '.mLb.clN.sorted.bam' : '.mLb.clN.bam'\n    vst = params.deseq2_vst ? '--vst TRUE' : ''\n    \"\"\"\n    featurecounts_deseq2.r \\\\\n        --featurecount_file $counts \\\\\n        --bam_suffix '$bam_ext' \\\\\n        --outdir ./ \\\\\n        --outprefix $prefix \\\\\n        --outsuffix .mRp.clN \\\\\n        --cores $task.cpus \\\\\n        $vst\n\n    cat $mrep_deseq2_pca_header ${prefix}.pca.vals.txt > ${prefix}.pca.vals_mqc.tsv\n    cat $mrep_deseq2_clustering_header ${prefix}.sample.dists.txt > ${prefix}.sample.dists_mqc.tsv\n\n    find * -type f -name \"*.FDR0.05.results.bed\" -exec echo -e \"bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus/deseq2/\"{}\"\\\\t255,0,0\" \\\\; > ${prefix}.igv.txt\n    \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "    prefix = 'consensus_peaks.mRp.clN'\n    bam_ext = params.single_end ? '.mLb.clN.sorted.bam' : '.mLb.clN.bam'\n    vst = params.deseq2_vst ? '--vst TRUE' : ''\n    \"\"\"\n    featurecounts_deseq2.r \\\\\n        --featurecount_file $counts \\\\\n        --bam_suffix '$bam_ext' \\\\\n        --outdir ./ \\\\\n        --outprefix $prefix \\\\\n        --outsuffix .mRp.clN \\\\\n        --cores $task.cpus \\\\\n        $vst\n\n    cat $mrep_deseq2_pca_header ${prefix}.pca.vals.txt > ${prefix}.pca.vals_mqc.tsv\n    cat $mrep_deseq2_clustering_header ${prefix}.sample.dists.txt > ${prefix}.sample.dists_mqc.tsv\n\n    find * -type f -name \"*.FDR0.05.results.bed\" -exec echo -e \"bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus/deseq2/\"{}\"\\\\t255,0,0\" \\\\; > ${prefix}.igv.txt\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_mrep_macs_consensus_counts",
            "ch_mrep_deseq2_pca_header",
            "ch_mrep_deseq2_clustering_header"
        ],
        "nb_inputs": 3,
        "outputs": [
            "ch_mrep_macs_consensus_deseq_mqc",
            "ch_mrep_macs_consensus_deseq_comp_igv"
        ],
        "nb_outputs": 2,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/bwa/mergedReplicate/macs/${PEAK_TYPE}/consensus/deseq2\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.endsWith('.igv.txt')) null else filename }"
        ],
        "when": "!params.skip_merge_replicates && replicatesExist && params.macs_gsize && multipleGroups && !params.skip_consensus_peaks && !params.skip_diff_analysis",
        "stub": ""
    },
    "IGV": {
        "name_process": "IGV",
        "string_process": "\nprocess IGV {\n    publishDir \"${params.outdir}/igv/${PEAK_TYPE}\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_igv\n\n    input:\n    path fasta from ch_fasta\n\n    path bigwigs from ch_mlib_bigwig_igv.collect().ifEmpty([])\n    path peaks from ch_mlib_macs_igv.collect().ifEmpty([])\n    path consensus_peaks from ch_mlib_macs_consensus_igv.collect().ifEmpty([])\n    path differential_peaks from ch_mlib_macs_consensus_deseq_comp_igv.collect().ifEmpty([])\n\n    path rbigwigs from ch_mrep_bigwig_igv.collect().ifEmpty([])\n    path rpeaks from ch_mrep_macs_igv.collect().ifEmpty([])\n    path rconsensus_peaks from ch_mrep_macs_consensus_igv.collect().ifEmpty([])\n    path rdifferential_peaks from ch_mrep_macs_consensus_deseq_comp_igv.collect().ifEmpty([])\n\n    output:\n    path '*.{txt,xml}'\n\n    script:                                                                  \n    \"\"\"\n    cat *.txt > igv_files.txt\n    igv_files_to_session.py igv_session.xml igv_files.txt ../../genome/${fasta.getName()} --path_prefix '../../'\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    cat *.txt > igv_files.txt\n    igv_files_to_session.py igv_session.xml igv_files.txt ../../genome/${fasta.getName()} --path_prefix '../../'\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_fasta",
            "ch_mlib_bigwig_igv",
            "ch_mlib_macs_igv",
            "ch_mlib_macs_consensus_igv",
            "ch_mlib_macs_consensus_deseq_comp_igv",
            "ch_mrep_bigwig_igv",
            "ch_mrep_macs_igv",
            "ch_mrep_macs_consensus_igv",
            "ch_mrep_macs_consensus_deseq_comp_igv"
        ],
        "nb_inputs": 9,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "publishDir \"${params.outdir}/igv/${PEAK_TYPE}\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_igv",
        "stub": ""
    },
    "get_software_versions": {
        "name_process": "get_software_versions",
        "string_process": "\nprocess get_software_versions {\n    publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode,\n        saveAs: { filename ->\n                      if (filename.indexOf('.csv') > 0) filename\n                      else null\n                }\n\n    output:\n    path 'software_versions_mqc.yaml' into ch_software_versions_mqc\n    path 'software_versions.csv'\n\n    script:\n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    trim_galore --version > v_trim_galore.txt\n    echo \\$(bwa 2>&1) > v_bwa.txt\n    samtools --version > v_samtools.txt\n    bedtools --version > v_bedtools.txt\n    echo \\$(bamtools --version 2>&1) > v_bamtools.txt\n    echo \\$(plotFingerprint --version 2>&1) > v_deeptools.txt || true\n    picard MarkDuplicates --version &> v_picard.txt  || true\n    echo \\$(R --version 2>&1) > v_R.txt\n    python -c \"import pysam; print(pysam.__version__)\" > v_pysam.txt\n    echo \\$(macs2 --version 2>&1) > v_macs2.txt\n    touch v_homer.txt\n    echo \\$(ataqv --version 2>&1) > v_ataqv.txt\n    echo \\$(featureCounts -v 2>&1) > v_featurecounts.txt\n    preseq &> v_preseq.txt\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    trim_galore --version > v_trim_galore.txt\n    echo \\$(bwa 2>&1) > v_bwa.txt\n    samtools --version > v_samtools.txt\n    bedtools --version > v_bedtools.txt\n    echo \\$(bamtools --version 2>&1) > v_bamtools.txt\n    echo \\$(plotFingerprint --version 2>&1) > v_deeptools.txt || true\n    picard MarkDuplicates --version &> v_picard.txt  || true\n    echo \\$(R --version 2>&1) > v_R.txt\n    python -c \"import pysam; print(pysam.__version__)\" > v_pysam.txt\n    echo \\$(macs2 --version 2>&1) > v_macs2.txt\n    touch v_homer.txt\n    echo \\$(ataqv --version 2>&1) > v_ataqv.txt\n    echo \\$(featureCounts -v 2>&1) > v_featurecounts.txt\n    preseq &> v_preseq.txt\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "FastQC",
            "SAMtools",
            "BEDTools",
            "Picard",
            "preseq",
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc",
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools",
            "https://bio.tools/picard_tools",
            "https://bio.tools/preseq",
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "preseq",
                "uri": "https://bio.tools/preseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package is aimed at predicting and number of distinct reads and how many will be expected from additional sequencing using an initial sequencing experiment. The estimates can then be used to examine the utility of further sequencing, optimize the sequencing depth, or to screen multiple libraries to avoid low complexity samples.",
                "homepage": "http://smithlabresearch.org/software/preseq/"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "ch_software_versions_mqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode , saveAs: { filename -> if (filename.indexOf('.csv') > 0) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "MULTIQC": {
        "name_process": "MULTIQC",
        "string_process": "\nprocess MULTIQC {\n    publishDir \"${params.outdir}/multiqc/${PEAK_TYPE}\", mode: params.publish_dir_mode\n\n    when:\n    !params.skip_multiqc\n\n    input:\n    path (multiqc_config) from ch_multiqc_config\n    path (mqc_custom_config) from ch_multiqc_custom_config.collect().ifEmpty([])\n\n    path ('software_versions/*') from ch_software_versions_mqc.collect()\n    path workflow_summary from ch_workflow_summary.collectFile(name: 'workflow_summary_mqc.yaml')\n\n    path ('fastqc/*') from ch_fastqc_reports_mqc.collect().ifEmpty([])\n    path ('trimgalore/*') from ch_trimgalore_results_mqc.collect().ifEmpty([])\n    path ('trimgalore/fastqc/*') from ch_trimgalore_fastqc_reports_mqc.collect().ifEmpty([])\n\n    path ('alignment/library/*') from ch_sort_bam_flagstat_mqc.collect()\n\n    path ('alignment/mergedLibrary/*') from ch_mlib_bam_stats_mqc.collect()\n    path ('alignment/mergedLibrary/*') from ch_mlib_rm_orphan_flagstat_mqc.collect{it[1]}\n    path ('alignment/mergedLibrary/*') from ch_mlib_rm_orphan_stats_mqc.collect()\n    path ('alignment/mergedLibrary/picard_metrics/*') from ch_mlib_bam_metrics_mqc.collect()\n    path ('alignment/mergedLibrary/picard_metrics/*') from ch_mlib_collectmetrics_mqc.collect()\n    path ('macs/mergedLibrary/*') from ch_mlib_macs_mqc.collect().ifEmpty([])\n    path ('macs/mergedLibrary/*') from ch_mlib_peak_qc_mqc.collect().ifEmpty([])\n    path ('macs/mergedLibrary/consensus/*') from ch_mlib_macs_consensus_counts_mqc.collect().ifEmpty([])\n    path ('macs/mergedLibrary/consensus/*') from ch_mlib_macs_consensus_deseq_mqc.collect().ifEmpty([])\n    path ('preseq/*') from ch_mlib_preseq_mqc.collect().ifEmpty([])\n    path ('deeptools/*') from ch_mlib_plotprofile_mqc.collect().ifEmpty([])\n    path ('deeptools/*') from ch_mlib_plotfingerprint_mqc.collect().ifEmpty([])\n\n    path ('alignment/mergedReplicate/*') from ch_mrep_bam_flagstat_mqc.collect{it[1]}.ifEmpty([])\n    path ('alignment/mergedReplicate/*') from ch_mrep_bam_stats_mqc.collect().ifEmpty([])\n    path ('alignment/mergedReplicate/*') from ch_mrep_bam_metrics_mqc.collect().ifEmpty([])\n    path ('macs/mergedReplicate/*') from ch_mrep_macs_mqc.collect().ifEmpty([])\n    path ('macs/mergedReplicate/*') from ch_mrep_peak_qc_mqc.collect().ifEmpty([])\n    path ('macs/mergedReplicate/consensus/*') from ch_mrep_macs_consensus_counts_mqc.collect().ifEmpty([])\n    path ('macs/mergedReplicate/consensus/*') from ch_mrep_macs_consensus_deseq_mqc.collect().ifEmpty([])\n\n    output:\n    path '*multiqc_report.html' into ch_multiqc_report\n    path '*_data'\n\n    script:\n    rtitle = custom_runName ? \"--title \\\"$custom_runName\\\"\" : ''\n    rfilename = custom_runName ? \"--filename \" + custom_runName.replaceAll('\\\\W','_').replaceAll('_+','_') + \"_multiqc_report\" : ''\n    custom_config_file = params.multiqc_config ? \"--config $mqc_custom_config\" : ''\n    \"\"\"\n    multiqc . -f $rtitle $rfilename $custom_config_file\n    \"\"\"\n}",
        "nb_lignes_process": 51,
        "string_script": "    rtitle = custom_runName ? \"--title \\\"$custom_runName\\\"\" : ''\n    rfilename = custom_runName ? \"--filename \" + custom_runName.replaceAll('\\\\W','_').replaceAll('_+','_') + \"_multiqc_report\" : ''\n    custom_config_file = params.multiqc_config ? \"--config $mqc_custom_config\" : ''\n    \"\"\"\n    multiqc . -f $rtitle $rfilename $custom_config_file\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "ch_multiqc_config",
            "ch_multiqc_custom_config",
            "ch_software_versions_mqc",
            "ch_workflow_summary",
            "ch_fastqc_reports_mqc",
            "ch_trimgalore_results_mqc",
            "ch_trimgalore_fastqc_reports_mqc",
            "ch_sort_bam_flagstat_mqc",
            "ch_mlib_bam_stats_mqc",
            "ch_mlib_rm_orphan_flagstat_mqc",
            "ch_mlib_rm_orphan_stats_mqc",
            "ch_mlib_bam_metrics_mqc",
            "ch_mlib_collectmetrics_mqc",
            "ch_mlib_macs_mqc",
            "ch_mlib_peak_qc_mqc",
            "ch_mlib_macs_consensus_counts_mqc",
            "ch_mlib_macs_consensus_deseq_mqc",
            "ch_mlib_preseq_mqc",
            "ch_mlib_plotprofile_mqc",
            "ch_mlib_plotfingerprint_mqc",
            "ch_mrep_bam_flagstat_mqc",
            "ch_mrep_bam_stats_mqc",
            "ch_mrep_bam_metrics_mqc",
            "ch_mrep_macs_mqc",
            "ch_mrep_peak_qc_mqc",
            "ch_mrep_macs_consensus_counts_mqc",
            "ch_mrep_macs_consensus_deseq_mqc"
        ],
        "nb_inputs": 27,
        "outputs": [
            "ch_multiqc_report"
        ],
        "nb_outputs": 1,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "publishDir \"${params.outdir}/multiqc/${PEAK_TYPE}\", mode: params.publish_dir_mode"
        ],
        "when": "!params.skip_multiqc",
        "stub": ""
    },
    "output_documentation": {
        "name_process": "output_documentation",
        "string_process": "\nprocess output_documentation {\n    publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode\n\n    input:\n    path output_docs from ch_output_docs\n    path images from ch_output_docs_images\n\n    output:\n    path 'results_description.html'\n\n    script:\n    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    markdown_to_html.py $output_docs -o results_description.html\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_output_docs",
            "ch_output_docs_images"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "lengfei5__atacseq_nf",
        "directive": [
            "publishDir \"${params.outdir}/pipeline_info\", mode: params.publish_dir_mode"
        ],
        "when": "",
        "stub": ""
    }
}