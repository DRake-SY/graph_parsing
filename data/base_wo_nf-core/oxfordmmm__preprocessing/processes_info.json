{
    "checkBamValidity": {
        "name_process": "checkBamValidity",
        "string_process": "\nprocess checkBamValidity {\n       \n                                                       \n      \n\n    tag { bam_file.getBaseName() }\n  \n    publishDir \"${params.output_dir}/${bam_file.getBaseName()}\", mode: 'copy', pattern: '*.log'\n\n    memory '5 GB'\n\n    input:\n    path(bam_file)\n   \n    output:\n    tuple path(bam_file), stdout, emit: checkValidity_bam\n\n    script:\n    error_log = \"${bam_file.getBaseName()}.log\"\n\t\t\t\n    \"\"\"\n    is_ok=\\$(samtools quickcheck $bam_file && echo 'OK' || echo 'FAIL' )\n\n    if [ \\$is_ok == 'OK' ]; then printf \"\" >> ${error_log}; else echo \"error: bam did not pass samtools quickcheck\" >> ${error_log}; fi\n    printf \\$is_ok\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    error_log = \"${bam_file.getBaseName()}.log\"\n\t\t\t\n    \"\"\"\n    is_ok=\\$(samtools quickcheck $bam_file && echo 'OK' || echo 'FAIL' )\n\n    if [ \\$is_ok == 'OK' ]; then printf \"\" >> ${error_log}; else echo \"error: bam did not pass samtools quickcheck\" >> ${error_log}; fi\n    printf \\$is_ok\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bam_file"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { bam_file.getBaseName() }",
            "publishDir \"${params.output_dir}/${bam_file.getBaseName()}\", mode: 'copy', pattern: '*.log'",
            "memory '5 GB'"
        ],
        "when": "",
        "stub": ""
    },
    "checkFqValidity": {
        "name_process": "checkFqValidity",
        "string_process": "\nprocess checkFqValidity {\n       \n                                                              \n      \n   \n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'\n\n    memory '5 GB'\n\n    input:\n    tuple val(sample_name), path(fq1), path(fq2)\n\t\n    output:\n    tuple val(sample_name), path(fq1), path(fq2), stdout, emit: checkValidity_fqs\n    path(\"${sample_name}.log\", emit: checkValidity_log)\n\t\t\n    script:\n    error_log  = \"${sample_name}.log\"\n\t\n    \"\"\"\n    is_ok=\\$(fqtools validate $fq1 $fq2)\n\n    if [ \\$is_ok == 'OK' ]; then printf \"\" >> ${error_log}; else echo \"error: sample did not pass fqtools validation check\" >> ${error_log}; fi\n    printf \\$is_ok\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    error_log  = \"${sample_name}.log\"\n\t\n    \"\"\"\n    is_ok=\\$(fqtools validate $fq1 $fq2)\n\n    if [ \\$is_ok == 'OK' ]; then printf \"\" >> ${error_log}; else echo \"error: sample did not pass fqtools validation check\" >> ${error_log}; fi\n    printf \\$is_ok\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_name",
            "fq1",
            "fq2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'",
            "memory '5 GB'"
        ],
        "when": "",
        "stub": ""
    },
    "bam2fastq": {
        "name_process": "bam2fastq",
        "string_process": "\nprocess bam2fastq {\n       \n                        \n      \n\n    tag { bam_file.getBaseName() }\n\n    memory '5 GB'\n    \n    when:\n    is_ok == 'OK'    \n\n    input:\n    path(bam_file)\n    \n    output:\n    tuple val(\"${bam_file.getBaseName()}\"), path(\"${bam_file.getBaseName()}_1.fq.gz\"), path(\"${bam_file.getBaseName()}_2.fq.gz\"), emit: bam2fastq_fqs\n\n    script:\n    \"\"\"\n    samtools sort -n $bam_file -o ${bam_file.getBaseName()}.sorted.bam\n\n    bedtools bamtofastq -i ${bam_file.getBaseName()}.sorted.bam -fq ${bam_file.getBaseName()}_1.fq -fq2 ${bam_file.getBaseName()}_2.fq\n\n    rm ${bam_file.getBaseName()}.sorted.bam\n\n    gzip ${bam_file.getBaseName()}_1.fq || true\n    gzip ${bam_file.getBaseName()}_2.fq || true\n\n    printf 'OK'\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    samtools sort -n $bam_file -o ${bam_file.getBaseName()}.sorted.bam\n\n    bedtools bamtofastq -i ${bam_file.getBaseName()}.sorted.bam -fq ${bam_file.getBaseName()}_1.fq -fq2 ${bam_file.getBaseName()}_2.fq\n\n    rm ${bam_file.getBaseName()}.sorted.bam\n\n    gzip ${bam_file.getBaseName()}_1.fq || true\n    gzip ${bam_file.getBaseName()}_2.fq || true\n\n    printf 'OK'\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "bam_file"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { bam_file.getBaseName() }",
            "memory '5 GB'"
        ],
        "when": "is_ok == 'OK'",
        "stub": ""
    },
    "countReads": {
        "name_process": "countReads",
        "string_process": "\nprocess countReads {\n       \n                                                             \n      \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'\n\n    memory '5 GB'\n\n    when:\n    is_ok == 'OK'\n  \n    input:\n    tuple val(sample_name), path(fq1), path(fq2), val(is_ok)\n\n    output:\n    tuple val(sample_name), path(fq1), path(fq2), stdout, emit: countReads_fqs\n    path(\"${sample_name}.log\", emit: countReads_log)\n\n    script:\n    error_log = \"${sample_name}.log\"\n    \"\"\"\n    num_reads=\\$(fqtools count $fq1 $fq2)\n\n    if (( \\$num_reads > 100000 )); then printf \"\" >> ${error_log} && printf \"pass\"; else echo \"error: sample did not have > 100k pairs of raw reads (it only contained \\$num_reads)\" >> ${error_log} && printf \"fail\"; fi\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    error_log = \"${sample_name}.log\"\n    \"\"\"\n    num_reads=\\$(fqtools count $fq1 $fq2)\n\n    if (( \\$num_reads > 100000 )); then printf \"\" >> ${error_log} && printf \"pass\"; else echo \"error: sample did not have > 100k pairs of raw reads (it only contained \\$num_reads)\" >> ${error_log} && printf \"fail\"; fi\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_name",
            "is_ok",
            "fq1",
            "fq2"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'",
            "memory '5 GB'"
        ],
        "when": "is_ok == 'OK'",
        "stub": ""
    },
    "fastp": {
        "name_process": "fastp",
        "string_process": "\nprocess fastp {\n       \n                                                                             \n      \n     \n    tag { sample_name }\n \n    publishDir \"${params.output_dir}/$sample_name/raw_read_QC_reports\", mode: 'copy', pattern: '*.json'\n    publishDir \"${params.output_dir}/$sample_name/output_reads\", mode: 'copy', pattern: '*.fq.gz'                                         \n    publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'\n\n    memory '5 GB'\n\n    when:\n    run_fastp == 'pass'\n\n    input:\n    tuple val(sample_name), path(fq1), path(fq2), val(run_fastp)\n\t\t\n    output:\n    tuple val(sample_name), path(\"${sample_name}_cleaned_1.fq.gz\"), path(\"${sample_name}_cleaned_2.fq.gz\"), stdout, emit: fastp_fqs\n    path(\"${sample_name}_fastp.json\", emit: fastp_json)\n    path(\"${sample_name}.log\", emit: fastp_log)\n   \n    script:\n    clean_fq1  = \"${sample_name}_cleaned_1.fq.gz\"\n    clean_fq2  = \"${sample_name}_cleaned_2.fq.gz\"\n    fastp_json = \"${sample_name}_fastp.json\"\n    fastp_html = \"${sample_name}_fastp.html\"\n    error_log  = \"${sample_name}.log\"\n\t\n    \"\"\"\n    fastp -i $fq1 -I $fq2 -o ${clean_fq1} -O ${clean_fq2} -j ${fastp_json} -h ${fastp_html} --length_required 50 --average_qual 10 --low_complexity_filter --correction --cut_right --cut_tail --cut_tail_window_size 1 --cut_tail_mean_quality 20\n    \n    rm -rf ${fastp_html}\n\n    num_reads=\\$(jq '.summary.after_filtering.total_reads' ${fastp_json} | awk '{sum+=\\$0} END{print sum}')\n\n    if (( \\$num_reads > 100000 )); then printf \"\" >> ${error_log} && printf \"pass\"; else echo \"error: after fastp, sample did not have > 100k reads (it only contained \\$num_reads)\" >> ${error_log} && printf \"fail\"; fi\n    \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "    clean_fq1  = \"${sample_name}_cleaned_1.fq.gz\"\n    clean_fq2  = \"${sample_name}_cleaned_2.fq.gz\"\n    fastp_json = \"${sample_name}_fastp.json\"\n    fastp_html = \"${sample_name}_fastp.html\"\n    error_log  = \"${sample_name}.log\"\n\t\n    \"\"\"\n    fastp -i $fq1 -I $fq2 -o ${clean_fq1} -O ${clean_fq2} -j ${fastp_json} -h ${fastp_html} --length_required 50 --average_qual 10 --low_complexity_filter --correction --cut_right --cut_tail --cut_tail_window_size 1 --cut_tail_mean_quality 20\n    \n    rm -rf ${fastp_html}\n\n    num_reads=\\$(jq '.summary.after_filtering.total_reads' ${fastp_json} | awk '{sum+=\\$0} END{print sum}')\n\n    if (( \\$num_reads > 100000 )); then printf \"\" >> ${error_log} && printf \"pass\"; else echo \"error: after fastp, sample did not have > 100k reads (it only contained \\$num_reads)\" >> ${error_log} && printf \"fail\"; fi\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "sample_name",
            "run_fastp",
            "fq1",
            "fq2"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/raw_read_QC_reports\", mode: 'copy', pattern: '*.json'",
            "publishDir \"${params.output_dir}/$sample_name/output_reads\", mode: 'copy', pattern: '*.fq.gz'",
            "publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'",
            "memory '5 GB'"
        ],
        "when": "run_fastp == 'pass'",
        "stub": ""
    },
    "fastQC": {
        "name_process": "fastQC",
        "string_process": "\nprocess fastQC {\n       \n                        \n      \n\t\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/raw_read_QC_reports\", mode: 'copy'\n\n    memory '5 GB'\n\n    input:\n    tuple val(sample_name), path(fq1), path(fq2), val(enough_reads)\n\t\n    output:\n    path(\"*\", emit: fastQC_all)\n\t\n    script:\n    \"\"\"\n    cat $fq1 $fq2 > ${sample_name}.fq.gz\n    fastqc ${sample_name}.fq.gz\n    rm ${sample_name}.fq.gz\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    cat $fq1 $fq2 > ${sample_name}.fq.gz\n    fastqc ${sample_name}.fq.gz\n    rm ${sample_name}.fq.gz\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "sample_name",
            "enough_reads",
            "fq1",
            "fq2"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/raw_read_QC_reports\", mode: 'copy'",
            "memory '5 GB'"
        ],
        "when": "",
        "stub": ""
    },
    "kraken2": {
        "name_process": "kraken2",
        "string_process": "\nprocess kraken2 {\n       \n                                                                                                  \n      \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedReads\", mode: 'copy', pattern: '*_kraken_report.*'\n    publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'\n       \n    cpus 8\n\n    memory '10 GB'\n\n    when:\n    enough_reads == 'pass'\n\n    input:\n    tuple val(sample_name), path(fq1), path(fq2), val(enough_reads)\n    path(database)\n\t\t\n    output:\n    tuple path(\"${sample_name}_kraken_report.txt\"), path(\"${sample_name}_kraken_report.json\"), emit: kraken2_report\n    tuple val(sample_name), path(\"${sample_name}_clean_exclNonBacteria_1.fq.gz\"), path(\"${sample_name}_clean_exclNonBacteria_2.fq.gz\"), stdout, emit: kraken2_fqs\n    path(\"${sample_name}.log\", emit: kraken2_log)\n\t\t\t\n    script:\n    kraken2_report = \"${sample_name}_kraken_report.txt\"\n    kraken2_json = \"${sample_name}_kraken_report.json\"\n    kraken2_read_classification = \"${sample_name}_read_classifications.txt\"\n    nonBac_depleted_reads_1 = \"${sample_name}_clean_exclNonBacteria_1.fq\"\n    nonBac_depleted_reads_2 = \"${sample_name}_clean_exclNonBacteria_2.fq\"\n    error_log = \"${sample_name}.log\"\n\t\n    \"\"\"\n    kraken2 --threads ${task.cpus} --db . --output ${kraken2_read_classification} --report ${kraken2_report} --paired $fq1 $fq2\n\n    perl ${baseDir}/bin/parse_kraken_report2.pl ${kraken2_report} ${kraken2_json} 0.5 5000\n\n    ${baseDir}/bin/extract_kraken_reads.py -k ${kraken2_read_classification} -r ${kraken2_report} -s $fq1 -s2 $fq2 -o ${nonBac_depleted_reads_1} -o2 ${nonBac_depleted_reads_2} --taxid 2 --include-children --fastq-output >/dev/null\n\n    gzip ${nonBac_depleted_reads_1}\n    gzip ${nonBac_depleted_reads_2}\n\n    rm -rf ${sample_name}_read_classifications.txt\n\n    run_mykrobe=\\$(jq '.Mykrobe' ${kraken2_json})\n\n    if [ \\$run_mykrobe == '\\\"true\\\"' ]; then printf \"\" >> ${error_log} && printf \"yes\"; else echo \"error: Kraken's top family hit either wasn't Mycobacteriaceae, or represented < 5000 reads in absolute terms or < 0.5% of the total\" >> ${error_log} && printf \"no\"; fi\n    \"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "    kraken2_report = \"${sample_name}_kraken_report.txt\"\n    kraken2_json = \"${sample_name}_kraken_report.json\"\n    kraken2_read_classification = \"${sample_name}_read_classifications.txt\"\n    nonBac_depleted_reads_1 = \"${sample_name}_clean_exclNonBacteria_1.fq\"\n    nonBac_depleted_reads_2 = \"${sample_name}_clean_exclNonBacteria_2.fq\"\n    error_log = \"${sample_name}.log\"\n\t\n    \"\"\"\n    kraken2 --threads ${task.cpus} --db . --output ${kraken2_read_classification} --report ${kraken2_report} --paired $fq1 $fq2\n\n    perl ${baseDir}/bin/parse_kraken_report2.pl ${kraken2_report} ${kraken2_json} 0.5 5000\n\n    ${baseDir}/bin/extract_kraken_reads.py -k ${kraken2_read_classification} -r ${kraken2_report} -s $fq1 -s2 $fq2 -o ${nonBac_depleted_reads_1} -o2 ${nonBac_depleted_reads_2} --taxid 2 --include-children --fastq-output >/dev/null\n\n    gzip ${nonBac_depleted_reads_1}\n    gzip ${nonBac_depleted_reads_2}\n\n    rm -rf ${sample_name}_read_classifications.txt\n\n    run_mykrobe=\\$(jq '.Mykrobe' ${kraken2_json})\n\n    if [ \\$run_mykrobe == '\\\"true\\\"' ]; then printf \"\" >> ${error_log} && printf \"yes\"; else echo \"error: Kraken's top family hit either wasn't Mycobacteriaceae, or represented < 5000 reads in absolute terms or < 0.5% of the total\" >> ${error_log} && printf \"no\"; fi\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "kraken2",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/kraken2",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "sample_name",
            "enough_reads",
            "fq1",
            "fq2",
            "database"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedReads\", mode: 'copy', pattern: '*_kraken_report.*'",
            "publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'",
            "cpus 8",
            "memory '10 GB'"
        ],
        "when": "enough_reads == 'pass'",
        "stub": ""
    },
    "mykrobe": {
        "name_process": "mykrobe",
        "string_process": "\nprocess mykrobe {\n       \n                        \n      \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedReads\", mode: 'copy', pattern: '*_mykrobe_report.json'\n\n    cpus 8\n\n    memory '5 GB'\n\n    when:\n    run_mykrobe == 'yes'\n\t\n    input:\n    tuple val(sample_name), path(fq1), path(fq2), val(run_mykrobe)\n\t\t\n    output:\n    tuple val(sample_name), path(\"${sample_name}_mykrobe_report.json\"), stdout, emit: mykrobe_report\n\n    script:\n    mykrobe_report = \"${sample_name}_mykrobe_report.json\"\n\t\n    \"\"\"\n    mykrobe predict ${sample_name} tb --threads ${task.cpus} --format json --output ${mykrobe_report} -1 $fq1 $fq2\n    printf 'yes'\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    mykrobe_report = \"${sample_name}_mykrobe_report.json\"\n\t\n    \"\"\"\n    mykrobe predict ${sample_name} tb --threads ${task.cpus} --format json --output ${mykrobe_report} -1 $fq1 $fq2\n    printf 'yes'\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "Mykrobe"
        ],
        "tools_url": [
            "https://bio.tools/Mykrobe"
        ],
        "tools_dico": [
            {
                "name": "Mykrobe",
                "uri": "https://bio.tools/Mykrobe",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3482",
                                    "term": "Antimicrobial resistance prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Antibiotic resistance prediction for Mycobacterium tuberculosis from genome sequence data with Mykrobe.\n\nAntibiotic resistance prediction in minutes.\n\nTable of Contents generated with DocToc.\n\nAMR prediction (Mykrobe predictor).\n\nBefore attempting to install with bioconda, please ensure you have your channels set up as specified in the documentation. If you don't, you may run into issues with an older version of mykrobe being installed",
                "homepage": "https://github.com/mykrobe-tools/mykrobe"
            }
        ],
        "inputs": [
            "sample_name",
            "run_mykrobe",
            "fq1",
            "fq2"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedReads\", mode: 'copy', pattern: '*_mykrobe_report.json'",
            "cpus 8",
            "memory '5 GB'"
        ],
        "when": "run_mykrobe == 'yes'",
        "stub": ""
    },
    "bowtie2": {
        "name_process": "bowtie2",
        "string_process": "\nprocess bowtie2 {\n       \n                        \n      \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/output_reads\", mode: 'copy', pattern: '*.fq.gz', overwrite: 'true'\n\n    cpus 8\n\n    memory '5 GB'\n\n    when:\n    enough_myco_reads == 'yes'\n\n    input:\n    tuple val(sample_name), path(fq1), path(fq2), val(enough_myco_reads)\n    path(index)\n\n    output:\n    tuple val(sample_name), path(\"${sample_name}_cleaned_1.fq.gz\"), path(\"${sample_name}_cleaned_2.fq.gz\"), emit: bowtie2_fqs\n\n    script:\n    bam = \"${sample_name}.bam\"\n    humanfree_fq1 = \"${sample_name}_cleaned_1.fq\"\n    humanfree_fq2 = \"${sample_name}_cleaned_2.fq\"\n\t\n    \"\"\"\n    bowtie2 --very-sensitive -p ${task.cpus} -x ${index}/${params.bowtie_index_name} -1 $fq1 -2 $fq2 | samtools view -f 4 -Shb - > ${bam}\n    samtools fastq -1 ${humanfree_fq1} -2 ${humanfree_fq2} -s singleton.fq ${bam}\n\n    rm -rf ${bam}\n    rm -rf singleton.fq\n\n    gzip -f ${humanfree_fq1}\n    gzip -f ${humanfree_fq2}\n    \"\"\"\t\n}",
        "nb_lignes_process": 38,
        "string_script": "    bam = \"${sample_name}.bam\"\n    humanfree_fq1 = \"${sample_name}_cleaned_1.fq\"\n    humanfree_fq2 = \"${sample_name}_cleaned_2.fq\"\n\t\n    \"\"\"\n    bowtie2 --very-sensitive -p ${task.cpus} -x ${index}/${params.bowtie_index_name} -1 $fq1 -2 $fq2 | samtools view -f 4 -Shb - > ${bam}\n    samtools fastq -1 ${humanfree_fq1} -2 ${humanfree_fq2} -s singleton.fq ${bam}\n\n    rm -rf ${bam}\n    rm -rf singleton.fq\n\n    gzip -f ${humanfree_fq1}\n    gzip -f ${humanfree_fq2}\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "BaMM",
            "Rbowtie2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bamm",
            "https://bio.tools/rbowtie2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BaMM",
                "uri": "https://bio.tools/bamm",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip sequencing"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Sequence motif recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0238",
                                    "term": "Sequence motif discovery"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Motif scanning"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Sequence signature recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Sequence signature detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Over-representation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0238",
                                    "term": "Motif discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "de-novo motif discovery and regulatory sequence analysis.\nDiscovery of regulatory motifs with higher-order Bayesian Markov Models (BaMMs)",
                "homepage": "https://bammmotif.mpibpc.mpg.de"
            },
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_name",
            "enough_myco_reads",
            "fq1",
            "fq2",
            "index"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/output_reads\", mode: 'copy', pattern: '*.fq.gz', overwrite: 'true'",
            "cpus 8",
            "memory '5 GB'"
        ],
        "when": "enough_myco_reads == 'yes'",
        "stub": ""
    },
    "identifyBacterialContaminants": {
        "name_process": "identifyBacterialContaminants",
        "string_process": "\nprocess identifyBacterialContaminants {\n       \n                                                                                                               \n          \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedReads\", mode: 'copy', pattern: '*.json'\n    publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log' \n\n    when:\n    enough_myco_reads == 'yes'\n\n    input:\n    tuple val(sample_name), path(mykrobe_json), val(enough_myco_reads)\n    tuple path(kraken_report), path(kraken_json)\n\t\t\n    output:\n    path(\"${sample_name}_species_in_sample.json\", emit: sample_json)\n    tuple val(sample_name), path(\"${sample_name}_urllist.txt\"), stdout, emit: contam_list\n    path(\"${sample_name}.log\", emit: contam_log)\n\t\t\n    script:\n    error_log = \"${sample_name}.log\"\t\n\n    \"\"\"\n    perl ${baseDir}/bin/identify_tophit_and_contaminants2.pl ${mykrobe_json} ${kraken_json} ${baseDir}/resources/assembly_summary_refseq.txt ${params.species} ${params.unmix_myco}\n\n    num_urls=\\$(cat ${sample_name}_urllist.txt | wc -l)\n\n    contam_to_remove=\\$(jq '.ContaminantsToRemove' ${sample_name}_species_in_sample.json)\n    acceptable_species=\\$(jq '.AcceptableSpecies' ${sample_name}_species_in_sample.json)\n\n    if (( \\$num_urls > 0 )); then printf \"\" >> ${error_log} && printf \"yes\"; else echo \"no contaminant genomes detected for ${sample_name} (note: if --unmix_myco is 'no', contaminating mycobacteria, if any, won't be counted here)\" >> ${error_log} && printf \"no\"; fi\n\n    if [ \\$contam_to_remove == '\\\"no\\\"' ] && [ \\$acceptable_species == '\\\"yes\\\"' ]; then echo \"workflow complete without error\" >> ${error_log}; else echo \"top hit in ${sample_name} is not one of the 10 accepted mycobacteria\" >> ${error_log}; fi\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    error_log = \"${sample_name}.log\"\t\n\n    \"\"\"\n    perl ${baseDir}/bin/identify_tophit_and_contaminants2.pl ${mykrobe_json} ${kraken_json} ${baseDir}/resources/assembly_summary_refseq.txt ${params.species} ${params.unmix_myco}\n\n    num_urls=\\$(cat ${sample_name}_urllist.txt | wc -l)\n\n    contam_to_remove=\\$(jq '.ContaminantsToRemove' ${sample_name}_species_in_sample.json)\n    acceptable_species=\\$(jq '.AcceptableSpecies' ${sample_name}_species_in_sample.json)\n\n    if (( \\$num_urls > 0 )); then printf \"\" >> ${error_log} && printf \"yes\"; else echo \"no contaminant genomes detected for ${sample_name} (note: if --unmix_myco is 'no', contaminating mycobacteria, if any, won't be counted here)\" >> ${error_log} && printf \"no\"; fi\n\n    if [ \\$contam_to_remove == '\\\"no\\\"' ] && [ \\$acceptable_species == '\\\"yes\\\"' ]; then echo \"workflow complete without error\" >> ${error_log}; else echo \"top hit in ${sample_name} is not one of the 10 accepted mycobacteria\" >> ${error_log}; fi\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_name",
            "enough_myco_reads",
            "mykrobe_json",
            "kraken_report",
            "kraken_json"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedReads\", mode: 'copy', pattern: '*.json'",
            "publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'"
        ],
        "when": "enough_myco_reads == 'yes'",
        "stub": ""
    },
    "downloadContamGenomes": {
        "name_process": "downloadContamGenomes",
        "string_process": "\nprocess downloadContamGenomes {\n       \n                                                                                           \n      \n    \n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'\n\n    when:\n    run_decontaminator == 'yes'\n\n    input:\n    tuple val(sample_name), path(contam_list), val(run_decontaminator)\n\t\t\n    output:\n    tuple path(\"${sample_name}_contaminants.fa\"), stdout, emit: contam_fa\n    path(\"${sample_name}.log\", emit: downcontam_log)\n\t\n    script:\n    contaminant_fa = \"${sample_name}_contaminants.fa\"\n    error_log = \"${sample_name}.log\"\n\t\n    \"\"\"\n    wget -i ${contam_list} --spider -nv -a linktestlog.txt 2>&1\n    cat linktestlog.txt | awk '/listing\\\" \\\\[1\\\\]/{print \\$4}' > confirmedurllist.txt\n    wget -i confirmedurllist.txt\n\n    gunzip *.gz\n    cat *.fna > ${contaminant_fa}\n    rm -rf *.fna\n\n    num_urls_in=\\$(cat $contam_list | wc -l)\n    num_urls_out=\\$(cat confirmedurllist.txt | wc -l)\n\n    rm -rf linktestlog.txt confirmedurllist.txt\n\n    if (( \\$num_urls_in == \\$num_urls_out )); then printf \"\" >> ${error_log} && printf \"pass\"; else echo \"error: there were \\$num_urls_in contaminant genomes but only \\$num_urls_out could be downloaded\" >> ${error_log} && printf \"fail\"; fi\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    contaminant_fa = \"${sample_name}_contaminants.fa\"\n    error_log = \"${sample_name}.log\"\n\t\n    \"\"\"\n    wget -i ${contam_list} --spider -nv -a linktestlog.txt 2>&1\n    cat linktestlog.txt | awk '/listing\\\" \\\\[1\\\\]/{print \\$4}' > confirmedurllist.txt\n    wget -i confirmedurllist.txt\n\n    gunzip *.gz\n    cat *.fna > ${contaminant_fa}\n    rm -rf *.fna\n\n    num_urls_in=\\$(cat $contam_list | wc -l)\n    num_urls_out=\\$(cat confirmedurllist.txt | wc -l)\n\n    rm -rf linktestlog.txt confirmedurllist.txt\n\n    if (( \\$num_urls_in == \\$num_urls_out )); then printf \"\" >> ${error_log} && printf \"pass\"; else echo \"error: there were \\$num_urls_in contaminant genomes but only \\$num_urls_out could be downloaded\" >> ${error_log} && printf \"fail\"; fi\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_name",
            "run_decontaminator",
            "contam_list"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'"
        ],
        "when": "run_decontaminator == 'yes'",
        "stub": ""
    },
    "mapToContamFa": {
        "name_process": "mapToContamFa",
        "string_process": "\nprocess mapToContamFa {\n       \n                        \n      \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/output_reads\", mode: 'copy', pattern: '*.fq.gz', overwrite: 'true'\n\n    cpus 8\n\n    memory '10 GB'\n\n    when:\n    does_fa_pass == 'pass'\n\n    input:\n    tuple val(sample_name), path(fq1), path(fq2)\n    tuple path(contam_fa), val(does_fa_pass)\n\t\t\t\n    output:\n    tuple val(sample_name), path(\"${sample_name}_cleaned_1.fq.gz\"), path(\"${sample_name}_cleaned_2.fq.gz\"), emit: reClassification_fqs\n\n    script:\n    bam = \"${sample_name}.bam\"\n    decontam_fq1 = \"${sample_name}_cleaned_1.fq\"\n    decontam_fq2 = \"${sample_name}_cleaned_2.fq\"\n\t\n    \"\"\"\n    bwa index ${contam_fa}\n    bwa mem -t ${task.cpus} -M ${contam_fa} ${fq1} ${fq2} | samtools view -f 4 -f 8 -Shb - > ${bam}\n\n    samtools fastq -1 ${decontam_fq1} -2 ${decontam_fq2} ${bam}\n    rm -rf ${bam}\n\n    gzip -f ${decontam_fq1}\n    gzip -f ${decontam_fq2}\n    \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "    bam = \"${sample_name}.bam\"\n    decontam_fq1 = \"${sample_name}_cleaned_1.fq\"\n    decontam_fq2 = \"${sample_name}_cleaned_2.fq\"\n\t\n    \"\"\"\n    bwa index ${contam_fa}\n    bwa mem -t ${task.cpus} -M ${contam_fa} ${fq1} ${fq2} | samtools view -f 4 -f 8 -Shb - > ${bam}\n\n    samtools fastq -1 ${decontam_fq1} -2 ${decontam_fq2} ${bam}\n    rm -rf ${bam}\n\n    gzip -f ${decontam_fq1}\n    gzip -f ${decontam_fq2}\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "BaMM",
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bamm",
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BaMM",
                "uri": "https://bio.tools/bamm",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "ChIP-sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3169",
                            "term": "Chip sequencing"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Sequence motif recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0238",
                                    "term": "Sequence motif discovery"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Motif scanning"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Sequence signature recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0239",
                                    "term": "Sequence signature detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Enrichment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3501",
                                    "term": "Over-representation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0238",
                                    "term": "Motif discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "de-novo motif discovery and regulatory sequence analysis.\nDiscovery of regulatory motifs with higher-order Bayesian Markov Models (BaMMs)",
                "homepage": "https://bammmotif.mpibpc.mpg.de"
            },
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_name",
            "fq1",
            "fq2",
            "does_fa_pass",
            "contam_fa"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/output_reads\", mode: 'copy', pattern: '*.fq.gz', overwrite: 'true'",
            "cpus 8",
            "memory '10 GB'"
        ],
        "when": "does_fa_pass == 'pass'",
        "stub": ""
    },
    "reKraken": {
        "name_process": "reKraken",
        "string_process": "\nprocess reKraken {\n       \n                        \n      \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedAndUnmixedReads\", mode: 'copy', pattern: '*_kraken_report.*'\n\n    cpus 8\n\n    memory '10 GB'\n    \n    input:\n    tuple val(sample_name), path(fq1), path(fq2)\n    path(database)\n\t\t\n    output:\n    tuple path(\"${sample_name}_kraken_report.txt\"), path(\"${sample_name}_kraken_report.json\"), emit: reKraken_report\n\n    script:\n    kraken2_report = \"${sample_name}_kraken_report.txt\"\n    kraken2_json = \"${sample_name}_kraken_report.json\"\n    kraken2_read_classification = \"${sample_name}_read_classifications.txt\"\n    \n    \"\"\"\n    kraken2 --threads ${task.cpus} --db . --output ${kraken2_read_classification} --report ${kraken2_report} --paired $fq1 $fq2\n\n    perl ${baseDir}/bin/parse_kraken_report2.pl ${kraken2_report} ${kraken2_json} 0.5 5000\n    rm -rf ${sample_name}_read_classifications.txt\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    kraken2_report = \"${sample_name}_kraken_report.txt\"\n    kraken2_json = \"${sample_name}_kraken_report.json\"\n    kraken2_read_classification = \"${sample_name}_read_classifications.txt\"\n    \n    \"\"\"\n    kraken2 --threads ${task.cpus} --db . --output ${kraken2_read_classification} --report ${kraken2_report} --paired $fq1 $fq2\n\n    perl ${baseDir}/bin/parse_kraken_report2.pl ${kraken2_report} ${kraken2_json} 0.5 5000\n    rm -rf ${sample_name}_read_classifications.txt\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "kraken2"
        ],
        "tools_url": [
            "https://bio.tools/kraken2"
        ],
        "tools_dico": [
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            }
        ],
        "inputs": [
            "sample_name",
            "fq1",
            "fq2",
            "database"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedAndUnmixedReads\", mode: 'copy', pattern: '*_kraken_report.*'",
            "cpus 8",
            "memory '10 GB'"
        ],
        "when": "",
        "stub": ""
    },
    "reMykrobe": {
        "name_process": "reMykrobe",
        "string_process": "\nprocess reMykrobe {\n       \n                        \n      \n     \n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedAndUnmixedReads\", mode: 'copy', pattern: '*_mykrobe_report.json'\n\t\n    cpus 8\n\n    memory '5 GB'\n\n    input:\n    tuple val(sample_name), path(fq1), path(fq2)\n\t\t\n    output:\n    tuple val(sample_name), path(\"${sample_name}_mykrobe_report.json\"), emit: reMykrobe_report\n\n    script:\n    mykrobe_report = \"${sample_name}_mykrobe_report.json\"\n\t\n    \"\"\"\n    mykrobe predict ${sample_name} tb --threads ${task.cpus} --format json --output ${mykrobe_report} -1 $fq1 $fq2\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    mykrobe_report = \"${sample_name}_mykrobe_report.json\"\n\t\n    \"\"\"\n    mykrobe predict ${sample_name} tb --threads ${task.cpus} --format json --output ${mykrobe_report} -1 $fq1 $fq2\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "Mykrobe"
        ],
        "tools_url": [
            "https://bio.tools/Mykrobe"
        ],
        "tools_dico": [
            {
                "name": "Mykrobe",
                "uri": "https://bio.tools/Mykrobe",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0632",
                            "term": "Probes and primers"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3482",
                                    "term": "Antimicrobial resistance prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Antibiotic resistance prediction for Mycobacterium tuberculosis from genome sequence data with Mykrobe.\n\nAntibiotic resistance prediction in minutes.\n\nTable of Contents generated with DocToc.\n\nAMR prediction (Mykrobe predictor).\n\nBefore attempting to install with bioconda, please ensure you have your channels set up as specified in the documentation. If you don't, you may run into issues with an older version of mykrobe being installed",
                "homepage": "https://github.com/mykrobe-tools/mykrobe"
            }
        ],
        "inputs": [
            "sample_name",
            "fq1",
            "fq2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedAndUnmixedReads\", mode: 'copy', pattern: '*_mykrobe_report.json'",
            "cpus 8",
            "memory '5 GB'"
        ],
        "when": "",
        "stub": ""
    },
    "summarise": {
        "name_process": "summarise",
        "string_process": "\nprocess summarise {\n       \n                        \n          \n\n    tag { sample_name }\n\n    publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedAndUnmixedReads\", mode: 'copy', pattern: '*.json'\n    publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'\n\n    input:\n    tuple val(sample_name), path(mykrobe_json)\n    tuple path(kraken_report), path(kraken_json)\n\t\t\n    output:\n    path(\"${sample_name}_species_in_sample.json\", emit: summary_json)\n    path(\"${sample_name}.log\", emit: summary_log)\n\t\n    script:\n    error_log = \"${sample_name}.log\"\n\t\n    \"\"\"\n    perl ${baseDir}/bin/identify_tophit_and_contaminants2.pl ${mykrobe_json} ${kraken_json} ${baseDir}/resources/assembly_summary_refseq.txt ${params.species} ${params.unmix_myco}\n\n    contam_to_remove=\\$(jq '.ContaminantsToRemove' ${sample_name}_species_in_sample.json)\n    acceptable_species=\\$(jq '.AcceptableSpecies' ${sample_name}_species_in_sample.json)\n\n    if [ \\$contam_to_remove == '\\\"yes\\\"' ]; then echo \"error: ${sample_name} remains contaminated, even after attempting to resolve this\" >> ${error_log}; fi\n\n    if [ \\$contam_to_remove == '\\\"no\\\"' ] && [ \\$acceptable_species == '\\\"yes\\\"' ]; then echo \"workflow complete without error\" >> ${error_log}; else echo \"error: top hit in ${sample_name} is not one of the 10 accepted mycobacteria\" >> ${error_log}; fi\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    error_log = \"${sample_name}.log\"\n\t\n    \"\"\"\n    perl ${baseDir}/bin/identify_tophit_and_contaminants2.pl ${mykrobe_json} ${kraken_json} ${baseDir}/resources/assembly_summary_refseq.txt ${params.species} ${params.unmix_myco}\n\n    contam_to_remove=\\$(jq '.ContaminantsToRemove' ${sample_name}_species_in_sample.json)\n    acceptable_species=\\$(jq '.AcceptableSpecies' ${sample_name}_species_in_sample.json)\n\n    if [ \\$contam_to_remove == '\\\"yes\\\"' ]; then echo \"error: ${sample_name} remains contaminated, even after attempting to resolve this\" >> ${error_log}; fi\n\n    if [ \\$contam_to_remove == '\\\"no\\\"' ] && [ \\$acceptable_species == '\\\"yes\\\"' ]; then echo \"workflow complete without error\" >> ${error_log}; else echo \"error: top hit in ${sample_name} is not one of the 10 accepted mycobacteria\" >> ${error_log}; fi\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample_name",
            "mykrobe_json",
            "kraken_report",
            "kraken_json"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "oxfordmmm__preprocessing",
        "directive": [
            "tag { sample_name }",
            "publishDir \"${params.output_dir}/$sample_name/speciation_reports_cleanedAndUnmixedReads\", mode: 'copy', pattern: '*.json'",
            "publishDir \"${params.output_dir}/$sample_name\", mode: 'copy', pattern: '*.log'"
        ],
        "when": "",
        "stub": ""
    }
}