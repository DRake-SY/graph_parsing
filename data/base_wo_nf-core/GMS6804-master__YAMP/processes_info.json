{
    "dedup": {
        "name_process": "dedup",
        "string_process": "\nprocess dedup {\n\t\n\tinput:\n\tset file(in1), file(in2) from todedup\n\n\toutput:\n\tfile  \".log.2\" into log2\n\tfile(\"${params.prefix}_dedupe*.fq\") into totrim\n\tfile(\"${params.prefix}_dedupe*.fq\") into topublishdedupe\n\n\twhen:\n\t(params.mode == \"QC\" || params.mode == \"complete\") && params.dedup\n\n\tscript:\n\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. STEP 1 [De-duplication] at \\$sysdate\\\" > .log.2\n\techo \\\" \\\" >> .log.2\n\t\n\t#Sets the maximum memory to the value requested in the config file\n\tmaxmem=\\$(echo \\\"$task.memory\\\" | sed 's/ //g' | sed 's/B//g')\n\t\n\t#Defines command for de-duplication\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"clumpify.sh -Xmx\\\"\\$maxmem\\\" in1=$in1 in2=$in2 out1=${params.prefix}_dedupe_R1.fq out2=${params.prefix}_dedupe_R2.fq qin=$params.qin dedupe subs=0 threads=${task.cpus}\\\"\n\telse\n\t\tCMD=\\\"clumpify.sh -Xmx\\\"\\$maxmem\\\" in=$in1 out=${params.prefix}_dedupe.fq qin=$params.qin dedupe subs=0 threads=${task.cpus}\\\"\n\tfi\n\t\t\t\t\t\n\t#Logs version of the software and executed command (BBmap prints on stderr)\n\tversion=\\$(clumpify.sh --version 2>&1 >/dev/null | grep \\\"BBMap version\\\") \n\techo \\\"Using clumpify.sh in \\$version \\\" >> .log.2\n\techo \\\"Executing command: \\$CMD \\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\t\n\t#De-duplicates\n\texec \\$CMD 2>&1 | tee tmp.log\n\n\t#Logs some figures about sequences passing de-duplication\n\techo  \\\"Clumpify's de-duplication stats: \\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\tsed -n '/Reads In:/,/Duplicates Found:/p' tmp.log >> .log.2\n\techo \\\" \\\" >> .log.2\n\ttotR=\\$(grep \\\"Reads In:\\\" tmp.log | cut -f 1 | cut -d: -f 2 | sed 's/ //g')\n\tremR=\\$(grep \\\"Duplicates Found:\\\" tmp.log | cut -f 1 | cut -d: -f 2 | sed 's/ //g')\n\tsurvivedR=\\$((\\$totR-\\$remR))\n\tpercentage=\\$(echo \\$survivedR \\$totR | awk '{print \\$1/\\$2*100}' )\n\techo \\\"\\$survivedR out of \\$totR paired reads survived de-duplication (\\$percentage%, \\$remR reads removed)\\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\n\t#Measures and logs execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"STEP 1 (Quality control) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\t\"\"\"\n}",
        "nb_lignes_process": 61,
        "string_script": "\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. STEP 1 [De-duplication] at \\$sysdate\\\" > .log.2\n\techo \\\" \\\" >> .log.2\n\t\n\t#Sets the maximum memory to the value requested in the config file\n\tmaxmem=\\$(echo \\\"$task.memory\\\" | sed 's/ //g' | sed 's/B//g')\n\t\n\t#Defines command for de-duplication\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"clumpify.sh -Xmx\\\"\\$maxmem\\\" in1=$in1 in2=$in2 out1=${params.prefix}_dedupe_R1.fq out2=${params.prefix}_dedupe_R2.fq qin=$params.qin dedupe subs=0 threads=${task.cpus}\\\"\n\telse\n\t\tCMD=\\\"clumpify.sh -Xmx\\\"\\$maxmem\\\" in=$in1 out=${params.prefix}_dedupe.fq qin=$params.qin dedupe subs=0 threads=${task.cpus}\\\"\n\tfi\n\t\t\t\t\t\n\t#Logs version of the software and executed command (BBmap prints on stderr)\n\tversion=\\$(clumpify.sh --version 2>&1 >/dev/null | grep \\\"BBMap version\\\") \n\techo \\\"Using clumpify.sh in \\$version \\\" >> .log.2\n\techo \\\"Executing command: \\$CMD \\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\t\n\t#De-duplicates\n\texec \\$CMD 2>&1 | tee tmp.log\n\n\t#Logs some figures about sequences passing de-duplication\n\techo  \\\"Clumpify's de-duplication stats: \\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\tsed -n '/Reads In:/,/Duplicates Found:/p' tmp.log >> .log.2\n\techo \\\" \\\" >> .log.2\n\ttotR=\\$(grep \\\"Reads In:\\\" tmp.log | cut -f 1 | cut -d: -f 2 | sed 's/ //g')\n\tremR=\\$(grep \\\"Duplicates Found:\\\" tmp.log | cut -f 1 | cut -d: -f 2 | sed 's/ //g')\n\tsurvivedR=\\$((\\$totR-\\$remR))\n\tpercentage=\\$(echo \\$survivedR \\$totR | awk '{print \\$1/\\$2*100}' )\n\techo \\\"\\$survivedR out of \\$totR paired reads survived de-duplication (\\$percentage%, \\$remR reads removed)\\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\n\t#Measures and logs execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"STEP 1 (Quality control) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.2\n\techo \\\" \\\" >> .log.2\n\t\"\"\"",
        "nb_lignes_script": 46,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "todedup"
        ],
        "nb_inputs": 1,
        "outputs": [
            "log2",
            "totrim",
            "topublishdedupe"
        ],
        "nb_outputs": 3,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [],
        "when": "(params.mode == \"QC\" || params.mode == \"complete\") && params.dedup",
        "stub": ""
    },
    "trim": {
        "name_process": "trim",
        "string_process": "\nprocess trim {\n\n\tinput:\n   \tset file(reads1), file(reads2) from totrim.concat(mocktrim).flatMap().take(2).buffer(size : 2)\n\tfile(adapters) from Channel.from( file(params.adapters) )\n\tfile(artifacts) from Channel.from( file(params.artifacts) )\n\tfile(phix174ill) from Channel.from( file(params.phix174ill) )\n\n\toutput:\n\tfile  \".log.3\" into log3\n\tfile(\"${params.prefix}_trimmed*.fq\") into trimmedreads\n\tfile(\"${params.prefix}_trimmed*.fq\") into todecontaminate\n\tfile(\"${params.prefix}_trimmed*.fq\") into topublishtrim \t\n\n\twhen:\n\tparams.mode == \"QC\" || params.mode == \"complete\"\n\n   \tscript:\n\t\"\"\"\t\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. STEP 2 [Trimming] at \\$sysdate\\\" > .log.3\n\techo \\\" \\\" >> .log.3\n\n\t#Sets the maximum memory to the value requested in the config file\n\tmaxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n\t#Defines command for trimming of adapters and low quality bases\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=$reads1 in2=$reads2 out=${params.prefix}_trimmed_R1_tmp.fq out2=${params.prefix}_trimmed_R2_tmp.fq outs=${params.prefix}_trimmed_singletons_tmp.fq ktrim=r k=$params.kcontaminants mink=$params.mink hdist=$params.hdist qtrim=rl trimq=$params.phred  minlength=$params.minlength ref=$adapters qin=$params.qin threads=${task.cpus} tbo tpe ow\\\"\n\telse\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=$reads1 out=${params.prefix}_trimmed_tmp.fq ktrim=r k=$params.kcontaminants mink=$params.mink hdist=$params.hdist qtrim=rl trimq=$params.phred  minlength=$params.minlength ref=$adapters qin=$params.qin threads=${task.cpus} tbo tpe ow\\\"\n\tfi\n\t\n\t#Logs version of the software and executed command (BBMap prints on stderr)\n\tversion=\\$(bbduk.sh --version 2>&1 >/dev/null | grep \\\"BBMap version\\\") \n\techo \\\"Using bbduk.sh in \\$version \\\" >> .log.3\n\techo \\\"Using adapters in $params.adapters \\\" >> .log.3\n\techo \\\"Using synthetic contaminants in $params.phix174ill and in $params.artifacts \\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\techo \\\"Executing command: \\$CMD \\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\t\n\t#Trims adapters and low quality bases\t\n\texec \\$CMD 2>&1 | tee tmp.log\n\t\n\t#Logs some figures about sequences passing trimming\n\techo  \\\"BBduk's trimming stats (trimming adapters and low quality reads): \\\" >> .log.3\n\tsed -n '/Input:/,/Result:/p' tmp.log >> .log.3\n\techo \\\" \\\" >> .log.3\t\t\t\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tunpairedR=\\$(wc -l ${params.prefix}_trimmed_singletons_tmp.fq | cut -d\\\" \\\" -f 1)\n\t\tunpairedR=\\$((\\$unpairedR/4))\n\t\techo  \\\"\\$unpairedR singleton reads whose mate was trimmed shorter preserved\\\" >> .log.3\n\t\techo \\\" \\\" >> .log.3\n\tfi\n\n\t#Defines command for removing synthetic contaminants\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=${params.prefix}_trimmed_R1_tmp.fq in2=${params.prefix}_trimmed_R2_tmp.fq out=${params.prefix}_trimmed_R1.fq out2=${params.prefix}_trimmed_R2.fq k=31 ref=$phix174ill,$artifacts qin=$params.qin threads=${task.cpus} ow\\\"\n\telse\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=${params.prefix}_trimmed_tmp.fq out=${params.prefix}_trimmed.fq k=31 ref=$phix174ill,$artifacts qin=$params.qin threads=${task.cpus} ow\\\"\n\tfi\n\n\t#Logs executed command\n\techo \\\"Executing command: \\$CMD \\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\t\n\t#Removes synthetic contaminants\n\texec \\$CMD 2>&1 | tee tmp.log\n\n\t#Logs some figures about sequences passing deletion of contaminants\n\techo  \\\"BBduk's trimming stats (synthetic contaminants): \\\" >> .log.3\n\tsed -n '/Input:/,/Result:/p' tmp.log >> .log.3\n\techo \\\" \\\" >> .log.3\n\n\t#Removes synthetic contaminants and logs some figures (singleton read file, \n\t#that exists iif the library layout was 'paired')\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=${params.prefix}_trimmed_singletons_tmp.fq out=${params.prefix}_trimmed_singletons.fq k=31 ref=$phix174ill,$artifacts qin=$params.qin threads=${task.cpus} ow\\\"\n\t\t\n\t\techo \\\"Executing command: \\$CMD \\\" >> .log.3\n\t\techo \\\" \\\" >> .log.3\n\t\n\t\t#Removes synthetic contaminants\n\t\texec \\$CMD 2>&1 | tee tmp.log\t\t\n\t\t\t\t\t\t\t\n\t\t#Logs some figures about sequences passing deletion of contaminants\n\t\techo  \\\"BBduk's trimming stats (synthetic contaminants, singleton reads): \\\" >> .log.3\n\t\tsed -n '/Input:/,/Result:/p' tmp.log >> .log.3\n\t\techo \\\" \\\" >> .log.3\n\tfi\n\t\n\t#Removes tmp files. This avoids adding them to the output channels\n\trm -rf ${params.prefix}_trimmed*_tmp.fq \n\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"STEP 2 (Quality Control) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.3\n\techo \\\"\\\" >> .log.3\n\t\"\"\"\n}",
        "nb_lignes_process": 106,
        "string_script": "\t\"\"\"\t\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. STEP 2 [Trimming] at \\$sysdate\\\" > .log.3\n\techo \\\" \\\" >> .log.3\n\n\t#Sets the maximum memory to the value requested in the config file\n\tmaxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\n\t#Defines command for trimming of adapters and low quality bases\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=$reads1 in2=$reads2 out=${params.prefix}_trimmed_R1_tmp.fq out2=${params.prefix}_trimmed_R2_tmp.fq outs=${params.prefix}_trimmed_singletons_tmp.fq ktrim=r k=$params.kcontaminants mink=$params.mink hdist=$params.hdist qtrim=rl trimq=$params.phred  minlength=$params.minlength ref=$adapters qin=$params.qin threads=${task.cpus} tbo tpe ow\\\"\n\telse\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=$reads1 out=${params.prefix}_trimmed_tmp.fq ktrim=r k=$params.kcontaminants mink=$params.mink hdist=$params.hdist qtrim=rl trimq=$params.phred  minlength=$params.minlength ref=$adapters qin=$params.qin threads=${task.cpus} tbo tpe ow\\\"\n\tfi\n\t\n\t#Logs version of the software and executed command (BBMap prints on stderr)\n\tversion=\\$(bbduk.sh --version 2>&1 >/dev/null | grep \\\"BBMap version\\\") \n\techo \\\"Using bbduk.sh in \\$version \\\" >> .log.3\n\techo \\\"Using adapters in $params.adapters \\\" >> .log.3\n\techo \\\"Using synthetic contaminants in $params.phix174ill and in $params.artifacts \\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\techo \\\"Executing command: \\$CMD \\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\t\n\t#Trims adapters and low quality bases\t\n\texec \\$CMD 2>&1 | tee tmp.log\n\t\n\t#Logs some figures about sequences passing trimming\n\techo  \\\"BBduk's trimming stats (trimming adapters and low quality reads): \\\" >> .log.3\n\tsed -n '/Input:/,/Result:/p' tmp.log >> .log.3\n\techo \\\" \\\" >> .log.3\t\t\t\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tunpairedR=\\$(wc -l ${params.prefix}_trimmed_singletons_tmp.fq | cut -d\\\" \\\" -f 1)\n\t\tunpairedR=\\$((\\$unpairedR/4))\n\t\techo  \\\"\\$unpairedR singleton reads whose mate was trimmed shorter preserved\\\" >> .log.3\n\t\techo \\\" \\\" >> .log.3\n\tfi\n\n\t#Defines command for removing synthetic contaminants\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=${params.prefix}_trimmed_R1_tmp.fq in2=${params.prefix}_trimmed_R2_tmp.fq out=${params.prefix}_trimmed_R1.fq out2=${params.prefix}_trimmed_R2.fq k=31 ref=$phix174ill,$artifacts qin=$params.qin threads=${task.cpus} ow\\\"\n\telse\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=${params.prefix}_trimmed_tmp.fq out=${params.prefix}_trimmed.fq k=31 ref=$phix174ill,$artifacts qin=$params.qin threads=${task.cpus} ow\\\"\n\tfi\n\n\t#Logs executed command\n\techo \\\"Executing command: \\$CMD \\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\t\n\t#Removes synthetic contaminants\n\texec \\$CMD 2>&1 | tee tmp.log\n\n\t#Logs some figures about sequences passing deletion of contaminants\n\techo  \\\"BBduk's trimming stats (synthetic contaminants): \\\" >> .log.3\n\tsed -n '/Input:/,/Result:/p' tmp.log >> .log.3\n\techo \\\" \\\" >> .log.3\n\n\t#Removes synthetic contaminants and logs some figures (singleton read file, \n\t#that exists iif the library layout was 'paired')\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbduk.sh -Xmx\\\"\\$maxmem\\\" in=${params.prefix}_trimmed_singletons_tmp.fq out=${params.prefix}_trimmed_singletons.fq k=31 ref=$phix174ill,$artifacts qin=$params.qin threads=${task.cpus} ow\\\"\n\t\t\n\t\techo \\\"Executing command: \\$CMD \\\" >> .log.3\n\t\techo \\\" \\\" >> .log.3\n\t\n\t\t#Removes synthetic contaminants\n\t\texec \\$CMD 2>&1 | tee tmp.log\t\t\n\t\t\t\t\t\t\t\n\t\t#Logs some figures about sequences passing deletion of contaminants\n\t\techo  \\\"BBduk's trimming stats (synthetic contaminants, singleton reads): \\\" >> .log.3\n\t\tsed -n '/Input:/,/Result:/p' tmp.log >> .log.3\n\t\techo \\\" \\\" >> .log.3\n\tfi\n\t\n\t#Removes tmp files. This avoids adding them to the output channels\n\trm -rf ${params.prefix}_trimmed*_tmp.fq \n\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"STEP 2 (Quality Control) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.3\n\techo \\\" \\\" >> .log.3\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.3\n\techo \\\"\\\" >> .log.3\n\t\"\"\"",
        "nb_lignes_script": 87,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "totrim",
            "mocktrim"
        ],
        "nb_inputs": 2,
        "outputs": [
            "log3",
            "trimmedreads",
            "todecontaminate",
            "topublishtrim"
        ],
        "nb_outputs": 4,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [],
        "when": "params.mode == \"QC\" || params.mode == \"complete\"",
        "stub": ""
    },
    "decontaminate": {
        "name_process": "decontaminate",
        "string_process": "\nprocess decontaminate {\n\t\n\tpublishDir  workingdir, mode: 'move', pattern: \"*_clean.fq.gz\"\n\t\t\n\tinput:\n\tset file(infile1), file(infile2), file(infile12) from todecontaminate.concat(mockdecontaminate).flatMap().take(3).buffer(size : 3)\n\tfile(refForeingGenome) from Channel.from( file(params.refForeingGenome, type: 'dir') )\n\t\n\toutput:\n\tfile \"*_clean.fq.gz\"\n\tfile  \".log.5\" into log5\n\tfile \"${params.prefix}_clean.fq\" into decontaminatedreads\n\tfile \"${params.prefix}_clean.fq\" into toprofiletaxa\n\tfile \"${params.prefix}_clean.fq\" into toprofilefunctionreads\n\tfile \"${params.prefix}_cont.fq\" into topublishdecontaminate\n\n\twhen:\n\tparams.mode == \"QC\" || params.mode == \"complete\"\n\t\n\tscript:\n\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. STEP 3 [Decontamination] at \\$sysdate\\\" > .log.5\n\techo \\\" \\\" >> .log.5\n\n\t#Sets the maximum memory to the value requested in the config file\n\tmaxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\t\n\t#Defines command for decontamination\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbwrap.sh  -Xmx\\\"\\$maxmem\\\" mapper=bbmap append=t in1=$infile1,$infile12 in2=$infile2,null outu=${params.prefix}_clean.fq outm=${params.prefix}_cont.fq minid=$params.mind maxindel=$params.maxindel bwr=$params.bwr bw=12 minhits=2 qtrim=rl trimq=$params.phred path=$refForeingGenome qin=$params.qin threads=${task.cpus} untrim quickmatch fast ow\\\"\n\telse\n\t\tCMD=\\\"bbwrap.sh  -Xmx\\\"\\$maxmem\\\" mapper=bbmap append=t in1=$infile1 outu=${params.prefix}_clean.fq outm=${params.prefix}_cont.fq minid=$params.mind maxindel=$params.maxindel bwr=$params.bwr bw=12 minhits=2 qtrim=rl trimq=$params.phred path=$refForeingGenome qin=$params.qin threads=${task.cpus} untrim quickmatch fast ow\\\"\n\tfi\n\t\n\t#Logs version of the software and executed command (BBmap prints on stderr)\n\tversion=\\$(bbwrap.sh --version 2>&1 >/dev/null | grep \\\"BBMap version\\\") \n\techo \\\"Using bbwrap.sh in \\$version \\\" >> .log.5\n\techo \\\"Using contaminant (pan)genome indexed in $params.refForeingGenome \\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\techo \\\"Executing command: \\$CMD \\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\t\n\t#Decontaminates\n\texec \\$CMD 2>&1 | tee tmp.log\n\t\n\t#Logs some figures about decontaminated/contaminated reads\n\techo  \\\"BBwrap's human decontamination stats (paired reads): \\\" >> .log.5\n\tsed -n '/Read 1 data:/,/N Rate:/p' tmp.log | head -17 >> .log.5\n\techo \\\" \\\" >> .log.5\n\tsed -n '/Read 2 data:/,/N Rate:/p' tmp.log >> .log.5\n\techo \\\" \\\" >> .log.5\n\t\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\techo  \\\"BBmap's human decontamination stats (singletons reads): \\\" >> .log.5\n\t\tsed -n '/Read 1 data:/,/N Rate:/p' tmp.log | tail -17 >> .log.5\n\t\techo \\\" \\\" >> .log.5\n\tfi\n\n\tgzip -c ${params.prefix}_clean.fq > ${params.prefix}_clean.fq.gz\n\n\tnClean=\\$(wc -l ${params.prefix}_clean.fq | cut -d\\\" \\\" -f 1)\n\tnClean=\\$((\\$nClean/4))\n\tnCont=\\$(wc -l ${params.prefix}_cont.fq | cut -d\\\" \\\" -f 1)\n\tnCont=\\$((\\$nCont/4))\n\techo \\\"\\$nClean reads survived decontamination (\\$nCont reads removed)\\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"STEP 3 (Quality Control) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.5\n\techo \\\"\\\" >> .log.5\n\t\"\"\"\n}",
        "nb_lignes_process": 79,
        "string_script": "\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. STEP 3 [Decontamination] at \\$sysdate\\\" > .log.5\n\techo \\\" \\\" >> .log.5\n\n\t#Sets the maximum memory to the value requested in the config file\n\tmaxmem=\\$(echo ${task.memory} | sed 's/ //g' | sed 's/B//g')\n\t\n\t#Defines command for decontamination\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\tCMD=\\\"bbwrap.sh  -Xmx\\\"\\$maxmem\\\" mapper=bbmap append=t in1=$infile1,$infile12 in2=$infile2,null outu=${params.prefix}_clean.fq outm=${params.prefix}_cont.fq minid=$params.mind maxindel=$params.maxindel bwr=$params.bwr bw=12 minhits=2 qtrim=rl trimq=$params.phred path=$refForeingGenome qin=$params.qin threads=${task.cpus} untrim quickmatch fast ow\\\"\n\telse\n\t\tCMD=\\\"bbwrap.sh  -Xmx\\\"\\$maxmem\\\" mapper=bbmap append=t in1=$infile1 outu=${params.prefix}_clean.fq outm=${params.prefix}_cont.fq minid=$params.mind maxindel=$params.maxindel bwr=$params.bwr bw=12 minhits=2 qtrim=rl trimq=$params.phred path=$refForeingGenome qin=$params.qin threads=${task.cpus} untrim quickmatch fast ow\\\"\n\tfi\n\t\n\t#Logs version of the software and executed command (BBmap prints on stderr)\n\tversion=\\$(bbwrap.sh --version 2>&1 >/dev/null | grep \\\"BBMap version\\\") \n\techo \\\"Using bbwrap.sh in \\$version \\\" >> .log.5\n\techo \\\"Using contaminant (pan)genome indexed in $params.refForeingGenome \\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\techo \\\"Executing command: \\$CMD \\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\t\n\t#Decontaminates\n\texec \\$CMD 2>&1 | tee tmp.log\n\t\n\t#Logs some figures about decontaminated/contaminated reads\n\techo  \\\"BBwrap's human decontamination stats (paired reads): \\\" >> .log.5\n\tsed -n '/Read 1 data:/,/N Rate:/p' tmp.log | head -17 >> .log.5\n\techo \\\" \\\" >> .log.5\n\tsed -n '/Read 2 data:/,/N Rate:/p' tmp.log >> .log.5\n\techo \\\" \\\" >> .log.5\n\t\n\tif [ \\\"$params.librarylayout\\\" = \\\"paired\\\" ]; then\n\t\techo  \\\"BBmap's human decontamination stats (singletons reads): \\\" >> .log.5\n\t\tsed -n '/Read 1 data:/,/N Rate:/p' tmp.log | tail -17 >> .log.5\n\t\techo \\\" \\\" >> .log.5\n\tfi\n\n\tgzip -c ${params.prefix}_clean.fq > ${params.prefix}_clean.fq.gz\n\n\tnClean=\\$(wc -l ${params.prefix}_clean.fq | cut -d\\\" \\\" -f 1)\n\tnClean=\\$((\\$nClean/4))\n\tnCont=\\$(wc -l ${params.prefix}_cont.fq | cut -d\\\" \\\" -f 1)\n\tnCont=\\$((\\$nCont/4))\n\techo \\\"\\$nClean reads survived decontamination (\\$nCont reads removed)\\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"STEP 3 (Quality Control) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.5\n\techo \\\" \\\" >> .log.5\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.5\n\techo \\\"\\\" >> .log.5\n\t\"\"\"",
        "nb_lignes_script": 58,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "todecontaminate",
            "mockdecontaminate"
        ],
        "nb_inputs": 2,
        "outputs": [
            "log5",
            "decontaminatedreads",
            "toprofiletaxa",
            "toprofilefunctionreads",
            "topublishdecontaminate"
        ],
        "nb_outputs": 5,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [
            "publishDir workingdir, mode: 'move', pattern: \"*_clean.fq.gz\""
        ],
        "when": "params.mode == \"QC\" || params.mode == \"complete\"",
        "stub": ""
    },
    "qualityAssessment": {
        "name_process": "qualityAssessment",
        "string_process": "\nprocess qualityAssessment {\n\t\n\tpublishDir  workingdir, mode: 'move', pattern: \"*.{html,txt}\"\n\t  \t\n\tinput:\n   \tset val(step), file(reads), val(label), val(stem) from toQC\n\n\toutput:\n\tfile \".log.$step$label\" into logQC\n\tfile \"${params.prefix}*_fastqc.html\" \n\tfile \"${params.prefix}*_fastqc_data.txt\" \n\n\twhen:\n\tparams.mode == \"QC\" || params.mode == \"complete\"\n\n   \tscript:\n\t\"\"\"\t\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. [Assessment of read quality] at \\$sysdate\\\" > .log.$step$label\n\techo \\\"File being analysed: $reads\\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\n\t\n\t#Logs version of the software and executed command\n\tversion=\\$(fastqc --version) \n\tCMD=\\\"fastqc --quiet --noextract --format fastq --outdir=. --threads ${task.cpus} $reads\\\"\n\t\n\techo \\\"Using \\$version \\\" >> .log.$step$label\n\techo \\\"Executing command \\$CMD \\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\n\t\n\t#Does QC, extracts relevant information, and removes temporary files\n\tbash fastQC.sh $reads ${params.prefix}${stem}${label} ${task.cpus} $reads\n\t\n\t#Logging QC statistics (number of sequences, Pass/warning/fail, basic statistics, duplication level, kmers)\n\tbase=\\$(basename $reads)\n\tbash logQC.sh \\$base ${params.prefix}${stem}${label}_fastqc_data.txt .log.$step$label\n\t\t\t\t\n\t#Measures and log execution time\t\t\t\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"Quality assessment on $reads terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\t\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\t\n\t\"\"\"\t\n}",
        "nb_lignes_process": 48,
        "string_script": "\t\"\"\"\t\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Quality Control. [Assessment of read quality] at \\$sysdate\\\" > .log.$step$label\n\techo \\\"File being analysed: $reads\\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\n\t\n\t#Logs version of the software and executed command\n\tversion=\\$(fastqc --version) \n\tCMD=\\\"fastqc --quiet --noextract --format fastq --outdir=. --threads ${task.cpus} $reads\\\"\n\t\n\techo \\\"Using \\$version \\\" >> .log.$step$label\n\techo \\\"Executing command \\$CMD \\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\n\t\n\t#Does QC, extracts relevant information, and removes temporary files\n\tbash fastQC.sh $reads ${params.prefix}${stem}${label} ${task.cpus} $reads\n\t\n\t#Logging QC statistics (number of sequences, Pass/warning/fail, basic statistics, duplication level, kmers)\n\tbase=\\$(basename $reads)\n\tbash logQC.sh \\$base ${params.prefix}${stem}${label}_fastqc_data.txt .log.$step$label\n\t\t\t\t\n\t#Measures and log execution time\t\t\t\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"Quality assessment on $reads terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\t\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.$step$label\n\techo \\\" \\\" >> .log.$step$label\t\n\t\"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "toQC"
        ],
        "nb_inputs": 1,
        "outputs": [
            "logQC"
        ],
        "nb_outputs": 1,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [
            "publishDir workingdir, mode: 'move', pattern: \"*.{html,txt}\""
        ],
        "when": "params.mode == \"QC\" || params.mode == \"complete\"",
        "stub": ""
    },
    "profileTaxa": {
        "name_process": "profileTaxa",
        "string_process": "\nprocess profileTaxa {\n\n\tpublishDir  workingdir, mode: 'copy', pattern: \"*.{biom,tsv}\"\n\t\n\tinput:\n\tfile(infile) from toprofiletaxa\n\tfile(mpa_pkl) from Channel.from( file(params.mpa_pkl) )\n\tfile(bowtie2db) from Channel.fromPath( params.bowtie2db, type: 'dir' )\n\n    output:\n\tfile \".log.7\" into log7\n\tfile \"${params.prefix}.biom\" into toalphadiversity\n\tfile \"${params.prefix}_metaphlan_bugs_list.tsv\" into toprofilefunctionbugs\n\tfile \"${params.prefix}_bt2out.txt\" into topublishprofiletaxa\n\n\twhen:\n\tparams.mode == \"characterisation\" || params.mode == \"complete\"\n\n\tscript:\n\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Community Characterisation. STEP 1 [Taxonomic binning and profiling] at \\$sysdate\\\" > .log.7\n\techo \\\" \\\" >> .log.7\n\t\n\t#If a file with the same name is already present, Metaphlan2 will crash\n\trm -rf ${params.prefix}_bt2out.txt\n\t\n\t#Defines command for estimating abundances\n\tCMD=\\\"metaphlan2.py --input_type fastq --tmp_dir=. --biom ${params.prefix}.biom --bowtie2out=${params.prefix}_bt2out.txt --mpa_pkl $mpa_pkl  --bowtie2db $bowtie2db/$params.bowtie2dbfiles --bt2_ps $params.bt2options --nproc ${task.cpus} $infile ${params.prefix}_metaphlan_bugs_list.tsv\\\"\n\n\t#Logs version of the software and executed command \n\t#MetaPhlAn prints on stderr\n\tversion=\\$(metaphlan2.py --version 2>&1 >/dev/null | grep \\\"MetaPhlAn\\\")\n\techo \\\"Using \\$version \\\" >> .log.7\n\techo \\\"Using BowTie2 database in $params.bowtie2db \\\" >> .log.7\n\techo \\\" \\\" >> .log.7\n\techo \\\"Executing command: \\$CMD \\\" >> .log.7\n\t\n\techo \\\" \\\" >> .log.7\n\n\t#Estimates microbial abundances\n\texec \\$CMD 2>&1 | tee tmp.log\n\n\t#Sets the prefix in the biom file\n\tsed -i 's/Metaphlan2_Analysis/${params.prefix}/g' ${params.prefix}.biom\n\tsed -i 's/Metaphlan2_Analysis/${params.prefix}/g' ${params.prefix}_metaphlan_bugs_list.tsv\n\n\t#Logs some info\n\ttree=(kingdom phylum class order family genus species)\n\tfor i in {2..7}\n\tdo\n\t\tc=\\$(sed '1d' ${params.prefix}_metaphlan_bugs_list.tsv | cut -d\\\"|\\\" -f \\$i | grep -v \\\"k__\\\" | cut -f 1  | sort | uniq | sed '/^\\\\s*\\$/d' | wc -l | cut -d\\\" \\\" -f 1)\n\t\techo \\\"\\$c \\${tree[((\\$i-1))]} found\\\" >> .log.7\n\tdone\n\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"\\\" >> .log.7\n\techo \\\"STEP 1 (Community Characterisation) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.7\n\techo \\\" \\\" >> .log.7\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.7\n\techo \\\"\\\" >> .log.7\n\t\"\"\"\n}",
        "nb_lignes_process": 67,
        "string_script": "\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Community Characterisation. STEP 1 [Taxonomic binning and profiling] at \\$sysdate\\\" > .log.7\n\techo \\\" \\\" >> .log.7\n\t\n\t#If a file with the same name is already present, Metaphlan2 will crash\n\trm -rf ${params.prefix}_bt2out.txt\n\t\n\t#Defines command for estimating abundances\n\tCMD=\\\"metaphlan2.py --input_type fastq --tmp_dir=. --biom ${params.prefix}.biom --bowtie2out=${params.prefix}_bt2out.txt --mpa_pkl $mpa_pkl  --bowtie2db $bowtie2db/$params.bowtie2dbfiles --bt2_ps $params.bt2options --nproc ${task.cpus} $infile ${params.prefix}_metaphlan_bugs_list.tsv\\\"\n\n\t#Logs version of the software and executed command \n\t#MetaPhlAn prints on stderr\n\tversion=\\$(metaphlan2.py --version 2>&1 >/dev/null | grep \\\"MetaPhlAn\\\")\n\techo \\\"Using \\$version \\\" >> .log.7\n\techo \\\"Using BowTie2 database in $params.bowtie2db \\\" >> .log.7\n\techo \\\" \\\" >> .log.7\n\techo \\\"Executing command: \\$CMD \\\" >> .log.7\n\t\n\techo \\\" \\\" >> .log.7\n\n\t#Estimates microbial abundances\n\texec \\$CMD 2>&1 | tee tmp.log\n\n\t#Sets the prefix in the biom file\n\tsed -i 's/Metaphlan2_Analysis/${params.prefix}/g' ${params.prefix}.biom\n\tsed -i 's/Metaphlan2_Analysis/${params.prefix}/g' ${params.prefix}_metaphlan_bugs_list.tsv\n\n\t#Logs some info\n\ttree=(kingdom phylum class order family genus species)\n\tfor i in {2..7}\n\tdo\n\t\tc=\\$(sed '1d' ${params.prefix}_metaphlan_bugs_list.tsv | cut -d\\\"|\\\" -f \\$i | grep -v \\\"k__\\\" | cut -f 1  | sort | uniq | sed '/^\\\\s*\\$/d' | wc -l | cut -d\\\" \\\" -f 1)\n\t\techo \\\"\\$c \\${tree[((\\$i-1))]} found\\\" >> .log.7\n\tdone\n\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"\\\" >> .log.7\n\techo \\\"STEP 1 (Community Characterisation) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.7\n\techo \\\" \\\" >> .log.7\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.7\n\techo \\\"\\\" >> .log.7\n\t\"\"\"",
        "nb_lignes_script": 47,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "toprofiletaxa"
        ],
        "nb_inputs": 1,
        "outputs": [
            "log7",
            "toalphadiversity",
            "toprofilefunctionbugs",
            "topublishprofiletaxa"
        ],
        "nb_outputs": 4,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [
            "publishDir workingdir, mode: 'copy', pattern: \"*.{biom,tsv}\""
        ],
        "when": "params.mode == \"characterisation\" || params.mode == \"complete\"",
        "stub": ""
    },
    "alphaDiversity": {
        "name_process": "alphaDiversity",
        "string_process": "\nprocess alphaDiversity {\n\n\tpublishDir  workingdir, mode: 'move', pattern: \"*.{tsv}\"\n\t\n\tinput:\n\tfile(infile) from toalphadiversity\n\tfile(treepath) from Channel.from( file(params.treepath) )\n\t\n    output:\n\tfile \".log.8\" into log8\n\tfile \"${params.prefix}_alpha_diversity.tsv\"\n\t\n\twhen:\n\tparams.mode == \"characterisation\" || params.mode == \"complete\"\n\n\tscript:\n\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Community Characterisation. STEP 2 [Evaluating alpha-diversity] at \\$sysdate\\\" > .log.8\n\techo \\\" \\\" >> .log.8\n\n\t#It checks if the profiling was successful, that is if identifies at least three species\n\tn=\\$(grep -o s__ $infile | wc -l  | cut -d\\\" \\\" -f 1)\n\tif (( n > 3 ))\n\tthen\n\t\t#Defines command -- if the tree path is not specified, not all the alpha \n\t\t#measures can be evaluated (that is, PD_whole_tree is skipped)\n\t\tif [ $params.treepath == null ]\n\t\tthen\n\t\t\tCMD=\\\"alpha_diversity.py -i $infile -o ${params.prefix}_alpha_diversity.tsv -m ace,berger_parker_d,brillouin_d,chao1,chao1_ci,dominance,doubles,enspie,equitability,esty_ci,fisher_alpha,gini_index,goods_coverage,heip_e,kempton_taylor_q,margalef,mcintosh_d,mcintosh_e,menhinick,michaelis_menten_fit,observed_otus,observed_species,osd,simpson_reciprocal,robbins,shannon,simpson,simpson_e,singles,strong\\\"\n\t\telse\n\t\t\tCMD=\\\"alpha_diversity.py -i $infile -o ${params.prefix}_alpha_diversity.tsv -m ace,berger_parker_d,brillouin_d,chao1,chao1_ci,dominance,doubles,enspie,equitability,esty_ci,fisher_alpha,gini_index,goods_coverage,heip_e,kempton_taylor_q,margalef,mcintosh_d,mcintosh_e,menhinick,michaelis_menten_fit,observed_otus,observed_species,osd,simpson_reciprocal,robbins,shannon,simpson,simpson_e,singles,strong,PD_whole_tree -t $treepath\\\"\n\t\tfi\n\t\t\n\t\t#Logs version of the software and executed command\n\t\tversion=\\$(alpha_diversity.py --version) \n\t\techo \\\"Using \\$version \\\" >> .log.8\n\t\tif [ $params.treepath == null ]\n\t\tthen\n\t\t\techo \\\"Newick tree not used, PD_whole_tree skipped\\\" >> .log.8\n\t\telse\n\t\t\techo \\\"Using Newick tree in $params.treepath\\\" >> .log.8\n\t\tfi\n\t\techo \\\" \\\" >> .log.8\n\t\techo \\\"Executing command: \\$CMD \\\" >> .log.8\n\t\techo \\\" \\\" >> .log.8\n\t\t\n\t\t#Evaluates alpha diversities, redirect is done here because QIIME gets it as an extra parameter\n\t\texec \\$CMD 2>&1 | tee tmp.log\n\telse\n\t\t#Also if the alpha are not evaluated the file should be created in order to be returned\n\t\techo \\\"Not enough classified species detected (N=\\$n). Analysis skipped.\\\" >> .log.8\n\t\ttouch ${params.prefix}_alpha_diversity.tsv \n\tfi\n\t\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"\\\" >> .log.8\n\techo \\\"STEP 2 (Community Characterisation) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.8\n\techo \\\" \\\" >> .log.8\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.8\n\techo \\\"\\\" >> .log.8\n\t\"\"\"\n}",
        "nb_lignes_process": 67,
        "string_script": "\t\"\"\"\n\t#Measures execution time\n\tsysdate=\\$(date)\n\tstarttime=\\$(date +%s.%N)\n\techo \\\"Performing Community Characterisation. STEP 2 [Evaluating alpha-diversity] at \\$sysdate\\\" > .log.8\n\techo \\\" \\\" >> .log.8\n\n\t#It checks if the profiling was successful, that is if identifies at least three species\n\tn=\\$(grep -o s__ $infile | wc -l  | cut -d\\\" \\\" -f 1)\n\tif (( n > 3 ))\n\tthen\n\t\t#Defines command -- if the tree path is not specified, not all the alpha \n\t\t#measures can be evaluated (that is, PD_whole_tree is skipped)\n\t\tif [ $params.treepath == null ]\n\t\tthen\n\t\t\tCMD=\\\"alpha_diversity.py -i $infile -o ${params.prefix}_alpha_diversity.tsv -m ace,berger_parker_d,brillouin_d,chao1,chao1_ci,dominance,doubles,enspie,equitability,esty_ci,fisher_alpha,gini_index,goods_coverage,heip_e,kempton_taylor_q,margalef,mcintosh_d,mcintosh_e,menhinick,michaelis_menten_fit,observed_otus,observed_species,osd,simpson_reciprocal,robbins,shannon,simpson,simpson_e,singles,strong\\\"\n\t\telse\n\t\t\tCMD=\\\"alpha_diversity.py -i $infile -o ${params.prefix}_alpha_diversity.tsv -m ace,berger_parker_d,brillouin_d,chao1,chao1_ci,dominance,doubles,enspie,equitability,esty_ci,fisher_alpha,gini_index,goods_coverage,heip_e,kempton_taylor_q,margalef,mcintosh_d,mcintosh_e,menhinick,michaelis_menten_fit,observed_otus,observed_species,osd,simpson_reciprocal,robbins,shannon,simpson,simpson_e,singles,strong,PD_whole_tree -t $treepath\\\"\n\t\tfi\n\t\t\n\t\t#Logs version of the software and executed command\n\t\tversion=\\$(alpha_diversity.py --version) \n\t\techo \\\"Using \\$version \\\" >> .log.8\n\t\tif [ $params.treepath == null ]\n\t\tthen\n\t\t\techo \\\"Newick tree not used, PD_whole_tree skipped\\\" >> .log.8\n\t\telse\n\t\t\techo \\\"Using Newick tree in $params.treepath\\\" >> .log.8\n\t\tfi\n\t\techo \\\" \\\" >> .log.8\n\t\techo \\\"Executing command: \\$CMD \\\" >> .log.8\n\t\techo \\\" \\\" >> .log.8\n\t\t\n\t\t#Evaluates alpha diversities, redirect is done here because QIIME gets it as an extra parameter\n\t\texec \\$CMD 2>&1 | tee tmp.log\n\telse\n\t\t#Also if the alpha are not evaluated the file should be created in order to be returned\n\t\techo \\\"Not enough classified species detected (N=\\$n). Analysis skipped.\\\" >> .log.8\n\t\ttouch ${params.prefix}_alpha_diversity.tsv \n\tfi\n\t\n\t#Measures and log execution time\n\tendtime=\\$(date +%s.%N)\n\texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n\tsysdate=\\$(date)\n\techo \\\"\\\" >> .log.8\n\techo \\\"STEP 2 (Community Characterisation) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.8\n\techo \\\" \\\" >> .log.8\n\techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.8\n\techo \\\"\\\" >> .log.8\n\t\"\"\"",
        "nb_lignes_script": 50,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "toalphadiversity"
        ],
        "nb_inputs": 1,
        "outputs": [
            "log8"
        ],
        "nb_outputs": 1,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [
            "publishDir workingdir, mode: 'move', pattern: \"*.{tsv}\""
        ],
        "when": "params.mode == \"characterisation\" || params.mode == \"complete\"",
        "stub": ""
    },
    "profileFunction": {
        "name_process": "profileFunction",
        "string_process": "\nprocess profileFunction {\n\n\tpublishDir  workingdir, mode: 'copy', pattern: \"*.{tsv,log}\"\n\t\n\tinput:\n\tfile(cleanreads) from toprofilefunctionreads\n\tfile(metaphlanbuglist) from toprofilefunctionbugs\n\tfile(chocophlan) from Channel.fromPath( params.chocophlan, type: 'dir' )\n\tfile(uniref) from Channel.fromPath( params.uniref, type: 'dir' )\n\t\n    output:\n\tfile \".log.9\" into log9\n\tfile \"${params.prefix}_HUMAnN2.log\"\n\tfile \"${params.prefix}_genefamilies.tsv\"\n\tfile \"${params.prefix}_pathcoverage.tsv\"\n\tfile \"${params.prefix}_pathabundance.tsv\"\n\t\n\t                                                                                     \n\tset (\"${params.prefix}_bowtie2_aligned.sam\", \"${params.prefix}_bowtie2_aligned.tsv\", \"${params.prefix}_diamond_aligned.tsv\", \"${params.prefix}_bowtie2_unaligned.fa\", \"${params.prefix}_diamond_unaligned.fa\") into topublishhumann2\t\n\n\twhen:\n\tparams.mode == \"characterisation\" || params.mode == \"complete\"\n\n\tscript:\n\t\"\"\"\n\t#Measures execution time\n \tsysdate=\\$(date)\n \tstarttime=\\$(date +%s.%N)\n \techo \\\"Performing Community Characterisation. STEP 3 [Performing functional annotation] with HUMAnN2 at \\$sysdate\\\" > .log.9\n \techo \\\" \\\" >> .log.9\n\n\t#Defines HUMAnN2 command taking advantages of the MetaPhlAn2's results\n\tCMD=\\\"humann2 --input $cleanreads --output . --output-basename ${params.prefix} --taxonomic-profile $metaphlanbuglist --nucleotide-database $chocophlan --protein-database $uniref --pathways metacyc --threads ${task.cpus} --memory-use minimum\\\"\n\t\n\t#Logs version of the software and executed command\n\t#HUMAnN2 prints on stderr\n\tversion=\\$(humann2 --version 2>&1 >/dev/null | grep \\\"humann2\\\") \n\techo \\\"Using \\$version \\\" >> .log.9\n\techo \\\"Using ChocoPhlAn database in $params.chocophlan \\\" >> .log.9\n\techo \\\"Using UniRef database in $params.uniref \\\" >> .log.9\n\techo \\\" \\\" >> .log.9\n\techo \\\"Executing command: \\$CMD > ${params.prefix}_HUMAnN2.log\\\" >> .log.9\n\techo \\\" \\\" >> .log.9\n\t\n\t#Performs functional annotation, redirect is done here because HUMAnN2 freaks out\n\t#This is  also reported in the log.\n\texec \\$CMD 2>&1 | tee ${params.prefix}_HUMAnN2.log \n\n\t#If `|| true` is not add, nextflow stops... WTF \n\tgrep \\\"Total species selected from prescreen:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Selected species explain\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Unaligned reads after nucleotide alignment:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Total gene families after translated alignment:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Unaligned reads after translated alignment:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\techo \\\"More information on HUMAnN2 run are available in the ${params.prefix}_HUMAnN2.log file\\\" >> .log.9 \n\n\t#Some of temporary files (if they exist) may be moved in the working directory, \n\t#according to the keepCCtmpfile parameter. Others (such as the bowties2 indexes), \n\t#are always removed. Those that should be moved, but have not been created by \n\t#HUMAnN2, are now created by the script (they are needed as output for the channel)\n\tfiles=(${params.prefix}_bowtie2_aligned.sam ${params.prefix}_bowtie2_aligned.tsv ${params.prefix}_diamond_aligned.tsv ${params.prefix}_bowtie2_unaligned.fa ${params.prefix}_diamond_unaligned.fa)\n\tfor i in {1..5}\n\tdo\n\t\tif [ -f ${params.prefix}_humann2_temp/\\${files[((\\$i-1))]} ]\n\t\tthen\n\t\t\tmv ${params.prefix}_humann2_temp/\\${files[((\\$i-1))]} .\n\t\telse\n\t\t\ttouch \\${files[((\\$i-1))]}\n\t\tfi\n\tdone\n\trm -rf ${params.prefix}_humann2_temp/\n\n \t#Measures and log execution time\n \tendtime=\\$(date +%s.%N)\n \texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n \tsysdate=\\$(date)\n \techo \\\"\\\" >> .log.9\n \techo \\\"STEP 3 (Community Characterisation) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.9\n \techo \\\" \\\" >> .log.9\n \techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.9\n \techo \\\"\\\" >> .log.9\n \t\"\"\"\n}",
        "nb_lignes_process": 82,
        "string_script": "\t\"\"\"\n\t#Measures execution time\n \tsysdate=\\$(date)\n \tstarttime=\\$(date +%s.%N)\n \techo \\\"Performing Community Characterisation. STEP 3 [Performing functional annotation] with HUMAnN2 at \\$sysdate\\\" > .log.9\n \techo \\\" \\\" >> .log.9\n\n\t#Defines HUMAnN2 command taking advantages of the MetaPhlAn2's results\n\tCMD=\\\"humann2 --input $cleanreads --output . --output-basename ${params.prefix} --taxonomic-profile $metaphlanbuglist --nucleotide-database $chocophlan --protein-database $uniref --pathways metacyc --threads ${task.cpus} --memory-use minimum\\\"\n\t\n\t#Logs version of the software and executed command\n\t#HUMAnN2 prints on stderr\n\tversion=\\$(humann2 --version 2>&1 >/dev/null | grep \\\"humann2\\\") \n\techo \\\"Using \\$version \\\" >> .log.9\n\techo \\\"Using ChocoPhlAn database in $params.chocophlan \\\" >> .log.9\n\techo \\\"Using UniRef database in $params.uniref \\\" >> .log.9\n\techo \\\" \\\" >> .log.9\n\techo \\\"Executing command: \\$CMD > ${params.prefix}_HUMAnN2.log\\\" >> .log.9\n\techo \\\" \\\" >> .log.9\n\t\n\t#Performs functional annotation, redirect is done here because HUMAnN2 freaks out\n\t#This is  also reported in the log.\n\texec \\$CMD 2>&1 | tee ${params.prefix}_HUMAnN2.log \n\n\t#If `|| true` is not add, nextflow stops... WTF \n\tgrep \\\"Total species selected from prescreen:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Selected species explain\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Unaligned reads after nucleotide alignment:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Total gene families after translated alignment:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\tgrep \\\"Unaligned reads after translated alignment:\\\" ${params.prefix}_HUMAnN2.log >> .log.9 || true\n\techo \\\"More information on HUMAnN2 run are available in the ${params.prefix}_HUMAnN2.log file\\\" >> .log.9 \n\n\t#Some of temporary files (if they exist) may be moved in the working directory, \n\t#according to the keepCCtmpfile parameter. Others (such as the bowties2 indexes), \n\t#are always removed. Those that should be moved, but have not been created by \n\t#HUMAnN2, are now created by the script (they are needed as output for the channel)\n\tfiles=(${params.prefix}_bowtie2_aligned.sam ${params.prefix}_bowtie2_aligned.tsv ${params.prefix}_diamond_aligned.tsv ${params.prefix}_bowtie2_unaligned.fa ${params.prefix}_diamond_unaligned.fa)\n\tfor i in {1..5}\n\tdo\n\t\tif [ -f ${params.prefix}_humann2_temp/\\${files[((\\$i-1))]} ]\n\t\tthen\n\t\t\tmv ${params.prefix}_humann2_temp/\\${files[((\\$i-1))]} .\n\t\telse\n\t\t\ttouch \\${files[((\\$i-1))]}\n\t\tfi\n\tdone\n\trm -rf ${params.prefix}_humann2_temp/\n\n \t#Measures and log execution time\n \tendtime=\\$(date +%s.%N)\n \texectime=\\$(echo \\\"\\$endtime \\$starttime\\\" | awk '{print \\$1-\\$2}')\n \tsysdate=\\$(date)\n \techo \\\"\\\" >> .log.9\n \techo \\\"STEP 3 (Community Characterisation) terminated at \\$sysdate (\\$exectime seconds)\\\" >> .log.9\n \techo \\\" \\\" >> .log.9\n \techo \\\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\\\" >> .log.9\n \techo \\\"\\\" >> .log.9\n \t\"\"\"",
        "nb_lignes_script": 57,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "toprofilefunctionreads",
            "toprofilefunctionbugs"
        ],
        "nb_inputs": 2,
        "outputs": [
            "log9",
            "topublishhumann2"
        ],
        "nb_outputs": 2,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [
            "publishDir workingdir, mode: 'copy', pattern: \"*.{tsv,log}\""
        ],
        "when": "params.mode == \"characterisation\" || params.mode == \"complete\"",
        "stub": ""
    },
    "logQC": {
        "name_process": "logQC",
        "string_process": "\nprocess logQC {\n\n\tinput:\n\tfile(tolog)  from logQC.flatMap().mix(log2, log3, log5).toSortedList( { a, b -> a.name <=> b.name } )\n\n\twhen:\n\tparams.mode == \"QC\" || params.mode == \"complete\"\n\n\tscript:\n\t\"\"\"\n\tcat $tolog >> $mylog\n\t\"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\t\"\"\"\n\tcat $tolog >> $mylog\n\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "logQC",
            "log2",
            "log3",
            "log5"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [],
        "when": "params.mode == \"QC\" || params.mode == \"complete\"",
        "stub": ""
    },
    "saveQCtmpfile": {
        "name_process": "saveQCtmpfile",
        "string_process": "\nprocess saveQCtmpfile {\n\n\tpublishDir  workingdir, mode: 'copy'\n\t\t\n\tinput:\n\tfile (tmpfile) from topublishdedupe.mix(topublishtrim, topublishdecontaminate).flatMap()\n\n\toutput:\n\tfile \"*.fq.gz\"\n\n\twhen:\n\t(params.mode == \"QC\" || params.mode == \"complete\") && params.keepQCtmpfile\n\t\t\n\tscript:\n\t\"\"\"\n\tgzip --force -c $tmpfile > ${tmpfile}.gz\n\t\"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\t\"\"\"\n\tgzip --force -c $tmpfile > ${tmpfile}.gz\n\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "topublishdedupe",
            "topublishtrim",
            "topublishdecontaminate"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [
            "publishDir workingdir, mode: 'copy'"
        ],
        "when": "(params.mode == \"QC\" || params.mode == \"complete\") && params.keepQCtmpfile",
        "stub": ""
    },
    "logCC": {
        "name_process": "logCC",
        "string_process": "\nprocess logCC {\n\n\tinput:\n\tfile(tolog) from log7.mix(log8, log9).flatMap().toSortedList( { a, b -> a.name <=> b.name } )\n\t\n\twhen:\n\tparams.mode == \"characterisation\" || params.mode == \"complete\"\n\t\t\n\tscript:\n\t\"\"\"\n\tcat $tolog >> $mylog\n\t\"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\t\"\"\"\n\tcat $tolog >> $mylog\n\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "log7",
            "log8",
            "log9"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [],
        "when": "params.mode == \"characterisation\" || params.mode == \"complete\"",
        "stub": ""
    },
    "saveCCtmpfile": {
        "name_process": "saveCCtmpfile",
        "string_process": "\nprocess saveCCtmpfile {\n\n\tpublishDir  workingdir, mode: 'copy'\n\t\t\n\tinput:\n\tfile (tmpfile) from topublishprofiletaxa.mix(topublishhumann2).flatMap()\n\n\toutput:\n\tfile \"$tmpfile\"\n\n\twhen:\n\t(params.mode == \"characterisation\" || params.mode == \"complete\") && params.keepCCtmpfile\n\t\t\n\tscript:\n\t\"\"\"\n\techo $tmpfile\n\t\"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "\t\"\"\"\n\techo $tmpfile\n\t\"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "topublishprofiletaxa",
            "topublishhumann2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "GMS6804-master__YAMP",
        "directive": [
            "publishDir workingdir, mode: 'copy'"
        ],
        "when": "(params.mode == \"characterisation\" || params.mode == \"complete\") && params.keepCCtmpfile",
        "stub": ""
    }
}