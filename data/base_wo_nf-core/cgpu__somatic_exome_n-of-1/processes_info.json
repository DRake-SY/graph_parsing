{
    "grchvers": {
        "name_process": "grchvers",
        "string_process": "\nprocess grchvers {\n  executor 'local'\n\n  input:\n  file(datDir) from vers\n\n  output:\n  stdout into (cpsr_grchvers, pcgr_grchvers)\n\n  \"\"\"\n  GRCHVERS=\\$(ls $datDir/)\n  echo -n \\$GRCHVERS\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n  GRCHVERS=\\$(ls $datDir/)\n  echo -n \\$GRCHVERS\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vers"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "executor 'local'"
        ],
        "when": "",
        "stub": ""
    },
    "vepp": {
        "name_process": "vepp",
        "string_process": "\nprocess vepp {\n  executor 'local'\n  echo true\n\n  input:\n  file(datDir) from vepp\n\n  output:\n  file('.vep/') into vepanndir\n\n  \"\"\"\n  GRCHVERS=\\$(ls $datDir)\n  ln -s \\$(readlink -e ${params.refDir}/pcgr/$datDir/\\$GRCHVERS/.vep) ./\n  \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\n  GRCHVERS=\\$(ls $datDir)\n  ln -s \\$(readlink -e ${params.refDir}/pcgr/$datDir/\\$GRCHVERS/.vep) ./\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vepp"
        ],
        "nb_inputs": 1,
        "outputs": [
            "vepanndir"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "executor 'local'",
            "echo true"
        ],
        "when": "",
        "stub": ""
    },
    "meta": {
        "name_process": "meta",
        "string_process": "\nprocess meta {\n  executor 'local'\n  input:\n  file(txt) from sampleInputs\n\n  output:\n  file('inputs.txt') into (sampleCsvInput, pcgrMetaInput)\n\n  script:\n  \"\"\"\n  cat $txt > \"inputs.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "  \"\"\"\n  cat $txt > \"inputs.txt\"\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sampleInputs"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "executor 'local'"
        ],
        "when": "",
        "stub": ""
    },
    "bbduk": {
        "name_process": "bbduk",
        "string_process": "\nprocess bbduk {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/bbduk\", mode: \"copy\", pattern: \"*.txt\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) from bbduking\n\n  output:\n  file('*') into completed0_0\n  tuple val(type), val(sampleID), val(meta), file('*.bbduk.R1.fastq.gz'), file('*.bbduk.R2.fastq.gz') into bwa_memming\n  tuple val(type), val(sampleID), val(meta), file('*.bbduk.R1.fastq.gz'), file('*.bbduk.R2.fastq.gz'), file(read1), file(read2) into fastping\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) into fastqcing\n\n  script:\n  \"\"\"\n  {\n    sh bbduk.sh ${params.quarter_javamem} \\\n      in1=$read1 \\\n      in2=$read2 \\\n      out1=$sampleID\".bbduk.R1.fastq.gz\" \\\n      out2=$sampleID\".bbduk.R2.fastq.gz\" \\\n      k=31 \\\n      mink=5 \\\n      hdist=1 \\\n      ktrim=r \\\n      trimq=20 \\\n      qtrim=rl \\\n      maq=20 \\\n      ref=/opt/miniconda/envs/somatic_exome_n-of-1/opt/bbmap-38.57-0/resources/adapters.fa \\\n      tpe \\\n      tbo \\\n      stats=$sampleID\".bbduk.adapterstats.txt\" \\\n      overwrite=T\n  } 2>&1 | tee > $sampleID\".bbduk.runstats.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "  \"\"\"\n  {\n    sh bbduk.sh ${params.quarter_javamem} \\\n      in1=$read1 \\\n      in2=$read2 \\\n      out1=$sampleID\".bbduk.R1.fastq.gz\" \\\n      out2=$sampleID\".bbduk.R2.fastq.gz\" \\\n      k=31 \\\n      mink=5 \\\n      hdist=1 \\\n      ktrim=r \\\n      trimq=20 \\\n      qtrim=rl \\\n      maq=20 \\\n      ref=/opt/miniconda/envs/somatic_exome_n-of-1/opt/bbmap-38.57-0/resources/adapters.fa \\\n      tpe \\\n      tbo \\\n      stats=$sampleID\".bbduk.adapterstats.txt\" \\\n      overwrite=T\n  } 2>&1 | tee > $sampleID\".bbduk.runstats.txt\"\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "RASH",
            "TPES",
            "NetBox"
        ],
        "tools_url": [
            "https://bio.tools/RASH",
            "https://bio.tools/TPES",
            "https://bio.tools/netbox"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            },
            {
                "name": "TPES",
                "uri": "https://bio.tools/TPES",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tumor Purity Estimation from SNVs.",
                "homepage": "https://bitbucket.org/l0ka/tpes.git"
            },
            {
                "name": "NetBox",
                "uri": "https://bio.tools/netbox",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2259",
                            "term": "Systems biology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2497",
                                    "term": "Pathway or network analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "NetBox is a Java-based software tool for performing network analysis on human interaction networks. It is pre-loaded with a Human Interaction Network (HIN) derived from four literature curated data sources, including the Human Protein Reference Database (HPRD), Reactome, NCI-Nature Pathway Interaction (PID) Database, and the MSKCC Cancer Cell Map.",
                "homepage": "http://cbio.mskcc.org/tools/netbox/index.html"
            }
        ],
        "inputs": [
            "bbduking"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completed0_0",
            "bwa_memming",
            "fastping",
            "fastqcing"
        ],
        "nb_outputs": 4,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/bbduk\", mode: \"copy\", pattern: \"*.txt\""
        ],
        "when": "",
        "stub": ""
    },
    "fastp": {
        "name_process": "fastp",
        "string_process": "\nprocess fastp {\n\n  publishDir \"$params.outDir/samples/$sampleID/fastp\", mode: \"copy\", pattern: \"*.html\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(preread1), file(preread2), file(postread1), file(postread2) from fastping\n\n  output:\n  file('*.html') into completed0_1\n  file('*.json') into fastp_multiqc\n\n  script:\n  \"\"\"\n  fastp -w ${task.cpus} -h $sampleID\"_pre.fastp.html\" -j $sampleID\"_pre.fastp.json\" --in1 $preread1 --in2 $preread2\n\n  fastp -w ${task.cpus} -h $sampleID\"_post.fastp.html\" -j $sampleID\"_post.fastp.json\" --in1 $postread1 --in2 $postread2\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  fastp -w ${task.cpus} -h $sampleID\"_pre.fastp.html\" -j $sampleID\"_pre.fastp.json\" --in1 $preread1 --in2 $preread2\n\n  fastp -w ${task.cpus} -h $sampleID\"_post.fastp.html\" -j $sampleID\"_post.fastp.json\" --in1 $postread1 --in2 $postread2\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "fastping"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completed0_1",
            "fastp_multiqc"
        ],
        "nb_outputs": 2,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/samples/$sampleID/fastp\", mode: \"copy\", pattern: \"*.html\""
        ],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n\n  publishDir \"$params.outDir/samples/$sampleID/fastqc\", mode: \"copy\", pattern: \"*.html\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) from fastqcing\n\n  output:\n  file('*.html') into fastqc_multiqc\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  fastqc -t ${task.cpus} --noextract -o ./ $read1 $read2\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  fastqc -t ${task.cpus} --noextract -o ./ $read1 $read2\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "fastqcing"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_multiqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/samples/$sampleID/fastqc\", mode: \"copy\", pattern: \"*.html\""
        ],
        "when": "",
        "stub": ""
    },
    "bwamem": {
        "name_process": "bwamem",
        "string_process": "\nprocess bwamem {\n\n  cache 'deep'\n\n  publishDir path: \"$params.outDir/samples/$sampleID/bwa\", mode: \"copy\", pattern: \"*.log.txt\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(read1), file(read2) from bwa_memming\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  tuple file(amb), file(ann), file(bwt), file(pac), file(sa) from Channel.value([params.amb, params.ann, params.bwt, params.pac, params.sa])\n\n  output:\n  tuple val(type), val(sampleID), val(meta), file('*.bam'), file('*.bai') into (cramming, dup_marking)\n  file('*.log.txt') into completedbwa\n\n  script:\n  \"\"\"\n  DATE=\\$(date +\"%Y-%m-%dT%T\")\n  RGLINE=\"@RG\\\\tID:$sampleID\\\\tPL:ILLUMINA\\\\tSM:$sampleID\\\\tDS:$type\\\\tCN:UCD\\\\tLB:LANE_X\\\\tDT:\\$DATE\"\n\n  {\n  bwa mem \\\n    -t${task.cpus} \\\n    -M \\\n    -R \\$RGLINE \\\n    $fasta \\\n    $read1 $read2 | \\\n    samtools sort -T \"tmp.\"$sampleID -o $sampleID\".sort.bam\"\n\n  samtools index $sampleID\".sort.bam\"\n\n  } 2>&1 | tee > $sampleID\".bwa-mem.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "  \"\"\"\n  DATE=\\$(date +\"%Y-%m-%dT%T\")\n  RGLINE=\"@RG\\\\tID:$sampleID\\\\tPL:ILLUMINA\\\\tSM:$sampleID\\\\tDS:$type\\\\tCN:UCD\\\\tLB:LANE_X\\\\tDT:\\$DATE\"\n\n  {\n  bwa mem \\\n    -t${task.cpus} \\\n    -M \\\n    -R \\$RGLINE \\\n    $fasta \\\n    $read1 $read2 | \\\n    samtools sort -T \"tmp.\"$sampleID -o $sampleID\".sort.bam\"\n\n  samtools index $sampleID\".sort.bam\"\n\n  } 2>&1 | tee > $sampleID\".bwa-mem.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bwa_memming"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "completedbwa"
        ],
        "nb_outputs": 2,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "cache 'deep'",
            "publishDir path: \"$params.outDir/samples/$sampleID/bwa\", mode: \"copy\", pattern: \"*.log.txt\""
        ],
        "when": "",
        "stub": ""
    },
    "cram": {
        "name_process": "cram",
        "string_process": "\nprocess cram {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/bwa\", mode: \"copy\", pattern: \"*.cra*\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai) from cramming\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n\n  output:\n  tuple file('*.cram'), file('*.crai') into completedcram\n\n  script:\n  \"\"\"\n  samtools view -hC -T $fasta $sampleID\".sort.bam\" > $sampleID\".sort.cram\"\n  samtools index $sampleID\".sort.cram\"\n  \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  samtools view -hC -T $fasta $sampleID\".sort.bam\" > $sampleID\".sort.cram\"\n  samtools index $sampleID\".sort.cram\"\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "cramming"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completedcram"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/bwa\", mode: \"copy\", pattern: \"*.cra*\""
        ],
        "when": "",
        "stub": ""
    },
    "mrkdup": {
        "name_process": "mrkdup",
        "string_process": "\nprocess mrkdup {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/picard/markdup\", mode: \"copy\", pattern: \"*[!.metrics.txt]\"\n  publishDir path: \"$params.outDir/samples/$sampleID/picard/metrics\", mode: \"copy\", pattern: \"*.metrics.txt\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai) from dup_marking\n\n  output:\n  file('*md.metrics.txt') into mrkdup_multiqc\n  tuple val(type), val(sampleID), val(meta), file('*.md.bam'), file('*.md.bam.bai') into gatk4recaling\n\n  script:\n  \"\"\"\n  OUTBAM=\\$(echo $bam | sed 's/bam/md.bam/')\n  OUTMET=\\$(echo $bam | sed 's/bam/md.metrics.txt/')\n  {\n    picard ${params.quarter_javamem} \\\n      MarkDuplicates \\\n      TMP_DIR=./ \\\n      INPUT=$bam \\\n      OUTPUT=/dev/stdout \\\n      COMPRESSION_LEVEL=0 \\\n      QUIET=TRUE \\\n      METRICS_FILE=\\$OUTMET \\\n      REMOVE_DUPLICATES=FALSE \\\n      ASSUME_SORTED=TRUE \\\n      VALIDATION_STRINGENCY=LENIENT \\\n      VERBOSITY=ERROR | samtools view -Shb - > \\$OUTBAM\n\n  samtools index \\$OUTBAM\n  } 2>&1 | tee > $sampleID\".picard_markDuplicates.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "  \"\"\"\n  OUTBAM=\\$(echo $bam | sed 's/bam/md.bam/')\n  OUTMET=\\$(echo $bam | sed 's/bam/md.metrics.txt/')\n  {\n    picard ${params.quarter_javamem} \\\n      MarkDuplicates \\\n      TMP_DIR=./ \\\n      INPUT=$bam \\\n      OUTPUT=/dev/stdout \\\n      COMPRESSION_LEVEL=0 \\\n      QUIET=TRUE \\\n      METRICS_FILE=\\$OUTMET \\\n      REMOVE_DUPLICATES=FALSE \\\n      ASSUME_SORTED=TRUE \\\n      VALIDATION_STRINGENCY=LENIENT \\\n      VERBOSITY=ERROR | samtools view -Shb - > \\$OUTBAM\n\n  samtools index \\$OUTBAM\n  } 2>&1 | tee > $sampleID\".picard_markDuplicates.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "Picard",
            "MarkDuplicates (IP)",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools",
            "https://bio.tools/markduplicates_ip",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            },
            {
                "name": "MarkDuplicates (IP)",
                "uri": "https://bio.tools/markduplicates_ip",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0253",
                                    "term": "Sequence feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0253",
                                    "term": "Sequence feature recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0253",
                                    "term": "Sequence feature prediction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "Marks all duplicate reads in a provided SAM or BAM file and either removes them or flags them.",
                "homepage": "https://galaxy.pasteur.fr/tool_runner?tool_id=toolshed.pasteur.fr/repos/fmareuil/picard_pasteur_wrapper/rgPicardMarkDups/1.56.0"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "dup_marking"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mrkdup_multiqc",
            "gatk4recaling"
        ],
        "nb_outputs": 2,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/picard/markdup\", mode: \"copy\", pattern: \"*[!.metrics.txt]\"",
            "publishDir path: \"$params.outDir/samples/$sampleID/picard/metrics\", mode: \"copy\", pattern: \"*.metrics.txt\""
        ],
        "when": "",
        "stub": ""
    },
    "gtkrcl": {
        "name_process": "gtkrcl",
        "string_process": "\nprocess gtkrcl {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/gatk4/bestpractice\", mode: \"copy\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai) from gatk4recaling\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  tuple file(dbsnp), file(dbsnptbi) from Channel.value([params.dbsnp, params.dbsnptbi])\n  file(exomeintlist) from Channel.value(params.exomeintlist)\n\n  output:\n  file('*.table') into gtkrcl_multiqc\n  tuple val(type), val(sampleID), file('*.bqsr.bam'), file('*.bqsr.bam.bai') into (somafiltering, germfiltering, varlpreproc)\n  tuple val(type), val(sampleID), val(meta), file('*.bqsr.bam'), file('*.bqsr.bam.bai') into gatk_germ\n\n  script:\n  \"\"\"\n  {\n    gatk BaseRecalibrator \\\n    -R $fasta \\\n    -I $bam \\\n    --known-sites $dbsnp \\\n    --use-original-qualities \\\n    -O ${sampleID}.recal_data.table \\\n    --disable-sequence-dictionary-validation true \\\n    -L $exomeintlist\n\n  #ApplyBQSR\n  OUTBAM=\\$(echo $bam | sed 's/bam/bqsr.bam/')\n  gatk ApplyBQSR \\\n    -R $fasta \\\n    -I $bam \\\n    --bqsr-recal-file ${sampleID}.recal_data.table \\\n    --add-output-sam-program-record \\\n    --use-original-qualities \\\n    -O \\$OUTBAM \\\n    -L $exomeintlist\n\n  samtools index \\$OUTBAM \\$OUTBAM\".bai\"\n  } 2>&1 | tee > $sampleID\".GATK4_recal.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "  \"\"\"\n  {\n    gatk BaseRecalibrator \\\n    -R $fasta \\\n    -I $bam \\\n    --known-sites $dbsnp \\\n    --use-original-qualities \\\n    -O ${sampleID}.recal_data.table \\\n    --disable-sequence-dictionary-validation true \\\n    -L $exomeintlist\n\n  #ApplyBQSR\n  OUTBAM=\\$(echo $bam | sed 's/bam/bqsr.bam/')\n  gatk ApplyBQSR \\\n    -R $fasta \\\n    -I $bam \\\n    --bqsr-recal-file ${sampleID}.recal_data.table \\\n    --add-output-sam-program-record \\\n    --use-original-qualities \\\n    -O \\$OUTBAM \\\n    -L $exomeintlist\n\n  samtools index \\$OUTBAM \\$OUTBAM\".bai\"\n  } 2>&1 | tee > $sampleID\".GATK4_recal.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "GATK",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/gatk",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "gatk4recaling"
        ],
        "nb_inputs": 1,
        "outputs": [
            "gtkrcl_multiqc",
            "",
            "gatk_germ"
        ],
        "nb_outputs": 3,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/gatk4/bestpractice\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "gatkgerm": {
        "name_process": "gatkgerm",
        "string_process": "\nprocess gatkgerm {\n\n  publishDir \"$params.outDir/samples/$sampleID/gatk4/HC_germline\", mode: \"copy\", pattern: \"*\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(bam), file(bai) from gatk_germ\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  tuple file(dbsnp), file(dbsnptbi) from Channel.value([params.dbsnp, params.dbsnptbi])\n  file(exomeintlist) from Channel.value(params.exomeintlist)\n  tuple file(omni), file(otbi), file(kgp1), file(ktbi), file(hpmp), file(htbi) from Channel.value([params.omni, params.otbi, params.kgp1, params.ktbi, params.hpmp, params.htbi])\n\n  output:\n  tuple val(type), val(sampleID), val(meta), file('*.HC.vcf.gz'), file('*.HC.vcf.gz.tbi') into germ_vcf\n\n  when:\n  type == \"germline\"\n\n  script:\n  \"\"\"\n  {\n    #HaplotypeCaller\n    INPUTBAM=$bam\n    OUTVCF=\\$(echo \\$INPUTBAM | sed 's/bam/hc.vcf/')\n    gatk --java-options ${params.full_javamem} HaplotypeCaller \\\n      -R $fasta \\\n      -I \\$INPUTBAM \\\n      --dont-use-soft-clipped-bases \\\n      --standard-min-confidence-threshold-for-calling 20 \\\n      --dbsnp $dbsnp \\\n      --native-pair-hmm-threads ${task.cpus} \\\n      -O $sampleID\".HC.vcf\" \\\n      --disable-sequence-dictionary-validation true \\\n      -L $exomeintlist\n\n    bgzip $sampleID\".HC.vcf\"\n    tabix $sampleID\".HC.vcf.gz\"\n\n  } 2>&1 | tee $sampleID\".GATK4_HaplotypeCaller-germline.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "  \"\"\"\n  {\n    #HaplotypeCaller\n    INPUTBAM=$bam\n    OUTVCF=\\$(echo \\$INPUTBAM | sed 's/bam/hc.vcf/')\n    gatk --java-options ${params.full_javamem} HaplotypeCaller \\\n      -R $fasta \\\n      -I \\$INPUTBAM \\\n      --dont-use-soft-clipped-bases \\\n      --standard-min-confidence-threshold-for-calling 20 \\\n      --dbsnp $dbsnp \\\n      --native-pair-hmm-threads ${task.cpus} \\\n      -O $sampleID\".HC.vcf\" \\\n      --disable-sequence-dictionary-validation true \\\n      -L $exomeintlist\n\n    bgzip $sampleID\".HC.vcf\"\n    tabix $sampleID\".HC.vcf.gz\"\n\n  } 2>&1 | tee $sampleID\".GATK4_HaplotypeCaller-germline.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "gatk_germ"
        ],
        "nb_inputs": 1,
        "outputs": [
            "germ_vcf"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/samples/$sampleID/gatk4/HC_germline\", mode: \"copy\", pattern: \"*\""
        ],
        "when": "type == \"germline\"",
        "stub": ""
    },
    "cpsr": {
        "name_process": "cpsr",
        "string_process": "\nprocess cpsr {\n\n  publishDir \"$params.outDir/reports\", mode: \"copy\", pattern: \"*.html\"\n  publishDir \"$params.outDir/output/cpsr\", mode: \"copy\", pattern: \"*[!.html]\"\n\n  input:\n  tuple val(type), val(sampleID), val(meta), file(vcf), file(tbi) from germ_vcf\n  each file(cpsr_grch) from CPSR\n  val(grchvers) from cpsr_grchvers\n\n  output:\n  file('*') into cpsr_vcfs\n\n  script:\n  \"\"\"\n  {\n    CONFIG=\\$(readlink -e $cpsr_grch/data/*/cpsr_configuration_default.toml)\n    META=\\$(echo $meta | sed 's/\\\\s */_/g')\n    cpsr.py \\\n      --no-docker \\\n      --no_vcf_validate \\\n      $vcf \\\n      $cpsr_grch \\\n      ./ \\\n      $grchvers \\\n      0 \\\n      \\$CONFIG \\\n      \\$META\n\n  } 2>&1 | tee $sampleID\".cpsr.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "  \"\"\"\n  {\n    CONFIG=\\$(readlink -e $cpsr_grch/data/*/cpsr_configuration_default.toml)\n    META=\\$(echo $meta | sed 's/\\\\s */_/g')\n    cpsr.py \\\n      --no-docker \\\n      --no_vcf_validate \\\n      $vcf \\\n      $cpsr_grch \\\n      ./ \\\n      $grchvers \\\n      0 \\\n      \\$CONFIG \\\n      \\$META\n\n  } 2>&1 | tee $sampleID\".cpsr.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "germ_vcf",
            "CPSR",
            "cpsr_grchvers"
        ],
        "nb_inputs": 3,
        "outputs": [
            "cpsr_vcfs"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/reports\", mode: \"copy\", pattern: \"*.html\"",
            "publishDir \"$params.outDir/output/cpsr\", mode: \"copy\", pattern: \"*[!.html]\""
        ],
        "when": "",
        "stub": ""
    },
    "grmflt": {
        "name_process": "grmflt",
        "string_process": "\nprocess grmflt {\n  executor 'local'\n\n  input:\n  tuple val(type), val(sampleID), file(bam), file(bai) from germfiltering\n\n  output:\n                                     \n                                  \n                                  \n  tuple val(sampleID), file(bam), file(bai) into (germcombine, gmultimetricing, germbamcand)\n  val(sampleID) into germlineID\n\n  when:\n  type == \"germline\"\n\n  script:\n  \"\"\"\n  \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  \"\"\"",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "germfiltering"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "germlineID"
        ],
        "nb_outputs": 2,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "executor 'local'"
        ],
        "when": "type == \"germline\"",
        "stub": ""
    },
    "smaflt": {
        "name_process": "smaflt",
        "string_process": "\nprocess smaflt {\n  executor 'local'\n\n  input:\n  tuple val(type), val(sampleID), file(bam), file(bai) from somafiltering\n\n  output:\n  tuple val(sampleID), file(bam), file(bai) into (multimetricing, somacombine)\n\n  when:\n  type != \"germline\"\n\n  script:\n  \"\"\"\n  \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  \"\"\"",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "somafiltering"
        ],
        "nb_inputs": 1,
        "outputs": [
            ""
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "executor 'local'"
        ],
        "when": "type != \"germline\"",
        "stub": ""
    },
    "combinegs": {
        "name_process": "combinegs",
        "string_process": "\nprocess combinegs {\n  executor 'local'\n\n  input:\n  tuple val(sampleID), file(somafiles), val(germlineID), file(germlinefiles) from somagermtap\n\n  output:\n  tuple val(sampleID), file(\"${somafiles[0]}\"), file(\"${somafiles[1]}\"), val(germlineID), file(\"${germlinefiles[0]}\"), file(\"${germlinefiles[1]}\") into ( mutect2somaticing, facetsomaing, msisensoring, mantastrelka2ing, lanceting )\n  val(germlineID) into vcfGRaID\n\n  script:\n  \"\"\"\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "  \"\"\"\n  \"\"\"",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "somagermtap"
        ],
        "nb_inputs": 1,
        "outputs": [
            "",
            "vcfGRaID"
        ],
        "nb_outputs": 2,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "executor 'local'"
        ],
        "when": "",
        "stub": ""
    },
    "mltmet": {
        "name_process": "mltmet",
        "string_process": "\nprocess mltmet {\n\n  publishDir \"$params.outDir/samples/$sampleID/metrics\"\n\n  input:\n  tuple val(sampleID), file(bam), file(bai) from MULTIALL\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  file(exomeintlist) from Channel.value(params.exomeintlist)\n\n  output:\n  file('*') into all2_0\n  file('*.txt') into multimetrics_multiqc\n\n  script:\n  \"\"\"\n  {\n    picard CollectHsMetrics \\\n      I=$bam \\\n      O=$sampleID\".hs_metrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta \\\n      BAIT_INTERVALS=$exomeintlist  \\\n      TARGET_INTERVALS=$exomeintlist\n\n    picard CollectAlignmentSummaryMetrics \\\n      I=$bam \\\n      O=$sampleID\".AlignmentSummaryMetrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta\n\n    picard CollectMultipleMetrics \\\n      I=$bam \\\n      O=$sampleID\".CollectMultipleMetrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta\n\n    picard CollectSequencingArtifactMetrics \\\n      I=$bam \\\n      O=$sampleID\".artifact_metrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta\n\n    picard EstimateLibraryComplexity \\\n      I=$bam \\\n      O=$sampleID\".est_lib_complex_metrics.txt\" \\\n      TMP_DIR=./\n\n    picard CollectInsertSizeMetrics \\\n      I=$bam \\\n      O=$sampleID\".insert_size_metrics.txt\" \\\n      H=$bam\".histogram.pdf\" \\\n      TMP_DIR=./\n\n  } 2>&1 | tee > $sampleID\".picard.metrics.log\"\n  \"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "  \"\"\"\n  {\n    picard CollectHsMetrics \\\n      I=$bam \\\n      O=$sampleID\".hs_metrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta \\\n      BAIT_INTERVALS=$exomeintlist  \\\n      TARGET_INTERVALS=$exomeintlist\n\n    picard CollectAlignmentSummaryMetrics \\\n      I=$bam \\\n      O=$sampleID\".AlignmentSummaryMetrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta\n\n    picard CollectMultipleMetrics \\\n      I=$bam \\\n      O=$sampleID\".CollectMultipleMetrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta\n\n    picard CollectSequencingArtifactMetrics \\\n      I=$bam \\\n      O=$sampleID\".artifact_metrics.txt\" \\\n      TMP_DIR=./ \\\n      R=$fasta\n\n    picard EstimateLibraryComplexity \\\n      I=$bam \\\n      O=$sampleID\".est_lib_complex_metrics.txt\" \\\n      TMP_DIR=./\n\n    picard CollectInsertSizeMetrics \\\n      I=$bam \\\n      O=$sampleID\".insert_size_metrics.txt\" \\\n      H=$bam\".histogram.pdf\" \\\n      TMP_DIR=./\n\n  } 2>&1 | tee > $sampleID\".picard.metrics.log\"\n  \"\"\"",
        "nb_lignes_script": 40,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "MULTIALL"
        ],
        "nb_inputs": 1,
        "outputs": [
            "all2_0",
            "multimetrics_multiqc"
        ],
        "nb_outputs": 2,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/samples/$sampleID/metrics\""
        ],
        "when": "",
        "stub": ""
    },
    "fctcsv": {
        "name_process": "fctcsv",
        "string_process": "\nprocess fctcsv {\n\n  publishDir \"$params.outDir/samples/$sampleID/facets\"\n\n  input:\n  set val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai) from facetsomaing\n  set file(dbsnp), file(dbsnptbi) from Channel.value([params.dbsnp, params.dbsnptbi])\n\n  output:\n  file('*.cncf-jointsegs.pcgr.tsv') into facets_consensusing\n  file('*.pcgr.tsv') into facets_pcgr\n  file('*') into facetsoutputR\n\n  script:\n  \"\"\"\n  CSVFILE=\\$(echo $tumourbam | sed 's/bam/facets.r10.csv/')\n\n  {\n    snp-pileup \\\n      $dbsnp \\\n      -r 10 \\\n      -p \\\n      \\$CSVFILE \\\n      $germlinebam \\\n      $tumourbam\n\n    Rscript --vanilla  ${workflow.projectDir}/bin/facets_cna.call.R \\$CSVFILE\n\n    echo -e \"Chromosome\\\\tStart\\\\tEnd\\\\tSegment_Mean\" > $sampleID\".cncf-jointsegs.pcgr.tsv\"\n    tail -n+2 $sampleID\".fit_cncf-jointsegs.tsv\" | awk '{print \\$1\"\\\\t\"\\$10\"\\\\t\"\\$11\"\\\\t\"\\$5}' >> $sampleID\".cncf-jointsegs.pcgr.tsv\"\n\n    tail -n+2 $sampleID\".fit_ploidy-purity.tab\" > $sampleID\".fit_ploidy-purity.pcgr.tsv\"\n\n  } 2>&1 | tee > $sampleID\".facets_snpp_call.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "  \"\"\"\n  CSVFILE=\\$(echo $tumourbam | sed 's/bam/facets.r10.csv/')\n\n  {\n    snp-pileup \\\n      $dbsnp \\\n      -r 10 \\\n      -p \\\n      \\$CSVFILE \\\n      $germlinebam \\\n      $tumourbam\n\n    Rscript --vanilla  ${workflow.projectDir}/bin/facets_cna.call.R \\$CSVFILE\n\n    echo -e \"Chromosome\\\\tStart\\\\tEnd\\\\tSegment_Mean\" > $sampleID\".cncf-jointsegs.pcgr.tsv\"\n    tail -n+2 $sampleID\".fit_cncf-jointsegs.tsv\" | awk '{print \\$1\"\\\\t\"\\$10\"\\\\t\"\\$11\"\\\\t\"\\$5}' >> $sampleID\".cncf-jointsegs.pcgr.tsv\"\n\n    tail -n+2 $sampleID\".fit_ploidy-purity.tab\" > $sampleID\".fit_ploidy-purity.pcgr.tsv\"\n\n  } 2>&1 | tee > $sampleID\".facets_snpp_call.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "facetsomaing"
        ],
        "nb_inputs": 1,
        "outputs": [
            "facets_consensusing",
            "facets_pcgr",
            "facetsoutputR"
        ],
        "nb_outputs": 3,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/samples/$sampleID/facets\""
        ],
        "when": "",
        "stub": ""
    },
    "fctcon": {
        "name_process": "fctcon",
        "string_process": "\nprocess fctcon {\n\n  publishDir \"$params.outDir/output/scna/facets\"\n\n  input:\n  file(filesn) from facets_consensusing.collect()\n  file(dict) from Channel.value(params.dict)\n\n  output:\n  file('*') into completed2_11\n\n  script:\n  \"\"\"\n  {\n  OUTID=\\$(basename ${workflow.launchDir})\n  Rscript --vanilla  ${workflow.projectDir}/bin/facets_cna_consensus.call.R \\\n    $dict \\\n    \\$OUTID \\\n    ${workflow.projectDir}/bin/facets_cna_consensus.func.R\n  } 2>&1 | tee > \"facets_cons.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  \"\"\"\n  {\n  OUTID=\\$(basename ${workflow.launchDir})\n  Rscript --vanilla  ${workflow.projectDir}/bin/facets_cna_consensus.call.R \\\n    $dict \\\n    \\$OUTID \\\n    ${workflow.projectDir}/bin/facets_cna_consensus.func.R\n  } 2>&1 | tee > \"facets_cons.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "facets_consensusing"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completed2_11"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/output/scna/facets\""
        ],
        "when": "",
        "stub": ""
    },
    "mutct2": {
        "name_process": "mutct2",
        "string_process": "\nprocess mutct2 {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/mutect2\", mode: \"copy\"\n  publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*raw.vcf'\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai) from mutect2somaticing\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  file(exomeintlist) from Channel.value(params.exomeintlist)\n  tuple file(gps), file(gpstbi) from Channel.value([params.gps, params.gpstbi])\n\n  output:\n  file('*.pass.vcf') into mutect2_veping mode flatten\n  file('*.raw.vcf') into mutect2_rawVcf\n  file('*') into completedmutect2call\n  tuple val(sampleID), file('*calculatecontamination.table') into contamination\n\n  script:\n  \"\"\"\n  {\n    gatk --java-options ${params.full_javamem} \\\n      Mutect2 \\\n      --native-pair-hmm-threads ${task.cpus} \\\n      --reference $fasta \\\n      --input $germlinebam \\\n      --input $tumourbam \\\n      --normal-sample $germlineID \\\n      --tumor-sample $sampleID \\\n      --output $sampleID\".md.recal.mutect2.vcf\" \\\n      --disable-sequence-dictionary-validation true \\\n      -L $exomeintlist\n\n    gatk --java-options ${params.full_javamem} \\\n      GetPileupSummaries \\\n      -I $tumourbam \\\n      -V $gps \\\n      -O $sampleID\".getpileupsummaries.table\" \\\n      -L $exomeintlist\n\n    gatk CalculateContamination \\\n      -I $sampleID\".getpileupsummaries.table\" \\\n      -O $sampleID\".calculatecontamination.table\"\n\n    gatk --java-options ${params.full_javamem} \\\n      FilterMutectCalls \\\n      --reference $fasta \\\n      --contamination-table $sampleID\".calculatecontamination.table\" \\\n      --interval-padding 5 \\\n      --output $sampleID\".md.recal.mutect2.FilterMutectCalls.vcf\" \\\n      --unique-alt-read-count 3 \\\n      --variant $sampleID\".md.recal.mutect2.vcf\" \\\n      --disable-sequence-dictionary-validation true \\\n      -L $exomeintlist\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n      ID=$sampleID \\\n      DP=14 \\\n      MD=2 \\\n      VCF=$sampleID\".md.recal.mutect2.FilterMutectCalls.vcf\"\n\n  } 2>&1 | tee > $sampleID\".GATK4_mutect2.log.txt\"\n  \"\"\"\n\n}",
        "nb_lignes_process": 63,
        "string_script": "  \"\"\"\n  {\n    gatk --java-options ${params.full_javamem} \\\n      Mutect2 \\\n      --native-pair-hmm-threads ${task.cpus} \\\n      --reference $fasta \\\n      --input $germlinebam \\\n      --input $tumourbam \\\n      --normal-sample $germlineID \\\n      --tumor-sample $sampleID \\\n      --output $sampleID\".md.recal.mutect2.vcf\" \\\n      --disable-sequence-dictionary-validation true \\\n      -L $exomeintlist\n\n    gatk --java-options ${params.full_javamem} \\\n      GetPileupSummaries \\\n      -I $tumourbam \\\n      -V $gps \\\n      -O $sampleID\".getpileupsummaries.table\" \\\n      -L $exomeintlist\n\n    gatk CalculateContamination \\\n      -I $sampleID\".getpileupsummaries.table\" \\\n      -O $sampleID\".calculatecontamination.table\"\n\n    gatk --java-options ${params.full_javamem} \\\n      FilterMutectCalls \\\n      --reference $fasta \\\n      --contamination-table $sampleID\".calculatecontamination.table\" \\\n      --interval-padding 5 \\\n      --output $sampleID\".md.recal.mutect2.FilterMutectCalls.vcf\" \\\n      --unique-alt-read-count 3 \\\n      --variant $sampleID\".md.recal.mutect2.vcf\" \\\n      --disable-sequence-dictionary-validation true \\\n      -L $exomeintlist\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n      ID=$sampleID \\\n      DP=14 \\\n      MD=2 \\\n      VCF=$sampleID\".md.recal.mutect2.FilterMutectCalls.vcf\"\n\n  } 2>&1 | tee > $sampleID\".GATK4_mutect2.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 43,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "mutect2somaticing"
        ],
        "nb_inputs": 1,
        "outputs": [
            "mutect2_veping",
            "mutect2_rawVcf",
            "completedmutect2call",
            "contamination"
        ],
        "nb_outputs": 4,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/mutect2\", mode: \"copy\"",
            "publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*raw.vcf'"
        ],
        "when": "",
        "stub": ""
    },
    "mutct2_contam": {
        "name_process": "mutct2_contam",
        "string_process": "\nprocess mutct2_contam {\n\n  publishDir path: \"$params.outDir/samples/\", mode: \"copy\", pattern: '*issue.table'\n\n  input:\n  tuple val(sampleID), file(contable) from contamination\n\n  output:\n  file('*.table') into completedcontam\n\n  \"\"\"\n  Rscript --vanilla ${workflow.projectDir}/bin/MuTect2_contamination.call.R $contable $sampleID\n  \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n  Rscript --vanilla ${workflow.projectDir}/bin/MuTect2_contamination.call.R $contable $sampleID\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "contamination"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completedcontam"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/\", mode: \"copy\", pattern: '*issue.table'"
        ],
        "when": "",
        "stub": ""
    },
    "mntstr": {
        "name_process": "mntstr",
        "string_process": "\nprocess mntstr {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/manta-strelka2\"\n  publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*raw.vcf'\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai) from mantastrelka2ing\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  tuple file(exomebedgz), file(exomebedgztbi) from Channel.value([params.exomebedgz, params.exomebedgztbi])\n\n  output:\n  val(sampleID) into completed2_4\n  file('*.strelka2.snv_indel.pass.vcf') into strelka2_veping\n  file('*.raw.vcf') into strelka2_rawVcf\n  file('manta/*') into completedmantacall\n\n  script:\n  \"\"\"\n  {\n    configManta.py \\\n      --exome \\\n      --referenceFasta=$fasta \\\n      --callRegions $exomebedgz \\\n      --normalBam=$germlinebam \\\n      --tumourBam=$tumourbam \\\n      --runDir=manta\n\n    manta/runWorkflow.py -m local -j ${task.cpus}\n\n    configureStrelkaSomaticWorkflow.py \\\n      --exome \\\n      --referenceFasta=$fasta \\\n      --callRegions $exomebedgz \\\n      --indelCandidates=manta/results/variants/candidateSmallIndels.vcf.gz \\\n      --normalBam=$germlinebam \\\n      --tumorBam=$tumourbam \\\n      --runDir=strelka2\n\n    strelka2/runWorkflow.py -m local -j ${task.cpus}\n\n    TUMOURSNVVCF=\\$(echo $tumourbam | sed 's/bam/strelka2.snv.vcf/')\n    gunzip -c strelka2/results/variants/somatic.snvs.vcf.gz | \\\n    perl -ane 'if(\\$F[0]=~m/^#/){if(\\$_=~m/^#CHROM/){\n        \\$_=~s/NORMAL/$germlineID/;\n        \\$_=~s/TUMOR/$sampleID/;\n        print \\$_;next;}\n        else{print \\$_;next;}\n      }\n      else{print \\$_;}' > \\$TUMOURSNVVCF\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n     ID=$sampleID \\\n     DP=14 \\\n     MD=2 \\\n     VCF=\\$TUMOURSNVVCF\n\n    TUMOURINDELVCF=\\$(echo $tumourbam | sed 's/bam/strelka2.indel.vcf/')\n    gunzip -c strelka2/results/variants/somatic.indels.vcf.gz | \\\n    perl -ane 'if(\\$F[0]=~m/^#/){if(\\$_=~m/^#CHROM/){\n        \\$_=~s/NORMAL/$germlineID/;\n        \\$_=~s/TUMOR/$sampleID/;\n        print \\$_;next;}\n        else{print \\$_;next;}}\n      else{print \\$_;}' > \\$TUMOURINDELVCF\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n      ID=$sampleID \\\n      DP=14 \\\n      MD=2 \\\n      VCF=\\$TUMOURINDELVCF\n\n    PASSSNV=\\$(ls | grep strelka2.snv.pass.vcf)\n    PASSIND=\\$(ls | grep strelka2.indel.pass.vcf)\n\n    gatk MergeVcfs \\\n      -I \\$PASSSNV \\\n      -I \\$PASSIND \\\n      -O $sampleID\".strelka2.snv_indel.pass.vcf\"\n\n  } 2>&1 | tee > $sampleID\".manta-strelka2.log.txt\"\n  \"\"\"\n}",
        "nb_lignes_process": 81,
        "string_script": "  \"\"\"\n  {\n    configManta.py \\\n      --exome \\\n      --referenceFasta=$fasta \\\n      --callRegions $exomebedgz \\\n      --normalBam=$germlinebam \\\n      --tumourBam=$tumourbam \\\n      --runDir=manta\n\n    manta/runWorkflow.py -m local -j ${task.cpus}\n\n    configureStrelkaSomaticWorkflow.py \\\n      --exome \\\n      --referenceFasta=$fasta \\\n      --callRegions $exomebedgz \\\n      --indelCandidates=manta/results/variants/candidateSmallIndels.vcf.gz \\\n      --normalBam=$germlinebam \\\n      --tumorBam=$tumourbam \\\n      --runDir=strelka2\n\n    strelka2/runWorkflow.py -m local -j ${task.cpus}\n\n    TUMOURSNVVCF=\\$(echo $tumourbam | sed 's/bam/strelka2.snv.vcf/')\n    gunzip -c strelka2/results/variants/somatic.snvs.vcf.gz | \\\n    perl -ane 'if(\\$F[0]=~m/^#/){if(\\$_=~m/^#CHROM/){\n        \\$_=~s/NORMAL/$germlineID/;\n        \\$_=~s/TUMOR/$sampleID/;\n        print \\$_;next;}\n        else{print \\$_;next;}\n      }\n      else{print \\$_;}' > \\$TUMOURSNVVCF\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n     ID=$sampleID \\\n     DP=14 \\\n     MD=2 \\\n     VCF=\\$TUMOURSNVVCF\n\n    TUMOURINDELVCF=\\$(echo $tumourbam | sed 's/bam/strelka2.indel.vcf/')\n    gunzip -c strelka2/results/variants/somatic.indels.vcf.gz | \\\n    perl -ane 'if(\\$F[0]=~m/^#/){if(\\$_=~m/^#CHROM/){\n        \\$_=~s/NORMAL/$germlineID/;\n        \\$_=~s/TUMOR/$sampleID/;\n        print \\$_;next;}\n        else{print \\$_;next;}}\n      else{print \\$_;}' > \\$TUMOURINDELVCF\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n      ID=$sampleID \\\n      DP=14 \\\n      MD=2 \\\n      VCF=\\$TUMOURINDELVCF\n\n    PASSSNV=\\$(ls | grep strelka2.snv.pass.vcf)\n    PASSIND=\\$(ls | grep strelka2.indel.pass.vcf)\n\n    gatk MergeVcfs \\\n      -I \\$PASSSNV \\\n      -I \\$PASSIND \\\n      -O $sampleID\".strelka2.snv_indel.pass.vcf\"\n\n  } 2>&1 | tee > $sampleID\".manta-strelka2.log.txt\"\n  \"\"\"",
        "nb_lignes_script": 63,
        "language_script": "bash",
        "tools": [
            "NextSV",
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/nextsv",
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "NextSV",
                "uri": "https://bio.tools/nextsv",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "Genomic structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3175",
                            "term": "DNA structural variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3228",
                                    "term": "Structural variation discovery"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A meta SV caller and a computational pipeline to perform SV calling from low coverage long-read sequencing data. It integrates three aligners and three SV callers and generates two integrated call sets (sensitive/stringent) for different analysis purpose.",
                "homepage": "http://github.com/Nextomics/NextSV"
            },
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "mantastrelka2ing"
        ],
        "nb_inputs": 1,
        "outputs": [
            "completed2_4",
            "strelka2_veping",
            "strelka2_rawVcf",
            "completedmantacall"
        ],
        "nb_outputs": 4,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/manta-strelka2\"",
            "publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*raw.vcf'"
        ],
        "when": "",
        "stub": ""
    },
    "lancet": {
        "name_process": "lancet",
        "string_process": "\nprocess lancet {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/lancet\"\n  publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*raw.vcf'\n\n  input:\n  tuple val(sampleID), file(tumourbam), file(tumourbai), val(germlineID), file(germlinebam), file(germlinebai) from lanceting\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  file(exomebed) from Channel.value(params.exomebed)\n\n  output:\n  file('*.pass.vcf') into lancet_veping mode flatten\n  file('*.raw.vcf') into lancet_rawVcf\n  file('*') into completedlancetcall\n\n  script:\n  \"\"\"\n  TUMOURVCF=\\$(echo $tumourbam | sed 's/bam/lancet.legacy.vcf/')\n  {\n    lancet \\\n      --num-threads ${task.cpus} \\\n      --ref $fasta \\\n      --bed $exomebed \\\n      --tumor $tumourbam \\\n      --normal $germlinebam | \\\n      perl -ane 'if(\\$F[0]=~m/^\\\\#CHROM/){\n        \\$_=~s/TUMOR/$sampleID/;\n        \\$_=~s/NORMAL/$germlineID/;\n        print \\$_;}\n      else{print \\$_;}' > \\$TUMOURVCF\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n      ID=$sampleID \\\n      DP=14 \\\n      MD=2 \\\n      VCF=\\$TUMOURVCF\n\n  } 2>&1 | tee > $sampleID\".lancet.log.txt\"\n\n  \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "  \"\"\"\n  TUMOURVCF=\\$(echo $tumourbam | sed 's/bam/lancet.legacy.vcf/')\n  {\n    lancet \\\n      --num-threads ${task.cpus} \\\n      --ref $fasta \\\n      --bed $exomebed \\\n      --tumor $tumourbam \\\n      --normal $germlinebam | \\\n      perl -ane 'if(\\$F[0]=~m/^\\\\#CHROM/){\n        \\$_=~s/TUMOR/$sampleID/;\n        \\$_=~s/NORMAL/$germlineID/;\n        print \\$_;}\n      else{print \\$_;}' > \\$TUMOURVCF\n\n    perl ${workflow.projectDir}/bin/filter_Lancet_Mutect2_Manta-Strelka2_Format.pl \\\n      ID=$sampleID \\\n      DP=14 \\\n      MD=2 \\\n      VCF=\\$TUMOURVCF\n\n  } 2>&1 | tee > $sampleID\".lancet.log.txt\"\n\n  \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "lanceting"
        ],
        "nb_inputs": 1,
        "outputs": [
            "lancet_veping",
            "lancet_rawVcf",
            "completedlancetcall"
        ],
        "nb_outputs": 3,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/lancet\"",
            "publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*raw.vcf'"
        ],
        "when": "",
        "stub": ""
    },
    "vepann": {
        "name_process": "vepann",
        "string_process": "\nprocess vepann {\n\n  publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*.vcf'\n\n  input:\n  each file(vcf) from ALLVCFS\n  set file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n  file(pcgr_grch_vep) from vepanndir\n\n  output:\n  file('*.vcf') into runGRanges\n\n  script:\n  \"\"\"\n  VCFANNO=\\$(echo $vcf | sed \"s/.vcf/.vep.vcf/\")\n  VEPVERS=\\$(ls $pcgr_grch_vep/homo_sapiens/ | cut -d \"_\" -f2)\n  vep --dir_cache $pcgr_grch_vep \\\n    --offline \\\n    --assembly \\$VEPVERS \\\n    --vcf_info_field ANN \\\n    --symbol \\\n    --species homo_sapiens \\\n    --check_existing \\\n    --cache \\\n    --fork ${task.cpus} \\\n    --af_1kg \\\n    --af_gnomad \\\n    --vcf \\\n    --input_file $vcf \\\n    --output_file \\$VCFANNO \\\n    --format \"vcf\" \\\n    --fasta $fasta \\\n    --hgvs \\\n    --canonical \\\n    --ccds \\\n    --force_overwrite \\\n    --verbose\n  \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "  \"\"\"\n  VCFANNO=\\$(echo $vcf | sed \"s/.vcf/.vep.vcf/\")\n  VEPVERS=\\$(ls $pcgr_grch_vep/homo_sapiens/ | cut -d \"_\" -f2)\n  vep --dir_cache $pcgr_grch_vep \\\n    --offline \\\n    --assembly \\$VEPVERS \\\n    --vcf_info_field ANN \\\n    --symbol \\\n    --species homo_sapiens \\\n    --check_existing \\\n    --cache \\\n    --fork ${task.cpus} \\\n    --af_1kg \\\n    --af_gnomad \\\n    --vcf \\\n    --input_file $vcf \\\n    --output_file \\$VCFANNO \\\n    --format \"vcf\" \\\n    --fasta $fasta \\\n    --hgvs \\\n    --canonical \\\n    --ccds \\\n    --force_overwrite \\\n    --verbose\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "fivepseq"
        ],
        "tools_url": [
            "https://bio.tools/fivepseq"
        ],
        "tools_dico": [
            {
                "name": "fivepseq",
                "uri": "https://bio.tools/fivepseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3563",
                                    "term": "RNA-seq read count analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Fivepseq is a software package for analysis of 5prime endpoints distribution in RNA sequencing datasets. This is particularly useful for techniques that capture 5prime  monophosphorylated RNAs, such as 5PSeq, PARE-seq or GMUC. It may also be useful for ribosome profiling datasets and alike.",
                "homepage": "http://pelechanolab.com/software/fivepseq"
            }
        ],
        "inputs": [
            "ALLVCFS",
            "vepanndir"
        ],
        "nb_inputs": 2,
        "outputs": [
            "runGRanges"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/output/vcf\", mode: \"copy\", pattern: '*.vcf'"
        ],
        "when": "",
        "stub": ""
    },
    "vcfGRa": {
        "name_process": "vcfGRa",
        "string_process": "\nprocess vcfGRa {\n\n  publishDir \"$params.outDir/output/pdf\", pattern: '*.pdf'\n  publishDir \"$params.outDir/output/vcf\", pattern: '*.vcf'\n  publishDir \"$params.outDir/output/data\", pattern: '*.[*RData,*tab]'\n\n  input:\n  file(grangesvcfs) from ALLVVCFS.collect()\n\n  output:\n  file('*.ALL.pcgr.all.tab.vcf') into pcgrvcfs\n  file('*') into completedvcfGRangesConsensus\n\n  script:\n  \"\"\"\n  Rscript --vanilla ${workflow.projectDir}/bin/variants_GRanges_consensus_plot.call.R \\\n    ${workflow.projectDir}/bin/variants_GRanges_consensus_plot.func.R \\\n    ${params.germlineID} \\\n    \"snv_indel.pass.vep.vcf\" \\\n    \\\"${params.includeOrder}\\\"\n  \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "  \"\"\"\n  Rscript --vanilla ${workflow.projectDir}/bin/variants_GRanges_consensus_plot.call.R \\\n    ${workflow.projectDir}/bin/variants_GRanges_consensus_plot.func.R \\\n    ${params.germlineID} \\\n    \"snv_indel.pass.vep.vcf\" \\\n    \\\"${params.includeOrder}\\\"\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ALLVVCFS"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcgrvcfs",
            "completedvcfGRangesConsensus"
        ],
        "nb_outputs": 2,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/output/pdf\", pattern: '*.pdf'",
            "publishDir \"$params.outDir/output/vcf\", pattern: '*.vcf'",
            "publishDir \"$params.outDir/output/data\", pattern: '*.[*RData,*tab]'"
        ],
        "when": "",
        "stub": ""
    },
    "pcgrVcf": {
        "name_process": "pcgrVcf",
        "string_process": "\nprocess pcgrVcf {\n\n  input:\n  file(vcf) from pcgrvcfs\n\n  output:\n  file('*snv_indel.pass.pcgr.vcf') into pcgrinput\n\n  script:\n  \"\"\"\n  for VCF in *vcf; do\n    NVCF=\\$(echo \\$VCF | sed 's/ALL.pcgr.all.tab.vcf/snv_indel.pass.pcgr.vcf/')\n    cat ${workflow.projectDir}/bin/vcf42.head.txt > \\$NVCF\n    head -n1 \\$VCF >> \\$NVCF\n    tail -n+2 \\$VCF | sort -V >> \\$NVCF\n  done\n  \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  for VCF in *vcf; do\n    NVCF=\\$(echo \\$VCF | sed 's/ALL.pcgr.all.tab.vcf/snv_indel.pass.pcgr.vcf/')\n    cat ${workflow.projectDir}/bin/vcf42.head.txt > \\$NVCF\n    head -n1 \\$VCF >> \\$NVCF\n    tail -n+2 \\$VCF | sort -V >> \\$NVCF\n  done\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "pcgrvcfs"
        ],
        "nb_inputs": 1,
        "outputs": [
            "pcgrinput"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "pcgrreport": {
        "name_process": "pcgrreport",
        "string_process": "\nprocess pcgrreport {\n\n  publishDir \"$params.outDir/reports\", mode: \"copy\", pattern: \"*html\"\n  publishDir \"$params.outDir/output/pcgr\", mode: \"copy\", pattern: \"*[!.html]\"\n\n  input:\n  file(pcgrinput) from varl_called\n                                                \n  file(pcgr_grch) from PCGR\n  file(pcgrmeta) from pcgrMetaInput\n  val(grchvers) from pcgr_grchvers\n\n  output:\n  file('*') into completedPCGR\n\n  script:\n  \"\"\"\n  {\n    for VCF in *vcf; do\n      SAMPLEID=\\$(echo \\$VCF | cut -d \".\" -f 1)\n      METAID=\\$(grep \\$SAMPLEID $pcgrmeta | cut -d \",\" -f 3 | sed 's/\\\\s */_/g')\n\n      ##set up tumour ploidy (from facets)\n      PLOIDY=\\$(cut -f 1 \\$SAMPLEID\".fit_ploidy-purity.pcgr.tsv\")\n      PURITY=\\$(cut -f 2 \\$SAMPLEID\".fit_ploidy-purity.pcgr.tsv\")\n      PP=\"--tumor_ploidy \\$PLOIDY --tumor_purity \\$PURITY\"\n      FACETI=\\$SAMPLEID\".cncf-jointsegs.pcgr.tsv\"\n\n      if [[ \\$PLOIDY == \"NA\" || \\$PURITY == \"NA\" ]]; then\n        PP=\"\"\n      fi\n\n      if [[ -e \\$FACETI ]]; then\n        FPP=\"--input_cna \\$FACETI \\$PP\"\n      else\n        FPP=\"\\$PP\"\n      fi\n\n      CONFIG=\\$(readlink -e pcgr/data/*/pcgr_configuration_default.toml)\n      pcgr.py $pcgr_grch \\\n        ./ \\\n        $grchvers \\\n        \\$CONFIG \\\n        \\$METAID \\\n        --input_vcf \\$VCF \\$FPP \\\n        --no-docker \\\n        --force_overwrite\n    done\n  } 2>&1 | tee pcgr.log.txt\n  \"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "  \"\"\"\n  {\n    for VCF in *vcf; do\n      SAMPLEID=\\$(echo \\$VCF | cut -d \".\" -f 1)\n      METAID=\\$(grep \\$SAMPLEID $pcgrmeta | cut -d \",\" -f 3 | sed 's/\\\\s */_/g')\n\n      ##set up tumour ploidy (from facets)\n      PLOIDY=\\$(cut -f 1 \\$SAMPLEID\".fit_ploidy-purity.pcgr.tsv\")\n      PURITY=\\$(cut -f 2 \\$SAMPLEID\".fit_ploidy-purity.pcgr.tsv\")\n      PP=\"--tumor_ploidy \\$PLOIDY --tumor_purity \\$PURITY\"\n      FACETI=\\$SAMPLEID\".cncf-jointsegs.pcgr.tsv\"\n\n      if [[ \\$PLOIDY == \"NA\" || \\$PURITY == \"NA\" ]]; then\n        PP=\"\"\n      fi\n\n      if [[ -e \\$FACETI ]]; then\n        FPP=\"--input_cna \\$FACETI \\$PP\"\n      else\n        FPP=\"\\$PP\"\n      fi\n\n      CONFIG=\\$(readlink -e pcgr/data/*/pcgr_configuration_default.toml)\n      pcgr.py $pcgr_grch \\\n        ./ \\\n        $grchvers \\\n        \\$CONFIG \\\n        \\$METAID \\\n        --input_vcf \\$VCF \\$FPP \\\n        --no-docker \\\n        --force_overwrite\n    done\n  } 2>&1 | tee pcgr.log.txt\n  \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "varl_called",
            "PCGR",
            "pcgrMetaInput",
            "pcgr_grchvers"
        ],
        "nb_inputs": 4,
        "outputs": [
            "completedPCGR"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir \"$params.outDir/reports\", mode: \"copy\", pattern: \"*html\"",
            "publishDir \"$params.outDir/output/pcgr\", mode: \"copy\", pattern: \"*[!.html]\""
        ],
        "when": "",
        "stub": ""
    },
    "mltiQC": {
        "name_process": "mltiQC",
        "string_process": "\nprocess mltiQC {\n\n  publishDir path: \"$params.outDir/reports\", mode: \"copy\", pattern: \"*html\"\n\n  input:\n  file(fastps) from fastp_multiqc.collect()\n  file(fastqcs) from fastqc_multiqc.collect()\n  file(gtkrcls) from gtkrcl_multiqc.collect()\n  file(multimetrics) from multimetrics_multiqc.collect()\n  file(mrkdups) from mrkdup_multiqc.collect()\n\n  output:\n  file('*') into completedmultiqc\n\n  script:\n  \"\"\"\n  OUTID=\\$(basename ${workflow.launchDir})\n  if [[ -e ${params.multiqcConfig} ]]; then\n    multiqc . -i \\$OUTID --tag DNA -f -c ${params.multiqcConfig}\n  else\n    multiqc . -i \\$OUTID --tag DNA -f\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "  \"\"\"\n  OUTID=\\$(basename ${workflow.launchDir})\n  if [[ -e ${params.multiqcConfig} ]]; then\n    multiqc . -i \\$OUTID --tag DNA -f -c ${params.multiqcConfig}\n  else\n    multiqc . -i \\$OUTID --tag DNA -f\n  fi\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastp_multiqc",
            "fastqc_multiqc",
            "gtkrcl_multiqc",
            "multimetrics_multiqc",
            "mrkdup_multiqc"
        ],
        "nb_inputs": 5,
        "outputs": [
            "completedmultiqc"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/reports\", mode: \"copy\", pattern: \"*html\""
        ],
        "when": "",
        "stub": ""
    },
    "varl_candidates": {
        "name_process": "varl_candidates",
        "string_process": "\nprocess varl_candidates {\n\n  publishDir path: \"$params.outDir/outputs/vcf/varlociraptor\", mode: \"copy\"\n\n  input:\n  file(vcf) from ALLVCFS.collect()\n  tuple val(germlineID), file(germlinebam), file(germlinebai) from germbamcand\n\n  output:\n  file(\"candidates.vcf\") into varlpreproccand\n\n  script:\n  \"\"\"\n  echo \"##fileformat=VCFv4.1\" > \"candidates.vcf\"\n  samtools view -H $germlinebam | grep @SQ | while read LINE; do\n    CHR=\\$(echo \\$LINE | perl -ane '\\$F[1]=~s/SN://; print \\$F[1];')\n    LEN=\\$(echo \\$LINE | perl -ane '\\$F[2]=~s/LN://; print \\$F[2];')\n    echo \"##contig=<ID=\\${CHR},length=\\${LEN}>\"\n  done >> \"candidates.vcf\"\n  echo -e \"#CHROM\\\\tPOS\\\\tREF\\\\tALT\" >> \"candidates.vcf\"\n  for VCF in *.vcf; do\n    grep -v '#' \\$VCF | cut -f 1,2,4,5;\n  done | sort -V | uniq >> \"candidates.vcf\"\n  \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "  \"\"\"\n  echo \"##fileformat=VCFv4.1\" > \"candidates.vcf\"\n  samtools view -H $germlinebam | grep @SQ | while read LINE; do\n    CHR=\\$(echo \\$LINE | perl -ane '\\$F[1]=~s/SN://; print \\$F[1];')\n    LEN=\\$(echo \\$LINE | perl -ane '\\$F[2]=~s/LN://; print \\$F[2];')\n    echo \"##contig=<ID=\\${CHR},length=\\${LEN}>\"\n  done >> \"candidates.vcf\"\n  echo -e \"#CHROM\\\\tPOS\\\\tREF\\\\tALT\" >> \"candidates.vcf\"\n  for VCF in *.vcf; do\n    grep -v '#' \\$VCF | cut -f 1,2,4,5;\n  done | sort -V | uniq >> \"candidates.vcf\"\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ALLVCFS",
            "germbamcand"
        ],
        "nb_inputs": 2,
        "outputs": [
            "varlpreproccand"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/outputs/vcf/varlociraptor\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "varl_preproc": {
        "name_process": "varl_preproc",
        "string_process": "\nprocess varl_preproc {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/varlociraptor\", mode: \"copy\"\n\n  input:\n  tuple val(type), val(sampleID), file(bam), file(bai) from varlpreproc\n  each file(candvcf) from varlpreproccand\n  tuple file(fasta), file(fai), file(dict) from Channel.value([params.fasta, params.fai, params.dict])\n\n  output:\n  file('*.observations.vcf') into varlcalling\n\n  script:\n  \"\"\"\n  varlociraptor preprocess variants $fasta \\\n    --bam $bam \\\n    --output $sampleID\".observations.vcf\" < $candvcf\n\n  \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  varlociraptor preprocess variants $fasta \\\n    --bam $bam \\\n    --output $sampleID\".observations.vcf\" < $candvcf\n\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "varlociraptor"
        ],
        "tools_url": [
            "https://bio.tools/varlociraptor"
        ],
        "tools_dico": [
            {
                "name": "varlociraptor",
                "uri": "https://bio.tools/varlociraptor",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3675",
                                    "term": "Variant filtering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Indel discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0452",
                                    "term": "Sequence alignment analysis (indel detection)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Enhancing sensitivity and controlling false discovery rate in somatic indel discovery | Varlociraptor is a flexible, uncertainty-aware variant calling framework with parameter free filtration via FDR control",
                "homepage": "https://varlociraptor.github.io"
            }
        ],
        "inputs": [
            "varlpreproc",
            "varlpreproccand"
        ],
        "nb_inputs": 2,
        "outputs": [
            "varlcalling"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/varlociraptor\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "varl_call": {
        "name_process": "varl_call",
        "string_process": "\nprocess varl_call {\n\n  publishDir path: \"$params.outDir/samples/$sampleID/varlociraptor\", mode: \"copy\"\n\n  input:\n  file(vcf) from varlcalling.collect()\n\n  output:\n  file('cons.calls.bcf') into varl_called\n\n  script:\n  \"\"\"\n  ##create YAML scenario, shell to execute scenario\n  perl ${workflow.projectDir}/bin/varlociraptor_call_yaml.pl \\\n    ${params.germlineID} > varlociraptor_call.yaml\n\n  ##run call made in above #customPerl script\n  sh varlociraptor_scenario_call.sh\n  \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  ##create YAML scenario, shell to execute scenario\n  perl ${workflow.projectDir}/bin/varlociraptor_call_yaml.pl \\\n    ${params.germlineID} > varlociraptor_call.yaml\n\n  ##run call made in above #customPerl script\n  sh varlociraptor_scenario_call.sh\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "RASH"
        ],
        "tools_url": [
            "https://bio.tools/RASH"
        ],
        "tools_dico": [
            {
                "name": "RASH",
                "uri": "https://bio.tools/RASH",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0089",
                            "term": "Ontology and terminology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature and language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Language"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3068",
                            "term": "Literature"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3778",
                                    "term": "Text annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "a Web-first format for HTML-based scholarly articles.\n\nResearch Articles in Simplified HTML (RASH) Framework includes a markup language defined as a subset of HTML+RDF for writing scientific articles, and related tools to convert it into different formats, to extract data from it, etc.\n\nHow to cite: Peroni, S., Osborne, F., Di Iorio, A., Nuzzolese, A. G., Poggi, F., Vitali, F., Motta, E. (2017). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ Computer Science 3: e132. e2513. DOI: https://doi.org/10.7717/peerj-cs.132.\n\n# rash-check.sh - fully check RASH documents.\n\nThe odt2rash.jar executable converts an ODT file into the RASH format.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Research Articles Simplified HTML', 'SAVE-SD'",
                "homepage": "https://w3id.org/people/essepuntato/papers/rash-peerj2016.html"
            }
        ],
        "inputs": [
            "varlcalling"
        ],
        "nb_inputs": 1,
        "outputs": [
            "varl_called"
        ],
        "nb_outputs": 1,
        "name_workflow": "cgpu__somatic_exome_n-of-1",
        "directive": [
            "publishDir path: \"$params.outDir/samples/$sampleID/varlociraptor\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    }
}