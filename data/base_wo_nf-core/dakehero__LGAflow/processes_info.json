{
    "hisat2index": {
        "name_process": "hisat2index",
        "string_process": "process hisat2index {\n    label 'hisat2'\n    input:\n    path(ref_genome)\n\n    output:\n    path \"${ref_genome.baseName}*.ht2\"\n\n    script:\n    \"\"\"\n    hisat2-build -p ${task.cpus} ${ref_genome} ${ref_genome.baseName}\n    \"\"\"\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    hisat2-build -p ${task.cpus} ${ref_genome} ${ref_genome.baseName}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ref_genome"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'hisat2'"
        ],
        "when": "",
        "stub": ""
    },
    "hisat2": {
        "name_process": "hisat2",
        "string_process": "\nprocess hisat2 {\n    label 'hisat2'\n    publishDir \"${params.output}/${params.hisat2_dir}\", mode: 'copy', pattern: \"*.sorted.bam\"\n\n    input:\n    val(sample_name)\n    path(reads)\n    path(reference)\n    path(index)\n\n    output:\n    path \"${sample_name}.sorted.bam\", emit: sample_bam \n    path \"${sample_name}_summary.log\", emit: log\n\n    script:\n    \"\"\"\n    hisat2 -x ${reference.baseName} -1 ${reads[0]} -2 ${reads[1]} -p ${task.cpus} --new-summary --summary-file ${sample_name}_summary.log | samtools view -bS | samtools sort -o ${sample_name}.sorted.bam -T tmp --threads ${task.cpus}\n    \"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    hisat2 -x ${reference.baseName} -1 ${reads[0]} -2 ${reads[1]} -p ${task.cpus} --new-summary --summary-file ${sample_name}_summary.log | samtools view -bS | samtools sort -o ${sample_name}.sorted.bam -T tmp --threads ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "HISAT2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/hisat2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "HISAT2",
                "uri": "https://bio.tools/hisat2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).",
                "homepage": "https://ccb.jhu.edu/software/hisat2/index.shtml"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_name",
            "reads",
            "reference",
            "index"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'hisat2'",
            "publishDir \"${params.output}/${params.hisat2_dir}\", mode: 'copy', pattern: \"*.sorted.bam\""
        ],
        "when": "",
        "stub": ""
    },
    "index_bam": {
        "name_process": "index_bam",
        "string_process": "\nprocess index_bam {\n    label 'samtools'\n    label 'smallTask'\n    \n    publishDir \"${params.output}/${params.hisat2_dir}\", mode: 'copy', pattern: \"*.bai\"\n\n    input:\n    tuple val(sample_name), path(bam_file)\n\n    output:\n    path(\"${bam_file}.bai\")\n\n    script:\n    \"\"\"\n    samtools index ${bam_file}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    samtools index ${bam_file}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample_name",
            "bam_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'samtools'",
            "label 'smallTask'",
            "publishDir \"${params.output}/${params.hisat2_dir}\", mode: 'copy', pattern: \"*.bai\""
        ],
        "when": "",
        "stub": ""
    },
    "seqkit_to_uppercase": {
        "name_process": "seqkit_to_uppercase",
        "string_process": "process seqkit_to_uppercase {\n    label 'seqkit'\n    publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(fasta_lowercase)\n\n    output:\n    path \"*_uppercase.fa\"\n    \n    \"\"\"\n    seqkit seq -u ${fasta_lowercase} ${params.seqkit_additional_params} > ${fasta_lowercase.simpleName}_uppercase.fa\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "\"\"\"\n    seqkit seq -u ${fasta_lowercase} ${params.seqkit_additional_params} > ${fasta_lowercase.simpleName}_uppercase.fa\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_lowercase"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'seqkit'",
            "publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "seqkit_to_singleline": {
        "name_process": "seqkit_to_singleline",
        "string_process": "\nprocess seqkit_to_singleline {\n    label 'seqkit'\n    publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(fasta_multiline)\n    \n    output:\n    path \"*_singleline.fa\"\n    \n    \"\"\"\n    seqkit seq ${fasta_multiline} -w 0 ${params.seqkit_additional_params} > ${fasta_multiline.simpleName}_singleline.fa\n    \"\"\"\n\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\n    seqkit seq ${fasta_multiline} -w 0 ${params.seqkit_additional_params} > ${fasta_multiline.simpleName}_singleline.fa\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_multiline"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'seqkit'",
            "publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "seqkit_length_filter": {
        "name_process": "seqkit_length_filter",
        "string_process": "\nprocess seqkit_length_filter {\n    label 'seqkit'\n    publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(fasta)\n    \n    output:\n    path \"*_filted.fa\"\n\n    \"\"\"\n    seqkit seq ${fasta} -m 500 -g ${params.seqkit_additional_params} > ${fasta.simpleName}_filted.fa\n    \"\"\"\n\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\n    seqkit seq ${fasta} -m 500 -g ${params.seqkit_additional_params} > ${fasta.simpleName}_filted.fa\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'seqkit'",
            "publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "seqkit_sliding_trimming": {
        "name_process": "seqkit_sliding_trimming",
        "string_process": "\nprocess seqkit_sliding_trimming {\n    label 'seqkit'\n    publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(fasta)\n\n    output:\n    path '*_trimmed.fa'\n\n    \"\"\"\n    seqkit sliding -g -s 900000 -W 1000000 ${params.seqkit_additional_params} ${fasta} | seqkit seq -w 0 ${params.seqkit_additional_params} > ${fasta.simpleName}_trimmed.fa\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"\n    seqkit sliding -g -s 900000 -W 1000000 ${params.seqkit_additional_params} ${fasta} | seqkit seq -w 0 ${params.seqkit_additional_params} > ${fasta.simpleName}_trimmed.fa\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'seqkit'",
            "publishDir \"${params.output}/${params.seqkit_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "cdhit": {
        "name_process": "cdhit",
        "string_process": "process  cdhit{\n    label cdhit\n    \n    publishDir \"${params.output}/${params.cdhit_dir}\", mode: 'copy', pattern: \"merged_prot.fa\"\n\n    input:\n    path(proteins)\n\n    output:\n    path 'merged_prot.fa'\n\n    script:\n    MEM=task.memory * 1000\n    \"\"\"\n    cat ${proteins} > all.fa\n    cd-hit -i all.fa -o merged_prot.fa -T ${task.cpus} -M ${MEM} ${params.cdhit_additional_params} \n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    MEM=task.memory * 1000\n    \"\"\"\n    cat ${proteins} > all.fa\n    cd-hit -i all.fa -o merged_prot.fa -T ${task.cpus} -M ${MEM} ${params.cdhit_additional_params} \n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "cd-hit"
        ],
        "tools_url": [
            "https://bio.tools/cd-hit"
        ],
        "tools_dico": [
            {
                "name": "cd-hit",
                "uri": "https://bio.tools/cd-hit",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ]
                    }
                ],
                "description": "Cluster a nucleotide dataset into representative sequences.",
                "homepage": "https://github.com/weizhongli/cdhit"
            }
        ],
        "inputs": [
            "proteins"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label cdhit",
            "publishDir \"${params.output}/${params.cdhit_dir}\", mode: 'copy', pattern: \"merged_prot.fa\""
        ],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "process fastqc {\n    label 'fastqc'\n\n    input:\n    path(reads) \n\n    output:\n    path \"*_fastqc.zip\", emit: zip\n\n    script:\n    \"\"\"\n    fastqc --noextract -t ${task.cpus} ${reads}\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n    fastqc --noextract -t ${task.cpus} ${reads}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "reads"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'fastqc'"
        ],
        "when": "",
        "stub": ""
    },
    "busco": {
        "name_process": "busco",
        "string_process": "process busco {\n    label 'busco'\n   \n    publishDir \"${params.output}/${params.busco_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(fasta)\n    path(busco_db)\n    path(ausgutus_config)\n    val(sepecies_name)\n    val(augustus_species)\n    \n    output:\n    path \"BUSCO_${sepecies_name}*\", emit:busco_model\n\n    script:\n    if (params.useConda) {\n        run_busco = 'run_busco'\n    } else {\n        run_busco = 'run_BUSCO.py'\n    }\n    \"\"\"\n    export AUGUSTUS_CONFIG_PATH=${ausgutus_config} && \\\n    ${run_busco} -i ${fasta} -o ${sepecies_name} -l ${busco_db} --long -m geno --species ${augustus_species} \\\n    -c ${task.cpus} ${params.busco_additional_params} && \\\n    unset AUGUSTUS_CONIF_PATH\n    MODELNAME=`ls run_c_elegans_trsk/augustus_output/retraining_parameters/ | sed -n 's/_weightmatrix.txt//p'`\n    mkdir \\$MODELNAME && \\\n    cp run_${sepecies_name}/augustus_output/retraining_parameters/* ./\\$MODELNAME\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    if (params.useConda) {\n        run_busco = 'run_busco'\n    } else {\n        run_busco = 'run_BUSCO.py'\n    }\n    \"\"\"\n    export AUGUSTUS_CONFIG_PATH=${ausgutus_config} && \\\n    ${run_busco} -i ${fasta} -o ${sepecies_name} -l ${busco_db} --long -m geno --species ${augustus_species} \\\n    -c ${task.cpus} ${params.busco_additional_params} && \\\n    unset AUGUSTUS_CONIF_PATH\n    MODELNAME=`ls run_c_elegans_trsk/augustus_output/retraining_parameters/ | sed -n 's/_weightmatrix.txt//p'`\n    mkdir \\$MODELNAME && \\\n    cp run_${sepecies_name}/augustus_output/retraining_parameters/* ./\\$MODELNAME\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "busco_db",
            "ausgutus_config",
            "sepecies_name",
            "augustus_species"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'busco'",
            "publishDir \"${params.output}/${params.busco_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "busco_get_model_name": {
        "name_process": "busco_get_model_name",
        "string_process": "\nprocess busco_get_model_name {\n    label 'smalljobs'\n    input:\n    path(model_path)\n\n    output:\n    val(model_name)\n\n    script:\n    model_name = file(\"${model_path}\").getName()\n    \"\"\"\n    ls ${model_path}\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    model_name = file(\"${model_path}\").getName()\n    \"\"\"\n    ls ${model_path}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "model_path"
        ],
        "nb_inputs": 1,
        "outputs": [
            "model_name"
        ],
        "nb_outputs": 1,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'"
        ],
        "when": "",
        "stub": ""
    },
    "run_evm": {
        "name_process": "run_evm",
        "string_process": "process run_evm{\n    label 'evm'\n    cpus 1\n\n    input:\n    path(command)\n\n    output:\n    path 'evm_*.log'\n\n    shell:\n    '''\n    RUN_ID=$(pwd | awk -F/ '{print $NF}')\n    $EVM_HOME/EvmUtils/execute_EVM_commands.pl !{command} > evm_${RUN_ID}.log\n    '''\n}",
        "nb_lignes_process": 14,
        "string_script": "    '''\n    RUN_ID=$(pwd | awk -F/ '{print $NF}')\n    $EVM_HOME/EvmUtils/execute_EVM_commands.pl !{command} > evm_${RUN_ID}.log\n    '''",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "command"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'evm'",
            "cpus 1"
        ],
        "when": "",
        "stub": ""
    },
    "evm_partition": {
        "name_process": "evm_partition",
        "string_process": "\nprocess evm_partition {\n    label 'evm'\n    publishDir \"${params.output}/${params.evidencemodeler_dir}\", mode: 'copy', pattern: \"*\"\n    \n    input:\n    path(genome_file)\n    path(de_novo_gff)\n    path(protein_gff)\n    path(transcript_gff)\n    path(weights)\n    val(segment_size)\n    val(overlap_size)\n\n    output:\n    path 'partitions_list.out', emit:partition_list\n    path 'commands_list.out', emit:commands_list\n\n    script:\n\n    gene_predictions = \"--gene_predictions ${de_novo_gff}\"\n    transcript_alignments = \"--transcript_alignments ${transcript_gff}\"\n    protein_alignments = \"--protein_alignments ${protein_gff}\"\n\n    \"\"\"\n    \\$EVM_HOME/EvmUtils/partition_EVM_inputs.pl --genome ${genome_file} ${gene_predictions} ${transcript_alignments} ${protein_alignments} --segmentSize ${segment_size} --overlapSize ${overlap_size} --partition_listing partitions_list.out\n    \\$EVM_HOME/EvmUtils/write_EVM_commands.pl --genome ${genome_file} ${gene_predictions} ${transcript_alignments} ${protein_alignments}  --weights `pwd`/${weights} --partitions partitions_list.out --output_file_name evm.out > commands_list.out\n    \"\"\"\n\n}",
        "nb_lignes_process": 28,
        "string_script": "    gene_predictions = \"--gene_predictions ${de_novo_gff}\"\n    transcript_alignments = \"--transcript_alignments ${transcript_gff}\"\n    protein_alignments = \"--protein_alignments ${protein_gff}\"\n\n    \"\"\"\n    \\$EVM_HOME/EvmUtils/partition_EVM_inputs.pl --genome ${genome_file} ${gene_predictions} ${transcript_alignments} ${protein_alignments} --segmentSize ${segment_size} --overlapSize ${overlap_size} --partition_listing partitions_list.out\n    \\$EVM_HOME/EvmUtils/write_EVM_commands.pl --genome ${genome_file} ${gene_predictions} ${transcript_alignments} ${protein_alignments}  --weights `pwd`/${weights} --partitions partitions_list.out --output_file_name evm.out > commands_list.out\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_file",
            "de_novo_gff",
            "protein_gff",
            "transcript_gff",
            "weights",
            "segment_size",
            "overlap_size"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'evm'",
            "publishDir \"${params.output}/${params.evidencemodeler_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "evm_convert_and_merge_result": {
        "name_process": "evm_convert_and_merge_result",
        "string_process": "\nprocess evm_convert_and_merge_result {\n    label 'evm'\n    publishDir \"${params.output}/${params.evidencemodeler_dir}\", mode: 'copy'\n\n    input:\n    path(genome_file)\n    path(partition)\n    path(results)\n    path(merge_evm_gff_script)\n\n    output:\n    path 'evm.out.gff'\n\n    script:\n    \"\"\"\n    \\$EVM_HOME/EvmUtils/recombine_EVM_partial_outputs.pl --partitions ${partition} --output_file_name evm.out\n    \\$EVM_HOME/EvmUtils/convert_EVM_outputs_to_GFF3.pl  --partitions ${partition} --output evm.out  --genome ${genome_file}\n    perl ${merge_evm_gff_script} --partitions ${partition} --gff evm.out.gff\n    \"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    \\$EVM_HOME/EvmUtils/recombine_EVM_partial_outputs.pl --partitions ${partition} --output_file_name evm.out\n    \\$EVM_HOME/EvmUtils/convert_EVM_outputs_to_GFF3.pl  --partitions ${partition} --output evm.out  --genome ${genome_file}\n    perl ${merge_evm_gff_script} --partitions ${partition} --gff evm.out.gff\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "genome_file",
            "partition",
            "results",
            "merge_evm_gff_script"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'evm'",
            "publishDir \"${params.output}/${params.evidencemodeler_dir}\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "augustus_to_evm": {
        "name_process": "augustus_to_evm",
        "string_process": "\nprocess augustus_to_evm {\n    label 'evm'\n    publishDir \"${params.output}/${params.augustus_dir}\", pattern: \"*\", mode: \"copy\"\n\n    input:\n    path(augustus_out_gff)\n    path(relocate_script)\n\n    output:\n    path \"*.fa.augustus_out.convertd.gff\"\n\n    script:\n    \n    \"\"\"\n    \\$EVM_HOME/EvmUtils/misc/augustus_GTF_to_EVM_GFF3.pl ${augustus_out_gff} | awk -f ${relocate_script} > ${augustus_out_gff.simpleName}.fa.augustus_out.convertd.gff\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    \\$EVM_HOME/EvmUtils/misc/augustus_GTF_to_EVM_GFF3.pl ${augustus_out_gff} | awk -f ${relocate_script} > ${augustus_out_gff.simpleName}.fa.augustus_out.convertd.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "augustus_out_gff",
            "relocate_script"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'evm'",
            "publishDir \"${params.output}/${params.augustus_dir}\", pattern: \"*\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "exonerate_to_evm": {
        "name_process": "exonerate_to_evm",
        "string_process": "\nprocess exonerate_to_evm {\n    label 'evm'\n    publishDir \"${params.output}/${params.augustus_dir}\", pattern: \"*\", mode: \"copy\"\n\n    input:\n    path(exonerate_out_gff)\n    path(relocate_script)\n\n    output:\n    path \"*.fa.exonerate_out.convertd.gff\"\n\n    script:\n    \n    \"\"\"\n    \\$EVM_HOME/EvmUtils/misc/exonerate_gff_to_alignment_gff3.pl ${exonerate_out_gff} | awk -f ${relocate_script} > ${exonerate_out_gff.simpleName}.fa.exonerate_out.convertd.gff\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    \\$EVM_HOME/EvmUtils/misc/exonerate_gff_to_alignment_gff3.pl ${exonerate_out_gff} | awk -f ${relocate_script} > ${exonerate_out_gff.simpleName}.fa.exonerate_out.convertd.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "exonerate_out_gff",
            "relocate_script"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'evm'",
            "publishDir \"${params.output}/${params.augustus_dir}\", pattern: \"*\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "evm_merge_input": {
        "name_process": "evm_merge_input",
        "string_process": "\nprocess evm_merge_input {\n    label 'smalljob'\n\n    input:\n    path(de_novo_gff)\n    path(transdecoder_gff)\n\n    output:\n    path 'gene_pred.gff'\n\n    script:\n    \"\"\"\n    cat ${de_novo_gff} ${transdecoder_gff} > gene_pred.gff\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    cat ${de_novo_gff} ${transdecoder_gff} > gene_pred.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "de_novo_gff",
            "transdecoder_gff"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljob'"
        ],
        "when": "",
        "stub": ""
    },
    "build_database": {
        "name_process": "build_database",
        "string_process": "process build_database {\n    label 'repeatmodeler'\n    publishDir \"${params.output}/${params.repeatmodeler_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(genome_file)\n    val(db_name)\n    val(engine)\n\n    output:\n    path \"RM_*/consensi.fa.classified\", emit: model\n\n    script:\n    parallel = task.cpus / 4\n    \"\"\"\n    BuildDatabase -name ${db_name} ${genome_file}\n    RepeatModeler -pa ${parallel} -database ${db_name}\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    parallel = task.cpus / 4\n    \"\"\"\n    BuildDatabase -name ${db_name} ${genome_file}\n    RepeatModeler -pa ${parallel} -database ${db_name}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "parallelGWAS",
            "RepeatModeler"
        ],
        "tools_url": [
            "https://bio.tools/parallelgwas",
            "https://bio.tools/RepeatModeler2"
        ],
        "tools_dico": [
            {
                "name": "parallelGWAS",
                "uri": "https://bio.tools/parallelgwas",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Developing parallel computing tools for genome-wide association studies.",
                "homepage": "https://en.osdn.jp/projects/parallelgwas/"
            },
            {
                "name": "RepeatModeler",
                "uri": "https://bio.tools/RepeatModeler2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0157",
                            "term": "Sequence composition, complexity and repeats"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0798",
                            "term": "Mobile genetic elements"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3644",
                                    "term": "de Novo sequencing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "RepeatModeler is a de novo transposable element (TE) family identification and modeling package. At the heart of RepeatModeler are three de-novo repeat finding programs ( RECON, RepeatScout and LtrHarvest/Ltr_retriever ) which employ complementary computational methods for identifying repeat element boundaries and family relationships from sequence data.",
                "homepage": "https://github.com/Dfam-consortium/RepeatModeler"
            }
        ],
        "inputs": [
            "genome_file",
            "db_name",
            "engine"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'repeatmodeler'",
            "publishDir \"${params.output}/${params.repeatmodeler_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "repeatmasker": {
        "name_process": "repeatmasker",
        "string_process": "\nprocess repeatmasker {\n    label 'repeatmasker'\n\n    publishDir \"${params.output}/${params.repeatmasker_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(genome_file)\n    val(species)\n    val(engine)                           \n\n    output:\n    path \"*.fa.out.gff\", emit: mask_gff\n    path \"*.out\", emit: results\n    path \"*.tbl\", emit: tbl_file\n\n    script: \n    parallel = task.cpus / 4\n    \"\"\"\n    RepeatMasker -pa ${parallel} -e ${engine} -species '${species}' -gff -dir . ${params.repeatmasker_additional_params} ${genome_file}\n    mv ${genome_file.name}.out.gff ${genome_file.simpleName}_masker.fa.out.gff\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    parallel = task.cpus / 4\n    \"\"\"\n    RepeatMasker -pa ${parallel} -e ${engine} -species '${species}' -gff -dir . ${params.repeatmasker_additional_params} ${genome_file}\n    mv ${genome_file.name}.out.gff ${genome_file.simpleName}_masker.fa.out.gff\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "parallelGWAS",
            "RepeatMasker"
        ],
        "tools_url": [
            "https://bio.tools/parallelgwas",
            "https://bio.tools/repeatmasker"
        ],
        "tools_dico": [
            {
                "name": "parallelGWAS",
                "uri": "https://bio.tools/parallelgwas",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Developing parallel computing tools for genome-wide association studies.",
                "homepage": "https://en.osdn.jp/projects/parallelgwas/"
            },
            {
                "name": "RepeatMasker",
                "uri": "https://bio.tools/repeatmasker",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0157",
                            "term": "Sequence composition, complexity and repeats"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A program that screens DNA sequences for interspersed repeats and low complexity DNA sequences. The output of the program is a detailed annotation of the repeats that are present in the query sequence as well as a modified version of the query sequence in which all the annotated repeats have been masked (default: replaced by Ns).",
                "homepage": "http://www.repeatmasker.org/"
            }
        ],
        "inputs": [
            "genome_file",
            "species",
            "engine"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'repeatmasker'",
            "publishDir \"${params.output}/${params.repeatmasker_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "repeatmodeler": {
        "name_process": "repeatmodeler",
        "string_process": "\nprocess repeatmodeler {\n    label 'repeatmasker'\n\n    publishDir \"${params.output}/${params.repeatmodeler_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(genome_file)\n    path(model)\n    val(engine)                           \n\n    output:\n    path \"*.fa.out.gff\", emit: mask_gff\n    path \"*.out\", emit: results\n    path \"*.tbl\", emit: tbl_file\n\n    script:\n    parallel = task.cpus / 4\n    \"\"\"\n    RepeatMasker -pa ${parallel} -e ${engine} -lib ${model} -gff -dir . ${params.repeatmasker_additional_params} ${genome_file}\n    mv ${genome_file.name}.out.gff ${genome_file.simpleName}_modeler.fa.out.gff\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    parallel = task.cpus / 4\n    \"\"\"\n    RepeatMasker -pa ${parallel} -e ${engine} -lib ${model} -gff -dir . ${params.repeatmasker_additional_params} ${genome_file}\n    mv ${genome_file.name}.out.gff ${genome_file.simpleName}_modeler.fa.out.gff\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "parallelGWAS",
            "RepeatMasker"
        ],
        "tools_url": [
            "https://bio.tools/parallelgwas",
            "https://bio.tools/repeatmasker"
        ],
        "tools_dico": [
            {
                "name": "parallelGWAS",
                "uri": "https://bio.tools/parallelgwas",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Developing parallel computing tools for genome-wide association studies.",
                "homepage": "https://en.osdn.jp/projects/parallelgwas/"
            },
            {
                "name": "RepeatMasker",
                "uri": "https://bio.tools/repeatmasker",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0157",
                            "term": "Sequence composition, complexity and repeats"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A program that screens DNA sequences for interspersed repeats and low complexity DNA sequences. The output of the program is a detailed annotation of the repeats that are present in the query sequence as well as a modified version of the query sequence in which all the annotated repeats have been masked (default: replaced by Ns).",
                "homepage": "http://www.repeatmasker.org/"
            }
        ],
        "inputs": [
            "genome_file",
            "model",
            "engine"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'repeatmasker'",
            "publishDir \"${params.output}/${params.repeatmodeler_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "repeatproteinmasker": {
        "name_process": "repeatproteinmasker",
        "string_process": "\nprocess repeatproteinmasker {\n    label 'repeat'\n\n    publishDir \"${params.output}/${params.repeatproteinmasker_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(genome_file)\n    val(engine)\n\n    output:\n    path \"*.fa.out.gff\", emit: mask_gff\n    path \"*.out\", emit: results\n    path \"*.tbl\", emit: tbl_file\n\n    script:\n    parallel = params.cores/4\n    \"\"\"\n    RepeatProteinMask -pa ${parallel} -engine ${engine} -dir . ${repeatproteinmasker_additional_params} ${genome_file}\n    \"\"\"\n\n}",
        "nb_lignes_process": 20,
        "string_script": "    parallel = params.cores/4\n    \"\"\"\n    RepeatProteinMask -pa ${parallel} -engine ${engine} -dir . ${repeatproteinmasker_additional_params} ${genome_file}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "parallelGWAS"
        ],
        "tools_url": [
            "https://bio.tools/parallelgwas"
        ],
        "tools_dico": [
            {
                "name": "parallelGWAS",
                "uri": "https://bio.tools/parallelgwas",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Developing parallel computing tools for genome-wide association studies.",
                "homepage": "https://en.osdn.jp/projects/parallelgwas/"
            }
        ],
        "inputs": [
            "genome_file",
            "engine"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'repeat'",
            "publishDir \"${params.output}/${params.repeatproteinmasker_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "bedtools_mask": {
        "name_process": "bedtools_mask",
        "string_process": "process bedtools_mask {\n    label 'bedtools'\n    publishDir \"${params.output}/${params.repeatannotation_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(fasta)\n    path(gffs)\n\n    output:\n    path '*.softmasked', emit: softmasked_file\n    path '*.hardmasked', emit: hardmasked_file\n    path 'mergedmask.bed', emit: repeat_annotation\n\n    script:\n    \"\"\"\n    cat ${gffs} | bedtools sort | bedtools merge > mergedmask.bed\n    bedtools maskfasta -soft -fi ${fasta} -bed mergedmask.bed -fo ${fasta.baseName}.softmasked\n    sed 'y/atcg/NNNN/' ${fasta.baseName}.softmasked > ${fasta.baseName}.hardmasked\n    \"\"\"\n\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    cat ${gffs} | bedtools sort | bedtools merge > mergedmask.bed\n    bedtools maskfasta -soft -fi ${fasta} -bed mergedmask.bed -fo ${fasta.baseName}.softmasked\n    sed 'y/atcg/NNNN/' ${fasta.baseName}.softmasked > ${fasta.baseName}.hardmasked\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "fasta",
            "gffs"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'bedtools'",
            "publishDir \"${params.output}/${params.repeatannotation_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "exonerate": {
        "name_process": "exonerate",
        "string_process": "process exonerate {\n    label 'exonerate'\n\n    input:\n    each path(fasta)\n    path(uniprot_fasta)\n\n    output:\n    path '*.exonerate_out.gff'\n\n    script:\n    \"\"\"\n    exonerate -q ${uniprot_fasta} -Q protein --softmaskquery no -t ${fasta} -T dna --softmasktarget yes --showquerygff no --showtargetgff yes --ryo 'AveragePercentIdentity: %pi\\n' --showvulgar no --showalignment no ${params.exonerate_additional_params} | tee ${fasta.simpleName}.${uniprot_fasta.simpleName}.exonerate_out.gff\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    exonerate -q ${uniprot_fasta} -Q protein --softmaskquery no -t ${fasta} -T dna --softmasktarget yes --showquerygff no --showtargetgff yes --ryo 'AveragePercentIdentity: %pi\\n' --showvulgar no --showalignment no ${params.exonerate_additional_params} | tee ${fasta.simpleName}.${uniprot_fasta.simpleName}.exonerate_out.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Exonerate"
        ],
        "tools_url": [
            "https://bio.tools/exonerate"
        ],
        "tools_dico": [
            {
                "name": "Exonerate",
                "uri": "https://bio.tools/exonerate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3182",
                                    "term": "Genome alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0302",
                                    "term": "Protein threading"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3182",
                                    "term": "Genome alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3182",
                                    "term": "Whole genome alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0302",
                                    "term": "Sequence-structure alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for pairwise sequence alignment. It enables alignment for DNA-DNA and DNA-protein pairs and also gapped and ungapped alignment.",
                "homepage": "http://www.ebi.ac.uk/%7Eguy/exonerate"
            }
        ],
        "inputs": [
            "fasta",
            "uniprot_fasta"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'exonerate'"
        ],
        "when": "",
        "stub": ""
    },
    "exonerate_partition": {
        "name_process": "exonerate_partition",
        "string_process": "\nprocess exonerate_partition{\n    label 'exonerate'\n\n    input:\n    path(fasta)\n    path(split_genome_script)\n                       \n\n    output:\n    path \"Split-*.fa\"\n\n    script:\n    \"\"\"\n    perl ${split_genome_script} 3e6 ${fasta}\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    perl ${split_genome_script} 3e6 ${fasta}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "split_genome_script"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'exonerate'"
        ],
        "when": "",
        "stub": ""
    },
    "merge_result_exonerate": {
        "name_process": "merge_result_exonerate",
        "string_process": "\nprocess merge_result_exonerate {\n    label 'smalljobs'\n    publishDir \"${params.output}/${params.exonerate_dir}\", pattern: \"*\", mode: \"copy\"\n\n    input:\n    path(gffs)\n    val(genome_name)\n\n    output:\n    path \"${genome_name}.fa.exonerate_out.gff\"\n\n    \"\"\"\n    cat ${gffs} > ${genome_name}.fa.exonerate_out.gff\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\n    cat ${gffs} > ${genome_name}.fa.exonerate_out.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gffs",
            "genome_name"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'",
            "publishDir \"${params.output}/${params.exonerate_dir}\", pattern: \"*\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "convert_format_exonerate": {
        "name_process": "convert_format_exonerate",
        "string_process": "\nprocess convert_format_exonerate {\n    label 'exonerate'\n    publishDir \"${params.output}/${params.exonerate_dir}\", pattern: \"*\",  mode: \"copy\"\n\n    input:\n    path(convert_format_script)\n    path(relocate_script)\n    each path(fasta)\n\n    output:\n    path \"*.exonerate_out.convertd.gff\"\n\n    shell:\n    '''\n    perl !{convert_format_script} !{fasta} | awk \\'BEGIN{i=0};{if($0~/alignment_id 1\\\\s/){i++};print $1\"\\\\t\"$2\"\\\\t\"$3\"\\\\t\"$4\"\\\\t\"$5\"\\\\t\"$6\"\\\\t\"$7\"\\\\t\"$8\"\\\\t\" \"ID=match_NO_\" i \";AveragePercentIdentity=\"$19 }\\' | grep -v \"line\" | awk -f !{relocate_script} > !{fasta.simpleName}.exonerate_out.convertd.gff\n    '''\n}",
        "nb_lignes_process": 16,
        "string_script": "    '''\n    perl !{convert_format_script} !{fasta} | awk \\'BEGIN{i=0};{if($0~/alignment_id 1\\\\s/){i++};print $1\"\\\\t\"$2\"\\\\t\"$3\"\\\\t\"$4\"\\\\t\"$5\"\\\\t\"$6\"\\\\t\"$7\"\\\\t\"$8\"\\\\t\" \"ID=match_NO_\" i \";AveragePercentIdentity=\"$19 }\\' | grep -v \"line\" | awk -f !{relocate_script} > !{fasta.simpleName}.exonerate_out.convertd.gff\n    '''",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "convert_format_script",
            "relocate_script",
            "fasta"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'exonerate'",
            "publishDir \"${params.output}/${params.exonerate_dir}\", pattern: \"*\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "samtools_sam_to_bam": {
        "name_process": "samtools_sam_to_bam",
        "string_process": "process samtools_sam_to_bam {\n    label 'samtools'\n\n    input:\n    path(sam)\n\n    output:\n    path \"${sam.baseName}.bam\"\n\n    script:\n    \"\"\"\n    samtools view -@ ${task.cpus} -b -S ${sam} -o ${sam.baseName}.bam\n    \"\"\"\n}",
        "nb_lignes_process": 12,
        "string_script": "    \"\"\"\n    samtools view -@ ${task.cpus} -b -S ${sam} -o ${sam.baseName}.bam\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sam"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'samtools'"
        ],
        "when": "",
        "stub": ""
    },
    "pasa_seq_clean": {
        "name_process": "pasa_seq_clean",
        "string_process": "process pasa_seq_clean {\n    label 'pasa'\n\n    input:\n    path(transcripts)\n    path(univec)\n\n    output:\n    path \"*.fasta.cln\", emit: cln\n    path \"*.fasta.clean\", emit: clean\n    script:\n    \"\"\"\n    \\$PASAHOME/bin/seqclean ${transcripts} -v ${univec}\n    \"\"\"\n\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    \\$PASAHOME/bin/seqclean ${transcripts} -v ${univec}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "transcripts",
            "univec"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'pasa'"
        ],
        "when": "",
        "stub": ""
    },
    "pasa_concat": {
        "name_process": "pasa_concat",
        "string_process": "\nprocess pasa_concat {\n    label 'smalljobs'\n    input:\n    path(assembly_gg)\n    path(assembly_denovo)\n    \n    output:\n    path 'assembly_conacted.fasta'\n    \n    script:\n    \"\"\"\n    cat ${assembly_gg} ${assembly_denovo} > assembly_conacted.fasta\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    cat ${assembly_gg} ${assembly_denovo} > assembly_conacted.fasta\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "assembly_gg",
            "assembly_denovo"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'"
        ],
        "when": "",
        "stub": ""
    },
    "pasa_mysql_config": {
        "name_process": "pasa_mysql_config",
        "string_process": "\nprocess pasa_mysql_config {\n    label 'smalljobs'\n    \n    input:\n    path(conf_template)\n    path(align_conf_template)\n    val(host)\n    val(db_name)\n    val(username)\n    val(password)\n    \n    output:\n    path 'conf.txt',emit:pasa_conf\n    path 'alignAssembly.txt', emit:pasa_alignassembly_conf\n\n    script:\n    \"\"\"\n    sed -e 's/MYSQLSERVER=localhost/MYSQLSERVER=${host}/1; s/MYSQL_RW_USER=xxxxxx/MYSQL_RW_USER=${username}/1; s/MYSQL_RW_PASSWORD=xxxxx/MYSQL_RW_PASSWORD=${password}/1' ${conf_template} > conf.txt\n    sed 's!DATABASE=<__DATABASE__>!DATABASE=${db_name}!1' ${align_conf_template} > alignAssembly.txt\n    \"\"\"\n    \n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    sed -e 's/MYSQLSERVER=localhost/MYSQLSERVER=${host}/1; s/MYSQL_RW_USER=xxxxxx/MYSQL_RW_USER=${username}/1; s/MYSQL_RW_PASSWORD=xxxxx/MYSQL_RW_PASSWORD=${password}/1' ${conf_template} > conf.txt\n    sed 's!DATABASE=<__DATABASE__>!DATABASE=${db_name}!1' ${align_conf_template} > alignAssembly.txt\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "conf_template",
            "align_conf_template",
            "host",
            "db_name",
            "username",
            "password"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'"
        ],
        "when": "",
        "stub": ""
    },
    "pasa_sqlite_config": {
        "name_process": "pasa_sqlite_config",
        "string_process": "\nprocess pasa_sqlite_config {\n    label 'smalljobs'\n\n    input:\n    path(conf_template)\n    path(align_conf_template)\n    val(db_path)\n    \n    output:\n    path 'conf.txt',emit:pasa_conf\n    path 'alignAssembly.txt', emit:pasa_alignassembly_conf\n    \n    script:\n    \"\"\"\n    cp ${conf_template} conf.txt\n    sed 's!DATABASE=<__DATABASE__>!DATABASE=${db_path}!1' ${align_conf_template} > alignAssembly.txt\n    \n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    cp ${conf_template} conf.txt\n    sed 's!DATABASE=<__DATABASE__>!DATABASE=${db_path}!1' ${align_conf_template} > alignAssembly.txt\n    \n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "conf_template",
            "align_conf_template",
            "db_path"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'"
        ],
        "when": "",
        "stub": ""
    },
    "pasa_create_tdn": {
        "name_process": "pasa_create_tdn",
        "string_process": "\nprocess pasa_create_tdn {\n    label 'pasa'\n    publishDir \"${params.output}/${params.pasa_dir}\", mode: 'copy', pattern: \"*.tdn.accs\"\n\n    input:\n    path(assembly_denovo)\n \n    output:\n    path 'tdn.accs'\n\n    script:\n    \"\"\"\n    \\$PASAHOME/misc_utilities/accession_extractor.pl < ${assembly_denovo} > tdn.accs\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    \\$PASAHOME/misc_utilities/accession_extractor.pl < ${assembly_denovo} > tdn.accs\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "assembly_denovo"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'pasa'",
            "publishDir \"${params.output}/${params.pasa_dir}\", mode: 'copy', pattern: \"*.tdn.accs\""
        ],
        "when": "",
        "stub": ""
    },
    "pasa": {
        "name_process": "pasa",
        "string_process": "\nprocess pasa {\n    label 'pasa'\n    publishDir \"${params.output}/${params.pasa_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(align_config)\n    path(pasa_config)\n    path(ref_genome_masked)\n    path(transcript)\n    path(transcript_clean)\n    path(transcript_cln)\n    path(tdn)\n\n    output:\n    path '*.pasa_assemblies.gff3',emit: assemblies_gff\n    path '*.transdecoder.gff3',emit: transdecoder_gff\n    path '*.transdecoder.cds',emit: transdecoder_cds\n    path '*.transdecoder.bed',emit: transdecoder_bed\n    path '*.assemblies.fasta',emit: assemblies_fasta\n\n\n    script:\n    if ( workflow.containerEngine != null ) {\n        params.pasa_additional_params = '--ALIGNERS blat,minimap2 -I 600000'\n    }\n    PASACONF = ' '\n    if (params.pasa_use_mysql) {\n        PASACONF = \"--PASACONF ${pasa_config}\"\n    }\n\n    \"\"\"\n    rm -f ${params.pasa_sqlite_path}\n    \\$PASAHOME/Launch_PASA_pipeline.pl -c ${align_config} -C -R -g ${ref_genome_masked} -T -u ${transcript} -t ${transcript_clean} --CPU ${task.cpus} --TDN ${tdn} ${PASACONF} ${params.pasa_additional_params} --TRANSDECODER\n    \"\"\"\n    \n}",
        "nb_lignes_process": 35,
        "string_script": "    if ( workflow.containerEngine != null ) {\n        params.pasa_additional_params = '--ALIGNERS blat,minimap2 -I 600000'\n    }\n    PASACONF = ' '\n    if (params.pasa_use_mysql) {\n        PASACONF = \"--PASACONF ${pasa_config}\"\n    }\n\n    \"\"\"\n    rm -f ${params.pasa_sqlite_path}\n    \\$PASAHOME/Launch_PASA_pipeline.pl -c ${align_config} -C -R -g ${ref_genome_masked} -T -u ${transcript} -t ${transcript_clean} --CPU ${task.cpus} --TDN ${tdn} ${PASACONF} ${params.pasa_additional_params} --TRANSDECODER\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "align_config",
            "pasa_config",
            "ref_genome_masked",
            "transcript",
            "transcript_clean",
            "transcript_cln",
            "tdn"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'pasa'",
            "publishDir \"${params.output}/${params.pasa_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "pasa_assemblies_to_orf": {
        "name_process": "pasa_assemblies_to_orf",
        "string_process": "\nprocess pasa_assemblies_to_orf {\n    label 'pasa'\n    publishDir \"${params.output}/${params.pasa_dir}\", mode: 'copy', pattern: \"*\"\n\n    input:\n    path(transcripts_fasta)\n    path(transcript_gff3)\n\n    output:\n    path '*.fasta.transdecoder.genome.gff3',emit:transdecoder_gff\n\n    script:\n    \"\"\"\n    \\$PASAHOME/scripts/pasa_asmbls_to_training_set.dbi  --pasa_transcripts_fasta ${transcripts_fasta} --pasa_transcripts_gff3 ${transcript_gff3}\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    \\$PASAHOME/scripts/pasa_asmbls_to_training_set.dbi  --pasa_transcripts_fasta ${transcripts_fasta} --pasa_transcripts_gff3 ${transcript_gff3}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "transcripts_fasta",
            "transcript_gff3"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'pasa'",
            "publishDir \"${params.output}/${params.pasa_dir}\", mode: 'copy', pattern: \"*\""
        ],
        "when": "",
        "stub": ""
    },
    "augustus": {
        "name_process": "augustus",
        "string_process": "\nprocess augustus { \n    label 'augustus'\n\n    input:\n    each path(fasta)\n    path(config)\n    val(species)\n\n    output:\n    path \"*.gff\"\n\n    script:\n    \"\"\"\n    augustus --softmasking=1 --species=${species} --AUGUSTUS_CONFIG_PATH=${config} --UTR=off ${params.augustus_additional_params} ${fasta} > ${fasta.name}.augustus.out.gff\n    \"\"\"\n\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    augustus --softmasking=1 --species=${species} --AUGUSTUS_CONFIG_PATH=${config} --UTR=off ${params.augustus_additional_params} ${fasta} > ${fasta.name}.augustus.out.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "AUGUSTUS"
        ],
        "tools_url": [
            "https://bio.tools/augustus"
        ],
        "tools_dico": [
            {
                "name": "AUGUSTUS",
                "uri": "https://bio.tools/augustus",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Gene and protein families"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Genes, gene family or system"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Homology-based gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3662",
                                    "term": "Ab-initio gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0004",
                                    "term": "Operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Evidence-based gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Gene prediction (homology-based)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Empirical gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Similarity-based gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3663",
                                    "term": "Empirical gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3662",
                                    "term": "Gene prediction (ab-initio)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "AUGUSTUS is a eukaryotic gene prediction tool. It can integrate evidence, e.g. from RNA-Seq, ESTs, proteomics, but can also predict genes ab initio. The PPX extension to AUGUSTUS can take a protein sequence multiple sequence alignment as input to find new members of the family in a genome. It can be run through a web interface (see https://bio.tools/webaugustus), or downloaded and run locally.",
                "homepage": "http://bioinf.uni-greifswald.de/augustus"
            }
        ],
        "inputs": [
            "fasta",
            "config",
            "species"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'augustus'"
        ],
        "when": "",
        "stub": ""
    },
    "augustus_partition": {
        "name_process": "augustus_partition",
        "string_process": "\nprocess augustus_partition {\n    label 'augustus'\n\n    input:\n    path(fasta)\n    path(split_genome_script)\n                       \n\n    output:\n    path \"Split-*.fa\"\n\n    script:\n    \"\"\"\n    perl ${split_genome_script} 3e6 ${fasta}\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    perl ${split_genome_script} 3e6 ${fasta}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "split_genome_script"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'augustus'"
        ],
        "when": "",
        "stub": ""
    },
    "copy_augustus_model": {
        "name_process": "copy_augustus_model",
        "string_process": "\nprocess copy_augustus_model {\n    label 'smalljobs'\n    input:\n    path(augustus_model)\n    path(augustus_config_path)\n\n    script:\n    \"\"\"\n    cp -r -f -u ${augustus_model} ${augustus_config_path}/species\n    \"\"\"\n\n}",
        "nb_lignes_process": 11,
        "string_script": "    \"\"\"\n    cp -r -f -u ${augustus_model} ${augustus_config_path}/species\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "augustus_model",
            "augustus_config_path"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'"
        ],
        "when": "",
        "stub": ""
    },
    "create_augustus_config": {
        "name_process": "create_augustus_config",
        "string_process": "\nprocess create_augustus_config {\n    label 'smalljobs'\n\n    input:\n    path(config_tarball)\n\n    output:\n    path './config'\n\n    script:\n    \"\"\"\n    tar -xzvf ${config_tarball}\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    tar -xzvf ${config_tarball}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "config_tarball"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'"
        ],
        "when": "",
        "stub": ""
    },
    "merge_result_augustus": {
        "name_process": "merge_result_augustus",
        "string_process": "\nprocess merge_result_augustus {\n    label 'smalljobs'\n    publishDir \"${params.output}/${params.augustus_dir}\", pattern: \"*\", mode: \"copy\"\n\n    input:\n    path(gffs)\n    val(genome_name)\n\n    output:\n    path \"${genome_name}.fa.augustus_out.gff\"\n\n    \"\"\"\n    cat ${gffs} > ${genome_name}.fa.augustus_out.gff\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "\"\"\"\n    cat ${gffs} > ${genome_name}.fa.augustus_out.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gffs",
            "genome_name"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'smalljobs'",
            "publishDir \"${params.output}/${params.augustus_dir}\", pattern: \"*\", mode: \"copy\""
        ],
        "when": "",
        "stub": ""
    },
    "glimmerhmm": {
        "name_process": "glimmerhmm",
        "string_process": "process glimmerhmm {\n    label 'glimmerhmm'\n\n    input:\n    path(fasta_hardmasked)\n\n    output:\n    path \"*.out.gff\"\n\n    script:\n    \n    \"\"\"\n    glimmerhmm ${fasta_hardmasked} > ${fasta_hardmasked.simpleName}.fa.out.gff\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    glimmerhmm ${fasta_hardmasked} > ${fasta_hardmasked.simpleName}.fa.out.gff\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta_hardmasked"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'glimmerhmm'"
        ],
        "when": "",
        "stub": ""
    },
    "train_glimmerhmm": {
        "name_process": "train_glimmerhmm",
        "string_process": "\nprocess train_glimmerhmm {\n    label 'glimmerhmm'\n\n    input:\n    path(fasta)\n    path(exon)\n\n    output:\n    \n    script:\n\n    \"\"\"\n    trainGlimmerHMM ${fasta} ${exon} ${params.train_glimmerhmm_additional}\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    trainGlimmerHMM ${fasta} ${exon} ${params.train_glimmerhmm_additional}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "exon"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'glimmerhmm'"
        ],
        "when": "",
        "stub": ""
    },
    "fastp": {
        "name_process": "fastp",
        "string_process": "process fastp {\n    label 'fastp'\n    publishDir \"${params.output}/${params.fastp_dir}\", mode: 'copy', pattern: \"*.trimmed.fastq.gz\" \n\n    input:\n    val(name)\n    path(reads)\n\n    output:\n    path(\"${name}*.trimmed.fastq.gz\"), emit: sample_trimmed\n    path \"${name}_fastp.json\", emit: json_report\n\n    script:\n    \"\"\"\n    fastp -i ${reads[0]} -I ${reads[1]} -o ${name}.R1.trimmed.fastq.gz -O ${name}.R2.trimmed.fastq.gz --thread ${task.cpus} --json ${name}_fastp.json ${params.fastp_additional_params}\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    fastp -i ${reads[0]} -I ${reads[1]} -o ${name}.R1.trimmed.fastq.gz -O ${name}.R2.trimmed.fastq.gz --thread ${task.cpus} --json ${name}_fastp.json ${params.fastp_additional_params}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "name",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'fastp'",
            "publishDir \"${params.output}/${params.fastp_dir}\", mode: 'copy', pattern: \"*.trimmed.fastq.gz\""
        ],
        "when": "",
        "stub": ""
    },
    "trinity_de_novo_assembly": {
        "name_process": "trinity_de_novo_assembly",
        "string_process": "process trinity_de_novo_assembly {\n    label 'trinity'\n    publishDir \"${params.output}/${params.trinity_dir}/denovo\", mode: 'copy', pattern: \"trinity_out_dir\"\n\n    input:\n    path(reads)\n\n    output:\n    path \"trinity.fasta\"\n\n    script:\n    \"\"\"\n    MEM=\\$(echo ${task.memory} | awk '{print \\$1}')\n    Trinity --seqType fq --left ${reads[0]} --right ${reads[1]} --CPU ${task.cpus} --max_memory \\${MEM}G\n    cp trinity_out_dir.Trinity.fasta trinity.fasta\n    \"\"\"\n\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    MEM=\\$(echo ${task.memory} | awk '{print \\$1}')\n    Trinity --seqType fq --left ${reads[0]} --right ${reads[1]} --CPU ${task.cpus} --max_memory \\${MEM}G\n    cp trinity_out_dir.Trinity.fasta trinity.fasta\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "Trinity"
        ],
        "tools_url": [
            "https://bio.tools/trinity"
        ],
        "tools_dico": [
            {
                "name": "Trinity",
                "uri": "https://bio.tools/trinity",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Trinity is a transcriptome assembler which relies on three different tools, inchworm an assembler, chrysalis which pools contigs and butterfly which amongst others compacts a graph resulting from butterfly with reads.",
                "homepage": "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
            }
        ],
        "inputs": [
            "reads"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'trinity'",
            "publishDir \"${params.output}/${params.trinity_dir}/denovo\", mode: 'copy', pattern: \"trinity_out_dir\""
        ],
        "when": "",
        "stub": ""
    },
    "tririty_genome_guided_assembly": {
        "name_process": "tririty_genome_guided_assembly",
        "string_process": "\nprocess tririty_genome_guided_assembly {\n    label 'trinity'\n    publishDir \"${params.output}/${params.trinity_dir}/genome_guided\", mode: 'copy', pattern: \"trinity_out_dir\"\n\n    input:\n    path(genome_bam)\n    val(max_intron)\n\n    output:\n    path \"trinity-gg.fasta\"\n\n    script:\n    \"\"\"\n    MEM=\\$(echo ${task.memory} | awk '{print \\$1}')\n    Trinity --genome_guided_bam ${genome_bam} --genome_guided_max_intron ${max_intron} --CPU ${task.cpus} --max_memory \\${MEM}G\n    cp trinity_out_dir/Trinity-GG.fasta trinity-gg.fasta\n    \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    MEM=\\$(echo ${task.memory} | awk '{print \\$1}')\n    Trinity --genome_guided_bam ${genome_bam} --genome_guided_max_intron ${max_intron} --CPU ${task.cpus} --max_memory \\${MEM}G\n    cp trinity_out_dir/Trinity-GG.fasta trinity-gg.fasta\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [
            "Trinity"
        ],
        "tools_url": [
            "https://bio.tools/trinity"
        ],
        "tools_dico": [
            {
                "name": "Trinity",
                "uri": "https://bio.tools/trinity",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Trinity is a transcriptome assembler which relies on three different tools, inchworm an assembler, chrysalis which pools contigs and butterfly which amongst others compacts a graph resulting from butterfly with reads.",
                "homepage": "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
            }
        ],
        "inputs": [
            "genome_bam",
            "max_intron"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "dakehero__LGAflow",
        "directive": [
            "label 'trinity'",
            "publishDir \"${params.output}/${params.trinity_dir}/genome_guided\", mode: 'copy', pattern: \"trinity_out_dir\""
        ],
        "when": "",
        "stub": ""
    }
}