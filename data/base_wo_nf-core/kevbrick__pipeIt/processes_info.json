{
    "SRAtoFQ": {
        "name_process": "SRAtoFQ",
        "string_process": "\nprocess SRAtoFQ {\n\n  label 'getFQ'\n\n  time { 4.hour * task.attempt }\n\n  input:\n  val sraNum\n\n  output:\n  tuple(val(\"gz\"), path('*.R1.fastq.gz'), emit: R1)\n  tuple(val(\"gz\"), path('*.R2.fastq.gz'), emit: R2, optional: true)\n\n  script:\n  \"\"\"\n  sra=\\$(echo \"${sraNum}\" | tr \",\" \"\\\\n\")\n\n  for s in \\$sra\n  do\n    fastq-dump \\$s --split-files >/dev/null 2>/dev/null\n\n    if [ -f \\$s\"_2.fastq\" ] ; then\n      mv \\$s\"_1.fastq\" \\$s\".R1.fastq\"\n      mv \\$s\"_2.fastq\" \\$s\".R2.fastq\"\n    else\n      mv \\$s\"_1.fastq\" \\$s\".R1.fastq\"\n    fi\n  done\n\n  gzip *R?.fastq\n  \"\"\"\n  }",
        "nb_lignes_process": 31,
        "string_script": "  \"\"\"\n  sra=\\$(echo \"${sraNum}\" | tr \",\" \"\\\\n\")\n\n  for s in \\$sra\n  do\n    fastq-dump \\$s --split-files >/dev/null 2>/dev/null\n\n    if [ -f \\$s\"_2.fastq\" ] ; then\n      mv \\$s\"_1.fastq\" \\$s\".R1.fastq\"\n      mv \\$s\"_2.fastq\" \\$s\".R2.fastq\"\n    else\n      mv \\$s\"_1.fastq\" \\$s\".R1.fastq\"\n    fi\n  done\n\n  gzip *R?.fastq\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "sraNum"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'getFQ'",
            "time { 4.hour * task.attempt }"
        ],
        "when": "",
        "stub": ""
    },
    "BAMtoFQ": {
        "name_process": "BAMtoFQ",
        "string_process": "\nprocess BAMtoFQ {\n\n  label 'getFQ'\n\n  time { 1.hour * bam.size()/4000000000 * task.attempt}\n\n  tag { bam.size() }\n\n  input:\n  file(bam)\n\n  output:\n  tuple(val(\"gz\"), path('*.R1.fastq.gz'), emit: R1)\n  tuple(val(\"gz\"), path('*.R2.fastq.gz'), emit: R2, optional: true)\n\n  script:\n  \"\"\"\n  n=`samtools view -h ${bam} |head -n 100000 |samtools view -f 1 -S /dev/stdin |wc -l`\n\n  if [ \\$n -eq 0 ]; then\n    isSRPE=\"SR\"\n\n    java -jar \\$PICARDJAR SortSam \\\n                   I=${bam}  \\\n                   O=querynameSort.bam \\\n                   SO=queryname \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n\n    java -jar \\$PICARDJAR SamToFastq I=querynameSort.bam \\\n                   F=nxf.R1.fastq.gz \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n  else\n    isSRPE=\"PE\"\n    java -jar \\$PICARDJAR FixMateInformation \\\n                   I=${bam} \\\n                   O=fixMate.bam \\\n                   SORT_ORDER=queryname \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n\n    java -jar \\$PICARDJAR SortSam \\\n                   I=fixMate.bam  \\\n                   O=querynameSort.bam \\\n                   SO=queryname \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n\n    java -jar \\$PICARDJAR SamToFastq I=querynameSort.bam \\\n                   F=nxf.R1.fastq.gz F2=nxf.R2.fastq.gz \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n    fi\n  \"\"\"\n  }",
        "nb_lignes_process": 55,
        "string_script": "  \"\"\"\n  n=`samtools view -h ${bam} |head -n 100000 |samtools view -f 1 -S /dev/stdin |wc -l`\n\n  if [ \\$n -eq 0 ]; then\n    isSRPE=\"SR\"\n\n    java -jar \\$PICARDJAR SortSam \\\n                   I=${bam}  \\\n                   O=querynameSort.bam \\\n                   SO=queryname \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n\n    java -jar \\$PICARDJAR SamToFastq I=querynameSort.bam \\\n                   F=nxf.R1.fastq.gz \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n  else\n    isSRPE=\"PE\"\n    java -jar \\$PICARDJAR FixMateInformation \\\n                   I=${bam} \\\n                   O=fixMate.bam \\\n                   SORT_ORDER=queryname \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n\n    java -jar \\$PICARDJAR SortSam \\\n                   I=fixMate.bam  \\\n                   O=querynameSort.bam \\\n                   SO=queryname \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n\n    java -jar \\$PICARDJAR SamToFastq I=querynameSort.bam \\\n                   F=nxf.R1.fastq.gz F2=nxf.R2.fastq.gz \\\n                   TMP_DIR=\\$TMPDIR \\\n                   VALIDATION_STRINGENCY=LENIENT >/dev/null 2>/dev/null\n    fi\n  \"\"\"",
        "nb_lignes_script": 38,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "bam"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'getFQ'",
            "time { 1.hour * bam.size()/4000000000 * task.attempt}",
            "tag { bam.size() }"
        ],
        "when": "",
        "stub": ""
    },
    "FQtoFQpe": {
        "name_process": "FQtoFQpe",
        "string_process": "\nprocess FQtoFQpe {\n  cpus 2\n  memory '4g'\n\n  time { 1.hour * inFQ1.size()/5000000000 * task.attempt}\n  errorStrategy { 'retry' }\n  maxRetries 1\n\n  tag { inFQ1 }\n\n  input:\n  file inFQ1\n  file inFQ2\n\n  output:\n  path('*.R[12].fastq', emit: fqs)\n\n  script:\n  if (inFQ1 =~ /.gz$/)\n    \"\"\"\n    gunzip --stdout ${inFQ1} >nxf.R1.fastq 2>/dev/null\n    gunzip --stdout ${inFQ2} >nxf.R2.fastq 2>/dev/null\n    isSRPE=\"PE\"\n    \"\"\"\n  else\n    \"\"\"\n    ln -s ${inFQ1} nxf.R1.fastq 2>/dev/null\n    ln -s ${inFQ2} nxf.R2.fastq 2>/dev/null\n    isSRPE=\"PE\"\n    \"\"\"\n  }",
        "nb_lignes_process": 30,
        "string_script": "  if (inFQ1 =~ /.gz$/)\n    \"\"\"\n    gunzip --stdout ${inFQ1} >nxf.R1.fastq 2>/dev/null\n    gunzip --stdout ${inFQ2} >nxf.R2.fastq 2>/dev/null\n    isSRPE=\"PE\"\n    \"\"\"\n  else\n    \"\"\"\n    ln -s ${inFQ1} nxf.R1.fastq 2>/dev/null\n    ln -s ${inFQ2} nxf.R2.fastq 2>/dev/null\n    isSRPE=\"PE\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "inFQ1",
            "inFQ2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "cpus 2",
            "memory '4g'",
            "time { 1.hour * inFQ1.size()/5000000000 * task.attempt}",
            "errorStrategy { 'retry' }",
            "maxRetries 1",
            "tag { inFQ1 }"
        ],
        "when": "",
        "stub": ""
    },
    "FQtoFQsr": {
        "name_process": "FQtoFQsr",
        "string_process": "\nprocess FQtoFQsr {\n  cpus 2\n  memory '4g'\n\n  time { 1.hour * inFQ1.size()/5000000000 * task.attempt}\n  errorStrategy { 'retry' }\n  maxRetries 1\n\n  tag { inFQ1 }\n\n  input:\n  file inFQ1\n\n  output:\n  path('*.R[12].fastq', emit: fqs)\n\n  script:\n  if (inFQ1 =~ /.gz$/)\n    \"\"\"\n    gunzip --stdout ${inFQ1} >nxf.R1.fastq 2>/dev/null\n    isSRPE=\"SR\"\n    \"\"\"\n  else\n    \"\"\"\n    ln -s ${inFQ1} nxf.R1.fastq\n    isSRPE=\"PE\"\n    \"\"\"\n  }",
        "nb_lignes_process": 27,
        "string_script": "  if (inFQ1 =~ /.gz$/)\n    \"\"\"\n    gunzip --stdout ${inFQ1} >nxf.R1.fastq 2>/dev/null\n    isSRPE=\"SR\"\n    \"\"\"\n  else\n    \"\"\"\n    ln -s ${inFQ1} nxf.R1.fastq\n    isSRPE=\"PE\"\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "inFQ1"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "cpus 2",
            "memory '4g'",
            "time { 1.hour * inFQ1.size()/5000000000 * task.attempt}",
            "errorStrategy { 'retry' }",
            "maxRetries 1",
            "tag { inFQ1 }"
        ],
        "when": "",
        "stub": ""
    },
    "OBJtoFQ": {
        "name_process": "OBJtoFQ",
        "string_process": "\nprocess OBJtoFQ{\n\n  label 'getFQ'\n\n  time { 3.hour * task.attempt}\n\n  tag { objName }\n\n  input:\n  val(objName)\n\n  output:\n  tuple(val(\"gz\"), path('*.R1.fastq.gz'), emit: R1)\n  tuple(val(\"gz\"), path('*.R2.fastq.gz'), emit: R2, optional: true)\n\n  script:\n  \"\"\"\n  echo \"OBJ\"\n  getFromBiowulfObj --v RDCO --p ${objName} --get --f\n  \"\"\"\n  }",
        "nb_lignes_process": 20,
        "string_script": "  \"\"\"\n  echo \"OBJ\"\n  getFromBiowulfObj --v RDCO --p ${objName} --get --f\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "objName"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'getFQ'",
            "time { 3.hour * task.attempt}",
            "tag { objName }"
        ],
        "when": "",
        "stub": ""
    },
    "mergeFQ": {
        "name_process": "mergeFQ",
        "string_process": "\nprocess mergeFQ {\n\n  tag {\"${params.name}\"}\n\n  input:\n  tuple(val(type),file(R1),file(R2))\n\n  output:\n  path(\"*.R[12].fastq*\", emit: fqs)\n\n  script:\n  def multiR1 = R1[1]\n  def multiR2 = R2[1]\n  def name = \"${params.name}.merged\"\n                                            \n                                                                        \n                                           \n  \"\"\"\n  if [ \"${type}\" == \"gz\" ]; then\n    if [ \"${multiR1}\" == \"null\" ]; then\n      ln -s ${R1} ${name}.R1.fastq.gz\n    else\n      cat ${R1} >${name}.R1.fastq.gz\n    fi\n\n    #if [ ! -z \"${R2}\" ]; then\n    if [ \"${R2}\" != \"input.2\" ]; then\n      if [ \"${multiR2}\" == \"null\" ]; then\n        ln -s ${R2} ${name}.R2.fastq.gz\n      else\n        cat ${R2} >${name}.R2.fastq.gz\n      fi\n    fi\n  else\n    cat ${R1} |gzip -c >${name}.R1.fastq\n\n    #if [ ! -z \"${R2}\" ]; then\n    if [ \"${R2}\" != \"input.2\" ]; then\n      cat ${R2} |gzip -c >${name}.R2.fastq\n    fi\n  fi\n\n  if [ \"${params.sortFQ}\" == \"true\" ]; then\n    if [ \"${type}\" == \"gz\" ]; then\n      gunzip -c ${name}.R1.fastq.gz >tmp.fq\n      fastq-sort --id tmp.fq |gzip -c >${name}.R1.fastq.gz\n      rm tmp.fq\n\n      #if [ ! -z \"${R2}\" ]; then\n      if [ \"${R2}\" != \"input.2\" ]; then\n        gunzip -c ${name}.R2.fastq.gz >tmp.fq\n        fastq-sort --id tmp.fq |gzip -c >${name}.R2.fastq.gz\n        rm tmp.fq\n      fi\n    else\n      fastq-sort --id ${name}.R1.fastq R1.fastq\n      mv R1.fastq ${name}.R1.fastq\n      gzip ${name}.R1.fastq\n\n      #if [ ! -z \"${R2}\" ]; then\n      if [ \"${R2}\" != \"input.2\" ]; then\n        fastq-sort --id ${name}.R2.fastq R2.fastq\n        mv R2.fastq ${name}.R2.fastq\n        gzip ${name}.R2.fastq\n      fi\n    fi\n  fi\n\n  \"\"\"\n  }",
        "nb_lignes_process": 69,
        "string_script": "  def multiR1 = R1[1]\n  def multiR2 = R2[1]\n  def name = \"${params.name}.merged\"\n                                            \n                                                                        \n                                           \n  \"\"\"\n  if [ \"${type}\" == \"gz\" ]; then\n    if [ \"${multiR1}\" == \"null\" ]; then\n      ln -s ${R1} ${name}.R1.fastq.gz\n    else\n      cat ${R1} >${name}.R1.fastq.gz\n    fi\n\n    #if [ ! -z \"${R2}\" ]; then\n    if [ \"${R2}\" != \"input.2\" ]; then\n      if [ \"${multiR2}\" == \"null\" ]; then\n        ln -s ${R2} ${name}.R2.fastq.gz\n      else\n        cat ${R2} >${name}.R2.fastq.gz\n      fi\n    fi\n  else\n    cat ${R1} |gzip -c >${name}.R1.fastq\n\n    #if [ ! -z \"${R2}\" ]; then\n    if [ \"${R2}\" != \"input.2\" ]; then\n      cat ${R2} |gzip -c >${name}.R2.fastq\n    fi\n  fi\n\n  if [ \"${params.sortFQ}\" == \"true\" ]; then\n    if [ \"${type}\" == \"gz\" ]; then\n      gunzip -c ${name}.R1.fastq.gz >tmp.fq\n      fastq-sort --id tmp.fq |gzip -c >${name}.R1.fastq.gz\n      rm tmp.fq\n\n      #if [ ! -z \"${R2}\" ]; then\n      if [ \"${R2}\" != \"input.2\" ]; then\n        gunzip -c ${name}.R2.fastq.gz >tmp.fq\n        fastq-sort --id tmp.fq |gzip -c >${name}.R2.fastq.gz\n        rm tmp.fq\n      fi\n    else\n      fastq-sort --id ${name}.R1.fastq R1.fastq\n      mv R1.fastq ${name}.R1.fastq\n      gzip ${name}.R1.fastq\n\n      #if [ ! -z \"${R2}\" ]; then\n      if [ \"${R2}\" != \"input.2\" ]; then\n        fastq-sort --id ${name}.R2.fastq R2.fastq\n        mv R2.fastq ${name}.R2.fastq\n        gzip ${name}.R2.fastq\n      fi\n    fi\n  fi\n\n  \"\"\"",
        "nb_lignes_script": 57,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "type",
            "R1",
            "R2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag {\"${params.name}\"}"
        ],
        "when": "",
        "stub": ""
    },
    "commitToObj": {
        "name_process": "commitToObj",
        "string_process": "\nprocess commitToObj {\n\n  cpus 1\n  memory '6g'\n\n  time { 5.hour * task.attempt}\n  errorStrategy { 'retry' }\n  maxRetries 1\n\n  input:\n  file(fqs)\n\n  script:\n  \"\"\"\n  for f in `ls *fastq.gz`; do\n    #obj_rm  -v RDCO \\$f 2>/dev/null || true\n    obj_put --force -v RDCO \\$f\n  done\n  \"\"\"\n  }",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  for f in `ls *fastq.gz`; do\n    #obj_rm  -v RDCO \\$f 2>/dev/null || true\n    obj_put --force -v RDCO \\$f\n  done\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "fqs"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "cpus 1",
            "memory '6g'",
            "time { 5.hour * task.attempt}",
            "errorStrategy { 'retry' }",
            "maxRetries 1"
        ],
        "when": "",
        "stub": ""
    },
    "fastqC": {
        "name_process": "fastqC",
        "string_process": "\nprocess fastqC {\n  tag {\"${params.name}\"}\n\n  publishDir \"${params.outdir}/reports\",  mode: 'copy', overwrite: true\n\n  input:\n  path(fq)\n\n  output:\n  path('*fastqc_report.*', emit: rep)\n\n  when:\n  !(\"${workflow.scriptName}\" =~ /commit/)\n\n  script:\n  \"\"\"\n  for f in *fastq*; do\n    if [[ \"\\$f\" =~ \".gz\" ]]; then\n      zcat \\$f |head -n 10000000 >subset.fastq\n      name=\\${f/.(fastq|fq).gz/}\n    else\n      head -n 10000000 \\$f >subset.fastq\n      name=\\${f/.(fastq|fq).gz/}\n    fi\n\n    fastqc -t ${task.cpus} subset.fastq\n\n    mv subset_fastqc.html \\$name\".fastqc_report.html\"\n    mv subset_fastqc.zip  \\$name\".fastqc_report.zip\"\n  done\n  \"\"\"\n  }",
        "nb_lignes_process": 31,
        "string_script": "  \"\"\"\n  for f in *fastq*; do\n    if [[ \"\\$f\" =~ \".gz\" ]]; then\n      zcat \\$f |head -n 10000000 >subset.fastq\n      name=\\${f/.(fastq|fq).gz/}\n    else\n      head -n 10000000 \\$f >subset.fastq\n      name=\\${f/.(fastq|fq).gz/}\n    fi\n\n    fastqc -t ${task.cpus} subset.fastq\n\n    mv subset_fastqc.html \\$name\".fastqc_report.html\"\n    mv subset_fastqc.zip  \\$name\".fastqc_report.zip\"\n  done\n  \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag {\"${params.name}\"}",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true"
        ],
        "when": "!(\"${workflow.scriptName}\" =~ /commit/)",
        "stub": ""
    },
    "fastqScreen": {
        "name_process": "fastqScreen",
        "string_process": "\nprocess fastqScreen {\n  tag {\"${params.name}\"}\n\n  publishDir \"${params.outdir}/reports\",  mode: 'copy', overwrite: true\n\n  when:\n  !(\"${workflow.scriptName}\" =~ /commit/)\n\n  input:\n  path(fq)\n\n  output:\n  path('*_screen*', emit: report)\n\n  script:\n  \"\"\"\n  ##Make FastqScreen config file\n  echo \"# This is a config file for FastQ Screen\\n\\n\" >conf.txt\n  echo \"THREADS ${task.cpus}\\n\\n\" >>conf.txt\n\n  gList=\"${params.genomes2screen}\"\n  g2use=\\${gList//,/\\$'\\n'}\n\n  for g in \\$g2use; do\n    echo \"DATABASE \\$g \\$NXF_GENOMES/\\$g/BWAIndex/version0.7.10/genome.fa\" >>conf.txt\n  done\n\n  for f in *.R1.fastq*; do\n    if [[ \"\\$f\" =~ \"q.gz\" ]]; then\n      fqs=`echo \\$f |perl -pi -e 's/(fq|fastq).gz/ds.fastq/' 2>/dev/null`\n      zcat \\$f |head -n 4000000 |tail -n 400000 >\\$fqs\n    else\n      fqs=`echo \\$f |perl -pi -e 's/(fq|fastq)\\$/ds.fastq/' 2>/dev/null`\n      cat \\$f |head -n 4000000 |tail -n 400000 >\\$fqs\n    fi\n    \n    fastq_screen \\\n      --threads ${task.cpus} --force \\\n      --aligner bwa \\$fqs \\\n      --conf conf.txt\n  done\n  \"\"\"\n  }",
        "nb_lignes_process": 42,
        "string_script": "  \"\"\"\n  ##Make FastqScreen config file\n  echo \"# This is a config file for FastQ Screen\\n\\n\" >conf.txt\n  echo \"THREADS ${task.cpus}\\n\\n\" >>conf.txt\n\n  gList=\"${params.genomes2screen}\"\n  g2use=\\${gList//,/\\$'\\n'}\n\n  for g in \\$g2use; do\n    echo \"DATABASE \\$g \\$NXF_GENOMES/\\$g/BWAIndex/version0.7.10/genome.fa\" >>conf.txt\n  done\n\n  for f in *.R1.fastq*; do\n    if [[ \"\\$f\" =~ \"q.gz\" ]]; then\n      fqs=`echo \\$f |perl -pi -e 's/(fq|fastq).gz/ds.fastq/' 2>/dev/null`\n      zcat \\$f |head -n 4000000 |tail -n 400000 >\\$fqs\n    else\n      fqs=`echo \\$f |perl -pi -e 's/(fq|fastq)\\$/ds.fastq/' 2>/dev/null`\n      cat \\$f |head -n 4000000 |tail -n 400000 >\\$fqs\n    fi\n    \n    fastq_screen \\\n      --threads ${task.cpus} --force \\\n      --aligner bwa \\$fqs \\\n      --conf conf.txt\n  done\n  \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag {\"${params.name}\"}",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true"
        ],
        "when": "!(\"${workflow.scriptName}\" =~ /commit/)",
        "stub": ""
    },
    "bwa4D": {
        "name_process": "bwa4D",
        "string_process": "\nprocess bwa4D {\n  tag { fq1 }\n\n  publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*bam', enabled: params.saveBAM\n\n  input:\n  tuple(val(id), val(sample), val(rep), val(bio), path(fq1), path(fq2))\n\n  output:\n  tuple(val(sample), val(rep), val(bio), path('*BWAinit.bam'))\n\n  script:\n  def nm = fq1.name.replaceAll(\"R1.(\\\\d+).fastq.gz\",\"\\$1\")\n                                                        \n  \"\"\"\n  #ln -s ${fq1} fastq1.gz\n  #ln -s ${fq2} fastq2.gz\n\n  bwa mem \\\n    -t ${task.cpus} \\\n    -SP5M \\\n    ${params.bwaidx} \\\n    ${fq1} ${fq2} | samtools view -Shb -o ${nm}.BWAinit.bam -\n  \"\"\"\n  }",
        "nb_lignes_process": 24,
        "string_script": "  def nm = fq1.name.replaceAll(\"R1.(\\\\d+).fastq.gz\",\"\\$1\")\n                                                        \n  \"\"\"\n  #ln -s ${fq1} fastq1.gz\n  #ln -s ${fq2} fastq2.gz\n\n  bwa mem \\\n    -t ${task.cpus} \\\n    -SP5M \\\n    ${params.bwaidx} \\\n    ${fq1} ${fq2} | samtools view -Shb -o ${nm}.BWAinit.bam -\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "id",
            "sample",
            "rep",
            "bio",
            "fq1",
            "fq2"
        ],
        "nb_inputs": 6,
        "outputs": [
            "bio"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { fq1 }",
            "publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*bam', enabled: params.saveBAM"
        ],
        "when": "",
        "stub": ""
    },
    "bowtie2_end2end": {
        "name_process": "bowtie2_end2end",
        "string_process": "\nprocess bowtie2_end2end {\n  tag { fq1 }\n\n  input:\n  tuple(val(id), val(sample), val(rep), val(bio), path(fq1), path(fq2))\n  val(trim)\n  val(removeUnaligned)\n\n  output:\n  tuple(val(sample), val(rep), val(bio), val(fq1.name), val('R1'), path('*R1*endtoend.bam'), emit: bamR1)\n  tuple(val(sample), val(rep), val(bio), val(fq1.name), val('R2'), path('*R2*endtoend.bam'), emit: bamR2)\n  tuple(val(sample), val(rep), val(bio), val(fq1.name), val('R1'), path('*R1*.unmap.fastq'), emit: unmappedR1)\n  tuple(val(sample), val(rep), val(bio), val(fq1.name), val('R2'), path('*R2*.unmap.fastq'), emit: unmappedR2)\n\n  script:\n  def nm = fq1.name.replaceAll(\"R1.(\\\\d+).fastq\",\"\\$1\")\n  \"\"\"\n  if [ \"${trim}\" -gt 0 ]; then\n    zcat ${fq1} |perl -lane 'chomp; \\$l++; if (\\$l == 1 || \\$l == 3){\\$out = \\$_}else{\\$out = substr(\\$_,1,${trim})}; print \\$out; \\$l=(\\$l==4)?0:\\$l' >R1.fastq\n    zcat ${fq2} |perl -lane 'chomp; \\$l++; if (\\$l == 1 || \\$l == 3){\\$out = \\$_}else{\\$out = substr(\\$_,1,${trim})}; print \\$out; \\$l=(\\$l==4)?0:\\$l' >R2.fastq\n    name=\"${nm}_BOWTIE_trim${trim}\"\n  else\n    ln -s ${fq1} R1.fastq.gz\n    ln -s ${fq2} R2.fastq.gz\n    name=\"${nm}_BOWTIE${trim}\"\n  fi\n\n  if [ ${removeUnaligned} -eq 0 ]; then\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n        \t--very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R1.unmap.fastq\" \\\\\n        \t-U R1.fastq  | samtools view -bS - > \\${name}\".R1.bowtie_endtoend.bam\"\n\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n        \t--very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R2.unmap.fastq\" \\\\\n        \t-U R2.fastq  | samtools view -bS - > \\${name}\".R2.bowtie_endtoend.bam\"\n  else\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n          --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R1.unmap.fastq\" \\\\\n          -U R1.fastq  | samtools view -F 4 -bS - > \\${name}\".R1.bowtie_endtoend.bam\"\n\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n          --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R2.unmap.fastq\" \\\\\n          -U R2.fastq  | samtools view -F 4 -bS - > \\${name}\".R2.bowtie_endtoend.bam\"\n  fi\n  rm R1.fastq R2.fastq\n\n  \"\"\"\n  }",
        "nb_lignes_process": 59,
        "string_script": "  def nm = fq1.name.replaceAll(\"R1.(\\\\d+).fastq\",\"\\$1\")\n  \"\"\"\n  if [ \"${trim}\" -gt 0 ]; then\n    zcat ${fq1} |perl -lane 'chomp; \\$l++; if (\\$l == 1 || \\$l == 3){\\$out = \\$_}else{\\$out = substr(\\$_,1,${trim})}; print \\$out; \\$l=(\\$l==4)?0:\\$l' >R1.fastq\n    zcat ${fq2} |perl -lane 'chomp; \\$l++; if (\\$l == 1 || \\$l == 3){\\$out = \\$_}else{\\$out = substr(\\$_,1,${trim})}; print \\$out; \\$l=(\\$l==4)?0:\\$l' >R2.fastq\n    name=\"${nm}_BOWTIE_trim${trim}\"\n  else\n    ln -s ${fq1} R1.fastq.gz\n    ln -s ${fq2} R2.fastq.gz\n    name=\"${nm}_BOWTIE${trim}\"\n  fi\n\n  if [ ${removeUnaligned} -eq 0 ]; then\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n        \t--very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R1.unmap.fastq\" \\\\\n        \t-U R1.fastq  | samtools view -bS - > \\${name}\".R1.bowtie_endtoend.bam\"\n\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n        \t--very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R2.unmap.fastq\" \\\\\n        \t-U R2.fastq  | samtools view -bS - > \\${name}\".R2.bowtie_endtoend.bam\"\n  else\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n          --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R1.unmap.fastq\" \\\\\n          -U R1.fastq  | samtools view -F 4 -bS - > \\${name}\".R1.bowtie_endtoend.bam\"\n\n    bowtie2 --rg-id BMG --rg SM:bowtiealn \\\\\n          --very-sensitive -L 30 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\\\n          -p ${task.cpus} \\\\\n          -x ${params.bt2idx} \\\\\n          --un \\${name}\".bowtie.R2.unmap.fastq\" \\\\\n          -U R2.fastq  | samtools view -F 4 -bS - > \\${name}\".R2.bowtie_endtoend.bam\"\n  fi\n  rm R1.fastq R2.fastq\n\n  \"\"\"",
        "nb_lignes_script": 43,
        "language_script": "bash",
        "tools": [
            "Rbowtie2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/rbowtie2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "id",
            "sample",
            "rep",
            "bio",
            "fq1",
            "fq2",
            "trim",
            "removeUnaligned"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { fq1 }"
        ],
        "when": "",
        "stub": ""
    },
    "trim_hic_reads": {
        "name_process": "trim_hic_reads",
        "string_process": "\nprocess trim_hic_reads {\n\n  input:\n  tuple(val(sample), val(rep), val(bio), val(name), val(read), path(fq))\n\n  output:\n  tuple(val(sample), val(rep), val(bio), val(name), val(read), path(\"*trimmed.fastq\"))\n\n  script:\n  def outfq=fq.name.replaceFirst('unmap.fastq.*','trimmed.fastq')\n  \"\"\"\n  /HiC-Pro_3.0.0/scripts/cutsite_trimming --fastq ${fq} \\\\\n                   --cutsite  ${params.ligation_site} \\\\\n                   --out ${outfq}\n  \"\"\"\n  }",
        "nb_lignes_process": 15,
        "string_script": "  def outfq=fq.name.replaceFirst('unmap.fastq.*','trimmed.fastq')\n  \"\"\"\n  /HiC-Pro_3.0.0/scripts/cutsite_trimming --fastq ${fq} \\\\\n                   --cutsite  ${params.ligation_site} \\\\\n                   --out ${outfq}\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "rep",
            "bio",
            "name",
            "read",
            "fq"
        ],
        "nb_inputs": 6,
        "outputs": [
            "read"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "bowtie2_on_trimmed_reads": {
        "name_process": "bowtie2_on_trimmed_reads",
        "string_process": "\nprocess bowtie2_on_trimmed_reads {\n\n  input:\n  tuple(val(sample), val(rep), val(bio), val(name), val(read), path(fq))\n\n  output:\n  tuple(val(sample), val(rep), val(bio), val(name), val(read), path(\"*bam\"))\n\n  script:\n  def bam=fq.name.replaceFirst('trimmed.fastq.*','trimmed.bam')\n  \"\"\"\n  bowtie2 --rg-id BMG --rg SM:${bam} \\\n          --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\n          -p ${task.cpus} \\\n          -x ${params.bt2idx} \\\n          -U ${fq} | samtools view -bS - > ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 17,
        "string_script": "  def bam=fq.name.replaceFirst('trimmed.fastq.*','trimmed.bam')\n  \"\"\"\n  bowtie2 --rg-id BMG --rg SM:${bam} \\\n          --very-sensitive -L 20 --score-min L,-0.6,-0.2 --end-to-end --reorder \\\n          -p ${task.cpus} \\\n          -x ${params.bt2idx} \\\n          -U ${fq} | samtools view -bS - > ${bam}\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Rbowtie2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/rbowtie2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample",
            "rep",
            "bio",
            "name",
            "read",
            "fq"
        ],
        "nb_inputs": 6,
        "outputs": [
            "read"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "bowtie2_mergeR1R2": {
        "name_process": "bowtie2_mergeR1R2",
        "string_process": "\nprocess bowtie2_mergeR1R2{\n\n  input:\n  tuple(val(sample), val(rep), val(bio), val(name), val(read), path(bams))\n\n  output:\n  tuple(val(sample), val(rep), val(bio), val(name), path(\"*merged.bam\"), emit: bam)\n\n  script:\n  def nm = name.replaceAll(\"R1.(\\\\d+).fastq.*\",\"\\$1\")\n  def outbam=\"${nm}.${read}.merged.bam\"\n  \"\"\"\n  samtools merge -@ ${task.cpus} \\\n               -f tmp.bam \\\n             ${bams[0]} ${bams[1]}\n\n  samtools sort -@ ${task.cpus} -m 800M \\\n  \t              -n -T \\$TMPDIR \\\n                  -o ${outbam} \\\n                  tmp.bam\n  \"\"\"\n  }",
        "nb_lignes_process": 21,
        "string_script": "  def nm = name.replaceAll(\"R1.(\\\\d+).fastq.*\",\"\\$1\")\n  def outbam=\"${nm}.${read}.merged.bam\"\n  \"\"\"\n  samtools merge -@ ${task.cpus} \\\n               -f tmp.bam \\\n             ${bams[0]} ${bams[1]}\n\n  samtools sort -@ ${task.cpus} -m 800M \\\n  \t              -n -T \\$TMPDIR \\\n                  -o ${outbam} \\\n                  tmp.bam\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample",
            "rep",
            "bio",
            "name",
            "read",
            "bams"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "bowtie2_make_paired_bam": {
        "name_process": "bowtie2_make_paired_bam",
        "string_process": "\nprocess bowtie2_make_paired_bam{\n\n  tag { fqName.replaceFirst(\".fastq.*\",\"\") }\n\n  publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*bam', enabled: params.saveBAM\n\n  input:\n  tuple(val(sample), val(rep), val(bio), val(fqName), path(read1), path(read2))\n\n  output:\n  tuple(val(sample), val(rep), val(bio), path('*bt2.bam'))\n\n  script:\n  def opts = \" -t --single --multi -q 10 \"\n  def name = fqName.replaceFirst(\".fastq.*\",\"\")\n  \"\"\"\n  /HiC-Pro_3.0.0/scripts/mergeSAM.py -f ${read1} -r ${read2} -o ${name}.bt2.bam ${opts}\n\n  #/HiC-Pro_3.0.0/scripts/mergeSAM.py -f \\${name}\".R1.bowtie_endtoend.bam\" -r \\${name}\".R2.bowtie_endtoend.bam\" -o \\$name\".bwt2.bam\" -q 0 -t bowtie.stat\n  \"\"\"\n  }",
        "nb_lignes_process": 20,
        "string_script": "  def opts = \" -t --single --multi -q 10 \"\n  def name = fqName.replaceFirst(\".fastq.*\",\"\")\n  \"\"\"\n  /HiC-Pro_3.0.0/scripts/mergeSAM.py -f ${read1} -r ${read2} -o ${name}.bt2.bam ${opts}\n\n  #/HiC-Pro_3.0.0/scripts/mergeSAM.py -f \\${name}\".R1.bowtie_endtoend.bam\" -r \\${name}\".R2.bowtie_endtoend.bam\" -o \\$name\".bwt2.bam\" -q 0 -t bowtie.stat\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "rep",
            "bio",
            "fqName",
            "read1",
            "read2"
        ],
        "nb_inputs": 6,
        "outputs": [
            "bio"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { fqName.replaceFirst(\".fastq.*\",\"\") }",
            "publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*bam', enabled: params.saveBAM"
        ],
        "when": "",
        "stub": ""
    },
    "fixMDtags": {
        "name_process": "fixMDtags",
        "string_process": "\nprocess fixMDtags {\n  tag { bam.name.replaceFirst(\".bt2.bam\",\"\") }\n\n                                                                    \n\n  input:\n  tuple(val(sample), val(rep), val(bio), path(bam))\n\n  output:\n  tuple(val(sample), val(rep), val(bio), path('*qSort.bam'), emit:bam)\n\n  script:\n  def bamname = bam.name.replaceFirst(\".bam\",\"\")\n  \"\"\"\n  ## NOTE LENIENT IS REQUIRED BECAUSE THE FLAGS INTRODUCED BY HiCPro BOWTIE ALIGNMENT\n  ## ARE FLAGGED AS ERRORS BY PICARD\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/picard/picard.jar SortSam \\\n                -SO coordinate \\\n                -I ${bam} \\\n                --VALIDATION_STRINGENCY LENIENT \\\n                -O ${bamname}.sorted.bam\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/picard/picard.jar SetNmMdAndUqTags \\\n                -R ${params.fasta} \\\n                -I ${bamname}.sorted.bam \\\n                -O ${bamname}.MDfixed.bam \\\n                --VALIDATION_STRINGENCY LENIENT\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/picard/picard.jar SortSam \\\n                -SO queryname \\\n                -I ${bamname}.MDfixed.bam \\\n                -O ${bamname}.qSort.bam \\\n                --VALIDATION_STRINGENCY LENIENT\n  \"\"\"\n  }",
        "nb_lignes_process": 35,
        "string_script": "  def bamname = bam.name.replaceFirst(\".bam\",\"\")\n  \"\"\"\n  ## NOTE LENIENT IS REQUIRED BECAUSE THE FLAGS INTRODUCED BY HiCPro BOWTIE ALIGNMENT\n  ## ARE FLAGGED AS ERRORS BY PICARD\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/picard/picard.jar SortSam \\\n                -SO coordinate \\\n                -I ${bam} \\\n                --VALIDATION_STRINGENCY LENIENT \\\n                -O ${bamname}.sorted.bam\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/picard/picard.jar SetNmMdAndUqTags \\\n                -R ${params.fasta} \\\n                -I ${bamname}.sorted.bam \\\n                -O ${bamname}.MDfixed.bam \\\n                --VALIDATION_STRINGENCY LENIENT\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/picard/picard.jar SortSam \\\n                -SO queryname \\\n                -I ${bamname}.MDfixed.bam \\\n                -O ${bamname}.qSort.bam \\\n                --VALIDATION_STRINGENCY LENIENT\n  \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "rep",
            "bio",
            "bam"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { bam.name.replaceFirst(\".bt2.bam\",\"\") }"
        ],
        "when": "",
        "stub": ""
    },
    "markAlleleOfOrigin": {
        "name_process": "markAlleleOfOrigin",
        "string_process": "\nprocess markAlleleOfOrigin {\n  tag { bam.name.replaceFirst(\".bt2.qSort.bam\",\"\") }\n\n  publishDir \"${params.outdir}/bam\",     mode: 'copy', overwrite: true, pattern: \"*phased.bam\", enabled: params.saveBAM\n                                                                                                           \n\n  input:\n  tuple(val(sample), val(rep), val(bio), path(bam))\n\n  output:\n  tuple(val(sample), val(rep), val(bio), path('*bam'), emit: bam)\n  tuple(val(\"${sample}_${bio}\"), path('*markallelicstatus.txt'), emit: rep)\n  tuple(val(\"${sample}_${bio}\"), path('*allelic_stats.txt'), emit: report)\n\n  script:\n  def outbam = bam.name.replaceFirst(\".bam\",\".phased.bam\")\n  def tmprep = bam.name.replaceFirst(\".bam\",\".phased.allelstat\")\n  def outrep = bam.name.replaceFirst(\".bam\",\".phased.markallelicstatus.txt\")\n  def outmqc = bam.name.replaceFirst(\".bam\",\".allelic_stats.txt\")\n  \"\"\"\n  echo \"${sample}${rep}${bio}\"\n\n  ##Bugs in reporting - use custom script instead\n  ##/HiC-Pro_3.0.0/scripts/markAllelicStatus.py -i ${bam} -s ${params.vcf} -r |samtools view -Shb - > ${outbam}\n\n  python /usr/local/hicpro/scripts/markAllelicStatus.py -i ${bam} -s ${params.vcf} -r -o ${outbam}\n\n  grep    allelic_status ${tmprep}                      >${outmqc}\n  grep -v allelic_status ${tmprep} |grep -v FOR-MULTIQC >${outrep}\n  \"\"\"\n  }",
        "nb_lignes_process": 30,
        "string_script": "  def outbam = bam.name.replaceFirst(\".bam\",\".phased.bam\")\n  def tmprep = bam.name.replaceFirst(\".bam\",\".phased.allelstat\")\n  def outrep = bam.name.replaceFirst(\".bam\",\".phased.markallelicstatus.txt\")\n  def outmqc = bam.name.replaceFirst(\".bam\",\".allelic_stats.txt\")\n  \"\"\"\n  echo \"${sample}${rep}${bio}\"\n\n  ##Bugs in reporting - use custom script instead\n  ##/HiC-Pro_3.0.0/scripts/markAllelicStatus.py -i ${bam} -s ${params.vcf} -r |samtools view -Shb - > ${outbam}\n\n  python /usr/local/hicpro/scripts/markAllelicStatus.py -i ${bam} -s ${params.vcf} -r -o ${outbam}\n\n  grep    allelic_status ${tmprep}                      >${outmqc}\n  grep -v allelic_status ${tmprep} |grep -v FOR-MULTIQC >${outrep}\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample",
            "rep",
            "bio",
            "bam"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { bam.name.replaceFirst(\".bt2.qSort.bam\",\"\") }",
            "publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: \"*phased.bam\", enabled: params.saveBAM"
        ],
        "when": "",
        "stub": ""
    },
    "pairsam": {
        "name_process": "pairsam",
        "string_process": "\nprocess pairsam {\n\n  tag { bam.name.replaceFirst(\".bt2.qSort.phased.bam\",\"\") }\n\n  input:\n  tuple(val(sample), val(rep), val(bio), path(bam))\n\n  output:\n  tuple(val({ (bio == 'NA') ? \"${sample}\" : \"${sample}_${bio}\"} ), path('*.sam.pairs.gz'), emit: pairs)\n  tuple(val({ (bio == 'NA') ? \"${sample}\" : \"${sample}_${bio}\"} ), path('*.stat.txt'), emit: rep)\n\n  script:\n  def initpairs   = bam.name.replaceFirst(\".bam\",\".initpairs.gz\")\n  def initpairsOK = bam.name.replaceFirst(\".bam\",\".initpairsOK\")\n  def pairs       = bam.name.replaceFirst(\".bam\",\".sam.pairs.gz\")\n  def pairstat    = bam.name.replaceFirst(\".bam\",\".sam.pairsam.stat.txt\")\n  def samcols     = (params.phased)?\"mapq,XA,MD\":\"mapq\"\n  \"\"\"\n  #!/bin/bash\n\n  # Classify Hi-C molecules as unmapped/single-sided/multimapped/chimeric/etc\n  # and output one line per read, containing the following, separated by \\\\v:\n  #  * true-flipped pairs\n  #  * read id\n  #  * type of a Hi-C molecule\n  #  * corresponding sam entries\n\n  samtools view -h ${bam} | pairtools parse -c ${params.fai} \\\n    --output-stats ${pairstat} \\\n    --add-columns ${samcols} \\\n    -o ${initpairs}\n\n  ## The output of pairtools parse does not account for missing fields. This messes\n  ## things up later. Here, we do a small cleanup, replacing missing fields with NA\n\n  ## First, get the header - use perl to prevent the need to go through whole file with grep\n  zcat ${initpairs} |perl -lane 'exit if (\\$_ !~ /^#/);print \\$_' >${initpairsOK}\n\n  ## Get the number of expected columns\n  ncols=`grep ^#columns ${initpairsOK} |perl -lane 'print \\$#F'`\n\n  ## Pad out gaps with NA\n  zcat ${initpairs}|grep -v ^# |\n      perl  -pe 's/\\\\t(?=\\\\t)/\\\\tNA/g' | ##This line does adjacent gaps\n      perl -lane 'print \\$_.(\"\\\\tNA\" x ('\\$ncols'-\\$#F-1))' >>${initpairsOK} ## This line does gaps at the end of the line\n\n  cat ${initpairsOK} | pairtools sort --nproc ${task.cpus} \\\n    --compress-program lz4c \\\n    --tmpdir ${TMPDIR} \\\n    --output ${pairs}\n  \"\"\"\n  }",
        "nb_lignes_process": 51,
        "string_script": "  def initpairs   = bam.name.replaceFirst(\".bam\",\".initpairs.gz\")\n  def initpairsOK = bam.name.replaceFirst(\".bam\",\".initpairsOK\")\n  def pairs       = bam.name.replaceFirst(\".bam\",\".sam.pairs.gz\")\n  def pairstat    = bam.name.replaceFirst(\".bam\",\".sam.pairsam.stat.txt\")\n  def samcols     = (params.phased)?\"mapq,XA,MD\":\"mapq\"\n  \"\"\"\n  #!/bin/bash\n\n  # Classify Hi-C molecules as unmapped/single-sided/multimapped/chimeric/etc\n  # and output one line per read, containing the following, separated by \\\\v:\n  #  * true-flipped pairs\n  #  * read id\n  #  * type of a Hi-C molecule\n  #  * corresponding sam entries\n\n  samtools view -h ${bam} | pairtools parse -c ${params.fai} \\\n    --output-stats ${pairstat} \\\n    --add-columns ${samcols} \\\n    -o ${initpairs}\n\n  ## The output of pairtools parse does not account for missing fields. This messes\n  ## things up later. Here, we do a small cleanup, replacing missing fields with NA\n\n  ## First, get the header - use perl to prevent the need to go through whole file with grep\n  zcat ${initpairs} |perl -lane 'exit if (\\$_ !~ /^#/);print \\$_' >${initpairsOK}\n\n  ## Get the number of expected columns\n  ncols=`grep ^#columns ${initpairsOK} |perl -lane 'print \\$#F'`\n\n  ## Pad out gaps with NA\n  zcat ${initpairs}|grep -v ^# |\n      perl  -pe 's/\\\\t(?=\\\\t)/\\\\tNA/g' | ##This line does adjacent gaps\n      perl -lane 'print \\$_.(\"\\\\tNA\" x ('\\$ncols'-\\$#F-1))' >>${initpairsOK} ## This line does gaps at the end of the line\n\n  cat ${initpairsOK} | pairtools sort --nproc ${task.cpus} \\\n    --compress-program lz4c \\\n    --tmpdir ${TMPDIR} \\\n    --output ${pairs}\n  \"\"\"",
        "nb_lignes_script": 38,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "sample",
            "rep",
            "bio",
            "bam"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { bam.name.replaceFirst(\".bt2.qSort.phased.bam\",\"\") }"
        ],
        "when": "",
        "stub": ""
    },
    "mergepairs_dedup": {
        "name_process": "mergepairs_dedup",
        "string_process": "\nprocess mergepairs_dedup {\n\n  tag { grp }\n\n  publishDir \"${params.outdir}/pairs/dedup\",   mode: 'copy', overwrite: true, pattern: '*pairs*', enabled: params.saveAllPairs\n\n  input:\n  tuple(val(grp), path(pairsGZ))\n\n  output:\n                                                                                                \n  tuple(val(grp), path('*.all.pairs.gz'), path('*.all.pairs.gz.px2'))\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  ### MERGE SEQUENCING REPLICATES AND\n  ### MARK DUPLICATES\n  nmax=`ls *pairs.gz |wc -l`\n\n  pairtools merge --max-nmerge \\$nmax --nproc ${task.cpus} --memory  ${task.memory} --output ${grp}.merged.sam.pairs.gz ${pairsGZ}\n  pairtools dedup --mark-dups --output-dups - --output-unmapped - --output ${grp}.dedup.all.pairs.gz ${grp}.merged.sam.pairs.gz\n\n  pairix ${grp}.dedup.all.pairs.gz\n  \"\"\"\n  }",
        "nb_lignes_process": 25,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  ### MERGE SEQUENCING REPLICATES AND\n  ### MARK DUPLICATES\n  nmax=`ls *pairs.gz |wc -l`\n\n  pairtools merge --max-nmerge \\$nmax --nproc ${task.cpus} --memory  ${task.memory} --output ${grp}.merged.sam.pairs.gz ${pairsGZ}\n  pairtools dedup --mark-dups --output-dups - --output-unmapped - --output ${grp}.dedup.all.pairs.gz ${grp}.merged.sam.pairs.gz\n\n  pairix ${grp}.dedup.all.pairs.gz\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "grp",
            "pairsGZ"
        ],
        "nb_inputs": 2,
        "outputs": [
            "grp"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }",
            "publishDir \"${params.outdir}/pairs/dedup\", mode: 'copy', overwrite: true, pattern: '*pairs*', enabled: params.saveAllPairs"
        ],
        "when": "",
        "stub": ""
    },
    "pairs_to_bam": {
        "name_process": "pairs_to_bam",
        "string_process": "\nprocess pairs_to_bam {\n\n  tag { grp }\n\n  input:\n  tuple(val(id), val(grp), path(pairsGZ))\n\n  output:\n  tuple(val(id), val(grp), path('*.bam'))\n\n  script:\n  def bam=pairsGZ.name.replaceFirst(\"pairs.gz\",\"bam\")\n  \"\"\"\n  #!/bin/bash\n  pairtools split ${pairsGZ} --output-pairs pairs.gz --output-sam pairs.sam\n  samtools view -Shb pairs.sam >${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 17,
        "string_script": "  def bam=pairsGZ.name.replaceFirst(\"pairs.gz\",\"bam\")\n  \"\"\"\n  #!/bin/bash\n  pairtools split ${pairsGZ} --output-pairs pairs.gz --output-sam pairs.sam\n  samtools view -Shb pairs.sam >${bam}\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "id",
            "grp",
            "pairsGZ"
        ],
        "nb_inputs": 3,
        "outputs": [
            "grp"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }"
        ],
        "when": "",
        "stub": ""
    },
    "clean_dnase_bam": {
        "name_process": "clean_dnase_bam",
        "string_process": "\nprocess clean_dnase_bam {\n\n  tag { grp }\n\n  publishDir \"${params.outdir}/dnase\",   mode: 'copy', overwrite: true, pattern: '*dnase.bam*'\n\n  input:\n  tuple(val(sample), val(grp), path(pairsBAM))\n\n  output:\n  tuple(val(sample), val(grp), path('*.dnase.bam'), path('*.dnase.bam.bai'))\n\n  shell:\n  outBAM = pairsBAM.name.replaceFirst(\"bam\",\"dnase.bam\")\n  tmpBAM = pairsBAM.name.replaceFirst(\"bam\",\"tmp.bam\")\n  '''\n  #!/usr/bin/env python\n  import pysam\n  import argparse\n  import re\n\n  inBAM  =\"!{pairsBAM}\"\n  tmpBAM =\"!{tmpBAM}\"\n  outBAM =\"!{outBAM}\"\n\n  if re.search(\".bam\",inBAM):\n      samfile = pysam.AlignmentFile(inBAM, \"rb\")\n  else:\n      if re.search(\".sam\",inBAM):\n          samfile = pysam.AlignmentFile(inBAM, \"r\")\n\n  bamfile = pysam.AlignmentFile(tmpBAM, \"wb\", template=samfile)\n\n  for read in samfile:\n      if read.is_paired:\n          if (read.is_read1):\n              read.is_paired=False\n              read.is_proper_pair=False\n              read.is_read1=False\n              read.is_read2=False\n              read.mate_is_reverse=False\n              read.mate_is_unmapped=False\n              read.next_reference_id=-1\n              read.next_reference_start=-1\n              read.template_length=-1\n\n              bamfile.write(read)\n\n  samfile.close()\n  bamfile.close()\n\n  pysam.sort(\"-o\",outBAM,tmpBAM)\n  pysam.index(outBAM)\n\n  '''\n  }",
        "nb_lignes_process": 55,
        "string_script": "  outBAM = pairsBAM.name.replaceFirst(\"bam\",\"dnase.bam\")\n  tmpBAM = pairsBAM.name.replaceFirst(\"bam\",\"tmp.bam\")\n  '''\n  #!/usr/bin/env python\n  import pysam\n  import argparse\n  import re\n\n  inBAM  =\"!{pairsBAM}\"\n  tmpBAM =\"!{tmpBAM}\"\n  outBAM =\"!{outBAM}\"\n\n  if re.search(\".bam\",inBAM):\n      samfile = pysam.AlignmentFile(inBAM, \"rb\")\n  else:\n      if re.search(\".sam\",inBAM):\n          samfile = pysam.AlignmentFile(inBAM, \"r\")\n\n  bamfile = pysam.AlignmentFile(tmpBAM, \"wb\", template=samfile)\n\n  for read in samfile:\n      if read.is_paired:\n          if (read.is_read1):\n              read.is_paired=False\n              read.is_proper_pair=False\n              read.is_read1=False\n              read.is_read2=False\n              read.mate_is_reverse=False\n              read.mate_is_unmapped=False\n              read.next_reference_id=-1\n              read.next_reference_start=-1\n              read.template_length=-1\n\n              bamfile.write(read)\n\n  samfile.close()\n  bamfile.close()\n\n  pysam.sort(\"-o\",outBAM,tmpBAM)\n  pysam.index(outBAM)\n\n  '''",
        "nb_lignes_script": 41,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "grp",
            "pairsBAM"
        ],
        "nb_inputs": 3,
        "outputs": [
            "grp"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }",
            "publishDir \"${params.outdir}/dnase\", mode: 'copy', overwrite: true, pattern: '*dnase.bam*'"
        ],
        "when": "",
        "stub": ""
    },
    "make_mnase_bigwig": {
        "name_process": "make_mnase_bigwig",
        "string_process": "\nprocess make_mnase_bigwig {\n\n  tag { grp }\n  publishDir \"${params.outdir}/dnase\",   mode: 'copy', overwrite: true, pattern: '*bigwig'\n\n  input:\n  tuple(val(id), val(grp), path(bam), path(bai))\n\n  output:\n  path('*bigwig', emit: bigwig)\n\n  script:\n  def bigwig=bam.name.replaceFirst(\"bam\",\"bigwig\")\n  \"\"\"\n  #!/bin/bash\n  bamCoverage -b ${bam} --centerReads -p ${task.cpus} --minMappingQuality 20 --ignoreDuplicates --extendReads 150 --centerReads --binSize 10 -o ${bigwig}\n  \"\"\"\n  }",
        "nb_lignes_process": 17,
        "string_script": "  def bigwig=bam.name.replaceFirst(\"bam\",\"bigwig\")\n  \"\"\"\n  #!/bin/bash\n  bamCoverage -b ${bam} --centerReads -p ${task.cpus} --minMappingQuality 20 --ignoreDuplicates --extendReads 150 --centerReads --binSize 10 -o ${bigwig}\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "id",
            "grp",
            "bam",
            "bai"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }",
            "publishDir \"${params.outdir}/dnase\", mode: 'copy', overwrite: true, pattern: '*bigwig'"
        ],
        "when": "",
        "stub": ""
    },
    "filter_pairs": {
        "name_process": "filter_pairs",
        "string_process": "\nprocess filter_pairs {\n\n  tag { grp }\n\n  publishDir \"${params.outdir}/pairs/filtered\",   mode: 'copy', overwrite: true, pattern: '*filtered.pair*'\n\n  input:\n  tuple(val(grp), path(pairs), path(idx))\n\n  output:\n  tuple(val(grp), path('*.filtered.pairs.gz'), path('*.filtered.pairs.gz.px2'))\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  ### FILTER PAIRSSAM FILE\n  ## Generate lossless bam\n  pairtools split --output-sam ${grp}.lossless.bam ${pairs}\n\n  # Select UU, UR, RU reads\n  pairtools select '(pair_type == \"UU\") or (pair_type == \"UR\") or (pair_type == \"RU\")' \\\n      --output-rest ${grp}.unmapped.sam.pairs.gz \\\n      --output temp.gz \\\n      ${pairs}\n\n  pairtools split --output-pairs temp1.gz temp.gz\n  pairtools select 'True' --chrom-subset ${params.fai} -o ${grp}.filtered.pairs.gz temp1.gz\n  pairix ${grp}.filtered.pairs.gz\n\n  \"\"\"\n  }",
        "nb_lignes_process": 30,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  ### FILTER PAIRSSAM FILE\n  ## Generate lossless bam\n  pairtools split --output-sam ${grp}.lossless.bam ${pairs}\n\n  # Select UU, UR, RU reads\n  pairtools select '(pair_type == \"UU\") or (pair_type == \"UR\") or (pair_type == \"RU\")' \\\n      --output-rest ${grp}.unmapped.sam.pairs.gz \\\n      --output temp.gz \\\n      ${pairs}\n\n  pairtools split --output-pairs temp1.gz temp.gz\n  pairtools select 'True' --chrom-subset ${params.fai} -o ${grp}.filtered.pairs.gz temp1.gz\n  pairix ${grp}.filtered.pairs.gz\n\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "grp",
            "pairs",
            "idx"
        ],
        "nb_inputs": 3,
        "outputs": [
            "grp"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }",
            "publishDir \"${params.outdir}/pairs/filtered\", mode: 'copy', overwrite: true, pattern: '*filtered.pair*'"
        ],
        "when": "",
        "stub": ""
    },
    "pairtools_stats": {
        "name_process": "pairtools_stats",
        "string_process": "\nprocess pairtools_stats {\n\n  tag { grp }\n\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(grp), path(pairsGZ))\n\n  output:\n  path(\"*pairtools_report*\", emit: reports, optional: true)\n\n  script:\n                                                                                  \n  \"\"\"\n  #!/bin/bash\n  ## AVOID GENERATING PAIRS REPORTS FOR LESS THAN 1000 READS\n  ## CAN BE PROBLEMATIC\n  nreads=`zcat ${pairsGZ} |wc -l`\n  if [[ \"\\$nreads\" -gt 1000 ]]; then\n    pairtools stats -o ${grp}.pairtools_report.txt ${pairsGZ}\n  fi\n  \"\"\"\n  }",
        "nb_lignes_process": 23,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  ## AVOID GENERATING PAIRS REPORTS FOR LESS THAN 1000 READS\n  ## CAN BE PROBLEMATIC\n  nreads=`zcat ${pairsGZ} |wc -l`\n  if [[ \"\\$nreads\" -gt 1000 ]]; then\n    pairtools stats -o ${grp}.pairtools_report.txt ${pairsGZ}\n  fi\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "grp",
            "pairsGZ"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "splitByPhase": {
        "name_process": "splitByPhase",
        "string_process": "\nprocess splitByPhase {\n\n  tag { grp }\n\n  publishDir \"${params.outdir}/pairs/phased\",  mode: 'copy', overwrite: true, pattern: '*pairs*'\n  publishDir \"${params.outdir}/reports\"      , mode: 'copy', overwrite: true, pattern: '*pairstats.txt'\n\n  input:\n  tuple(val(grp), path(pairs), path(pairsIDX))\n\n  output:\n  tuple(val(grp), path('*.phased.*.pairs.gz'), path('*.phased.*.pairs.gz.px2'), emit: pairs)\n  tuple(val(grp), path('*.pairstats.txt'), emit: report)\n\n  script:\n  def pairsGT1=\"${grp}.phased.hom1.pairs.gz\"\n  def pairsGT2=\"${grp}.phased.hom2.pairs.gz\"\n  def pairsHET=\"${grp}.phased.het.pairs.gz\"\n  def pairsHOM=\"${grp}.phased.hom.pairs.gz\"\n  def pairs00=\"${grp}.00.gz\"\n  def pairs01=\"${grp}.01.gz\"\n  def pairs02=\"${grp}.02.gz\"\n  def pairsSTAT=\"${grp}.pairstats.txt\"\n  \"\"\"\n  #!/bin/bash\n  pairtools select '(chrom1 != \"!\") and (chrom2 != \"!\")' ${pairs}         --output aligned.pairs.gz\n  pairtools select 'XA1+XA2 == \"11\"'                     aligned.pairs.gz --output ${pairsGT1}\n  pairtools select 'XA1+XA2 == \"22\"'                     aligned.pairs.gz --output ${pairsGT2}\n  pairtools select 'XA1+XA2 in (\"12\",\"21\")'              aligned.pairs.gz --output ${pairsHET}\n  pairtools select 'XA1+XA2 not in (\"12\",\"21\")'          aligned.pairs.gz --output ${pairsHOM}\n  pairtools select 'XA1+XA2 in (\"00\")'                   aligned.pairs.gz --output ${pairs00}\n  pairtools select 'XA1+XA2 in (\"01\",\"10\")'              aligned.pairs.gz --output ${pairs01}\n  pairtools select 'XA1+XA2 in (\"02\",\"20\")'              aligned.pairs.gz --output ${pairs02}\n\n  for pairsGZ in ${pairsGT1} ${pairsGT2} ${pairsHET} ${pairsHOM}; do\n    n=`zcat \\$pairsGZ |grep -v ^# |head -n 1000 |wc -l`\n    if [[ \"\\$n\" -gt 0 ]]; then\n      pairix \\$pairsGZ\n    else\n      echo \"**** WARNING **** : No valid pairs for \\$pairsGZ\"\n      rm \\$pairsGZ\n    fi\n  done\n\n  ## Pair types report\n  n00=`zcat ${pairs00}  |grep -v ^# |wc -l`; echo -e \"allelic_pairs/0-0\\\\t\\$n00\" >>${pairsSTAT}\n  n01=`zcat ${pairs01}  |grep -v ^# |wc -l`; echo -e \"allelic_pairs/0-1\\\\t\\$n01\" >>${pairsSTAT}\n  n02=`zcat ${pairs02}  |grep -v ^# |wc -l`; echo -e \"allelic_pairs/0-2\\\\t\\$n02\" >>${pairsSTAT}\n  n11=`zcat ${pairsGT1} |grep -v ^# |wc -l`; echo -e \"allelic_pairs/1-1\\\\t\\$n11\" >>${pairsSTAT}\n  n12=`zcat ${pairsHET} |grep -v ^# |wc -l`; echo -e \"allelic_pairs/1-2\\\\t\\$n12\" >>${pairsSTAT}\n  n22=`zcat ${pairsGT2} |grep -v ^# |wc -l`; echo -e \"allelic_pairs/2-2\\\\t\\$n22\" >>${pairsSTAT}\n  \"\"\"\n  }",
        "nb_lignes_process": 52,
        "string_script": "  def pairsGT1=\"${grp}.phased.hom1.pairs.gz\"\n  def pairsGT2=\"${grp}.phased.hom2.pairs.gz\"\n  def pairsHET=\"${grp}.phased.het.pairs.gz\"\n  def pairsHOM=\"${grp}.phased.hom.pairs.gz\"\n  def pairs00=\"${grp}.00.gz\"\n  def pairs01=\"${grp}.01.gz\"\n  def pairs02=\"${grp}.02.gz\"\n  def pairsSTAT=\"${grp}.pairstats.txt\"\n  \"\"\"\n  #!/bin/bash\n  pairtools select '(chrom1 != \"!\") and (chrom2 != \"!\")' ${pairs}         --output aligned.pairs.gz\n  pairtools select 'XA1+XA2 == \"11\"'                     aligned.pairs.gz --output ${pairsGT1}\n  pairtools select 'XA1+XA2 == \"22\"'                     aligned.pairs.gz --output ${pairsGT2}\n  pairtools select 'XA1+XA2 in (\"12\",\"21\")'              aligned.pairs.gz --output ${pairsHET}\n  pairtools select 'XA1+XA2 not in (\"12\",\"21\")'          aligned.pairs.gz --output ${pairsHOM}\n  pairtools select 'XA1+XA2 in (\"00\")'                   aligned.pairs.gz --output ${pairs00}\n  pairtools select 'XA1+XA2 in (\"01\",\"10\")'              aligned.pairs.gz --output ${pairs01}\n  pairtools select 'XA1+XA2 in (\"02\",\"20\")'              aligned.pairs.gz --output ${pairs02}\n\n  for pairsGZ in ${pairsGT1} ${pairsGT2} ${pairsHET} ${pairsHOM}; do\n    n=`zcat \\$pairsGZ |grep -v ^# |head -n 1000 |wc -l`\n    if [[ \"\\$n\" -gt 0 ]]; then\n      pairix \\$pairsGZ\n    else\n      echo \"**** WARNING **** : No valid pairs for \\$pairsGZ\"\n      rm \\$pairsGZ\n    fi\n  done\n\n  ## Pair types report\n  n00=`zcat ${pairs00}  |grep -v ^# |wc -l`; echo -e \"allelic_pairs/0-0\\\\t\\$n00\" >>${pairsSTAT}\n  n01=`zcat ${pairs01}  |grep -v ^# |wc -l`; echo -e \"allelic_pairs/0-1\\\\t\\$n01\" >>${pairsSTAT}\n  n02=`zcat ${pairs02}  |grep -v ^# |wc -l`; echo -e \"allelic_pairs/0-2\\\\t\\$n02\" >>${pairsSTAT}\n  n11=`zcat ${pairsGT1} |grep -v ^# |wc -l`; echo -e \"allelic_pairs/1-1\\\\t\\$n11\" >>${pairsSTAT}\n  n12=`zcat ${pairsHET} |grep -v ^# |wc -l`; echo -e \"allelic_pairs/1-2\\\\t\\$n12\" >>${pairsSTAT}\n  n22=`zcat ${pairsGT2} |grep -v ^# |wc -l`; echo -e \"allelic_pairs/2-2\\\\t\\$n22\" >>${pairsSTAT}\n  \"\"\"",
        "nb_lignes_script": 36,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "grp",
            "pairs",
            "pairsIDX"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }",
            "publishDir \"${params.outdir}/pairs/phased\", mode: 'copy', overwrite: true, pattern: '*pairs*'",
            "publishDir \"${params.outdir}/reports\" , mode: 'copy', overwrite: true, pattern: '*pairstats.txt'"
        ],
        "when": "",
        "stub": ""
    },
    "pairsQC": {
        "name_process": "pairsQC",
        "string_process": "\nprocess pairsQC {\n\n  tag { grp }\n\n  publishDir \"${params.outdir}/reports\",     mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(sample), val(grp), path(pairs), path(idx))\n\n  output:\n  path('*.zip')\n\n  script:\n  \"\"\"\n  scriptdir=\"/usr/local/bin/pairsqc/\"\n\n  #if [ \"${params.genome}\" == \"mm10\" ]; then\n  #  max_distance=8.2\n  #else\n  #  max_distance=8.4\n  #fi\n\n  sort -k1,1 -V -s ${params.fai} >chrom_sizes.txt\n\n  max_distance=`sort -k2n,2n chrom_sizes.txt |tail -n1 |cut -f2 |perl -lane 'print sprintf(\"%2.1f\",((log(\\$_)/log(10))-0.05))'`\n\n  python3 \\$scriptdir/pairsqc.py -p ${pairs} -c chrom_sizes.txt -tP -s ${grp} -O ${grp} -M \\$max_distance\n\n  ## NOTE : Should be coded properly ... assumes a 4-cutter (4)\n  Rscript \\$scriptdir/plot.r 4 ${grp}_report\n\n  zip -r ${grp}_pairsQC_report.zip ${grp}_report\n\n  \"\"\"\n  }",
        "nb_lignes_process": 34,
        "string_script": "  \"\"\"\n  scriptdir=\"/usr/local/bin/pairsqc/\"\n\n  #if [ \"${params.genome}\" == \"mm10\" ]; then\n  #  max_distance=8.2\n  #else\n  #  max_distance=8.4\n  #fi\n\n  sort -k1,1 -V -s ${params.fai} >chrom_sizes.txt\n\n  max_distance=`sort -k2n,2n chrom_sizes.txt |tail -n1 |cut -f2 |perl -lane 'print sprintf(\"%2.1f\",((log(\\$_)/log(10))-0.05))'`\n\n  python3 \\$scriptdir/pairsqc.py -p ${pairs} -c chrom_sizes.txt -tP -s ${grp} -O ${grp} -M \\$max_distance\n\n  ## NOTE : Should be coded properly ... assumes a 4-cutter (4)\n  Rscript \\$scriptdir/plot.r 4 ${grp}_report\n\n  zip -r ${grp}_pairsQC_report.zip ${grp}_report\n\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "grp",
            "pairs",
            "idx"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { grp }",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "get_RE_file": {
        "name_process": "get_RE_file",
        "string_process": "\nprocess get_RE_file {\n\n  tag { params.re }\n\n  publishDir \"${params.outdir}/re\", mode: 'copy', overwrite: true\n\n  output:\n  path('*.txt')\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  python /usr/local/bin/juicer/misc/generate_site_positions.py ${params.re} genome ${params.fasta}\n\n  \"\"\"\n  }",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  python /usr/local/bin/juicer/misc/generate_site_positions.py ${params.re} genome ${params.fasta}\n\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { params.re }",
            "publishDir \"${params.outdir}/re\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "mergepairs_nodedup": {
        "name_process": "mergepairs_nodedup",
        "string_process": "\nprocess mergepairs_nodedup {\n\n  tag { sample }\n\n  publishDir \"${params.outdir}/pairs\", mode: 'copy', overwrite: true, enabled: params.dnase\n\n  input:\n  tuple(val(sample), path(pairs), path(idx))\n\n  output:\n  tuple(val(sample), path('*.pairs.gz'),path('*.pairs.gz.px2'))\n\n  script:\n  \"\"\"\n  #!/bin/bash\n\n  n=`ls *.pairs.gz | wc -l`\n\n  if [ \\$n -eq 1 ]\n  then\n      cp ${pairs} ${sample}.pairs.gz\n      pairix -f ${sample}.pairs.gz\n  else\n      # unzipping to named pipes\n      arg=''\n      k=1\n      for f in *.pairs.gz\n      do\n        mkfifo pp.\\$k\n        arg=\"\\$arg pp.\\$k\"\n        gunzip -c \\$f | grep -v '^#' > pp.\\$k &\n        let \"k++\"\n      done\n\n      # header\n      gunzip -c ${pairs[0]} | grep \"^#\" | grep -v '^#command:'  > ${sample}.pairs\n\n      for f in *.pairs.gz\n      do\n        gunzip -c \\$f | grep '^#command:' >> ${sample}.pairs\n      done\n\n      # merging\n      sort -m -k2,2 -k4,4 -k3,3g -k5,5g \\$arg >> ${sample}.pairs\n\n      # compressing\n      bgzip -f ${sample}.pairs\n\n      # indexing\n      pairix -f ${sample}.pairs.gz\n\n  fi\n  \"\"\"\n  }",
        "nb_lignes_process": 53,
        "string_script": "  \"\"\"\n  #!/bin/bash\n\n  n=`ls *.pairs.gz | wc -l`\n\n  if [ \\$n -eq 1 ]\n  then\n      cp ${pairs} ${sample}.pairs.gz\n      pairix -f ${sample}.pairs.gz\n  else\n      # unzipping to named pipes\n      arg=''\n      k=1\n      for f in *.pairs.gz\n      do\n        mkfifo pp.\\$k\n        arg=\"\\$arg pp.\\$k\"\n        gunzip -c \\$f | grep -v '^#' > pp.\\$k &\n        let \"k++\"\n      done\n\n      # header\n      gunzip -c ${pairs[0]} | grep \"^#\" | grep -v '^#command:'  > ${sample}.pairs\n\n      for f in *.pairs.gz\n      do\n        gunzip -c \\$f | grep '^#command:' >> ${sample}.pairs\n      done\n\n      # merging\n      sort -m -k2,2 -k4,4 -k3,3g -k5,5g \\$arg >> ${sample}.pairs\n\n      # compressing\n      bgzip -f ${sample}.pairs\n\n      # indexing\n      pairix -f ${sample}.pairs.gz\n\n  fi\n  \"\"\"",
        "nb_lignes_script": 39,
        "language_script": "bash",
        "tools": [
            "carlet"
        ],
        "tools_url": [
            "https://bio.tools/carlet"
        ],
        "tools_dico": [
            {
                "name": "carlet",
                "uri": "https://bio.tools/carlet",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0084",
                            "term": "Phylogeny"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Targeted exome capture"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "WES"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Whole exome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3676",
                            "term": "Exome capture"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phlyogenetic tree construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0323",
                                    "term": "Phylogenetic tree generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Single-cell tumor phylogeny inference with copy-number constrained mutation losses.\n\nSCARLET (Single-cell Algorithm for Reconstructing Loss-supported Evolution of Tumors) is an algorithm that reconstructs tumor phylogenies from single-cell DNA sequencing data. SCARLET uses a loss-supported model that constrains mutation losses based on observed copy-number data.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'S carlet', 'loss-supported'",
                "homepage": "http://github.com/raphael-group/scarlet"
            }
        ],
        "inputs": [
            "sample",
            "pairs",
            "idx"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { sample }",
            "publishDir \"${params.outdir}/pairs\", mode: 'copy', overwrite: true, enabled: params.dnase"
        ],
        "when": "",
        "stub": ""
    },
    "addfrag2pairs": {
        "name_process": "addfrag2pairs",
        "string_process": "\nprocess addfrag2pairs{\n  tag { sample }\n\n                                                                      \n\n  input:\n  tuple(val(sample), path(pairs), path(idx), path(re))\n\n  output:\n  tuple(val(sample), path('*.final.pairs.gz'),path('*.final.pairs.gz.px2'))\n\n  script:\n  \"\"\"\n  #run-addfrag2pairs.sh -i ${pairs} -r ${re} -o ${sample}\n\n  if [ \"${params.dnase}\" == \"true\" ]; then\n    cp ${pairs} ${sample}.final.pairs.gz\n    cp ${idx}   ${sample}.final.pairs.gz.px2\n  else\n    gunzip -c ${pairs} | /usr/local/bin/pairix/util/fragment_4dnpairs.pl -a - ${sample}.final.pairs ${re}\n    bgzip -f ${sample}.final.pairs\n    pairix -f ${sample}.final.pairs.gz\n  fi\n  \"\"\"\n  }",
        "nb_lignes_process": 24,
        "string_script": "  \"\"\"\n  #run-addfrag2pairs.sh -i ${pairs} -r ${re} -o ${sample}\n\n  if [ \"${params.dnase}\" == \"true\" ]; then\n    cp ${pairs} ${sample}.final.pairs.gz\n    cp ${idx}   ${sample}.final.pairs.gz.px2\n  else\n    gunzip -c ${pairs} | /usr/local/bin/pairix/util/fragment_4dnpairs.pl -a - ${sample}.final.pairs ${re}\n    bgzip -f ${sample}.final.pairs\n    pairix -f ${sample}.final.pairs.gz\n  fi\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "pairs",
            "idx",
            "re"
        ],
        "nb_inputs": 4,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { sample }"
        ],
        "when": "",
        "stub": ""
    },
    "run_cooler": {
        "name_process": "run_cooler",
        "string_process": "\nprocess run_cooler{\n  tag { sample }\n\n  publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(sample), path(pairs), path(idx))\n\n  output:\n  tuple(val(sample),path('*.cool'))\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  sort -k1,1 -V -s ${params.fai} >chrom_sizes.txt\n\n  #For some reason, this is EXTREMELY SLOOOOOOOOOOOOOOOOOOOOOOOOOW\n  #cooler cload pairix -p ${task.cpus} -s 10 chrom_sizes.txt:1000 ${pairs} ${sample}.cool\n  ## Use non-indexed version instead !\n  cooler cload pairs -c1 2 -p1 3 -c2 4 -p2 5 chrom_sizes.txt:1000 ${pairs} ${sample}.cool\n  \"\"\"\n  }",
        "nb_lignes_process": 21,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  sort -k1,1 -V -s ${params.fai} >chrom_sizes.txt\n\n  #For some reason, this is EXTREMELY SLOOOOOOOOOOOOOOOOOOOOOOOOOW\n  #cooler cload pairix -p ${task.cpus} -s 10 chrom_sizes.txt:1000 ${pairs} ${sample}.cool\n  ## Use non-indexed version instead !\n  cooler cload pairs -c1 2 -p1 3 -c2 4 -p2 5 chrom_sizes.txt:1000 ${pairs} ${sample}.cool\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "pairs",
            "idx"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { sample }",
            "publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "balance_cool_matrix": {
        "name_process": "balance_cool_matrix",
        "string_process": "\nprocess balance_cool_matrix{\n  tag { sample }\n\n  publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(sample), path(cool))\n\n  output:\n  tuple(val(sample),path('*.balanced.cool'))\n\n  script:\n  def balanced_cool=cool.name.replaceFirst(\".cool\",\".balanced.cool\")\n  \"\"\"\n  cp ${cool} ${balanced_cool}\n\n  if [ -f \"${params.blacklist}\" ]; then\n    grep -vP '(rand|Un)' ${params.blacklist} |sort -k1,1 -k2n,2n -V >bl.bed\n    cooler balance -p ${task.cpus} --blacklist bl.bed --max-iters 500 --force ${balanced_cool}\n  else\n    cooler balance -p ${task.cpus} --max-iters 500 --force ${balanced_cool}\n  fi\n\n  \"\"\"\n  }",
        "nb_lignes_process": 24,
        "string_script": "  def balanced_cool=cool.name.replaceFirst(\".cool\",\".balanced.cool\")\n  \"\"\"\n  cp ${cool} ${balanced_cool}\n\n  if [ -f \"${params.blacklist}\" ]; then\n    grep -vP '(rand|Un)' ${params.blacklist} |sort -k1,1 -k2n,2n -V >bl.bed\n    cooler balance -p ${task.cpus} --blacklist bl.bed --max-iters 500 --force ${balanced_cool}\n  else\n    cooler balance -p ${task.cpus} --max-iters 500 --force ${balanced_cool}\n  fi\n\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "cool"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { sample }",
            "publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "call_compartments_from_cool": {
        "name_process": "call_compartments_from_cool",
        "string_process": "\nprocess call_compartments_from_cool{\n  tag { cool }\n\n  publishDir \"${params.outdir}/annotation\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(sample), path(cool))\n\n  output:\n  tuple(val(sample),path('*.balanced.cool'))\n\n  script:\n  def balanced_cool=cool.name.replaceFirst(\".cool\",\".compartments\")\n  \"\"\"\n  cooltools call-compartments -v --bigwig -o ${compartments} ${cool}\n  \"\"\"\n  }",
        "nb_lignes_process": 16,
        "string_script": "  def balanced_cool=cool.name.replaceFirst(\".cool\",\".compartments\")\n  \"\"\"\n  cooltools call-compartments -v --bigwig -o ${compartments} ${cool}\n  \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "cool"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { cool }",
            "publishDir \"${params.outdir}/annotation\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "run_juicebox_pre": {
        "name_process": "run_juicebox_pre",
        "string_process": "\nprocess run_juicebox_pre{\n  tag { sample }\n\n  publishDir \"${params.outdir}/juicer\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(sample), path(pairs), path(idx))\n\n  output:\n  tuple(val(sample),path('*hic'))\n\n  script:\n  \"\"\"\n  #!/bin/bash\n\n  sort -k1,1 -V -s ${params.fai} |cut -f1,2 >chrom_sizes.txt\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/local/bin/juicer_tools.jar pre \\\n            -n ${pairs} ${sample}.hic \\\n             -r 1000,2000,5000,10000,25000,50000,100000,250000,500000,1000000,2500000,5000000,10000000 \\\n             chrom_sizes.txt -q 0\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/local/bin/juicer_tools.jar addNorm \\\n            -w 1000 -d -F ${sample}.hic\n\n  \"\"\"\n  }",
        "nb_lignes_process": 26,
        "string_script": "  \"\"\"\n  #!/bin/bash\n\n  sort -k1,1 -V -s ${params.fai} |cut -f1,2 >chrom_sizes.txt\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/local/bin/juicer_tools.jar pre \\\n            -n ${pairs} ${sample}.hic \\\n             -r 1000,2000,5000,10000,25000,50000,100000,250000,500000,1000000,2500000,5000000,10000000 \\\n             chrom_sizes.txt -q 0\n\n  java -Xmx${task.memory.toGiga()}g -Xms${task.memory.toGiga()}g -jar /usr/local/bin/juicer_tools.jar addNorm \\\n            -w 1000 -d -F ${sample}.hic\n\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "pairs",
            "idx"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { sample }",
            "publishDir \"${params.outdir}/juicer\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "cool2multirescool": {
        "name_process": "cool2multirescool",
        "string_process": "\nprocess cool2multirescool{\n  tag { sample }\n\n  publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(sample), path(cool))\n\n  output:\n  tuple(val(sample),path('*cool*'))\n\n  script:\n  \"\"\"\n  #!/bin/bash\n\n  run-cool2multirescool.sh \\\n     -i ${cool} \\\n     -p ${task.cpus} \\\n     -o ${sample} \\\n     -c 10000000 \\\n     -u 1000,2000,5000,10000,25000,50000,100000,250000,500000,1000000,2500000,5000000,10000000\n\n  \"\"\"\n  }",
        "nb_lignes_process": 23,
        "string_script": "  \"\"\"\n  #!/bin/bash\n\n  run-cool2multirescool.sh \\\n     -i ${cool} \\\n     -p ${task.cpus} \\\n     -o ${sample} \\\n     -c 10000000 \\\n     -u 1000,2000,5000,10000,25000,50000,100000,250000,500000,1000000,2500000,5000000,10000000\n\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sample",
            "cool"
        ],
        "nb_inputs": 2,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { sample }",
            "publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "hicnormvector_to_mcool": {
        "name_process": "hicnormvector_to_mcool",
        "string_process": "\nprocess hicnormvector_to_mcool{\n  tag { sample }\n\n  publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(sample), path(cool_file), path(hic_file))\n\n  output:\n  tuple(val(sample),path('*mcool*'))\n\n  script:\n  def outcool=cool_file.name.replaceFirst(\"cool\",\"mcool\")\n  \"\"\"\n  #!/bin/bash\n  cp ${cool_file} ${outcool}\n\n  scriptdir=/usr/local/bin/\n  hic2cool extract-norms -e ${hic_file} ${outcool}\n  \"\"\"\n  }",
        "nb_lignes_process": 20,
        "string_script": "  def outcool=cool_file.name.replaceFirst(\"cool\",\"mcool\")\n  \"\"\"\n  #!/bin/bash\n  cp ${cool_file} ${outcool}\n\n  scriptdir=/usr/local/bin/\n  hic2cool extract-norms -e ${hic_file} ${outcool}\n  \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "bin3C"
        ],
        "tools_url": [
            "https://bio.tools/bin3C"
        ],
        "tools_dico": [
            {
                "name": "bin3C",
                "uri": "https://bio.tools/bin3C",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3837",
                            "term": "Metagenomic sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3837",
                            "term": "Shotgun metagenomic sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3216",
                                    "term": "Scaffolding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3216",
                                    "term": "Scaffold construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3216",
                                    "term": "Scaffold generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Extracts metagenome-assembled genomes (MAGs) from metagenomic data using Hi-C.",
                "homepage": "https://github.com/cerebis/bin3C"
            }
        ],
        "inputs": [
            "sample",
            "cool_file",
            "hic_file"
        ],
        "nb_inputs": 3,
        "outputs": [
            "sample"
        ],
        "nb_outputs": 1,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { sample }",
            "publishDir \"${params.outdir}/cooler\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "concatenate_phasing_reports": {
        "name_process": "concatenate_phasing_reports",
        "string_process": "\nprocess concatenate_phasing_reports {\n  tag { id }\n\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(id), path(reports))\n\n  output:\n  path('*phasing_report.txt')\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  for v in `cut -f1 *stats.txt |sort |uniq`; do n=`grep \\$v *txt |cut -f2 |\n       awk -F',' '{sum+=\\$1;} END{print sum;}'`; echo -e \"\\$v\\\\t\\$n\"; done |sort -k1,1 >${id}.phasing_report.txt\n  \"\"\"\n  }",
        "nb_lignes_process": 17,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  for v in `cut -f1 *stats.txt |sort |uniq`; do n=`grep \\$v *txt |cut -f2 |\n       awk -F',' '{sum+=\\$1;} END{print sum;}'`; echo -e \"\\$v\\\\t\\$n\"; done |sort -k1,1 >${id}.phasing_report.txt\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "id",
            "reports"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { id }",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "concatenate_allelicstatus_reports": {
        "name_process": "concatenate_allelicstatus_reports",
        "string_process": "\nprocess concatenate_allelicstatus_reports {\n  tag { id }\n\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(name), path(report))\n\n  output:\n  path('*allelicstatusreport.txt')\n\n  shell:\n  '''\n  #!/usr/bin/perl\n  my $nord = 0;\n  my (%ord);\n\n  open my $IN, \"-|\", \"cat *markallelicstatus.txt\";\n  open OUT, '>', \"!{name}.allelicstatusreport.txt\";\n\n  my ($totSNP, $totSNPN, $totREADS, $totN, $totOneN, $totUn);\n  my ($nRef  ,   $nAlt,   $nUnN,   $nUnO,   $nOth,   $nConf, $tot, $cnttot);\n  my ($cntRef, $cntAlt, $cntUnN, $cntUnO, $cntOth, $cntConf);\n\n  while (<$IN>){\n    chomp;\n\n    if ($_ =~ /^##/ && $_ !~ /^##\\s.+========/){\n      $_ =~ s/^(.+?)\\\\..+bam$/$1/;\n      $header .= $_.\"\\n\" unless ($headerDets{$_}++);\n    }\n\n    $totSNP   += $1 if ($_ =~ /Total number of snps loaded\\\\s+([\\\\d\\\\.]+)/);\n    $totSNPN  ++    if ($_ =~ /Total number of snps loaded\\\\s+([\\\\d\\\\.]+)/);\n    $totREADS += $1 if ($_ =~ /Total number of reads\\\\s+([\\\\d\\\\.]+)/);\n    $totN     += $1 if ($_ =~ /Total number of \\\\'N\\\\'s\\\\s+([\\\\d\\\\.]+)/);\n    $totOneN  += $1 if ($_ =~ /Total number of reads with at least one \\\\'N\\\\'\\\\s+([\\\\d\\\\.]+)/);\n    $totUn    += $1 if ($_ =~ /Total number of unassigned reads\\\\s+([\\\\d\\\\.]+)/);\n\n    if ($_ =~ /Number of reads assigned to ref genome\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nRef += $1;\n        $tot  += int($1/$2*100) if ($1>0);\n        $cnttot++ if ($1>0);\n        $cntRef++;\n    }\n\n    if ($_ =~ /Number of reads assigned to alt genome\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nAlt += $1;\n        $tot  += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntAlt++;\n    }\n\n    if ($_ =~ /Number of unassigned N-containing reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nUnN += $1;\n        $tot  += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntUnN++;\n    }\n\n    if ($_ =~ /Number of other type unassigned reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nUnO += $1;\n        $tot  += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntUnO++;\n    }\n\n    if ($_ =~ /Number of conflicting reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nConf += $1;\n        $tot   += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntConf++;\n    }\n\n    if ($_ =~ /Number of other reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nOth += $1;\n        $tot   += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntOth++;\n    }\n  }\n\n  print OUT $header;\n\n  print OUT \"## =========================\\n\";\n  print OUT join(\"\\t\",\"Total number of snps loaded\",$totSNP?int($totSNP/$totSNPN):\"0\").\"\\n\";\n  print OUT \"## =========================\\n\";\n  print OUT join(\"\\t\",\"Total number of reads\",$totREADS?$totREADS:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of \\'N\\'s\",$totN?$totN:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of reads with at least one \\'N\\'\",$totOneN?$totOneN:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of unassigned reads\",$totUn?$totUn:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Total number of snps loaded\",$totSNP?$totSNP:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"## = PERCENTAGES ========================\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of reads assigned to ref genome\", ($nRef?$nRef:\"0\"),($nRef?sprintf(\"%4.2f\",$nRef/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of reads assigned to alt genome\", ($nAlt?$nAlt:\"0\"),($nAlt?sprintf(\"%4.2f\",$nAlt/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of unassigned N-containing reads\",($nUnN?$nUnN:\"0\"),($nUnN?sprintf(\"%4.2f\",$nUnN/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of other type unassigned reads\",  ($nUnO?$nUnO:\"0\"),($nUnO?sprintf(\"%4.2f\",$nUnO/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of conflicting reads\",            ($nCon?$nCon:\"0\"),($nCon?sprintf(\"%4.2f\",$nCon/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of other reads\",                  ($nOth?$nOth:\"0\"),($nOth?sprintf(\"%4.2f\",$nOth/$totREADS*100):\"0\")).\"\\n\";\n\n  '''\n  }",
        "nb_lignes_process": 101,
        "string_script": "  '''\n  #!/usr/bin/perl\n  my $nord = 0;\n  my (%ord);\n\n  open my $IN, \"-|\", \"cat *markallelicstatus.txt\";\n  open OUT, '>', \"!{name}.allelicstatusreport.txt\";\n\n  my ($totSNP, $totSNPN, $totREADS, $totN, $totOneN, $totUn);\n  my ($nRef  ,   $nAlt,   $nUnN,   $nUnO,   $nOth,   $nConf, $tot, $cnttot);\n  my ($cntRef, $cntAlt, $cntUnN, $cntUnO, $cntOth, $cntConf);\n\n  while (<$IN>){\n    chomp;\n\n    if ($_ =~ /^##/ && $_ !~ /^##\\s.+========/){\n      $_ =~ s/^(.+?)\\\\..+bam$/$1/;\n      $header .= $_.\"\\n\" unless ($headerDets{$_}++);\n    }\n\n    $totSNP   += $1 if ($_ =~ /Total number of snps loaded\\\\s+([\\\\d\\\\.]+)/);\n    $totSNPN  ++    if ($_ =~ /Total number of snps loaded\\\\s+([\\\\d\\\\.]+)/);\n    $totREADS += $1 if ($_ =~ /Total number of reads\\\\s+([\\\\d\\\\.]+)/);\n    $totN     += $1 if ($_ =~ /Total number of \\\\'N\\\\'s\\\\s+([\\\\d\\\\.]+)/);\n    $totOneN  += $1 if ($_ =~ /Total number of reads with at least one \\\\'N\\\\'\\\\s+([\\\\d\\\\.]+)/);\n    $totUn    += $1 if ($_ =~ /Total number of unassigned reads\\\\s+([\\\\d\\\\.]+)/);\n\n    if ($_ =~ /Number of reads assigned to ref genome\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nRef += $1;\n        $tot  += int($1/$2*100) if ($1>0);\n        $cnttot++ if ($1>0);\n        $cntRef++;\n    }\n\n    if ($_ =~ /Number of reads assigned to alt genome\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nAlt += $1;\n        $tot  += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntAlt++;\n    }\n\n    if ($_ =~ /Number of unassigned N-containing reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nUnN += $1;\n        $tot  += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntUnN++;\n    }\n\n    if ($_ =~ /Number of other type unassigned reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nUnO += $1;\n        $tot  += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntUnO++;\n    }\n\n    if ($_ =~ /Number of conflicting reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nConf += $1;\n        $tot   += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntConf++;\n    }\n\n    if ($_ =~ /Number of other reads\\\\s+([\\\\d\\\\.]+)\\\\s+([\\\\d\\\\.]+)/){\n        $nOth += $1;\n        $tot   += int($1/$2*100) if ($1>0 && int($2)>0);\n        $cnttot++ if ($1>0);\n        $cntOth++;\n    }\n  }\n\n  print OUT $header;\n\n  print OUT \"## =========================\\n\";\n  print OUT join(\"\\t\",\"Total number of snps loaded\",$totSNP?int($totSNP/$totSNPN):\"0\").\"\\n\";\n  print OUT \"## =========================\\n\";\n  print OUT join(\"\\t\",\"Total number of reads\",$totREADS?$totREADS:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of \\'N\\'s\",$totN?$totN:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of reads with at least one \\'N\\'\",$totOneN?$totOneN:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of unassigned reads\",$totUn?$totUn:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"Total number of snps loaded\",$totSNP?$totSNP:\"0\").\"\\n\";\n  print OUT join(\"\\t\",\"## = PERCENTAGES ========================\").\"\\n\";\n  print OUT join(\"\\t\",\"Number of reads assigned to ref genome\", ($nRef?$nRef:\"0\"),($nRef?sprintf(\"%4.2f\",$nRef/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of reads assigned to alt genome\", ($nAlt?$nAlt:\"0\"),($nAlt?sprintf(\"%4.2f\",$nAlt/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of unassigned N-containing reads\",($nUnN?$nUnN:\"0\"),($nUnN?sprintf(\"%4.2f\",$nUnN/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of other type unassigned reads\",  ($nUnO?$nUnO:\"0\"),($nUnO?sprintf(\"%4.2f\",$nUnO/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of conflicting reads\",            ($nCon?$nCon:\"0\"),($nCon?sprintf(\"%4.2f\",$nCon/$totREADS*100):\"0\")).\"\\n\";\n  print OUT join(\"\\t\",\"Number of other reads\",                  ($nOth?$nOth:\"0\"),($nOth?sprintf(\"%4.2f\",$nOth/$totREADS*100):\"0\")).\"\\n\";\n\n  '''",
        "nb_lignes_script": 88,
        "language_script": "perl",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "name",
            "report"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { id }",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc{\n  tag { reports[0] }\n\n  publishDir \"${params.outdir}/multiqc\", mode: 'copy', overwrite: true\n\n  input:\n  path(reports)\n\n  output:\n  path('*multiqc*')\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  nm=`ls *.pairtools_report.txt`\n  name=\\${nm/.all.pairtools_report.txt/.multiqc}\n\n  for z in *zip; do\n    cp \\$z report.zip\n    unzip report.zip\n  done\n\n  multiqc -n \\$name .\n  \"\"\"\n  }",
        "nb_lignes_process": 24,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  nm=`ls *.pairtools_report.txt`\n  name=\\${nm/.all.pairtools_report.txt/.multiqc}\n\n  for z in *zip; do\n    cp \\$z report.zip\n    unzip report.zip\n  done\n\n  multiqc -n \\$name .\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "reports"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { reports[0] }",
            "publishDir \"${params.outdir}/multiqc\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "bamCoverage": {
        "name_process": "bamCoverage",
        "string_process": "process bamCoverage {\n    tag { id }\n\n    publishDir \"${params.outdir}/deeptools/bigwig\",   mode: 'copy', overwrite: true, pattern: '*bigwig'\n\n    input:\n    tuple(val(id), path(bam), path(bai))\n\n    output:\n    path('*bigwig', emit: bigwig)\n\n    script:\n    def bigwig=bam.name.replaceFirst(\"bam\",\"bigwig\")\n    \"\"\"\n    #!/bin/bash\n    bamCoverage -b ${bam} --centerReads -p ${task.cpus} \\\n                --minMappingQuality 20 \\\n                --ignoreDuplicates \\\n                --extendReads 150 \\\n                --centerReads \\\n                --binSize 10 \\\n                -o ${bigwig}\n    \"\"\"\n  }",
        "nb_lignes_process": 22,
        "string_script": "    def bigwig=bam.name.replaceFirst(\"bam\",\"bigwig\")\n    \"\"\"\n    #!/bin/bash\n    bamCoverage -b ${bam} --centerReads -p ${task.cpus} \\\n                --minMappingQuality 20 \\\n                --ignoreDuplicates \\\n                --extendReads 150 \\\n                --centerReads \\\n                --binSize 10 \\\n                -o ${bigwig}\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "id",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { id }",
            "publishDir \"${params.outdir}/deeptools/bigwig\", mode: 'copy', overwrite: true, pattern: '*bigwig'"
        ],
        "when": "",
        "stub": ""
    },
    "computeMatrixRefPoint": {
        "name_process": "computeMatrixRefPoint",
        "string_process": "\nprocess computeMatrixRefPoint {\n  tag { id }\n\n  publishDir \"${params.outdir}/deeptools/matrix\",  mode: 'copy', overwrite: true, pattern: \"*matrix\"\n  publishDir \"${params.outdir}/deeptools/matrix\",  mode: 'copy', overwrite: true, pattern: \"*tab\"\n  publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*svg\"\n  publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*png\"\n\n  input:\n  tuple(val(id),   path(bigwig))\n  tuple(val(type), path(bed))\n\n  output:\n  path('*.matrix', emit: matrix)\n  path('*.tab',    emit: tab)\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  computeMatrix reference-point \\\n              -S ${bigwig} \\\n              -R ${bed} \\\n              -o \"${id}.${type}.deeptools.matrix\" \\\n              --outFileNameMatrix \"${id}.${type}.deeptools.tab\" \\\n              --referencePoint center \\\n              -b 2000 \\\n              -a 2000\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.png\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat png\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.svg\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat svg\n  \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  computeMatrix reference-point \\\n              -S ${bigwig} \\\n              -R ${bed} \\\n              -o \"${id}.${type}.deeptools.matrix\" \\\n              --outFileNameMatrix \"${id}.${type}.deeptools.tab\" \\\n              --referencePoint center \\\n              -b 2000 \\\n              -a 2000\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.png\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat png\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.svg\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat svg\n  \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "id",
            "bigwig",
            "type",
            "bed"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { id }",
            "publishDir \"${params.outdir}/deeptools/matrix\", mode: 'copy', overwrite: true, pattern: \"*matrix\"",
            "publishDir \"${params.outdir}/deeptools/matrix\", mode: 'copy', overwrite: true, pattern: \"*tab\"",
            "publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*svg\"",
            "publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*png\""
        ],
        "when": "",
        "stub": ""
    },
    "computeMatrixRefPointMultiple": {
        "name_process": "computeMatrixRefPointMultiple",
        "string_process": "\nprocess computeMatrixRefPointMultiple {\n  tag { \"${bigwig}\" }\n\n  publishDir \"${params.outdir}/deeptools/matrix\",  mode: 'copy', overwrite: true, pattern: \"*matrix\"\n  publishDir \"${params.outdir}/deeptools/matrix\",  mode: 'copy', overwrite: true, pattern: \"*tab\"\n  publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*svg\"\n  publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*png\"\n\n  input:\n  path(bigwig)\n  path(bed)\n\n  output:\n  path('*.matrix', emit: matrix)\n  path('*.tab',    emit: tab)\n  path('*.png',    emit: png)\n  path('*.svg',    emit: svg)\n\n  script:\n  def id = bigwig.name.replaceFirst(\".bigwig\",\"\")\n  def type = 'all'\n  \"\"\"\n  #!/bin/bash\n  computeMatrix reference-point \\\n              -S ${bigwig} \\\n              -R ${bed} \\\n              -o \"${id}.${type}.deeptools.matrix\" \\\n              --outFileNameMatrix \"${id}.${type}.deeptools.tab\" \\\n              --referencePoint center \\\n              -b 2000 \\\n              -a 2000\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.png\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat png --perGroup\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.svg\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat svg --perGroup\n  \"\"\"\n  }",
        "nb_lignes_process": 48,
        "string_script": "  def id = bigwig.name.replaceFirst(\".bigwig\",\"\")\n  def type = 'all'\n  \"\"\"\n  #!/bin/bash\n  computeMatrix reference-point \\\n              -S ${bigwig} \\\n              -R ${bed} \\\n              -o \"${id}.${type}.deeptools.matrix\" \\\n              --outFileNameMatrix \"${id}.${type}.deeptools.tab\" \\\n              --referencePoint center \\\n              -b 2000 \\\n              -a 2000\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.png\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat png --perGroup\n\n  plotHeatmap -m \"${id}.${type}.deeptools.matrix\" \\\n              --outFileName \"${id}.${type}.deeptools.svg\" \\\n              --plotType se \\\n              --averageTypeSummaryPlot mean \\\n              --heatmapWidth 10 \\\n              --xAxisLabel \"Distance\" \\\n              --plotFileFormat svg --perGroup\n  \"\"\"",
        "nb_lignes_script": 28,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bigwig",
            "bed"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { \"${bigwig}\" }",
            "publishDir \"${params.outdir}/deeptools/matrix\", mode: 'copy', overwrite: true, pattern: \"*matrix\"",
            "publishDir \"${params.outdir}/deeptools/matrix\", mode: 'copy', overwrite: true, pattern: \"*tab\"",
            "publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*svg\"",
            "publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true, pattern: \"*png\""
        ],
        "when": "",
        "stub": ""
    },
    "ssdsAlign": {
        "name_process": "ssdsAlign",
        "string_process": "process ssdsAlign {\n\n  time { fqR1.size()<300000000? 3.hour : 3.hour * fqR1.size()/300000000 * task.attempt }\n\n  tag {fqR1}\n\n  input:\n  tuple file(fqR1),file(fqR2)\n\n  output:\n  path('*_split_*bam')\n\n  script:\n                              \n  def nm = new Random().with {(1..12).collect {(('a'..'z')).join()[ nextInt((('a'..'z')).join().length())]}.join()}\n  def tmp = 'tmp_' + nm\n  def tmpR1fq = 'tmp_' + nm + '.R1.fq'\n  def tmpR2fq = 'tmp_' + nm + '.R2.fq'\n  def tmpR1sai = 'tmp_' + nm + '.R1.sai'\n  def tmpR2sai = 'tmp_' + nm + '.R2.sai'\n  def bamOut = params.name + '_split_' + nm + '.bam'\n  def bamAll = 'all_' + nm + '.bam'\n\n  println(\"R1 len: ${params.r1Len}\")\n\n  if (params.original){\n    \"\"\"\n\t  fastx_trimmer -Q 33 -f 1 -l ${params.r1Len} -i ${fqR1} -o ${tmpR1fq}\n\t  fastx_trimmer -Q 33 -f 1 -l ${params.r2Len} -i ${fqR2} -o ${tmpR2fq}\n\n\t  bwa_0.7.12 aln \\\n\t    -t ${task.cpus} \\\n\t    ${params.genome_bwaidx} \\\n\t    ${tmpR1fq} >${tmpR1sai}\n\n\t  bwa_ra_0.7.12 aln \\\n\t    -t ${task.cpus} \\\n\t    ${params.genome_bwaidx} \\\n\t    ${tmpR2fq} >${tmpR2sai}\n\n\t  bwa_0.7.12 sampe \\\n\t    ${params.genome_bwaidx} \\\n\t    ${tmpR1sai} ${tmpR2sai} \\\n\t    ${tmpR1fq} ${tmpR2fq} >${tmp}\".unsorted.sam\"\n\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SamFormatConverter \\\n                 I=${tmp}.unsorted.sam \\\n                 O=${tmp}.unsorted.tmpbam \\\n                 TMP_DIR=\"\\$TMPDIR\" \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n                 I=${tmp}.unsorted.tmpbam \\\n                 O=${bamOut} \\\n                 SO=coordinate \\\n                 TMP_DIR=\"\\$TMPDIR\" \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n    samtools index ${bamOut}\n    \"\"\"\n  }else{\n    \"\"\"\n    fqLen=`cat ${fqR1} |sed -n '2~4p' |perl -lane 'print length(\\$_)' |head -n 10000 |sort -k1n,1n |tail -n1`\n\n    if [ \\$fqLen -ge 99 ]; then\n      echo \"FASTQ Max Length = \\$fqLen : Using minimap2 for initial alignment ...\"\n      minimap2 -ax sr -I 12g \\\n        -t ${task.cpus} \\\n        ${params.genome_mm2idx} \\\n        ${fqR1} ${fqR2} >${tmp}.unsorted.sam\n    else\n      echo \"FASTQ Max Length = \\$fqLen : Using bwa mem for initial alignment ...\"\n      bwa_0.7.12 mem \\\n        -t ${task.cpus} \\\n        ${params.genome_bwaidx} \\\n        ${fqR1} ${fqR2} >${tmp}.unsorted.sam\n    fi\n\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SamFormatConverter \\\n              I=${tmp}.unsorted.sam \\\n              O=${tmp}.unsorted.tmpbam \\\n              TMP_DIR=\"\\$TMPDIR\" \\\n              VALIDATION_STRINGENCY=LENIENT\n\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n              I=${tmp}.unsorted.tmpbam \\\n              O=${tmp}.Qsorted.sam \\\n              SO=queryname \\\n              TMP_DIR=\"\\$TMPDIR\" \\\n              VALIDATION_STRINGENCY=LENIENT\n\n    flagReadPairsWithMultipleSupplementaryMappings.pl ${tmp}.Qsorted.sam ${tmp}.ok.sam\n\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n              I=${tmp}.ok.sam \\\n              O=${bamAll} \\\n              SO=coordinate \\\n              TMP_DIR=\"\\$TMPDIR\" \\\n              VALIDATION_STRINGENCY=LENIENT\n\n    samtools index ${bamAll}\n\n    samtools view -hb ${bamAll} >${bamOut}\n    samtools index ${bamOut}\n    \"\"\"\n    }\n  }",
        "nb_lignes_process": 105,
        "string_script": "  def nm = new Random().with {(1..12).collect {(('a'..'z')).join()[ nextInt((('a'..'z')).join().length())]}.join()}\n  def tmp = 'tmp_' + nm\n  def tmpR1fq = 'tmp_' + nm + '.R1.fq'\n  def tmpR2fq = 'tmp_' + nm + '.R2.fq'\n  def tmpR1sai = 'tmp_' + nm + '.R1.sai'\n  def tmpR2sai = 'tmp_' + nm + '.R2.sai'\n  def bamOut = params.name + '_split_' + nm + '.bam'\n  def bamAll = 'all_' + nm + '.bam'\n\n  println(\"R1 len: ${params.r1Len}\")\n\n  if (params.original){\n    \"\"\"\n\t  fastx_trimmer -Q 33 -f 1 -l ${params.r1Len} -i ${fqR1} -o ${tmpR1fq}\n\t  fastx_trimmer -Q 33 -f 1 -l ${params.r2Len} -i ${fqR2} -o ${tmpR2fq}\n\n\t  bwa_0.7.12 aln \\\n\t    -t ${task.cpus} \\\n\t    ${params.genome_bwaidx} \\\n\t    ${tmpR1fq} >${tmpR1sai}\n\n\t  bwa_ra_0.7.12 aln \\\n\t    -t ${task.cpus} \\\n\t    ${params.genome_bwaidx} \\\n\t    ${tmpR2fq} >${tmpR2sai}\n\n\t  bwa_0.7.12 sampe \\\n\t    ${params.genome_bwaidx} \\\n\t    ${tmpR1sai} ${tmpR2sai} \\\n\t    ${tmpR1fq} ${tmpR2fq} >${tmp}\".unsorted.sam\"\n\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SamFormatConverter \\\n                 I=${tmp}.unsorted.sam \\\n                 O=${tmp}.unsorted.tmpbam \\\n                 TMP_DIR=\"\\$TMPDIR\" \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n                 I=${tmp}.unsorted.tmpbam \\\n                 O=${bamOut} \\\n                 SO=coordinate \\\n                 TMP_DIR=\"\\$TMPDIR\" \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n    samtools index ${bamOut}\n    \"\"\"\n  }else{\n    \"\"\"\n    fqLen=`cat ${fqR1} |sed -n '2~4p' |perl -lane 'print length(\\$_)' |head -n 10000 |sort -k1n,1n |tail -n1`\n\n    if [ \\$fqLen -ge 99 ]; then\n      echo \"FASTQ Max Length = \\$fqLen : Using minimap2 for initial alignment ...\"\n      minimap2 -ax sr -I 12g \\\n        -t ${task.cpus} \\\n        ${params.genome_mm2idx} \\\n        ${fqR1} ${fqR2} >${tmp}.unsorted.sam\n    else\n      echo \"FASTQ Max Length = \\$fqLen : Using bwa mem for initial alignment ...\"\n      bwa_0.7.12 mem \\\n        -t ${task.cpus} \\\n        ${params.genome_bwaidx} \\\n        ${fqR1} ${fqR2} >${tmp}.unsorted.sam\n    fi\n\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SamFormatConverter \\\n              I=${tmp}.unsorted.sam \\\n              O=${tmp}.unsorted.tmpbam \\\n              TMP_DIR=\"\\$TMPDIR\" \\\n              VALIDATION_STRINGENCY=LENIENT\n\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n              I=${tmp}.unsorted.tmpbam \\\n              O=${tmp}.Qsorted.sam \\\n              SO=queryname \\\n              TMP_DIR=\"\\$TMPDIR\" \\\n              VALIDATION_STRINGENCY=LENIENT\n\n    flagReadPairsWithMultipleSupplementaryMappings.pl ${tmp}.Qsorted.sam ${tmp}.ok.sam\n\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n              I=${tmp}.ok.sam \\\n              O=${bamAll} \\\n              SO=coordinate \\\n              TMP_DIR=\"\\$TMPDIR\" \\\n              VALIDATION_STRINGENCY=LENIENT\n\n    samtools index ${bamAll}\n\n    samtools view -hb ${bamAll} >${bamOut}\n    samtools index ${bamOut}\n    \"\"\"\n    }",
        "nb_lignes_script": 91,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "Minimap2"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/minimap2"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            }
        ],
        "inputs": [
            "fqR1",
            "fqR2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "time { fqR1.size()<300000000? 3.hour : 3.hour * fqR1.size()/300000000 * task.attempt }",
            "tag {fqR1}"
        ],
        "when": "",
        "stub": ""
    },
    "mergeBAMssds": {
        "name_process": "mergeBAMssds",
        "string_process": "\nprocess mergeBAMssds {\n\n  publishDir \"${params.outdir}/bam\",     mode: 'copy', overwrite: true, pattern: '*unparsed.bam*'\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*MDmetrics.txt*'\n\n  tag {params.name}\n\n  input:\n  path(bams)\n\n  output:\n  tuple path('*unparsed.bam'),path('*unparsed.bam.bai'), emit: bam\n  tuple path('*ignments.bam'),path('*ignments.bam.bai'), emit: suppbam, optional: true\n  path('*MDmetrics.txt', emit: mdmetrics)\n\n  script:\n                              \n  def input_args = bams.collect{ \"I=$it\" }.join(\" \")\n  def name = \"${params.name}.${params.genome}\"\n  \"\"\"\n  java -jar -Xmx32g \\$PICARDJAR MergeSamFiles \\\n                 ${input_args} \\\n                 O=allREADS.bam \\\n                 AS=true \\\n                 SO=coordinate \\\n                 TMP_DIR=\"\\$TMPDIR\" \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  java -jar -Xmx32g \\$PICARDJAR MarkDuplicatesWithMateCigar \\\n               I=allREADS.bam \\\n               O=${name}.allReads.bam \\\n               PG=Picard2.9.2_MarkDuplicates \\\n               M=${name}.MDmetrics.txt \\\n               MINIMUM_DISTANCE=400 \\\n               TMP_DIR=\"\\$TMPDIR\" \\\n\t\t   CREATE_INDEX=false \\\n\t\t   ASSUME_SORT_ORDER=coordinate \\\n       VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${name}.allReads.bam\n\n  samtools view -F 2048 -hb ${name}.allReads.bam > ${name}.SSDSunparsed.bam\n  samtools index ${name}.SSDSunparsed.bam\n\n  #samtools view -f 2 -hb ${name}.SSDSall.bam >${name}.SSDSunparsed_andPaired.bam\n  #samtools index ${name}.SSDSunparsed_andPaired.bam\n\n  samtools view -f 2048 -hb ${name}.allReads.bam > ${name}.SSDSunparsed.suppAlignments.bam\n  samtools index ${name}.SSDSunparsed.suppAlignments.bam\n\n  \"\"\"\n  }",
        "nb_lignes_process": 51,
        "string_script": "  def input_args = bams.collect{ \"I=$it\" }.join(\" \")\n  def name = \"${params.name}.${params.genome}\"\n  \"\"\"\n  java -jar -Xmx32g \\$PICARDJAR MergeSamFiles \\\n                 ${input_args} \\\n                 O=allREADS.bam \\\n                 AS=true \\\n                 SO=coordinate \\\n                 TMP_DIR=\"\\$TMPDIR\" \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  java -jar -Xmx32g \\$PICARDJAR MarkDuplicatesWithMateCigar \\\n               I=allREADS.bam \\\n               O=${name}.allReads.bam \\\n               PG=Picard2.9.2_MarkDuplicates \\\n               M=${name}.MDmetrics.txt \\\n               MINIMUM_DISTANCE=400 \\\n               TMP_DIR=\"\\$TMPDIR\" \\\n\t\t   CREATE_INDEX=false \\\n\t\t   ASSUME_SORT_ORDER=coordinate \\\n       VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${name}.allReads.bam\n\n  samtools view -F 2048 -hb ${name}.allReads.bam > ${name}.SSDSunparsed.bam\n  samtools index ${name}.SSDSunparsed.bam\n\n  #samtools view -f 2 -hb ${name}.SSDSall.bam >${name}.SSDSunparsed_andPaired.bam\n  #samtools index ${name}.SSDSunparsed_andPaired.bam\n\n  samtools view -f 2048 -hb ${name}.allReads.bam > ${name}.SSDSunparsed.suppAlignments.bam\n  samtools index ${name}.SSDSunparsed.suppAlignments.bam\n\n  \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bams"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*unparsed.bam*'",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*MDmetrics.txt*'",
            "tag {params.name}"
        ],
        "when": "",
        "stub": ""
    },
    "parseITRs": {
        "name_process": "parseITRs",
        "string_process": "\nprocess parseITRs {\n\n  tag {bam}\n\n  cpus 4\n  memory '12 GB'\n  time { 6.hour * task.attempt}\n\n  errorStrategy 'retry'\n  maxRetries 1\n\n  input:\n  path(bam)\n\n  output:\n  path('*.bam', emit: pBam)\n  path('*.bai', emit: pBai)\n  path('*.bed', emit: pBed)\n\n  script:\n  def parseScript = params.original ? 'ITR_id_v3.pl' : 'ITR_id_v3_long.pl';\n  def name = bam.name.replaceFirst(\".bam\",\".pairs.bam\")\n  \"\"\"\n  samtools view -f 2 -hb ${bam} >${name}\n  samtools index ${name}\n\n  ${parseScript} ${name} ${params.genome} 2>/dev/null\n\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.ssDNA_type1.bed  -o ${name}.ssDNA_type1.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.ssDNA_type2.bed  -o ${name}.ssDNA_type2.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.dsDNA.bed        -o ${name}.dsDNA.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.dsDNA_strict.bed -o ${name}.dsDNA_strict.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.unclassified.bed -o ${name}.unclassified.bed\n\n  samtools view -H ${name}   >header.txt\n  echo -e '@PG\\\\tID:SSDSpipeline PN:SSDSpipeline VN:2.0_nextflowDSL2' >>header.txt\n\n  cat header.txt ${name}.ssDNA_type1.sam  >${name}.ssDNA_type1.RH.sam\n  cat header.txt ${name}.ssDNA_type2.sam  >${name}.ssDNA_type2.RH.sam\n  cat header.txt ${name}.dsDNA.sam        >${name}.dsDNA.RH.sam\n  cat header.txt ${name}.dsDNA_strict.sam >${name}.dsDNA_strict.RH.sam\n  cat header.txt ${name}.unclassified.sam >${name}.unclassified.RH.sam\n\n  samtools view -Shb ${name}.ssDNA_type1.RH.sam  >${name}.ssDNA_type1.US.bam\n  samtools view -Shb ${name}.ssDNA_type2.RH.sam  >${name}.ssDNA_type2.US.bam\n  samtools view -Shb ${name}.dsDNA.RH.sam        >${name}.dsDNA.US.bam\n  samtools view -Shb ${name}.dsDNA_strict.RH.sam >${name}.dsDNA_strict.US.bam\n  samtools view -Shb ${name}.unclassified.RH.sam >${name}.unclassified.US.bam\n\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.ssDNA_type1.US.bam  O=${name}.ssDNA_type1.bam  SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.ssDNA_type2.US.bam  O=${name}.ssDNA_type2.bam  SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.dsDNA.US.bam        O=${name}.dsDNA.bam        SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.dsDNA_strict.US.bam O=${name}.dsDNA_strict.bam SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.unclassified.US.bam O=${name}.unclassified.bam SO=coordinate VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${name}.ssDNA_type1.bam\n  samtools index ${name}.ssDNA_type2.bam\n  samtools index ${name}.dsDNA.bam\n  samtools index ${name}.dsDNA_strict.bam\n  samtools index ${name}.unclassified.bam\n  \"\"\"\n  }",
        "nb_lignes_process": 61,
        "string_script": "  def parseScript = params.original ? 'ITR_id_v3.pl' : 'ITR_id_v3_long.pl';\n  def name = bam.name.replaceFirst(\".bam\",\".pairs.bam\")\n  \"\"\"\n  samtools view -f 2 -hb ${bam} >${name}\n  samtools index ${name}\n\n  ${parseScript} ${name} ${params.genome} 2>/dev/null\n\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.ssDNA_type1.bed  -o ${name}.ssDNA_type1.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.ssDNA_type2.bed  -o ${name}.ssDNA_type2.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.dsDNA.bed        -o ${name}.dsDNA.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.dsDNA_strict.bed -o ${name}.dsDNA_strict.bed\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 ${name}.unclassified.bed -o ${name}.unclassified.bed\n\n  samtools view -H ${name}   >header.txt\n  echo -e '@PG\\\\tID:SSDSpipeline PN:SSDSpipeline VN:2.0_nextflowDSL2' >>header.txt\n\n  cat header.txt ${name}.ssDNA_type1.sam  >${name}.ssDNA_type1.RH.sam\n  cat header.txt ${name}.ssDNA_type2.sam  >${name}.ssDNA_type2.RH.sam\n  cat header.txt ${name}.dsDNA.sam        >${name}.dsDNA.RH.sam\n  cat header.txt ${name}.dsDNA_strict.sam >${name}.dsDNA_strict.RH.sam\n  cat header.txt ${name}.unclassified.sam >${name}.unclassified.RH.sam\n\n  samtools view -Shb ${name}.ssDNA_type1.RH.sam  >${name}.ssDNA_type1.US.bam\n  samtools view -Shb ${name}.ssDNA_type2.RH.sam  >${name}.ssDNA_type2.US.bam\n  samtools view -Shb ${name}.dsDNA.RH.sam        >${name}.dsDNA.US.bam\n  samtools view -Shb ${name}.dsDNA_strict.RH.sam >${name}.dsDNA_strict.US.bam\n  samtools view -Shb ${name}.unclassified.RH.sam >${name}.unclassified.US.bam\n\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.ssDNA_type1.US.bam  O=${name}.ssDNA_type1.bam  SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.ssDNA_type2.US.bam  O=${name}.ssDNA_type2.bam  SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.dsDNA.US.bam        O=${name}.dsDNA.bam        SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.dsDNA_strict.US.bam O=${name}.dsDNA_strict.bam SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.unclassified.US.bam O=${name}.unclassified.bam SO=coordinate VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${name}.ssDNA_type1.bam\n  samtools index ${name}.ssDNA_type2.bam\n  samtools index ${name}.dsDNA.bam\n  samtools index ${name}.dsDNA_strict.bam\n  samtools index ${name}.unclassified.bam\n  \"\"\"",
        "nb_lignes_script": 40,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "bam"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag {bam}",
            "cpus 4",
            "memory '12 GB'",
            "time { 6.hour * task.attempt}",
            "errorStrategy 'retry'",
            "maxRetries 1"
        ],
        "when": "",
        "stub": ""
    },
    "gatherITROutputs": {
        "name_process": "gatherITROutputs",
        "string_process": "\nprocess gatherITROutputs {\n\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*txt'\n  publishDir \"${params.outdir}/bam\",     mode: 'copy', overwrite: true, pattern: '*bam*'\n  publishDir \"${params.outdir}/bed\",     mode: 'copy', overwrite: true, pattern: '*bed*'\n\n  tag {bam}\n\n  time { bam.size() < 100 ? 2.hour : 2.hour * (1 + bam.size()/100 * task.attempt) }\n\n  input:\n  path(bam)\n  path(bed)\n  val(type)\n\n  output:\n  tuple(path('*bam'), path('*bai'), emit: bambai)\n  tuple(path('*bam'), path('*bai'), path('*bed'), path('*metrics.txt'), emit: itrFinal)\n  path('*.txt*', emit: report)\n  path('*.bam*', emit: bam)\n  path('*.bed',  emit: bed)\n\n  script:\n  def name=\"${params.name}.${params.genome}.${type}\"\n  \"\"\"\n  java -jar -Xmx8g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" O=${name}.US.BAM `ls *${type}.bam | sed 's/.*\\$/I=& /'`\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.US.BAM   O=${name}.S.BAM   SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR MarkDuplicatesWithMateCigar TMP_DIR=\"\\$TMPDIR\" I=${name}.S.BAM  O=${name}.bam  PG=Picard2.9.2_MarkDuplicates M=${name}.MDmetrics.txt  CREATE_INDEX=false VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${name}.bam\n\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 -m *${type}.bed  >${name}.bed\n  rm -f ${name}.US.BAM\n  rm -f ${name}.S.BAM\n    \"\"\"\n  }",
        "nb_lignes_process": 35,
        "string_script": "  def name=\"${params.name}.${params.genome}.${type}\"\n  \"\"\"\n  java -jar -Xmx8g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" O=${name}.US.BAM `ls *${type}.bam | sed 's/.*\\$/I=& /'`\n  java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${name}.US.BAM   O=${name}.S.BAM   SO=coordinate VALIDATION_STRINGENCY=LENIENT\n  java -jar -Xmx8g \\$PICARDJAR MarkDuplicatesWithMateCigar TMP_DIR=\"\\$TMPDIR\" I=${name}.S.BAM  O=${name}.bam  PG=Picard2.9.2_MarkDuplicates M=${name}.MDmetrics.txt  CREATE_INDEX=false VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${name}.bam\n\n  sort -k1,1 -k2n,2n -k3n,3n -k4,4 -k5,5 -k6,6 -m *${type}.bed  >${name}.bed\n  rm -f ${name}.US.BAM\n  rm -f ${name}.S.BAM\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bam",
            "bed",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*txt'",
            "publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*bam*'",
            "publishDir \"${params.outdir}/bed\", mode: 'copy', overwrite: true, pattern: '*bed*'",
            "tag {bam}",
            "time { bam.size() < 100 ? 2.hour : 2.hour * (1 + bam.size()/100 * task.attempt) }"
        ],
        "when": "",
        "stub": ""
    },
    "makeFRBWssds": {
        "name_process": "makeFRBWssds",
        "string_process": "\nprocess makeFRBWssds {\n\n  publishDir \"${params.outdir}/bigwig\", mode: 'copy', overwrite: true, pattern: '*bigwig*'\n\n  cpus 2\n  memory '12 GB'\n\n  tag {bam}\n  time { bam.size()< 2000000000 ? 1.hour * task.attempt : 1.hour * bam.size()/2000000000 * task.attempt }\n\n  errorStrategy { 'retry' }\n  maxRetries 1\n\n  input:\n  tuple path(bam), path(idx)\n\n  output:\n  path('*.bigwig', emit: bw)\n\n  script:\n  iName = bam.name.replaceAll(/.bam/,\".out\")\n\n  \"\"\"\n  if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n    idx=\"${params.genome_fai}\";\n\n    bedtools makewindows  -g \\$idx -w 1000 -s 100 |sort -k1,1 -k2n,2n |perl -lane 'print \\$_ if ((\\$F[2]-\\$F[1]) == 1000)' >win.bed\n    java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${bam} O=qSort.bam SO=queryname VALIDATION_STRINGENCY=LENIENT\n    bedtools bamtobed -mate1 -i qSort.bam -bedpe >frags.bedpe\n\n    perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[1], \\$F[5], @F[6..8]) if (\\$F[8] eq \"+\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.POS.bed\n    perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[4], \\$F[2], @F[6..8]) if (\\$F[8] eq \"-\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.NEG.bed\n\n    mapBed -a win.bed -b frags.POS.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >pos.bg\n    mapBed -a win.bed -b frags.NEG.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >neg.bg\n\n    paste pos.bg neg.bg |perl -lane '\\$F[3]+=0.5; \\$F[7]+=0.5; \\$v=(\\$F[3]/\\$F[7]); print join(\"\\\\t\",@F[0..2],(log(\\$v)/log(2)))' >fr.bg\n    paste pos.bg neg.bg |perl -lane '\\$v=(\\$F[3]+\\$F[7]); print join(\"\\\\t\",@F[0..2],\\$v)' >tot.bg\n\n    bedGraphToBigWig pos.bg \\$idx ${iName}.F.bigwig\n    bedGraphToBigWig neg.bg \\$idx ${iName}.R.bigwig\n    bedGraphToBigWig fr.bg  \\$idx ${iName}.FR.bigwig\n    bedGraphToBigWig tot.bg \\$idx ${iName}.Tot.bigwig\n  else\n    touch \"EMPTY_TOOFEWREADS_${iName}.F.bigwig\n    touch \"EMPTY_TOOFEWREADS_${iName}.R.bigwig\n    touch \"EMPTY_TOOFEWREADS_${iName}.FR.bigwig\n    touch \"EMPTY_TOOFEWREADS_${iName}.Tot.bigwig\n  fi\n  \"\"\"\n  }",
        "nb_lignes_process": 50,
        "string_script": "  iName = bam.name.replaceAll(/.bam/,\".out\")\n\n  \"\"\"\n  if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n    idx=\"${params.genome_fai}\";\n\n    bedtools makewindows  -g \\$idx -w 1000 -s 100 |sort -k1,1 -k2n,2n |perl -lane 'print \\$_ if ((\\$F[2]-\\$F[1]) == 1000)' >win.bed\n    java -jar -Xmx8g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" I=${bam} O=qSort.bam SO=queryname VALIDATION_STRINGENCY=LENIENT\n    bedtools bamtobed -mate1 -i qSort.bam -bedpe >frags.bedpe\n\n    perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[1], \\$F[5], @F[6..8]) if (\\$F[8] eq \"+\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.POS.bed\n    perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[4], \\$F[2], @F[6..8]) if (\\$F[8] eq \"-\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.NEG.bed\n\n    mapBed -a win.bed -b frags.POS.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >pos.bg\n    mapBed -a win.bed -b frags.NEG.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >neg.bg\n\n    paste pos.bg neg.bg |perl -lane '\\$F[3]+=0.5; \\$F[7]+=0.5; \\$v=(\\$F[3]/\\$F[7]); print join(\"\\\\t\",@F[0..2],(log(\\$v)/log(2)))' >fr.bg\n    paste pos.bg neg.bg |perl -lane '\\$v=(\\$F[3]+\\$F[7]); print join(\"\\\\t\",@F[0..2],\\$v)' >tot.bg\n\n    bedGraphToBigWig pos.bg \\$idx ${iName}.F.bigwig\n    bedGraphToBigWig neg.bg \\$idx ${iName}.R.bigwig\n    bedGraphToBigWig fr.bg  \\$idx ${iName}.FR.bigwig\n    bedGraphToBigWig tot.bg \\$idx ${iName}.Tot.bigwig\n  else\n    touch \"EMPTY_TOOFEWREADS_${iName}.F.bigwig\n    touch \"EMPTY_TOOFEWREADS_${iName}.R.bigwig\n    touch \"EMPTY_TOOFEWREADS_${iName}.FR.bigwig\n    touch \"EMPTY_TOOFEWREADS_${iName}.Tot.bigwig\n  fi\n  \"\"\"",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [
            "DINAMelt",
            "BEDTools",
            "bedGraphToBigWig"
        ],
        "tools_url": [
            "https://bio.tools/dinamelt",
            "https://bio.tools/bedtools",
            "https://bio.tools/bedgraphtobigwig"
        ],
        "tools_dico": [
            {
                "name": "DINAMelt",
                "uri": "https://bio.tools/dinamelt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein secondary structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0082",
                            "term": "Structure prediction"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0099",
                            "term": "RNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein features (secondary structure)"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Fold recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Protein secondary structure prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0483",
                                    "term": "RNA inverse folding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0278",
                                    "term": "RNA secondary structure prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Protein domain prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Fold prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Protein fold recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Domain prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Protein fold prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Secondary structure prediction (protein)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0483",
                                    "term": "Nucleic acid folding family identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0483",
                                    "term": "Structured RNA prediction and optimisation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "DINAMelt is a tool for predicting hybridization and folding (secondary structure) of DNA and RNA using equilibrium thermodynamic methods.",
                "homepage": "http://mfold.rna.albany.edu/?q=DINAMelt"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "bedGraphToBigWig",
                "uri": "https://bio.tools/bedgraphtobigwig",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Convert bedGraph to bigWig file.",
                "homepage": "https://www.encodeproject.org/software/bedgraphtobigwig/"
            }
        ],
        "inputs": [
            "bam",
            "idx"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/bigwig\", mode: 'copy', overwrite: true, pattern: '*bigwig*'",
            "cpus 2",
            "memory '12 GB'",
            "tag {bam}",
            "time { bam.size()< 2000000000 ? 1.hour * task.attempt : 1.hour * bam.size()/2000000000 * task.attempt }",
            "errorStrategy { 'retry' }",
            "maxRetries 1"
        ],
        "when": "",
        "stub": ""
    },
    "makeSSreport": {
        "name_process": "makeSSreport",
        "string_process": "\nprocess makeSSreport {\n\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true\n\n  tag {bam}\n\n  input:\n  tuple path(bam), path(bai)\n  path(ssfiles)\n\n  output:\n  path('*SSDSreport*', emit: report)\n\n  script:\n  \"\"\"\n  echo \"makeSSMultiQCReport_nextFlow.pl ${bam} \"`ls *bed`\" --g ${params.genome}\"\n  makeSSMultiQCReport_nextFlow.pl ${bam} `ls *bed` --g ${params.genome}\n\n  \"\"\"\n  }",
        "nb_lignes_process": 19,
        "string_script": "  \"\"\"\n  echo \"makeSSMultiQCReport_nextFlow.pl ${bam} \"`ls *bed`\" --g ${params.genome}\"\n  makeSSMultiQCReport_nextFlow.pl ${bam} `ls *bed` --g ${params.genome}\n\n  \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bam",
            "bai",
            "ssfiles"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true",
            "tag {bam}"
        ],
        "when": "",
        "stub": ""
    },
    "multiQCssds": {
        "name_process": "multiQCssds",
        "string_process": "\nprocess multiQCssds {\n\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true\n\n  tag {reports}\n\n  input:\n  path(reports)\n\n  output:\n  path('*ultiQC*', emit: mqcReport)\n\n  script:\n  \"\"\"\n  multiqc -f -m ssds -n ${params.name}.multiQC .\n  \"\"\"\n  }",
        "nb_lignes_process": 16,
        "string_script": "  \"\"\"\n  multiqc -f -m ssds -n ${params.name}.multiQC .\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "reports"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true",
            "tag {reports}"
        ],
        "when": "",
        "stub": ""
    },
    "getB6xCASThotspots": {
        "name_process": "getB6xCASThotspots",
        "string_process": "process getB6xCASThotspots {\n\n  cpus 2\n  memory '4g'\n\n  time { 1.hour * task.attempt }\n\n  errorStrategy { 'retry' }\n  maxRetries 1\n\n  input:\n  path(mm10FA)\n  path(mm10IDX)\n  path(mm10w1ks100)\n\n  output:\n\tpath('*.oneMotif.500bp.bed', emit: hotspotOneMotif500bp)\n\tpath('*_maleHS.3Kb.bedgraph', emit: hotspotsBG3Kbp)\n\tpath('B6_maleHS.3Kb.bed', emit: hotspotsBED3Kbp)\n\tpath('*oneMotif.500bp.bed', emit: hotspotsOneMotif500bp)\n\tpath('*oneMotif.3Kb.bed', emit: hotspotsOneMotif3Kb)\n  path('B6_maleHS.1bp.bedgraph', emit: hotspotBG1bp)\n  path('B6_maleHS.500bp.bedgraph', emit: hotspotBG500bp)\n  path('B6_maleHS.1Kb.bed', emit: hotspotBED)\n\tpath('CST_maleHS.1bp.bedgraph', emit: cstHotspotBG1bp)\n  path('CST_maleHS.500bp.bedgraph', emit: cstHotspotBG500bp)\n\tpath('CST_maleHS.3Kb.bedgraph', emit: cstHotspotBG3Kbp)\n  path('CST_maleHS.1Kb.bed', emit: cstHotspotBED)\n\tpath('B6xCST.heat.bedgraph', emit: b6xcst_HeatBG)\n\tpath('B6xCST.bias.bedgraph', emit: b6xcst_BiasBG)\n  path('B6xCST.details.tab', emit: b6xcst_details)\n\tpath('B6xCST_maleHS.3Kb.bed', emit: hotspotsBEDBxC3Kbp)\n\n  script:\n  \"\"\"\n\t## get B6 hotspots\n  wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2664nnn/GSM2664275/suppl/GSM2664275_Testis_SSDS_T1.DSBhotspots.bedgraph.gz\n  gunzip -c GSM2664275_Testis_SSDS_T1.DSBhotspots.bedgraph.gz |cut -f1-3,6 |grep -P \\'^chr[0-9]+\\' >B6_maleHS.bedgraph\n\n \tbedtools slop -l -0.5 -r -0.5 -pct -i B6_maleHS.bedgraph -g ${mm10IDX} |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6_maleHS.1bp.bedgraph\n  cut -f1-3 B6_maleHS.1bp.bedgraph                                                                                       >B6_maleHS.1bp.bed\n\n \tbedtools slop -l 250  -r 250       -i B6_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6_maleHS.500bp.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6_maleHS.3Kb.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6_maleHS.1bp.bedgraph          -g ${mm10IDX} |cut -f1-3 >B6_maleHS.3Kb.bed\n\n\tbedtools slop -l 500 -r 500      -i B6_maleHS.1bp.bedgraph            -g ${mm10IDX} |cut -f1-3 >B6_maleHS.1Kb.bed\n\n  perl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' B6_maleHS.500bp.bedgraph >B6HS500forFIMO.bed\n  bedtools getfasta -fi ${mm10FA} -bed B6HS500forFIMO.bed -name -fo B6_maleHS.500bp.fa\n\n\trm -rf fimo\n  fimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo1 ${params.accessorydir}/PRDM9motif/PRBS_B6.MEMEv4.pwm B6_maleHS.500bp.fa\n\n  perl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo1/fimo.tsv --w 250 --out B6.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6.oneMotif.500bp.bed -g ${mm10IDX} >B6.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i B6.oneMotif.1bp.bed   -g ${mm10IDX} >B6.oneMotif.3Kb.bed\n\n\t## get CST hotspots\n  wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1954nnn/GSM1954846/suppl/GSM1954846%5FCAST%5Fhotspots%2Etab%2Egz\n  gunzip -c GSM1954846_CAST_hotspots.tab.gz |cut -f1-3,4 |grep -P \\'^chr[0-9]+\\' >CST_maleHS.bedgraph\n\n \tbedtools slop -l -0.5 -r -0.5 -pct -i CST_maleHS.bedgraph -g ${mm10IDX} |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >CST_maleHS.1bp.bedgraph\n  cut -f1-3 CST_maleHS.1bp.bedgraph                                                                                       >CST_maleHS.1bp.bed\n\n \tbedtools slop -l 250  -r 250       -i CST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >CST_maleHS.500bp.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i CST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >CST_maleHS.3Kb.bedgraph\n\n\tbedtools slop -l 500 -r 500      -i CST_maleHS.1bp.bedgraph            -g ${mm10IDX} |cut -f1-3 >CST_maleHS.1Kb.bed\n\n  perl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' CST_maleHS.500bp.bedgraph >CSTHS500forFIMO.bed\n  bedtools getfasta -fi ${mm10FA} -bed CSTHS500forFIMO.bed -name -fo CST_maleHS.500bp.fa\n\n\trm -rf fimo\n  fimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo2 ${params.accessorydir}/PRDM9motif/PRBS_CST.MEMEv4.pwm CST_maleHS.500bp.fa\n\n  perl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo2/fimo.tsv --w 250 --out CST.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i CST.oneMotif.500bp.bed -g ${mm10IDX} >CST.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i CST.oneMotif.1bp.bed   -g ${mm10IDX} >CST.oneMotif.3Kb.bed\n\n\t## get CSTXb6 hotspots\n  wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2049nnn/GSM2049312/suppl/GSM2049312%5Fdmc1hotspots%5FB6CASTF1%2EPRDM9bc%2Etxt%2Egz\n\n\tgunzip -c GSM2049312_dmc1hotspots_B6CASTF1.PRDM9bc.txt.gz |grep -v heat |perl -lane 'print \"chr\".join(\"\\\\t\",\\$F[0],\\$F[1]-500,\\$F[1]+500,\\$F[2])' >B6xCST.heat.bedgraph\n\tgunzip -c GSM2049312_dmc1hotspots_B6CASTF1.PRDM9bc.txt.gz |grep -v heat |perl -lane 'print \"chr\".join(\"\\\\t\",\\$F[0],\\$F[1]-500,\\$F[1]+500,(\\$F[3] == NA?\"0.5\":\\$F[3]))' >B6xCST.bias.bedgraph\n  gunzip -c GSM2049312_dmc1hotspots_B6CASTF1.PRDM9bc.txt.gz |grep -v heat |perl -lane 'print \"chr\".join(\"\\\\t\",\\$F[0],\\$F[1]-500,\\$F[1]+500,\\$F[2],\\$F[3])' >B6xCST.bg\n\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST.bg -g ${mm10IDX} |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6xCST_maleHS.1bp.bedgraph\n\n \tbedtools slop -l 250  -r 250       -i B6xCST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6xCST_maleHS.500bp.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6xCST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6xCST_maleHS.3Kb.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6xCST_maleHS.1bp.bedgraph          -g ${mm10IDX} |cut -f1-3 >B6xCST_maleHS.3Kb.bed\n\n  intersectBed -a B6xCST.bg -b CST_maleHS.1Kb.bed -c >C1.bg\n  intersectBed -a C1.bg     -b B6_maleHS.1Kb.bed -c   >C2.bg\n\n  cat C2.bg |perl -lane '\\$type = \"\"; \\$type = \"CST\" if ((\\$F[5] > 0 && \\$F[6] == 0) || (\\$F[5] == 0 && \\$F[6] == 0 && (\\$F[4] > 0.75))); \\$type = \"B6\" if ((\\$F[5] == 0 && \\$F[6] > 0) || (\\$F[5] == 0 && \\$F[6] == 0 && (\\$F[4] < 0.25))); \\$type = \"Ambiguous\" if (not \\$type); print join(\"\\\\t\",@F,\\$type)' |sort -k1,1 -k2n,2n -k3n,3n >B6CST_all.tab\n\n  grep CST B6CST_all.tab |cut -f1-5 >B6xCST.CSTHS.tab\n  grep B6 B6CST_all.tab  |cut -f1-5 >B6xCST.B6HS.tab\n\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST.CSTHS.tab -g ${mm10IDX} |cut -f1-3 |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6xCST.CSTHS.1bp.bedgraph\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST.B6HS.tab   -g ${mm10IDX} |cut -f1-3 |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6xCST.B6HS.1bp.bedgraph\n\n\tbedtools slop -l 250  -r 250       -i B6xCST.CSTHS.1bp.bedgraph          -g ${mm10IDX}            >B6xCST.CSTHS.500bp.bedgraph\n\tbedtools slop -l 250  -r 250       -i B6xCST.B6HS.1bp.bedgraph            -g ${mm10IDX}            >B6xCST.B6HS.500bp.bedgraph\n\n  paste B6xCST.bias.bedgraph B6xCST.heat.bedgraph |cut -f1-4,8 >B6xCST.heatbias.tmp\n  intersectBed -a B6xCST.bias.bedgraph -b B6xCST.B6HS.1bp.bedgraph  -c |cut -f5 >likely_b6_defined.tab\n  intersectBed -a B6xCST.bias.bedgraph -b B6xCST.CSTHS.1bp.bedgraph -c |cut -f5 >likely_cast_defined.tab\n\n  echo -e \"cs\\\\tfrom\\\\tto\\\\tbias\\\\theat\\\\tB6\\\\tCAST\"                       >B6xCST.details.tab\n  paste B6xCST.heatbias.tmp likely_b6_defined.tab likely_cast_defined.tab >>B6xCST.details.tab\n\n  perl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' B6xCST.CSTHS.500bp.bedgraph >BxC_CSTHS500forFIMO.bed\n\tperl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' B6xCST.B6HS.500bp.bedgraph   >BxC_B6HS500forFIMO.bed\n\n\tbedtools getfasta -fi ${mm10FA} -bed BxC_CSTHS500forFIMO.bed -name -fo BxC_CST_maleHS.500bp.fa\n\tbedtools getfasta -fi ${mm10FA} -bed BxC_B6HS500forFIMO.bed   -name -fo BxC_B6_maleHS.500bp.fa\n\n  rm -rf fimo\n\tfimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo3 ${params.accessorydir}/PRDM9motif/PRBS_CST.MEMEv4.pwm BxC_CST_maleHS.500bp.fa\n\tperl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo3/fimo.tsv --w 250 --out B6xCST_CSTHS.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST_CSTHS.oneMotif.500bp.bed -g ${mm10IDX} >B6xCST_CSTHS.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i B6xCST_CSTHS.oneMotif.1bp.bed   -g ${mm10IDX} >B6xCST_CSTHS.oneMotif.3Kb.bed\n\n  rm -rf fimo\n\tfimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo4 ${params.accessorydir}/PRDM9motif/PRBS_B6.MEMEv4.pwm BxC_B6_maleHS.500bp.fa\n\tperl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo4/fimo.tsv --w 250 --out B6xCST_B6HS.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST_B6HS.oneMotif.500bp.bed -g ${mm10IDX} >B6xCST_B6HS.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i B6xCST_B6HS.oneMotif.1bp.bed   -g ${mm10IDX} >B6xCST_B6HS.oneMotif.3Kb.bed\n\n\tsort -k1,1 -k2n,2n -k3n,3n B6xCST_CSTHS.oneMotif.500bp.bed B6xCST_B6HS.oneMotif.500bp.bed >B6xCST.oneMotif.500bp.bed\n\tsort -k1,1 -k2n,2n -k3n,3n B6xCST_CSTHS.oneMotif.3Kb.bed B6xCST_B6HS.oneMotif.3Kb.bed     >B6xCST.oneMotif.3Kb.bed\n\n  \"\"\"\n  }",
        "nb_lignes_process": 135,
        "string_script": "  \"\"\"\n\t## get B6 hotspots\n  wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2664nnn/GSM2664275/suppl/GSM2664275_Testis_SSDS_T1.DSBhotspots.bedgraph.gz\n  gunzip -c GSM2664275_Testis_SSDS_T1.DSBhotspots.bedgraph.gz |cut -f1-3,6 |grep -P \\'^chr[0-9]+\\' >B6_maleHS.bedgraph\n\n \tbedtools slop -l -0.5 -r -0.5 -pct -i B6_maleHS.bedgraph -g ${mm10IDX} |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6_maleHS.1bp.bedgraph\n  cut -f1-3 B6_maleHS.1bp.bedgraph                                                                                       >B6_maleHS.1bp.bed\n\n \tbedtools slop -l 250  -r 250       -i B6_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6_maleHS.500bp.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6_maleHS.3Kb.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6_maleHS.1bp.bedgraph          -g ${mm10IDX} |cut -f1-3 >B6_maleHS.3Kb.bed\n\n\tbedtools slop -l 500 -r 500      -i B6_maleHS.1bp.bedgraph            -g ${mm10IDX} |cut -f1-3 >B6_maleHS.1Kb.bed\n\n  perl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' B6_maleHS.500bp.bedgraph >B6HS500forFIMO.bed\n  bedtools getfasta -fi ${mm10FA} -bed B6HS500forFIMO.bed -name -fo B6_maleHS.500bp.fa\n\n\trm -rf fimo\n  fimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo1 ${params.accessorydir}/PRDM9motif/PRBS_B6.MEMEv4.pwm B6_maleHS.500bp.fa\n\n  perl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo1/fimo.tsv --w 250 --out B6.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6.oneMotif.500bp.bed -g ${mm10IDX} >B6.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i B6.oneMotif.1bp.bed   -g ${mm10IDX} >B6.oneMotif.3Kb.bed\n\n\t## get CST hotspots\n  wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM1954nnn/GSM1954846/suppl/GSM1954846%5FCAST%5Fhotspots%2Etab%2Egz\n  gunzip -c GSM1954846_CAST_hotspots.tab.gz |cut -f1-3,4 |grep -P \\'^chr[0-9]+\\' >CST_maleHS.bedgraph\n\n \tbedtools slop -l -0.5 -r -0.5 -pct -i CST_maleHS.bedgraph -g ${mm10IDX} |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >CST_maleHS.1bp.bedgraph\n  cut -f1-3 CST_maleHS.1bp.bedgraph                                                                                       >CST_maleHS.1bp.bed\n\n \tbedtools slop -l 250  -r 250       -i CST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >CST_maleHS.500bp.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i CST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >CST_maleHS.3Kb.bedgraph\n\n\tbedtools slop -l 500 -r 500      -i CST_maleHS.1bp.bedgraph            -g ${mm10IDX} |cut -f1-3 >CST_maleHS.1Kb.bed\n\n  perl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' CST_maleHS.500bp.bedgraph >CSTHS500forFIMO.bed\n  bedtools getfasta -fi ${mm10FA} -bed CSTHS500forFIMO.bed -name -fo CST_maleHS.500bp.fa\n\n\trm -rf fimo\n  fimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo2 ${params.accessorydir}/PRDM9motif/PRBS_CST.MEMEv4.pwm CST_maleHS.500bp.fa\n\n  perl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo2/fimo.tsv --w 250 --out CST.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i CST.oneMotif.500bp.bed -g ${mm10IDX} >CST.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i CST.oneMotif.1bp.bed   -g ${mm10IDX} >CST.oneMotif.3Kb.bed\n\n\t## get CSTXb6 hotspots\n  wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2049nnn/GSM2049312/suppl/GSM2049312%5Fdmc1hotspots%5FB6CASTF1%2EPRDM9bc%2Etxt%2Egz\n\n\tgunzip -c GSM2049312_dmc1hotspots_B6CASTF1.PRDM9bc.txt.gz |grep -v heat |perl -lane 'print \"chr\".join(\"\\\\t\",\\$F[0],\\$F[1]-500,\\$F[1]+500,\\$F[2])' >B6xCST.heat.bedgraph\n\tgunzip -c GSM2049312_dmc1hotspots_B6CASTF1.PRDM9bc.txt.gz |grep -v heat |perl -lane 'print \"chr\".join(\"\\\\t\",\\$F[0],\\$F[1]-500,\\$F[1]+500,(\\$F[3] == NA?\"0.5\":\\$F[3]))' >B6xCST.bias.bedgraph\n  gunzip -c GSM2049312_dmc1hotspots_B6CASTF1.PRDM9bc.txt.gz |grep -v heat |perl -lane 'print \"chr\".join(\"\\\\t\",\\$F[0],\\$F[1]-500,\\$F[1]+500,\\$F[2],\\$F[3])' >B6xCST.bg\n\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST.bg -g ${mm10IDX} |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6xCST_maleHS.1bp.bedgraph\n\n \tbedtools slop -l 250  -r 250       -i B6xCST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6xCST_maleHS.500bp.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6xCST_maleHS.1bp.bedgraph          -g ${mm10IDX}            >B6xCST_maleHS.3Kb.bedgraph\n\tbedtools slop -l 1500 -r 1500      -i B6xCST_maleHS.1bp.bedgraph          -g ${mm10IDX} |cut -f1-3 >B6xCST_maleHS.3Kb.bed\n\n  intersectBed -a B6xCST.bg -b CST_maleHS.1Kb.bed -c >C1.bg\n  intersectBed -a C1.bg     -b B6_maleHS.1Kb.bed -c   >C2.bg\n\n  cat C2.bg |perl -lane '\\$type = \"\"; \\$type = \"CST\" if ((\\$F[5] > 0 && \\$F[6] == 0) || (\\$F[5] == 0 && \\$F[6] == 0 && (\\$F[4] > 0.75))); \\$type = \"B6\" if ((\\$F[5] == 0 && \\$F[6] > 0) || (\\$F[5] == 0 && \\$F[6] == 0 && (\\$F[4] < 0.25))); \\$type = \"Ambiguous\" if (not \\$type); print join(\"\\\\t\",@F,\\$type)' |sort -k1,1 -k2n,2n -k3n,3n >B6CST_all.tab\n\n  grep CST B6CST_all.tab |cut -f1-5 >B6xCST.CSTHS.tab\n  grep B6 B6CST_all.tab  |cut -f1-5 >B6xCST.B6HS.tab\n\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST.CSTHS.tab -g ${mm10IDX} |cut -f1-3 |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6xCST.CSTHS.1bp.bedgraph\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST.B6HS.tab   -g ${mm10IDX} |cut -f1-3 |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >B6xCST.B6HS.1bp.bedgraph\n\n\tbedtools slop -l 250  -r 250       -i B6xCST.CSTHS.1bp.bedgraph          -g ${mm10IDX}            >B6xCST.CSTHS.500bp.bedgraph\n\tbedtools slop -l 250  -r 250       -i B6xCST.B6HS.1bp.bedgraph            -g ${mm10IDX}            >B6xCST.B6HS.500bp.bedgraph\n\n  paste B6xCST.bias.bedgraph B6xCST.heat.bedgraph |cut -f1-4,8 >B6xCST.heatbias.tmp\n  intersectBed -a B6xCST.bias.bedgraph -b B6xCST.B6HS.1bp.bedgraph  -c |cut -f5 >likely_b6_defined.tab\n  intersectBed -a B6xCST.bias.bedgraph -b B6xCST.CSTHS.1bp.bedgraph -c |cut -f5 >likely_cast_defined.tab\n\n  echo -e \"cs\\\\tfrom\\\\tto\\\\tbias\\\\theat\\\\tB6\\\\tCAST\"                       >B6xCST.details.tab\n  paste B6xCST.heatbias.tmp likely_b6_defined.tab likely_cast_defined.tab >>B6xCST.details.tab\n\n  perl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' B6xCST.CSTHS.500bp.bedgraph >BxC_CSTHS500forFIMO.bed\n\tperl -lane \\'\\$nm=join(\"_\",@F[0..2]); print join(\"\\\\t\",@F[0..2],\\$nm,\\$nm,\\$F[3])' B6xCST.B6HS.500bp.bedgraph   >BxC_B6HS500forFIMO.bed\n\n\tbedtools getfasta -fi ${mm10FA} -bed BxC_CSTHS500forFIMO.bed -name -fo BxC_CST_maleHS.500bp.fa\n\tbedtools getfasta -fi ${mm10FA} -bed BxC_B6HS500forFIMO.bed   -name -fo BxC_B6_maleHS.500bp.fa\n\n  rm -rf fimo\n\tfimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo3 ${params.accessorydir}/PRDM9motif/PRBS_CST.MEMEv4.pwm BxC_CST_maleHS.500bp.fa\n\tperl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo3/fimo.tsv --w 250 --out B6xCST_CSTHS.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST_CSTHS.oneMotif.500bp.bed -g ${mm10IDX} >B6xCST_CSTHS.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i B6xCST_CSTHS.oneMotif.1bp.bed   -g ${mm10IDX} >B6xCST_CSTHS.oneMotif.3Kb.bed\n\n  rm -rf fimo\n\tfimo --max-stored-scores 1000000 --thresh 1e-3 --o fimo4 ${params.accessorydir}/PRDM9motif/PRBS_B6.MEMEv4.pwm BxC_B6_maleHS.500bp.fa\n\tperl ${params.codedir}/getHotspotsWithSingleMotif.pl --fimo  ./fimo4/fimo.tsv --w 250 --out B6xCST_B6HS.oneMotif.500bp.bed\n\tbedtools slop -l -0.5 -r -0.5 -pct -i B6xCST_B6HS.oneMotif.500bp.bed -g ${mm10IDX} >B6xCST_B6HS.oneMotif.1bp.bed\n\tbedtools slop -l 1500 -r 1500 -pct -i B6xCST_B6HS.oneMotif.1bp.bed   -g ${mm10IDX} >B6xCST_B6HS.oneMotif.3Kb.bed\n\n\tsort -k1,1 -k2n,2n -k3n,3n B6xCST_CSTHS.oneMotif.500bp.bed B6xCST_B6HS.oneMotif.500bp.bed >B6xCST.oneMotif.500bp.bed\n\tsort -k1,1 -k2n,2n -k3n,3n B6xCST_CSTHS.oneMotif.3Kb.bed B6xCST_B6HS.oneMotif.3Kb.bed     >B6xCST.oneMotif.3Kb.bed\n\n  \"\"\"",
        "nb_lignes_script": 101,
        "language_script": "bash",
        "tools": [
            "BEDTools",
            "meme_fimo"
        ],
        "tools_url": [
            "https://bio.tools/bedtools",
            "https://bio.tools/meme_fimo"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "meme_fimo",
                "uri": "https://bio.tools/meme_fimo",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3473",
                            "term": "Data mining"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Nucleic acid feature detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0238",
                                    "term": "Sequence motif discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3092",
                                    "term": "Protein feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Sequence feature detection (nucleic acid)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0238",
                                    "term": "Motif discovery"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3092",
                                    "term": "Protein feature prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3092",
                                    "term": "Protein feature recognition"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "A software tool for scanning DNA or protein sequences with motifs described as position-specific scoring matrices.",
                "homepage": "http://meme-suite.org/tools/meme"
            }
        ],
        "inputs": [
            "mm10FA",
            "mm10IDX",
            "mm10w1ks100"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "cpus 2",
            "memory '4g'",
            "time { 1.hour * task.attempt }",
            "errorStrategy { 'retry' }",
            "maxRetries 1"
        ],
        "when": "",
        "stub": ""
    },
    "getGENCODE": {
        "name_process": "getGENCODE",
        "string_process": "\nprocess getGENCODE {\n  cpus 2\n  memory '4g'\n  time { 1.hour * task.attempt }\n\n  errorStrategy { 'retry' }\n  maxRetries 1\n\n                        \n                             \n                     \n                        \n                      \n\n  input:\n  path(mm10FA)\n  path(mm10IDX)\n  path(mm10w1ks100)\n\n  output:\n  path('gencodeTSS.1Kb.bed', emit: tssBEDa)\n  path('gencodeTES.1Kb.bed', emit: gencodeTESBED)\n  path('gencodeGene.bed', emit: gencodeGeneBED)\n\tpath('refseqTSS.bed', emit: refseqTSSb)\n\n  script:\n  \"\"\"\n  ##GENCODE\n  wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M20/gencode.vM20.annotation.gtf.gz\n  ##TSS\n  perl ${params.codedir}/gencodeGTFtoTSS.pl gencode.vM20.annotation.gtf.gz |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >gencodeTSS.1bp.noMerge.bed\n\n  bedtools slop -l 500 -r 500   -i gencodeTSS.1bp.noMerge.bed -g ${mm10IDX} >gencodeTSS.1Kb.noMerge.bed\n  mergeBed -i gencodeTSS.1Kb.noMerge.bed -c 4,5,6 -o distinct,distinct,distinct |grep -vP '([\\\\+\\\\-],[\\\\+\\\\-])' |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX}            >gencodeTSS.1Kb.bed\n  mergeBed -i gencodeTSS.1Kb.noMerge.bed -c 4,5,6 -o distinct,distinct,distinct |grep -vP '([\\\\+\\\\-],[\\\\+\\\\-])' |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} |cut -f1-3 >gencodeTSS.1Kb3Col.bed\n\n  cat gencodeTSS.1KbDets.bed |perl -lane \\'print join(\"\\\\t\",@F[0..2],0,@F[4..5])\\'                           >gencodeTSS.1Kb.forMerge.bed\n\n  ##TES\n  perl ${params.codedir}/gencodeGTFtoTES.pl gencode.vM20.annotation.gtf.gz |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} |grep -P \"\\\\s+\" >gencodeTES.1bp.noMerge.bed\n\n  bedtools slop -l 500 -r 500   -i gencodeTES.1bp.noMerge.bed -g ${mm10IDX} >gencodeTES.1Kb.noMerge.bed\n  mergeBed -i gencodeTES.1Kb.noMerge.bed -c 4,5,6 -o distinct,distinct,first |\\\n                                          ${params.codedir}/sortBEDByFAI.pl - \\\n                                          ${mm10IDX} >gencodeTES.1Kb.bed\n\n  ##GENES\n  perl ${params.codedir}/gencodeGTFtoCDS.pl gencode.vM20.annotation.gtf.gz |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >gencodeGene.noMerge.bed\n  mergeBed -s -i gencodeGene.noMerge.bed -c 4,5,6 \\\n           -o distinct,distinct,first |${params.codedir}/sortBEDByFAI.pl - \\\n          ${mm10IDX} |grep -P \"\\\\s+\" >gencodeGene.bed\n\n\t##REFSEQ - move to annotation section later\n\twget http://hgdownload.soe.ucsc.edu/goldenPath/mm10/database/ncbiRefSeqCurated.txt.gz\n\tperl ${params.codedir}/parseRefSeq.pl ncbiRefSeqCurated.txt.gz TSS  |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >refseqTSS.bed\n  \"\"\"\n  }",
        "nb_lignes_process": 56,
        "string_script": "  \"\"\"\n  ##GENCODE\n  wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M20/gencode.vM20.annotation.gtf.gz\n  ##TSS\n  perl ${params.codedir}/gencodeGTFtoTSS.pl gencode.vM20.annotation.gtf.gz |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >gencodeTSS.1bp.noMerge.bed\n\n  bedtools slop -l 500 -r 500   -i gencodeTSS.1bp.noMerge.bed -g ${mm10IDX} >gencodeTSS.1Kb.noMerge.bed\n  mergeBed -i gencodeTSS.1Kb.noMerge.bed -c 4,5,6 -o distinct,distinct,distinct |grep -vP '([\\\\+\\\\-],[\\\\+\\\\-])' |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX}            >gencodeTSS.1Kb.bed\n  mergeBed -i gencodeTSS.1Kb.noMerge.bed -c 4,5,6 -o distinct,distinct,distinct |grep -vP '([\\\\+\\\\-],[\\\\+\\\\-])' |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} |cut -f1-3 >gencodeTSS.1Kb3Col.bed\n\n  cat gencodeTSS.1KbDets.bed |perl -lane \\'print join(\"\\\\t\",@F[0..2],0,@F[4..5])\\'                           >gencodeTSS.1Kb.forMerge.bed\n\n  ##TES\n  perl ${params.codedir}/gencodeGTFtoTES.pl gencode.vM20.annotation.gtf.gz |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} |grep -P \"\\\\s+\" >gencodeTES.1bp.noMerge.bed\n\n  bedtools slop -l 500 -r 500   -i gencodeTES.1bp.noMerge.bed -g ${mm10IDX} >gencodeTES.1Kb.noMerge.bed\n  mergeBed -i gencodeTES.1Kb.noMerge.bed -c 4,5,6 -o distinct,distinct,first |\\\n                                          ${params.codedir}/sortBEDByFAI.pl - \\\n                                          ${mm10IDX} >gencodeTES.1Kb.bed\n\n  ##GENES\n  perl ${params.codedir}/gencodeGTFtoCDS.pl gencode.vM20.annotation.gtf.gz |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >gencodeGene.noMerge.bed\n  mergeBed -s -i gencodeGene.noMerge.bed -c 4,5,6 \\\n           -o distinct,distinct,first |${params.codedir}/sortBEDByFAI.pl - \\\n          ${mm10IDX} |grep -P \"\\\\s+\" >gencodeGene.bed\n\n\t##REFSEQ - move to annotation section later\n\twget http://hgdownload.soe.ucsc.edu/goldenPath/mm10/database/ncbiRefSeqCurated.txt.gz\n\tperl ${params.codedir}/parseRefSeq.pl ncbiRefSeqCurated.txt.gz TSS  |${params.codedir}/sortBEDByFAI.pl - ${mm10IDX} >refseqTSS.bed\n  \"\"\"",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "mm10FA",
            "mm10IDX",
            "mm10w1ks100"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "cpus 2",
            "memory '4g'",
            "time { 1.hour * task.attempt }",
            "errorStrategy { 'retry' }",
            "maxRetries 1"
        ],
        "when": "",
        "stub": ""
    },
    "getMouseMeiosisChromatinMods": {
        "name_process": "getMouseMeiosisChromatinMods",
        "string_process": "\nprocess getMouseMeiosisChromatinMods {\n  cpus 2\n  memory '4g'\n  time { 1.hour * task.attempt }\n\n  errorStrategy { 'retry' }\n  maxRetries 1\n\n                        \n                             \n                     \n                        \n                      \n\n  input:\n  path(mm10FA)\n  path(mm10IDX)\n  path(mm10w1ks100)\n\n  output:\n\tpath('Zygotene_H3K4me3.peaks.bed', emit: h3k4m3GL)\n\tpath('Zygotene_H3K4me3.peaks.bedgraph', emit: h3k4m3GLBG)\n\tpath('H3K36m3_B6.bedgraph', emit: h3k36m3B6)\n\tpath('H3K36m3_B6Spo11KO.bedgraph', emit: h3k36m3B6Spo11)\n\n  script:\n  \"\"\"\n\t## ZYGO H3K4me3 Peaks\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3734nnn/GSM3734414/suppl/GSM3734414%5FZY%2ER1%2EH3K4me3%2Epeaks%2Ebed%2Egz\n\tgunzip -c GSM3734414_ZY.R1.H3K4me3.peaks.bed.gz |cut -f1-3 >Zygotene_H3K4me3.peaks.bed\n\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3734nnn/GSM3734414/suppl/GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bigwig\n\tbigWigToBedGraph GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bigwig GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bedgraph\n\n\tmapBed -a Zygotene_H3K4me3.peaks.bed -b GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bedgraph -c 4 -o sum |sortBEDByFAI.pl - ${mm10IDX} >Zygotene_H3K4me3.peaks.bedgraph\n\n\t## H3K36m3 Peaks and PRDM9 ChIP-Seq data\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE93nnn/GSE93955/suppl/GSE93955_CHIP_H3K36me3_B6_coverage.bw\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE93nnn/GSE93955/suppl/GSE93955_CHIP_H3K36me3_B6_spo11_coverage.bw\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE93nnn/GSE93955/suppl/GSE93955_CHIP_PRDM9_B6_peaks.bed.gz\n\tbigWigToBedGraph GSE93955_CHIP_H3K36me3_B6_coverage.bw       GSE93955_CHIP_H3K36me3_B6_coverage.mm9.bedgraph\n\tbigWigToBedGraph GSE93955_CHIP_H3K36me3_B6_spo11_coverage.bw GSE93955_CHIP_H3K36me3_B6_spo11_coverage.mm9.bedgraph\n\n\t## GET LIFTOVER CHAIN FILE\n\twget --timestamping ftp://hgdownload.cse.ucsc.edu/goldenPath/mm9/liftOver/mm9ToMm10.over.chain.gz   -O mm9ToMm10.over.chain.gz\n\n\tliftOver GSE93955_CHIP_H3K36me3_B6_coverage.mm9.bedgraph        mm9ToMm10.over.chain.gz  H3K36m3_B6.bgtmp na\n\tliftOver GSE93955_CHIP_H3K36me3_B6_spo11_coverage.mm9.bedgraph  mm9ToMm10.over.chain.gz  H3K36m3_B6Spo11KO.bgtmp na\n\n  cat H3K36m3_B6.bgtmp        |sortBEDByFAI.pl - ${mm10IDX} >H3K36m3_B6.bedgraph\n\tcat H3K36m3_B6Spo11KO.bgtmp |sortBEDByFAI.pl - ${mm10IDX} >H3K36m3_B6Spo11KO.bedgraph\n\n  \"\"\"\n  }",
        "nb_lignes_process": 53,
        "string_script": "  \"\"\"\n\t## ZYGO H3K4me3 Peaks\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3734nnn/GSM3734414/suppl/GSM3734414%5FZY%2ER1%2EH3K4me3%2Epeaks%2Ebed%2Egz\n\tgunzip -c GSM3734414_ZY.R1.H3K4me3.peaks.bed.gz |cut -f1-3 >Zygotene_H3K4me3.peaks.bed\n\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM3734nnn/GSM3734414/suppl/GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bigwig\n\tbigWigToBedGraph GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bigwig GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bedgraph\n\n\tmapBed -a Zygotene_H3K4me3.peaks.bed -b GSM3734414_ZY.R1.H3K4me3.monoCorrected.ws25bp.bedgraph -c 4 -o sum |sortBEDByFAI.pl - ${mm10IDX} >Zygotene_H3K4me3.peaks.bedgraph\n\n\t## H3K36m3 Peaks and PRDM9 ChIP-Seq data\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE93nnn/GSE93955/suppl/GSE93955_CHIP_H3K36me3_B6_coverage.bw\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE93nnn/GSE93955/suppl/GSE93955_CHIP_H3K36me3_B6_spo11_coverage.bw\n\twget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE93nnn/GSE93955/suppl/GSE93955_CHIP_PRDM9_B6_peaks.bed.gz\n\tbigWigToBedGraph GSE93955_CHIP_H3K36me3_B6_coverage.bw       GSE93955_CHIP_H3K36me3_B6_coverage.mm9.bedgraph\n\tbigWigToBedGraph GSE93955_CHIP_H3K36me3_B6_spo11_coverage.bw GSE93955_CHIP_H3K36me3_B6_spo11_coverage.mm9.bedgraph\n\n\t## GET LIFTOVER CHAIN FILE\n\twget --timestamping ftp://hgdownload.cse.ucsc.edu/goldenPath/mm9/liftOver/mm9ToMm10.over.chain.gz   -O mm9ToMm10.over.chain.gz\n\n\tliftOver GSE93955_CHIP_H3K36me3_B6_coverage.mm9.bedgraph        mm9ToMm10.over.chain.gz  H3K36m3_B6.bgtmp na\n\tliftOver GSE93955_CHIP_H3K36me3_B6_spo11_coverage.mm9.bedgraph  mm9ToMm10.over.chain.gz  H3K36m3_B6Spo11KO.bgtmp na\n\n  cat H3K36m3_B6.bgtmp        |sortBEDByFAI.pl - ${mm10IDX} >H3K36m3_B6.bedgraph\n\tcat H3K36m3_B6Spo11KO.bgtmp |sortBEDByFAI.pl - ${mm10IDX} >H3K36m3_B6Spo11KO.bedgraph\n\n  \"\"\"",
        "nb_lignes_script": 26,
        "language_script": "bash",
        "tools": [
            "LiftOver"
        ],
        "tools_url": [
            "https://bio.tools/liftover"
        ],
        "tools_dico": [
            {
                "name": "LiftOver",
                "uri": "https://bio.tools/liftover",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This service converts genome coordinates and genome annotation files between assemblies.",
                "homepage": "http://api.bioinfo.no/wsdl/LiftOverService.wsdl"
            }
        ],
        "inputs": [
            "mm10FA",
            "mm10IDX",
            "mm10w1ks100"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "cpus 2",
            "memory '4g'",
            "time { 1.hour * task.attempt }",
            "errorStrategy { 'retry' }",
            "maxRetries 1"
        ],
        "when": "",
        "stub": ""
    },
    "drawHeatmap": {
        "name_process": "drawHeatmap",
        "string_process": "\nprocess drawHeatmap {\n  tag { id }\n\n  publishDir \"${params.outdir}/deeptools/heatmap\",   mode: 'copy', overwrite: true\n\n  input:\n  tuple(val(id),   path(matrix))\n\n  output:\n  path('*.png', emit: png)\n  path('*.svg', emit: svg)\n\n  script:\n  \"\"\"\n  #!/bin/bash\n  plotHeatmap -m  reference-point \\\n              -S ${bigwig} \\\n              -R ${bed} \\\n              -o \"${id}.${type}.deeptools.matrix\" \\\n              --outFileNameMatrix \"${id}.${type}.deeptools.tab\" \\\n              --referencePoint center \\\n              -b 2000 \\\n              -a 2000\n  \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "  \"\"\"\n  #!/bin/bash\n  plotHeatmap -m  reference-point \\\n              -S ${bigwig} \\\n              -R ${bed} \\\n              -o \"${id}.${type}.deeptools.matrix\" \\\n              --outFileNameMatrix \"${id}.${type}.deeptools.tab\" \\\n              --referencePoint center \\\n              -b 2000 \\\n              -a 2000\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "id",
            "matrix"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { id }",
            "publishDir \"${params.outdir}/deeptools/heatmap\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "minimap2SR": {
        "name_process": "minimap2SR",
        "string_process": "process minimap2SR {\n  label 'aligner'\n\n  time { fq.size() < 1000000000 ? 0.5.hour : 1.hour * (1+fq.size()/1000000000 * task.attempt) }\n\n  input:\n  file(fq)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  minimap2 -ax sr \\\n    -t ${task.cpus} \\\n    ${params.genome_mm2idx} \\\n    ${fq} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n\t\t\t\t\t\tTMP_DIR=\"\\$TMPDIR\" \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 27,
        "string_script": "  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  minimap2 -ax sr \\\n    -t ${task.cpus} \\\n    ${params.genome_mm2idx} \\\n    ${fq} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n\t\t\t\t\t\tTMP_DIR=\"\\$TMPDIR\" \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "Minimap2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/minimap2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq.size() < 1000000000 ? 0.5.hour : 1.hour * (1+fq.size()/1000000000 * task.attempt) }"
        ],
        "when": "",
        "stub": ""
    },
    "minimap2PE": {
        "name_process": "minimap2PE",
        "string_process": "\nprocess minimap2PE {\n  label 'aligner'\n\n  time { fq1.size() < 3.GB ? 2.hour : 2.hour + 1.hour * (fq1.size()/3000000000) * task.attempt }\n\n  input:\n  tuple path(fq1), path(fq2)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n\n  \"\"\"\n  minimap2 -ax sr \\\n    -t ${task.cpus} \\\n    ${params.genome_mm2idx} \\\n    ${fq1} ${fq2} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 28,
        "string_script": "  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n\n  \"\"\"\n  minimap2 -ax sr \\\n    -t ${task.cpus} \\\n    ${params.genome_mm2idx} \\\n    ${fq1} ${fq2} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "Minimap2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/minimap2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq1",
            "fq2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq1.size() < 3.GB ? 2.hour : 2.hour + 1.hour * (fq1.size()/3000000000) * task.attempt }"
        ],
        "when": "",
        "stub": ""
    },
    "bwaAlnSR": {
        "name_process": "bwaAlnSR",
        "string_process": "\nprocess bwaAlnSR {\n  label 'aligner'\n\n  time { fq.size() < 1.GB ? 2.hour : 2.hour + 3.hour * (fq.size()/3000000000) * task.attempt }\n\n  tag { fq }\n\n  input:\n  path(fq)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bwa aln \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq} >r1.sai\n\n  bwa samse \\\n    ${params.genome_bwaidx} \\\n    r1.sai ${fq} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam  TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 33,
        "string_script": "  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bwa aln \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq} >r1.sai\n\n  bwa samse \\\n    ${params.genome_bwaidx} \\\n    r1.sai ${fq} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam  TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq.size() < 1.GB ? 2.hour : 2.hour + 3.hour * (fq.size()/3000000000) * task.attempt }",
            "tag { fq }"
        ],
        "when": "",
        "stub": ""
    },
    "bwaAlnPE": {
        "name_process": "bwaAlnPE",
        "string_process": "\nprocess bwaAlnPE {\n  label 'aligner'\n\n  time { fq1.size() < 1.GB ? 2.hour : 2.hour + 3.hour * (fq1.size()/3000000000) * task.attempt }\n\n  tag { fq1 }\n\n  input:\n  tuple path(fq1), path(fq2)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bwa aln \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq1} >r1.sai\n\n  bwa aln \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq2} >r2.sai\n\n  bwa sampe \\\n    ${params.genome_bwaidx} \\\n    r1.sai r2.sai \\\n    ${fq1} ${fq2} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 39,
        "string_script": "  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bwa aln \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq1} >r1.sai\n\n  bwa aln \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq2} >r2.sai\n\n  bwa sampe \\\n    ${params.genome_bwaidx} \\\n    r1.sai r2.sai \\\n    ${fq1} ${fq2} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq1",
            "fq2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq1.size() < 1.GB ? 2.hour : 2.hour + 3.hour * (fq1.size()/3000000000) * task.attempt }",
            "tag { fq1 }"
        ],
        "when": "",
        "stub": ""
    },
    "bwaMemSR": {
        "name_process": "bwaMemSR",
        "string_process": "\nprocess bwaMemSR {\n  label 'aligner'\n\n  time { fq.size() < 3.GB ? 2.hour : 2.hour + 3.hour * (fq.size()/3000000000) * task.attempt }\n\n  tag { fq }\n\n  input:\n  path(fq)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bwa mem \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} ${fq} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 28,
        "string_script": "  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bwa mem \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} ${fq} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq.size() < 3.GB ? 2.hour : 2.hour + 3.hour * (fq.size()/3000000000) * task.attempt }",
            "tag { fq }"
        ],
        "when": "",
        "stub": ""
    },
    "bwaMemPE": {
        "name_process": "bwaMemPE",
        "string_process": "\nprocess bwaMemPE {\n  label 'aligner'\n\n  time { fq1.size() < 3.GB ? 2.hour : 2.hour + 3.hour * (fq1.size()/3000000000) * task.attempt }\n\n  tag { fq1 }\n\n  input:\n  tuple path(fq1), path(fq2)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n\n  \"\"\"\n  bwa mem \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq1} ${fq2} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 30,
        "string_script": "  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n\n  \"\"\"\n  bwa mem \\\n    -t ${task.cpus} \\\n    ${params.genome_bwaidx} \\\n    ${fq1} ${fq2} >tmp.sam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=tmp.sam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "BWA",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/bwa",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "BWA",
                "uri": "https://bio.tools/bwa",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3211",
                                    "term": "Genome indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3429",
                                    "term": "Construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Oligonucleotide alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short sequence read mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3198",
                                    "term": "Short read alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2012",
                                "term": "Sequence coordinates"
                            },
                            {
                                "uri": "http://edamontology.org/data_1916",
                                "term": "Alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3210",
                                "term": "Genome index"
                            }
                        ]
                    }
                ],
                "description": "Fast, accurate, memory-efficient aligner for short and long sequencing reads",
                "homepage": "http://bio-bwa.sourceforge.net"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq1",
            "fq2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq1.size() < 3.GB ? 2.hour : 2.hour + 3.hour * (fq1.size()/3000000000) * task.attempt }",
            "tag { fq1 }"
        ],
        "when": "",
        "stub": ""
    },
    "bowtie2SR": {
        "name_process": "bowtie2SR",
        "string_process": "\nprocess bowtie2SR {\n  label 'aligner'\n\n  time { fq.size() < 3.GB ? 2.hour : 2.hour + 1.hour * (fq.size()/3000000000) * task.attempt }\n\n  tag { fq }\n\n  input:\n  file(fq)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bowtie2 -x ${params.genome_bt2idx} -1 ${fq} -b init.tmpbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=init.tmpbam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 26,
        "string_script": "  def bam   = fq.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bowtie2 -x ${params.genome_bt2idx} -1 ${fq} -b init.tmpbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=init.tmpbam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "Rbowtie2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/rbowtie2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq.size() < 3.GB ? 2.hour : 2.hour + 1.hour * (fq.size()/3000000000) * task.attempt }",
            "tag { fq }"
        ],
        "when": "",
        "stub": ""
    },
    "bowtie2PE": {
        "name_process": "bowtie2PE",
        "string_process": "\nprocess bowtie2PE {\n  label 'aligner'\n\n  time { fq1.size() < 3.GB ? 2.hour : 2.hour + 1.hour * (fq1.size()/3000000000) * task.attempt }\n\n  tag { fq1 }\n\n  input:\n  tuple path(fq1), path(fq2)\n\n  output:\n  tuple path('*.bam'), path('*.bai'), emit: bam\n\n  script:\n  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bowtie2 -x ${params.genome_bt2idx} -1 ${fq1} -2 ${fq2} -b init.tmpbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=init.tmpbam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"\n  }",
        "nb_lignes_process": 26,
        "string_script": "  def bam   = fq1.name.replaceFirst(\"(.R1.fastq|.R1.fastq.gz|.fastq.gz|.fastq)\",\".bam\")\n  \"\"\"\n  bowtie2 -x ${params.genome_bt2idx} -1 ${fq1} -2 ${fq2} -b init.tmpbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n            I=init.tmpbam \\\n            O=${bam} \\\n            SO=coordinate \\\n            VALIDATION_STRINGENCY=LENIENT\n\n  samtools index ${bam}\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "Rbowtie2",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/rbowtie2",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "Rbowtie2",
                "uri": "https://bio.tools/rbowtie2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence merging"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0232",
                                    "term": "Sequence splicing"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "This package provides an R wrapper of the popular bowtie2 sequencing reads aligner and AdapterRemoval, a convenient tool for rapid adapter trimming, identification, and read merging.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rbowtie2.html"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "fq1",
            "fq2"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'aligner'",
            "time { fq1.size() < 3.GB ? 2.hour : 2.hour + 1.hour * (fq1.size()/3000000000) * task.attempt }",
            "tag { fq1 }"
        ],
        "when": "",
        "stub": ""
    },
    "mergeBAM": {
        "name_process": "mergeBAM",
        "string_process": "\nprocess mergeBAM {\n  label 'mergeBAM'\n\n  publishDir \"${params.outdir}/bam\",     mode: 'copy', overwrite: true, pattern: '*bam*'\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*txt'\n\n  time { bams[0].size() < 200000000 ? 6.hour : bams[0].size()/200000000 * task.attempt * 6.hour }\n\n  tag { bams }\n  input:\n  path(bams)\n\n  output:\n  tuple(path('*.bam'),path('*.bai'), emit: bam)\n  path('*MDmetrics.txt', emit: mdreport)\n\n  script:\n                              \n  def input_args = bams.findAll{ it =~ \".bam\\$\" }.collect{ \"I=$it\" }.join(\" \")\n  def name = \"${params.name}.${params.genome}\"\n  \"\"\"\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" \\\n                 ${input_args} \\\n                 O=merged.tmpbam \\\n                 AS=false \\\n                 SO=coordinate \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  if [[ `samtools view -h merged.bam |head -n 100000 |samtools view -f 2 ` ]]; then\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicatesWithMateCigar TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.bam \\\n                   PG=Picard2.9.2_MarkDuplicatesWithMateCigar \\\n                   M=${name}.MDmetrics.txt \\\n                   MINIMUM_DISTANCE=400 \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  else\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.bam \\\n                   PG=Picard2.9.2_MarkDuplicates \\\n                   M=${name}.MDmetrics.txt \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  fi\n\n  samtools index ${name}.bam\n  \"\"\"\n  }",
        "nb_lignes_process": 51,
        "string_script": "  def input_args = bams.findAll{ it =~ \".bam\\$\" }.collect{ \"I=$it\" }.join(\" \")\n  def name = \"${params.name}.${params.genome}\"\n  \"\"\"\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" \\\n                 ${input_args} \\\n                 O=merged.tmpbam \\\n                 AS=false \\\n                 SO=coordinate \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  if [[ `samtools view -h merged.bam |head -n 100000 |samtools view -f 2 ` ]]; then\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicatesWithMateCigar TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.bam \\\n                   PG=Picard2.9.2_MarkDuplicatesWithMateCigar \\\n                   M=${name}.MDmetrics.txt \\\n                   MINIMUM_DISTANCE=400 \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  else\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.bam \\\n                   PG=Picard2.9.2_MarkDuplicates \\\n                   M=${name}.MDmetrics.txt \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  fi\n\n  samtools index ${name}.bam\n  \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bams"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'mergeBAM'",
            "publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*bam*'",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*txt'",
            "time { bams[0].size() < 200000000 ? 6.hour : bams[0].size()/200000000 * task.attempt * 6.hour }",
            "tag { bams }"
        ],
        "when": "",
        "stub": ""
    },
    "getPicardMetrics": {
        "name_process": "getPicardMetrics",
        "string_process": "\nprocess getPicardMetrics {\n\n  publishDir \"${params.outdir}/reports\",  mode: 'copy', overwrite: true\n\n  time { bam.size()< 200000000 ? 2.hour * task.attempt: 2.hour + 2.hour * bam.size()/200000000 * task.attempt }\n\n  tag {bam}\n\n  input:\n  tuple path(bam), path(bai)\n  val(srpe)\n\n  output:\n  path('*Metrics*', emit: report)\n\n  script:\n  def name=bam[0].name.replaceFirst(\".bam\",\"\")\n  def picardMem=task.memory.toGiga() - 2\n\n  if (srpe == 'PE'){\n\t  \"\"\"\n    picard -Xmx${picardMem}g CreateSequenceDictionary \\\n\t      R=${params.genome_fasta} \\\n\t      O=genome.dict \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      VALIDATION_STRINGENCY=LENIENT\n\n    picard -Xmx${picardMem}g CollectAlignmentSummaryMetrics \\\n\t    VALIDATION_STRINGENCY=LENIENT \\\n\t    REFERENCE_SEQUENCE=${params.genome_fasta} \\\n\t    I=${bam} \\\n\t    O=${name}.AlignmentSummary.picardMetrics.tab \\\n\t    TMP_DIR=\\$TMPDIR\n\n    picard -Xmx${picardMem}g CollectInsertSizeMetrics \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.InsertSize.picardMetrics.tab \\\n\t      H=${name}.InsertSize.picardMetrics.pdf \\\n\t      M=0.5 \\\n\t      TMP_DIR=\\$TMPDIR\n\n    picard -Xmx${picardMem}g MeanQualityByCycle \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QByCycle.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QByCycle.picardMetrics.pdf\n\n    picard -Xmx${picardMem}g QualityScoreDistribution \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QScoreDist.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QScoreDist.picardMetrics.pdf\n\t  \"\"\"\n  }else{\n\t  \"\"\"\n    picard -Xmx${picardMem}g CreateSequenceDictionary \\\n\t      R=${params.genome_fasta} \\\n\t      O=genome.dict \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      VALIDATION_STRINGENCY=LENIENT\n\n    picard -Xmx${picardMem}g MeanQualityByCycle \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QByCycle.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QByCycle.picardMetrics.pdf\n\n    picard -Xmx${picardMem}g QualityScoreDistribution \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QScoreDist.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QScoreDist.picardMetrics.pdf\n\t  \"\"\"\n  }\n  }",
        "nb_lignes_process": 79,
        "string_script": "  def name=bam[0].name.replaceFirst(\".bam\",\"\")\n  def picardMem=task.memory.toGiga() - 2\n\n  if (srpe == 'PE'){\n\t  \"\"\"\n    picard -Xmx${picardMem}g CreateSequenceDictionary \\\n\t      R=${params.genome_fasta} \\\n\t      O=genome.dict \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      VALIDATION_STRINGENCY=LENIENT\n\n    picard -Xmx${picardMem}g CollectAlignmentSummaryMetrics \\\n\t    VALIDATION_STRINGENCY=LENIENT \\\n\t    REFERENCE_SEQUENCE=${params.genome_fasta} \\\n\t    I=${bam} \\\n\t    O=${name}.AlignmentSummary.picardMetrics.tab \\\n\t    TMP_DIR=\\$TMPDIR\n\n    picard -Xmx${picardMem}g CollectInsertSizeMetrics \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.InsertSize.picardMetrics.tab \\\n\t      H=${name}.InsertSize.picardMetrics.pdf \\\n\t      M=0.5 \\\n\t      TMP_DIR=\\$TMPDIR\n\n    picard -Xmx${picardMem}g MeanQualityByCycle \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QByCycle.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QByCycle.picardMetrics.pdf\n\n    picard -Xmx${picardMem}g QualityScoreDistribution \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QScoreDist.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QScoreDist.picardMetrics.pdf\n\t  \"\"\"\n  }else{\n\t  \"\"\"\n    picard -Xmx${picardMem}g CreateSequenceDictionary \\\n\t      R=${params.genome_fasta} \\\n\t      O=genome.dict \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      VALIDATION_STRINGENCY=LENIENT\n\n    picard -Xmx${picardMem}g MeanQualityByCycle \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QByCycle.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QByCycle.picardMetrics.pdf\n\n    picard -Xmx${picardMem}g QualityScoreDistribution \\\n\t      VALIDATION_STRINGENCY=LENIENT \\\n\t      I=${bam} \\\n\t      O=${name}.QScoreDist.picardMetrics.tab \\\n\t      TMP_DIR=\\$TMPDIR \\\n\t      CHART=${name}.QScoreDist.picardMetrics.pdf\n\t  \"\"\"\n  }",
        "nb_lignes_script": 62,
        "language_script": "bash",
        "tools": [
            "Picard"
        ],
        "tools_url": [
            "https://bio.tools/picard_tools"
        ],
        "tools_dico": [
            {
                "name": "Picard",
                "uri": "https://bio.tools/picard_tools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A set of command line tools for manipulating high-throughput sequencing (HTS) data in formats such as SAM/BAM/CRAM and VCF. Available as a standalone program or within the GATK4 program.",
                "homepage": "https://github.com/broadinstitute/picard"
            }
        ],
        "inputs": [
            "bam",
            "bai",
            "srpe"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true",
            "time { bam.size()< 200000000 ? 2.hour * task.attempt: 2.hour + 2.hour * bam.size()/200000000 * task.attempt }",
            "tag {bam}"
        ],
        "when": "",
        "stub": ""
    },
    "bamToBW": {
        "name_process": "bamToBW",
        "string_process": "\nprocess bamToBW {\n\n  publishDir \"${params.outdir}/bigwig\",  mode: 'copy', overwrite: true, pattern: '*bigwig'\n\n  time { bam.size()< 1000000000 ? 0.5.hour * task.attempt: 1.hour * bam.size()/1000000000 * task.attempt }\n\n\ttag { bam }\n\n  input:\n  tuple path(bam), path(bai)\n\n  output:\n  path('*bigwig', emit: bw)\n\n  script:\n  def name=bam.name.replaceFirst(\".bam\",\"\")\n  \"\"\"\n  if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n    genomeCoverageBed -ibam ${bam} -bg >${name}.tmpbg\n    ## SORT BY INDEX TO ASSURE WE ONLY HAVE CHROMOSOMES MENTIONED IN THE INDEX THEN DO A LINUX SORT\n    ## THIS IS A BIT ASSWAYS; FIX LATER\n    sortBEDByFAI.pl ${name}.tmpbg ${params.genome_fai} |sort -k1,1 -k2n,2n -k3n,3n >${name}.bedgraph\n    bedGraphToBigWig ${name}.bedgraph ${params.genome_fai} ${name}.bedtools.bigwig\n  else\n    touch EMPTY_TOOFEWREADS_${name}.bedtools.bigwig\n  fi\n  \"\"\"\n  }",
        "nb_lignes_process": 27,
        "string_script": "  def name=bam.name.replaceFirst(\".bam\",\"\")\n  \"\"\"\n  if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n    genomeCoverageBed -ibam ${bam} -bg >${name}.tmpbg\n    ## SORT BY INDEX TO ASSURE WE ONLY HAVE CHROMOSOMES MENTIONED IN THE INDEX THEN DO A LINUX SORT\n    ## THIS IS A BIT ASSWAYS; FIX LATER\n    sortBEDByFAI.pl ${name}.tmpbg ${params.genome_fai} |sort -k1,1 -k2n,2n -k3n,3n >${name}.bedgraph\n    bedGraphToBigWig ${name}.bedgraph ${params.genome_fai} ${name}.bedtools.bigwig\n  else\n    touch EMPTY_TOOFEWREADS_${name}.bedtools.bigwig\n  fi\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "HiFiX",
            "bedGraphToBigWig"
        ],
        "tools_url": [
            "https://bio.tools/hifix",
            "https://bio.tools/bedgraphtobigwig"
        ],
        "tools_dico": [
            {
                "name": "HiFiX",
                "uri": "https://bio.tools/hifix",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The software package HiFiX implements the novel algorithm for HIgh FIdelity Clustering of Sequences.",
                "homepage": "http://lbbe.univ-lyon1.fr/-HiFiX-.html"
            },
            {
                "name": "bedGraphToBigWig",
                "uri": "https://bio.tools/bedgraphtobigwig",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Convert bedGraph to bigWig file.",
                "homepage": "https://www.encodeproject.org/software/bedgraphtobigwig/"
            }
        ],
        "inputs": [
            "bam",
            "bai"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/bigwig\", mode: 'copy', overwrite: true, pattern: '*bigwig'",
            "time { bam.size()< 1000000000 ? 0.5.hour * task.attempt: 1.hour * bam.size()/1000000000 * task.attempt }",
            "tag { bam }"
        ],
        "when": "",
        "stub": ""
    },
    "trimFASTQsr": {
        "name_process": "trimFASTQsr",
        "string_process": "\nprocess trimFASTQsr {\n\n  label 'trimFQ'\n\n\ttime { fq.size() < 3.GB ? 1.hour : 1.hour + 1.hour * (fq.size()/3000000000) * task.attempt }\n\n  tag {fq}\n\n  input:\n  path(fq)\n\n  output:\n  path \"${params.name}.trimmed.R1.fastq\", emit: fq\n                                                        \n\n  script:\n  \"\"\"\n  if [[ \"${fq}\" =~ .gz\\$ ]]; then gz=${fq}; fq=\\${gz/.gz/}; zcat ${fq} >\\$fq; fi\n  fqr1=`ls *.R1.fastq`\n\n  #trimFQ1=`echo \"\\$fqr1\" |perl -pi -e 's/.fastq/_val_1.fq/'`\n  trimFQ1=\\${fqr1/.fastq/_trimmed.fq}\n\n  trim_galore -q 10 --dont_gzip --stringency 6 --length 25 \\$fqr1\n\n  mv \\$trimFQ1 ${params.name}.trimmed.R1.fastq\n\n  mv \\$fqr1\"_trimming_report.txt\" ${params.name}.R1_trimgalore_trimming_report.txt\n\n  \"\"\"\n  }",
        "nb_lignes_process": 30,
        "string_script": "  \"\"\"\n  if [[ \"${fq}\" =~ .gz\\$ ]]; then gz=${fq}; fq=\\${gz/.gz/}; zcat ${fq} >\\$fq; fi\n  fqr1=`ls *.R1.fastq`\n\n  #trimFQ1=`echo \"\\$fqr1\" |perl -pi -e 's/.fastq/_val_1.fq/'`\n  trimFQ1=\\${fqr1/.fastq/_trimmed.fq}\n\n  trim_galore -q 10 --dont_gzip --stringency 6 --length 25 \\$fqr1\n\n  mv \\$trimFQ1 ${params.name}.trimmed.R1.fastq\n\n  mv \\$fqr1\"_trimming_report.txt\" ${params.name}.R1_trimgalore_trimming_report.txt\n\n  \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'trimFQ'",
            "time { fq.size() < 3.GB ? 1.hour : 1.hour + 1.hour * (fq.size()/3000000000) * task.attempt }",
            "tag {fq}"
        ],
        "when": "",
        "stub": ""
    },
    "trimFASTQpe": {
        "name_process": "trimFASTQpe",
        "string_process": "\nprocess trimFASTQpe {\n\n  label 'trimFQ'\n\n  time { fq[0].size() < 3.GB ? 1.hour : 1.hour + 1.hour * (fq[0].size()/3000000000) * task.attempt }\n\n  tag { fq[0] }\n\n  input:\n  path(fq)\n\n  output:\n  tuple path(\"${params.name}.trimmed.R1.fastq\"), path(\"${params.name}.trimmed.R2.fastq\"), emit: fq\n                                                                                                        \n\n  script:\n  def fqR1=fq[0]\n  def fqR2=fq[1]\n  \"\"\"\n  if [[ \"${fqR1}\" =~ .gz\\$ ]]; then gz=${fqR1}; fq=\\${gz/.gz/}; zcat ${fqR1} >\\$fq; fi\n  if [[ \"${fqR2}\" =~ .gz\\$ ]]; then gz=${fqR2}; fq=\\${gz/.gz/}; zcat ${fqR2} >\\$fq; fi\n\n  fqr1=`ls *.R1.fastq`\n  fqr2=`ls *.R2.fastq`\n  trimFQ1=`echo \"\\$fqr1\" |perl -pi -e 's/.fastq/_val_1.fq/'`\n  trimFQ2=`echo \"\\$fqr2\" |perl -pi -e 's/.fastq/_val_2.fq/'`\n\n  trim_galore -q 10 --paired --dont_gzip --stringency 6 --length 25 \\$fqr1 \\$fqr2\n\n  mv \\$trimFQ1 ${params.name}.trimmed.R1.fastq\n  mv \\$trimFQ2 ${params.name}.trimmed.R2.fastq\n\n  mv \\$fqr1\"_trimming_report.txt\" ${params.name}.R1_trimgalore_trimming_report.txt\n  mv \\$fqr2\"_trimming_report.txt\" ${params.name}.R2_trimgalore_trimming_report.txt\n\n  \"\"\"\n  }",
        "nb_lignes_process": 36,
        "string_script": "  def fqR1=fq[0]\n  def fqR2=fq[1]\n  \"\"\"\n  if [[ \"${fqR1}\" =~ .gz\\$ ]]; then gz=${fqR1}; fq=\\${gz/.gz/}; zcat ${fqR1} >\\$fq; fi\n  if [[ \"${fqR2}\" =~ .gz\\$ ]]; then gz=${fqR2}; fq=\\${gz/.gz/}; zcat ${fqR2} >\\$fq; fi\n\n  fqr1=`ls *.R1.fastq`\n  fqr2=`ls *.R2.fastq`\n  trimFQ1=`echo \"\\$fqr1\" |perl -pi -e 's/.fastq/_val_1.fq/'`\n  trimFQ2=`echo \"\\$fqr2\" |perl -pi -e 's/.fastq/_val_2.fq/'`\n\n  trim_galore -q 10 --paired --dont_gzip --stringency 6 --length 25 \\$fqr1 \\$fqr2\n\n  mv \\$trimFQ1 ${params.name}.trimmed.R1.fastq\n  mv \\$trimFQ2 ${params.name}.trimmed.R2.fastq\n\n  mv \\$fqr1\"_trimming_report.txt\" ${params.name}.R1_trimgalore_trimming_report.txt\n  mv \\$fqr2\"_trimming_report.txt\" ${params.name}.R2_trimgalore_trimming_report.txt\n\n  \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fq"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'trimFQ'",
            "time { fq[0].size() < 3.GB ? 1.hour : 1.hour + 1.hour * (fq[0].size()/3000000000) * task.attempt }",
            "tag { fq[0] }"
        ],
        "when": "",
        "stub": ""
    },
    "makeDeeptoolsBW": {
        "name_process": "makeDeeptoolsBW",
        "string_process": "\nprocess makeDeeptoolsBW {\n\n  publishDir \"${params.outdir}/bigwig\",  mode: 'copy', overwrite: true, pattern: '*bigwig'\n  publishDir \"${params.outdir}/plots\",   mode: 'copy', overwrite: true, pattern: '*png'\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*tab'\n\n  time { bam.size()< 500000000 ? 1.hour : 1.hour + 1.hour * bam.size()/500000000 * task.attempt }\n\n  tag {bam}\n\n  input:\n  tuple(path(bam), path(bai))\n\n  output:\n  path('*bigwig', emit: bw)\n  path('*png',    emit: png)\n  path('*tab',    emit: tab)\n\n  script:\n  def name            = bam.name.replaceAll(/.bam/,'')\n  \"\"\"\n  if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n\n   ## Added KB 2003-03-19:\n   ## Split BAM by chromosome\n   for cs in `samtools idxstats ${bam} |cut -f1 |grep -vP '\\\\*'`; do\n     csbam=\\$cs\".bam\"\n     csBW=\\$cs\".ALL.BW\"\n     csBWND=\\$cs\".ND.BW\"\n     cswig=\\$cs\".ALL.wig\"\n     cswigND=\\$cs\".ND.wig\"\n\n     if [ `samtools view -F 4 ${bam} \\$cs |head -n 10 |wc -l` -eq 10 ]; then\n       samtools view -F 4 -hb ${bam} \\$cs >\\$csbam\n       samtools index \\$csbam\n\n       bamCoverage --bam \\$csbam --binSize 150 --normalizeUsing RPKM \\\n         -p max -v -o \\$csBW\n       bigWigToWig \\$csBW \\$cswig\n       grep -w \\$cs \\$cswig >>all.wig\n\n       bamCoverage --bam \\$csbam --binSize 150 --normalizeUsing RPKM \\\n           --ignoreDuplicates -p max -v -o \\$csBWND\n       bigWigToWig \\$csBWND \\$cswigND\n       grep -w \\$cs \\$cswigND >>ND.wig\n     fi\n   done\n\n   wigToBigWig all.wig ${params.genome_fai} ${name}.deeptools.150bp.RPKM.bigwig\n   wigToBigWig ND.wig  ${params.genome_fai} ${name}.deeptools.150bp.RPKM.noDups.bigwig\n\n   plotCoverage --bamfiles ${bam} --numberOfProcessors ${task.cpus} \\\n     -o ${name}.deeptools.coveragePlot.png\n\n   plotFingerprint --bamfiles ${bam} --labels ${bam} --numberOfProcessors ${task.cpus} \\\n     --minMappingQuality 30 --skipZeros \\\n     --plotFile ${name}.deeptools.fingerprints.png \\\n     --outRawCounts ${name}.deeptools.fingerprints.tab\n\n  else\n    touch EMPTY_TOOFEWREADS_${name}.bigwig\n    touch EMPTY_TOOFEWREADS_${name}.deeptools.coveragePlot.png\n    touch EMPTY_TOOFEWREADS_${name}.deeptools.fingerprints.png\n    touch EMPTY_TOOFEWREADS_${name}.deeptools.fingerprints.tab\n  fi\n  \"\"\"\n  }",
        "nb_lignes_process": 66,
        "string_script": "  def name            = bam.name.replaceAll(/.bam/,'')\n  \"\"\"\n  if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n\n   ## Added KB 2003-03-19:\n   ## Split BAM by chromosome\n   for cs in `samtools idxstats ${bam} |cut -f1 |grep -vP '\\\\*'`; do\n     csbam=\\$cs\".bam\"\n     csBW=\\$cs\".ALL.BW\"\n     csBWND=\\$cs\".ND.BW\"\n     cswig=\\$cs\".ALL.wig\"\n     cswigND=\\$cs\".ND.wig\"\n\n     if [ `samtools view -F 4 ${bam} \\$cs |head -n 10 |wc -l` -eq 10 ]; then\n       samtools view -F 4 -hb ${bam} \\$cs >\\$csbam\n       samtools index \\$csbam\n\n       bamCoverage --bam \\$csbam --binSize 150 --normalizeUsing RPKM \\\n         -p max -v -o \\$csBW\n       bigWigToWig \\$csBW \\$cswig\n       grep -w \\$cs \\$cswig >>all.wig\n\n       bamCoverage --bam \\$csbam --binSize 150 --normalizeUsing RPKM \\\n           --ignoreDuplicates -p max -v -o \\$csBWND\n       bigWigToWig \\$csBWND \\$cswigND\n       grep -w \\$cs \\$cswigND >>ND.wig\n     fi\n   done\n\n   wigToBigWig all.wig ${params.genome_fai} ${name}.deeptools.150bp.RPKM.bigwig\n   wigToBigWig ND.wig  ${params.genome_fai} ${name}.deeptools.150bp.RPKM.noDups.bigwig\n\n   plotCoverage --bamfiles ${bam} --numberOfProcessors ${task.cpus} \\\n     -o ${name}.deeptools.coveragePlot.png\n\n   plotFingerprint --bamfiles ${bam} --labels ${bam} --numberOfProcessors ${task.cpus} \\\n     --minMappingQuality 30 --skipZeros \\\n     --plotFile ${name}.deeptools.fingerprints.png \\\n     --outRawCounts ${name}.deeptools.fingerprints.tab\n\n  else\n    touch EMPTY_TOOFEWREADS_${name}.bigwig\n    touch EMPTY_TOOFEWREADS_${name}.deeptools.coveragePlot.png\n    touch EMPTY_TOOFEWREADS_${name}.deeptools.fingerprints.png\n    touch EMPTY_TOOFEWREADS_${name}.deeptools.fingerprints.tab\n  fi\n  \"\"\"",
        "nb_lignes_script": 46,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "plotcoverage"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/plotcoverage"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "plotcoverage",
                "uri": "https://bio.tools/plotcoverage",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0797",
                            "term": "Comparative genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2424",
                                    "term": "Comparison"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_3002",
                                "term": "Annotation track"
                            },
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "Plot the coverage of the first data with respect to the second one.",
                "homepage": "https://urgi.versailles.inra.fr/Tools/REPET"
            }
        ],
        "inputs": [
            "bam",
            "bai"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/bigwig\", mode: 'copy', overwrite: true, pattern: '*bigwig'",
            "publishDir \"${params.outdir}/plots\", mode: 'copy', overwrite: true, pattern: '*png'",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*tab'",
            "time { bam.size()< 500000000 ? 1.hour : 1.hour + 1.hour * bam.size()/500000000 * task.attempt }",
            "tag {bam}"
        ],
        "when": "",
        "stub": ""
    },
    "samStats": {
        "name_process": "samStats",
        "string_process": "\nprocess samStats {\n\n  publishDir \"${params.outdir}/reports\",  mode: 'copy', overwrite: true\n\n  time { bam.size()< 10000000000 ? 1.hour : 1.hour * bam.size()/10000000000 * task.attempt }\n\n  tag {bam}\n\n  input:\n  tuple path(bam),  path(idx)\n\n  output:\n  path('*stats.tab', emit: report)\n\n  script:\n  iStat = bam.name.replaceAll(/.bam/,\".idxstats.tab\")\n  sStat = bam.name.replaceAll(/.bam/,\".samstats.tab\")\n  \"\"\"\n  samtools idxstats ${bam} >${iStat}\n  samtools stats ${bam} >${sStat}\n  \"\"\"\n  }",
        "nb_lignes_process": 21,
        "string_script": "  iStat = bam.name.replaceAll(/.bam/,\".idxstats.tab\")\n  sStat = bam.name.replaceAll(/.bam/,\".samstats.tab\")\n  \"\"\"\n  samtools idxstats ${bam} >${iStat}\n  samtools stats ${bam} >${sStat}\n  \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "ppiStats",
            "MSstats",
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/ppistats",
            "https://bio.tools/msstats",
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "ppiStats",
                "uri": "https://bio.tools/ppistats",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0128",
                            "term": "Protein interactions"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2949",
                                    "term": "Protein-protein interaction analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2949",
                                    "term": "Protein interaction analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tools for the analysis of protein interaction data.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/ppiStats.html"
            },
            {
                "name": "MSstats",
                "uri": "https://bio.tools/msstats",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0121",
                            "term": "Proteomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0531",
                                    "term": "Heat map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3441",
                                    "term": "Plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3741",
                                    "term": "Differential protein expression profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3664",
                                    "term": "Statistical modelling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0531",
                                    "term": "Heatmap generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0531",
                                    "term": "Heat map construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3741",
                                    "term": "Differential protein expression analysis"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2603",
                                "term": "Expression data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1636",
                                "term": "Heat map"
                            },
                            {
                                "uri": "http://edamontology.org/data_2884",
                                "term": "Plot"
                            },
                            {
                                "uri": "http://edamontology.org/data_2603",
                                "term": "Expression data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0951",
                                "term": "Statistical estimate score"
                            }
                        ]
                    }
                ],
                "description": "Statistical tool for quantitative mass spectrometry-based proteomics.",
                "homepage": "http://www.msstats.org/"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "bam",
            "idx"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true",
            "time { bam.size()< 10000000000 ? 1.hour : 1.hour * bam.size()/10000000000 * task.attempt }",
            "tag {bam}"
        ],
        "when": "",
        "stub": ""
    },
    "makeFRBW": {
        "name_process": "makeFRBW",
        "string_process": " process makeFRBW {\n    publishDir \"${params.outdir}/bigwig\",  mode: 'copy', overwrite: true, pattern: '*bigwig'\n\n    cpus 2\n    memory 6\n\n    time { bam.size()< 5000000000 ? 1.hour : 1.hour * bam.size()/5000000000 * task.attempt }\n\n    errorStrategy { 'retry' }\n    maxRetries 1\n\n    input:\n    tuple path(bam), path(idx)\n\n    output:\n    path('*.bigwig', emit: bw)\n\n    script:\n    iName = bam.name.replaceAll(/.bam/,\".out\")\n\n    \"\"\"\n    if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n      idx=\"${params.genome_fai}\";\n\n      bedtools makewindows  -g \\$idx -w 1000 -s 100 |sort -k1,1 -k2n,2n |perl -lane 'print \\$_ if ((\\$F[2]-\\$F[1]) == 1000)' >win.bed\n      java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam I=${bam} O=qSort.bam SO=queryname VALIDATION_STRINGENCY=LENIENT TMP_DIR=\"\\$TMPDIR\"\n      bedtools bamtobed -mate1 -i qSort.bam -bedpe >frags.bedpe\n\n      perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[1], \\$F[5], @F[6..8]) if (\\$F[8] eq \"+\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.POS.bed\n      perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[4], \\$F[2], @F[6..8]) if (\\$F[8] eq \"-\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.NEG.bed\n\n      mapBed -a win.bed -b frags.POS.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >pos.bg\n      mapBed -a win.bed -b frags.NEG.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >neg.bg\n\n      paste pos.bg neg.bg |perl -lane '\\$F[3]+=0.5; \\$F[7]+=0.5; \\$v=(\\$F[3]/\\$F[7]); print join(\"\\\\t\",@F[0..2],(log(\\$v)/log(2)))' >fr.bg\n      paste pos.bg neg.bg |perl -lane '\\$v=(\\$F[3]+\\$F[7]); print join(\"\\\\t\",@F[0..2],\\$v)' >tot.bg\n\n      bedGraphToBigWig pos.bg \\$idx ${iName}.F.bigwig\n      bedGraphToBigWig neg.bg \\$idx ${iName}.F.bigwig\n      bedGraphToBigWig fr.bg  \\$idx ${iName}.FR.bigwig\n      bedGraphToBigWig tot.bg \\$idx ${iName}.Tot.bigwig\n    else\n      touch \"EMPTY_TOOFEWREADS_${iName}.F.bigwig\n      touch \"EMPTY_TOOFEWREADS_${iName}.R.bigwig\n      touch \"EMPTY_TOOFEWREADS_${iName}.FR.bigwig\n      touch \"EMPTY_TOOFEWREADS_${iName}.Tot.bigwig\n    fi\n    \"\"\"\n    }",
        "nb_lignes_process": 47,
        "string_script": "    iName = bam.name.replaceAll(/.bam/,\".out\")\n\n    \"\"\"\n    if [[ `samtools view -F 4 ${bam} |head -n 5001 |wc -l` -gt 5000 ]]; then\n      idx=\"${params.genome_fai}\";\n\n      bedtools makewindows  -g \\$idx -w 1000 -s 100 |sort -k1,1 -k2n,2n |perl -lane 'print \\$_ if ((\\$F[2]-\\$F[1]) == 1000)' >win.bed\n      java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam I=${bam} O=qSort.bam SO=queryname VALIDATION_STRINGENCY=LENIENT TMP_DIR=\"\\$TMPDIR\"\n      bedtools bamtobed -mate1 -i qSort.bam -bedpe >frags.bedpe\n\n      perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[1], \\$F[5], @F[6..8]) if (\\$F[8] eq \"+\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.POS.bed\n      perl -lane 'print join(\"\\\\t\", \\$F[0], \\$F[4], \\$F[2], @F[6..8]) if (\\$F[8] eq \"-\")' frags.bedpe |sort -k1,1 -k2n,2n >frags.NEG.bed\n\n      mapBed -a win.bed -b frags.POS.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >pos.bg\n      mapBed -a win.bed -b frags.NEG.bed -c 1 -o count |perl -lane 'use Math::Round; \\$p=round((\\$F[1]+\\$F[2])/2); print join(\"\\\\t\",\\$F[0],\\$p-49,\\$p+50,\\$F[3])' >neg.bg\n\n      paste pos.bg neg.bg |perl -lane '\\$F[3]+=0.5; \\$F[7]+=0.5; \\$v=(\\$F[3]/\\$F[7]); print join(\"\\\\t\",@F[0..2],(log(\\$v)/log(2)))' >fr.bg\n      paste pos.bg neg.bg |perl -lane '\\$v=(\\$F[3]+\\$F[7]); print join(\"\\\\t\",@F[0..2],\\$v)' >tot.bg\n\n      bedGraphToBigWig pos.bg \\$idx ${iName}.F.bigwig\n      bedGraphToBigWig neg.bg \\$idx ${iName}.F.bigwig\n      bedGraphToBigWig fr.bg  \\$idx ${iName}.FR.bigwig\n      bedGraphToBigWig tot.bg \\$idx ${iName}.Tot.bigwig\n    else\n      touch \"EMPTY_TOOFEWREADS_${iName}.F.bigwig\n      touch \"EMPTY_TOOFEWREADS_${iName}.R.bigwig\n      touch \"EMPTY_TOOFEWREADS_${iName}.FR.bigwig\n      touch \"EMPTY_TOOFEWREADS_${iName}.Tot.bigwig\n    fi\n    \"\"\"",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [
            "DINAMelt",
            "BEDTools",
            "bedGraphToBigWig"
        ],
        "tools_url": [
            "https://bio.tools/dinamelt",
            "https://bio.tools/bedtools",
            "https://bio.tools/bedgraphtobigwig"
        ],
        "tools_dico": [
            {
                "name": "DINAMelt",
                "uri": "https://bio.tools/dinamelt",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein secondary structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0082",
                            "term": "Structure prediction"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0099",
                            "term": "RNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3542",
                            "term": "Protein features (secondary structure)"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0097",
                            "term": "Nucleic acid structure"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Fold recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Protein secondary structure prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0483",
                                    "term": "RNA inverse folding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0278",
                                    "term": "RNA secondary structure prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Protein domain prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Fold prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Protein fold recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Domain prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0303",
                                    "term": "Protein fold prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0267",
                                    "term": "Secondary structure prediction (protein)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0483",
                                    "term": "Nucleic acid folding family identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0483",
                                    "term": "Structured RNA prediction and optimisation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "DINAMelt is a tool for predicting hybridization and folding (secondary structure) of DNA and RNA using equilibrium thermodynamic methods.",
                "homepage": "http://mfold.rna.albany.edu/?q=DINAMelt"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            },
            {
                "name": "bedGraphToBigWig",
                "uri": "https://bio.tools/bedgraphtobigwig",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Convert bedGraph to bigWig file.",
                "homepage": "https://www.encodeproject.org/software/bedgraphtobigwig/"
            }
        ],
        "inputs": [
            "bam",
            "idx"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/bigwig\", mode: 'copy', overwrite: true, pattern: '*bigwig'",
            "cpus 2",
            "memory 6",
            "time { bam.size()< 5000000000 ? 1.hour : 1.hour * bam.size()/5000000000 * task.attempt }",
            "errorStrategy { 'retry' }",
            "maxRetries 1"
        ],
        "when": "",
        "stub": ""
    },
    "mergeBAMv2": {
        "name_process": "mergeBAMv2",
        "string_process": "\nprocess mergeBAMv2 {\n\n  label 'mergeBAM'\n\n  time { 5.hour * task.attempt }\n\n  tag { \"${name} : ${bams.size()}\" }\n\n  input:\n  tuple(val(name), path(bams))\n\n  output:\n  tuple(val(name), path('*.bam'), path('*.bai'), emit: bam)\n\n  script:\n                              \n                                                                                \n  \"\"\"\n  ## STUPID PAIRTOOLS CAN ADD DUPLICATE PG FIELDS TO BAM\n  ## THIS FIXES THE ISSUE (WHICH KILLS PICARD)\n  for bam in *.bam; do\n    newbam=\\${bam/bam/okheader.tmpbam}\n    samtools view -h \\$bam |perl -lane 'if (\\$_ =~/ID:(\\\\S+)/){\\$prog=\\$1; if(\\$PG{\\$prog}++){\\$_ =~ s/ID:(\\\\S+)/ID:\\$1\\\\.\\$PG{\\$prog}/}}; if (\\$_ =~/PN:(\\\\S+)/){\\$prog=\\$1; if(\\$PN{\\$prog}++){\\$_ =~ s/PN:(\\\\S+)/PN:\\$1\\\\.\\$PN{\\$prog}/}};print \\$_;' |samtools view -Shb - >\\$newbam\n    #samtools view -h \\$bam |perl -lane 'if (\\$_ =~/ID:(\\\\S+)/){\\$prog=\\$1; if(\\$PG{\\$prog}++){\\$_ =~ s/ID:(\\\\S+)/ID:\\$1\\\\.\\$PG{\\$prog}/}}; if (\\$_ =~/PN:(\\\\S+)/){\\$prog=\\$1; if(\\$PN{\\$prog}++){\\$_ =~ s/PN:(\\\\S+)/PN:\\$1\\\\.\\$PN{\\$prog}/}}; print \\$_;' |samtools view -Shb - >S3ok.bam\n  done\n\n  input_args=`ls *okheader.tmpbam |perl -pi -e 's/\\\\n/ /g' |perl -pi -e 's/(\\\\S+)/I=\\$1/g'`\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" \\\n                 \\$input_args \\\n                 O=merged.tmpbam \\\n                 AS=false \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n                I=merged.tmpbam \\\n                O=${name}.bam \\\n                SO=coordinate \\\n                VALIDATION_STRINGENCY=LENIENT\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR BuildBamIndex \\\n                I=${name}.bam VALIDATION_STRINGENCY=LENIENT\n  \"\"\"\n  }",
        "nb_lignes_process": 43,
        "string_script": "  \"\"\"\n  ## STUPID PAIRTOOLS CAN ADD DUPLICATE PG FIELDS TO BAM\n  ## THIS FIXES THE ISSUE (WHICH KILLS PICARD)\n  for bam in *.bam; do\n    newbam=\\${bam/bam/okheader.tmpbam}\n    samtools view -h \\$bam |perl -lane 'if (\\$_ =~/ID:(\\\\S+)/){\\$prog=\\$1; if(\\$PG{\\$prog}++){\\$_ =~ s/ID:(\\\\S+)/ID:\\$1\\\\.\\$PG{\\$prog}/}}; if (\\$_ =~/PN:(\\\\S+)/){\\$prog=\\$1; if(\\$PN{\\$prog}++){\\$_ =~ s/PN:(\\\\S+)/PN:\\$1\\\\.\\$PN{\\$prog}/}};print \\$_;' |samtools view -Shb - >\\$newbam\n    #samtools view -h \\$bam |perl -lane 'if (\\$_ =~/ID:(\\\\S+)/){\\$prog=\\$1; if(\\$PG{\\$prog}++){\\$_ =~ s/ID:(\\\\S+)/ID:\\$1\\\\.\\$PG{\\$prog}/}}; if (\\$_ =~/PN:(\\\\S+)/){\\$prog=\\$1; if(\\$PN{\\$prog}++){\\$_ =~ s/PN:(\\\\S+)/PN:\\$1\\\\.\\$PN{\\$prog}/}}; print \\$_;' |samtools view -Shb - >S3ok.bam\n  done\n\n  input_args=`ls *okheader.tmpbam |perl -pi -e 's/\\\\n/ /g' |perl -pi -e 's/(\\\\S+)/I=\\$1/g'`\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" \\\n                 \\$input_args \\\n                 O=merged.tmpbam \\\n                 AS=false \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam TMP_DIR=\"\\$TMPDIR\" \\\n                I=merged.tmpbam \\\n                O=${name}.bam \\\n                SO=coordinate \\\n                VALIDATION_STRINGENCY=LENIENT\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR BuildBamIndex \\\n                I=${name}.bam VALIDATION_STRINGENCY=LENIENT\n  \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "name",
            "bams"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'mergeBAM'",
            "time { 5.hour * task.attempt }",
            "tag { \"${name} : ${bams.size()}\" }"
        ],
        "when": "",
        "stub": ""
    },
    "markBAMduplicates": {
        "name_process": "markBAMduplicates",
        "string_process": "\nprocess markBAMduplicates {\n\n  label 'mergeBAM'\n\n  publishDir \"${params.outdir}/bam\",     mode: 'copy', overwrite: true, pattern: '*bam*'\n  publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*txt'\n\n  time { bam.size() < 2000000000 ? 6.hour : bam.size()/2000000000 * task.attempt * 6.hour }\n\n  tag { bam }\n\n  input:\n  tuple(val(name), path(bam), path(bai))\n\n  output:\n  tuple(val(name), path('*.bam'), path('*.bai'), emit: bam)\n  path('*MDmetrics.txt', emit: mdreport)\n\n  script:\n  \"\"\"\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" \\\n                 I=${bam} \\\n                 O=merged.tmpbam \\\n                 AS=true \\\n                 SO=coordinate \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  if [[ `samtools view -h merged.bam |head -n 100000 |samtools view -f 2 ` ]]; then\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicatesWithMateCigar TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.MD.bam \\\n                   PG=Picard_MarkDuplicatesWithMateCigar \\\n                   M=${name}.MDmetrics.txt \\\n                   MINIMUM_DISTANCE=400 \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  else\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.MD.bam \\\n                   PG=Picard_MarkDuplicates \\\n                   M=${name}.MDmetrics.txt \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  fi\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR BuildBamIndex \\\n                I=${name}.MD.bam VALIDATION_STRINGENCY=LENIENT\n  \"\"\"\n  }",
        "nb_lignes_process": 51,
        "string_script": "  \"\"\"\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MergeSamFiles TMP_DIR=\"\\$TMPDIR\" \\\n                 I=${bam} \\\n                 O=merged.tmpbam \\\n                 AS=true \\\n                 SO=coordinate \\\n                 VALIDATION_STRINGENCY=LENIENT\n\n  if [[ `samtools view -h merged.bam |head -n 100000 |samtools view -f 2 ` ]]; then\n\t  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicatesWithMateCigar TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.MD.bam \\\n                   PG=Picard_MarkDuplicatesWithMateCigar \\\n                   M=${name}.MDmetrics.txt \\\n                   MINIMUM_DISTANCE=400 \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  else\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates TMP_DIR=\"\\$TMPDIR\" \\\n                   I=merged.tmpbam \\\n                   O=${name}.MD.bam \\\n                   PG=Picard_MarkDuplicates \\\n                   M=${name}.MDmetrics.txt \\\n\t\t\t     CREATE_INDEX=false \\\n\t\t\t     ASSUME_SORT_ORDER=coordinate \\\n           VALIDATION_STRINGENCY=LENIENT\n  fi\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR BuildBamIndex \\\n                I=${name}.MD.bam VALIDATION_STRINGENCY=LENIENT\n  \"\"\"",
        "nb_lignes_script": 31,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "name",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "label 'mergeBAM'",
            "publishDir \"${params.outdir}/bam\", mode: 'copy', overwrite: true, pattern: '*bam*'",
            "publishDir \"${params.outdir}/reports\", mode: 'copy', overwrite: true, pattern: '*txt'",
            "time { bam.size() < 2000000000 ? 6.hour : bam.size()/2000000000 * task.attempt * 6.hour }",
            "tag { bam }"
        ],
        "when": "",
        "stub": ""
    },
    "getCoverage": {
        "name_process": "getCoverage",
        "string_process": "process getCoverage {\n\n  tag { chrom }\n\n  input:\n  tuple(path(bam), path(bai))\n  path(gctab)\n  val(chrom)\n\n  output:\n  path(\"*.w*0k.bedgraph\", emit: bg)\n  path(\"*.GCdata.tab\",    emit: gcData)\n\n  script:\n  \n  def win101=\"${chrom}.win101ALL.bed\"\n  \"\"\"\n  tbam=\"${chrom}.tmp.bam\"\n  s1bam=\"${chrom}.s1.bam\"\n  s2bam=\"${chrom}.s2.bam\"\n  s3bam=\"${chrom}.s3.bam\"\n  s4bam=\"${chrom}.s4.bam\"\n  cbam=\"${chrom}.bam\"\n\n  samtools view -hb -q 30 ${bam} ${chrom} >\\$tbam\n  samtools index \\$tbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam I=\\$tbam O=\\$s1bam VALIDATION_STRINGENCY=LENIENT SO=queryname TMP_DIR=\"\\$TMPDIR\"\n\n  nPE=`samtools view -h \\$tbam |head -n 100000 |samtools view -c -f 1 -S /dev/stdin`\n\n  if [ \"\\$nPE\" -eq \"0\" ]; then\n    ln -s \\$s1bam \\$s3bam\n  else\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR FixMateInformation I=\\$s1bam O=\\$s2bam VALIDATION_STRINGENCY=LENIENT SO=queryname AS=true TMP_DIR=\"\\$TMPDIR\"\n    samtools view -hb -f 2 \\$s2bam >\\$s3bam\n  fi\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates I=\\$s3bam O=\\$s4bam VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=true M=metrics.tab TMP_DIR=\"\\$TMPDIR\"\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam I=\\$s4bam O=\\$cbam VALIDATION_STRINGENCY=LENIENT SO=coordinate TMP_DIR=\"\\$TMPDIR\"\n  samtools index \\$cbam\n\n  readLen=`perl ${params.rtData}/scripts/getClosestReadLength.pl \\$tbam 50,150`\n  #win101=\"${params.rtData}/genomewin/${chrom}.win101.bed\"\n  #ps101=\"${params.rtData}/genomewin/${chrom}.psr\"\\$readLen\".tab\"\n  #gc101=\"${params.rtData}/genomewin/${chrom}.win101.GC.tab\"\n\n  ### NEW ###\n  grep -w ${chrom} ${params.genome_fai} >chrom.fai\n  \n  bedtools makewindows -g chrom.fai -w 101 -s 1 |\n    perl -lane 'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 101)' >${win101}\n    \n  bedtools nuc -fi ${params.genome_fasta} -bed ${win101} -C | grep ^chr | \\\n                   cut -f1-3,5 | perl -M\"Math::Round\" -pi -e 's/(0\\\\.\\\\d\\\\d+)/round(\\$1*100)/e' |cut -f4 >GC.tab\n  \n  cp \"${params.rtData}/mapability/${params.genome}/${chrom}.mapability_\"\\$readLen\"bp.tab.gz\" ./mapability.txt.gz\n  gunzip mapability.txt.gz\n      \n  intersectBed -a ${win101} -b \\$cbam -c -sorted -g ${params.genome_fai} |perl -pi -e 's/\\\\./0/g' >${chrom}.cover.tab\n\n  paste ${chrom}.cover.tab mapability.txt GC.tab |perl -pi -e 's/\\\\s\\\\./0(\\\\s|\\$)/g' >${chrom}.tmp\n  \n  intersectBed -v -sorted -a ${chrom}.tmp -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed >${chrom}.tab\n  ### END NEW ###\n  \n  ## DO GC NORMALIZATION\n  expectedSim=`echo \\$readLen + 100 |bc`\n  mapabilityLowerLim=`echo \"(\\$readLen + 100)*0.66\" |bc`\n  mapabilityUpperLim=`echo \"(\\$readLen + 100)*1.2\" |bc`\n\n  perl ${params.rtData}/scripts/normalizeBy2NGC.pl ${gctab} ${chrom}.tab \\$expectedSim\n\n  shuf GCData.tab |head -n 1000000 |sort -k1rn,1rn >${chrom}.GCdata.tab\n\n  perl -lane 'print join(\"\\\\t\",@F[0..2],\\$F[4]) if (\\$F[4] > '\\$mapabilityLowerLim' && \\$F[4] <  '\\$mapabilityUpperLim' )' ${chrom}.tab >${chrom}.mapability.tab\n  nCov=`echo \"500000 * ${params.covPC} /100\" |bc`\n  \n  bedtools makewindows -g chrom.fai -w 500000 -s 50000  | perl -lane \\'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 500000)\\' >win500k50k.init.bed\n  bedtools makewindows -g chrom.fai -w 500000 -s 100000 | perl -lane \\'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 500000)\\' >win500k100k.init.bed\n\n  mapBed -a win500k50k.init.bed  -b ${chrom}.mapability.tab -c 4 -o count |perl -lane 'print join(\"\\\\t\",@F[0..2]) if (\\$F[3] > int(500000*'${params.covPC}'/100))' >win500k50k.bed\n  mapBed -a win500k100k.init.bed -b ${chrom}.mapability.tab -c 4 -o count |perl -lane 'print join(\"\\\\t\",@F[0..2]) if (\\$F[3] > int(500000*'${params.covPC}'/100))' >win500k100k.bed\n\n  mapBed -a win500k50k.bed  -b ${chrom}.GCcorrected.bedgraph -c 4,4 -o sum,count |perl -M\"Math::Round\" -lane '\\$F[3] = 0 if (\\$F[3] eq \".\" );  \\$val=\\$F[4]?\\$F[3]/\\$F[4]:0; print join(\"\\\\t\",\\$F[0],\\$F[1]+250000-25000,\\$F[1]+250000+24999,round(\\$val*100)/100) if (\\$val)' >${chrom}.win500k50k.tmp\n  mapBed -a win500k100k.bed -b ${chrom}.GCcorrected.bedgraph -c 4,4 -o sum,count |perl -M\"Math::Round\" -lane '\\$F[3] = 0 if (\\$F[3] eq \".\" );  \\$val=\\$F[4]?\\$F[3]/\\$F[4]:0; print join(\"\\\\t\",\\$F[0],\\$F[1]+250000-50000,\\$F[1]+250000+49999,round(\\$val*100)/100) if (\\$val)' >${chrom}.win500k100k.tmp\n\n  intersectBed -c -sorted -a ${chrom}.win500k50k.tmp  -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed  >${chrom}.w500ks50k.bedgraph\n  intersectBed -c -sorted -a ${chrom}.win500k100k.tmp -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed  >${chrom}.w500ks100k.bedgraph\n  \"\"\"\n  }",
        "nb_lignes_process": 89,
        "string_script": "  def win101=\"${chrom}.win101ALL.bed\"\n  \"\"\"\n  tbam=\"${chrom}.tmp.bam\"\n  s1bam=\"${chrom}.s1.bam\"\n  s2bam=\"${chrom}.s2.bam\"\n  s3bam=\"${chrom}.s3.bam\"\n  s4bam=\"${chrom}.s4.bam\"\n  cbam=\"${chrom}.bam\"\n\n  samtools view -hb -q 30 ${bam} ${chrom} >\\$tbam\n  samtools index \\$tbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam I=\\$tbam O=\\$s1bam VALIDATION_STRINGENCY=LENIENT SO=queryname TMP_DIR=\"\\$TMPDIR\"\n\n  nPE=`samtools view -h \\$tbam |head -n 100000 |samtools view -c -f 1 -S /dev/stdin`\n\n  if [ \"\\$nPE\" -eq \"0\" ]; then\n    ln -s \\$s1bam \\$s3bam\n  else\n    java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR FixMateInformation I=\\$s1bam O=\\$s2bam VALIDATION_STRINGENCY=LENIENT SO=queryname AS=true TMP_DIR=\"\\$TMPDIR\"\n    samtools view -hb -f 2 \\$s2bam >\\$s3bam\n  fi\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates I=\\$s3bam O=\\$s4bam VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=true M=metrics.tab TMP_DIR=\"\\$TMPDIR\"\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR SortSam I=\\$s4bam O=\\$cbam VALIDATION_STRINGENCY=LENIENT SO=coordinate TMP_DIR=\"\\$TMPDIR\"\n  samtools index \\$cbam\n\n  readLen=`perl ${params.rtData}/scripts/getClosestReadLength.pl \\$tbam 50,150`\n  #win101=\"${params.rtData}/genomewin/${chrom}.win101.bed\"\n  #ps101=\"${params.rtData}/genomewin/${chrom}.psr\"\\$readLen\".tab\"\n  #gc101=\"${params.rtData}/genomewin/${chrom}.win101.GC.tab\"\n\n  ### NEW ###\n  grep -w ${chrom} ${params.genome_fai} >chrom.fai\n  \n  bedtools makewindows -g chrom.fai -w 101 -s 1 |\n    perl -lane 'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 101)' >${win101}\n    \n  bedtools nuc -fi ${params.genome_fasta} -bed ${win101} -C | grep ^chr | \\\n                   cut -f1-3,5 | perl -M\"Math::Round\" -pi -e 's/(0\\\\.\\\\d\\\\d+)/round(\\$1*100)/e' |cut -f4 >GC.tab\n  \n  cp \"${params.rtData}/mapability/${params.genome}/${chrom}.mapability_\"\\$readLen\"bp.tab.gz\" ./mapability.txt.gz\n  gunzip mapability.txt.gz\n      \n  intersectBed -a ${win101} -b \\$cbam -c -sorted -g ${params.genome_fai} |perl -pi -e 's/\\\\./0/g' >${chrom}.cover.tab\n\n  paste ${chrom}.cover.tab mapability.txt GC.tab |perl -pi -e 's/\\\\s\\\\./0(\\\\s|\\$)/g' >${chrom}.tmp\n  \n  intersectBed -v -sorted -a ${chrom}.tmp -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed >${chrom}.tab\n  ### END NEW ###\n  \n  ## DO GC NORMALIZATION\n  expectedSim=`echo \\$readLen + 100 |bc`\n  mapabilityLowerLim=`echo \"(\\$readLen + 100)*0.66\" |bc`\n  mapabilityUpperLim=`echo \"(\\$readLen + 100)*1.2\" |bc`\n\n  perl ${params.rtData}/scripts/normalizeBy2NGC.pl ${gctab} ${chrom}.tab \\$expectedSim\n\n  shuf GCData.tab |head -n 1000000 |sort -k1rn,1rn >${chrom}.GCdata.tab\n\n  perl -lane 'print join(\"\\\\t\",@F[0..2],\\$F[4]) if (\\$F[4] > '\\$mapabilityLowerLim' && \\$F[4] <  '\\$mapabilityUpperLim' )' ${chrom}.tab >${chrom}.mapability.tab\n  nCov=`echo \"500000 * ${params.covPC} /100\" |bc`\n  \n  bedtools makewindows -g chrom.fai -w 500000 -s 50000  | perl -lane \\'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 500000)\\' >win500k50k.init.bed\n  bedtools makewindows -g chrom.fai -w 500000 -s 100000 | perl -lane \\'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 500000)\\' >win500k100k.init.bed\n\n  mapBed -a win500k50k.init.bed  -b ${chrom}.mapability.tab -c 4 -o count |perl -lane 'print join(\"\\\\t\",@F[0..2]) if (\\$F[3] > int(500000*'${params.covPC}'/100))' >win500k50k.bed\n  mapBed -a win500k100k.init.bed -b ${chrom}.mapability.tab -c 4 -o count |perl -lane 'print join(\"\\\\t\",@F[0..2]) if (\\$F[3] > int(500000*'${params.covPC}'/100))' >win500k100k.bed\n\n  mapBed -a win500k50k.bed  -b ${chrom}.GCcorrected.bedgraph -c 4,4 -o sum,count |perl -M\"Math::Round\" -lane '\\$F[3] = 0 if (\\$F[3] eq \".\" );  \\$val=\\$F[4]?\\$F[3]/\\$F[4]:0; print join(\"\\\\t\",\\$F[0],\\$F[1]+250000-25000,\\$F[1]+250000+24999,round(\\$val*100)/100) if (\\$val)' >${chrom}.win500k50k.tmp\n  mapBed -a win500k100k.bed -b ${chrom}.GCcorrected.bedgraph -c 4,4 -o sum,count |perl -M\"Math::Round\" -lane '\\$F[3] = 0 if (\\$F[3] eq \".\" );  \\$val=\\$F[4]?\\$F[3]/\\$F[4]:0; print join(\"\\\\t\",\\$F[0],\\$F[1]+250000-50000,\\$F[1]+250000+49999,round(\\$val*100)/100) if (\\$val)' >${chrom}.win500k100k.tmp\n\n  intersectBed -c -sorted -a ${chrom}.win500k50k.tmp  -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed  >${chrom}.w500ks50k.bedgraph\n  intersectBed -c -sorted -a ${chrom}.win500k100k.tmp -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed  >${chrom}.w500ks100k.bedgraph\n  \"\"\"",
        "nb_lignes_script": 74,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "bam",
            "bai",
            "gctab",
            "chrom"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { chrom }"
        ],
        "when": "",
        "stub": ""
    },
    "mergeCoverageBedgraphs": {
        "name_process": "mergeCoverageBedgraphs",
        "string_process": "\nprocess mergeCoverageBedgraphs {\n\n  publishDir \"${params.outdir}/bedgraph/RTmodelling/raw\"                ,  mode: 'copy', overwrite: true, pattern: '*age.forModel.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/RTmodelling/medianNorm/byChr\"   ,  mode: 'copy', overwrite: true, pattern: '*ChromMedian.forModel.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/RTmodelling/meanNorm/byChr\"     ,  mode: 'copy', overwrite: true, pattern: '*ChromMean.forModel.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/RTmodelling/medianNorm/byGenome\",  mode: 'copy', overwrite: true, pattern: '*GenomeMedian.forModel.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/RTmodelling/meanNorm/byGenome\"  ,  mode: 'copy', overwrite: true, pattern: '*GenomeMean.forModel.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/raw\"                            ,  mode: 'copy', overwrite: true, pattern: '*age.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/medianNorm/byChr\"               ,  mode: 'copy', overwrite: true, pattern: '*ChromMedian.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/meanNorm/byChr\"                 ,  mode: 'copy', overwrite: true, pattern: '*ChromMean.bedgraph'  \n  publishDir \"${params.outdir}/bedgraph/medianNorm/byGenome\"            ,  mode: 'copy', overwrite: true, pattern: '*GenomeMedian.bedgraph'\n  publishDir \"${params.outdir}/bedgraph/meanNorm/byGenome\"              ,  mode: 'copy', overwrite: true, pattern: '*GenomeMean.bedgraph'\n  publishDir \"${params.outdir}/bedgraph\"                                ,  mode: 'copy', overwrite: true, pattern: '*w500ks50k.normByGenomeMedian.forModel.bedgraph'\n  publishDir \"${params.outdir}/fig\"                                     ,  mode: 'copy', overwrite: true, pattern: '*pdf'\n  publishDir \"${params.outdir}/fig\"                                     ,  mode: 'copy', overwrite: true, pattern: '*png'\n\n  input:\n  val(outName)\n  path(gc)\n  path(bg)\n\n  output:\n  path(\"*norm*.bedgraph\",    emit: normBG)\n  path(\"*coverage.bedgraph\", emit: coverBG)\n  path(\"*png\",               emit: png)\n  path(\"*pdf\",               emit: pdf)\n\n  script:\n  \"\"\"\n  shuf -n 2000000 ${bg} |awk NF >GCdata.tab\n  \n  R --vanilla <${params.accessoryDir}/scripts/R/plotGCcorrectionStats.R\n  mv gcCorrection.png ${outName}.gcCorrection.png\n  mv gcCorrection.pdf ${outName}.gcCorrection.pdf\n\n  for step in 50 100; do\n    sort -k1,1 -k2n,2n *\".w500ks\"\\$step\"k.bedgraph\"  |perl -lane \\'\\$F[3] = 0 if (\\$F[4]); print join(\"\\\\t\",@F[0..3])\\' >\"${outName}.w500ks\"\\$step\"k.coverage.bedgraph\"\n    perl ${params.accessoryDir}/scripts/normalizeBedgraph.pl \"${outName}.w500ks\"\\$step\"k.coverage.bedgraph\" \"${outName}.w500ks\"\\$step\"k\"\n\n    mv \"${outName}.w500ks\"\\$step\"k.normByGenomeMean.penultimateBG\"    \"${outName}.w500ks\"\\$step\"k.normByGenomeMean.bedgraph\"\n    mv \"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.penultimateBG\"  \"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.bedgraph\"\n    mv \"${outName}.w500ks\"\\$step\"k.normByChromMean.penultimateBG\"     \"${outName}.w500ks\"\\$step\"k.normByChromMean.bedgraph\"\n    mv \"${outName}.w500ks\"\\$step\"k.normByChromMedian.penultimateBG\"   \"${outName}.w500ks\"\\$step\"k.normByChromMedian.bedgraph\"\n\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByGenomeMean.bedgraph\"   ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByGenomeMean.forModel.bedgraph\"\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.bedgraph\" ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.forModel.bedgraph\"\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByChromMean.bedgraph\"    ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByChromMean.forModel.bedgraph\"\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByChromMedian.bedgraph\"  ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByChromMedian.forModel.bedgraph\"\n  done\n  \"\"\"\n  }",
        "nb_lignes_process": 50,
        "string_script": "  \"\"\"\n  shuf -n 2000000 ${bg} |awk NF >GCdata.tab\n  \n  R --vanilla <${params.accessoryDir}/scripts/R/plotGCcorrectionStats.R\n  mv gcCorrection.png ${outName}.gcCorrection.png\n  mv gcCorrection.pdf ${outName}.gcCorrection.pdf\n\n  for step in 50 100; do\n    sort -k1,1 -k2n,2n *\".w500ks\"\\$step\"k.bedgraph\"  |perl -lane \\'\\$F[3] = 0 if (\\$F[4]); print join(\"\\\\t\",@F[0..3])\\' >\"${outName}.w500ks\"\\$step\"k.coverage.bedgraph\"\n    perl ${params.accessoryDir}/scripts/normalizeBedgraph.pl \"${outName}.w500ks\"\\$step\"k.coverage.bedgraph\" \"${outName}.w500ks\"\\$step\"k\"\n\n    mv \"${outName}.w500ks\"\\$step\"k.normByGenomeMean.penultimateBG\"    \"${outName}.w500ks\"\\$step\"k.normByGenomeMean.bedgraph\"\n    mv \"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.penultimateBG\"  \"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.bedgraph\"\n    mv \"${outName}.w500ks\"\\$step\"k.normByChromMean.penultimateBG\"     \"${outName}.w500ks\"\\$step\"k.normByChromMean.bedgraph\"\n    mv \"${outName}.w500ks\"\\$step\"k.normByChromMedian.penultimateBG\"   \"${outName}.w500ks\"\\$step\"k.normByChromMedian.bedgraph\"\n\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByGenomeMean.bedgraph\"   ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByGenomeMean.forModel.bedgraph\"\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.bedgraph\" ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByGenomeMedian.forModel.bedgraph\"\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByChromMean.bedgraph\"    ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByChromMean.forModel.bedgraph\"\n    perl ${params.accessoryDir}/scripts/convertToModellingBG.pl \"${outName}.w500ks\"\\$step\"k.normByChromMedian.bedgraph\"  ${params.genome_fai} >\"${outName}.w500ks\"\\$step\"k.normByChromMedian.forModel.bedgraph\"\n  done\n  \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "outName",
            "gc",
            "bg"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/bedgraph/RTmodelling/raw\" , mode: 'copy', overwrite: true, pattern: '*age.forModel.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/RTmodelling/medianNorm/byChr\" , mode: 'copy', overwrite: true, pattern: '*ChromMedian.forModel.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/RTmodelling/meanNorm/byChr\" , mode: 'copy', overwrite: true, pattern: '*ChromMean.forModel.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/RTmodelling/medianNorm/byGenome\", mode: 'copy', overwrite: true, pattern: '*GenomeMedian.forModel.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/RTmodelling/meanNorm/byGenome\" , mode: 'copy', overwrite: true, pattern: '*GenomeMean.forModel.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/raw\" , mode: 'copy', overwrite: true, pattern: '*age.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/medianNorm/byChr\" , mode: 'copy', overwrite: true, pattern: '*ChromMedian.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/meanNorm/byChr\" , mode: 'copy', overwrite: true, pattern: '*ChromMean.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/medianNorm/byGenome\" , mode: 'copy', overwrite: true, pattern: '*GenomeMedian.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph/meanNorm/byGenome\" , mode: 'copy', overwrite: true, pattern: '*GenomeMean.bedgraph'",
            "publishDir \"${params.outdir}/bedgraph\" , mode: 'copy', overwrite: true, pattern: '*w500ks50k.normByGenomeMedian.forModel.bedgraph'",
            "publishDir \"${params.outdir}/fig\" , mode: 'copy', overwrite: true, pattern: '*pdf'",
            "publishDir \"${params.outdir}/fig\" , mode: 'copy', overwrite: true, pattern: '*png'"
        ],
        "when": "",
        "stub": ""
    },
    "getGCcorrFile": {
        "name_process": "getGCcorrFile",
        "string_process": "\nprocess getGCcorrFile{\n  \n  publishDir \"${params.outdir}/gcCorrectionFile\",  mode: 'copy', overwrite: false\n\n  output:\n  path(\"gcCorrectionTable.tab\",  emit: tab)\n\n  script:\n  \"\"\"\n  if [ -f \"${params.gcCorrection}\" ]; then\n    cp ${params.gcCorrection} gcCorrectionTable.tab\n  else\n    cp /usr/local/rtseq/gcCorrectionFiles/${params.gcCorrection.toUpperCase()}.tab gcCorrectionTable.tab\n  fi\n  \"\"\"  \n  }",
        "nb_lignes_process": 15,
        "string_script": "  \"\"\"\n  if [ -f \"${params.gcCorrection}\" ]; then\n    cp ${params.gcCorrection} gcCorrectionTable.tab\n  else\n    cp /usr/local/rtseq/gcCorrectionFiles/${params.gcCorrection.toUpperCase()}.tab gcCorrectionTable.tab\n  fi\n  \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/gcCorrectionFile\", mode: 'copy', overwrite: false"
        ],
        "when": "",
        "stub": ""
    },
    "generateMpileup": {
        "name_process": "generateMpileup",
        "string_process": "\nprocess generateMpileup {\n\n  tag { chrom }\n\n                                                             \n\n  input:\n  tuple(path(bam),path(bai))\n  val(chrom)\n\n  output:\n                                  \n  path(\"*.DS.tab\",  emit: dsGC)\n\n  script:\n  def nregion;\n  if (params.test & !params.fullChromTest){\n    nregion=\":1-15000000\"\n  }else{\n    nregion=\"\"\n  }\n\n  \"\"\"\n  tbam=\"${chrom}.tmp.bam\"\n  cbam=\"${chrom}.bam\"\n\n  samtools view -hb ${bam} ${chrom} >\\$tbam\n  samtools index \\$tbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates I=\\$tbam O=\\$cbam \\\n                     VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=true AS=true M=metrics.tab TMP_DIR=\"\\$TMPDIR\"\n  samtools index \\$cbam\n\n  readLen=`perl ${params.accessoryDir}/rtSeq/scripts/getClosestReadLength.pl \\$tbam 50,150`\n  pseudoReadDir=${params.pseudoReadBase}\"/\"\\$readLen\"bpReads_1bpStep/\"\n  \n  genomeCoverageBed -ibam \\$cbam -d -g >coverage.gcb.tab\n  \n  samtools mpileup -r ${chrom}${nregion} -f ${params.genome_mask_fa} -q 31 \\\n                                   \\$pseudoReadDir/${chrom}.bam \\$cbam \\\n                                   |perl -lane \\'print join(\"\\\\t\",\\$F[0],\\$F[1]-1,\\$F[1],\\$F[3],\\$F[6],(\\$F[2] =~ /[GATC]/?1:0),(\\$F[2] =~ /[GC]/?1:0))\\' \\\n                                   >${chrom}.mpu\n\n  grep -w ${chrom} ${params.genome_fai} >idx.fai\n  bedtools makewindows -g idx.fai -w 101 -s 1 | intersectBed -v -sorted -a - -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed \\\n                                              |perl -lane \\'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 101)\\' >win101.bed\n\n  nwin=`cat win101.bed |wc -l`\n  nDS=`printf %1.0f \\$(echo \"\\$nwin*0.02\" |bc)`\n  \n  mapBed -a win101.bed -b ${chrom}.mpu -c 4,5,6,7 -o sum,sum,sum,sum |perl -pi -e 's/\\\\./NA/g' >${chrom}.ALL.tab\n\n  ##Criteria :              NOT NA         && >0 cover &&   Fully mapable  &&  no repeat DNA\n  perl -lane 'print \\$_ if (\\$F[4] !~ /NA/ &&  \\$F[4]  && \\$F[3] == ('\\$readLen' * 101) && \\$F[5] eq \"101\")' ${chrom}.ALL.tab >ok.tab\n\n  shuf ok.tab |head -n \\$nDS |sort -k1,1 -k2n,2n >${chrom}.DS.tab\n  \"\"\"\n  }",
        "nb_lignes_process": 57,
        "string_script": "  def nregion;\n  if (params.test & !params.fullChromTest){\n    nregion=\":1-15000000\"\n  }else{\n    nregion=\"\"\n  }\n\n  \"\"\"\n  tbam=\"${chrom}.tmp.bam\"\n  cbam=\"${chrom}.bam\"\n\n  samtools view -hb ${bam} ${chrom} >\\$tbam\n  samtools index \\$tbam\n\n  java -jar -Xmx${task.memory.toGiga()}g \\$PICARDJAR MarkDuplicates I=\\$tbam O=\\$cbam \\\n                     VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=true AS=true M=metrics.tab TMP_DIR=\"\\$TMPDIR\"\n  samtools index \\$cbam\n\n  readLen=`perl ${params.accessoryDir}/rtSeq/scripts/getClosestReadLength.pl \\$tbam 50,150`\n  pseudoReadDir=${params.pseudoReadBase}\"/\"\\$readLen\"bpReads_1bpStep/\"\n  \n  genomeCoverageBed -ibam \\$cbam -d -g >coverage.gcb.tab\n  \n  samtools mpileup -r ${chrom}${nregion} -f ${params.genome_mask_fa} -q 31 \\\n                                   \\$pseudoReadDir/${chrom}.bam \\$cbam \\\n                                   |perl -lane \\'print join(\"\\\\t\",\\$F[0],\\$F[1]-1,\\$F[1],\\$F[3],\\$F[6],(\\$F[2] =~ /[GATC]/?1:0),(\\$F[2] =~ /[GC]/?1:0))\\' \\\n                                   >${chrom}.mpu\n\n  grep -w ${chrom} ${params.genome_fai} >idx.fai\n  bedtools makewindows -g idx.fai -w 101 -s 1 | intersectBed -v -sorted -a - -b ${params.rtData}/blacklist/${params.genome}.blacklist.bed \\\n                                              |perl -lane \\'print join(\"\\\\t\",@F) unless ((\\$F[2]-\\$F[1]) != 101)\\' >win101.bed\n\n  nwin=`cat win101.bed |wc -l`\n  nDS=`printf %1.0f \\$(echo \"\\$nwin*0.02\" |bc)`\n  \n  mapBed -a win101.bed -b ${chrom}.mpu -c 4,5,6,7 -o sum,sum,sum,sum |perl -pi -e 's/\\\\./NA/g' >${chrom}.ALL.tab\n\n  ##Criteria :              NOT NA         && >0 cover &&   Fully mapable  &&  no repeat DNA\n  perl -lane 'print \\$_ if (\\$F[4] !~ /NA/ &&  \\$F[4]  && \\$F[3] == ('\\$readLen' * 101) && \\$F[5] eq \"101\")' ${chrom}.ALL.tab >ok.tab\n\n  shuf ok.tab |head -n \\$nDS |sort -k1,1 -k2n,2n >${chrom}.DS.tab\n  \"\"\"",
        "nb_lignes_script": 41,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "bam",
            "bai",
            "chrom"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "tag { chrom }"
        ],
        "when": "",
        "stub": ""
    },
    "getGCstats": {
        "name_process": "getGCstats",
        "string_process": "\nprocess getGCstats {\n\n  publishDir \"${params.outdir}/tables\",  mode: 'copy', overwrite: true, pattern: '*DS.tab'\n  publishDir \"${params.outdir}/tables\",  mode: 'copy', overwrite: true, pattern: '*table.tab'\n  publishDir \"${params.outdir}/figs\",    mode: 'copy', overwrite: true, pattern: '*Before_v_After*'\n\n  input:\n  file(gctab)\n\n  output:\n  path(\"*.wholeGenome.DS.tab\"       ,emit: allGCDS)\n  path(\"*GCcorrectiontable.tab\"     ,emit: correctionTab)\n  path(\"*chromCorrectiontable.tab\"  ,emit: chromMeans)\n  path(\"*Before_v*.png\"             ,emit: correctionPNG)\n  path(\"*Before_v*.pdf\"             ,emit: correctionPDF)\n\n  script:\n  \"\"\"\n  sort -k1,1 -k2n,2n *DS.tab |grep -P \"^chr[0123456789XY]+\" |cut -f1-3,5,7 >wholeGenome.DS.tab\n  R --no-save --no-site-file --no-init-file --no-restore --silent --slave <${params.accessoryFiles}/scripts/R/getGCcorrectionFactors.R ||true\n\n  cp wholeGenome.DS.tab ${outName}.wholeGenome.DS.tab\n\n  mv chromCorrectiontable.tab ${outName}.chromCorrectiontable.tab\n  mv GCcorrectiontable.tab    ${outName}.GCcorrectiontable.tab\n\n  for f in `ls *_rtSeq_GCCorrection_Before_v_After.png`; do mv \\$f ${outName}.rtSeq_GCCorrection_Before_v_After.png; done\n  for f in `ls *_rtSeq_GCCorrection_Before_v_After.pdf`; do mv \\$f ${outName}.rtSeq_GCCorrection_Before_v_After.pdf; done\n\n  \"\"\"\n  }",
        "nb_lignes_process": 30,
        "string_script": "  \"\"\"\n  sort -k1,1 -k2n,2n *DS.tab |grep -P \"^chr[0123456789XY]+\" |cut -f1-3,5,7 >wholeGenome.DS.tab\n  R --no-save --no-site-file --no-init-file --no-restore --silent --slave <${params.accessoryFiles}/scripts/R/getGCcorrectionFactors.R ||true\n\n  cp wholeGenome.DS.tab ${outName}.wholeGenome.DS.tab\n\n  mv chromCorrectiontable.tab ${outName}.chromCorrectiontable.tab\n  mv GCcorrectiontable.tab    ${outName}.GCcorrectiontable.tab\n\n  for f in `ls *_rtSeq_GCCorrection_Before_v_After.png`; do mv \\$f ${outName}.rtSeq_GCCorrection_Before_v_After.png; done\n  for f in `ls *_rtSeq_GCCorrection_Before_v_After.pdf`; do mv \\$f ${outName}.rtSeq_GCCorrection_Before_v_After.pdf; done\n\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gctab"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [
            "publishDir \"${params.outdir}/tables\", mode: 'copy', overwrite: true, pattern: '*DS.tab'",
            "publishDir \"${params.outdir}/tables\", mode: 'copy', overwrite: true, pattern: '*table.tab'",
            "publishDir \"${params.outdir}/figs\", mode: 'copy', overwrite: true, pattern: '*Before_v_After*'"
        ],
        "when": "",
        "stub": ""
    },
    "multiQC": {
        "name_process": "multiQC",
        "string_process": "process multiQC {\n\n  input:\n  path(reports)\n\n  output:\n  path('*ultiQC*', emit: mqcReport)\n\n  script:\n  \"\"\"\n  multiqc -f -n ${params.name}.multiQC .\n  \"\"\"\n  }",
        "nb_lignes_process": 11,
        "string_script": "  \"\"\"\n  multiqc -f -n ${params.name}.multiQC .\n  \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "reports"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "kevbrick__pipeIt",
        "directive": [],
        "when": "",
        "stub": ""
    }
}