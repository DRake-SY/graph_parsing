{
    "SYNAPSE_LIST": {
        "name_process": "SYNAPSE_LIST",
        "string_process": "\nprocess SYNAPSE_LIST {\n    publishDir \"${params.outdir}/synapse/\"\n\n    input:\n    val synid\n\n    output:\n    path \"*.synlist.csv\", emit: synlist_csv\n\n    script:\n    \"\"\"\n    synapse list -l $synid | cut -c-11 > ${synid}.synlist.csv\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    synapse list -l $synid | cut -c-11 > ${synid}.synlist.csv\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "synid"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "daisyhan97__nf-fetchngs-synapse",
        "directive": [
            "publishDir \"${params.outdir}/synapse/\""
        ],
        "when": "",
        "stub": ""
    },
    "SYNAPSE_GET": {
        "name_process": "SYNAPSE_GET",
        "string_process": "\nprocess SYNAPSE_GET {\n    publishDir \"${params.outdir}/fastq/\"\n\n    input:\n    val(synapseID)\n\n    output:\n    path \"*\", emit: fastq\n\n    script:\n    \"\"\"\n    synapse get $synapseID\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    synapse get $synapseID\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "synapseID"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "daisyhan97__nf-fetchngs-synapse",
        "directive": [
            "publishDir \"${params.outdir}/fastq/\""
        ],
        "when": "",
        "stub": ""
    },
    "SYNAPSE_SHOW": {
        "name_process": "SYNAPSE_SHOW",
        "string_process": "\nprocess SYNAPSE_SHOW {\n    publishDir \"${params.outdir}/synapse/\"\n\n    input:\n    val(synapseID)\n\n    output:\n    path \"*.metadata.txt\", emit: metadata\n\n    script:\n    \"\"\"\n    synapse show $synapseID | sed -n '1,3p;15,16p;20p;23p' > ${synapseID}.metadata.txt\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    synapse show $synapseID | sed -n '1,3p;15,16p;20p;23p' > ${synapseID}.metadata.txt\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "synapseID"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "daisyhan97__nf-fetchngs-synapse",
        "directive": [
            "publishDir \"${params.outdir}/synapse/\""
        ],
        "when": "",
        "stub": ""
    },
    "READ_PAIRS_TO_SAMPLESHEET": {
        "name_process": "READ_PAIRS_TO_SAMPLESHEET",
        "string_process": "\nprocess READ_PAIRS_TO_SAMPLESHEET {\n    publishDir \"${params.outdir}/samplesheet/\"\n\n    input:\n    tuple val(id), val(files)\n    val strandedness\n\n    output:\n    path(\"*samplesheet.csv\"), emit: samplesheet\n\n    exec:\n                                                      \n    pipeline_map = [\n        sample  : \"${id}\",\n        fastq_1 : \"${params.outdir}/${params.results_dir}/${files[0].getBaseName()}\",\n        fastq_2 : \"${params.outdir}/${params.results_dir}/${files[1].getBaseName()}\"\n    ]\n                       \n    pipeline_map << [ strandedness: \"${strandedness}\" ]\n    \n                         \n    samplesheet  = pipeline_map.keySet().collect{ '\"' + it + '\"'}.join(\",\") + '\\n'\n    samplesheet += pipeline_map.values().collect{ '\"' + it + '\"'}.join(\",\")\n\n    def samplesheet_file2 = task.workDir.resolve(\"${pipeline_map.sample}.samplesheet.csv\")\n    samplesheet_file2.text = samplesheet\n}",
        "nb_lignes_process": 26,
        "string_script": "    pipeline_map = [\n        sample  : \"${id}\",\n        fastq_1 : \"${params.outdir}/${params.results_dir}/${files[0].getBaseName()}\",\n        fastq_2 : \"${params.outdir}/${params.results_dir}/${files[1].getBaseName()}\"\n    ]\n                       \n    pipeline_map << [ strandedness: \"${strandedness}\" ]\n    \n                         \n    samplesheet  = pipeline_map.keySet().collect{ '\"' + it + '\"'}.join(\",\") + '\\n'\n    samplesheet += pipeline_map.values().collect{ '\"' + it + '\"'}.join(\",\")\n\n    def samplesheet_file2 = task.workDir.resolve(\"${pipeline_map.sample}.samplesheet.csv\")\n    samplesheet_file2.text = samplesheet",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "SAMPLE"
        ],
        "tools_url": [
            "https://bio.tools/sample"
        ],
        "tools_dico": [
            {
                "name": "SAMPLE",
                "uri": "https://bio.tools/sample",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Linkage mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Functional mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic cartography"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0282",
                                    "term": "Genetic map generation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The tool is designed to identify regions that are linked to a recessive disease by analysing genotype data from the parents and unaffected sibs of affected individuals. Since this analysis does not use data from affected patients, it is suited to the identification of lethal recessive genes, when the patients may have died before DNA samples could be obtained.",
                "homepage": "http://dna.leeds.ac.uk/sample/"
            }
        ],
        "inputs": [
            "id",
            "files",
            "strandedness"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "daisyhan97__nf-fetchngs-synapse",
        "directive": [
            "publishDir \"${params.outdir}/samplesheet/\""
        ],
        "when": "",
        "stub": ""
    },
    "METADATA_TO_METAMAP": {
        "name_process": "METADATA_TO_METAMAP",
        "string_process": "\nprocess METADATA_TO_METAMAP {\n    publishDir \"${params.outdir}/metadata/\"\n    input: \n    val data\n\n    output:\n    path(\"*metasheet.csv\"), emit: metasheet\n\n    exec:\n    meta_map = [\n        md5         : \"${data[0]}\",\n        fileSize    : \"${data[1]}\",\n        etag        : \"${data[2]}\",\n        id          : \"${data[3]}\",\n        fileName    : \"${data[4]}\",\n        fileVersion : \"${data[5]}\"\n    ]\n\n                            \n    metasheet  = meta_map.keySet().collect{ '\"' + it + '\"'}.join(\",\") + '\\n'\n    metasheet += meta_map.values().collect{ '\"' + it + '\"'}.join(\",\")\n\n    def metasheet_file = task.workDir.resolve(\"${meta_map.id}.metasheet.csv\")\n    metasheet_file.text = metasheet\n}",
        "nb_lignes_process": 24,
        "string_script": "    meta_map = [\n        md5         : \"${data[0]}\",\n        fileSize    : \"${data[1]}\",\n        etag        : \"${data[2]}\",\n        id          : \"${data[3]}\",\n        fileName    : \"${data[4]}\",\n        fileVersion : \"${data[5]}\"\n    ]\n\n                            \n    metasheet  = meta_map.keySet().collect{ '\"' + it + '\"'}.join(\",\") + '\\n'\n    metasheet += meta_map.values().collect{ '\"' + it + '\"'}.join(\",\")\n\n    def metasheet_file = task.workDir.resolve(\"${meta_map.id}.metasheet.csv\")\n    metasheet_file.text = metasheet",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "MetaGUN",
            "MID"
        ],
        "tools_url": [
            "https://bio.tools/metagun",
            "https://bio.tools/mid"
        ],
        "tools_dico": [
            {
                "name": "MetaGUN",
                "uri": "https://bio.tools/metagun",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Novel gene prediction method for metagenomic fragments based on a machine learning approach of SVM.",
                "homepage": "http://cqb.pku.edu.cn/ZhuLab/MetaGUN/index.html"
            },
            {
                "name": "MID",
                "uri": "https://bio.tools/mid",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2423",
                                    "term": "Prediction and recognition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "MID (Micro-Inversion Detector) is a tool to detect microinversions (MIs) by mapping initially unmapped short reads back onto reference genome sequence (i.e. human genome assebly hg19).",
                "homepage": "http://cqb.pku.edu.cn/ZhuLab/MID/index.html"
            }
        ],
        "inputs": [
            "data"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "daisyhan97__nf-fetchngs-synapse",
        "directive": [
            "publishDir \"${params.outdir}/metadata/\""
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_SAMPLESHEET": {
        "name_process": "MERGE_SAMPLESHEET",
        "string_process": "\nprocess MERGE_SAMPLESHEET {\n    publishDir \"${params.outdir}\"\n\n    input:\n    path ('samplesheets/*')\n    path ('metasheet/*')\n\n    output:\n    path \"samplesheet.csv\", emit: samplesheet\n    path \"metasheet.csv\", emit: metasheet\n\n    script:\n    \"\"\"\n    head -n 1 `ls ./samplesheets/* | head -n 1` > samplesheet.csv\n    for fileid in `ls ./samplesheets/*`; do\n        awk 'NR>1' \\$fileid >> samplesheet.csv\n    done\n\n    head -n 1 `ls ./metasheet/* | head -n 1` > metasheet.csv\n    for fileid in `ls ./metasheet/*`; do\n        awk 'NR>1' \\$fileid >> metasheet.csv\n    done\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    head -n 1 `ls ./samplesheets/* | head -n 1` > samplesheet.csv\n    for fileid in `ls ./samplesheets/*`; do\n        awk 'NR>1' \\$fileid >> samplesheet.csv\n    done\n\n    head -n 1 `ls ./metasheet/* | head -n 1` > metasheet.csv\n    for fileid in `ls ./metasheet/*`; do\n        awk 'NR>1' \\$fileid >> metasheet.csv\n    done\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "daisyhan97__nf-fetchngs-synapse",
        "directive": [
            "publishDir \"${params.outdir}\""
        ],
        "when": "",
        "stub": ""
    }
}