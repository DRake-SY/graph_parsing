{
    "TRANSLATE_TARGET_FILE": {
        "name_process": "TRANSLATE_TARGET_FILE",
        "string_process": "\nprocess TRANSLATE_TARGET_FILE {\n    \n                                                                                            \n    \n\n              \n  label 'in_container'\n  publishDir \"${params.outdir}/00_translated_target_file\", mode: 'copy'\n\n  when:\n    params.translate_target_file_for_blastx\n\n  input:\n    path(target_file_nucleotides)\n\n  output:\n    path \"target_file_translated.fasta\", emit: translated_target_file\n    path(\"translation_warnings.txt\")\n\n  script:\n    \"\"\"\n    #!/usr/bin/env python\n\n    from Bio import SeqIO\n\n    translated_seqs_to_write = []\n    with open(\"${target_file_nucleotides}\", 'r') as target_file_nucleotides:\n      seqs = SeqIO.parse(target_file_nucleotides, 'fasta')\n      with open('translation_warnings.txt', 'w') as translation_warnings:\n        for seq in seqs:\n          if len(seq.seq) % 3 != 0:\n            translation_warnings.write(f\"WARNING: sequence for gene {seq.name} is not a multiple of 3. Translating anyway...\\\\n\")\n          protein_translation = seq.translate()\n          protein_translation.name = seq.name\n          protein_translation.id = seq.id\n          protein_translation.description = 'translated sequence from nucleotide target file'\n          num_stop_codons = protein_translation.seq.count('*')\n          if num_stop_codons != 0:\n            translation_warnings.write(f'WARNING: stop codons present in translation of sequence {seq.name}, please check\\\\n')\n          translated_seqs_to_write.append(protein_translation)\n\n    with open('target_file_translated.fasta', 'w') as translated_handle:\n      SeqIO.write(translated_seqs_to_write, translated_handle, 'fasta')\n\n    \"\"\"\n}",
        "nb_lignes_process": 45,
        "string_script": "    \"\"\"\n    #!/usr/bin/env python\n\n    from Bio import SeqIO\n\n    translated_seqs_to_write = []\n    with open(\"${target_file_nucleotides}\", 'r') as target_file_nucleotides:\n      seqs = SeqIO.parse(target_file_nucleotides, 'fasta')\n      with open('translation_warnings.txt', 'w') as translation_warnings:\n        for seq in seqs:\n          if len(seq.seq) % 3 != 0:\n            translation_warnings.write(f\"WARNING: sequence for gene {seq.name} is not a multiple of 3. Translating anyway...\\\\n\")\n          protein_translation = seq.translate()\n          protein_translation.name = seq.name\n          protein_translation.id = seq.id\n          protein_translation.description = 'translated sequence from nucleotide target file'\n          num_stop_codons = protein_translation.seq.count('*')\n          if num_stop_codons != 0:\n            translation_warnings.write(f'WARNING: stop codons present in translation of sequence {seq.name}, please check\\\\n')\n          translated_seqs_to_write.append(protein_translation)\n\n    with open('target_file_translated.fasta', 'w') as translated_handle:\n      SeqIO.write(translated_seqs_to_write, translated_handle, 'fasta')\n\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "target_file_nucleotides"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/00_translated_target_file\", mode: 'copy'"
        ],
        "when": "params.translate_target_file_for_blastx",
        "stub": ""
    },
    "COMBINE_LANES_PAIRED_END": {
        "name_process": "COMBINE_LANES_PAIRED_END",
        "string_process": "\nprocess COMBINE_LANES_PAIRED_END {\n    \n                                                                                             \n    \n\n  label 'in_container'\n              \n  publishDir \"$params.outdir/02_reads_combined_lanes\", mode: 'copy', pattern: \"*.fastq*\"\n\n  if (params.num_forks) {\n    maxForks params.num_forks\n  }\n\n  when:\n    params.combine_read_files\n\n  input:\n    tuple val(prefix), path(reads_R1), path(reads_R2)\n\n  output:\n    tuple val(prefix), path(\"*R1.fastq*\"), path(\"*R2.fastq*\"), emit: combined_lane_paired_reads\n\n  script:\n    \"\"\"\n    first_file=\\$(echo $reads_R1 | cut -d' ' -f1)\n    echo \\$first_file\n\n    if [[ \\$first_file = *.gz ]]\n      then \n        cat $reads_R1 > ${prefix}_combinedLanes_R1.fastq.gz\n        cat $reads_R2 > ${prefix}_combinedLanes_R2.fastq.gz\n    fi\n\n    if [[ \\$first_file = *.fq ]] || [[ \\$first_file = *.fastq ]]\n      then \n        cat $reads_R1 > ${prefix}_combinedLanes_R1.fastq\n        cat $reads_R2 > ${prefix}_combinedLanes_R2.fastq\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "    \"\"\"\n    first_file=\\$(echo $reads_R1 | cut -d' ' -f1)\n    echo \\$first_file\n\n    if [[ \\$first_file = *.gz ]]\n      then \n        cat $reads_R1 > ${prefix}_combinedLanes_R1.fastq.gz\n        cat $reads_R2 > ${prefix}_combinedLanes_R2.fastq.gz\n    fi\n\n    if [[ \\$first_file = *.fq ]] || [[ \\$first_file = *.fastq ]]\n      then \n        cat $reads_R1 > ${prefix}_combinedLanes_R1.fastq\n        cat $reads_R2 > ${prefix}_combinedLanes_R2.fastq\n    fi\n    \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "reads_R1",
            "reads_R2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"$params.outdir/02_reads_combined_lanes\", mode: 'copy', pattern: \"*.fastq*\" if (params.num_forks) { maxForks params.num_forks }"
        ],
        "when": "params.combine_read_files",
        "stub": ""
    },
    "COMBINE_LANES_SINGLE_END": {
        "name_process": "COMBINE_LANES_SINGLE_END",
        "string_process": "\nprocess COMBINE_LANES_SINGLE_END {\n    \n                                                                                        \n    \n\n  label 'in_container'\n              \n  publishDir \"$params.outdir/02_reads_combined_lanes\", mode: 'copy', pattern: \"*.fastq*\"\n\n  if (params.num_forks) {\n    maxForks params.num_forks\n  }\n\n  when:\n    params.combine_read_files\n\n  input:\n    tuple val(prefix), path(reads_single)\n\n  output:\n    tuple val(prefix), path(\"*single.fastq*\"), emit: combined_lane_single_reads_ch\n\n  script:\n    \"\"\"\n    first_file=\\$(echo $reads_single | cut -d' ' -f1)\n    echo \\$first_file\n\n    if [[ \\$first_file = *.gz ]]\n      then \n        cat $reads_single > ${prefix}_combinedLanes_single.fastq.gz\n    fi\n\n    if [[ \\$first_file = *.fq ]] || [[ \\$first_file = *.fastq ]]\n      then \n        cat $reads_single > ${prefix}_combinedLanes_single.fastq\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n    first_file=\\$(echo $reads_single | cut -d' ' -f1)\n    echo \\$first_file\n\n    if [[ \\$first_file = *.gz ]]\n      then \n        cat $reads_single > ${prefix}_combinedLanes_single.fastq.gz\n    fi\n\n    if [[ \\$first_file = *.fq ]] || [[ \\$first_file = *.fastq ]]\n      then \n        cat $reads_single > ${prefix}_combinedLanes_single.fastq\n    fi\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "reads_single"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"$params.outdir/02_reads_combined_lanes\", mode: 'copy', pattern: \"*.fastq*\" if (params.num_forks) { maxForks params.num_forks }"
        ],
        "when": "params.combine_read_files",
        "stub": ""
    },
    "TRIMMOMATIC_PAIRED": {
        "name_process": "TRIMMOMATIC_PAIRED",
        "string_process": "\nprocess TRIMMOMATIC_PAIRED {\n    \n                                                                                         \n    \n\n              \n  label 'in_container'\n  publishDir \"$params.outdir/03a_trimmomatic_logs\", mode: 'copy', pattern: \"*.log\"\n  publishDir \"$params.outdir/03b_trimmomatic_paired_and_single_reads\", mode: 'copy', pattern: \"*_paired.fq*\"\n  publishDir \"$params.outdir/03b_trimmomatic_paired_and_single_reads\", mode: 'copy', pattern: \"*_R1-R2_unpaired.fq*\"\n\n\n  if (params.num_forks) {\n    maxForks params.num_forks\n  }\n\n  when:\n    params.use_trimmomatic\n\n  input:\n    tuple val(prefix), path(reads_R1), path(reads_R2)\n\n  output:\n    path(\"*\")\n    tuple val(prefix), path(\"*R1_paired*\"), path(\"*R2_paired*\"), path(\"*R1-R2_unpaired*\"), emit: trimmed_paired_and_orphaned_ch\n\n  script:\n    read_pairs_pattern_list = params.read_pairs_pattern?.tokenize(',')\n\n    \"\"\"\n    R1=${reads_R1}\n    R2=${reads_R2}\n    sampleID_R1=\\${R1%_${read_pairs_pattern_list[0]}*}\n    sampleID_R2=\\${R2%_${read_pairs_pattern_list[1]}*}\n\n    echo \\$R1\n    echo \\$R2\n\n    if [[ \\$R1 = *.gz ]]\n      then \n        R1_filename_strip_gz=\"\\${R1%.gz}\"\n        fastq_extension=\"\\${R1_filename_strip_gz##*.}\"\n\n        output_forward_paired=\\${sampleID_R1}_R1_paired.fq.gz\n        output_reverse_paired=\\${sampleID_R2}_R2_paired.fq.gz\n        output_forward_unpaired=\\${sampleID_R1}_R1_unpaired.fq.gz\n        output_reverse_unpaired=\\${sampleID_R2}_R2_unpaired.fq.gz\n        output_both_unpaired=\\${sampleID_R1}_R1-R2_unpaired.fq.gz\n\n      else\n        fastq_extension=\"\\${R1##*.}\"\n\n        output_forward_paired=\\${sampleID_R1}_R1_paired.fq\n        output_reverse_paired=\\${sampleID_R2}_R2_paired.fq\n        output_forward_unpaired=\\${sampleID_R1}_R1_unpaired.fq\n        output_reverse_unpaired=\\${sampleID_R2}_R2_unpaired.fq\n        output_both_unpaired=\\${sampleID_R1}_R1-R2_unpaired.fq\n    fi\n\n    # Write adapters fasta file:\n    echo -e \">PrefixPE/1\\nTACACTCTTTCCCTACACGACGCTCTTCCGATCT\\n>PrefixPE/2\\nGTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\\n>PE1\\nTACACTCTTTCCCTACACGACGCTCTTCCGATCT\\n>PE1_rc\\nAGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA\\n>PE2\\nGTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\\n>PE2_rc\\nAGATCGGAAGAGCACACGTCTGAACTCCAGTCA\" > TruSeq3-PE-2.fa\n\n    # Run Trimmomtic:\n    trimmomatic PE -phred33 -threads ${task.cpus} \\\n    ${reads_R1} ${reads_R2} \\${output_forward_paired} \\${output_forward_unpaired} \\\n    \\${output_reverse_paired} \\${output_reverse_unpaired} \\\n    ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:1:true \\\n    LEADING:${params.trimmomatic_leading_quality} \\\n    TRAILING:${params.trimmomatic_trailing_quality} \\\n    SLIDINGWINDOW:${params.trimmomatic_sliding_window_size}:${params.trimmomatic_sliding_window_quality} \\\n    MINLEN:${params.trimmomatic_min_length} 2>&1 | tee \\${sampleID_R1}.log \n    cat \\${output_forward_unpaired} \\${output_reverse_unpaired} > \\${output_both_unpaired}\n    \"\"\"\n}",
        "nb_lignes_process": 73,
        "string_script": "    read_pairs_pattern_list = params.read_pairs_pattern?.tokenize(',')\n\n    \"\"\"\n    R1=${reads_R1}\n    R2=${reads_R2}\n    sampleID_R1=\\${R1%_${read_pairs_pattern_list[0]}*}\n    sampleID_R2=\\${R2%_${read_pairs_pattern_list[1]}*}\n\n    echo \\$R1\n    echo \\$R2\n\n    if [[ \\$R1 = *.gz ]]\n      then \n        R1_filename_strip_gz=\"\\${R1%.gz}\"\n        fastq_extension=\"\\${R1_filename_strip_gz##*.}\"\n\n        output_forward_paired=\\${sampleID_R1}_R1_paired.fq.gz\n        output_reverse_paired=\\${sampleID_R2}_R2_paired.fq.gz\n        output_forward_unpaired=\\${sampleID_R1}_R1_unpaired.fq.gz\n        output_reverse_unpaired=\\${sampleID_R2}_R2_unpaired.fq.gz\n        output_both_unpaired=\\${sampleID_R1}_R1-R2_unpaired.fq.gz\n\n      else\n        fastq_extension=\"\\${R1##*.}\"\n\n        output_forward_paired=\\${sampleID_R1}_R1_paired.fq\n        output_reverse_paired=\\${sampleID_R2}_R2_paired.fq\n        output_forward_unpaired=\\${sampleID_R1}_R1_unpaired.fq\n        output_reverse_unpaired=\\${sampleID_R2}_R2_unpaired.fq\n        output_both_unpaired=\\${sampleID_R1}_R1-R2_unpaired.fq\n    fi\n\n    # Write adapters fasta file:\n    echo -e \">PrefixPE/1\\nTACACTCTTTCCCTACACGACGCTCTTCCGATCT\\n>PrefixPE/2\\nGTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\\n>PE1\\nTACACTCTTTCCCTACACGACGCTCTTCCGATCT\\n>PE1_rc\\nAGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA\\n>PE2\\nGTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT\\n>PE2_rc\\nAGATCGGAAGAGCACACGTCTGAACTCCAGTCA\" > TruSeq3-PE-2.fa\n\n    # Run Trimmomtic:\n    trimmomatic PE -phred33 -threads ${task.cpus} \\\n    ${reads_R1} ${reads_R2} \\${output_forward_paired} \\${output_forward_unpaired} \\\n    \\${output_reverse_paired} \\${output_reverse_unpaired} \\\n    ILLUMINACLIP:TruSeq3-PE-2.fa:2:30:10:1:true \\\n    LEADING:${params.trimmomatic_leading_quality} \\\n    TRAILING:${params.trimmomatic_trailing_quality} \\\n    SLIDINGWINDOW:${params.trimmomatic_sliding_window_size}:${params.trimmomatic_sliding_window_quality} \\\n    MINLEN:${params.trimmomatic_min_length} 2>&1 | tee \\${sampleID_R1}.log \n    cat \\${output_forward_unpaired} \\${output_reverse_unpaired} > \\${output_both_unpaired}\n    \"\"\"",
        "nb_lignes_script": 45,
        "language_script": "bash",
        "tools": [
            "Trimmomatic"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            }
        ],
        "inputs": [
            "prefix",
            "reads_R1",
            "reads_R2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"$params.outdir/03a_trimmomatic_logs\", mode: 'copy', pattern: \"*.log\"",
            "publishDir \"$params.outdir/03b_trimmomatic_paired_and_single_reads\", mode: 'copy', pattern: \"*_paired.fq*\"",
            "publishDir \"$params.outdir/03b_trimmomatic_paired_and_single_reads\", mode: 'copy', pattern: \"*_R1-R2_unpaired.fq*\" if (params.num_forks) { maxForks params.num_forks }"
        ],
        "when": "params.use_trimmomatic",
        "stub": ""
    },
    "TRIMMOMATIC_SINGLE": {
        "name_process": "TRIMMOMATIC_SINGLE",
        "string_process": "\nprocess TRIMMOMATIC_SINGLE {\n    \n                                                                                         \n    \n\n              \n  label 'in_container'\n  publishDir \"$params.outdir/03a_trimmomatic_logs\", mode: 'copy', pattern: \"*.log\"\n  publishDir \"$params.outdir/03c_trimmomatic_single_reads\", mode: 'copy', pattern: \"*_single*\"\n\n  if (params.num_forks) {\n    maxForks params.num_forks\n  }\n\n  when:\n    params.use_trimmomatic\n\n  input:\n    tuple val(prefix), path(reads_single)\n\n  output:\n    path(\"*\")\n    tuple val(prefix), file(\"*single*\"), emit: trimmed_single_ch\n\n  script:\n    \"\"\"\n    single=${reads_single}\n\n\n    if [[ \\$single = *.gz ]]\n      then \n        output_single=${prefix}_trimmed_single.fq.gz\n      else\n        output_single=${prefix}_trimmed_single.fq\n    fi\n\n    echo -e \">TruSeq3_IndexedAdapter\\nAGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\\n>TruSeq3_UniversalAdapter\\nAGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA\\n\" > TruSeq3-SE.fa\n    trimmomatic SE -phred33 -threads ${task.cpus} \\\n    ${reads_single} \\${output_single} ILLUMINACLIP:TruSeq3-SE.fa:2:30:10:1:true \\\n    LEADING:${params.trimmomatic_leading_quality} \\\n    TRAILING:${params.trimmomatic_trailing_quality} \\\n    SLIDINGWINDOW:${params.trimmomatic_sliding_window_size}:${params.trimmomatic_sliding_window_quality} \\\n    MINLEN:${params.trimmomatic_min_length} 2>&1 | tee ${prefix}.log \n    \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "    \"\"\"\n    single=${reads_single}\n\n\n    if [[ \\$single = *.gz ]]\n      then \n        output_single=${prefix}_trimmed_single.fq.gz\n      else\n        output_single=${prefix}_trimmed_single.fq\n    fi\n\n    echo -e \">TruSeq3_IndexedAdapter\\nAGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\\n>TruSeq3_UniversalAdapter\\nAGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA\\n\" > TruSeq3-SE.fa\n    trimmomatic SE -phred33 -threads ${task.cpus} \\\n    ${reads_single} \\${output_single} ILLUMINACLIP:TruSeq3-SE.fa:2:30:10:1:true \\\n    LEADING:${params.trimmomatic_leading_quality} \\\n    TRAILING:${params.trimmomatic_trailing_quality} \\\n    SLIDINGWINDOW:${params.trimmomatic_sliding_window_size}:${params.trimmomatic_sliding_window_quality} \\\n    MINLEN:${params.trimmomatic_min_length} 2>&1 | tee ${prefix}.log \n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "Trimmomatic"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            }
        ],
        "inputs": [
            "prefix",
            "reads_single"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"$params.outdir/03a_trimmomatic_logs\", mode: 'copy', pattern: \"*.log\"",
            "publishDir \"$params.outdir/03c_trimmomatic_single_reads\", mode: 'copy', pattern: \"*_single*\" if (params.num_forks) { maxForks params.num_forks }"
        ],
        "when": "params.use_trimmomatic",
        "stub": ""
    },
    "READS_FIRST_SINGLE_END": {
        "name_process": "READS_FIRST_SINGLE_END",
        "string_process": "\nprocess READS_FIRST_SINGLE_END {\n    \n                                                  \n    \n\n              \n  label 'in_container'\n  publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${prefix}/${prefix}_genes_with_supercontigs.csv\"\n  publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${prefix}/${prefix}_supercontigs_with_discordant_reads.csv\"\n\n  if (params.num_forks) {\n    maxForks params.num_forks\n  }\n\n  when:\n    params.single_end\n\n  input:\n    path(target_file)\n    tuple val(prefix), path(reads_single)\n\n  output:\n    path(\"${prefix}\"), emit: reads_first_with_single_end_ch optional true\n    path(\"${prefix}/${prefix}_genes_with_supercontigs.csv\") optional true\n    path(\"${prefix}/${prefix}_supercontigs_with_discordant_reads.csv\") optional true\n\n  script:\n    def command_list = []\n\n    if (params.nosupercontigs) {\n      command_list << \"--nosupercontigs\"\n      }\n    if (params.memory) {\n      command_list << \"--memory ${params.memory}\"\n      }\n    if (params.discordant_reads_edit_distance) {\n      command_list << \"--discordant_reads_edit_distance ${params.discordant_reads_edit_distance}\"\n      }\n    if (params.discordant_reads_cutoff) {\n      command_list << \"--discordant_reads_cutoff ${params.discordant_reads_cutoff}\"\n      } \n    if (params.merged) {\n      command_list << \"--merged\"\n      }\n    if (!params.use_blastx && !params.translate_target_file_for_blastx) {\n      command_list << \"--bwa\"\n    }\n    if (params.blastx_evalue) {\n      command_list << \"--evalue ${params.blastx_evalue}\"\n    }\n    if (params.paralog_warning_min_len_percent) {\n      command_list << \"--paralog_warning_min_length_percentage ${params.paralog_warning_min_len_percent}\"\n    }\n    if (params.cov_cutoff) {\n      command_list << \"--cov_cutoff ${params.cov_cutoff}\"\n    }\n    if (params.cleanup) {\n      cleanup = \"python /HybPiper/cleanup.py ${prefix}\"\n    } else {\n      cleanup = ''\n    }\n    reads_first_command = \"python /HybPiper/reads_first.py -b ${target_file} -r ${reads_single} --prefix ${prefix} --cpu ${task.cpus} \" + command_list.join(' ')\n\n    \"\"\"\n    echo ${reads_first_command}\n    ${reads_first_command}\n    ${cleanup}\n    \"\"\"\n}",
        "nb_lignes_process": 68,
        "string_script": "    def command_list = []\n\n    if (params.nosupercontigs) {\n      command_list << \"--nosupercontigs\"\n      }\n    if (params.memory) {\n      command_list << \"--memory ${params.memory}\"\n      }\n    if (params.discordant_reads_edit_distance) {\n      command_list << \"--discordant_reads_edit_distance ${params.discordant_reads_edit_distance}\"\n      }\n    if (params.discordant_reads_cutoff) {\n      command_list << \"--discordant_reads_cutoff ${params.discordant_reads_cutoff}\"\n      } \n    if (params.merged) {\n      command_list << \"--merged\"\n      }\n    if (!params.use_blastx && !params.translate_target_file_for_blastx) {\n      command_list << \"--bwa\"\n    }\n    if (params.blastx_evalue) {\n      command_list << \"--evalue ${params.blastx_evalue}\"\n    }\n    if (params.paralog_warning_min_len_percent) {\n      command_list << \"--paralog_warning_min_length_percentage ${params.paralog_warning_min_len_percent}\"\n    }\n    if (params.cov_cutoff) {\n      command_list << \"--cov_cutoff ${params.cov_cutoff}\"\n    }\n    if (params.cleanup) {\n      cleanup = \"python /HybPiper/cleanup.py ${prefix}\"\n    } else {\n      cleanup = ''\n    }\n    reads_first_command = \"python /HybPiper/reads_first.py -b ${target_file} -r ${reads_single} --prefix ${prefix} --cpu ${task.cpus} \" + command_list.join(' ')\n\n    \"\"\"\n    echo ${reads_first_command}\n    ${reads_first_command}\n    ${cleanup}\n    \"\"\"",
        "nb_lignes_script": 40,
        "language_script": "bash",
        "tools": [
            "rMSIcleanup"
        ],
        "tools_url": [
            "https://bio.tools/rMSIcleanup"
        ],
        "tools_dico": [
            {
                "name": "rMSIcleanup",
                "uri": "https://bio.tools/rMSIcleanup",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3382",
                            "term": "Imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3553",
                                    "term": "Image annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "PCA plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak assignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak finding"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An open-source tool for matrix-related peak annotation in mass spectrometry imaging and its application to silver-assisted laser desorption/ionization.\n\nAutomated annotation of matrix-related signals in MSI.\n\nrMSIcleanup is an open-source R package to annotate matrix-related signals in MSI data. The algorithm takes into account the chemical formula and the spatial distribution to determine which ions are matrix-related. The algorithm incorporates an overlapping peak detection feature to prevent misclassification of overlapped or isobaric ions. Additionally, the package generates a visual report to transparently justify each annotation",
                "homepage": "https://github.com/gbaquer/rMSIcleanup"
            }
        ],
        "inputs": [
            "target_file",
            "prefix",
            "reads_single"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${prefix}/${prefix}_genes_with_supercontigs.csv\"",
            "publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${prefix}/${prefix}_supercontigs_with_discordant_reads.csv\" if (params.num_forks) { maxForks params.num_forks }"
        ],
        "when": "params.single_end",
        "stub": ""
    },
    "READS_FIRST_PAIRED_AND_SINGLE_END": {
        "name_process": "READS_FIRST_PAIRED_AND_SINGLE_END",
        "string_process": "\nprocess READS_FIRST_PAIRED_AND_SINGLE_END {\n    \n                                                              \n    \n\n             \n  label 'in_container'\n  publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_genes_with_supercontigs.csv\"\n  publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_supercontigs_with_discordant_reads.csv\"\n\n  if (params.num_forks) {\n    maxForks params.num_forks\n  }\n\n  when:\n    (params.use_trimmomatic || params.paired_and_single)\n\n  input:\n    path(target_file) \n    tuple val(pair_id), path(reads_R1), path(reads_R2), path(reads_unpaired)\n\n  output:\n    path(\"${pair_id}\"), emit: reads_first_with_unPaired_ch optional true\n    path(\"${pair_id}/${pair_id}_genes_with_supercontigs.csv\") optional true\n    path(\"${pair_id}/${pair_id}_supercontigs_with_discordant_reads.csv\") optional true\n\n  script:\n    def command_list = []\n\n    if (params.nosupercontigs) {\n      command_list << \"--nosupercontigs\"\n      }\n    if (params.memory) {\n      command_list << \"--memory ${params.memory}\"\n      }\n    if (params.bbmap_subfilter) {\n      command_list << \"--bbmap_subfilter ${params.bbmap_subfilter}\"\n      }\n    if (params.discordant_reads_edit_distance) {\n      command_list << \"--discordant_reads_edit_distance ${params.discordant_reads_edit_distance}\"\n      }\n    if (params.discordant_reads_cutoff) {\n      command_list << \"--discordant_reads_cutoff ${params.discordant_reads_cutoff}\"\n      } \n    if (params.merged) {\n      command_list << \"--merged\"\n      }\n    if (!params.use_blastx && !params.translate_target_file_for_blastx) {\n      command_list << \"--bwa\"\n    }\n    if (params.blastx_evalue) {\n      command_list << \"--evalue ${params.blastx_evalue}\"\n    }\n    if (params.paralog_warning_min_len_percent) {\n      command_list << \"--paralog_warning_min_length_percentage ${params.paralog_warning_min_len_percent}\"\n    }\n    if (params.cov_cutoff) {\n      command_list << \"--cov_cutoff ${params.cov_cutoff}\"\n    }\n    if (params.cleanup) {\n      cleanup = \"python /HybPiper/cleanup.py ${pair_id}\"\n    } else {\n      cleanup = ''\n    }\n    reads_first_command = \"python /HybPiper/reads_first.py -b ${target_file} -r ${reads_R1} ${reads_R2} --unpaired ${reads_unpaired} --prefix ${pair_id} --cpu ${task.cpus} \" + command_list.join(' ')\n\n    script:\n    \"\"\"\n    echo ${reads_first_command}\n    ${reads_first_command}\n    ${cleanup}\n    \"\"\"\n  }",
        "nb_lignes_process": 72,
        "string_script": "    def command_list = []\n\n    if (params.nosupercontigs) {\n      command_list << \"--nosupercontigs\"\n      }\n    if (params.memory) {\n      command_list << \"--memory ${params.memory}\"\n      }\n    if (params.bbmap_subfilter) {\n      command_list << \"--bbmap_subfilter ${params.bbmap_subfilter}\"\n      }\n    if (params.discordant_reads_edit_distance) {\n      command_list << \"--discordant_reads_edit_distance ${params.discordant_reads_edit_distance}\"\n      }\n    if (params.discordant_reads_cutoff) {\n      command_list << \"--discordant_reads_cutoff ${params.discordant_reads_cutoff}\"\n      } \n    if (params.merged) {\n      command_list << \"--merged\"\n      }\n    if (!params.use_blastx && !params.translate_target_file_for_blastx) {\n      command_list << \"--bwa\"\n    }\n    if (params.blastx_evalue) {\n      command_list << \"--evalue ${params.blastx_evalue}\"\n    }\n    if (params.paralog_warning_min_len_percent) {\n      command_list << \"--paralog_warning_min_length_percentage ${params.paralog_warning_min_len_percent}\"\n    }\n    if (params.cov_cutoff) {\n      command_list << \"--cov_cutoff ${params.cov_cutoff}\"\n    }\n    if (params.cleanup) {\n      cleanup = \"python /HybPiper/cleanup.py ${pair_id}\"\n    } else {\n      cleanup = ''\n    }\n    reads_first_command = \"python /HybPiper/reads_first.py -b ${target_file} -r ${reads_R1} ${reads_R2} --unpaired ${reads_unpaired} --prefix ${pair_id} --cpu ${task.cpus} \" + command_list.join(' ')\n\n    script:\n    \"\"\"\n    echo ${reads_first_command}\n    ${reads_first_command}\n    ${cleanup}\n    \"\"\"",
        "nb_lignes_script": 44,
        "language_script": "bash",
        "tools": [
            "rMSIcleanup"
        ],
        "tools_url": [
            "https://bio.tools/rMSIcleanup"
        ],
        "tools_dico": [
            {
                "name": "rMSIcleanup",
                "uri": "https://bio.tools/rMSIcleanup",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3382",
                            "term": "Imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3553",
                                    "term": "Image annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "PCA plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak assignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak finding"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An open-source tool for matrix-related peak annotation in mass spectrometry imaging and its application to silver-assisted laser desorption/ionization.\n\nAutomated annotation of matrix-related signals in MSI.\n\nrMSIcleanup is an open-source R package to annotate matrix-related signals in MSI data. The algorithm takes into account the chemical formula and the spatial distribution to determine which ions are matrix-related. The algorithm incorporates an overlapping peak detection feature to prevent misclassification of overlapped or isobaric ions. Additionally, the package generates a visual report to transparently justify each annotation",
                "homepage": "https://github.com/gbaquer/rMSIcleanup"
            }
        ],
        "inputs": [
            "target_file",
            "pair_id",
            "reads_R1",
            "reads_R2",
            "reads_unpaired"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_genes_with_supercontigs.csv\"",
            "publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_supercontigs_with_discordant_reads.csv\" if (params.num_forks) {",
            "maxForks params.num_forks }"
        ],
        "when": "(params.use_trimmomatic || params.paired_and_single)",
        "stub": ""
    },
    "READS_FIRST_PAIRED_END": {
        "name_process": "READS_FIRST_PAIRED_END",
        "string_process": "\nprocess READS_FIRST_PAIRED_END {\n    \n                                              \n    \n\n              \n  label 'in_container'\n  publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_genes_with_supercontigs.csv\"\n  publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_supercontigs_with_discordant_reads.csv\"\n\n  if (params.num_forks) {\n    maxForks params.num_forks\n  }\n\n  when:\n    (!params.paired_and_single && !params.single_end && !params.use_trimmomatic)\n\n  input:\n    path(target_file) \n    tuple val(pair_id), path(reads_R1), path(reads_R2)\n\n  output:\n    path(\"${pair_id}\"), emit: reads_first_ch optional true\n    path(\"${pair_id}/${pair_id}_genes_with_supercontigs.csv\") optional true\n    path(\"${pair_id}/${pair_id}_supercontigs_with_discordant_reads.csv\") optional true\n\n  script:\n    def command_list = []\n\n    if (params.nosupercontigs) {\n      command_list << \"--nosupercontigs\"\n      }\n    if (params.memory) {\n      command_list << \"--memory ${params.memory}\"\n      }\n    if (params.bbmap_subfilter) {\n      command_list << \"--bbmap_subfilter ${params.bbmap_subfilter}\"\n      }\n    if (params.discordant_reads_edit_distance) {\n      command_list << \"--discordant_reads_edit_distance ${params.discordant_reads_edit_distance}\"\n      }\n    if (params.discordant_reads_cutoff) {\n      command_list << \"--discordant_reads_cutoff ${params.discordant_reads_cutoff}\"\n      }\n    if (params.merged) {\n      command_list << \"--merged\"\n      }\n    if (!params.use_blastx && !params.translate_target_file_for_blastx) {\n      command_list << \"--bwa\"\n    }\n    if (params.blastx_evalue) {\n      command_list << \"--evalue ${params.blastx_evalue}\"\n    }\n    if (params.paralog_warning_min_len_percent) {\n      command_list << \"--paralog_warning_min_length_percentage ${params.paralog_warning_min_len_percent}\"\n    }\n    if (params.cov_cutoff) {\n      command_list << \"--cov_cutoff ${params.cov_cutoff}\"\n    }\n    if (params.cleanup) {\n      cleanup = \"python /HybPiper/cleanup.py ${pair_id}\"\n    } else {\n      cleanup = ''\n    }\n    reads_first_command = \"python /HybPiper/reads_first.py -b ${target_file} -r ${reads_R1} ${reads_R2} --prefix ${pair_id} --cpu ${task.cpus} \" + command_list.join(' ')\n\n\n    script:\n    \"\"\"\n    echo \"about to try command: ${reads_first_command}\"\n    ${reads_first_command}\n    ${cleanup}\n    \"\"\"\n}",
        "nb_lignes_process": 73,
        "string_script": "    def command_list = []\n\n    if (params.nosupercontigs) {\n      command_list << \"--nosupercontigs\"\n      }\n    if (params.memory) {\n      command_list << \"--memory ${params.memory}\"\n      }\n    if (params.bbmap_subfilter) {\n      command_list << \"--bbmap_subfilter ${params.bbmap_subfilter}\"\n      }\n    if (params.discordant_reads_edit_distance) {\n      command_list << \"--discordant_reads_edit_distance ${params.discordant_reads_edit_distance}\"\n      }\n    if (params.discordant_reads_cutoff) {\n      command_list << \"--discordant_reads_cutoff ${params.discordant_reads_cutoff}\"\n      }\n    if (params.merged) {\n      command_list << \"--merged\"\n      }\n    if (!params.use_blastx && !params.translate_target_file_for_blastx) {\n      command_list << \"--bwa\"\n    }\n    if (params.blastx_evalue) {\n      command_list << \"--evalue ${params.blastx_evalue}\"\n    }\n    if (params.paralog_warning_min_len_percent) {\n      command_list << \"--paralog_warning_min_length_percentage ${params.paralog_warning_min_len_percent}\"\n    }\n    if (params.cov_cutoff) {\n      command_list << \"--cov_cutoff ${params.cov_cutoff}\"\n    }\n    if (params.cleanup) {\n      cleanup = \"python /HybPiper/cleanup.py ${pair_id}\"\n    } else {\n      cleanup = ''\n    }\n    reads_first_command = \"python /HybPiper/reads_first.py -b ${target_file} -r ${reads_R1} ${reads_R2} --prefix ${pair_id} --cpu ${task.cpus} \" + command_list.join(' ')\n\n\n    script:\n    \"\"\"\n    echo \"about to try command: ${reads_first_command}\"\n    ${reads_first_command}\n    ${cleanup}\n    \"\"\"",
        "nb_lignes_script": 45,
        "language_script": "bash",
        "tools": [
            "rMSIcleanup"
        ],
        "tools_url": [
            "https://bio.tools/rMSIcleanup"
        ],
        "tools_dico": [
            {
                "name": "rMSIcleanup",
                "uri": "https://bio.tools/rMSIcleanup",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3382",
                            "term": "Imaging"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3172",
                            "term": "Metabolomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3553",
                                    "term": "Image annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "PCA plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak assignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3215",
                                    "term": "Peak finding"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "An open-source tool for matrix-related peak annotation in mass spectrometry imaging and its application to silver-assisted laser desorption/ionization.\n\nAutomated annotation of matrix-related signals in MSI.\n\nrMSIcleanup is an open-source R package to annotate matrix-related signals in MSI data. The algorithm takes into account the chemical formula and the spatial distribution to determine which ions are matrix-related. The algorithm incorporates an overlapping peak detection feature to prevent misclassification of overlapped or isobaric ions. Additionally, the package generates a visual report to transparently justify each annotation",
                "homepage": "https://github.com/gbaquer/rMSIcleanup"
            }
        ],
        "inputs": [
            "target_file",
            "pair_id",
            "reads_R1",
            "reads_R2"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_genes_with_supercontigs.csv\"",
            "publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy', pattern: \"${pair_id}/${pair_id}_supercontigs_with_discordant_reads.csv\" if (params.num_forks) {",
            "maxForks params.num_forks }"
        ],
        "when": "(!params.paired_and_single && !params.single_end && !params.use_trimmomatic)",
        "stub": ""
    },
    "VISUALISE": {
        "name_process": "VISUALISE",
        "string_process": "\nprocess VISUALISE {\n    \n                                   \n    \n\n              \n  label 'in_container'\n  publishDir \"${params.outdir}/05_visualise\", mode: 'copy'\n\n  input:\n    path(reads_first)\n    path(target_file)\n    path(namelist)\n\n  output:\n    path(\"seq_lengths.txt\"), emit: seq_lengths_ch\n    path(\"heatmap.png\")\n\n  script:\n    \"\"\"\n    python /HybPiper/get_seq_lengths.py ${target_file} ${namelist} dna > seq_lengths.txt\n    Rscript /HybPiper/gene_recovery_heatmap_ggplot.R\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    python /HybPiper/get_seq_lengths.py ${target_file} ${namelist} dna > seq_lengths.txt\n    Rscript /HybPiper/gene_recovery_heatmap_ggplot.R\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_first",
            "target_file",
            "namelist"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/05_visualise\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "SUMMARY_STATS": {
        "name_process": "SUMMARY_STATS",
        "string_process": "\nprocess SUMMARY_STATS {\n  \n                             \n  \n\n              \n  label 'in_container'\n  publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy'\n\n  input:\n    path(reads_first)\n    path(seq_lengths) \n    path(namelist)\n\n  output:\n    path(\"stats.txt\"), emit: stats_file\n\n  script:\n    if (params.translate_target_file_for_blastx || params.use_blastx) {\n    \"\"\"\n    python /HybPiper/hybpiper_stats.py ${seq_lengths} ${namelist} --blastx_adjustment > stats.txt\n    \"\"\"\n    } else {\n    \"\"\"\n    python /HybPiper/hybpiper_stats.py ${seq_lengths} ${namelist} > stats.txt\n    \"\"\"\n    } \n}",
        "nb_lignes_process": 27,
        "string_script": "    if (params.translate_target_file_for_blastx || params.use_blastx) {\n    \"\"\"\n    python /HybPiper/hybpiper_stats.py ${seq_lengths} ${namelist} --blastx_adjustment > stats.txt\n    \"\"\"\n    } else {\n    \"\"\"\n    python /HybPiper/hybpiper_stats.py ${seq_lengths} ${namelist} > stats.txt\n    \"\"\"\n    }",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_first",
            "seq_lengths",
            "namelist"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/06_summary_stats\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "INTRONERATE": {
        "name_process": "INTRONERATE",
        "string_process": "\nprocess INTRONERATE {\n    \n                            \n    \n\n              \n  label 'in_container'\n\n  input:\n    path(reads_first)\n\n  output:\n    path(reads_first), emit: intronerate_ch optional true\n\n  script:\n    \"\"\"\n    echo ${reads_first}\n    python /HybPiper/intronerate.py --prefix ${reads_first}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    echo ${reads_first}\n    python /HybPiper/intronerate.py --prefix ${reads_first}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_first"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'"
        ],
        "when": "",
        "stub": ""
    },
    "PARALOGS": {
        "name_process": "PARALOGS",
        "string_process": "\nprocess PARALOGS {\n    \n                                     \n    \n\n             \n  label 'in_container'\n  publishDir \"${params.outdir}/04_processed_gene_directories\", mode: 'copy'\n\n  if (params.num_forks) {\n      maxForks params.num_forks\n  }\n\n  input:\n    path(intronerate_complete) \n\n  output:\n    path(intronerate_complete), emit: paralogs_ch optional true \n\n  script:\n    \"\"\"\n    python /HybPiper/paralog_investigator.py ${intronerate_complete}\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    python /HybPiper/paralog_investigator.py ${intronerate_complete}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "intronerate_complete"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/04_processed_gene_directories\", mode: 'copy' if (params.num_forks) { maxForks params.num_forks }"
        ],
        "when": "",
        "stub": ""
    },
    "RETRIEVE_SEQUENCES": {
        "name_process": "RETRIEVE_SEQUENCES",
        "string_process": "\nprocess RETRIEVE_SEQUENCES {\n    \n                                                              \n    \n\n              \n  label 'in_container'\n  publishDir \"${params.outdir}/07_sequences_dna\", mode: 'copy', pattern: \"*.FNA\"\n  publishDir \"${params.outdir}/08_sequences_aa\", mode: 'copy', pattern: \"*.FAA\"\n  publishDir \"${params.outdir}/09_sequences_intron\", mode: 'copy', pattern: \"*introns.fasta\"\n  publishDir \"${params.outdir}/10_sequences_supercontig\", mode: 'copy', pattern: \"*supercontig.fasta\"\n\n  input:\n    path(paralog_complete)\n    path(target_file)\n\n\n  output:\n    path(\"*.FNA\")\n    path(\"*.FAA\")\n    path(\"*.fasta\")\n\n  script:\n    \"\"\"\n    python /HybPiper/retrieve_sequences.py ${target_file} . dna\n    python /HybPiper/retrieve_sequences.py ${target_file} . aa\n    python /HybPiper/retrieve_sequences.py ${target_file} . intron\n    python /HybPiper/retrieve_sequences.py ${target_file} . supercontig\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    \"\"\"\n    python /HybPiper/retrieve_sequences.py ${target_file} . dna\n    python /HybPiper/retrieve_sequences.py ${target_file} . aa\n    python /HybPiper/retrieve_sequences.py ${target_file} . intron\n    python /HybPiper/retrieve_sequences.py ${target_file} . supercontig\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "paralog_complete",
            "target_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/07_sequences_dna\", mode: 'copy', pattern: \"*.FNA\"",
            "publishDir \"${params.outdir}/08_sequences_aa\", mode: 'copy', pattern: \"*.FAA\"",
            "publishDir \"${params.outdir}/09_sequences_intron\", mode: 'copy', pattern: \"*introns.fasta\"",
            "publishDir \"${params.outdir}/10_sequences_supercontig\", mode: 'copy', pattern: \"*supercontig.fasta\""
        ],
        "when": "",
        "stub": ""
    },
    "PARALOG_RETRIEVER": {
        "name_process": "PARALOG_RETRIEVER",
        "string_process": "\nprocess PARALOG_RETRIEVER {\n    \n                                  \n    \n\n             \n  label 'in_container'\n  publishDir \"${params.outdir}/11_paralogs\", mode: 'copy', pattern: \"*.paralogs.fasta\"\n  publishDir \"${params.outdir}/12_paralogs_noChimeras\", mode: 'copy', pattern: \"*.paralogs_noChimeras.fasta\"\n  publishDir \"${params.outdir}/12_paralogs_noChimeras/logs\", mode: 'copy', pattern: \"*mylog*\"\n\n  input:\n    path(paralog_complete_list)\n    path(namelist)\n    val(gene_list)\n\n\n  output:\n    path(\"*.fasta\")\n    path(\"*.mylog*\")  \n\n  script:\n    assert (gene_list in List)\n    list_of_names = gene_list.join(' ') // Note that this is necessary so that the list isn't of the form [4471, 4527, etc]\n    \"\"\"\n    for gene_name in ${list_of_names}\n    do\n      python /HybPiper/paralog_retriever.py ${namelist} \\${gene_name} > \\${gene_name}.paralogs_noChimeras.fasta 2> \\${gene_name}.paralogs.fasta\n    done\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    assert (gene_list in List)\n    list_of_names = gene_list.join(' ') // Note that this is necessary so that the list isn't of the form [4471, 4527, etc]\n    \"\"\"\n    for gene_name in ${list_of_names}\n    do\n      python /HybPiper/paralog_retriever.py ${namelist} \\${gene_name} > \\${gene_name}.paralogs_noChimeras.fasta 2> \\${gene_name}.paralogs.fasta\n    done\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "GPU-CASSERT"
        ],
        "tools_url": [
            "https://bio.tools/gpu-cassert"
        ],
        "tools_dico": [
            {
                "name": "GPU-CASSERT",
                "uri": "https://bio.tools/gpu-cassert",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_1317",
                            "term": "Structural biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0295",
                                    "term": "Structure alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0295",
                                    "term": "Structural alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The GPU-based implementation of the CASSERT algorithm for protein 3D structure similarity searching. The algorithm is based on the two-phase alignment of protein structures when matching fragments of compared proteins.",
                "homepage": "http://zti.polsl.pl/dmrozek/science/gpucassert/cassert.htm"
            }
        ],
        "inputs": [
            "paralog_complete_list",
            "namelist",
            "gene_list"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "label 'in_container'",
            "publishDir \"${params.outdir}/11_paralogs\", mode: 'copy', pattern: \"*.paralogs.fasta\"",
            "publishDir \"${params.outdir}/12_paralogs_noChimeras\", mode: 'copy', pattern: \"*.paralogs_noChimeras.fasta\"",
            "publishDir \"${params.outdir}/12_paralogs_noChimeras/logs\", mode: 'copy', pattern: \"*mylog*\""
        ],
        "when": "",
        "stub": ""
    },
    "LUCY_PROCESS": {
        "name_process": "LUCY_PROCESS",
        "string_process": "\nprocess LUCY_PROCESS {\n    \n        \n    \n\n  echo true\n  label 'in_container'\n  publishDir \"${params.outdir}/lucy_beagle_folder\", mode: 'copy'\n\n\n  input:\n    tuple val(prefix), path(reads_R1), path(reads_R2)\n\n  output:\n    path \"${reads_R1}\", emit: lucy_ch\n\n\n  script:\n    \"\"\"\n    echo ${reads_R1}\n\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    echo ${reads_R1}\n\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "reads_R1",
            "reads_R2"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "chrisjackson-pellicle__HybPiper-RBGV",
        "directive": [
            "echo true",
            "label 'in_container'",
            "publishDir \"${params.outdir}/lucy_beagle_folder\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    }
}