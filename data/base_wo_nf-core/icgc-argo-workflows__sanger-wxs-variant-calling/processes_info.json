{
    "payloadGenVariantCalling": {
        "name_process": "payloadGenVariantCalling",
        "string_process": "\nprocess payloadGenVariantCalling {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: \"${params.publish_dir ? true : ''}\"\n\n  input:\n    path normal_analysis\n    path tumour_analysis\n    path files_to_upload\n    val wf_name\n    val wf_short_name\n    val wf_version\n\n  output:\n    path \"*.payload.json\", emit: payload\n    path \"out/*{.tgz,.vcf.gz,.vcf.gz.tbi}\", emit: files_to_upload\n\n  script:\n    args_tumour_analysis = !tumour_analysis.empty() ? \"-t ${tumour_analysis}\" : \"\"\n    \"\"\"\n    main.py \\\n         -f ${files_to_upload} \\\n         -n ${normal_analysis} \\\n         -r ${workflow.runName} \\\n         -j ${workflow.sessionId} \\\n         -w ${wf_name} \\\n         -s ${wf_short_name} \\\n         -v ${wf_version} ${args_tumour_analysis}\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    args_tumour_analysis = !tumour_analysis.empty() ? \"-t ${tumour_analysis}\" : \"\"\n    \"\"\"\n    main.py \\\n         -f ${files_to_upload} \\\n         -n ${normal_analysis} \\\n         -r ${workflow.runName} \\\n         -j ${workflow.sessionId} \\\n         -w ${wf_name} \\\n         -s ${wf_short_name} \\\n         -v ${wf_version} ${args_tumour_analysis}\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "normal_analysis",
            "tumour_analysis",
            "files_to_upload",
            "wf_name",
            "wf_short_name",
            "wf_version"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: \"${params.publish_dir ? true : ''}\""
        ],
        "when": "",
        "stub": ""
    },
    "songGetAnalysis": {
        "name_process": "songGetAnalysis",
        "string_process": "\nprocess songGetAnalysis {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/song-client:${params.container_version}\"\n    publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n    tag \"${analysis_id}\"\n\n    input:\n        val study_id\n        val analysis_id\n\n    output:\n        path \"*.analysis.json\", emit: json\n\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing search -a ${analysis_id} > ${analysis_id}.analysis.json\n        \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing search -a ${analysis_id} > ${analysis_id}.analysis.json\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Nursing"
        ],
        "tools_url": [
            "https://bio.tools/Nursing"
        ],
        "tools_dico": [
            {
                "name": "Nursing",
                "uri": "https://bio.tools/Nursing",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Medical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Critical care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Medicines research and development"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Biomedical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Healthcare informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health and disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Clinical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Acute medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Emergency medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Intensive care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Drug discovery and development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The use and abuse of credentials.\n\nA Guide to Nursing Credentials and Degrees.\n\nComplete List of Common Nursing Certifications.\n\nFrom LPN to MSN, the jumble of letters following a nurse's name can be confusing. Learn what these nursing credentials mean and how they should be listed.\n\nView 183 commonly recognized nursing certifications along with links to their certifying organizations.\n\nThe confusing nature of nursing credentials has led to widespread use of the term \u201calphabet soup.\u201d The letters that follow a nurse\u2019s name can be perplexing to professionals in the medical field, and especially to patients and families. To solve this problem, nursing credentials need to be displayed properly.\n\nNever fear. Nurse.org has compiled an alphabetical list of 183 different nursing certifications along with the appropriate acronyms and links to their certifying organizations",
                "homepage": "https://online.alvernia.edu/program-resources/nursing-credentials/"
            }
        ],
        "inputs": [
            "study_id",
            "analysis_id"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/song-client:${params.container_version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "tag \"${analysis_id}\""
        ],
        "when": "",
        "stub": ""
    },
    "songSubmit": {
        "name_process": "songSubmit",
        "string_process": "\nprocess songSubmit {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/song-client:${params.container_version}\"\n    \n    tag \"${study_id}\"\n    label \"songSubmit\"\n    \n    input:\n        val study_id\n        path payload\n    \n    output:\n        stdout()\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        set -euxo pipefail\n        sing submit -f ${payload} | jq -er .analysisId | tr -d '\\\\n'\n        \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        set -euxo pipefail\n        sing submit -f ${payload} | jq -er .analysisId | tr -d '\\\\n'\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "Nursing"
        ],
        "tools_url": [
            "https://bio.tools/Nursing"
        ],
        "tools_dico": [
            {
                "name": "Nursing",
                "uri": "https://bio.tools/Nursing",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Medical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Critical care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Medicines research and development"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Biomedical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Healthcare informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health and disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Clinical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Acute medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Emergency medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Intensive care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Drug discovery and development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The use and abuse of credentials.\n\nA Guide to Nursing Credentials and Degrees.\n\nComplete List of Common Nursing Certifications.\n\nFrom LPN to MSN, the jumble of letters following a nurse's name can be confusing. Learn what these nursing credentials mean and how they should be listed.\n\nView 183 commonly recognized nursing certifications along with links to their certifying organizations.\n\nThe confusing nature of nursing credentials has led to widespread use of the term \u201calphabet soup.\u201d The letters that follow a nurse\u2019s name can be perplexing to professionals in the medical field, and especially to patients and families. To solve this problem, nursing credentials need to be displayed properly.\n\nNever fear. Nurse.org has compiled an alphabetical list of 183 different nursing certifications along with the appropriate acronyms and links to their certifying organizations",
                "homepage": "https://online.alvernia.edu/program-resources/nursing-credentials/"
            }
        ],
        "inputs": [
            "study_id",
            "payload"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/song-client:${params.container_version}\"",
            "tag \"${study_id}\"",
            "label \"songSubmit\""
        ],
        "when": "",
        "stub": ""
    },
    "extractFilesFromTarball": {
        "name_process": "extractFilesFromTarball",
        "string_process": "\nprocess extractFilesFromTarball {\n  container 'ubuntu:18.04'\n\n  input:\n    path tarball\n    val pattern\n\n  output:\n    path \"*${pattern}{.bam,.cram,.vcf.gz}\", emit: output_file\n    path \"*${pattern}{.bam.bai,.cram.crai,.vcf.gz.tbi}\", emit: output_file_index\n    tuple path(\"*${pattern}{.bam,.cram,.vcf.gz}\"), path(\"*${pattern}{.bam.bai,.cram.crai,.vcf.gz.tbi}\"), emit: extracted_files\n\n  script:\n    \"\"\"\n    tar -xzf ${tarball}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    tar -xzf ${tarball}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tarball",
            "pattern"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container 'ubuntu:18.04'"
        ],
        "when": "",
        "stub": ""
    },
    "prepSangerSupplement": {
        "name_process": "prepSangerSupplement",
        "string_process": "\nprocess prepSangerSupplement {\n  container \"quay.io/icgc-argo/prep-sanger-supplement:prep-sanger-supplement.${params.container_version ?: version}\"\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path result_tars\n\n  output:\n    path \"*.*-supplement.tgz\", emit: supplement_tar\n\n  script:\n    \"\"\"\n    prep-sanger-supplement.py \\\n      -r ${result_tars}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    prep-sanger-supplement.py \\\n      -r ${result_tars}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "result_tars"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"quay.io/icgc-argo/prep-sanger-supplement:prep-sanger-supplement.${params.container_version ?: version}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "scoreDownload": {
        "name_process": "scoreDownload",
        "string_process": "\nprocess scoreDownload {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/score:${params.container_version}\"\n    publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n    label \"scoreDownload\"\n    tag \"${analysis_id}\"\n\n    input:\n        path analysis\n        val study_id\n        val analysis_id\n\n    output:\n        path analysis, emit: analysis_json\n        path 'out/*', emit: files\n\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export METADATA_URL=${params.song_url}\n        export STORAGE_URL=${params.score_url}\n        export TRANSPORT_PARALLEL=${params.cpus}\n        export TRANSPORT_MEMORY=${params.transport_mem}\n        export ACCESSTOKEN=${accessToken}\n        \n        score-client download --analysis-id ${analysis_id} --study-id ${study_id} --output-dir ./out \n        \"\"\"\n}",
        "nb_lignes_process": 39,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export METADATA_URL=${params.song_url}\n        export STORAGE_URL=${params.score_url}\n        export TRANSPORT_PARALLEL=${params.cpus}\n        export TRANSPORT_MEMORY=${params.transport_mem}\n        export ACCESSTOKEN=${accessToken}\n        \n        score-client download --analysis-id ${analysis_id} --study-id ${study_id} --output-dir ./out \n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "analysis",
            "study_id",
            "analysis_id"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/score:${params.container_version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "label \"scoreDownload\"",
            "tag \"${analysis_id}\""
        ],
        "when": "",
        "stub": ""
    },
    "prepSangerQc": {
        "name_process": "prepSangerQc",
        "string_process": "\nprocess prepSangerQc {\n  container \"quay.io/icgc-argo/prep-sanger-qc:prep-sanger-qc.${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path qc_files\n\n  output:\n    path \"*_metrics.tgz\", emit: qc_metrics_tar\n\n  script:\n    \"\"\"\n    prep-sanger-qc.py \\\n      -r ${qc_files}\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    prep-sanger-qc.py \\\n      -r ${qc_files}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "qc_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"quay.io/icgc-argo/prep-sanger-qc:prep-sanger-qc.${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "repackSangerResults": {
        "name_process": "repackSangerResults",
        "string_process": "\nprocess repackSangerResults {\n  container \"quay.io/icgc-argo/repack-sanger-results:repack-sanger-results.${params.container_version ?: version}\"\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path sanger_results\n    val library_strategy\n\n  output:\n    path \"*.normal.contamination.tgz\", optional: true, emit: normal_contamination\n    path \"*.tumour.contamination.tgz\", optional: true, emit: tumour_contamination\n    path \"*.ascat.tgz\", optional: true, emit: ascat\n    path \"*.brass.tgz\", optional: true, emit: brass\n    path \"*.caveman.tgz\", optional: true, emit: caveman\n    path \"*.genotyped.tgz\", optional: true, emit: genotyped\n    path \"*.pindel.tgz\", optional: true, emit: pindel\n\n  script:\n    \"\"\"\n    repack-sanger-results.py \\\n      -i ${sanger_results} \\\n      -l ${library_strategy}\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    repack-sanger-results.py \\\n      -i ${sanger_results} \\\n      -l ${library_strategy}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sanger_results",
            "library_strategy"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"quay.io/icgc-argo/repack-sanger-results:repack-sanger-results.${params.container_version ?: version}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "songManifest": {
        "name_process": "songManifest",
        "string_process": "\nprocess songManifest {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/song-client:${params.container_version}\"\n\n    tag \"${analysis_id}\"\n\n    input:\n        val study_id\n        val analysis_id\n        path upload\n    \n    output:\n        path \"out/manifest.txt\"\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing manifest -a ${analysis_id} -d . -f ./out/manifest.txt\n        \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing manifest -a ${analysis_id} -d . -f ./out/manifest.txt\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Nursing"
        ],
        "tools_url": [
            "https://bio.tools/Nursing"
        ],
        "tools_dico": [
            {
                "name": "Nursing",
                "uri": "https://bio.tools/Nursing",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Medical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Critical care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Medicines research and development"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Biomedical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Healthcare informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health and disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Clinical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Acute medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Emergency medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Intensive care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Drug discovery and development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The use and abuse of credentials.\n\nA Guide to Nursing Credentials and Degrees.\n\nComplete List of Common Nursing Certifications.\n\nFrom LPN to MSN, the jumble of letters following a nurse's name can be confusing. Learn what these nursing credentials mean and how they should be listed.\n\nView 183 commonly recognized nursing certifications along with links to their certifying organizations.\n\nThe confusing nature of nursing credentials has led to widespread use of the term \u201calphabet soup.\u201d The letters that follow a nurse\u2019s name can be perplexing to professionals in the medical field, and especially to patients and families. To solve this problem, nursing credentials need to be displayed properly.\n\nNever fear. Nurse.org has compiled an alphabetical list of 183 different nursing certifications along with the appropriate acronyms and links to their certifying organizations",
                "homepage": "https://online.alvernia.edu/program-resources/nursing-credentials/"
            }
        ],
        "inputs": [
            "study_id",
            "analysis_id",
            "upload"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/song-client:${params.container_version}\"",
            "tag \"${analysis_id}\""
        ],
        "when": "",
        "stub": ""
    },
    "payloadAddUniformIds": {
        "name_process": "payloadAddUniformIds",
        "string_process": "\nprocess payloadAddUniformIds {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:                                 \n    path payload_json\n    path id_mapping_tsv\n\n  output:                                  \n    path \"output_dir/*.json\", emit: payload\n\n  script:\n                                                  \n\n    \"\"\"\n    mkdir -p output_dir\n\n    main.py \\\n      -p ${payload_json} \\\n      -i ${id_mapping_tsv} \\\n      -o output_dir\n\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    mkdir -p output_dir\n\n    main.py \\\n      -p ${payload_json} \\\n      -i ${id_mapping_tsv} \\\n      -o output_dir\n\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "payload_json",
            "id_mapping_tsv"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "cavemanVcfFix": {
        "name_process": "cavemanVcfFix",
        "string_process": "\nprocess cavemanVcfFix {\n  container \"quay.io/icgc-argo/caveman-vcf-fix:caveman-vcf-fix.${params.container_version ?: version}\"\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path input_tar\n\n  output:\n    path \"out/*.tgz\", emit: fixed_tar\n\n  script:\n    \"\"\"\n    caveman-vcf-fix.py -i ${input_tar}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    caveman-vcf-fix.py -i ${input_tar}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_tar"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"quay.io/icgc-argo/caveman-vcf-fix:caveman-vcf-fix.${params.container_version ?: version}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "sangerWxsVariantCaller": {
        "name_process": "sangerWxsVariantCaller",
        "string_process": "\nprocess sangerWxsVariantCaller {\n  container \"quay.io/icgc-argo/sanger-wxs-variant-caller:sanger-wxs-variant-caller.${params.container_version ?: version}\"\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  tag \"${tumour.size()}\"\n\n  input:\n    path reference\n    path annot\n    path snv_indel\n    path tumour\n    path tidx\n    path tumour_bas\n    path normal\n    path nidx\n    path normal_bas\n\n  output:\n    path \"run.params\", emit: run_params\n    path \"WXS_*_vs_*.result.tar.gz\", emit: result_archive\n    path \"WXS_*_vs_*.timings.tar.gz\", emit: timings\n\n  script:\n    arg_skipannot = params.skipannot ? \"-skipannot\" : \"\"\n    \"\"\"\n    /opt/wtsi-cgp/bin/ds-cgpwxs.pl \\\n      -cores ${task.cpus} \\\n      -reference ${reference} \\\n      -annot ${annot} \\\n      -snv_indel ${snv_indel} \\\n      -tumour ${tumour} \\\n      -tidx ${tidx} \\\n      -normal ${normal} \\\n      -nidx ${nidx} \\\n      -exclude ${params.exclude} \\\n      -species ${params.species} \\\n      -assembly ${params.assembly} \\\n      ${arg_skipannot} \\\n      -outdir \\$PWD\n    \"\"\"\n}",
        "nb_lignes_process": 42,
        "string_script": "    arg_skipannot = params.skipannot ? \"-skipannot\" : \"\"\n    \"\"\"\n    /opt/wtsi-cgp/bin/ds-cgpwxs.pl \\\n      -cores ${task.cpus} \\\n      -reference ${reference} \\\n      -annot ${annot} \\\n      -snv_indel ${snv_indel} \\\n      -tumour ${tumour} \\\n      -tidx ${tidx} \\\n      -normal ${normal} \\\n      -nidx ${nidx} \\\n      -exclude ${params.exclude} \\\n      -species ${params.species} \\\n      -assembly ${params.assembly} \\\n      ${arg_skipannot} \\\n      -outdir \\$PWD\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reference",
            "annot",
            "snv_indel",
            "tumour",
            "tidx",
            "tumour_bas",
            "normal",
            "nidx",
            "normal_bas"
        ],
        "nb_inputs": 9,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"quay.io/icgc-argo/sanger-wxs-variant-caller:sanger-wxs-variant-caller.${params.container_version ?: version}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "tag \"${tumour.size()}\""
        ],
        "when": "",
        "stub": ""
    },
    "songPublish": {
        "name_process": "songPublish",
        "string_process": "\nprocess songPublish {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/song-client:${params.container_version}\"\n\n    tag \"${analysis_id}\"\n    \n    input:\n        val study_id\n        val analysis_id\n\n    output:\n        val analysis_id, emit: analysis_id\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing publish -a  ${analysis_id}\n        \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export CLIENT_SERVER_URL=${params.song_url}\n        export CLIENT_STUDY_ID=${study_id}\n        export CLIENT_ACCESS_TOKEN=${accessToken}\n\n        sing publish -a  ${analysis_id}\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "Nursing"
        ],
        "tools_url": [
            "https://bio.tools/Nursing"
        ],
        "tools_dico": [
            {
                "name": "Nursing",
                "uri": "https://bio.tools/Nursing",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Medical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Critical care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Medicines research and development"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Biomedical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Healthcare informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Health and disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3063",
                            "term": "Clinical informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Acute medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Emergency medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3403",
                            "term": "Intensive care medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3376",
                            "term": "Drug discovery and development"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The use and abuse of credentials.\n\nA Guide to Nursing Credentials and Degrees.\n\nComplete List of Common Nursing Certifications.\n\nFrom LPN to MSN, the jumble of letters following a nurse's name can be confusing. Learn what these nursing credentials mean and how they should be listed.\n\nView 183 commonly recognized nursing certifications along with links to their certifying organizations.\n\nThe confusing nature of nursing credentials has led to widespread use of the term \u201calphabet soup.\u201d The letters that follow a nurse\u2019s name can be perplexing to professionals in the medical field, and especially to patients and families. To solve this problem, nursing credentials need to be displayed properly.\n\nNever fear. Nurse.org has compiled an alphabetical list of 183 different nursing certifications along with the appropriate acronyms and links to their certifying organizations",
                "homepage": "https://online.alvernia.edu/program-resources/nursing-credentials/"
            }
        ],
        "inputs": [
            "study_id",
            "analysis_id"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/song-client:${params.container_version}\"",
            "tag \"${analysis_id}\""
        ],
        "when": "",
        "stub": ""
    },
    "generateBas": {
        "name_process": "generateBas",
        "string_process": "\nprocess generateBas {\n  container \"quay.io/icgc-argo/generate-bas:generate-bas.${params.container_version ?: version}\"\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  tag \"${seq.size()}\"\n\n  input:\n    val tumour_normal\n    path seq\n    path seq_idx\n    path reference\n    path reference_fai\n\n  output:\n    path \"${seq.name}.bas\", emit: bas_file\n    path \"${seq.name}.${tumour_normal}.bas\", emit: bas_file_with_tn\n\n  script:\n    arg_ref = reference.name != 'NO_FILE' ? \"-r ${reference}\" : ''\n    \"\"\"\n    set -euxo pipefail\n\n    if [ \"${tumour_normal}\" != \"normal\" ] && [ \"${tumour_normal}\" != \"tumour\" ]; then\n      echo \"parameter 'tumour_normal' must be either 'tumour' or 'normal'\"\n      exit 1\n    fi\n\n    /opt/wtsi-cgp/bin/bam_stats \\\n      -i ${seq} \\\n      ${arg_ref} \\\n      --num_threads ${task.cpus} \\\n      -o ${seq.name}.bas\n\n    ln -s ${seq.name}.bas ${seq.name}.${tumour_normal}.bas\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    arg_ref = reference.name != 'NO_FILE' ? \"-r ${reference}\" : ''\n    \"\"\"\n    set -euxo pipefail\n\n    if [ \"${tumour_normal}\" != \"normal\" ] && [ \"${tumour_normal}\" != \"tumour\" ]; then\n      echo \"parameter 'tumour_normal' must be either 'tumour' or 'normal'\"\n      exit 1\n    fi\n\n    /opt/wtsi-cgp/bin/bam_stats \\\n      -i ${seq} \\\n      ${arg_ref} \\\n      --num_threads ${task.cpus} \\\n      -o ${seq.name}.bas\n\n    ln -s ${seq.name}.bas ${seq.name}.${tumour_normal}.bas\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tumour_normal",
            "seq",
            "seq_idx",
            "reference",
            "reference_fai"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"quay.io/icgc-argo/generate-bas:generate-bas.${params.container_version ?: version}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "tag \"${seq.size()}\""
        ],
        "when": "",
        "stub": ""
    },
    "cleanupWorkdir": {
        "name_process": "cleanupWorkdir",
        "string_process": "\nprocess cleanupWorkdir {\n  container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path files_to_delete                                                                                       \n    val virtual_dep_flag                                                                                               \n\n  output:\n    stdout\n\n  script:\n    \"\"\"\n    set -euxo pipefail\n\n    IFS=\" \"\n    read -a files <<< \"${files_to_delete}\"\n    for f in \"\\${files[@]}\"\n    do\n        dir_to_rm=\\$(dirname \\$(readlink -f \\$f))\n\n        if [[ \\$dir_to_rm != ${workflow.workDir}/* ]]; then  # skip dir not under workdir, like from input file dir\n            echo \"Not delete: \\$dir_to_rm/*\\\"\n            continue\n        fi\n\n        rm -fr \\$dir_to_rm/*  # delete all files and subdirs but not hidden ones\n        echo \"Deleted: \\$dir_to_rm/*\"\n    done\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n    set -euxo pipefail\n\n    IFS=\" \"\n    read -a files <<< \"${files_to_delete}\"\n    for f in \"\\${files[@]}\"\n    do\n        dir_to_rm=\\$(dirname \\$(readlink -f \\$f))\n\n        if [[ \\$dir_to_rm != ${workflow.workDir}/* ]]; then  # skip dir not under workdir, like from input file dir\n            echo \"Not delete: \\$dir_to_rm/*\\\"\n            continue\n        fi\n\n        rm -fr \\$dir_to_rm/*  # delete all files and subdirs but not hidden ones\n        echo \"Deleted: \\$dir_to_rm/*\"\n    done\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "files_to_delete",
            "virtual_dep_flag"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: params.publish_dir",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "scoreUpload": {
        "name_process": "scoreUpload",
        "string_process": "\nprocess scoreUpload {\n    maxRetries params.max_retries\n    errorStrategy {\n        sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long);                                           \n        return params.max_retries ? 'retry' : 'finish'\n    }\n\n    pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]\n    \n    cpus params.cpus\n    memory \"${params.mem} GB\"\n \n    container \"overture/score:${params.container_version}\"\n\n    tag \"${analysis_id}\"\n\n    input:\n        val analysis_id\n        path manifest\n        path upload\n\n    output:\n        val analysis_id, emit: ready_to_publish\n\n    script:\n        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export METADATA_URL=${params.song_url}\n        export STORAGE_URL=${params.score_url}\n        export TRANSPORT_PARALLEL=${params.cpus}\n        export TRANSPORT_MEMORY=${params.transport_mem}\n        export ACCESSTOKEN=${accessToken}\n        \n        score-client upload --manifest ${manifest}\n        \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "        accessToken = params.api_token ? params.api_token : \"`cat /tmp/rdpc_secret/secret`\"\n        \"\"\"\n        export METADATA_URL=${params.song_url}\n        export STORAGE_URL=${params.score_url}\n        export TRANSPORT_PARALLEL=${params.cpus}\n        export TRANSPORT_MEMORY=${params.transport_mem}\n        export ACCESSTOKEN=${accessToken}\n        \n        score-client upload --manifest ${manifest}\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "analysis_id",
            "manifest",
            "upload"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo-workflows__sanger-wxs-variant-calling",
        "directive": [
            "maxRetries params.max_retries",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * params.first_retry_wait_time * 1000 as long); return params.max_retries ? 'retry' : 'finish' }",
            "pod = [secret: workflow.runName + \"-secret\", mountPath: \"/tmp/rdpc_secret\"]",
            "cpus params.cpus",
            "memory \"${params.mem} GB\"",
            "container \"overture/score:${params.container_version}\"",
            "tag \"${analysis_id}\""
        ],
        "when": "",
        "stub": ""
    }
}