{
    "run_ustacks": {
        "name_process": "run_ustacks",
        "string_process": "process run_ustacks {\n    tag { id }\n\n    label 'stacks'\n\n    publishDir \"${outdir}/stacks/01_ustacks\", mode: 'copy'\n\n    input:\n        tuple id, file(reads)\n        val wf\n        val outdir\n        val opt\n\n    output:\n        val \"${outdir}/stacks/01_ustacks\", emit: pth\n        file \"*.tsv*\"\n\n    when:\n        wf.contains('stacks_pipeline')\n\n    script:\n                             \n        def opt_args = opt ?: ''\n\n        \"\"\"\n        ustacks -p ${task.cpus} -f ${reads} --name ${id} -i \\${RANDOM} -o \\${PWD} ${opt_args}\n        \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "        def opt_args = opt ?: ''\n\n        \"\"\"\n        ustacks -p ${task.cpus} -f ${reads} --name ${id} -i \\${RANDOM} -o \\${PWD} ${opt_args}\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads",
            "id",
            "wf",
            "outdir",
            "opt"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "label 'stacks'",
            "publishDir \"${outdir}/stacks/01_ustacks\", mode: 'copy'"
        ],
        "when": "wf.contains('stacks_pipeline')",
        "stub": ""
    },
    "run_cstacks": {
        "name_process": "run_cstacks",
        "string_process": "\nprocess run_cstacks {\n    tag { popMap.baseName }\n\n    label 'stacks'\n\n    publishDir \"${outdir}/stacks/comparison_${popMap.baseName}\", mode: 'copy'\n\n    input:\n        val wf\n        tuple popMap, sample_string, file_string\n        val opt\n        val outdir\n    \n    output:\n        tuple popMap, val(\"${outdir}/stacks/comparison_${popMap.baseName}\"), emit: pop_path\n        file(\"*catalog*\")\n        file(\"*tsv*\")\n\n    when:\n        wf.contains('stacks_pipeline')\n\n    script:\n                             \n        def opt_args = opt ?: ''\n\n        \"\"\"\n        mkdir -p ${outdir}/stacks/comparison_${popMap.baseName}\n        cp ${file_string} ${outdir}/stacks/comparison_${popMap.baseName}\n        cstacks -p ${task.cpus} -o \\${PWD} ${opt_args} ${sample_string}\n        \"\"\"\n\n}",
        "nb_lignes_process": 31,
        "string_script": "        def opt_args = opt ?: ''\n\n        \"\"\"\n        mkdir -p ${outdir}/stacks/comparison_${popMap.baseName}\n        cp ${file_string} ${outdir}/stacks/comparison_${popMap.baseName}\n        cstacks -p ${task.cpus} -o \\${PWD} ${opt_args} ${sample_string}\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "wf",
            "popMap",
            "opt",
            "outdir"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { popMap.baseName }",
            "label 'stacks'",
            "publishDir \"${outdir}/stacks/comparison_${popMap.baseName}\", mode: 'copy'"
        ],
        "when": "wf.contains('stacks_pipeline')",
        "stub": ""
    },
    "run_sstacks": {
        "name_process": "run_sstacks",
        "string_process": "\nprocess run_sstacks {\n    tag { popMap.baseName }\n\n    label 'stacks'\n\n    input:\n        val wf\n        tuple popMap, path\n        val opt\n\n    output:\n        tuple popMap, path, emit: pop_path\n\n    when:\n        wf.contains('stacks_pipeline')\n\n    script:\n                             \n        def opt_args = opt ?: ''\n\n    \"\"\"\n    sstacks -P ${path} -M ${popMap} -p ${task.cpus} ${opt_args}\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "        def opt_args = opt ?: ''\n\n    \"\"\"\n    sstacks -P ${path} -M ${popMap} -p ${task.cpus} ${opt_args}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "wf",
            "popMap",
            "opt"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { popMap.baseName }",
            "label 'stacks'"
        ],
        "when": "wf.contains('stacks_pipeline')",
        "stub": ""
    },
    "run_tsv2bam": {
        "name_process": "run_tsv2bam",
        "string_process": "\nprocess run_tsv2bam {\n    tag { popMap.baseName }\n\n    label 'stacks'\n\n    input:\n        val wf\n        tuple popMap, path\n        val opt\n\n    output:\n        tuple popMap, path, emit: pop_path\n\n    when:\n        wf.contains('stacks_pipeline')\n\n    script:\n                         \n        def opt_args = opt ?: ''\n\n    \"\"\"\n    tsv2bam -P ${path} -M ${popMap} -t ${task.cpus} ${opt_args}\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "        def opt_args = opt ?: ''\n\n    \"\"\"\n    tsv2bam -P ${path} -M ${popMap} -t ${task.cpus} ${opt_args}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "wf",
            "popMap",
            "opt"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { popMap.baseName }",
            "label 'stacks'"
        ],
        "when": "wf.contains('stacks_pipeline')",
        "stub": ""
    },
    "run_gstacks": {
        "name_process": "run_gstacks",
        "string_process": "\nprocess run_gstacks {\n    tag { popMap.baseName }\n\n    label 'stacks'\n\n    input:\n        val wf\n        tuple popMap, path\n        val opt\n\n    output:\n        tuple popMap, path, emit: pop_path\n\n    when:\n        wf.contains('stacks_pipeline')\n\n    script:\n                         \n        def opt_args = opt ?: ''\n\n    \"\"\"\n    gstacks -P ${path} -M ${popMap} -t ${task.cpus} ${opt_args}\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "        def opt_args = opt ?: ''\n\n    \"\"\"\n    gstacks -P ${path} -M ${popMap} -t ${task.cpus} ${opt_args}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "wf",
            "popMap",
            "opt"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { popMap.baseName }",
            "label 'stacks'"
        ],
        "when": "wf.contains('stacks_pipeline')",
        "stub": ""
    },
    "run_populations": {
        "name_process": "run_populations",
        "string_process": "\nprocess run_populations {\n    tag { popMap.baseName }\n\n    label 'stacks'\n\n    publishDir \"${path}/populations_out\", mode: 'copy'\n\n    input:\n        val wf\n        tuple popMap, path\n        val opt\n\n    output:\n        tuple popMap, path, emit: pop_path\n        file(\"*\")\n\n    when:\n        wf.contains('stacks_pipeline')\n\n    script:\n                         \n        def opt_args = opt ?: ''\n\n    \"\"\"\n    populations -P ${path} -M ${popMap} -t ${task.cpus} -O \\${PWD} ${opt_args}\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "        def opt_args = opt ?: ''\n\n    \"\"\"\n    populations -P ${path} -M ${popMap} -t ${task.cpus} -O \\${PWD} ${opt_args}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "wf",
            "popMap",
            "opt"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { popMap.baseName }",
            "label 'stacks'",
            "publishDir \"${path}/populations_out\", mode: 'copy'"
        ],
        "when": "wf.contains('stacks_pipeline')",
        "stub": ""
    },
    "run_index": {
        "name_process": "run_index",
        "string_process": "process run_index {\n    tag { ref }\n\n    publishDir \"${pth}\", mode: 'copy'\n\n    label 'index'\n\n    input:\n        tuple path(ref), pth\n        val wf\n\n    output:\n        tuple pth, file(\"${ref.baseName}*.{amb,ann,64,32,pac,0123,fai}\"), val(\"${pth}/${ref}\"), emit: refs\n\n    when:\n        wf.contains('consensus_pipeline')\n\n    script:\n        \"\"\"\n        if [[ -f ${pth}/${ref}.fai ]]; then\n            cp ${pth}/${ref}.fai \\${PWD}\n        else \n            samtools faidx ${ref}\n        fi \n\n        if [[ -f ${pth}/${ref}.bwt.2bit.64 ]]; then\n            cp ${pth}/${ref}.bwt* \\${PWD}\n            cp ${pth}/${ref}.amb \\${PWD}\n            cp ${pth}/${ref}.ann \\${PWD}\n            cp ${pth}/${ref}.pac \\${PWD}\n            cp ${pth}/${ref}.0123 \\${PWD}\n        else \n            bwa-mem2 index ${ref}\n        fi\n        \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "        \"\"\"\n        if [[ -f ${pth}/${ref}.fai ]]; then\n            cp ${pth}/${ref}.fai \\${PWD}\n        else \n            samtools faidx ${ref}\n        fi \n\n        if [[ -f ${pth}/${ref}.bwt.2bit.64 ]]; then\n            cp ${pth}/${ref}.bwt* \\${PWD}\n            cp ${pth}/${ref}.amb \\${PWD}\n            cp ${pth}/${ref}.ann \\${PWD}\n            cp ${pth}/${ref}.pac \\${PWD}\n            cp ${pth}/${ref}.0123 \\${PWD}\n        else \n            bwa-mem2 index ${ref}\n        fi\n        \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "ref",
            "wf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { ref }",
            "publishDir \"${pth}\", mode: 'copy'",
            "label 'index'"
        ],
        "when": "wf.contains('consensus_pipeline')",
        "stub": ""
    },
    "run_bwa": {
        "name_process": "run_bwa",
        "string_process": "\nprocess run_bwa {\n    tag { id }\n\n    publishDir \"${outdir}/consensus/01_bwa/${ref.simpleName}\", mode: 'copy'\n\n    label 'bwa'\n\n    input:\n        tuple id, file(seqs), path(ref), file(idx)\n        val outdir\n        val opt\n        val wf\n\n    output:\n        tuple id, file(seqs), file(ref), file(idx), path(\"*.bam\"), path(\"*.bai\"), emit: bam\n        file \"*.flagstat\"\n\n    when:\n        wf.contains('consensus_pipeline')\n\n    script:\n        def opt_args = opt ?: ''\n\n        \"\"\"\n        bwa-mem2 mem -t ${task.cpus} ${ref} ${seqs} ${opt_args} | \\\n        samtools sort -O BAM -o ${id}.bam\n\n        samtools index -@ ${task.cpus} ${id}.bam\n\n        samtools flagstat -@ ${task.cpus} ${id}.bam > ${id}.flagstat\n        \"\"\"        \n}",
        "nb_lignes_process": 31,
        "string_script": "        def opt_args = opt ?: ''\n\n        \"\"\"\n        bwa-mem2 mem -t ${task.cpus} ${ref} ${seqs} ${opt_args} | \\\n        samtools sort -O BAM -o ${id}.bam\n\n        samtools index -@ ${task.cpus} ${id}.bam\n\n        samtools flagstat -@ ${task.cpus} ${id}.bam > ${id}.flagstat\n        \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "seqs",
            "idx",
            "ref",
            "id",
            "outdir",
            "opt",
            "wf"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/consensus/01_bwa/${ref.simpleName}\", mode: 'copy'",
            "label 'bwa'"
        ],
        "when": "wf.contains('consensus_pipeline')",
        "stub": ""
    },
    "run_variantCalling_bcftools": {
        "name_process": "run_variantCalling_bcftools",
        "string_process": "\nprocess run_variantCalling_bcftools {\n    tag { id } \n\n    publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/bcftools\", mode: 'copy'\n\n    label 'varCall'\n\n    input:\n        tuple id, path(ref), file(idx), file(bam), file(bai)\n        val outdir\n        val opt_mpileup\n        val opt_norm\n        val wf\n    \n    output:\n        tuple id, file(\"${id}.vcf.gz\"), file(\"${id}.vcf.gz.csi\")\n\n    when:\n        wf.contains('variant_pipeline')\n    \n    script:\n        def opt_m = opt_mpileup ?: ''\n        def opt_n = opt_norm ?: ''\n\n        \"\"\"\n        bcftools mpileup --gvcf 0 -Ou ${opt_m} -f ${ref} ${bam} | \\\n        bcftools call --gvcf 0 -Ou -m | \\\n        bcftools norm ${opt_n} -f ${ref} -Ou | \\\n        bcftools convert --gvcf2vcf --fasta-ref ${ref} -Ou | \\\n        bcftools sort --temp-dir \\${PWD} -Oz -o ${id}.vcf.gz\n\n        bcftools index ${id}.vcf.gz\n        \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "        def opt_m = opt_mpileup ?: ''\n        def opt_n = opt_norm ?: ''\n\n        \"\"\"\n        bcftools mpileup --gvcf 0 -Ou ${opt_m} -f ${ref} ${bam} | \\\n        bcftools call --gvcf 0 -Ou -m | \\\n        bcftools norm ${opt_n} -f ${ref} -Ou | \\\n        bcftools convert --gvcf2vcf --fasta-ref ${ref} -Ou | \\\n        bcftools sort --temp-dir \\${PWD} -Oz -o ${id}.vcf.gz\n\n        bcftools index ${id}.vcf.gz\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "idx",
            "bam",
            "bai",
            "ref",
            "id",
            "outdir",
            "opt_mpileup",
            "opt_norm",
            "wf"
        ],
        "nb_inputs": 9,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/bcftools\", mode: 'copy'",
            "label 'varCall'"
        ],
        "when": "wf.contains('variant_pipeline')",
        "stub": ""
    },
    "run_gatk_haplotypeCaller": {
        "name_process": "run_gatk_haplotypeCaller",
        "string_process": "\nprocess run_gatk_haplotypeCaller {\n    tag { id } \n\n    publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/haplotypeCaller\", mode: 'copy'\n\n    label 'varCall'\n\n    input:\n        tuple id, path(ref), file(idx), file(bam), file(bai)\n        val outdir\n        val opt_haplotypeCaller\n        val wf\n\n    output:\n        tuple id, file(\"${id}.g.vcf.gz\"), file(\"${id}.g.vcf.gz.tbi\"), emit: vcf_files\n\n    when:\n        wf.contains('variant_pipeline')\n    \n    script:\n    def opt = opt_haplotypeCaller ?: ''\n    \"\"\"\n    gatk HaplotypeCaller \\\n    --input ${bam} \\\n    --output ${id}.g.vcf.gz \\\n    --reference ${ref} \\\n    --native-pair-hmm-threads ${task.cpus} \\\n    --tmp-dir \\${PWD} \\\n    -ERC GVCF\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    def opt = opt_haplotypeCaller ?: ''\n    \"\"\"\n    gatk HaplotypeCaller \\\n    --input ${bam} \\\n    --output ${id}.g.vcf.gz \\\n    --reference ${ref} \\\n    --native-pair-hmm-threads ${task.cpus} \\\n    --tmp-dir \\${PWD} \\\n    -ERC GVCF\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "idx",
            "bam",
            "bai",
            "ref",
            "id",
            "outdir",
            "opt_haplotypeCaller",
            "wf"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/haplotypeCaller\", mode: 'copy'",
            "label 'varCall'"
        ],
        "when": "wf.contains('variant_pipeline')",
        "stub": ""
    },
    "run_gatk_combine": {
        "name_process": "run_gatk_combine",
        "string_process": "\nprocess run_gatk_combine {\n    tag { 'CombineGVCF' } \n\n    publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/combineGVCF\", mode: 'copy'\n\n    label 'varCall'\n\n    input:\n        tuple path(ref), file(idx), file(data), val(str)\n        val outdir\n        val opt_combine\n        val wf\n\n    output:\n        tuple file(ref), file(idx), file(\"combined.g.vcf.gz\"), file(\"combined.g.vcf.gz.tbi\"), emit: combined\n\n    when:\n        wf.contains('variant_pipeline')\n    \n    script:\n    def opt = opt_combine ?: ''\n    \"\"\"\n    gatk CombineGVCFs \\\n    ${opt} \\\n    --reference ${ref} \\\n    ${str} \\\n    --output combined.g.vcf.gz\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    def opt = opt_combine ?: ''\n    \"\"\"\n    gatk CombineGVCFs \\\n    ${opt} \\\n    --reference ${ref} \\\n    ${str} \\\n    --output combined.g.vcf.gz\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "str",
            "idx",
            "data",
            "ref",
            "outdir",
            "opt_combine",
            "wf"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { 'CombineGVCF' }",
            "publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/combineGVCF\", mode: 'copy'",
            "label 'varCall'"
        ],
        "when": "wf.contains('variant_pipeline')",
        "stub": ""
    },
    "run_genotypeGVCF_combined": {
        "name_process": "run_genotypeGVCF_combined",
        "string_process": "\nprocess run_genotypeGVCF_combined {\n    tag { 'genotypeCombined' } \n\n    publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/genotypeGVCF\", mode: 'copy'\n\n    label 'varCall'\n\n    input:\n        tuple path(ref), file(idx), file(vcf), file(tbi)\n        val outdir\n        val opt_genotype\n        val wf\n\n    output:\n        tuple file(\"genotyped.vcf.gz\"), file(\"genotyped.vcf.gz.tbi\")\n\n    when:\n        wf.contains('variant_pipeline')\n\n    script:\n        def opt = opt_genotype ?: ''\n        \"\"\"\n        gatk GenotypeGVCFs \\\n        --reference ${ref} \\\n        --variant ${vcf} \\\n        --output genotyped.vcf.gz \\\n        --include-non-variant-sites \\\n        ${opt}\n        \"\"\"\n\n}",
        "nb_lignes_process": 30,
        "string_script": "        def opt = opt_genotype ?: ''\n        \"\"\"\n        gatk GenotypeGVCFs \\\n        --reference ${ref} \\\n        --variant ${vcf} \\\n        --output genotyped.vcf.gz \\\n        --include-non-variant-sites \\\n        ${opt}\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "idx",
            "vcf",
            "tbi",
            "ref",
            "outdir",
            "opt_genotype",
            "wf"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { 'genotypeCombined' }",
            "publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/genotypeGVCF\", mode: 'copy'",
            "label 'varCall'"
        ],
        "when": "wf.contains('variant_pipeline')",
        "stub": ""
    },
    "run_genotypeGVCF": {
        "name_process": "run_genotypeGVCF",
        "string_process": "\nprocess run_genotypeGVCF {\n    tag { id } \n\n    publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/genotypeGVCF\", mode: 'copy'\n\n    label 'varCall'\n\n    input:\n        tuple id, path(ref), file(idx), file(vcf), file(tbi)\n        val outdir\n        val opt_genotype\n        val wf\n\n    output:\n        tuple file(\"${id}.genotyped.vcf.gz\"), file(\"${id}.genotyped.vcf.gz.tbi\")\n\n    when:\n        wf.contains('variant_pipeline')\n\n    script:\n        def opt = opt_genotype ?: ''\n        \"\"\"\n        gatk GenotypeGVCFs \\\n        --reference ${ref} \\\n        --variant ${vcf} \\\n        --output ${id}.genotyped.vcf.gz \\\n        --include-non-variant-sites \\\n        ${opt}\n        \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "        def opt = opt_genotype ?: ''\n        \"\"\"\n        gatk GenotypeGVCFs \\\n        --reference ${ref} \\\n        --variant ${vcf} \\\n        --output ${id}.genotyped.vcf.gz \\\n        --include-non-variant-sites \\\n        ${opt}\n        \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "GATK"
        ],
        "tools_url": [
            "https://bio.tools/gatk"
        ],
        "tools_dico": [
            {
                "name": "GATK",
                "uri": "https://bio.tools/gatk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Workflows"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0769",
                            "term": "Pipelines"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3202",
                                    "term": "Polymorphism detection"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2403",
                                    "term": "Sequence analysis (general)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The Genome Analysis Toolkit (GATK) is a set of bioinformatic tools for analyzing high-throughput sequencing (HTS) and variant call format (VCF) data. The toolkit is well established for germline short variant discovery from whole genome and exome sequencing data. GATK4 expands functionality into copy number and somatic analyses and offers pipeline scripts for workflows.  \n\nVersion 4 (GATK4) is open-source at https://github.com/broadinstitute/gatk.",
                "homepage": "https://software.broadinstitute.org/gatk/"
            }
        ],
        "inputs": [
            "idx",
            "vcf",
            "tbi",
            "ref",
            "id",
            "outdir",
            "opt_genotype",
            "wf"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/variants/02_variants/${ref.simpleName}/genotypeGVCF\", mode: 'copy'",
            "label 'varCall'"
        ],
        "when": "wf.contains('variant_pipeline')",
        "stub": ""
    },
    "run_variant_clean_up": {
        "name_process": "run_variant_clean_up",
        "string_process": "\nprocess run_variant_clean_up {\n\n    input:\n        file vcfs\n        val tidy\n        val caller\n        val combine\n        val outdir\n        val wf\n\n    when:\n        wf.contains('variant_pipeline') && tidy == true\n\n    script:\n    if(caller == 'bcftools') {\n        \"\"\"\n        find ${outdir} -type f -name '*.bam' -delete\n        find ${outdir} -type f -name '*.bam.bai' -delete\n        \"\"\"\n    } else {\n        if(combine){\n            \"\"\"\n            find ${outdir} -type f -name '*.bam' -delete\n            find ${outdir} -type f -name '*.bam.bai' -delete\n            find ${outdir} -type d -name 'haplotypeCaller' -exec rm -r {} +\n            find ${outdir} -type d -name 'combineGVCF' -exec rm -r {} +\n            \"\"\"\n        } else {\n            \"\"\"\n            find ${outdir} -type f -name '*.bam' -delete\n            find ${outdir} -type f -name '*.bam.bai' -delete\n            find ${outdir} -type d -name 'haplotypeCaller' -exec rm -r {} +\n            \"\"\"\n        }\n    }\n}",
        "nb_lignes_process": 35,
        "string_script": "    if(caller == 'bcftools') {\n        \"\"\"\n        find ${outdir} -type f -name '*.bam' -delete\n        find ${outdir} -type f -name '*.bam.bai' -delete\n        \"\"\"\n    } else {\n        if(combine){\n            \"\"\"\n            find ${outdir} -type f -name '*.bam' -delete\n            find ${outdir} -type f -name '*.bam.bai' -delete\n            find ${outdir} -type d -name 'haplotypeCaller' -exec rm -r {} +\n            find ${outdir} -type d -name 'combineGVCF' -exec rm -r {} +\n            \"\"\"\n        } else {\n            \"\"\"\n            find ${outdir} -type f -name '*.bam' -delete\n            find ${outdir} -type f -name '*.bam.bai' -delete\n            find ${outdir} -type d -name 'haplotypeCaller' -exec rm -r {} +\n            \"\"\"\n        }\n    }",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vcfs",
            "tidy",
            "caller",
            "combine",
            "outdir",
            "wf"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [],
        "when": "wf.contains('variant_pipeline') && tidy == true",
        "stub": ""
    },
    "setup_ete": {
        "name_process": "setup_ete",
        "string_process": "process setup_ete {\n    tag { 'Installing ETE-EVOL' }\n\n    input:\n        val wf\n    \n    when:\n        wf.contains('codeml_pipeline')\n    \n    script:\n        \"\"\"\n        mkdir -p \\${FASTDIR}/pipelines\n        cd \\${FASTDIR}/pipelines\n        git clone https://github.com/etetoolkit/ete.git\n        cd ete\n        python setup.py install\n        \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "        \"\"\"\n        mkdir -p \\${FASTDIR}/pipelines\n        cd \\${FASTDIR}/pipelines\n        git clone https://github.com/etetoolkit/ete.git\n        cd ete\n        python setup.py install\n        \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "wf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { 'Installing ETE-EVOL' }"
        ],
        "when": "wf.contains('codeml_pipeline')",
        "stub": ""
    },
    "run_codeml": {
        "name_process": "run_codeml",
        "string_process": "\nprocess run_codeml {\n    tag { id }\n\n    publishDir \"${outdir}/codeml_ete-evol\", mode: 'copy'\n\n    label 'codeml'\n\n    input:\n        val setup\n        tuple id, file(seqs), tree, mark\n        val outdir\n        val models\n        val tests\n        val leaves\n        val internals\n        val opt\n        val wf\n\n    output:\n        file \"*\"\n        file \"results_codeml.txt\"\n\n    when:\n        wf.contains('codeml_pipeline')\n\n    script:\n        \n                             \n        def models = '--models ' + models\n        def tests = tests ? '--tests ' + tests : ''\n        def mark = mark ? '--mark ' + mark : ''\n        def leaves = leaves ? '--leaves' : ''\n        def internals = internals ? '--internals' : '' \n        def opt_args = opt ?: ''\n\n        \"\"\"\n        ete3 evol \\\n        --cpu ${task.cpus} \\\n        -t ${tree} \\\n        --alg ${seqs} \\\n        -o \\${PWD} \\\n        ${models} ${tests} ${mark} ${leaves} ${internals} ${opt_args}\n\n        cp .command.out results_codeml.txt\n        \"\"\"        \n}",
        "nb_lignes_process": 45,
        "string_script": "        def models = '--models ' + models\n        def tests = tests ? '--tests ' + tests : ''\n        def mark = mark ? '--mark ' + mark : ''\n        def leaves = leaves ? '--leaves' : ''\n        def internals = internals ? '--internals' : '' \n        def opt_args = opt ?: ''\n\n        \"\"\"\n        ete3 evol \\\n        --cpu ${task.cpus} \\\n        -t ${tree} \\\n        --alg ${seqs} \\\n        -o \\${PWD} \\\n        ${models} ${tests} ${mark} ${leaves} ${internals} ${opt_args}\n\n        cp .command.out results_codeml.txt\n        \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "setup",
            "seqs",
            "id",
            "outdir",
            "models",
            "tests",
            "leaves",
            "internals",
            "opt",
            "wf"
        ],
        "nb_inputs": 10,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/codeml_ete-evol\", mode: 'copy'",
            "label 'codeml'"
        ],
        "when": "wf.contains('codeml_pipeline')",
        "stub": ""
    },
    "run_fastp": {
        "name_process": "run_fastp",
        "string_process": "\nprocess run_fastp {\n    tag { id }\n\n    publishDir \"${outdir}/fastp/${id}\", mode: 'copy'\n\n    label 'fastp'\n\n    input:\n        tuple id, file(file_pair)\n        val wf\n        val outdir\n        val lib_type\n        val detect_adapter\n        val unpaired_file\n        val failed_file\n        val adapter_fasta\n        val trim\n        val opt\n\n    output:\n        tuple id, file(\"trim/${id}*.gz\"), emit: trimmed_reads\n        file 'failed_reads.fastq.gz'\n        file \"${id}.{html,json}\"\n        file 'unpaired_reads.fastq.gz' optional true\n\n    when:\n        trim == true && wf.contains('qc_pipeline')\n\n    script:\n    def opt_args = opt ?: ''\n\n    if(lib_type == 'paired')\n        if(detect_adapter == true)\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --in2 ${file_pair[1]} \\\n            --out1 trim/${file_pair[0].baseName}.gz \\\n            --out2 trim/${file_pair[1].baseName}.gz \\\n            --unpaired1 ${unpaired_file} \\\n            --failed_out ${failed_file} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n        else\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --in2 ${file_pair[1]} \\\n            --out1 trim/${file_pair[0].baseName}.gz \\\n            --out2 trim/${file_pair[1].baseName}.gz \\\n            --unpaired1 ${unpaired_file} \\\n            --failed_out ${failed_file} \\\n            --adapter_fasta ${adapter_fasta} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n    else if(lib_type == 'single')\n        if(detect_adapter == true)\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --out1 trim/${file_pair[0].baseName}.gz \\\n            --failed_out ${failed_file} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n        else\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --out1 trim/${file_pair[0].baseName} \\\n            --unpaired1 trim/${unpaired_file} \\\n            --failed_out ${failed_file} \\\n            --adapter_fasta ${adapter_fasta} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n    else\n        error \"Invalid argument provided to ${detect_adapter}\"\n}",
        "nb_lignes_process": 96,
        "string_script": "    def opt_args = opt ?: ''\n\n    if(lib_type == 'paired')\n        if(detect_adapter == true)\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --in2 ${file_pair[1]} \\\n            --out1 trim/${file_pair[0].baseName}.gz \\\n            --out2 trim/${file_pair[1].baseName}.gz \\\n            --unpaired1 ${unpaired_file} \\\n            --failed_out ${failed_file} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n        else\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --in2 ${file_pair[1]} \\\n            --out1 trim/${file_pair[0].baseName}.gz \\\n            --out2 trim/${file_pair[1].baseName}.gz \\\n            --unpaired1 ${unpaired_file} \\\n            --failed_out ${failed_file} \\\n            --adapter_fasta ${adapter_fasta} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n    else if(lib_type == 'single')\n        if(detect_adapter == true)\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --out1 trim/${file_pair[0].baseName}.gz \\\n            --failed_out ${failed_file} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n        else\n            \"\"\"\n            mkdir -p trim\n\n            fastp \\\n            --in1 ${file_pair[0]} \\\n            --out1 trim/${file_pair[0].baseName} \\\n            --unpaired1 trim/${unpaired_file} \\\n            --failed_out ${failed_file} \\\n            --adapter_fasta ${adapter_fasta} \\\n            --html ${id}.html \\\n            --json ${id}.json \\\n            --thread ${task.cpus} \\\n            ${opt_args}\n            \"\"\"\n    else\n        error \"Invalid argument provided to ${detect_adapter}\"",
        "nb_lignes_script": 66,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "file_pair",
            "id",
            "wf",
            "outdir",
            "lib_type",
            "detect_adapter",
            "unpaired_file",
            "failed_file",
            "adapter_fasta",
            "trim",
            "opt"
        ],
        "nb_inputs": 11,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/fastp/${id}\", mode: 'copy'",
            "label 'fastp'"
        ],
        "when": "trim == true && wf.contains('qc_pipeline')",
        "stub": ""
    },
    "run_fastqc_raw": {
        "name_process": "run_fastqc_raw",
        "string_process": "\nprocess run_fastqc_raw {\n    tag { id }\n\n    label 'fixCore'\n\n    publishDir \"${outdir}/fastqc/${id}/raw\", mode: 'copy'\n\n    input:\n        tuple id, file(reads)\n        val wf\n        val outdir\n\n    output:\n        tuple id, file(\"*.{zip,html}\")\n\n    when:\n        wf.contains('qc_pipeline')\n\n    script:\n        \"\"\"\n        fastqc  -t ${task.cpus} -k 9  -q ${reads}\n        \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        fastqc  -t ${task.cpus} -k 9  -q ${reads}\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "reads",
            "id",
            "wf",
            "outdir"
        ],
        "nb_inputs": 4,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "label 'fixCore'",
            "publishDir \"${outdir}/fastqc/${id}/raw\", mode: 'copy'"
        ],
        "when": "wf.contains('qc_pipeline')",
        "stub": ""
    },
    "run_fastqc_trim": {
        "name_process": "run_fastqc_trim",
        "string_process": "\nprocess run_fastqc_trim {\n    tag { id }\n\n    label 'fixCore'\n\n    publishDir \"${outdir}/fastqc/${id}/trim\", mode: 'copy'\n\n    input:\n        tuple id, file(reads)\n        val wf\n        val outdir\n\n    output:\n        tuple id, file(\"*.{zip,html}\")\n\n    when:\n        wf.contains('qc_pipeline')\n\n    script:\n        \"\"\"\n        fastqc  -t ${task.cpus} -k 9  -q ${reads}\n        \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        fastqc  -t ${task.cpus} -k 9  -q ${reads}\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "reads",
            "id",
            "wf",
            "outdir"
        ],
        "nb_inputs": 4,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "label 'fixCore'",
            "publishDir \"${outdir}/fastqc/${id}/trim\", mode: 'copy'"
        ],
        "when": "wf.contains('qc_pipeline')",
        "stub": ""
    },
    "run_trinity": {
        "name_process": "run_trinity",
        "string_process": "process run_trinity {\n    \n    tag { id }\n\n    publishDir \"${outdir}/trinity\", mode: 'copy'\n\n    label 'trin'\n\n    input:\n        tuple id, file(reads)\n        val lib_type\n        val outdir\n        val trinity_opt\n        val wf\n\n    output:\n        tuple id, file(\"*.Trinity.fasta\"), emit: fasta\n        file \"*SuperTrans*\"\n        file \"*.gene_trans_map\"\n\n    when:\n        wf.contains('transcript_pipeline')\n\n    script:\n    def opt_args = trinity_opt ?: ''\n\n    if(lib_type == 'paired') {\n        \"\"\"\n        Trinity \\\n        --seqType fq \\\n        --max_memory 50G \\\n        --left ${reads[0]} \\\n        --right ${reads[1]} \\\n        --output \\${PWD}/Trinity_${id} \\\n        --CPU ${task.cpus} \\\n        --include_supertranscripts \\\n        --full_cleanup \\\n        ${opt_args}\n        \"\"\"\n    } else if(lib_type == 'single') {\n        \"\"\"\n        Trinity \\\n        --seqType fq \\\n        --max_memory 50G \\\n        --single ${reads} \\\n        --output \\${PWD}/Trinity_${id} \\\n        --CPU ${task.cpus} \\\n        --include_supertranscripts \\\n        --full_cleanup \\\n        ${opt_args}\n        \"\"\"\n    }\n    \n}",
        "nb_lignes_process": 52,
        "string_script": "    def opt_args = trinity_opt ?: ''\n\n    if(lib_type == 'paired') {\n        \"\"\"\n        Trinity \\\n        --seqType fq \\\n        --max_memory 50G \\\n        --left ${reads[0]} \\\n        --right ${reads[1]} \\\n        --output \\${PWD}/Trinity_${id} \\\n        --CPU ${task.cpus} \\\n        --include_supertranscripts \\\n        --full_cleanup \\\n        ${opt_args}\n        \"\"\"\n    } else if(lib_type == 'single') {\n        \"\"\"\n        Trinity \\\n        --seqType fq \\\n        --max_memory 50G \\\n        --single ${reads} \\\n        --output \\${PWD}/Trinity_${id} \\\n        --CPU ${task.cpus} \\\n        --include_supertranscripts \\\n        --full_cleanup \\\n        ${opt_args}\n        \"\"\"\n    }",
        "nb_lignes_script": 27,
        "language_script": "bash",
        "tools": [
            "Trinity"
        ],
        "tools_url": [
            "https://bio.tools/trinity"
        ],
        "tools_dico": [
            {
                "name": "Trinity",
                "uri": "https://bio.tools/trinity",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Trinity is a transcriptome assembler which relies on three different tools, inchworm an assembler, chrysalis which pools contigs and butterfly which amongst others compacts a graph resulting from butterfly with reads.",
                "homepage": "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
            }
        ],
        "inputs": [
            "reads",
            "id",
            "lib_type",
            "outdir",
            "trinity_opt",
            "wf"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/trinity\", mode: 'copy'",
            "label 'trin'"
        ],
        "when": "wf.contains('transcript_pipeline')",
        "stub": ""
    },
    "run_cdhit": {
        "name_process": "run_cdhit",
        "string_process": "\nprocess run_cdhit {\n    \n    tag { id }\n\n    publishDir \"${outdir}/cdhit\", mode: 'copy'\n\n    label 'cdhit'\n\n    input:\n        tuple id, path(fastaFile)\n        val outdir\n        val cdhit\n        val wf\n\n    output:\n        tuple id, file(\"*.fasta\"), emit: fasta\n        file \"*.clstr\"\n\n    when:\n        wf.contains('transcript_pipeline') && cdhit == true\n\n    script:\n    \"\"\"\n    cd-hit-est -o ${id}_cdhit.fasta -c 0.98 -i ${fastaFile} -p 1 -d 0 -b 3 -T ${task.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    cd-hit-est -o ${id}_cdhit.fasta -c 0.98 -i ${fastaFile} -p 1 -d 0 -b 3 -T ${task.cpus}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastaFile",
            "id",
            "outdir",
            "cdhit",
            "wf"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/cdhit\", mode: 'copy'",
            "label 'cdhit'"
        ],
        "when": "wf.contains('transcript_pipeline') && cdhit == true",
        "stub": ""
    },
    "get_databases": {
        "name_process": "get_databases",
        "string_process": "\nprocess get_databases {\n    \n    publishDir \"${FASTDIR}/nf-databases\", mode: 'copy'\n\n    input:\n        val transdecoder\n        val wf\n\n    output:\n        path \"*.fasta*\", emit: blast_db\n        path \"*.hmm*\", emit: pfam_db\n\n    when:\n        wf.contains('transcript_pipeline') && transdecoder == true\n\n    script:\n    \"\"\"\n    if [[ ! -f \\${FASTDIR}/nf-databases/uniprot_sprot.fasta || ! -f \\${FASTDIR}/nf-databases/Pfam-A.hmm ]]; then\n        wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n\n        wget ftp://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz\n\n        gunzip uniprot_sprot.fasta.gz\n        gunzip Pfam-A.hmm.gz\n\n        makeblastdb \\\n        -in uniprot_sprot.fasta \\\n        -dbtype prot \\\n        -input_type fasta \\\n        -parse_seqids\n\n        hmmpress Pfam-A.hmm\n\n    else\n        cp \\${FASTDIR}/nf-databases/uniprot_sprot.fasta* .\n        cp \\${FASTDIR}/nf-databases/Pfam-A.hmm* .\n    fi\n    \n    \"\"\"\n\n}",
        "nb_lignes_process": 40,
        "string_script": "    \"\"\"\n    if [[ ! -f \\${FASTDIR}/nf-databases/uniprot_sprot.fasta || ! -f \\${FASTDIR}/nf-databases/Pfam-A.hmm ]]; then\n        wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz\n\n        wget ftp://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz\n\n        gunzip uniprot_sprot.fasta.gz\n        gunzip Pfam-A.hmm.gz\n\n        makeblastdb \\\n        -in uniprot_sprot.fasta \\\n        -dbtype prot \\\n        -input_type fasta \\\n        -parse_seqids\n\n        hmmpress Pfam-A.hmm\n\n    else\n        cp \\${FASTDIR}/nf-databases/uniprot_sprot.fasta* .\n        cp \\${FASTDIR}/nf-databases/Pfam-A.hmm* .\n    fi\n    \n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "transdecoder",
            "wf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "publishDir \"${FASTDIR}/nf-databases\", mode: 'copy'"
        ],
        "when": "wf.contains('transcript_pipeline') && transdecoder == true",
        "stub": ""
    },
    "run_transdecoder_longorfs": {
        "name_process": "run_transdecoder_longorfs",
        "string_process": "\nprocess run_transdecoder_longorfs {\n\n    tag { id }\n\n    publishDir \"${outdir}/transdecoder\", mode: 'copy'\n\n    label 'transd'\n\n    input:\n        tuple id, path(fastaFile)\n        val outdir\n        val transdecoder\n        val wf\n\n    output:\n        tuple id, path(\"${id}_longOrf\"), emit: path_longOrf\n\n    when:\n        wf.contains('transcript_pipeline') && transdecoder == true\n    \n    script:\n    \"\"\"\n    TransDecoder.LongOrfs -t ${fastaFile} --output_dir ${id}_longOrf\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    TransDecoder.LongOrfs -t ${fastaFile} --output_dir ${id}_longOrf\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastaFile",
            "id",
            "outdir",
            "transdecoder",
            "wf"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/transdecoder\", mode: 'copy'",
            "label 'transd'"
        ],
        "when": "wf.contains('transcript_pipeline') && transdecoder == true",
        "stub": ""
    },
    "run_blast": {
        "name_process": "run_blast",
        "string_process": "\nprocess run_blast {\n    \n    tag { id }\n\n    publishDir \"${outdir}/transdecoder/blast\", mode: 'copy'\n\n    label 'homology'\n\n    input:\n        tuple id, path(longOrf), file(fa), file(nhr), file(nin), file(nog), file(nsd), file(nsi), file(nsq)\n        val outdir\n        val transdecoder\n        val wf\n\n    output:\n        tuple id, path(\"${id}.outfmt6\")\n\n    when:\n        wf.contains('transcript_pipeline') && transdecoder == true\n\n    script:\n    \"\"\"\n    blastp \\\n    -query ${longOrf}/longest_orfs.pep \\\n    -db ${fa} \\\n    -max_target_seqs 1 \\\n    -outfmt 6 \\\n    -evalue 1e-5 \\\n    -num_threads ${task.cpus} > ${id}.outfmt6\n    \"\"\"\n\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    blastp \\\n    -query ${longOrf}/longest_orfs.pep \\\n    -db ${fa} \\\n    -max_target_seqs 1 \\\n    -outfmt 6 \\\n    -evalue 1e-5 \\\n    -num_threads ${task.cpus} > ${id}.outfmt6\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "BLASTP-ACC"
        ],
        "tools_url": [
            "https://bio.tools/BLASTP-ACC"
        ],
        "tools_dico": [
            {
                "name": "BLASTP-ACC",
                "uri": "https://bio.tools/BLASTP-ACC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3297",
                            "term": "Biotechnology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3802",
                                    "term": "Sorting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Sequence alignment (local)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parallel Architecture and Hardware Accelerator Design for BLAST-based Protein Sequence Alignment.\n\nIn this study, we design a hardware accelerator for a widely used sequence alignment algorithm, the basic local alignment search tool for proteins (BLASTP). The architecture of the proposed accelerator consists of five stages: a new systolic-array-based one-hit finding stage, a novel RAM-REG-based two-hit finding stage, a refined ungapped extension stage, a faster gapped extension stage, and a highly efficient parallel sorter. The system is implemented on an Altera Stratix V FPGA with a processing speed of more than 500 giga cell updates per second (GCUPS). It can receive a query sequence, compare it with the sequences in the database, and generate a list sorted in descending order of the similarity scores between the query sequence and the subject sequences.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'accelerator', 'Altera', 'Stratix', 'RAM-REG-based'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31581096"
            }
        ],
        "inputs": [
            "fa",
            "nhr",
            "nin",
            "nog",
            "nsd",
            "nsi",
            "nsq",
            "longOrf",
            "id",
            "outdir",
            "transdecoder",
            "wf"
        ],
        "nb_inputs": 12,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/transdecoder/blast\", mode: 'copy'",
            "label 'homology'"
        ],
        "when": "wf.contains('transcript_pipeline') && transdecoder == true",
        "stub": ""
    },
    "run_hmmer": {
        "name_process": "run_hmmer",
        "string_process": "\nprocess run_hmmer {\n    \n    tag { id }\n\n    publishDir \"${outdir}/transdecoder/hmmer\", mode: 'copy'\n\n    label 'homology'\n\n    input:\n        tuple id, path(longOrf), file(hmm), file(h3f), file(h3i), file(h3m), file(h3p)\n        val outdir\n        val transdecoder\n        val wf\n\n    output:\n        tuple id, path(\"${id}.domtblout\")\n\n    when:\n        wf.contains('transcript_pipeline') && transdecoder == true\n\n    script:\n    \"\"\"\n    hmmscan \\\n    --cpu ${task.cpus} \\\n    --domtblout ${id}.domtblout \\\n    ${hmm} \\\n    ${longOrf}/longest_orfs.pep\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    \"\"\"\n    hmmscan \\\n    --cpu ${task.cpus} \\\n    --domtblout ${id}.domtblout \\\n    ${hmm} \\\n    ${longOrf}/longest_orfs.pep\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "hmm",
            "h3f",
            "h3i",
            "h3m",
            "h3p",
            "longOrf",
            "id",
            "outdir",
            "transdecoder",
            "wf"
        ],
        "nb_inputs": 10,
        "outputs": [
            "id"
        ],
        "nb_outputs": 1,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/transdecoder/hmmer\", mode: 'copy'",
            "label 'homology'"
        ],
        "when": "wf.contains('transcript_pipeline') && transdecoder == true",
        "stub": ""
    },
    "run_transdecoder_predict": {
        "name_process": "run_transdecoder_predict",
        "string_process": "\nprocess run_transdecoder_predict {\n\n    tag { id }\n\n    publishDir \"${outdir}/transdecoder\", mode: 'copy'\n\n    label 'transd'\n\n    input:\n        tuple id, path(fastaFile), path(longOrfs), path(blast), path(hmmer)\n        val outdir\n        val transdecoder\n        val wf\n\n    output:\n        path longOrfs\n        path \"*.{gff3,bed,pep,cds}\"\n\n    when:\n        wf.contains('transcript_pipeline') && transdecoder == true\n    \n    script:\n    \"\"\"\n    TransDecoder.Predict -t ${fastaFile} \\\n    --retain_pfam_hits ${hmmer} \\\n    --retain_blastp_hits ${blast} \\\n    --output_dir ${longOrfs}\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    \"\"\"\n    TransDecoder.Predict -t ${fastaFile} \\\n    --retain_pfam_hits ${hmmer} \\\n    --retain_blastp_hits ${blast} \\\n    --output_dir ${longOrfs}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fastaFile",
            "longOrfs",
            "blast",
            "hmmer",
            "id",
            "outdir",
            "transdecoder",
            "wf"
        ],
        "nb_inputs": 8,
        "outputs": [
            "longOrfs"
        ],
        "nb_outputs": 1,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/transdecoder\", mode: 'copy'",
            "label 'transd'"
        ],
        "when": "wf.contains('transcript_pipeline') && transdecoder == true",
        "stub": ""
    },
    "run_consensus": {
        "name_process": "run_consensus",
        "string_process": "\nprocess run_consensus {\n    tag { id }\n\n    publishDir \"${outdir}/consensus/02_consensus/${ref.simpleName}\", mode: 'copy'\n\n    label 'consensus'\n\n    input:\n        tuple id, file(seqs), path(ref), file(idx), file(bam), file(bai)\n        val outdir\n        val mpileup\n        val norm\n        val filter\n        val view\n        val consensus\n        val wf\n\n    output:\n        path \"${id}.fasta\", emit: fasta\n        file \"${id}.vcf.gz\"\n\n    when:\n        wf.contains('consensus_pipeline')\n\n    script:\n        def opt_mpileup = mpileup ?: '-d 10 -Q 20 -q 20'\n        def opt_norm = norm ?: '-m +any'\n        def opt_filter = filter ?: '--SnpGap 5'\n        def opt_view = view ?: ''\n        def opt_consensus = consensus ?: '-H 1'\n        \n        \"\"\"\n        bcftools mpileup -Ou ${opt_mpileup} -f ${ref} ${bam} | \\\n        bcftools call -Ou -c - | \\\n        bcftools norm ${opt_norm} -f ${ref} -Ou | \\\n        bcftools filter -Ou ${opt_filter} | \\\n        bcftools view ${opt_view} | \\\n        bcftools sort --temp-dir \\${PWD} -Oz -o ${id}.vcf.gz\n\n        bcftools index ${id}.vcf.gz\n\n        bcftools consensus ${opt_consensus} -f ${ref} -o ${id}.fasta ${id}.vcf.gz\n        \"\"\"  \n}",
        "nb_lignes_process": 43,
        "string_script": "        def opt_mpileup = mpileup ?: '-d 10 -Q 20 -q 20'\n        def opt_norm = norm ?: '-m +any'\n        def opt_filter = filter ?: '--SnpGap 5'\n        def opt_view = view ?: ''\n        def opt_consensus = consensus ?: '-H 1'\n        \n        \"\"\"\n        bcftools mpileup -Ou ${opt_mpileup} -f ${ref} ${bam} | \\\n        bcftools call -Ou -c - | \\\n        bcftools norm ${opt_norm} -f ${ref} -Ou | \\\n        bcftools filter -Ou ${opt_filter} | \\\n        bcftools view ${opt_view} | \\\n        bcftools sort --temp-dir \\${PWD} -Oz -o ${id}.vcf.gz\n\n        bcftools index ${id}.vcf.gz\n\n        bcftools consensus ${opt_consensus} -f ${ref} -o ${id}.fasta ${id}.vcf.gz\n        \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "BCFtools"
        ],
        "tools_url": [
            "https://bio.tools/bcftools"
        ],
        "tools_dico": [
            {
                "name": "BCFtools",
                "uri": "https://bio.tools/bcftools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3516",
                            "term": "Genotyping experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant calling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3227",
                                    "term": "Variant mapping"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3498",
                                "term": "Sequence variations"
                            }
                        ]
                    }
                ],
                "description": "Set of utilities that manipulate variant calls in the Variant Call Format (VCF) and its binary counterpart BCF. All commands work transparently with both VCFs and BCFs, both uncompressed and BGZF-compressed.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "seqs",
            "idx",
            "bam",
            "bai",
            "ref",
            "id",
            "outdir",
            "mpileup",
            "norm",
            "filter",
            "view",
            "consensus",
            "wf"
        ],
        "nb_inputs": 13,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [
            "tag { id }",
            "publishDir \"${outdir}/consensus/02_consensus/${ref.simpleName}\", mode: 'copy'",
            "label 'consensus'"
        ],
        "when": "wf.contains('consensus_pipeline')",
        "stub": ""
    },
    "run_consensus_clean_up": {
        "name_process": "run_consensus_clean_up",
        "string_process": "\nprocess run_consensus_clean_up {\n\n    input:\n        file fasta\n        val cleanup\n        val outdir\n        val wf\n\n    when:\n        wf.contains('consensus_pipeline') && cleanup == true\n\n    script:\n        \"\"\"\n        find ${outdir} -type f -name '*.bam' -delete\n        find ${outdir} -type f -name '*.bam.bai' -delete\n        find ${outdir} -type f -name '*.vcf.gz' -delete\n        \"\"\"\n\n}",
        "nb_lignes_process": 18,
        "string_script": "        \"\"\"\n        find ${outdir} -type f -name '*.bam' -delete\n        find ${outdir} -type f -name '*.bam.bai' -delete\n        find ${outdir} -type f -name '*.vcf.gz' -delete\n        \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "cleanup",
            "outdir",
            "wf"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "danielyao12__Sanders-workflows",
        "directive": [],
        "when": "wf.contains('consensus_pipeline') && cleanup == true",
        "stub": ""
    }
}