{
    "run_trim": {
        "name_process": "run_trim",
        "string_process": "\nprocess run_trim {\n    conda 'conda_yml/trimmomatic_env.yml'\n    \n    executor='local'\n    label 'small'\n    \n    \"\"\"\n    trimmomatic -version\n    \"\"\"\n}",
        "nb_lignes_process": 9,
        "string_script": "\"\"\"\n    trimmomatic -version\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Trimmomatic"
        ],
        "tools_url": [
            "https://bio.tools/trimmomatic"
        ],
        "tools_dico": [
            {
                "name": "Trimmomatic",
                "uri": "https://bio.tools/trimmomatic",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            },
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ]
                    }
                ],
                "description": "A flexible read trimming tool for Illumina NGS data",
                "homepage": "http://www.usadellab.org/cms/index.php?page=trimmomatic"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/trimmomatic_env.yml'",
            "executor='local'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "run_low_complex": {
        "name_process": "run_low_complex",
        "string_process": "\nprocess run_low_complex {\n    conda 'conda_yml/bbmap_env.yml'\n    \n    executor='local'\n    label 'small'\n    \n    \"\"\"\n    bbmap.sh -version\n    bbduk.sh -version\n    \"\"\"\n}",
        "nb_lignes_process": 10,
        "string_script": "\"\"\"\n    bbmap.sh -version\n    bbduk.sh -version\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/bbmap_env.yml'",
            "executor='local'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "remove_phiX": {
        "name_process": "remove_phiX",
        "string_process": "\nprocess remove_phiX {\n    conda 'conda_yml/bbmap_env.yml'\n    \n    tag { pair_id }\n    \n    executor='slurm'\n    label 'medium'\n    \n    input:\n    set pair_id, file(reads) from reads_highC_ch\n\n    output:\n    set pair_id, file(\"${pair_id}*.trimmed.highC.phix.fq.gz\") into reads_phix_ch\n    file \"${pair_id}_bbduk_output.log\"\n\n    \"\"\"\n    \n    bbduk.sh threads=$task.cpus ref=${params.phix_dir}/${params.phix_file} k=31 hdist=1 \\\n    in1=${pair_id}_R1.trimmed.highC.fq.gz \\\n    in2=${pair_id}_R2.trimmed.highC.fq.gz\\\n    outm=${pair_id}.phix.reads.fq.gz \\\n    out1=${pair_id}.R1.trimmed.highC.phix.fq.gz \\\n    out2=${pair_id}.R2.trimmed.highC.phix.fq.gz \\\n    stats=stats.txt &> ${pair_id}_bbduk_output.log\n    \n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "\"\"\"\n    \n    bbduk.sh threads=$task.cpus ref=${params.phix_dir}/${params.phix_file} k=31 hdist=1 \\\n    in1=${pair_id}_R1.trimmed.highC.fq.gz \\\n    in2=${pair_id}_R2.trimmed.highC.fq.gz\\\n    outm=${pair_id}.phix.reads.fq.gz \\\n    out1=${pair_id}.R1.trimmed.highC.phix.fq.gz \\\n    out2=${pair_id}.R2.trimmed.highC.phix.fq.gz \\\n    stats=stats.txt &> ${pair_id}_bbduk_output.log\n    \n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_highC_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "reads_phix_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/bbmap_env.yml'",
            "tag { pair_id }",
            "executor='slurm'",
            "label 'medium'"
        ],
        "when": "",
        "stub": ""
    },
    "remove_host": {
        "name_process": "remove_host",
        "string_process": "\nprocess remove_host {\n    conda 'conda_yml/bbmap_env.yml'\n    publishDir \"${params.outdir}/03_clean_data\", mode: \"${params.savemode}\"\n    tag { pair_id }\n    \n    executor='slurm'\n    label 'large'\n\n    input:\n    set pair_id, file(reads) from reads_phix_ch\n\n    output:\n    set pair_id, file(\"${pair_id}.R{1,2}.clean.fq.gz\") into  clean_data_ch1,\n          clean_data_ch2, clean_data_ch3, clean_data_ch4, clean_data_ch5\n    file \"${pair_id}.*.human.fq.gz\"\n    file \"${pair_id}_bbmap_output.log\"\n\n    \"\"\"\n    \n    bbmap.sh -Xmx30g threads=$task.cpus \\\n    minid=0.95 maxindel=3 bwr=0.16 bw=12 \\\n    quickmatch fast minhits=2 \\\n    ref=${params.host_dir}/${params.host_file} \\\n    in=${pair_id}.R1.trimmed.highC.phix.fq.gz\\\n    in2=${pair_id}.R2.trimmed.highC.phix.fq.gz \\\n    outu=${pair_id}.R1.clean.fq.gz \\\n    outu2=${pair_id}.R2.clean.fq.gz \\\n    outm=${pair_id}.R1.human.fq.gz \\\n    outm2=${pair_id}.R2.human.fq.gz \\\n    statsfile=${pair_id}.human_result.txt &> ${pair_id}_bbmap_output.log\n    \n    \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "\"\"\"\n    \n    bbmap.sh -Xmx30g threads=$task.cpus \\\n    minid=0.95 maxindel=3 bwr=0.16 bw=12 \\\n    quickmatch fast minhits=2 \\\n    ref=${params.host_dir}/${params.host_file} \\\n    in=${pair_id}.R1.trimmed.highC.phix.fq.gz\\\n    in2=${pair_id}.R2.trimmed.highC.phix.fq.gz \\\n    outu=${pair_id}.R1.clean.fq.gz \\\n    outu2=${pair_id}.R2.clean.fq.gz \\\n    outm=${pair_id}.R1.human.fq.gz \\\n    outm2=${pair_id}.R2.human.fq.gz \\\n    statsfile=${pair_id}.human_result.txt &> ${pair_id}_bbmap_output.log\n    \n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads_phix_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "clean_data_ch1",
            "clean_data_ch2",
            "clean_data_ch3",
            "clean_data_ch4",
            "clean_data_ch5"
        ],
        "nb_outputs": 5,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/bbmap_env.yml'",
            "publishDir \"${params.outdir}/03_clean_data\", mode: \"${params.savemode}\"",
            "tag { pair_id }",
            "executor='slurm'",
            "label 'large'"
        ],
        "when": "",
        "stub": ""
    },
    "fastqc": {
        "name_process": "fastqc",
        "string_process": "\nprocess fastqc {\n    conda 'conda_yml/fastqc_env.yml'\n\n    publishDir \"${params.outdir}/01_fastqc\", mode: \"${params.savemode}\"\n    \n    tag \"FASTQC on $sample_id\"\n    \n    executor='slurm'\n    label 'small'\n\n    input:\n    set sample_id, file(reads) from read_pairs_ch\n\n    output:\n    file(\"fastqc_${sample_id}_logs\") into fastqc_raw_ch\n\n\n    script:\n    \"\"\"\n    \n    mkdir fastqc_${sample_id}_logs\n    fastqc -o fastqc_${sample_id}_logs -f fastq -q ${reads}\n    \n    \"\"\"  \n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    \n    mkdir fastqc_${sample_id}_logs\n    fastqc -o fastqc_${sample_id}_logs -f fastq -q ${reads}\n    \n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "read_pairs_ch"
        ],
        "nb_inputs": 1,
        "outputs": [
            "fastqc_raw_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/fastqc_env.yml'",
            "publishDir \"${params.outdir}/01_fastqc\", mode: \"${params.savemode}\"",
            "tag \"FASTQC on $sample_id\"",
            "executor='slurm'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "multiqc": {
        "name_process": "multiqc",
        "string_process": "\nprocess multiqc {\n    conda 'conda_yml/multiqc_env.yml'\n    publishDir \"${params.outdir}/02_multiqc\", mode: \"${params.savemode}\"\n    tag \"multiqc on fastqc\"\n    \n     executor='slurm'\n    label 'small'\n\n    input:\n    file('*') from fastqc_raw_ch.collect()\n    \n    output:\n    file('raw_data.multiqc_report.html')  \n     \n    script:\n    \"\"\"\n    \n    multiqc . \n    mv multiqc_report.html raw_data.multiqc_report.html\n    \n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    \n    multiqc . \n    mv multiqc_report.html raw_data.multiqc_report.html\n    \n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "fastqc_raw_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/multiqc_env.yml'",
            "publishDir \"${params.outdir}/02_multiqc\", mode: \"${params.savemode}\"",
            "tag \"multiqc on fastqc\"",
            "executor='slurm'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "run_coverage": {
        "name_process": "run_coverage",
        "string_process": "\nprocess run_coverage {\n    conda 'conda_yml/nonpareil_env.yml'\n    \n    executor='local'\n    label 'small'\n    \n    \"\"\"\n    nonpareil -V\n    \"\"\"\n}",
        "nb_lignes_process": 9,
        "string_script": "\"\"\"\n    nonpareil -V\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/nonpareil_env.yml'",
            "executor='local'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_coverage": {
        "name_process": "plot_coverage",
        "string_process": " process plot_coverage {\n    conda 'conda_yml/nonpareil_env.yml'\n    publishDir \"${params.outdir}/07_coverage_plots_clean_data\", mode: \"${params.savemode}\"\n    tag { \"all samples\" }\n\n    executor='slurm'\n    label 'small'\n\n    input:\n    file('*') from r_plotting_ch.collect()\n\n    output:\n    file \"*.png\"\n    file \"single_plots\"                                     \n\n    \"\"\"\n    \n    mkdir single_plots\n    Rscript $baseDir/Rscripts/process_npo_files.r\n    \n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "\"\"\"\n    \n    mkdir single_plots\n    Rscript $baseDir/Rscripts/process_npo_files.r\n    \n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "r_plotting_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/nonpareil_env.yml'",
            "publishDir \"${params.outdir}/07_coverage_plots_clean_data\", mode: \"${params.savemode}\"",
            "tag { \"all samples\" }",
            "executor='slurm'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "Average_gsize": {
        "name_process": "Average_gsize",
        "string_process": "\nprocess Average_gsize {\n    conda 'conda_yml/microbecensus_env.yml'\n    \n    executor='local'\n    label 'small'\n    \n    \"\"\"\n    run_microbe_census.py --version\n    \"\"\"\n}",
        "nb_lignes_process": 9,
        "string_script": "\"\"\"\n    run_microbe_census.py --version\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/microbecensus_env.yml'",
            "executor='local'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "plot_avgsizes": {
        "name_process": "plot_avgsizes",
        "string_process": "\nprocess plot_avgsizes {\n    conda 'conda_yml/microbecensus_env.yml'\n    publishDir \"${params.outdir}/09_average_genome_size_plots\", mode: \"${params.savemode}\"\n    tag { \"all_samples\" }\n\n    executor='slurm'\n    label 'small'\n\n    input:\n    file(\"*\") from avg_plot_ch.collect()\n\n    output:\n    file \"*.pdf\"\n\n    \"\"\"\n    \n    Rscript $baseDir/Rscripts/create_AVGsize_plots.r\n    \n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "\"\"\"\n    \n    Rscript $baseDir/Rscripts/create_AVGsize_plots.r\n    \n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "avg_plot_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/microbecensus_env.yml'",
            "publishDir \"${params.outdir}/09_average_genome_size_plots\", mode: \"${params.savemode}\"",
            "tag { \"all_samples\" }",
            "executor='slurm'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "hulk_calculation": {
        "name_process": "hulk_calculation",
        "string_process": "\nprocess hulk_calculation {\n    conda 'conda_yml/hulk_env.yml'\n    \n    executor='local'\n    label 'small'\n    \n    \"\"\"\n    hulk version\n    \"\"\"\n\n}",
        "nb_lignes_process": 10,
        "string_script": "\"\"\"\n    hulk version\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "HULK"
        ],
        "tools_url": [
            "https://bio.tools/HULK"
        ],
        "tools_dico": [
            {
                "name": "HULK",
                "uri": "https://bio.tools/HULK",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Microbial ecology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3837",
                            "term": "Metagenomic sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Environmental microbiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3837",
                            "term": "Shotgun metagenomic sequencing"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3472",
                                    "term": "k-mer counting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Histosketching Using Little Kmers (HULK) - tool that creates small, fixed-size sketches from streaming microbiome sequencing data, enabling rapid metagenomic dissimilarity analysis.",
                "homepage": "https://github.com/will-rowe/hulk"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/hulk_env.yml'",
            "executor='local'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "hulk_distance": {
        "name_process": "hulk_distance",
        "string_process": "\nprocess hulk_distance {\n    conda 'conda_yml/hulk_env.yml'\n    publishDir \"${params.outdir}/11_hulk_heatmap\", mode: \"${params.savemode}\"\n    tag { \"all samples\" }\n\n    executor='slurm'\n    label 'small'\n\n    input:\n    file (\"*\") from hulk_distance_ch.collect()\n\n    output:\n    file \"*.pdf\"\n    file(\"all_samples.Weighted_Jaccard.hulk-matrix.csv\")\n    \n    \"\"\"\n    \n    hulk smash -k 31 -m weightedjaccard -d ./ -o all_samples.Weighted_Jaccard\n    Rscript $baseDir/Rscripts/create_hulk_heatmap.r\n    \n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "\"\"\"\n    \n    hulk smash -k 31 -m weightedjaccard -d ./ -o all_samples.Weighted_Jaccard\n    Rscript $baseDir/Rscripts/create_hulk_heatmap.r\n    \n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "HULK"
        ],
        "tools_url": [
            "https://bio.tools/HULK"
        ],
        "tools_dico": [
            {
                "name": "HULK",
                "uri": "https://bio.tools/HULK",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Microbial ecology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3837",
                            "term": "Metagenomic sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Environmental microbiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3837",
                            "term": "Shotgun metagenomic sequencing"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3472",
                                    "term": "k-mer counting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Read binning"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning shotgun reads"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3798",
                                    "term": "Binning"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Histosketching Using Little Kmers (HULK) - tool that creates small, fixed-size sketches from streaming microbiome sequencing data, enabling rapid metagenomic dissimilarity analysis.",
                "homepage": "https://github.com/will-rowe/hulk"
            }
        ],
        "inputs": [
            "hulk_distance_ch"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/hulk_env.yml'",
            "publishDir \"${params.outdir}/11_hulk_heatmap\", mode: \"${params.savemode}\"",
            "tag { \"all samples\" }",
            "executor='slurm'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "Kraken_classification": {
        "name_process": "Kraken_classification",
        "string_process": "\nprocess Kraken_classification {\n    conda 'conda_yml/kraken2_env.yml'\n    \n    executor='local'\n    label 'small'\n    \n    \"\"\"\n    kraken2 --version\n    \"\"\"\n}",
        "nb_lignes_process": 9,
        "string_script": "\"\"\"\n    kraken2 --version\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "kraken2"
        ],
        "tools_url": [
            "https://bio.tools/kraken2"
        ],
        "tools_dico": [
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/kraken2_env.yml'",
            "executor='local'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "download_taxonomy": {
        "name_process": "download_taxonomy",
        "string_process": "\nprocess download_taxonomy {\n    conda 'conda_yml/kraken2_env.yml'\n    publishDir \"${params.kraken2.path}\", mode: \"${params.savemode}\"\n\n    executor='local'\n    \n    output:\n    file (\"${params.kraken2_dir}/taxonomy\") into taxonomy_ch\n\n    \"\"\"          \n    kraken2-build --download-taxonomy --threads 1 --db ${params.kraken2_dir}\n    \n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "\"\"\"          \n    kraken2-build --download-taxonomy --threads 1 --db ${params.kraken2_dir}\n    \n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [
            "taxonomy_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/kraken2_env.yml'",
            "publishDir \"${params.kraken2.path}\", mode: \"${params.savemode}\"",
            "executor='local'"
        ],
        "when": "",
        "stub": ""
    },
    "download_taxa": {
        "name_process": "download_taxa",
        "string_process": "\nprocess download_taxa {\n    conda 'conda_yml/kraken2_env.yml'\n                                                                     \n    tag \"$taxa\"\n\n    executor='local'\n\n\n    input:\n    val taxa from taxons\n\n\n    output:\n    file (\"${params.kraken2_dir}/library/$taxa\") into downloads_ch\n\n    \"\"\"\n    kraken2-build --download-library $taxa --threads 2 --no-masking --db ${params.kraken2_dir}\n    \n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "\"\"\"\n    kraken2-build --download-library $taxa --threads 2 --no-masking --db ${params.kraken2_dir}\n    \n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "taxons"
        ],
        "nb_inputs": 1,
        "outputs": [
            "downloads_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/kraken2_env.yml'",
            "tag \"$taxa\"",
            "executor='local'"
        ],
        "when": "",
        "stub": ""
    },
    "masking_taxa": {
        "name_process": "masking_taxa",
        "string_process": "\nprocess masking_taxa {\n    conda 'conda_yml/kraken2_env.yml'\n    publishDir \"${params.kraken2.path}\", mode: \"${params.savemode}\"\n    tag \"$taxa\"\n\n\n    executor='slurm'\n    label 'small'\n\n    input:\n    val taxa from taxons\n    file (\"${params.kraken2_dir}/library/$taxa\") from downloads_ch\n\n\n    output:\n    file (\"${params.kraken2_dir}/library/$taxa\") into database_ch\n    \n\n    \"\"\"\n    cd ${params.kraken2_dir}/library/$taxa\n    ls -lath \n    \n    #dustmasker commands\n    dustmasker -in library.fna -outfmt fasta | sed -e '/^>/!s/[a-z]/x/g' > library.fna.tmp\n    mv library.fna.tmp library.fna\n    touch library.fna.masked\n    cd -\n    \n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "\"\"\"\n    cd ${params.kraken2_dir}/library/$taxa\n    ls -lath \n    \n    #dustmasker commands\n    dustmasker -in library.fna -outfmt fasta | sed -e '/^>/!s/[a-z]/x/g' > library.fna.tmp\n    mv library.fna.tmp library.fna\n    touch library.fna.masked\n    cd -\n    \n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "taxons",
            "downloads_ch"
        ],
        "nb_inputs": 2,
        "outputs": [
            "database_ch"
        ],
        "nb_outputs": 1,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/kraken2_env.yml'",
            "publishDir \"${params.kraken2.path}\", mode: \"${params.savemode}\"",
            "tag \"$taxa\"",
            "executor='slurm'",
            "label 'small'"
        ],
        "when": "",
        "stub": ""
    },
    "build_Kraken2_db": {
        "name_process": "build_Kraken2_db",
        "string_process": "\nprocess build_Kraken2_db {\n    conda 'conda_yml/kraken2_env.yml'\n    \n    executor='slurm'\n    label 'large'\n    label 'longtime'\n\n    input:\n    val taxa from taxons\n    file (\"${params.kraken2_dir}/taxonomy\") from taxonomy_ch\n    file (\"${params.kraken2_dir}/library/$taxa\") from database_ch.collect()\n\n    \"\"\"\n    echo This is working\n\n    ls ${params.kraken2.path}/${params.kraken2_dir}\n    ls ${params.kraken2.path}/${params.kraken2_dir}/library\n    kraken2-build build --threads=8 --db ${params.kraken2.path}/${params.kraken2_dir}\n    #kraken2-build build --threads=24 --db ${params.kraken2.path}/${params.kraken2_dir}\n\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "\"\"\"\n    echo This is working\n\n    ls ${params.kraken2.path}/${params.kraken2_dir}\n    ls ${params.kraken2.path}/${params.kraken2_dir}/library\n    kraken2-build build --threads=8 --db ${params.kraken2.path}/${params.kraken2_dir}\n    #kraken2-build build --threads=24 --db ${params.kraken2.path}/${params.kraken2_dir}\n\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "taxons",
            "taxonomy_ch",
            "database_ch"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "NorwegianVeterinaryInstitute__Talos",
        "directive": [
            "conda 'conda_yml/kraken2_env.yml'",
            "executor='slurm'",
            "label 'large'",
            "label 'longtime'"
        ],
        "when": "",
        "stub": ""
    }
}