{
    "build_records": {
        "name_process": "build_records",
        "string_process": "\nprocess build_records {\n    stageInMode 'copy'\n    input:\n        tuple val(index), path('images/*') from ch_images\n    output:\n        tuple val(index), path('*.tfrecord') into ch_shards\n        tuple val(index), path('images/*', includeInputs: true) into ch_originals\n        tuple val(index), path('ratios.p') into ch_ratios\n        path('*.txt') into invalid_images optional true\n    when:\n        !params.masks\n    script:\n        \"\"\"\n        #!/usr/bin/env python\n\n        import logging\n        import os\n        import pickle\n\n        import tensorflow as tf\n\n        from data_record import create_record\n\n        logger = tf.get_logger()\n        logger.propagate = False\n        logger.setLevel('INFO')\n\n        images = tf.io.gfile.glob('images/*')\n\n        count = len(images)\n        invalid = 0\n        scale_factors = {}\n\n        with tf.io.TFRecordWriter('chunk.tfrecord') as writer:\n            for i in range(count):\n                filename = os.path.basename(images[i])\n                image_data = tf.io.gfile.GFile(images[i], 'rb').read()\n                try:\n                    image = tf.io.decode_image(image_data, channels=3)\n                except tf.errors.InvalidArgumentError:\n                    logger.info(\"%s is either corrupted or not a supported image format\" % filename)\n                    invalid += 1\n                    with open(\"invalid.txt\", \"a\") as broken:\n                        broken.write(f'{filename}\\\\n')\n                    continue\n\n                height, width = image.shape[:2]\n                max_dimension = 602\n                ratio = 1.0\n\n                if height * width > max_dimension**2:\n                    logger.info('%s: dimensions %d x %d are too large,' % (filename, height, width))\n                    ratio = max(height,width)/max_dimension\n                    new_height = int(height/ratio)\n                    new_width = int(width/ratio)\n                    logger.info('%s: resized to %d x %d (scale factor:%f)' % (filename, new_height, new_width, ratio))\n                    image = tf.image.resize(image, size=[new_height,new_width], preserve_aspect_ratio=False, antialias=True)\n                    image_data = tf.image.encode_png(tf.cast(image, tf.uint8)).numpy()\n                    tf.io.write_file(os.path.join(f'images/{filename}'), image_data)\n\n                scale_factors[filename] = ratio\n                record = create_record(image_data=image_data,\n                                    filename=filename,\n                                    height=height,\n                                    width=width,\n                                    ratio=ratio)\n\n                writer.write(record.SerializeToString())\n\n        pickle.dump(scale_factors, open(\"ratios.p\", \"wb\"))\n        \"\"\"\n}",
        "nb_lignes_process": 71,
        "string_script": "        \"\"\"\n        #!/usr/bin/env python\n\n        import logging\n        import os\n        import pickle\n\n        import tensorflow as tf\n\n        from data_record import create_record\n\n        logger = tf.get_logger()\n        logger.propagate = False\n        logger.setLevel('INFO')\n\n        images = tf.io.gfile.glob('images/*')\n\n        count = len(images)\n        invalid = 0\n        scale_factors = {}\n\n        with tf.io.TFRecordWriter('chunk.tfrecord') as writer:\n            for i in range(count):\n                filename = os.path.basename(images[i])\n                image_data = tf.io.gfile.GFile(images[i], 'rb').read()\n                try:\n                    image = tf.io.decode_image(image_data, channels=3)\n                except tf.errors.InvalidArgumentError:\n                    logger.info(\"%s is either corrupted or not a supported image format\" % filename)\n                    invalid += 1\n                    with open(\"invalid.txt\", \"a\") as broken:\n                        broken.write(f'{filename}\\\\n')\n                    continue\n\n                height, width = image.shape[:2]\n                max_dimension = 602\n                ratio = 1.0\n\n                if height * width > max_dimension**2:\n                    logger.info('%s: dimensions %d x %d are too large,' % (filename, height, width))\n                    ratio = max(height,width)/max_dimension\n                    new_height = int(height/ratio)\n                    new_width = int(width/ratio)\n                    logger.info('%s: resized to %d x %d (scale factor:%f)' % (filename, new_height, new_width, ratio))\n                    image = tf.image.resize(image, size=[new_height,new_width], preserve_aspect_ratio=False, antialias=True)\n                    image_data = tf.image.encode_png(tf.cast(image, tf.uint8)).numpy()\n                    tf.io.write_file(os.path.join(f'images/{filename}'), image_data)\n\n                scale_factors[filename] = ratio\n                record = create_record(image_data=image_data,\n                                    filename=filename,\n                                    height=height,\n                                    width=width,\n                                    ratio=ratio)\n\n                writer.write(record.SerializeToString())\n\n        pickle.dump(scale_factors, open(\"ratios.p\", \"wb\"))\n        \"\"\"",
        "nb_lignes_script": 58,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_images"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_shards",
            "ch_originals",
            "ch_ratios",
            "invalid_images"
        ],
        "nb_outputs": 4,
        "name_workflow": "phue__aradeepopsis",
        "directive": [
            "stageInMode 'copy'"
        ],
        "when": "!params.masks",
        "stub": ""
    },
    "run_predictions_DPP": {
        "name_process": "run_predictions_DPP",
        "string_process": " process run_predictions_DPP {\n        input:\n            path(\"vegetation-segmentation/*\") from ch_model.collect()\n            tuple val(index), path(shard) from ch_shards\n        output:\n            tuple val(index), path('*.png') into ch_predictions\n        when:\n            !params.masks\n        script:\n            \"\"\"\n            #!/usr/bin/env python\n\n            import logging\n\n            import numpy as np\n            import tensorflow as tf\n            import deepplantphenomics as dpp\n\n            from cv2 import imwrite\n            from data_record import parse_record\n\n            logger = tf.get_logger()\n            logger.propagate = False\n            logger.setLevel('INFO')\n\n            pretrainedDPP = dpp.networks.vegetationSegmentationNetwork(8)\n\n            def checkpoint_override(net, checkpoint_path, num_classes):\n                if num_classes != 2:\n                    net.model.set_num_segmentation_classes(num_classes)\n                net.model._add_layers_to_graph()\n                saver = tf.compat.v1.train.Saver()\n                saver.restore(net.model._session, tf.train.latest_checkpoint(checkpoint_path))\n\n            with pretrainedDPP.model._graph.as_default():\n                checkpoint_override(pretrainedDPP,'vegetation-segmentation/', 2)\n                dataset = (\n                tf.data.TFRecordDataset('${shard}')\n                .map(parse_record)\n                .batch(1)\n                .prefetch(1))\n\n                samples = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n\n                for i in samples:\n                    img, filename = tf.cast(samples['original'],tf.float32),  samples['filename']\n                    raw = pretrainedDPP.model.forward_pass(img, deterministic=True)\n                    try:\n                        while True:\n                            prediction, name = pretrainedDPP.model._session.run([raw,filename])\n                            logger.info(\"Running prediction on image %s\" % name)\n                            seg = np.interp(prediction, (prediction.min(), prediction.max()), (0, 1))\n                            mask = (np.squeeze(seg) > 0.5).astype(np.uint8)\n                            name = name[0].decode('utf-8').rsplit('.', 1)[0]\n                            imwrite(f'{name}.png', mask)\n                    except tf.errors.OutOfRangeError:\n                        pass\n            \"\"\"\n    }",
        "nb_lignes_process": 57,
        "string_script": "            \"\"\"\n            #!/usr/bin/env python\n\n            import logging\n\n            import numpy as np\n            import tensorflow as tf\n            import deepplantphenomics as dpp\n\n            from cv2 import imwrite\n            from data_record import parse_record\n\n            logger = tf.get_logger()\n            logger.propagate = False\n            logger.setLevel('INFO')\n\n            pretrainedDPP = dpp.networks.vegetationSegmentationNetwork(8)\n\n            def checkpoint_override(net, checkpoint_path, num_classes):\n                if num_classes != 2:\n                    net.model.set_num_segmentation_classes(num_classes)\n                net.model._add_layers_to_graph()\n                saver = tf.compat.v1.train.Saver()\n                saver.restore(net.model._session, tf.train.latest_checkpoint(checkpoint_path))\n\n            with pretrainedDPP.model._graph.as_default():\n                checkpoint_override(pretrainedDPP,'vegetation-segmentation/', 2)\n                dataset = (\n                tf.data.TFRecordDataset('${shard}')\n                .map(parse_record)\n                .batch(1)\n                .prefetch(1))\n\n                samples = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n\n                for i in samples:\n                    img, filename = tf.cast(samples['original'],tf.float32),  samples['filename']\n                    raw = pretrainedDPP.model.forward_pass(img, deterministic=True)\n                    try:\n                        while True:\n                            prediction, name = pretrainedDPP.model._session.run([raw,filename])\n                            logger.info(\"Running prediction on image %s\" % name)\n                            seg = np.interp(prediction, (prediction.min(), prediction.max()), (0, 1))\n                            mask = (np.squeeze(seg) > 0.5).astype(np.uint8)\n                            name = name[0].decode('utf-8').rsplit('.', 1)[0]\n                            imwrite(f'{name}.png', mask)\n                    except tf.errors.OutOfRangeError:\n                        pass\n            \"\"\"",
        "nb_lignes_script": 48,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_model",
            "ch_shards"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_predictions"
        ],
        "nb_outputs": 1,
        "name_workflow": "phue__aradeepopsis",
        "directive": [],
        "when": "!params.masks",
        "stub": ""
    },
    "run_predictions": {
        "name_process": "run_predictions",
        "string_process": " process run_predictions {\n        input:\n            path(model) from ch_model.collect()\n            tuple val(index), path(shard) from ch_shards\n        output:\n            tuple val(index), path('*.png') into ch_predictions\n        when:\n            !params.masks\n        script:\n            \"\"\"\n            #!/usr/bin/env python\n\n            import logging\n\n            import tensorflow as tf\n\n            from data_record import parse_record\n            from frozen_graph import wrap_frozen_graph\n\n            logger = tf.get_logger()\n            logger.propagate = False\n            logger.setLevel('INFO')\n\n            with tf.io.gfile.GFile('${model}', \"rb\") as f:\n                graph_def = tf.compat.v1.GraphDef()\n                graph_def.ParseFromString(f.read())\n\n            predict = wrap_frozen_graph(\n                graph_def,\n                inputs='ImageTensor:0',\n                outputs='SemanticPredictions:0')\n\n            dataset = (\n                tf.data.TFRecordDataset('${shard}')\n                .map(parse_record)\n                .batch(1)\n                .prefetch(1)\n                .enumerate(start=1))\n\n            size = len(list(dataset))\n\n            for index, sample in dataset:\n                filename = sample['filename'].numpy()[0].decode('utf-8')\n                logger.info(\"Running prediction on image %s (%d/%d)\" % (filename,index,size))\n                raw_segmentation = predict(sample['original'])[0][:, :, None]\n                output = tf.image.encode_png(tf.cast(raw_segmentation, tf.uint8))\n                tf.io.write_file(filename.rsplit('.', 1)[0] + '.png',output)\n            \"\"\"\n    }",
        "nb_lignes_process": 47,
        "string_script": "            \"\"\"\n            #!/usr/bin/env python\n\n            import logging\n\n            import tensorflow as tf\n\n            from data_record import parse_record\n            from frozen_graph import wrap_frozen_graph\n\n            logger = tf.get_logger()\n            logger.propagate = False\n            logger.setLevel('INFO')\n\n            with tf.io.gfile.GFile('${model}', \"rb\") as f:\n                graph_def = tf.compat.v1.GraphDef()\n                graph_def.ParseFromString(f.read())\n\n            predict = wrap_frozen_graph(\n                graph_def,\n                inputs='ImageTensor:0',\n                outputs='SemanticPredictions:0')\n\n            dataset = (\n                tf.data.TFRecordDataset('${shard}')\n                .map(parse_record)\n                .batch(1)\n                .prefetch(1)\n                .enumerate(start=1))\n\n            size = len(list(dataset))\n\n            for index, sample in dataset:\n                filename = sample['filename'].numpy()[0].decode('utf-8')\n                logger.info(\"Running prediction on image %s (%d/%d)\" % (filename,index,size))\n                raw_segmentation = predict(sample['original'])[0][:, :, None]\n                output = tf.image.encode_png(tf.cast(raw_segmentation, tf.uint8))\n                tf.io.write_file(filename.rsplit('.', 1)[0] + '.png',output)\n            \"\"\"",
        "nb_lignes_script": 38,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_model",
            "ch_shards"
        ],
        "nb_inputs": 2,
        "outputs": [
            "ch_predictions"
        ],
        "nb_outputs": 1,
        "name_workflow": "phue__aradeepopsis",
        "directive": [],
        "when": "!params.masks",
        "stub": ""
    },
    "extract_traits": {
        "name_process": "extract_traits",
        "string_process": "\nprocess extract_traits {\n    publishDir \"${params.outdir}/diagnostics\", mode: 'copy',\n        saveAs: { filename ->\n                if (filename.startsWith(\"mask_\")) \"mask/$filename\"\n                else if (filename.startsWith(\"overlay_\")) \"overlay/$filename\"\n                else if (filename.startsWith(\"crop_\")) \"crop/$filename\"\n                else if (filename.startsWith(\"hull_\")) \"convex_hull/$filename\"\n                else null\n            }\n\n    input:\n        tuple val(index), path(\"original_images/*\"), path(\"raw_masks/*\"), path(ratios) from ch_segmentations\n\n    output:\n        path('*.csv') into ch_results\n        tuple val(index), val('mask'), path('mask_*') into ch_masks optional true\n        tuple val(index), val('overlay'), path('overlay_*') into ch_overlays optional true\n        tuple val(index), val('crop'), path('crop_*') into ch_crops optional true\n        tuple val(index), val('hull'), path('hull_*') into ch_hull optional true\n\n    script:\n        def scale_ratios = ratios.name != 'ratios.p' ? \"None\" : \"pickle.load(open('ratios.p','rb'))\"\n        def cmap = params.warhol ? \"[[250,140,130],[119,204,98],[240,216,72],[82,128,199],[242,58,58]]\" : \"None\"\n        \"\"\"\n        #!/usr/bin/env python\n\n        import os\n        import pickle\n\n        from traits import measure_traits, draw_diagnostics, load_images\n\n        ratios = ${scale_ratios}\n        masks, originals = load_images()\n\n        for index, name in enumerate(originals.files):\n            measure_traits(masks[index],\n                        originals[index],\n                        ratios[os.path.basename(name)] if ratios is not None else 1.0,\n                        os.path.basename(name),\n                        ignore_label=${ignore_label},\n                        labels=dict(${labels}))\n            draw_diagnostics(masks[index],\n                            originals[index],\n                            os.path.basename(name),\n                            save_overlay=${params.save_overlay.toString().capitalize()},\n                            save_mask=${params.save_mask.toString().capitalize()},\n                            save_rosette=${params.save_rosette.toString().capitalize()},\n                            save_hull=${params.save_hull.toString().capitalize()},\n                            ignore_label=${ignore_label},\n                            labels=dict(${labels}),\n                            colormap=${cmap})\n        \"\"\"\n}",
        "nb_lignes_process": 52,
        "string_script": "        def scale_ratios = ratios.name != 'ratios.p' ? \"None\" : \"pickle.load(open('ratios.p','rb'))\"\n        def cmap = params.warhol ? \"[[250,140,130],[119,204,98],[240,216,72],[82,128,199],[242,58,58]]\" : \"None\"\n        \"\"\"\n        #!/usr/bin/env python\n\n        import os\n        import pickle\n\n        from traits import measure_traits, draw_diagnostics, load_images\n\n        ratios = ${scale_ratios}\n        masks, originals = load_images()\n\n        for index, name in enumerate(originals.files):\n            measure_traits(masks[index],\n                        originals[index],\n                        ratios[os.path.basename(name)] if ratios is not None else 1.0,\n                        os.path.basename(name),\n                        ignore_label=${ignore_label},\n                        labels=dict(${labels}))\n            draw_diagnostics(masks[index],\n                            originals[index],\n                            os.path.basename(name),\n                            save_overlay=${params.save_overlay.toString().capitalize()},\n                            save_mask=${params.save_mask.toString().capitalize()},\n                            save_rosette=${params.save_rosette.toString().capitalize()},\n                            save_hull=${params.save_hull.toString().capitalize()},\n                            ignore_label=${ignore_label},\n                            labels=dict(${labels}),\n                            colormap=${cmap})\n        \"\"\"",
        "nb_lignes_script": 30,
        "language_script": "python",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_segmentations"
        ],
        "nb_inputs": 1,
        "outputs": [
            "ch_results",
            "ch_masks",
            "ch_overlays",
            "ch_crops",
            "ch_hull"
        ],
        "nb_outputs": 5,
        "name_workflow": "phue__aradeepopsis",
        "directive": [
            "publishDir \"${params.outdir}/diagnostics\", mode: 'copy' , saveAs: { filename -> if (filename.startsWith(\"mask_\")) \"mask/$filename\" else if (filename.startsWith(\"overlay_\")) \"overlay/$filename\" else if (filename.startsWith(\"crop_\")) \"crop/$filename\" else if (filename.startsWith(\"hull_\")) \"convex_hull/$filename\" else null }"
        ],
        "when": "",
        "stub": ""
    },
    "draw_diagnostics": {
        "name_process": "draw_diagnostics",
        "string_process": "\nprocess draw_diagnostics {\n    publishDir \"${params.outdir}/diagnostics\", mode: 'copy',\n        saveAs: { filename ->\n                    if (filename.startsWith(\"mask_\")) \"summary/mask/$filename\"\n                    else if (filename.startsWith(\"overlay_\")) \"summary/overlay/$filename\"\n                    else if (filename.startsWith(\"crop_\")) \"summary/crop/$filename\"\n                    else null\n                }\n    input:\n        tuple val(index), val(type), path(image) from ch_masks.concat(ch_overlays,ch_crops)\n    output:\n        path('*.jpeg')\n    when:\n        params.summary_diagnostics\n\n    script:\n        def polaroid = params.polaroid ? '+polaroid' : ''\n        \"\"\"\n        #!/usr/bin/env bash\n\n        montage * -background 'black' -font Ubuntu-Condensed -geometry 200x200 -set label '%t' -fill white ${polaroid} \"${type}_chunk_${index}.jpeg\"\n        \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "        def polaroid = params.polaroid ? '+polaroid' : ''\n        \"\"\"\n        #!/usr/bin/env bash\n\n        montage * -background 'black' -font Ubuntu-Condensed -geometry 200x200 -set label '%t' -fill white ${polaroid} \"${type}_chunk_${index}.jpeg\"\n        \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "denvax",
            "TraceMontage"
        ],
        "tools_url": [
            "https://bio.tools/denvax",
            "https://bio.tools/TraceMontage"
        ],
        "tools_dico": [
            {
                "name": "denvax",
                "uri": "https://bio.tools/denvax",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3379",
                            "term": "Preclinical and clinical studies"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatric medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "https://en.wikipedia.org/wiki/Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3399",
                            "term": "Geriatrics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0560",
                                    "term": "DNA vaccine design"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Serostatus testing and dengue vaccine cost-benefit thresholds | R package for manuscript \"Serostatus Testing & Dengue Vaccine Cost Benefit Thresholds\"",
                "homepage": "https://cran.r-project.org/web/packages/denvax/index.html"
            },
            {
                "name": "TraceMontage",
                "uri": "https://bio.tools/TraceMontage",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3304",
                            "term": "Neurobiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3382",
                            "term": "Imaging"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3552",
                                    "term": "Microscope image visualisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A method for merging multiple independent neuronal traces.",
                "homepage": "https://www.cai-lab.org/tracemontage"
            }
        ],
        "inputs": [
            "ch_masks",
            "ch_overlays",
            "ch_crops"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "phue__aradeepopsis",
        "directive": [
            "publishDir \"${params.outdir}/diagnostics\", mode: 'copy' , saveAs: { filename -> if (filename.startsWith(\"mask_\")) \"summary/mask/$filename\" else if (filename.startsWith(\"overlay_\")) \"summary/overlay/$filename\" else if (filename.startsWith(\"crop_\")) \"summary/crop/$filename\" else null }"
        ],
        "when": "params.summary_diagnostics",
        "stub": ""
    },
    "launch_shiny": {
        "name_process": "launch_shiny",
        "string_process": "\nprocess launch_shiny {\n    containerOptions { workflow.profile.contains('singularity') ? '' : '-p 44333:44333' }\n    executor 'local'\n    cache false\n\n    input:\n        path ch_resultfile\n        path app from ch_shinyapp\n        env LABELS from labels\n    when:\n        params.shiny\n    script:\n        def ip = \"uname\".execute().text.trim() == \"Darwin\" ? \"localhost\" : \"hostname -i\".execute().text.trim()\n        log.error\"\"\"\n        Visit the shiny server running at ${\"http://\"+ip+':44333'} to inspect the results.\n        Closing the browser window will terminate the pipeline.\n        \"\"\".stripIndent()\n        \"\"\"\n        R -e \"shiny::runApp('${app}', port=44333, host='0.0.0.0')\"\n        \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "        def ip = \"uname\".execute().text.trim() == \"Darwin\" ? \"localhost\" : \"hostname -i\".execute().text.trim()\n        log.error\"\"\"\n        Visit the shiny server running at ${\"http://\"+ip+':44333'} to inspect the results.\n        Closing the browser window will terminate the pipeline.\n        \"\"\".stripIndent()\n        \"\"\"\n        R -e \"shiny::runApp('${app}', port=44333, host='0.0.0.0')\"\n        \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ch_resultfile",
            "ch_shinyapp",
            "labels"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "phue__aradeepopsis",
        "directive": [
            "containerOptions { workflow.profile.contains('singularity') ? '' : '-p 44333:44333' }",
            "executor 'local'",
            "cache false"
        ],
        "when": "params.shiny",
        "stub": ""
    }
}