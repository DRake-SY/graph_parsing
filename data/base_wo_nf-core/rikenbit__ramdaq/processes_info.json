{
    "FASTQC": {
        "name_process": "FASTQC",
        "string_process": "\nprocess FASTQC {\n    label 'process_low'\n    tag \"$name\"\n    \n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy',\n        saveAs: { filename ->\n                      filename.indexOf(\".zip\") > 0 ? \"zips/$filename\" : \"$filename\"\n                }\n\n    input:\n    tuple val(name), file(reads)\n\n    output:\n    path \"*_fastqc.{zip,html}\", emit: fastqc_results\n\n    script:\n    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n    def prefix_1 = options.suffix ? \"${name}_1${options.suffix}\" : \"${name}_1\"\n    def prefix_2 = options.suffix ? \"${name}_2${options.suffix}\" : \"${name}_2\"\n\n    if (params.single_end) {\n        newfastq = (reads.getName() =~ /\\.gz$/) ? \"${prefix}.fastq.gz\" : \"${prefix}.fastq\"\n        \"\"\"\n        if [ ! -f $newfastq ]; then\n            ln -s $reads $newfastq\n        fi\n        fastqc $options.args --threads $task.cpus $newfastq\n        \"\"\"\n    } else {\n        newfastq1 = (reads[0].getName() =~ /\\.gz$/) ? \"${prefix_1}.fastq.gz\" : \"${prefix_1}}.fastq\"\n        newfastq2 = (reads[1].getName() =~ /\\.gz$/) ? \"${prefix_2}.fastq.gz\" : \"${prefix_2}.fastq\"\n        \"\"\"\n        if [ ! -f $newfastq1 ]; then\n            ln -s ${reads[0]} $newfastq1\n            ln -s ${reads[1]} $newfastq2\n        fi\n        fastqc $options.args --threads $task.cpus $newfastq1\n        fastqc $options.args --threads $task.cpus $newfastq2\n        \"\"\"\n    }",
        "nb_lignes_process": 39,
        "string_script": "    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n    def prefix_1 = options.suffix ? \"${name}_1${options.suffix}\" : \"${name}_1\"\n    def prefix_2 = options.suffix ? \"${name}_2${options.suffix}\" : \"${name}_2\"\n\n    if (params.single_end) {\n        newfastq = (reads.getName() =~ /\\.gz$/) ? \"${prefix}.fastq.gz\" : \"${prefix}.fastq\"\n        \"\"\"\n        if [ ! -f $newfastq ]; then\n            ln -s $reads $newfastq\n        fi\n        fastqc $options.args --threads $task.cpus $newfastq\n        \"\"\"\n    } else {\n        newfastq1 = (reads[0].getName() =~ /\\.gz$/) ? \"${prefix_1}.fastq.gz\" : \"${prefix_1}}.fastq\"\n        newfastq2 = (reads[1].getName() =~ /\\.gz$/) ? \"${prefix_2}.fastq.gz\" : \"${prefix_2}.fastq\"\n        \"\"\"\n        if [ ! -f $newfastq1 ]; then\n            ln -s ${reads[0]} $newfastq1\n            ln -s ${reads[1]} $newfastq2\n        fi\n        fastqc $options.args --threads $task.cpus $newfastq1\n        fastqc $options.args --threads $task.cpus $newfastq2\n        \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "name",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "tag \"$name\"",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy' , saveAs: { filename -> filename.indexOf(\".zip\") > 0 ? \"zips/$filename\" : \"$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "GET_SOFTWARE_VERSIONS": {
        "name_process": "GET_SOFTWARE_VERSIONS",
        "string_process": "\nprocess GET_SOFTWARE_VERSIONS {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true,\n        saveAs: { filename ->\n                  if (filename.indexOf(\".csv\") > 0) filename\n                  else null\n            }\n    \n    output:\n    path \"software_versions_mqc.yaml\", emit: software_versions_yaml\n    path \"software_versions.csv\"\n    \n    script:\n    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    fastq-mcf -V > v_fastqmcf.txt\n    hisat2 --version > v_hisat2.txt\n    samtools --version > v_samtools.txt\n    bam2wig.py --version > v_bam2wig.txt\n    bamtools --version > v_bamtools.txt\n    read_distribution.py --version > v_read_distribution.txt\n    infer_experiment.py --version > v_infer_experiment.txt\n    inner_distance.py --version > v_inner_distance.txt\n    junction_annotation.py --version > v_junction_annotation.txt\n    featureCounts -v > v_featurecounts.txt 2>&1\n    rsem-calculate-expression --version > v_rsem.txt\n    Rscript -e \"write(x=as.character(R.version.string), file='v_R.txt')\"\n    Rscript -e \"library(edgeR); write(x=as.character(packageVersion('edgeR')), file='v_edgeR.txt')\"\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n    echo $workflow.manifest.version > v_pipeline.txt\n    echo $workflow.nextflow.version > v_nextflow.txt\n    fastqc --version > v_fastqc.txt\n    fastq-mcf -V > v_fastqmcf.txt\n    hisat2 --version > v_hisat2.txt\n    samtools --version > v_samtools.txt\n    bam2wig.py --version > v_bam2wig.txt\n    bamtools --version > v_bamtools.txt\n    read_distribution.py --version > v_read_distribution.txt\n    infer_experiment.py --version > v_infer_experiment.txt\n    inner_distance.py --version > v_inner_distance.txt\n    junction_annotation.py --version > v_junction_annotation.txt\n    featureCounts -v > v_featurecounts.txt 2>&1\n    rsem-calculate-expression --version > v_rsem.txt\n    Rscript -e \"write(x=as.character(R.version.string), file='v_R.txt')\"\n    Rscript -e \"library(edgeR); write(x=as.character(packageVersion('edgeR')), file='v_edgeR.txt')\"\n    multiqc --version > v_multiqc.txt\n    scrape_software_versions.py &> software_versions_mqc.yaml\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [
            "FastQC",
            "HISAT2",
            "SAMtools",
            "BamTools",
            "FeatureCounts",
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc",
            "https://bio.tools/hisat2",
            "https://bio.tools/samtools",
            "https://bio.tools/bamtools",
            "https://bio.tools/featurecounts",
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            },
            {
                "name": "HISAT2",
                "uri": "https://bio.tools/hisat2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).",
                "homepage": "https://ccb.jhu.edu/software/hisat2/index.shtml"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BamTools",
                "uri": "https://bio.tools/bamtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BamTools provides a fast, flexible C++ API & toolkit for reading, writing, and managing BAM files.",
                "homepage": "https://github.com/pezmaster31/bamtools"
            },
            {
                "name": "FeatureCounts",
                "uri": "https://bio.tools/featurecounts",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3793",
                                    "term": "Read summarisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "featureCounts is a very efficient read quantifier. It can be used to summarize RNA-seq reads and gDNA-seq reads to a variety of genomic features such as genes, exons, promoters, gene bodies and genomic bins. It is included in the Bioconductor Rsubread package and also in the SourceForge Subread package.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rsubread.html"
            },
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true , saveAs: { filename -> if (filename.indexOf(\".csv\") > 0) filename else null }"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_ASSIGNEDGENOME_RATE": {
        "name_process": "CALC_ASSIGNEDGENOME_RATE",
        "string_process": "\nprocess CALC_ASSIGNEDGENOME_RATE {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(totalseq_merged)\n    file(totalread_merged)\n    file(assignedgenome_header)\n    file(assignedgenome_header_gstat)\n    \n    output:\n    path \"*.{txt,pdf}\", emit: assignedgenome_rate_results\n    path \"barplot_*.csv\", emit: assignedgenome_rate_barplot\n    path \"gstat_*.csv\", emit: assignedgenome_rate_gstat\n    \n    script:\n    def is_pairedend = params.single_end ? \"False\" : \"True\"\n    \"\"\"\n    drawplot_assignedgenomerate_bar.r $totalseq_merged $totalread_merged $is_pairedend\n    cp barplot_assignedgenome_rate.csv gstat_assignedgenome_rate.csv\n    cat $assignedgenome_header barplot_assignedgenome_rate.csv >> tmp_file\n    mv tmp_file barplot_assignedgenome_rate_mqc.csv\n    cat $assignedgenome_header_gstat gstat_assignedgenome_rate.csv >> tmp_file\n    mv tmp_file gstat_assignedgenome_rate_mqc.csv\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    def is_pairedend = params.single_end ? \"False\" : \"True\"\n    \"\"\"\n    drawplot_assignedgenomerate_bar.r $totalseq_merged $totalread_merged $is_pairedend\n    cp barplot_assignedgenome_rate.csv gstat_assignedgenome_rate.csv\n    cat $assignedgenome_header barplot_assignedgenome_rate.csv >> tmp_file\n    mv tmp_file barplot_assignedgenome_rate_mqc.csv\n    cat $assignedgenome_header_gstat gstat_assignedgenome_rate.csv >> tmp_file\n    mv tmp_file gstat_assignedgenome_rate_mqc.csv\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "totalseq_merged",
            "totalread_merged",
            "assignedgenome_header",
            "assignedgenome_header_gstat"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_RSEM": {
        "name_process": "MERGE_RSEM",
        "string_process": "\nprocess MERGE_RSEM {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(input_files)\n    \n    output:\n    path \"merged_*.txt\", emit: merged_counts\n    \n    script:\n    def prefix = \"merged_rsem_${options.suffix}_TPM\"\n    def get_gene_ids = \"<(tail $options.args ${input_files[0]} | cut $options.args2 )\"\n    def get_counts = input_files.collect{filename ->\n        \"<(tail $options.args ${filename} | sed 's:TPM:${filename}:' | sed 's:.${options.suffix}.results::' | cut $options.args3)\"}.join(\" \")\n\n    \"\"\"\n    paste $get_gene_ids $get_counts > ${prefix}.txt\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    def prefix = \"merged_rsem_${options.suffix}_TPM\"\n    def get_gene_ids = \"<(tail $options.args ${input_files[0]} | cut $options.args2 )\"\n    def get_counts = input_files.collect{filename ->\n        \"<(tail $options.args ${filename} | sed 's:TPM:${filename}:' | sed 's:.${options.suffix}.results::' | cut $options.args3)\"}.join(\" \")\n\n    \"\"\"\n    paste $get_gene_ids $get_counts > ${prefix}.txt\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_SUMMARYFILE": {
        "name_process": "MERGE_SUMMARYFILE",
        "string_process": "\nprocess MERGE_SUMMARYFILE {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(input_files)\n    \n    output:\n    path \"merged_*.txt\", emit: merged_summary\n    \n    script:\n    def prefix = \"merged_${options.suffix}\"\n    command = input_files.collect{filename ->\n        \"awk '{if (FNR==1){print FILENAME, FNR, NR, \\$0}}' ${filename} | sed '$options.args' | cut $options.args2 --delim=\\\" \\\" >> ${prefix}.txt\"}.join(\" && \")\n    \"\"\"\n    $command\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    def prefix = \"merged_${options.suffix}\"\n    command = input_files.collect{filename ->\n        \"awk '{if (FNR==1){print FILENAME, FNR, NR, \\$0}}' ${filename} | sed '$options.args' | cut $options.args2 --delim=\\\" \\\" >> ${prefix}.txt\"}.join(\" && \")\n    \"\"\"\n    $command\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [
            "COMMAND"
        ],
        "tools_url": [
            "https://bio.tools/COMMAND"
        ],
        "tools_dico": [
            {
                "name": "COMMAND",
                "uri": "https://bio.tools/COMMAND",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Web-based application used to download, collect and manage gene expression data from public databases.",
                "homepage": "https://github.com/marcomoretto/command"
            }
        ],
        "inputs": [
            "input_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_FEATURECOUNTS_MAPRATE": {
        "name_process": "CALC_FEATURECOUNTS_MAPRATE",
        "string_process": "\nprocess CALC_FEATURECOUNTS_MAPRATE {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(totalseq_merged)\n    file(counts_merged)\n    file(fcounts_maprate_header)\n    file(fcounts_maprate_header_gstat)\n    \n    output:\n    path \"*.{txt,pdf}\", emit: fcounts_maprate_results\n    path \"barplot_*.csv\", emit: fcounts_maprate_barplot\n    path \"gstat_*.csv\", emit: fcounts_maprate_gstat\n\n    script:\n    def prefix = \"assignedrate_${options.suffix}\"\n    def is_pairedend = params.single_end ? \"False\" : \"True\"\n    \"\"\"\n    drawplot_fcount_mappedrate_bar.r $totalseq_merged $counts_merged $is_pairedend ${options.suffix}\n    cp barplot_${prefix}.csv gstat_${prefix}.csv\n    cat $fcounts_maprate_header barplot_${prefix}.csv >> tmp_file\n    mv tmp_file barplot_${prefix}_mqc.csv\n    cat $fcounts_maprate_header_gstat gstat_${prefix}.csv >> tmp_file\n    mv tmp_file gstat_${prefix}_mqc.csv\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    def prefix = \"assignedrate_${options.suffix}\"\n    def is_pairedend = params.single_end ? \"False\" : \"True\"\n    \"\"\"\n    drawplot_fcount_mappedrate_bar.r $totalseq_merged $counts_merged $is_pairedend ${options.suffix}\n    cp barplot_${prefix}.csv gstat_${prefix}.csv\n    cat $fcounts_maprate_header barplot_${prefix}.csv >> tmp_file\n    mv tmp_file barplot_${prefix}_mqc.csv\n    cat $fcounts_maprate_header_gstat gstat_${prefix}.csv >> tmp_file\n    mv tmp_file gstat_${prefix}_mqc.csv\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "totalseq_merged",
            "counts_merged",
            "fcounts_maprate_header",
            "fcounts_maprate_header_gstat"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "BAM2WIG": {
        "name_process": "BAM2WIG",
        "string_process": "\nprocess BAM2WIG  {\n    label 'process_medium'\n    tag \"$name\"\n\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n \n    input:\n    tuple val(name), file(bam), file(bai)\n    file chrsize\n\n    output:\n    file \"*.bw\"\n    file \"*.wig\"\n\n    script:\n    \"\"\"\n    bam2wig.py -i ${bam} -s $chrsize -u -o ${bam.baseName}\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    bam2wig.py -i ${bam} -s $chrsize -u -o ${bam.baseName}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "name",
            "bam",
            "bai",
            "chrsize"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_medium'",
            "tag \"$name\"",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "RSEM_BOWTIE2": {
        "name_process": "RSEM_BOWTIE2",
        "string_process": "\nprocess RSEM_BOWTIE2  {\n    tag \"$name\"\n    label 'process_high'\n    \n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true,\n        saveAs: { filename ->\n                    filename.indexOf(\".log\") > 0 ? \"logs/$filename\" : \"$filename\"\n                }\n\n    input:\n    tuple val(name), file(bam), file(bai)                  \n    tuple val(name), file(reads)\n    path rsem_indices\n\n    output:\n    path \"*.isoforms.results\", emit: rsem_isoforms_to_merge\n    path \"*.genes.results\", emit: rsem_genes_to_merge\n    path \"*.stat/*.cnt\", emit: rsem_results_stat\n    path \"*.{results,log}\"\n\n    script:\n    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n\n    def strandness = ''\n    if (params.stranded == 'fr-firststrand') {\n        strandness = \"--strandedness reverse\"\n    } else if (params.stranded == 'fr-secondstrand'){\n        strandness = \"--strandedness forward\"\n    }\n    threads_num = params.rsem_threads_num > 0 ? \"-p ${params.rsem_threads_num}\" : ''\n    index_base = rsem_indices[0].toString().split('\\\\.')[0]\n\n    if (params.single_end) {\n        if (params.stranded && params.stranded != 'unstranded') {\n            \"\"\"\n            rsem-calculate-expression $threads_num $strandness $reads --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        } else {\n            \"\"\"\n            rsem-calculate-expression $threads_num $reads --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        }\n    } else {\n        if (params.stranded && params.stranded != 'unstranded') {\n            \"\"\"\n            rsem-calculate-expression $threads_num $strandness --paired-end ${reads[0]} ${reads[1]} --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ \\\\\n            $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        } else {\n            \"\"\"\n            rsem-calculate-expression $threads_num --paired-end ${reads[0]} ${reads[1]} --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ \\\\\n            $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        }\n    }\n}",
        "nb_lignes_process": 71,
        "string_script": "    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n\n    def strandness = ''\n    if (params.stranded == 'fr-firststrand') {\n        strandness = \"--strandedness reverse\"\n    } else if (params.stranded == 'fr-secondstrand'){\n        strandness = \"--strandedness forward\"\n    }\n    threads_num = params.rsem_threads_num > 0 ? \"-p ${params.rsem_threads_num}\" : ''\n    index_base = rsem_indices[0].toString().split('\\\\.')[0]\n\n    if (params.single_end) {\n        if (params.stranded && params.stranded != 'unstranded') {\n            \"\"\"\n            rsem-calculate-expression $threads_num $strandness $reads --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        } else {\n            \"\"\"\n            rsem-calculate-expression $threads_num $reads --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        }\n    } else {\n        if (params.stranded && params.stranded != 'unstranded') {\n            \"\"\"\n            rsem-calculate-expression $threads_num $strandness --paired-end ${reads[0]} ${reads[1]} --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ \\\\\n            $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        } else {\n            \"\"\"\n            rsem-calculate-expression $threads_num --paired-end ${reads[0]} ${reads[1]} --bowtie2 --bowtie2-path /opt/conda/envs/ramdaq-1.0dev/bin/ \\\\\n            $index_base ${prefix}\n            samtools sort ${prefix}.transcript.bam -o ${prefix}.rsem.bam\n            samtools index ${prefix}.rsem.bam\n            samtools flagstat ${prefix}.rsem.bam > ${prefix}.rsem.bam.flagstat\n            rm ${prefix}.transcript.bam\n            \"\"\"\n        }\n    }",
        "nb_lignes_script": 49,
        "language_script": "bash",
        "tools": [
            "SAMtools"
        ],
        "tools_url": [
            "https://bio.tools/samtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            }
        ],
        "inputs": [
            "name",
            "bam",
            "bai",
            "name",
            "reads",
            "rsem_indices"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true , saveAs: { filename -> filename.indexOf(\".log\") > 0 ? \"logs/$filename\" : \"$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_DETECTEDGENES_DR": {
        "name_process": "CALC_DETECTEDGENES_DR",
        "string_process": "\nprocess CALC_DETECTEDGENES_DR {\n\n    label 'process_medium'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(tpm_count)\n    file(detectplot_header)\n    file(detectplot_header_gstat)\n    file(pcaplot_header)\n    file(tsneplot_header)\n    file(umapplot_header)\n    \n    output:\n    path \"*.{txt,pdf}\", emit: detectedgene_dr_results\n    path \"DRplot_*.csv\", optional:true, emit: drplot\n    path \"barplot_*.csv\", emit: detectedgene_barplot\n    path \"gstat_*.csv\", emit: detectedgene_gstat\n\n    script:\n    def prefix = \"num_of_${options.suffix}\"\n    \"\"\"\n    drawplot_tpm_counts.r $tpm_count ${options.args}\n    cp barplot_${prefix}.csv gstat_${prefix}.csv\n    cat $detectplot_header barplot_${prefix}.csv >> tmp_file\n    mv tmp_file barplot_${prefix}_mqc.csv\n    cat $detectplot_header_gstat gstat_${prefix}.csv >> tmp_file\n    mv tmp_file gstat_${prefix}_mqc.csv\n    \n    if [[ -f DRplot_pca_allsample.csv ]]; then\n        cat $pcaplot_header DRplot_pca_allsample.csv >> tmp_file\n        mv tmp_file DRplot_pca_allsample_mqc.csv\n    fi\n    \n    if [[ -f DRplot_tsne_allsample.csv ]]; then\n        cat $tsneplot_header DRplot_tsne_allsample.csv >> tmp_file\n        mv tmp_file DRplot_tsne_allsample_mqc.csv\n    fi\n\n    if [[ -f DRplot_umap_allsample.csv ]]; then\n        cat $umapplot_header DRplot_umap_allsample.csv >> tmp_file\n        mv tmp_file DRplot_umap_allsample_mqc.csv\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "    def prefix = \"num_of_${options.suffix}\"\n    \"\"\"\n    drawplot_tpm_counts.r $tpm_count ${options.args}\n    cp barplot_${prefix}.csv gstat_${prefix}.csv\n    cat $detectplot_header barplot_${prefix}.csv >> tmp_file\n    mv tmp_file barplot_${prefix}_mqc.csv\n    cat $detectplot_header_gstat gstat_${prefix}.csv >> tmp_file\n    mv tmp_file gstat_${prefix}_mqc.csv\n    \n    if [[ -f DRplot_pca_allsample.csv ]]; then\n        cat $pcaplot_header DRplot_pca_allsample.csv >> tmp_file\n        mv tmp_file DRplot_pca_allsample_mqc.csv\n    fi\n    \n    if [[ -f DRplot_tsne_allsample.csv ]]; then\n        cat $tsneplot_header DRplot_tsne_allsample.csv >> tmp_file\n        mv tmp_file DRplot_tsne_allsample_mqc.csv\n    fi\n\n    if [[ -f DRplot_umap_allsample.csv ]]; then\n        cat $umapplot_header DRplot_umap_allsample.csv >> tmp_file\n        mv tmp_file DRplot_umap_allsample_mqc.csv\n    fi\n    \"\"\"",
        "nb_lignes_script": 23,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tpm_count",
            "detectplot_header",
            "detectplot_header_gstat",
            "pcaplot_header",
            "tsneplot_header",
            "umapplot_header"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "FEATURECOUNTS": {
        "name_process": "FEATURECOUNTS",
        "string_process": "\nprocess FEATURECOUNTS {\n    tag \"$name\"\n    \n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true,\n        saveAs: {filename ->\n            if (filename.indexOf(\"biotype_counts\") > 0) \"biotype_counts/$filename\"\n            else if (filename.indexOf(\".featureCounts.txt.summary\") > 0) \"count_summaries/$filename\"\n            else if (filename.indexOf(\".featureCounts.txt\") > 0) \"counts/$filename\"\n            else \"$filename\"\n        }\n    \n    input:\n    tuple val(name), file(bam), file(bai)\n    file gtf\n    file biotypes_header\n\n    output:\n    path \"*.featureCounts.txt\", emit: counts_to_merge\n    path \"*.featureCounts.txt.summary\", emit: counts_summary\n    path \"${name}.allgene.featureCounts.txt\", optional:true, emit: counts_to_plot_corr\n    path \"${name}_biotype_counts*mqc.{txt,tsv}\", optional:true, emit: counts_biotype\n\n    script:\n    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n\n    def is_pairedend = params.single_end ? '' : \"-p\"\n    def strandspecific = ''\n    if (params.stranded && params.stranded == 'fr-firststrand') {\n        strandspecific = \"-s 2\"\n    } else if (params.stranded && params.stranded == 'fr-secondstrand'){\n        strandspecific = \"-s 1\"\n    }\n    def extra_attributes = params.extra_attributes ? \"--extraAttributes ${params.extra_attributes}\" : ''\n    def allow_multimap = params.allow_multimap ? \"-M\" : ''\n    def allow_overlap = params.allow_overlap ? \"-O\" : ''\n    def count_fractionally = params.count_fractionally ? \"--fraction\" : ''\n    def threads_num = params.fc_threads_num > 0 ? \"-T ${params.fc_threads_num}\" : ''\n    def biotype = params.group_features_type\n\n    if (options.suffix != '.allgene') {\n        \"\"\"\n        featureCounts -a $gtf -g ${params.group_features} -t ${params.count_type} -o ${prefix}.featureCounts.txt  \\\\\n        $is_pairedend $strandspecific $extra_attributes $allow_multimap $allow_overlap $count_fractionally $threads_num ${bam}\n        \"\"\"\n    } else {\n        \"\"\"\n        featureCounts -a $gtf -g ${params.group_features} -t ${params.count_type} -o ${prefix}.featureCounts.txt  \\\\\n        $is_pairedend $strandspecific $extra_attributes $allow_multimap $allow_overlap $count_fractionally $threads_num ${bam}\n\n        featureCounts -a $gtf -g $biotype -o ${name}_biotype_featureCounts.txt $is_pairedend $strandspecific ${bam}\n        cut -f 1,7 ${name}_biotype_featureCounts.txt | tail -n +3 | cat $biotypes_header - >> ${name}_biotype_counts_mqc.txt\n        \"\"\"\n\n    }\n\n\n\n\n}",
        "nb_lignes_process": 58,
        "string_script": "    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n\n    def is_pairedend = params.single_end ? '' : \"-p\"\n    def strandspecific = ''\n    if (params.stranded && params.stranded == 'fr-firststrand') {\n        strandspecific = \"-s 2\"\n    } else if (params.stranded && params.stranded == 'fr-secondstrand'){\n        strandspecific = \"-s 1\"\n    }\n    def extra_attributes = params.extra_attributes ? \"--extraAttributes ${params.extra_attributes}\" : ''\n    def allow_multimap = params.allow_multimap ? \"-M\" : ''\n    def allow_overlap = params.allow_overlap ? \"-O\" : ''\n    def count_fractionally = params.count_fractionally ? \"--fraction\" : ''\n    def threads_num = params.fc_threads_num > 0 ? \"-T ${params.fc_threads_num}\" : ''\n    def biotype = params.group_features_type\n\n    if (options.suffix != '.allgene') {\n        \"\"\"\n        featureCounts -a $gtf -g ${params.group_features} -t ${params.count_type} -o ${prefix}.featureCounts.txt  \\\\\n        $is_pairedend $strandspecific $extra_attributes $allow_multimap $allow_overlap $count_fractionally $threads_num ${bam}\n        \"\"\"\n    } else {\n        \"\"\"\n        featureCounts -a $gtf -g ${params.group_features} -t ${params.count_type} -o ${prefix}.featureCounts.txt  \\\\\n        $is_pairedend $strandspecific $extra_attributes $allow_multimap $allow_overlap $count_fractionally $threads_num ${bam}\n\n        featureCounts -a $gtf -g $biotype -o ${name}_biotype_featureCounts.txt $is_pairedend $strandspecific ${bam}\n        cut -f 1,7 ${name}_biotype_featureCounts.txt | tail -n +3 | cat $biotypes_header - >> ${name}_biotype_counts_mqc.txt\n        \"\"\"\n\n    }",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [
            "FeatureCounts"
        ],
        "tools_url": [
            "https://bio.tools/featurecounts"
        ],
        "tools_dico": [
            {
                "name": "FeatureCounts",
                "uri": "https://bio.tools/featurecounts",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3793",
                                    "term": "Read summarisation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "featureCounts is a very efficient read quantifier. It can be used to summarize RNA-seq reads and gDNA-seq reads to a variety of genomic features such as genes, exons, promoters, gene bodies and genomic bins. It is included in the Bioconductor Rsubread package and also in the SourceForge Subread package.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rsubread.html"
            }
        ],
        "inputs": [
            "name",
            "bam",
            "bai",
            "gtf",
            "biotypes_header"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "tag \"$name\"",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true , saveAs: {filename -> if (filename.indexOf(\"biotype_counts\") > 0) \"biotype_counts/$filename\" else if (filename.indexOf(\".featureCounts.txt.summary\") > 0) \"count_summaries/$filename\" else if (filename.indexOf(\".featureCounts.txt\") > 0) \"counts/$filename\" else \"$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "ADJUST_BED_NONCODING": {
        "name_process": "ADJUST_BED_NONCODING",
        "string_process": "\nprocess ADJUST_BED_NONCODING {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(bed)\n    \n    output:\n    path \"adjusted.bed\", emit: bed_adjusted\n    \n    script:\n    \"\"\"\n    adjust_bed_noncoding.r $bed\n    \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "    \"\"\"\n    adjust_bed_noncoding.r $bed\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "bed"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_ENTROPY_SIRV": {
        "name_process": "CALC_ENTROPY_SIRV",
        "string_process": "\nprocess CALC_ENTROPY_SIRV {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(tpm_count)\n    file(entropy_header)\n    file(entropy_header_gstat)\n    \n    output:\n    path \"*.{txt,pdf}\", emit: entropy_results\n    path \"barplot_*.csv\", emit: entropy_barplot\n    path \"gstat_*.csv\", emit: entropy_gstat\n\n    script:\n    def prefix = \"entropy_${options.suffix}\"\n    \"\"\"\n    drawplot_sirv_entropy.r $tpm_count $prefix\n    cp barplot_${prefix}.csv gstat_${prefix}.csv\n    cat $entropy_header barplot_${prefix}.csv >> tmp_file\n    mv tmp_file barplot_${prefix}_mqc.csv\n    cat $entropy_header_gstat gstat_${prefix}.csv >> tmp_file\n    mv tmp_file gstat_${prefix}_mqc.csv \n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    def prefix = \"entropy_${options.suffix}\"\n    \"\"\"\n    drawplot_sirv_entropy.r $tpm_count $prefix\n    cp barplot_${prefix}.csv gstat_${prefix}.csv\n    cat $entropy_header barplot_${prefix}.csv >> tmp_file\n    mv tmp_file barplot_${prefix}_mqc.csv\n    cat $entropy_header_gstat gstat_${prefix}.csv >> tmp_file\n    mv tmp_file gstat_${prefix}_mqc.csv \n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tpm_count",
            "entropy_header",
            "entropy_header_gstat"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "READCOVERAGE_SIRV": {
        "name_process": "READCOVERAGE_SIRV",
        "string_process": "\nprocess READCOVERAGE_SIRV  {\n    tag \"$name\"\n    label 'process_high'\n    container \"yuifu/readcoverage.jl:0.1.2-workaround\"\n\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n \n    when:\n    params.sirv_coverage\n\n    input:\n    tuple val(name), file(bam), file(bai)\n\n    output:\n    path \"*.txt\", emit: readcov_sirv_results\n\n    script:\n    def leftpos = [1001, 14644, 22555, 34498, 51620, 67226, 81063, 230020, 235017, 240016, 245017, 252017, 259017, 266017, 275018, 284018, 293018, 303959, 314960, 325930, 338959, 351958]\n    def rightpos = [11643, 19554, 31497, 48619, 64225, 78062, 228019, 234016, 239015, 244016, 251016, 258016, 265016, 274017, 283017, 292017, 302958, 313959, 324929, 337958, 350957, 363957]\n    def sirvname = [\"SIRV1\", \"SIRV2\", \"SIRV3\", \"SIRV4\", \"SIRV5\", \"SIRV6\", \"SIRV7\", \"SIRV4001\", \"SIRV4002\", \"SIRV4003\", \"SIRV6001\", \"SIRV6002\", \"SIRV6003\", \"SIRV8001\", \"SIRV8002\", \"SIRV8003\", \"SIRV10001\", \"SIRV10002\", \"SIRV10003\", \"SIRV12001\", \"SIRV12002\", \"SIRV12003\"]\n    def filename = bam.name.replaceAll(\"${options.args}\", \"\")\n\n    def command = ''\n    for( int i=0; i<sirvname.size(); i++ ) {\n        command += \"julia /opt/run.jl coverage $bam SIRVomeERCCome ${leftpos[i]} ${rightpos[i]} ${filename}.${sirvname[i]}; \" \n    } \n    command\n}",
        "nb_lignes_process": 27,
        "string_script": "    def leftpos = [1001, 14644, 22555, 34498, 51620, 67226, 81063, 230020, 235017, 240016, 245017, 252017, 259017, 266017, 275018, 284018, 293018, 303959, 314960, 325930, 338959, 351958]\n    def rightpos = [11643, 19554, 31497, 48619, 64225, 78062, 228019, 234016, 239015, 244016, 251016, 258016, 265016, 274017, 283017, 292017, 302958, 313959, 324929, 337958, 350957, 363957]\n    def sirvname = [\"SIRV1\", \"SIRV2\", \"SIRV3\", \"SIRV4\", \"SIRV5\", \"SIRV6\", \"SIRV7\", \"SIRV4001\", \"SIRV4002\", \"SIRV4003\", \"SIRV6001\", \"SIRV6002\", \"SIRV6003\", \"SIRV8001\", \"SIRV8002\", \"SIRV8003\", \"SIRV10001\", \"SIRV10002\", \"SIRV10003\", \"SIRV12001\", \"SIRV12002\", \"SIRV12003\"]\n    def filename = bam.name.replaceAll(\"${options.args}\", \"\")\n\n    def command = ''\n    for( int i=0; i<sirvname.size(); i++ ) {\n        command += \"julia /opt/run.jl coverage $bam SIRVomeERCCome ${leftpos[i]} ${rightpos[i]} ${filename}.${sirvname[i]}; \" \n    } \n    command",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "COMMAND"
        ],
        "tools_url": [
            "https://bio.tools/COMMAND"
        ],
        "tools_dico": [
            {
                "name": "COMMAND",
                "uri": "https://bio.tools/COMMAND",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarray experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3518",
                            "term": "Microarrays"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3800",
                                    "term": "RNA-Seq quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Web-based application used to download, collect and manage gene expression data from public databases.",
                "homepage": "https://github.com/marcomoretto/command"
            }
        ],
        "inputs": [
            "name",
            "bam",
            "bai"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "container \"yuifu/readcoverage.jl:0.1.2-workaround\"",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "params.sirv_coverage",
        "stub": ""
    },
    "RSEQC": {
        "name_process": "RSEQC",
        "string_process": "\nprocess RSEQC  {\n    tag \"$name\"\n    label 'process_high'\n\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true,\n        saveAs: {filename ->\n            if (filename.indexOf(\"readdist.txt\") > 0)         \"read_distribution/$filename\"\n            else if (filename.indexOf(\"inferexp.txt\") > 0)    \"infer_experiment/$filename\"\n            else if (filename.indexOf(\"inner_distance\") > 0)  \"inner_distance/$filename\"\n            else if (filename.indexOf(\"junction\") > 0)        \"junction_annotation/$filename\"\n            else if (filename.indexOf(\"splice_events\") > 0)   \"junction_annotation/$filename\"\n            else \"$filename\"\n        }\n\n    input:\n    tuple val(name), file(bam), file(bai)\n    file bed\n\n    output:\n    path \"*.{txt,pdf,r,xls,log}\", emit: rseqc_results\n    path \"${name}.readdist.txt\", optional:true, emit: readdist_totalread\n\n    script:\n    def min_intron = params.min_intron > 0 ? \"-m ${params.min_intron}\" : ''\n    if (params.single_end) {\n        \"\"\"\n        read_distribution.py -i ${bam} -r $bed > ${bam.baseName}.readdist.txt\n        infer_experiment.py -i ${bam} -r $bed > ${bam.baseName}.inferexp.txt\n        junction_annotation.py -i ${bam} -o ${bam.baseName} -r $bed $min_intron 2> ${bam.baseName}.junction_annotation.log\n        \"\"\"\n    } else {\n        \"\"\"\n        read_distribution.py -i ${bam} -r $bed > ${bam.baseName}.readdist.txt\n        infer_experiment.py -i ${bam} -r $bed > ${bam.baseName}.inferexp.txt\n        junction_annotation.py -i ${bam} -o ${bam.baseName} -r $bed $min_intron 2> ${bam.baseName}.junction_annotation.log\n        inner_distance.py -i ${bam} -o ${bam.baseName} -r $bed\n        \"\"\"\n    }\n\n}",
        "nb_lignes_process": 39,
        "string_script": "    def min_intron = params.min_intron > 0 ? \"-m ${params.min_intron}\" : ''\n    if (params.single_end) {\n        \"\"\"\n        read_distribution.py -i ${bam} -r $bed > ${bam.baseName}.readdist.txt\n        infer_experiment.py -i ${bam} -r $bed > ${bam.baseName}.inferexp.txt\n        junction_annotation.py -i ${bam} -o ${bam.baseName} -r $bed $min_intron 2> ${bam.baseName}.junction_annotation.log\n        \"\"\"\n    } else {\n        \"\"\"\n        read_distribution.py -i ${bam} -r $bed > ${bam.baseName}.readdist.txt\n        infer_experiment.py -i ${bam} -r $bed > ${bam.baseName}.inferexp.txt\n        junction_annotation.py -i ${bam} -o ${bam.baseName} -r $bed $min_intron 2> ${bam.baseName}.junction_annotation.log\n        inner_distance.py -i ${bam} -o ${bam.baseName} -r $bed\n        \"\"\"\n    }",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "name",
            "bam",
            "bai",
            "bed"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true , saveAs: {filename -> if (filename.indexOf(\"readdist.txt\") > 0) \"read_distribution/$filename\" else if (filename.indexOf(\"inferexp.txt\") > 0) \"infer_experiment/$filename\" else if (filename.indexOf(\"inner_distance\") > 0) \"inner_distance/$filename\" else if (filename.indexOf(\"junction\") > 0) \"junction_annotation/$filename\" else if (filename.indexOf(\"splice_events\") > 0) \"junction_annotation/$filename\" else \"$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "FASTQMCF": {
        "name_process": "FASTQMCF",
        "string_process": "\nprocess FASTQMCF  {\n    tag \"$name\"\n\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n \n    input:\n    tuple val(name), file(reads)\n    file adapter\n\n    output:\n    tuple val(name), file(\"*.fastq.gz\"), emit: trimmed_reads\n\n    script:\n    maxReadLength = params.maxReadLength > 0 ? \"-L ${params.maxReadLength}\" : ''\n    minReadLength = params.minReadLength > 0 ? \"-l ${params.minReadLength}\" : ''\n    skew = params.skew > 0 ? \"-k ${params.skew}\" : ''\n    quality = params.quality > 0 ? \"-q ${params.quality}\" : ''\n\n    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n    def prefix_1 = options.suffix ? \"${name}_1${options.suffix}\" : \"${name}_1\"\n    def prefix_2 = options.suffix ? \"${name}_2${options.suffix}\" : \"${name}_2\"\n\n    if (params.single_end) {\n        \"\"\"\n        fastq-mcf $adapter $reads -o ${prefix}.fastq $maxReadLength $minReadLength $skew $quality ; gzip ${prefix}.fastq\n        \"\"\"\n    } else {\n        \"\"\"\n        fastq-mcf $adapter ${reads[0]} ${reads[1]} -o ${prefix_1}.fastq -o ${prefix_2}.fastq $maxReadLength $minReadLength $skew $quality ; gzip ${prefix_1}.fastq && gzip ${prefix_2}.fastq\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 31,
        "string_script": "    maxReadLength = params.maxReadLength > 0 ? \"-L ${params.maxReadLength}\" : ''\n    minReadLength = params.minReadLength > 0 ? \"-l ${params.minReadLength}\" : ''\n    skew = params.skew > 0 ? \"-k ${params.skew}\" : ''\n    quality = params.quality > 0 ? \"-q ${params.quality}\" : ''\n\n    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n    def prefix_1 = options.suffix ? \"${name}_1${options.suffix}\" : \"${name}_1\"\n    def prefix_2 = options.suffix ? \"${name}_2${options.suffix}\" : \"${name}_2\"\n\n    if (params.single_end) {\n        \"\"\"\n        fastq-mcf $adapter $reads -o ${prefix}.fastq $maxReadLength $minReadLength $skew $quality ; gzip ${prefix}.fastq\n        \"\"\"\n    } else {\n        \"\"\"\n        fastq-mcf $adapter ${reads[0]} ${reads[1]} -o ${prefix_1}.fastq -o ${prefix_2}.fastq $maxReadLength $minReadLength $skew $quality ; gzip ${prefix_1}.fastq && gzip ${prefix_2}.fastq\n        \"\"\"\n    }",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "skewr",
            "QUALITY"
        ],
        "tools_url": [
            "https://bio.tools/skewr",
            "https://bio.tools/quality"
        ],
        "tools_dico": [
            {
                "name": "skewr",
                "uri": "https://bio.tools/skewr",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data visualisation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3295",
                            "term": "Epigenetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0092",
                            "term": "Data rendering"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tool for visualizing the output of the Illumina Human Methylation 450k BeadChip to aid in quality control. It creates a panel of nine plots. Six of the plots represent the density of either the methylated intensity or the unmethylated intensity given by one of three subsets of the 485,577 total probes. These subsets include Type I-red, Type I-green, and Type II. The remaining three distributions give the density of the Beta-values for these same three subsets.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/skewr.html"
            },
            {
                "name": "QUALITY",
                "uri": "https://bio.tools/quality",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3519",
                            "term": "PCR experiment"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Mathematics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3519",
                            "term": "Polymerase chain reaction"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3315",
                            "term": "Maths"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3664",
                                    "term": "Statistical modelling"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Variant of the minimum Chi-squared (MC) method for limiting dilution assays, and for which he has demonstrated by simulation desirable properties of minimum variance (i.e., high precision) and minimum bias. Our method modifies the MC method to allow the user to specify the probabilities of a false negative and false positive PCR.",
                "homepage": "http://indra.mullins.microbiol.washington.edu/quality/"
            }
        ],
        "inputs": [
            "name",
            "reads",
            "adapter"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "tag \"$name\"",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_FEATURECOUNTS": {
        "name_process": "MERGE_FEATURECOUNTS",
        "string_process": "\nprocess MERGE_FEATURECOUNTS {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(input_files)\n    \n    output:\n    path \"merged_featureCounts_${options.suffix}.txt\", emit: merged_counts\n    path '*_TPM.txt', optional:true, emit: counts_tpm_merged\n    path '*_ERCC_TPM_log.txt', optional:true, emit: ercc_tpm_merged\n    \n    script:\n    def prefix = \"merged_featureCounts_${options.suffix}\"\n    def get_gene_ids = \"<(tail $options.args ${input_files[0]} | cut $options.args2 )\"\n    def get_counts = input_files.collect{filename ->\n        \"<(tail $options.args ${filename} | sed 's:.bam::' | cut $options.args3)\"}.join(\" \")\n\n    if (options.suffix != 'allgene'){\n        \"\"\"\n        paste $get_gene_ids $get_counts > ${prefix}.txt\n        \"\"\"\n    } else {\n        \"\"\"\n        paste $get_gene_ids $get_counts > ${prefix}.txt\n        calc_TPMCounts.r ${prefix}.txt\n        \"\"\"\n    }\n\n}",
        "nb_lignes_process": 30,
        "string_script": "    def prefix = \"merged_featureCounts_${options.suffix}\"\n    def get_gene_ids = \"<(tail $options.args ${input_files[0]} | cut $options.args2 )\"\n    def get_counts = input_files.collect{filename ->\n        \"<(tail $options.args ${filename} | sed 's:.bam::' | cut $options.args3)\"}.join(\" \")\n\n    if (options.suffix != 'allgene'){\n        \"\"\"\n        paste $get_gene_ids $get_counts > ${prefix}.txt\n        \"\"\"\n    } else {\n        \"\"\"\n        paste $get_gene_ids $get_counts > ${prefix}.txt\n        calc_TPMCounts.r ${prefix}.txt\n        \"\"\"\n    }",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_SAMPLE_CORRELATION": {
        "name_process": "CALC_SAMPLE_CORRELATION",
        "string_process": "\nprocess CALC_SAMPLE_CORRELATION {\n\n    label 'process_medium'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(input_files)\n    val num_of_bams\n    file(mdsplot_header)\n    file(heatmap_header)\n    \n    output:\n    path \"*.{txt,pdf,csv}\", emit: sample_correlation\n    \n    when:\n    num_of_bams > 2\n\n    script:\n    \"\"\"\n    edgeR_heatmap_MDS.r $input_files\n    cat $mdsplot_header edgeR_MDS_Aplot_coordinates_mqc.csv >> tmp_file\n    mv tmp_file edgeR_MDS_Aplot_coordinates_mqc.csv\n    cat $heatmap_header log2CPM_sample_correlation_mqc.csv >> tmp_file\n    mv tmp_file log2CPM_sample_correlation_mqc.csv\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    edgeR_heatmap_MDS.r $input_files\n    cat $mdsplot_header edgeR_MDS_Aplot_coordinates_mqc.csv >> tmp_file\n    mv tmp_file edgeR_MDS_Aplot_coordinates_mqc.csv\n    cat $heatmap_header log2CPM_sample_correlation_mqc.csv >> tmp_file\n    mv tmp_file log2CPM_sample_correlation_mqc.csv\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_files",
            "num_of_bams",
            "mdsplot_header",
            "heatmap_header"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "num_of_bams > 2",
        "stub": ""
    },
    "MULTIQC": {
        "name_process": "MULTIQC",
        "string_process": "\nprocess MULTIQC {\n\n    label 'process_medium'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\"\n\n    input:\n    path multiqc_config\n    path multiqc_custom_config\n    path ('fastqc/*')\n    path ('fastqc/*')\n    path ('hisat2_genome/*')\n    path ('hisat2_rrna/*')\n    path ('rseqc/*')\n    path ('featureCounts/biotype_counts/*')\n    path ('rsem_bowtie2_allgenes/*')\n    path ('plot_sample_correlation/*')\n    path ('plot_ercc_correlation/*')\n    path ('plot_ercc_correlation/*')\n    path ('featurecounts_all_gtf/*')\n    path ('featurecounts_mt_gtf/*')\n    path ('featurecounts_histone_gtf/*')\n    path ('plot_assignedgenome/*')\n    path ('plot_assignedgenome/*')\n    path ('plot_fcounts_maprate_allgene/*')\n    path ('plot_fcounts_maprate_allgene/*')\n    path ('plot_fcounts_maprate_mt/*')\n    path ('plot_fcounts_maprate_mt/*')\n    path ('plot_fcounts_maprate_histone/*')\n    path ('plot_fcounts_maprate_histone/*')\n    path ('plot_detectedgenes_dr/*')\n    path ('plot_detectedgenes_dr/*')\n    path ('plot_detectedgenes_dr/*')\n    path ('plots_from_tpmcounts_rsem/*')\n    path ('plots_from_tpmcounts_rsem/*')\n    path ('plots_from_tpmcounts_rsem/*')\n    path ('plots_from_tpmcounts_rsem/*')\n    path ('plots_entropy_sirv/*')\n    path ('plots_entropy_sirv/*')\n    path ('software_versions/*')\n    path workflow_summary\n    \n    output:\n    path \"*.html\", emit: multiqc_report\n    path \"*_data\", emit: data\n    path \"*_plots\", optional:true, emit: plots\n    \n    script:\n    def custom_config = params.multiqc_config ? \"--config $multiqc_custom_config\" : ''\n    \"\"\"\n    multiqc -f $custom_config .\n    \"\"\"\n}",
        "nb_lignes_process": 52,
        "string_script": "    def custom_config = params.multiqc_config ? \"--config $multiqc_custom_config\" : ''\n    \"\"\"\n    multiqc -f $custom_config .\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "multiqc_config",
            "multiqc_custom_config",
            "workflow_summary"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_medium'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true",
            "container \"quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0\""
        ],
        "when": "",
        "stub": ""
    },
    "UNTAR_INDEX": {
        "name_process": "UNTAR_INDEX",
        "string_process": "\nprocess UNTAR_INDEX {\n\n    label 'process_low'\n    publishDir path: { params.saveReference ? \"${params.outdir}/${options.publish_dir}\" : params.outdir },\n       saveAs: { params.saveReference ? it : null }, mode: 'copy'\n    \n    input:\n    path gz\n    \n    output:\n    path \"$untar/${options.suffix}\", emit: index_files\n    \n    script:\n    untar = gz.toString() - '.tar.gz'\n    \"\"\"\n    tar -xvf $gz\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    untar = gz.toString() - '.tar.gz'\n    \"\"\"\n    tar -xvf $gz\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "gz"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir path: { params.saveReference ? \"${params.outdir}/${options.publish_dir}\" : params.outdir } , saveAs: { params.saveReference ? it : null }, mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_READCOVERAGE_SIRV": {
        "name_process": "MERGE_READCOVERAGE_SIRV",
        "string_process": "\nprocess MERGE_READCOVERAGE_SIRV {\n\n    label 'process_high'\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true\n    \n    input:\n    file(input_files)\n    \n    output:\n    path \"*.gz\", emit: coverage_sirv_merged\n    \n    script:\n    def prefix = \"merged_${options.suffix}.tsv\"\n    def command = input_files.collect{filename ->\n        \"awk -v filebasename=${filename.name} 'BEGIN{OFS=\\\"\\t\\\"; bam=filebasename; sirv=filebasename; sub(\\\"\\\\..+?.readCoverage.txt\\\", \\\"\\\", bam); sub(\\\".readCoverage.txt\\\", \\\"\\\", sirv); sub(\\\".+\\\\.\\\", \\\"\\\", sirv);}{print sirv, \\$1, \\$2, bam}' ${filename} >> ${prefix}\"}.join(\" && \")\n\n    \"\"\"\n    echo -e \"SIRV\\tposition\\tcoverage\\tbam\" > ${prefix}\n    $command\n    gzip ${prefix}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    def prefix = \"merged_${options.suffix}.tsv\"\n    def command = input_files.collect{filename ->\n        \"awk -v filebasename=${filename.name} 'BEGIN{OFS=\\\"\\t\\\"; bam=filebasename; sirv=filebasename; sub(\\\"\\\\..+?.readCoverage.txt\\\", \\\"\\\", bam); sub(\\\".readCoverage.txt\\\", \\\"\\\", sirv); sub(\\\".+\\\\.\\\", \\\"\\\", sirv);}{print sirv, \\$1, \\$2, bam}' ${filename} >> ${prefix}\"}.join(\" && \")\n\n    \"\"\"\n    echo -e \"SIRV\\tposition\\tcoverage\\tbam\" > ${prefix}\n    $command\n    gzip ${prefix}\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_high'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "READCOVERAGE": {
        "name_process": "READCOVERAGE",
        "string_process": "\nprocess READCOVERAGE  {\n    tag \"$name\"\n    label 'process_high'\n    container \"yuifu/readcoverage.jl:0.1.2-workaround\"\n\n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true,\n            saveAs: {filename ->\n            if (filename.indexOf(\"geneBodyCoverage.txt\") > 0) \"genebody_coverage/$filename\"\n            else \"$filename\"\n            }\n \n    input:\n    tuple val(name), file(bam), file(bai)\n    file bed\n\n    output:\n    path \"*.txt\", emit: readcov_results\n\n    script:\n    \"\"\"\n    julia /opt/run.jl relcov ${bam} $bed ${bam.baseName}\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    julia /opt/run.jl relcov ${bam} $bed ${bam.baseName}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "name",
            "bam",
            "bai",
            "bed"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "container \"yuifu/readcoverage.jl:0.1.2-workaround\"",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true , saveAs: {filename -> if (filename.indexOf(\"geneBodyCoverage.txt\") > 0) \"genebody_coverage/$filename\" else \"$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "CALC_ERCC_CORRELATION": {
        "name_process": "CALC_ERCC_CORRELATION",
        "string_process": "\nprocess CALC_ERCC_CORRELATION {\n\n    label 'process_low'\n    publishDir \"${params.outdir}/\", mode: 'copy', overwrite: true,\n        saveAs: {filename ->\n            filename.indexOf(\".txt\") > 0 ? \"${options.publish_dir}/$filename\" : \"${options.args}/$filename\"\n        }\n    \n    input:\n    val ercc_input_amount\n    val num_of_files\n    file(ercc_count)\n    file(ercc_data)\n    file(ercc_header)\n    file(ercc_header_gstat)\n    \n    output:\n    path \"*.{txt,pdf}\", emit: ercc_correlation_results\n    path \"barplot_*.csv\", emit: ercc_correlation_barplot\n    path \"gstat_*.csv\", emit: ercc_correlation_gstat\n    \n           \n                      \n\n    script:\n    \"\"\"\n    drawplot_ERCC_corr.r $ercc_count $ercc_data $ercc_input_amount\n    cp barplot_ercc_counts_copynum_correlation.csv gstat_ercc_counts_copynum_correlation.csv\n    cat $ercc_header barplot_ercc_counts_copynum_correlation.csv >> tmp_file\n    mv tmp_file barplot_ercc_counts_copynum_correlation_mqc.csv\n    cat $ercc_header_gstat gstat_ercc_counts_copynum_correlation.csv >> tmp_file\n    mv tmp_file gstat_ercc_counts_copynum_correlation_mqc.csv\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n    drawplot_ERCC_corr.r $ercc_count $ercc_data $ercc_input_amount\n    cp barplot_ercc_counts_copynum_correlation.csv gstat_ercc_counts_copynum_correlation.csv\n    cat $ercc_header barplot_ercc_counts_copynum_correlation.csv >> tmp_file\n    mv tmp_file barplot_ercc_counts_copynum_correlation_mqc.csv\n    cat $ercc_header_gstat gstat_ercc_counts_copynum_correlation.csv >> tmp_file\n    mv tmp_file gstat_ercc_counts_copynum_correlation_mqc.csv\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "ercc_input_amount",
            "num_of_files",
            "ercc_count",
            "ercc_data",
            "ercc_header",
            "ercc_header_gstat"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "label 'process_low'",
            "publishDir \"${params.outdir}/\", mode: 'copy', overwrite: true , saveAs: {filename -> filename.indexOf(\".txt\") > 0 ? \"${options.publish_dir}/$filename\" : \"${options.args}/$filename\" }"
        ],
        "when": "",
        "stub": ""
    },
    "HISAT2": {
        "name_process": "HISAT2",
        "string_process": "\nprocess HISAT2  {\n    tag \"$name\"\n    label 'process_high'\n    \n    publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true,\n        saveAs: { filename ->\n                    filename.indexOf(\".summary.txt\") > 0 ? \"summaries/$filename\" : \"$filename\"\n                }\n\n    input:\n    tuple val(name), file(reads)\n    path hs2_indices\n    path tools_dir\n\n    output:\n    tuple val(name), file(\"*.bam\"), file(\"*.bai\"), file(\"*.flagstat\"), emit: hisat2_bam_qc\n    tuple val(name), file(\"${name}.bam\"), file(\"${name}.bam.bai\"), file(\"${name}.bam.flagstat\"), optional:true, emit: hisat2_bam_count\n    path \"*.summary.txt\", emit: hisat2_summary\n\n    script:\n    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n\n    def strandness = ''\n    if (params.stranded == 'fr-firststrand') {\n        strandness = params.single_end ? \"--rna-strandness R\" : \"--rna-strandness RF\"\n    } else if (params.stranded == 'fr-secondstrand'){\n        strandness = params.single_end ? \"--rna-strandness F\" : \"--rna-strandness FR\"\n    }\n    softclipping = params.softclipping ? '' : \"--no-softclip\"\n    threads_num = params.hs_threads_num > 0 ? \"-p ${params.hs_threads_num}\" : ''\n    index_base = hs2_indices[0].toString() - ~/.\\d.ht2l?/\n\n    if (params.single_end) {\n        if (params.stranded && params.stranded != 'unstranded' && options.suffix != '.rrna') {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -U $reads $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.forward.bam -script ${tools_dir}/bamtools_f_SE.json\n            samtools index ${prefix}.forward.bam\n            samtools flagstat ${prefix}.forward.bam > ${prefix}.forward.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.reverse.bam -script ${tools_dir}/bamtools_r_SE.json\n            samtools index ${prefix}.reverse.bam\n            samtools flagstat ${prefix}.reverse.bam > ${prefix}.reverse.bam.flagstat\n            \"\"\"\n        } else {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -U $reads $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n            \"\"\"\n        }\n\n    } else {\n        if (params.stranded && params.stranded != 'unstranded' && options.suffix != '.rrna') {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -1 ${reads[0]} -2 ${reads[1]} $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.forward.bam -script ${tools_dir}/bamtools_f_PE.json\n            samtools index ${prefix}.forward.bam\n            samtools flagstat ${prefix}.forward.bam > ${prefix}.forward.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.reverse.bam -script ${tools_dir}/bamtools_r_PE.json\n            samtools index ${prefix}.reverse.bam\n            samtools flagstat ${prefix}.reverse.bam > ${prefix}.reverse.bam.flagstat\n\n            samtools view -bS -f 0x40 ${prefix}.bam -o ${prefix}.R1.bam\n            samtools index ${prefix}.R1.bam\n            samtools flagstat ${prefix}.R1.bam > ${prefix}.R1.bam.flagstat\n\n            samtools view -bS -f 0x80 ${prefix}.bam -o ${prefix}.R2.bam\n            samtools index ${prefix}.R2.bam\n            samtools flagstat ${prefix}.R2.bam > ${prefix}.R2.bam.flagstat\n            \"\"\"\n        } else if (params.stranded == 'unstranded' && options.suffix != '.rrna'){\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -1 ${reads[0]} -2 ${reads[1]} $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n\n            samtools view -bS -f 0x40 ${prefix}.bam -o ${prefix}.R1.bam\n            samtools index ${prefix}.R1.bam\n            samtools flagstat ${prefix}.R1.bam > ${prefix}.R1.bam.flagstat\n\n            samtools view -bS -f 0x80 ${prefix}.bam -o ${prefix}.R2.bam\n            samtools index ${prefix}.R2.bam\n            samtools flagstat ${prefix}.R2.bam > ${prefix}.R2.bam.flagstat\n            \"\"\"\n        } else {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -1 ${reads[0]} -2 ${reads[1]} $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n            \"\"\"\n        }\n    }\n}",
        "nb_lignes_process": 105,
        "string_script": "    def prefix = options.suffix ? \"${name}${options.suffix}\" : \"${name}\"\n\n    def strandness = ''\n    if (params.stranded == 'fr-firststrand') {\n        strandness = params.single_end ? \"--rna-strandness R\" : \"--rna-strandness RF\"\n    } else if (params.stranded == 'fr-secondstrand'){\n        strandness = params.single_end ? \"--rna-strandness F\" : \"--rna-strandness FR\"\n    }\n    softclipping = params.softclipping ? '' : \"--no-softclip\"\n    threads_num = params.hs_threads_num > 0 ? \"-p ${params.hs_threads_num}\" : ''\n    index_base = hs2_indices[0].toString() - ~/.\\d.ht2l?/\n\n    if (params.single_end) {\n        if (params.stranded && params.stranded != 'unstranded' && options.suffix != '.rrna') {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -U $reads $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.forward.bam -script ${tools_dir}/bamtools_f_SE.json\n            samtools index ${prefix}.forward.bam\n            samtools flagstat ${prefix}.forward.bam > ${prefix}.forward.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.reverse.bam -script ${tools_dir}/bamtools_r_SE.json\n            samtools index ${prefix}.reverse.bam\n            samtools flagstat ${prefix}.reverse.bam > ${prefix}.reverse.bam.flagstat\n            \"\"\"\n        } else {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -U $reads $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n            \"\"\"\n        }\n\n    } else {\n        if (params.stranded && params.stranded != 'unstranded' && options.suffix != '.rrna') {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -1 ${reads[0]} -2 ${reads[1]} $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.forward.bam -script ${tools_dir}/bamtools_f_PE.json\n            samtools index ${prefix}.forward.bam\n            samtools flagstat ${prefix}.forward.bam > ${prefix}.forward.bam.flagstat\n\n            bamtools filter -in ${prefix}.bam -out ${prefix}.reverse.bam -script ${tools_dir}/bamtools_r_PE.json\n            samtools index ${prefix}.reverse.bam\n            samtools flagstat ${prefix}.reverse.bam > ${prefix}.reverse.bam.flagstat\n\n            samtools view -bS -f 0x40 ${prefix}.bam -o ${prefix}.R1.bam\n            samtools index ${prefix}.R1.bam\n            samtools flagstat ${prefix}.R1.bam > ${prefix}.R1.bam.flagstat\n\n            samtools view -bS -f 0x80 ${prefix}.bam -o ${prefix}.R2.bam\n            samtools index ${prefix}.R2.bam\n            samtools flagstat ${prefix}.R2.bam > ${prefix}.R2.bam.flagstat\n            \"\"\"\n        } else if (params.stranded == 'unstranded' && options.suffix != '.rrna'){\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -1 ${reads[0]} -2 ${reads[1]} $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n\n            samtools view -bS -f 0x40 ${prefix}.bam -o ${prefix}.R1.bam\n            samtools index ${prefix}.R1.bam\n            samtools flagstat ${prefix}.R1.bam > ${prefix}.R1.bam.flagstat\n\n            samtools view -bS -f 0x80 ${prefix}.bam -o ${prefix}.R2.bam\n            samtools index ${prefix}.R2.bam\n            samtools flagstat ${prefix}.R2.bam > ${prefix}.R2.bam.flagstat\n            \"\"\"\n        } else {\n            \"\"\"\n            hisat2 $softclipping $threads_num -x $index_base -1 ${reads[0]} -2 ${reads[1]} $strandness $options.args --summary-file ${prefix}.summary.txt \\\\\n            | samtools view -bS - | samtools sort - -o ${prefix}.bam\n            samtools index ${prefix}.bam\n            samtools flagstat ${prefix}.bam > ${prefix}.bam.flagstat\n            \"\"\"\n        }\n    }",
        "nb_lignes_script": 84,
        "language_script": "bash",
        "tools": [
            "HISAT2",
            "SAMtools",
            "BamTools"
        ],
        "tools_url": [
            "https://bio.tools/hisat2",
            "https://bio.tools/samtools",
            "https://bio.tools/bamtools"
        ],
        "tools_dico": [
            {
                "name": "HISAT2",
                "uri": "https://bio.tools/hisat2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome).",
                "homepage": "https://ccb.jhu.edu/software/hisat2/index.shtml"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BamTools",
                "uri": "https://bio.tools/bamtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0258",
                                    "term": "Sequence alignment analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BamTools provides a fast, flexible C++ API & toolkit for reading, writing, and managing BAM files.",
                "homepage": "https://github.com/pezmaster31/bamtools"
            }
        ],
        "inputs": [
            "name",
            "reads",
            "hs2_indices",
            "tools_dir"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "rikenbit__ramdaq",
        "directive": [
            "tag \"$name\"",
            "label 'process_high'",
            "publishDir \"${params.outdir}/${options.publish_dir}\", mode: 'copy', overwrite: true , saveAs: { filename -> filename.indexOf(\".summary.txt\") > 0 ? \"summaries/$filename\" : \"$filename\" }"
        ],
        "when": "",
        "stub": ""
    }
}