{
    "fastp": {
        "name_process": "fastp",
        "string_process": "\nprocess fastp {\n    tag \"${meta}\"\n\n    publishDir \"${params.outdir}/fastp/${type}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"biocontainers/fastp:v0.20.1_cv1\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(type)\n    \n    output:\n        tuple val(meta), path(\"*.html\"), emit: html\n\n    script:\n        \"\"\"\n        fastp -i $reads -h ${meta}.html -A -L -Q \n        \"\"\"\n\n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        fastp -i $reads -h ${meta}.html -A -L -Q \n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "tag \"${meta}\"",
            "publishDir \"${params.outdir}/fastp/${type}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"biocontainers/fastp:v0.20.1_cv1\""
        ],
        "when": "",
        "stub": ""
    },
    "nanoplot": {
        "name_process": "nanoplot",
        "string_process": "\nprocess nanoplot {\n    tag \"${sequencing_summary}\"\n\n    publishDir \"${params.outdir}/nanoplot/${type}/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n    \n    container \"staphb/nanoplot:1.33.0\"\n\n    input:\n        tuple val(meta), path(reads)\n        val(type)\n    \n    output:\n        path \"*.{png, html, txt, log}\", emit: report\n    \n    script:\n        \"\"\"\n        NanoPlot --fastq $reads\n        \"\"\"\n \n}",
        "nb_lignes_process": 22,
        "string_script": "        \"\"\"\n        NanoPlot --fastq $reads\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "reads",
            "type"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "tag \"${sequencing_summary}\"",
            "publishDir \"${params.outdir}/nanoplot/${type}/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"staphb/nanoplot:1.33.0\""
        ],
        "when": "",
        "stub": ""
    },
    "filtlong": {
        "name_process": "filtlong",
        "string_process": "\nprocess filtlong{\n    tag \"${meta}\"\n\n    publishDir \"${params.outdir}/filtlong\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"nanozoo/filtlong:0.2.0--0c4cbe3\"\n\n    input:\n        tuple val(meta), path(reads)\n    \n    output:\n        tuple val(meta), path(\"*.trim.fastq.gz\"), emit: fastq\n    \n    script:\n        \"\"\"\n        filtlong --min_length $params.min_length --min_mean_q $params.min_mean_q $reads | gzip > ${meta}.trim.fastq.gz\n        \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "        \"\"\"\n        filtlong --min_length $params.min_length --min_mean_q $params.min_mean_q $reads | gzip > ${meta}.trim.fastq.gz\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [
            "Filtlong"
        ],
        "tools_url": [
            "https://bio.tools/Filtlong"
        ],
        "tools_dico": [
            {
                "name": "Filtlong",
                "uri": "https://bio.tools/Filtlong",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0749",
                            "term": "Transcription factors and regulatory sites"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0798",
                            "term": "Mobile genetic elements"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Sequence trimming"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3482",
                                    "term": "Antimicrobial resistance prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3472",
                                    "term": "k-mer counting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "Splitting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3192",
                                    "term": "Trimming"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3359",
                                    "term": "File splitting"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Complete hybrid genome assembly of clinical multidrug-resistant Bacteroides fragilis isolates enables comprehensive identification of antimicrobial-resistance genes and plasmids.\n\nquality filtering tool for long reads.\n\nFiltlong is a tool for filtering long reads by quality. It can take a set of long reads and produce a smaller, better subset. It uses both read length (longer is better) and read identity (higher is better) when choosing which reads pass the filter.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'Unicycler' (bio.tools/unicycler), 'Canu-corrected ONT', 'AMR', 'fragilis'",
                "homepage": "https://github.com/rrwick/Filtlong"
            }
        ],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "tag \"${meta}\"",
            "publishDir \"${params.outdir}/filtlong\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"nanozoo/filtlong:0.2.0--0c4cbe3\""
        ],
        "when": "",
        "stub": ""
    },
    "guppy_basecaller": {
        "name_process": "guppy_basecaller",
        "string_process": "\nprocess guppy_basecaller {\n    tag \"${reads}\"\n    \n    publishDir \"${params.outdir}/guppy\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    if (params.gpu_active){\n        container 'genomicpariscentre/guppy-gpu:4.2.2'\n    } else {\n        container 'genomicpariscentre/guppy:4.2.2'\n    }\n\n    input:\n        path(reads)\n\n    output:\n        path(\"fastq/*.fastq.gz\"), emit: fastq\n        path \"*.log\", emit: log\n        path \"*.txt\", emit: sequencing_summary\n        path \"*.js\", emit: telemetry\n\n    script:\n        flowcell=params.flowcell ? \"--flowcell $params.flowcell --kit $params.kit\": \"\"\n        barcode_kit=params.barcode_kit ? \"--barcode_kits '$params.barcode_kit'\": \"\"\n        cpu_opts=params.cpus ? \"--num_callers $params.cpus --cpu_threads_per_caller $params.threads\": \"\"\n        if (params.gpu_active){\n            gpu_opts = \"--gpu_runners_per_device $params.gpus -x cuda:all:100% \"\n        } else {\n            gpu_opts = \"\"\n        }\n        \"\"\"\n        guppy_basecaller --input_path $reads \\\\\n            --save_path . \\\\\n            --records_per_fastq 0 \\\\\n            --compress_fastq \\\\\n            $flowcell \\\\\n            $barcode_kit \\\\\n            $cpu_opts \\\\\n            $gpu_opts\n            \n        # have to combine fastqs\n        mkdir fastq\n        if [ \"\\$(find . -type d -name \"barcode*\" )\" != \"\" ]\n        then\n            for dir in barcode*/\n            do\n                dir=\\${dir%*/}\n                cat \\$dir/*.fastq.gz > ./fastq/\\$dir.fastq.gz\n            done\n        else\n            cat *.fastq.gz > ./fastq/output.fastq.gz\n        fi\n        \"\"\"\n}",
        "nb_lignes_process": 55,
        "string_script": "        flowcell=params.flowcell ? \"--flowcell $params.flowcell --kit $params.kit\": \"\"\n        barcode_kit=params.barcode_kit ? \"--barcode_kits '$params.barcode_kit'\": \"\"\n        cpu_opts=params.cpus ? \"--num_callers $params.cpus --cpu_threads_per_caller $params.threads\": \"\"\n        if (params.gpu_active){\n            gpu_opts = \"--gpu_runners_per_device $params.gpus -x cuda:all:100% \"\n        } else {\n            gpu_opts = \"\"\n        }\n        \"\"\"\n        guppy_basecaller --input_path $reads \\\\\n            --save_path . \\\\\n            --records_per_fastq 0 \\\\\n            --compress_fastq \\\\\n            $flowcell \\\\\n            $barcode_kit \\\\\n            $cpu_opts \\\\\n            $gpu_opts\n            \n        # have to combine fastqs\n        mkdir fastq\n        if [ \"\\$(find . -type d -name \"barcode*\" )\" != \"\" ]\n        then\n            for dir in barcode*/\n            do\n                dir=\\${dir%*/}\n                cat \\$dir/*.fastq.gz > ./fastq/\\$dir.fastq.gz\n            done\n        else\n            cat *.fastq.gz > ./fastq/output.fastq.gz\n        fi\n        \"\"\"",
        "nb_lignes_script": 30,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "reads"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "tag \"${reads}\"",
            "publishDir \"${params.outdir}/guppy\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename } if (params.gpu_active){ container 'genomicpariscentre/guppy-gpu:4.2.2' } else { container 'genomicpariscentre/guppy:4.2.2' }"
        ],
        "when": "",
        "stub": ""
    },
    "pycoqc": {
        "name_process": "pycoqc",
        "string_process": "\nprocess pycoqc {\n    tag \"${sequencing_summary}\"\n\n    publishDir \"${params.outdir}/pycoqc/${type}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"quay.io/biocontainers/pycoqc:2.5.0.23--py_0\"\n\n    input:\n        path(sequencing_summary)\n        val(type)\n\n    output:\n        path '*.html', emit: report\n\n    script:    \n        \"\"\"\n        pycoQC --summary_file $sequencing_summary --html_outfile pycoqc_report.html\n        \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "        \"\"\"\n        pycoQC --summary_file $sequencing_summary --html_outfile pycoqc_report.html\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "sequencing_summary",
            "type"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "tag \"${sequencing_summary}\"",
            "publishDir \"${params.outdir}/pycoqc/${type}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"quay.io/biocontainers/pycoqc:2.5.0.23--py_0\""
        ],
        "when": "",
        "stub": ""
    },
    "Kraken2": {
        "name_process": "Kraken2",
        "string_process": "\nprocess Kraken2 {\n    tag \"${reads}\"\n\n    publishDir \"${params.outdir}/kraken2/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n\n    container \"alemenze/kraken2-docker\"\n\n    input:\n        tuple val(meta), path(reads)\n        path(db)\n        val(read_type)\n\n    output:\n        tuple val(meta), path(\"*kraken2.krona\"), emit: kraken2krona\n        path(\"*_kraken2.report\")\n        path(\"*_bracken.tsv\")\n\n    script:\n        if (read_type=='single') {\n            input=\"$reads\"\n            read_len='250'\n        }\n        if (read_type=='paired') {\n            input=\"--paired ${reads[0]} ${reads[1]}\"\n            read_len='150'\n        }\n        \"\"\"\n        kraken2 -db $db --report ${meta}_kraken2.report $input > ${meta}_kraken2.output\n        cut -f 2,3 ${meta}_kraken2.output > ${meta}_kraken2.krona\n\n        bracken -d $db -r $read_len -i ${meta}_kraken2.report -l $params.kraken_tax_level -o ${meta}_bracken.tsv\n        \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "        if (read_type=='single') {\n            input=\"$reads\"\n            read_len='250'\n        }\n        if (read_type=='paired') {\n            input=\"--paired ${reads[0]} ${reads[1]}\"\n            read_len='150'\n        }\n        \"\"\"\n        kraken2 -db $db --report ${meta}_kraken2.report $input > ${meta}_kraken2.output\n        cut -f 2,3 ${meta}_kraken2.output > ${meta}_kraken2.krona\n\n        bracken -d $db -r $read_len -i ${meta}_kraken2.report -l $params.kraken_tax_level -o ${meta}_bracken.tsv\n        \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "kraken2",
            "Bracken"
        ],
        "tools_url": [
            "https://bio.tools/kraken2",
            "https://bio.tools/bracken"
        ],
        "tools_dico": [
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            },
            {
                "name": "Bracken",
                "uri": "https://bio.tools/bracken",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Microbial ecology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3697",
                            "term": "Environmental microbiology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Statistical method that computes the abundance of species in DNA sequences from a metagenomics sample.",
                "homepage": "https://ccb.jhu.edu/software/bracken/"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "db",
            "read_type"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "tag \"${reads}\"",
            "publishDir \"${params.outdir}/kraken2/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }",
            "container \"alemenze/kraken2-docker\""
        ],
        "when": "",
        "stub": ""
    },
    "Kraken2_db_build": {
        "name_process": "Kraken2_db_build",
        "string_process": "\nprocess Kraken2_db_build {\n\n    container \"alemenze/kraken2-docker\"\n\n    input:\n        path(kraken)\n        val(kraken_name)\n\n    output:\n        path(\"./${kraken_name}/\", type:'dir', emit: kraken2_ch)\n    \n    script:\n        \"\"\"\n        mkdir -p $kraken_name && tar -xvzf $kraken -C $kraken_name\n        \"\"\"\n}",
        "nb_lignes_process": 15,
        "string_script": "        \"\"\"\n        mkdir -p $kraken_name && tar -xvzf $kraken -C $kraken_name\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "kraken",
            "kraken_name"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "container \"alemenze/kraken2-docker\""
        ],
        "when": "",
        "stub": ""
    },
    "Krona": {
        "name_process": "Krona",
        "string_process": "\nprocess Krona {\n\n    container \"alemenze/kraken2-docker\"\n\n    publishDir \"${params.outdir}/kraken2_krona/${meta}\",\n        mode: \"copy\",\n        overwrite: true,\n        saveAs: { filename -> filename }\n    \n    input:\n        tuple val(meta), path(krona_in)\n    \n    output:\n        path(\"*_taxonomy_krona.html\")\n\n    script:\n        \"\"\"\n        ktImportTaxonomy -o ${meta}_kraken2_taxonomy_krona.html $krona_in\n        \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "        \"\"\"\n        ktImportTaxonomy -o ${meta}_kraken2_taxonomy_krona.html $krona_in\n        \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "krona_in"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "alemenze__ONT-basecalling",
        "directive": [
            "container \"alemenze/kraken2-docker\"",
            "publishDir \"${params.outdir}/kraken2_krona/${meta}\" , mode: \"copy\" , overwrite: true , saveAs: { filename -> filename }"
        ],
        "when": "",
        "stub": ""
    }
}