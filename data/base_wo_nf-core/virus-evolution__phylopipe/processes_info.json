{
    "mask_alignment": {
        "name_process": "mask_alignment",
        "string_process": "\nprocess mask_alignment {\n       \n                                     \n                      \n                               \n                       \n      \n\n    input:\n    path alignment\n\n    output:\n    path \"${alignment.baseName}.masked.fa\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/add_mask.py \\\n      --in-alignment ${alignment} \\\n      --out-alignment \"${alignment.baseName}.masked.fa\" \\\n      --mask ${mask_file}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    $project_dir/../bin/add_mask.py \\\n      --in-alignment ${alignment} \\\n      --out-alignment \"${alignment.baseName}.masked.fa\" \\\n      --mask ${mask_file}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alignment"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "filter_uk": {
        "name_process": "filter_uk",
        "string_process": "\nprocess filter_uk {\n       \n                                                                      \n                            \n      \n\n    input:\n    path fasta\n    path metadata\n\n    output:\n    path \"${fasta.baseName}.filtered.fasta\", emit: fasta\n    path \"${metadata.baseName}.filtered.csv\", emit: metadata\n\n    script:\n    \"\"\"\n    $project_dir/../bin/filter.py \\\n            --in-fasta ${fasta} \\\n            --in-metadata ${metadata} \\\n            --outgroups ${lineage_splits} \\\n            --out-fasta \"${fasta.baseName}.filtered.fasta\" \\\n            --out-metadata \"${metadata.baseName}.filtered.csv\" \\\n            --exclude_true duplicate\n    if [[ \\$(cat \"${metadata}\" | wc -l) != \\$(cat \"${metadata.baseName}.filtered.csv\" | wc -l) ]]\n            then\n                echo \\$(cat \"${metadata}\" | wc -l)\n                echo \\$(cat \"${metadata.baseName}.filtered.csv\" | wc -l)\n                exit 1\n            fi\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    $project_dir/../bin/filter.py \\\n            --in-fasta ${fasta} \\\n            --in-metadata ${metadata} \\\n            --outgroups ${lineage_splits} \\\n            --out-fasta \"${fasta.baseName}.filtered.fasta\" \\\n            --out-metadata \"${metadata.baseName}.filtered.csv\" \\\n            --exclude_true duplicate\n    if [[ \\$(cat \"${metadata}\" | wc -l) != \\$(cat \"${metadata.baseName}.filtered.csv\" | wc -l) ]]\n            then\n                echo \\$(cat \"${metadata}\" | wc -l)\n                echo \\$(cat \"${metadata.baseName}.filtered.csv\" | wc -l)\n                exit 1\n            fi\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "clean_fasta_headers": {
        "name_process": "clean_fasta_headers",
        "string_process": "\nprocess clean_fasta_headers {\n       \n                                \n                   \n      \n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.clean.fa\", emit: fasta\n    path \"${fasta.baseName}.map.csv\", emit: map\n\n    script:\n    \"\"\"\n    $project_dir/../bin/remove_dodgy_symbols.py \\\n          --in-fasta ${fasta} \\\n          --out-fasta \"${fasta.baseName}.clean.fa\" \\\n          --out-metadata \"${fasta.baseName}.map.csv\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    $project_dir/../bin/remove_dodgy_symbols.py \\\n          --in-fasta ${fasta} \\\n          --out-fasta \"${fasta.baseName}.clean.fa\" \\\n          --out-metadata \"${fasta.baseName}.map.csv\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "clean_fasta_headers_with_tree": {
        "name_process": "clean_fasta_headers_with_tree",
        "string_process": "\nprocess clean_fasta_headers_with_tree {\n       \n                                \n                   \n      \n\n    input:\n    path fasta\n    path tree\n\n    output:\n    path \"${fasta.baseName}.clean.fa\", emit: fasta\n    path \"${fasta.baseName}.map.csv\", emit: map\n    path \"${tree.baseName}.clean.tree\", emit: tree\n\n    script:\n    \"\"\"\n    $project_dir/../bin/remove_dodgy_symbols.py \\\n          --in-fasta ${fasta} \\\n          --in-tree ${tree} \\\n          --out-fasta \"${fasta.baseName}.clean.fa\" \\\n          --out-metadata \"${fasta.baseName}.map.csv\" \\\n          --out-tree \"${tree.baseName}.clean.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    $project_dir/../bin/remove_dodgy_symbols.py \\\n          --in-fasta ${fasta} \\\n          --in-tree ${tree} \\\n          --out-fasta \"${fasta.baseName}.clean.fa\" \\\n          --out-metadata \"${fasta.baseName}.map.csv\" \\\n          --out-tree \"${tree.baseName}.clean.tree\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "tree"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "clean_metadata": {
        "name_process": "clean_metadata",
        "string_process": "\nprocess clean_metadata {\n       \n                                     \n                          \n      \n\n    input:\n    path metadata\n    path map\n\n    output:\n    path \"${metadata.baseName}.clean.csv\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/apply_map.py \\\n          --in-metadata ${metadata} \\\n          --in-map \"${map}\" \\\n          --to-clean ${params.annotations} \\\n          --out-metadata \"${metadata.baseName}.clean.csv\"\n    if [[ \\$(cat \"${metadata}\" | wc -l) != \\$(cat \"${metadata.baseName}.clean.csv\" | wc -l) ]]\n    then\n        echo \\$(cat \"${metadata}\" | wc -l)\n        echo \\$(cat \"${metadata.baseName}.clean.csv\" | wc -l)\n        exit 1\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    $project_dir/../bin/apply_map.py \\\n          --in-metadata ${metadata} \\\n          --in-map \"${map}\" \\\n          --to-clean ${params.annotations} \\\n          --out-metadata \"${metadata.baseName}.clean.csv\"\n    if [[ \\$(cat \"${metadata}\" | wc -l) != \\$(cat \"${metadata.baseName}.clean.csv\" | wc -l) ]]\n    then\n        echo \\$(cat \"${metadata}\" | wc -l)\n        echo \\$(cat \"${metadata.baseName}.clean.csv\" | wc -l)\n        exit 1\n    fi\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata",
            "map"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "get_keep_tips": {
        "name_process": "get_keep_tips",
        "string_process": "\nprocess get_keep_tips {\n       \n                                                        \n                           \n      \n\n    memory { 4.GB + 4.GB * task.attempt }\n    errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n    maxRetries = 2\n\n    input:\n    path metadata\n    path tree\n\n    output:\n    path \"${metadata.baseName}.tips.txt\"\n\n    script:\n    \"\"\"\n    fastafunk get_tips \\\n      --in-metadata ${metadata} \\\n      --in-tree ${tree} \\\n      --out-tips \"${metadata.baseName}.tips.txt\"\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    fastafunk get_tips \\\n      --in-metadata ${metadata} \\\n      --in-tree ${tree} \\\n      --out-tips \"${metadata.baseName}.tips.txt\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata",
            "tree"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "memory { 4.GB + 4.GB * task.attempt }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries = 2"
        ],
        "when": "",
        "stub": ""
    },
    "prune_tree_with_metadata": {
        "name_process": "prune_tree_with_metadata",
        "string_process": "\nprocess prune_tree_with_metadata {\n       \n                                                    \n                           \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n    path tips\n\n    output:\n    path \"${tree.baseName}.pruned.newick\"\n\n    script:\n    if ( params.prune )\n    \"\"\"\n    gotree prune \\\n      -i ${tree} \\\n      -f ${tips} \\\n      -r \\\n      -o \"${tree.baseName}.pruned.newick\"\n    \"\"\"\n    else\n    \"\"\"\n    cp ${tree} \"${tree.baseName}.pruned.newick\"\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    if ( params.prune )\n    \"\"\"\n    gotree prune \\\n      -i ${tree} \\\n      -f ${tips} \\\n      -r \\\n      -o \"${tree.baseName}.pruned.newick\"\n    \"\"\"\n    else\n    \"\"\"\n    cp ${tree} \"${tree.baseName}.pruned.newick\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "tips"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "get_tree_tips": {
        "name_process": "get_tree_tips",
        "string_process": "\nprocess get_tree_tips {\n       \n                            \n                 \n      \n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n\n    output:\n    path \"${tree.baseName}.tips.txt\"\n\n    script:\n    \"\"\"\n    gotree stats tips \\\n      -i ${tree} | cut -f4 > \"${tree.baseName}.tips.txt\"\n    \"\"\"\n}",
        "nb_lignes_process": 18,
        "string_script": "    \"\"\"\n    gotree stats tips \\\n      -i ${tree} | cut -f4 > \"${tree.baseName}.tips.txt\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "annotate_metadata": {
        "name_process": "annotate_metadata",
        "string_process": "\nprocess annotate_metadata {\n       \n                                                                                 \n                     \n                      \n      \n\n    input:\n    path metadata\n    path hashmap\n    path ambiguous_site_log\n\n    output:\n    path \"${metadata.baseName}.annotated.csv\"\n\n    script:\n    \"\"\"\n    #!/usr/bin/env python3\n    import csv\n\n    tips = set()\n    hashmap = {}\n    with open(\"${hashmap}\", 'r', newline = '') as hashmap_in:\n        for line in hashmap_in:\n            tip, redundant = line.rstrip().split(\",\")\n            tips.add(tip)\n            for id in redundant.split(\"|\"):\n                hashmap[id] = tip\n    print(\"hashmap contains %d tips and %d redundants\" %(len(tips), len(hashmap)))\n\n    ambig = set()\n    with open(\"${ambiguous_site_log}\", 'r', newline = '') as ambiguous_site_log_in:\n        for line in ambiguous_site_log_in:\n            ambig.add(line.rstrip())\n    print(\"%d had ambiguous bases\" %len(ambig))\n\n    with open(\"${metadata}\", 'r', newline = '') as csv_in, \\\n        open(\"${metadata.baseName}.annotated.csv\", 'w', newline = '') as csv_out:\n        reader = csv.DictReader(csv_in, delimiter=\",\", quotechar='\\\"', dialect = \"unix\")\n        new_fieldnames = reader.fieldnames\n        if \"note\" not in reader.fieldnames:\n            new_fieldnames.append(\"note\")\n        writer = csv.DictWriter(csv_out, fieldnames = new_fieldnames, delimiter=\",\", quotechar='\\\"', quoting=csv.QUOTE_MINIMAL, dialect = \"unix\")\n        writer.writeheader()\n        for row in reader:\n            note = []\n            if row[\"sequence_name\"] in hashmap:\n                note.append(\"hashed to tip %s\" %hashmap[row[\"sequence_name\"]])\n            if row[\"sequence_name\"] in ambig:\n                note.append(\"filtered due to ambiguous base\")\n            if row[\"date_filter\"]:\n                if row[\"note\"] and \"downsample\" not in row[\"note\"]:\n                    note.append(\"date filtered\")\n            if row[\"note\"]:\n                note.append(row[\"note\"])\n            row[\"note\"] = \"|\".join(note)\n            writer.writerow(row)\n    \"\"\"\n}",
        "nb_lignes_process": 58,
        "string_script": "    \"\"\"\n    #!/usr/bin/env python3\n    import csv\n\n    tips = set()\n    hashmap = {}\n    with open(\"${hashmap}\", 'r', newline = '') as hashmap_in:\n        for line in hashmap_in:\n            tip, redundant = line.rstrip().split(\",\")\n            tips.add(tip)\n            for id in redundant.split(\"|\"):\n                hashmap[id] = tip\n    print(\"hashmap contains %d tips and %d redundants\" %(len(tips), len(hashmap)))\n\n    ambig = set()\n    with open(\"${ambiguous_site_log}\", 'r', newline = '') as ambiguous_site_log_in:\n        for line in ambiguous_site_log_in:\n            ambig.add(line.rstrip())\n    print(\"%d had ambiguous bases\" %len(ambig))\n\n    with open(\"${metadata}\", 'r', newline = '') as csv_in, \\\n        open(\"${metadata.baseName}.annotated.csv\", 'w', newline = '') as csv_out:\n        reader = csv.DictReader(csv_in, delimiter=\",\", quotechar='\\\"', dialect = \"unix\")\n        new_fieldnames = reader.fieldnames\n        if \"note\" not in reader.fieldnames:\n            new_fieldnames.append(\"note\")\n        writer = csv.DictWriter(csv_out, fieldnames = new_fieldnames, delimiter=\",\", quotechar='\\\"', quoting=csv.QUOTE_MINIMAL, dialect = \"unix\")\n        writer.writeheader()\n        for row in reader:\n            note = []\n            if row[\"sequence_name\"] in hashmap:\n                note.append(\"hashed to tip %s\" %hashmap[row[\"sequence_name\"]])\n            if row[\"sequence_name\"] in ambig:\n                note.append(\"filtered due to ambiguous base\")\n            if row[\"date_filter\"]:\n                if row[\"note\"] and \"downsample\" not in row[\"note\"]:\n                    note.append(\"date filtered\")\n            if row[\"note\"]:\n                note.append(row[\"note\"])\n            row[\"note\"] = \"|\".join(note)\n            writer.writerow(row)\n    \"\"\"",
        "nb_lignes_script": 41,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata",
            "hashmap",
            "ambiguous_site_log"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "announce_summary": {
        "name_process": "announce_summary",
        "string_process": "\nprocess announce_summary {\n       \n                                      \n                  \n      \n\n    input:\n    path original\n    path unique\n    path filtered_on_ambiguous_sites\n    path filtered_on_sample_date\n    path downsampled\n\n    output:\n    path \"announce.json\"\n\n    script:\n        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > announce.json\n            echo \"*${params.whoami}: Subsampling ${params.date} for tree*\\\\n\" >> announce.json\n            echo \"> Number of sequences in COG and GISAID input files : \\$(cat ${original} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of unique sequences : \\$(cat ${unique} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences with non-ambiguous bases at sites of interest : \\$(cat ${filtered_on_ambiguous_sites} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of (non-unique) sequences with sample_date older than ${params.time_window} days: \\$(cat ${filtered_on_sample_date} | grep 'sample_date older than' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences after downsampling: \\$(cat ${downsampled} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo '\"}' >> announce.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @announce.json ${params.webhook}\n            \"\"\"\n        else\n            \"\"\"\n            echo '{\"text\":\"' > announce.json\n            echo \"*${params.whoami}: Subsampling ${params.date} for tree*\\\\n\" >> announce.json\n            echo \"> Number of sequences in COG and GISAID input files : \\$(cat ${original} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of unique sequences : \\$(cat ${unique} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences with non-ambiguous bases at sites of interest : \\$(cat ${filtered_on_ambiguous_sites} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of (non-unique) sequences with sample_date older than ${params.time_window} days: \\$(cat ${filtered_on_sample_date} | grep 'sample_date older than' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences after downsampling: \\$(cat ${downsampled} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo '\"}' >> announce.json\n            \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > announce.json\n            echo \"*${params.whoami}: Subsampling ${params.date} for tree*\\\\n\" >> announce.json\n            echo \"> Number of sequences in COG and GISAID input files : \\$(cat ${original} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of unique sequences : \\$(cat ${unique} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences with non-ambiguous bases at sites of interest : \\$(cat ${filtered_on_ambiguous_sites} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of (non-unique) sequences with sample_date older than ${params.time_window} days: \\$(cat ${filtered_on_sample_date} | grep 'sample_date older than' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences after downsampling: \\$(cat ${downsampled} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo '\"}' >> announce.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @announce.json ${params.webhook}\n            \"\"\"\n        else\n            \"\"\"\n            echo '{\"text\":\"' > announce.json\n            echo \"*${params.whoami}: Subsampling ${params.date} for tree*\\\\n\" >> announce.json\n            echo \"> Number of sequences in COG and GISAID input files : \\$(cat ${original} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of unique sequences : \\$(cat ${unique} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences with non-ambiguous bases at sites of interest : \\$(cat ${filtered_on_ambiguous_sites} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of (non-unique) sequences with sample_date older than ${params.time_window} days: \\$(cat ${filtered_on_sample_date} | grep 'sample_date older than' | wc -l)\\\\n\" >> announce.json\n            echo \"> Number of sequences after downsampling: \\$(cat ${downsampled} | grep '>' | wc -l)\\\\n\" >> announce.json\n            echo '\"}' >> announce.json\n            \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [
            "getnumber",
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/getnumber",
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "getnumber",
                "uri": "https://bio.tools/getnumber",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3321",
                            "term": "Molecular genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3002",
                                "term": "Annotation track"
                            },
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            },
                            {
                                "uri": "http://edamontology.org/data_0006",
                                "term": "Data"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2968",
                                "term": "Image"
                            }
                        ]
                    }
                ],
                "description": "Get the distribution of exons per transcripts, or mapping per read, or transcript per cluster.",
                "homepage": "https://urgi.versailles.inra.fr/Tools/REPET"
            },
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "original",
            "unique",
            "filtered_on_ambiguous_sites",
            "filtered_on_sample_date",
            "downsampled"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "announce_metadata_pruned_tree": {
        "name_process": "announce_metadata_pruned_tree",
        "string_process": "\nprocess announce_metadata_pruned_tree {\n       \n                                    \n                 \n      \n\n    input:\n    path tree\n    path metadata\n    path pruned_tree\n\n    output:\n    path \"metadata_pruned_tree.json\"\n\n    script:\n        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > metadata_pruned_tree.json\n            echo \"*${params.whoami}: Metadata pruned tree for ${params.date} complete*\\\\n\" >> metadata_pruned_tree.json\n            echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n            echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n            echo \"> Total number of sequences in metadata: \\$(tail -n+1 ${metadata} | wc -l)\\\\n\" >> metadata_pruned_tree.json\n            echo '\"}' >> metadata_pruned_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @metadata_pruned_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           echo '{\"text\":\"' > metadata_pruned_tree.json\n           echo \"*${params.whoami}: Metadata pruned tree for ${params.date} complete*\\\\n\" >> metadata_pruned_tree.json\n           echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n           echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n           echo \"> Total number of sequences in metadata: \\$(tail -n+1 ${metadata} | wc -l)\\\\n\" >> metadata_pruned_tree.json\n           echo '\"}' >> metadata_pruned_tree.json\n           \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > metadata_pruned_tree.json\n            echo \"*${params.whoami}: Metadata pruned tree for ${params.date} complete*\\\\n\" >> metadata_pruned_tree.json\n            echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n            echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n            echo \"> Total number of sequences in metadata: \\$(tail -n+1 ${metadata} | wc -l)\\\\n\" >> metadata_pruned_tree.json\n            echo '\"}' >> metadata_pruned_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @metadata_pruned_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           echo '{\"text\":\"' > metadata_pruned_tree.json\n           echo \"*${params.whoami}: Metadata pruned tree for ${params.date} complete*\\\\n\" >> metadata_pruned_tree.json\n           echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n           echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> metadata_pruned_tree.json\n           echo \"> Total number of sequences in metadata: \\$(tail -n+1 ${metadata} | wc -l)\\\\n\" >> metadata_pruned_tree.json\n           echo '\"}' >> metadata_pruned_tree.json\n           \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [
            "totalVI",
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/totalVI",
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "totalVI",
                "uri": "https://bio.tools/totalVI",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0108",
                            "term": "Protein expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0166",
                            "term": "Protein structural motifs and surfaces"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0166",
                            "term": "Protein 3D motifs"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3630",
                                    "term": "Protein quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3630",
                                    "term": "Protein quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A Joint Model of RNA Expression and Surface Protein Abundance in Single Cells.",
                "homepage": "http://github.com/adamgayoso/totalVI_reproducibility"
            },
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "tree",
            "metadata",
            "pruned_tree"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "csv_to_tsv": {
        "name_process": "csv_to_tsv",
        "string_process": "\nprocess csv_to_tsv {\n    input:\n    path csv\n\n    output:\n    path \"${csv.baseName}.tsv\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/lineages_csv_to_tsv.py \\\n      --in-csv ${csv} \\\n      --out-tsv \"${csv.baseName}.tsv\"\n    \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "    \"\"\"\n    $project_dir/../bin/lineages_csv_to_tsv.py \\\n      --in-csv ${csv} \\\n      --out-tsv \"${csv.baseName}.tsv\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "csv"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "make_lineage_annotated_tree": {
        "name_process": "make_lineage_annotated_tree",
        "string_process": "\nprocess make_lineage_annotated_tree {\n       \n                                                     \n                               \n                      \n      \n\n    publishDir \"${publish_dir}/pangolin\", pattern: \"*.pb\", mode: 'copy'\n\n    input:\n    path protobuf\n    path lineages\n\n    output:\n    path \"${protobuf.baseName}.lineages.pb\"\n\n    script:\n    \"\"\"\n    matUtils annotate -i ${protobuf} -c ${lineages} -o \"${protobuf.baseName}.lineages.pb\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    matUtils annotate -i ${protobuf} -c ${lineages} -o \"${protobuf.baseName}.lineages.pb\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "protobuf",
            "lineages"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dir}/pangolin\", pattern: \"*.pb\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "anonymize_protobuf": {
        "name_process": "anonymize_protobuf",
        "string_process": "\nprocess anonymize_protobuf {\n       \n                                                     \n                     \n                      \n      \n\n    publishDir \"${publish_dir}/pangolin\", pattern: \"*.pb\", mode: 'copy'\n\n    input:\n    path protobuf\n\n    output:\n    path \"lineageTree.pb\"\n\n    script:\n    \"\"\"\n    matUtils mask -i ${protobuf} -S -o lineageTree.pb\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    matUtils mask -i ${protobuf} -S -o lineageTree.pb\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "protobuf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dir}/pangolin\", pattern: \"*.pb\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "announce_training_complete": {
        "name_process": "announce_training_complete",
        "string_process": "\nprocess announce_training_complete {\n       \n                                       \n                     \n      \n\n    input:\n    path protobuf\n\n    output:\n    path \"usher_pb.json\"\n\n    script:\n        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > usher_pb.json\n            echo \"*${params.whoami}: Usher training for ${params.date} complete*\\\\n\" >> usher_pb.json\n            echo '\"}' >> usher_pb.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @usher_pb.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           touch \"usher_pb.json\"\n           \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > usher_pb.json\n            echo \"*${params.whoami}: Usher training for ${params.date} complete*\\\\n\" >> usher_pb.json\n            echo '\"}' >> usher_pb.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @usher_pb.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           touch \"usher_pb.json\"\n           \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "protobuf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "annotate_tree_uk": {
        "name_process": "annotate_tree_uk",
        "string_process": "\nprocess annotate_tree_uk {\n       \n                                       \n                           \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n    path metadata\n\n    output:\n    path \"annotated1.tree\"\n\n    script:\n    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n          --in-metadata ${metadata} \\\n          --index-column sequence_name \\\n          --filter-column sequence_name country lineage uk_lineage \\\n          --out-metadata tmp.out.csv \\\n          --in-fasta in.fa \\\n          --out-fasta out.fa\n\n    clusterfunk annotate_tips \\\n        --in-metadata tmp.out.csv \\\n        --trait-columns country lineage uk_lineage \\\n        --index-column sequence_name \\\n        --boolean-for-trait country='UK' country='UK' \\\n        --boolean-trait-names country_uk country_uk_deltran \\\n        --in-format newick \\\n        --out-format nexus \\\n        --input ${tree} \\\n        --output \"annotated1.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n          --in-metadata ${metadata} \\\n          --index-column sequence_name \\\n          --filter-column sequence_name country lineage uk_lineage \\\n          --out-metadata tmp.out.csv \\\n          --in-fasta in.fa \\\n          --out-fasta out.fa\n\n    clusterfunk annotate_tips \\\n        --in-metadata tmp.out.csv \\\n        --trait-columns country lineage uk_lineage \\\n        --index-column sequence_name \\\n        --boolean-for-trait country='UK' country='UK' \\\n        --boolean-trait-names country_uk country_uk_deltran \\\n        --in-format newick \\\n        --out-format nexus \\\n        --input ${tree} \\\n        --output \"annotated1.tree\"\n    \"\"\"",
        "nb_lignes_script": 21,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "deltran_ancestral_reconstruction": {
        "name_process": "deltran_ancestral_reconstruction",
        "string_process": "\nprocess deltran_ancestral_reconstruction {\n       \n                     \n                 \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n\n    output:\n    path \"${tree.baseName}.deltrans.tree\"\n\n    script:\n    \"\"\"\n    clusterfunk ancestral_reconstruction \\\n        --traits country_uk_deltran \\\n        --deltran \\\n        --ancestral-state False \\\n        --input ${tree} \\\n        --output ${tree.baseName}.deltrans.tree\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    clusterfunk ancestral_reconstruction \\\n        --traits country_uk_deltran \\\n        --deltran \\\n        --ancestral-state False \\\n        --input ${tree} \\\n        --output ${tree.baseName}.deltrans.tree\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "label_deltran_introductions": {
        "name_process": "label_deltran_introductions",
        "string_process": "\nprocess label_deltran_introductions {\n       \n                                  \n                 \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n\n    output:\n    path \"${tree.baseName}.del_labelled.tree\"\n\n    script:\n    \"\"\"\n    clusterfunk label_transitions \\\n        --trait country_uk_deltran \\\n        --to True \\\n        --transition-name del_introduction \\\n        --transition-prefix del_trans_ \\\n        --stubborn \\\n        --input \"${tree}\" \\\n        --output \"${tree.baseName}.del_labelled.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    clusterfunk label_transitions \\\n        --trait country_uk_deltran \\\n        --to True \\\n        --transition-name del_introduction \\\n        --transition-prefix del_trans_ \\\n        --stubborn \\\n        --input \"${tree}\" \\\n        --output \"${tree.baseName}.del_labelled.tree\"\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "merge_sibling_del_introduction": {
        "name_process": "merge_sibling_del_introduction",
        "string_process": "\nprocess merge_sibling_del_introduction {\n       \n                                          \n                 \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n\n    output:\n    path \"${tree.baseName}.del_merged.tree\"\n\n    script:\n    \"\"\"\n    clusterfunk merge_transitions \\\n        --trait-to-merge del_introduction \\\n        --merged-trait-name del_lineage \\\n        --merge-siblings \\\n        --input ${tree} \\\n        --output \"${tree.baseName}.del_merged.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    clusterfunk merge_transitions \\\n        --trait-to-merge del_introduction \\\n        --merged-trait-name del_lineage \\\n        --merge-siblings \\\n        --input ${tree} \\\n        --output \"${tree.baseName}.del_merged.tree\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "output_annotations": {
        "name_process": "output_annotations",
        "string_process": "\nprocess output_annotations {\n       \n                        \n                 \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n\n    output:\n    path \"all_traits.csv\"\n\n    script:\n    \"\"\"\n    clusterfunk extract_tip_annotations \\\n        --traits country uk_lineage del_introduction del_lineage \\\n        --input ${tree} \\\n        --output \"all_traits.csv\"\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    clusterfunk extract_tip_annotations \\\n        --traits country uk_lineage del_introduction del_lineage \\\n        --input ${tree} \\\n        --output \"all_traits.csv\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "merge_and_create_new_uk_lineages": {
        "name_process": "merge_and_create_new_uk_lineages",
        "string_process": "\nprocess merge_and_create_new_uk_lineages {\n       \n                                      \n                       \n      \n\n    label 'retry_increasing_mem'\n    \n    input:\n    path traits_csv\n\n    output:\n    path \"updated_traits.csv\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/curate_linages.py \\\n            ${traits_csv} \\\n            \"updated_traits.csv\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    $project_dir/../bin/curate_linages.py \\\n            ${traits_csv} \\\n            \"updated_traits.csv\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "traits_csv"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "generate_sankey_plot": {
        "name_process": "generate_sankey_plot",
        "string_process": "\nprocess generate_sankey_plot {\n       \n                                          \n                                       \n      \n\n    input:\n    path traits_csv\n    path new_traits_csv\n\n    output:\n    path \"sankey_links.txt\"\n    path \"sankey.html\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/get_sankey_links.py \\\n            ${traits_csv} \\\n            ${new_traits_csv} \\\n            \"sankey_links.txt\"\n\n    Rscript $project_dir/../bin/plot_sankey.R \"sankey_links.txt\" \"sankey.html\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    $project_dir/../bin/get_sankey_links.py \\\n            ${traits_csv} \\\n            ${new_traits_csv} \\\n            \"sankey_links.txt\"\n\n    Rscript $project_dir/../bin/plot_sankey.R \"sankey_links.txt\" \"sankey.html\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "traits_csv",
            "new_traits_csv"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "update_uk_lineage_metadata": {
        "name_process": "update_uk_lineage_metadata",
        "string_process": "\nprocess update_uk_lineage_metadata {\n       \n                                                                                     \n                                                 \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path metadata\n    path traits_csv\n    path uk_lineage_csv\n\n    output:\n    path \"cog_gisaid.lineages.with_all_traits.csv\"\n\n    script:\n    \"\"\"\n    fastafunk add_columns \\\n              --in-metadata ${metadata} \\\n              --in-data ${traits_csv} \\\n              --index-column sequence_name \\\n              --join-on taxon \\\n              --new-columns del_lineage del_introduction \\\n              --out-metadata tmp.csv\n\n    fastafunk add_columns \\\n              --in-metadata tmp.csv \\\n              --in-data ${uk_lineage_csv} \\\n              --index-column sequence_name \\\n              --join-on taxon \\\n              --new-columns uk_lineage microreact_lineage \\\n              --out-metadata \"cog_gisaid.lineages.with_all_traits.csv\"\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n    fastafunk add_columns \\\n              --in-metadata ${metadata} \\\n              --in-data ${traits_csv} \\\n              --index-column sequence_name \\\n              --join-on taxon \\\n              --new-columns del_lineage del_introduction \\\n              --out-metadata tmp.csv\n\n    fastafunk add_columns \\\n              --in-metadata tmp.csv \\\n              --in-data ${uk_lineage_csv} \\\n              --index-column sequence_name \\\n              --join-on taxon \\\n              --new-columns uk_lineage microreact_lineage \\\n              --out-metadata \"cog_gisaid.lineages.with_all_traits.csv\"\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata",
            "traits_csv",
            "uk_lineage_csv"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "annotate_tree_uk_lineage": {
        "name_process": "annotate_tree_uk_lineage",
        "string_process": "\nprocess annotate_tree_uk_lineage {\n       \n                                       \n                           \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n    path metadata\n\n    output:\n    path \"annotated2.tree\"\n\n    script:\n    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n              --in-metadata ${metadata} \\\n              --index-column sequence_name \\\n              --filter-column sequence_name lineage uk_lineage \\\n              --out-metadata tmp.out.csv \\\n              --in-fasta in.fa \\\n              --out-fasta out.fa\n\n    clusterfunk annotate_tips \\\n        --in-metadata tmp.out.csv \\\n        --trait-columns uk_lineage \\\n        --index-column sequence_name \\\n        --input ${tree} \\\n        --output \"annotated2.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n              --in-metadata ${metadata} \\\n              --index-column sequence_name \\\n              --filter-column sequence_name lineage uk_lineage \\\n              --out-metadata tmp.out.csv \\\n              --in-fasta in.fa \\\n              --out-fasta out.fa\n\n    clusterfunk annotate_tips \\\n        --in-metadata tmp.out.csv \\\n        --trait-columns uk_lineage \\\n        --index-column sequence_name \\\n        --input ${tree} \\\n        --output \"annotated2.tree\"\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "get_uk_lineage_tips": {
        "name_process": "get_uk_lineage_tips",
        "string_process": "\nprocess get_uk_lineage_tips {\n       \n                                             \n                     \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path metadata\n\n    output:\n    path \"UK*.txt\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/get_uk_lineage_tips.py \\\n            --in-metadata ${metadata}\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    $project_dir/../bin/get_uk_lineage_tips.py \\\n            --in-metadata ${metadata}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "dequote_tree": {
        "name_process": "dequote_tree",
        "string_process": "\nprocess dequote_tree {\n       \n                   \n                 \n      \n\n    input:\n    path tree\n\n    output:\n    path \"${tree.baseName}.dequote.tree\"\n\n    script:\n    \"\"\"\n    sed \"s/'//g\" ${tree} > \"${tree.baseName}.dequote.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    sed \"s/'//g\" ${tree} > \"${tree.baseName}.dequote.tree\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "cut_out_tree": {
        "name_process": "cut_out_tree",
        "string_process": "\nprocess cut_out_tree {\n       \n                                                 \n                           \n      \n\n    input:\n    path tree\n    path tip_file\n\n    output:\n    path \"trees/${tip_file.baseName}.tree\"\n\n    script:\n    \"\"\"\n    mkdir -p trees\n    gotree prune -r \\\n        -i ${tree} \\\n        --tipfile ${tip_file} \\\n        -o \"trees/${tip_file.baseName}.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    mkdir -p trees\n    gotree prune -r \\\n        -i ${tree} \\\n        --tipfile ${tip_file} \\\n        -o \"trees/${tip_file.baseName}.tree\"\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "tip_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "phylotype_cut_tree": {
        "name_process": "phylotype_cut_tree",
        "string_process": "\nprocess phylotype_cut_tree {\n       \n                                                               \n                 \n      \n\n    input:\n    path tree\n\n    output:\n    path \"phylotyped_trees/${tree.baseName}.tree\"\n\n    script:\n    \"\"\"\n    mkdir -p phylotyped_trees\n    clusterfunk phylotype \\\n        --threshold ${params.phylotype_threshold} \\\n        --prefix \"${tree.baseName}_1\" \\\n        --input ${tree} \\\n        --in-format newick \\\n        --output \"phylotyped_trees/${tree.baseName}.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    mkdir -p phylotyped_trees\n    clusterfunk phylotype \\\n        --threshold ${params.phylotype_threshold} \\\n        --prefix \"${tree.baseName}_1\" \\\n        --input ${tree} \\\n        --in-format newick \\\n        --output \"phylotyped_trees/${tree.baseName}.tree\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "get_uk_phylotypes_csv": {
        "name_process": "get_uk_phylotypes_csv",
        "string_process": "\nprocess get_uk_phylotypes_csv {\n       \n                             \n                 \n      \n\n    input:\n    path tree\n\n    output:\n    path \"phylotype_csvs/${tree.baseName}.csv\"\n\n    script:\n    \"\"\"\n    mkdir -p phylotype_csvs\n    clusterfunk extract_tip_annotations \\\n        --traits country phylotype \\\n        --input ${tree} \\\n        --output \"phylotype_csvs/${tree.baseName}.csv\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    mkdir -p phylotype_csvs\n    clusterfunk extract_tip_annotations \\\n        --traits country phylotype \\\n        --input ${tree} \\\n        --output \"phylotype_csvs/${tree.baseName}.csv\"\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "update_metadata_with_phylotypes": {
        "name_process": "update_metadata_with_phylotypes",
        "string_process": "\nprocess update_metadata_with_phylotypes {\n       \n                                                                                     \n                                                 \n      \n\n    input:\n    path metadata\n    path phylotypes_csv\n\n    output:\n    path \"${metadata.baseName}.with_phylotype_traits.csv\"\n\n    script:\n    \"\"\"\n    fastafunk add_columns \\\n              --in-metadata ${metadata} \\\n              --in-data ${phylotypes_csv} \\\n              --index-column sequence_name \\\n              --join-on taxon \\\n              --new-columns phylotype \\\n              --out-metadata \"${metadata.baseName}.with_phylotype_traits.csv\"\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    fastafunk add_columns \\\n              --in-metadata ${metadata} \\\n              --in-data ${phylotypes_csv} \\\n              --index-column sequence_name \\\n              --join-on taxon \\\n              --new-columns phylotype \\\n              --out-metadata \"${metadata.baseName}.with_phylotype_traits.csv\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata",
            "phylotypes_csv"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "annotate_tree_phylotype": {
        "name_process": "annotate_tree_phylotype",
        "string_process": "\nprocess annotate_tree_phylotype {\n       \n                                       \n                           \n      \n    publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.nexus\" }, overwrite: true\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n    path metadata\n\n    output:\n    path \"annotated3.tree\"\n\n    script:\n    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n              --in-metadata ${metadata} \\\n              --index-column sequence_name \\\n              --filter-column sequence_name phylotype \\\n              --out-metadata tmp.out.csv \\\n              --in-fasta in.fa \\\n              --out-fasta out.fa\n\n    clusterfunk annotate_tips \\\n        --in-metadata tmp.out.csv \\\n        --trait-columns phylotype \\\n        --index-column sequence_name \\\n        --input ${tree} \\\n        --output \"annotated3.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n              --in-metadata ${metadata} \\\n              --index-column sequence_name \\\n              --filter-column sequence_name phylotype \\\n              --out-metadata tmp.out.csv \\\n              --in-fasta in.fa \\\n              --out-fasta out.fa\n\n    clusterfunk annotate_tips \\\n        --in-metadata tmp.out.csv \\\n        --trait-columns phylotype \\\n        --index-column sequence_name \\\n        --input ${tree} \\\n        --output \"annotated3.tree\"\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.nexus\" }, overwrite: true",
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "announce_annotation_complete": {
        "name_process": "announce_annotation_complete",
        "string_process": "\nprocess announce_annotation_complete {\n       \n                                           \n                 \n      \n\n    input:\n    path tree\n\n    output:\n    path \"full_tree.json\"\n\n    script:\n        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > full_tree.json\n            echo \"*${params.whoami}: Annotated tree for ${params.date} complete*\\\\n\" >> full_tree.json\n            echo '\"}' >> full_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @full_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           touch \"full_tree.json\"\n           \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > full_tree.json\n            echo \"*${params.whoami}: Annotated tree for ${params.date} complete*\\\\n\" >> full_tree.json\n            echo '\"}' >> full_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @full_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           touch \"full_tree.json\"\n           \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "annotate_tree": {
        "name_process": "annotate_tree",
        "string_process": "\nprocess annotate_tree {\n       \n                                       \n                           \n      \n    errorStrategy { task.attempt < 3 ? 'retry' : 'terminate'}\n    memory {8.GB * task.attempt}\n    maxRetries 3\n\n    input:\n    path tree\n    path metadata\n\n    output:\n    path \"annotated.tree\"\n\n    script:\n    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n      --in-metadata ${metadata} \\\n      --index-column sequence_name \\\n      --filter-column sequence_name ${params.annotations} \\\n      --out-metadata tmp.out.csv \\\n      --in-fasta in.fa \\\n      --out-fasta out.fa\n\n    jclusterfunk annotate \\\n      -i ${tree} \\\n      -c sequence_name \\\n      -m tmp.out.csv \\\n      --tip-attributes ${params.annotations} \\\n      -o \"annotated.tree\" \\\n      --ignore-missing\n    \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "    \"\"\"\n    touch in.fa\n\n    fastafunk fetch \\\n      --in-metadata ${metadata} \\\n      --index-column sequence_name \\\n      --filter-column sequence_name ${params.annotations} \\\n      --out-metadata tmp.out.csv \\\n      --in-fasta in.fa \\\n      --out-fasta out.fa\n\n    jclusterfunk annotate \\\n      -i ${tree} \\\n      -c sequence_name \\\n      -m tmp.out.csv \\\n      --tip-attributes ${params.annotations} \\\n      -o \"annotated.tree\" \\\n      --ignore-missing\n    \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "errorStrategy { task.attempt < 3 ? 'retry' : 'terminate'}",
            "memory {8.GB * task.attempt}",
            "maxRetries 3"
        ],
        "when": "",
        "stub": ""
    },
    "get_unreliable_tips": {
        "name_process": "get_unreliable_tips",
        "string_process": "\nprocess get_unreliable_tips {\n       \n                                        \n                     \n      \n\n    input:\n    path metadata\n\n    output:\n    path \"${metadata.baseName}.tips.txt\"\n\n    script:\n    \"\"\"\n    #!/usr/bin/env python3\n    import csv\n\n    filter_column = \"is_unreliable_in_tree\"\n    index_column = \"sequence_name\"\n    with open(\"${metadata}\", 'r', newline = '') as csv_in, \\\n         open(\"${metadata.baseName}.tips.txt\", 'w') as tips_out:\n        reader = csv.DictReader(csv_in, delimiter=\",\", quotechar='\\\"', dialect = \"unix\")\n        if index_column not in reader.fieldnames:\n            sys.exit(\"Index column %s not in CSV\" %index_column)\n        if filter_column in reader.fieldnames:\n            for row in reader:\n                if row[filter_column] in [\"Y\",\"Yes\",\"yes\",\"y\",True,\"True\"]:\n                    name = row[index_column].replace('\"','').replace(\"'\",\"\")\n                    tips_out.write(\"'%s'\\\\n\" %name)\n                    tips_out.write(\"%s\\\\n\" %name)\n    \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    \"\"\"\n    #!/usr/bin/env python3\n    import csv\n\n    filter_column = \"is_unreliable_in_tree\"\n    index_column = \"sequence_name\"\n    with open(\"${metadata}\", 'r', newline = '') as csv_in, \\\n         open(\"${metadata.baseName}.tips.txt\", 'w') as tips_out:\n        reader = csv.DictReader(csv_in, delimiter=\",\", quotechar='\\\"', dialect = \"unix\")\n        if index_column not in reader.fieldnames:\n            sys.exit(\"Index column %s not in CSV\" %index_column)\n        if filter_column in reader.fieldnames:\n            for row in reader:\n                if row[filter_column] in [\"Y\",\"Yes\",\"yes\",\"y\",True,\"True\"]:\n                    name = row[index_column].replace('\"','').replace(\"'\",\"\")\n                    tips_out.write(\"'%s'\\\\n\" %name)\n                    tips_out.write(\"%s\\\\n\" %name)\n    \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "prune_unreliable_tips": {
        "name_process": "prune_unreliable_tips",
        "string_process": "\nprocess prune_unreliable_tips {\n       \n                                     \n                           \n      \n\n    input:\n    path tree\n    path tips\n\n    output:\n    path \"${tree.baseName}.pruned.newick\"\n\n    script:\n    if ( params.prune )\n    \"\"\"\n    gotree prune \\\n      -i ${tree} \\\n      -f ${tips} \\\n      -o \"${tree.baseName}.pruned.newick\"\n    \"\"\"\n    else\n    \"\"\"\n    cp ${tree} \"${tree.baseName}.pruned.newick\"\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    if ( params.prune )\n    \"\"\"\n    gotree prune \\\n      -i ${tree} \\\n      -f ${tips} \\\n      -o \"${tree.baseName}.pruned.newick\"\n    \"\"\"\n    else\n    \"\"\"\n    cp ${tree} \"${tree.baseName}.pruned.newick\"\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "tips"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "announce_unreliable_pruned_tree": {
        "name_process": "announce_unreliable_pruned_tree",
        "string_process": "\nprocess announce_unreliable_pruned_tree {\n       \n                                      \n                                    \n      \n\n    input:\n    path tree\n    path tips\n    path pruned_tree\n\n    output:\n    path \"unreliable_pruned_tree.json\"\n\n    script:\n        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > unreliable_pruned_tree.json\n            echo \"*${params.whoami}: Pruned tree with unreliable tips removed for ${params.date} complete*\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in unreliable list: \\$(tail -n+1 ${tips} | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo '\"}' >> metadata_pruned_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @unreliable_pruned_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n            echo '{\"text\":\"' > unreliable_pruned_tree.json\n            echo \"*${params.whoami}: Pruned tree with unreliable tips removed for ${params.date} complete*\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in unreliable list: \\$(tail -n+1 ${tips} | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo '\"}' >> metadata_pruned_tree.json\n\n           \"\"\"\n}",
        "nb_lignes_process": 38,
        "string_script": "        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > unreliable_pruned_tree.json\n            echo \"*${params.whoami}: Pruned tree with unreliable tips removed for ${params.date} complete*\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in unreliable list: \\$(tail -n+1 ${tips} | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo '\"}' >> metadata_pruned_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @unreliable_pruned_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n            echo '{\"text\":\"' > unreliable_pruned_tree.json\n            echo \"*${params.whoami}: Pruned tree with unreliable tips removed for ${params.date} complete*\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in original tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in pruned tree: \\$(gotree stats tips -i ${pruned_tree} | tail -n+2 | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo \"> Total number of sequences in unreliable list: \\$(tail -n+1 ${tips} | wc -l)\\\\n\" >> unreliable_pruned_tree.json\n            echo '\"}' >> metadata_pruned_tree.json\n\n           \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [
            "totalVI",
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/totalVI",
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "totalVI",
                "uri": "https://bio.tools/totalVI",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0108",
                            "term": "Protein expression"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0166",
                            "term": "Protein structural motifs and surfaces"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0166",
                            "term": "Protein 3D motifs"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3630",
                                    "term": "Protein quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2495",
                                    "term": "Expression data analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3630",
                                    "term": "Protein quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A Joint Model of RNA Expression and Surface Protein Abundance in Single Cells.",
                "homepage": "http://github.com/adamgayoso/totalVI_reproducibility"
            },
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "tree",
            "tips",
            "pruned_tree"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "extract_tips_fasta": {
        "name_process": "extract_tips_fasta",
        "string_process": "\nprocess extract_tips_fasta {\n       \n                                                      \n                        \n      \n    label 'retry_increasing_mem'\n\n    input:\n    path fasta\n    path tree\n\n    output:\n    path \"${fasta.baseName}.tips.fasta\", emit: fasta\n    path \"${fasta.baseName}.new.fasta\", emit: to_add\n\n    script:\n    \"\"\"\n    fastafunk extract \\\n        --in-fasta ${fasta} \\\n        --in-tree ${tree} \\\n        --out-fasta \"${fasta.baseName}.tips.fasta\" \\\n        --reject-fasta \"${fasta.baseName}.new.fasta\" \\\n        --low-memory\n    # hack to make sure nexflow doesn't stall if no new sequences\n    if [  -z \\$(head -n1 \"${fasta.baseName}.new.fasta\") ]\n    then\n        head -n10 \"${fasta.baseName}.tips.fasta\" > \"${fasta.baseName}.new.fasta\"\n    fi\n    if [  -z \\$(head -n1 \"${fasta.baseName}.tips.fasta\") ]\n    then\n        head -n10 \"${fasta.baseName}.new.fasta\" > \"${fasta.baseName}.tips.fasta\"\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    \"\"\"\n    fastafunk extract \\\n        --in-fasta ${fasta} \\\n        --in-tree ${tree} \\\n        --out-fasta \"${fasta.baseName}.tips.fasta\" \\\n        --reject-fasta \"${fasta.baseName}.new.fasta\" \\\n        --low-memory\n    # hack to make sure nexflow doesn't stall if no new sequences\n    if [  -z \\$(head -n1 \"${fasta.baseName}.new.fasta\") ]\n    then\n        head -n10 \"${fasta.baseName}.tips.fasta\" > \"${fasta.baseName}.new.fasta\"\n    fi\n    if [  -z \\$(head -n1 \"${fasta.baseName}.tips.fasta\") ]\n    then\n        head -n10 \"${fasta.baseName}.new.fasta\" > \"${fasta.baseName}.tips.fasta\"\n    fi\n    \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "tree"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "publish_master_metadata": {
        "name_process": "publish_master_metadata",
        "string_process": "\nprocess publish_master_metadata {\n       \n                                                     \n                     \n                      \n      \n\n    publishDir \"${publish_dev}\", pattern: \"*/*.csv\", mode: 'copy', overwrite: true\n\n    input:\n    path metadata\n    val category\n\n    output:\n    path \"${category}/${category}_master.csv\"\n\n    script:\n    \"\"\"\n    mkdir -p ${category}\n    cp ${metadata} ${category}/${category}_master.csv\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    mkdir -p ${category}\n    cp ${metadata} ${category}/${category}_master.csv\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata",
            "category"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}\", pattern: \"*/*.csv\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "fetch_min_metadata": {
        "name_process": "fetch_min_metadata",
        "string_process": "\nprocess fetch_min_metadata {\n       \n                                                                                    \n                            \n                                 \n      \n\n    input:\n    path fasta\n    path metadata\n\n    output:\n    path \"cog_gisaid_min.fa\", emit: fasta\n    path \"cog_gisaid_min.csv\", emit: min_metadata\n\n    script:\n    \"\"\"\n        fastafunk fetch \\\n          --in-fasta ${fasta} \\\n          --in-metadata ${metadata} \\\n          --index-column sequence_name \\\n          --filter-column sequence_name is_uk is_cog_uk \\\n          --out-fasta \"cog_gisaid_min.fa\" \\\n          --out-metadata \"cog_gisaid_min.csv\" \\\n          --restrict --low-memory\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n        fastafunk fetch \\\n          --in-fasta ${fasta} \\\n          --in-metadata ${metadata} \\\n          --index-column sequence_name \\\n          --filter-column sequence_name is_uk is_cog_uk \\\n          --out-fasta \"cog_gisaid_min.fa\" \\\n          --out-metadata \"cog_gisaid_min.csv\" \\\n          --restrict --low-memory\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "split_recipes": {
        "name_process": "split_recipes",
        "string_process": "\nprocess split_recipes {\n    input:\n    path recipes\n\n    output:\n    path \"*.json\"\n\n    script:\n    \"\"\"\n    #!/usr/bin/env python3\n    import json\n    i = 0\n\n    with open(\"${recipes}\", 'r') as f:\n        recipes = json.load(f)\n\n        for d in recipes:\n            for entry in recipes[d]:\n                new_recipes = {d:[entry]}\n                with open(\"%i.json\" %i, 'w') as handle:\n                    json.dump(new_recipes,handle)\n                i += 1\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    #!/usr/bin/env python3\n    import json\n    i = 0\n\n    with open(\"${recipes}\", 'r') as f:\n        recipes = json.load(f)\n\n        for d in recipes:\n            for entry in recipes[d]:\n                new_recipes = {d:[entry]}\n                with open(\"%i.json\" %i, 'w') as handle:\n                    json.dump(new_recipes,handle)\n                i += 1\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "python3",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "recipes"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "publish_tree_recipes": {
        "name_process": "publish_tree_recipes",
        "string_process": "\nprocess publish_tree_recipes {\n       \n                                                                                   \n                                                      \n                                  \n                  \n      \n\n    errorStrategy 'retry'\n    memory = {16.GB * task.attempt}\n    maxRetries = 2\n    publishDir \"${publish_dir}/\", pattern: \"**/*.*\", mode: 'copy', overwrite: true\n\n    input:\n    tuple path(fasta),path(metadata),path(mutations),path(constellations),path(newick_tree),path(pruned_newick_tree),path(nexus_tree),path(recipe)\n\n    output:\n    path \"${recipe.baseName}.done.txt\", emit: flag\n    path \"public/cog_*_tree.newick\", optional: true, emit: tree\n    path \"**/cog_*.*\", emit: all\n\n    script:\n    \"\"\"\n    $project_dir/../bin/publish_from_config.py \\\n      --in-fasta ${fasta} \\\n      --in-metadata ${metadata} \\\n      --mutations ${mutations} \\\n      --constellations ${constellations} \\\n      --newick-tree ${newick_tree} \\\n      --pruned-newick-tree ${pruned_newick_tree} \\\n      --nexus-tree ${nexus_tree} \\\n      --seed ${params.seed} \\\n      --recipes ${recipe} \\\n      --date ${params.date}\n    touch \"${recipe.baseName}.done.txt\"\n    \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "    \"\"\"\n    $project_dir/../bin/publish_from_config.py \\\n      --in-fasta ${fasta} \\\n      --in-metadata ${metadata} \\\n      --mutations ${mutations} \\\n      --constellations ${constellations} \\\n      --newick-tree ${newick_tree} \\\n      --pruned-newick-tree ${pruned_newick_tree} \\\n      --nexus-tree ${nexus_tree} \\\n      --seed ${params.seed} \\\n      --recipes ${recipe} \\\n      --date ${params.date}\n    touch \"${recipe.baseName}.done.txt\"\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata",
            "mutations",
            "constellations",
            "newick_tree",
            "pruned_newick_tree",
            "nexus_tree",
            "recipe"
        ],
        "nb_inputs": 8,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "errorStrategy 'retry'",
            "memory = {16.GB * task.attempt}",
            "maxRetries = 2",
            "publishDir \"${publish_dir}/\", pattern: \"**/*.*\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "publish_s3": {
        "name_process": "publish_s3",
        "string_process": "\nprocess publish_s3 {\n       \n                                  \n                 \n      \n\n    publishDir \"${publish_dev}/\", pattern: \"s3dir\", mode: 'copy'\n\n    input:\n    path tree\n\n    output:\n    path s3dir\n\n    script:\n    \"\"\"\n    mkdir -p s3dir\n    cp ${tree} s3dir/cog_global_tree.newick\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    mkdir -p s3dir\n    cp ${tree} s3dir/cog_global_tree.newick\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [
            "s3dir"
        ],
        "nb_outputs": 1,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/\", pattern: \"s3dir\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "announce_to_webhook": {
        "name_process": "announce_to_webhook",
        "string_process": "\nprocess announce_to_webhook {\n    input:\n    file published_files\n    val name\n\n    script:\n    if (params.webhook)\n        \"\"\"\n        echo '{\"text\":\"' > announce.json\n        echo \"*${name} Complete*\\\\n\" >> announce.json\n        echo \"> Dev outputs in : ${publish_dev}\\\\n\" >> announce.json\n        echo \"> Publishable outputs in : ${publish_dir}\\\\n\" >> announce.json\n        echo '\"}' >> announce.json\n        echo 'webhook ${params.webhook}'\n\n        curl -X POST -H \"Content-type: application/json\" -d @announce.json ${params.webhook}\n        \"\"\"\n    else\n        \"\"\"\n        touch \"announce.json\"\n        \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    if (params.webhook)\n        \"\"\"\n        echo '{\"text\":\"' > announce.json\n        echo \"*${name} Complete*\\\\n\" >> announce.json\n        echo \"> Dev outputs in : ${publish_dev}\\\\n\" >> announce.json\n        echo \"> Publishable outputs in : ${publish_dir}\\\\n\" >> announce.json\n        echo '\"}' >> announce.json\n        echo 'webhook ${params.webhook}'\n\n        curl -X POST -H \"Content-type: application/json\" -d @announce.json ${params.webhook}\n        \"\"\"\n    else\n        \"\"\"\n        touch \"announce.json\"\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "imDEV",
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/imdev",
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "imDEV",
                "uri": "https://bio.tools/imdev",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3391",
                            "term": "Omics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3520",
                            "term": "Proteomics experiment"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3664",
                                    "term": "Statistical modelling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3766",
                                    "term": "Weighted correlation network analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0531",
                                    "term": "Heat map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3441",
                                    "term": "Plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2940",
                                    "term": "Scatter plot plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3432",
                                    "term": "Clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2990",
                                    "term": "Classification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3435",
                                    "term": "Standardisation and normalisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2936",
                                    "term": "Dendrograph plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3465",
                                    "term": "Correlation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3659",
                                    "term": "Regression analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3766",
                                    "term": "WGCNA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3766",
                                    "term": "Weighted gene co-expression network analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "PCA plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2939",
                                    "term": "Principal component plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0531",
                                    "term": "Heatmap generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0531",
                                    "term": "Heat map construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2940",
                                    "term": "Scatter chart plotting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2082",
                                "term": "Matrix"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2082",
                                "term": "Matrix"
                            },
                            {
                                "uri": "http://edamontology.org/data_2884",
                                "term": "Plot"
                            },
                            {
                                "uri": "http://edamontology.org/data_1636",
                                "term": "Heat map"
                            }
                        ]
                    }
                ],
                "description": "Data exploration and visualization in Excel.",
                "homepage": "http://imdevsoftware.wordpress.com/"
            },
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "published_files",
            "name"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "get_aliases": {
        "name_process": "get_aliases",
        "string_process": "\nprocess get_aliases {\n       \n                                             \n      \n\n    output:\n    path \"alias_key.json\"\n\n    script:\n        if (params.lineage_aliases)\n            \"\"\"\n            cp ${lineage_aliases} \"alias_key.json\"\n            \"\"\"\n        else\n            \"\"\"\n            wget https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json\n            \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "        if (params.lineage_aliases)\n            \"\"\"\n            cp ${lineage_aliases} \"alias_key.json\"\n            \"\"\"\n        else\n            \"\"\"\n            wget https://raw.githubusercontent.com/cov-lineages/pango-designation/master/pango_designation/alias_key.json\n            \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [],
        "nb_inputs": 0,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "split_fasta": {
        "name_process": "split_fasta",
        "string_process": "\nprocess split_fasta {\n       \n                                     \n                            \n      \n    label 'retry_increasing_mem'\n\n    input:\n    path fasta\n    path metadata\n    path aliases\n\n    output:\n    path \"*.fasta\", emit: fasta\n    path \"*.json\", emit: json\n\n    script:\n    \"\"\"\n    fastafunk split \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --index-column sequence_name \\\n        --index-field lineage \\\n        --lineage-csv ${lineage_splits} \\\n        --aliases ${aliases}\n\n    echo '{\"text\":\"' > pre_tree.json\n    echo \"*${params.whoami}: Ready for ${params.date} tree building*\\\\n\" >> pre_tree.json\n    num_lineages=\\$(cat ${lineage_splits} | wc -l)\n    range={\\$num_lineages..1}\n    for i in \\$(eval echo \\${range})\n    do\n        line=\\$(tail -n\\$i .command.log | head -n1)\n        echo \">\\$line\\\\n\" >> pre_tree.json\n    done\n    echo '\"}' >> pre_tree.json\n    \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "    \"\"\"\n    fastafunk split \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --index-column sequence_name \\\n        --index-field lineage \\\n        --lineage-csv ${lineage_splits} \\\n        --aliases ${aliases}\n\n    echo '{\"text\":\"' > pre_tree.json\n    echo \"*${params.whoami}: Ready for ${params.date} tree building*\\\\n\" >> pre_tree.json\n    num_lineages=\\$(cat ${lineage_splits} | wc -l)\n    range={\\$num_lineages..1}\n    for i in \\$(eval echo \\${range})\n    do\n        line=\\$(tail -n\\$i .command.log | head -n1)\n        echo \">\\$line\\\\n\" >> pre_tree.json\n    done\n    echo '\"}' >> pre_tree.json\n    \"\"\"",
        "nb_lignes_script": 19,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata",
            "aliases"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "announce_split": {
        "name_process": "announce_split",
        "string_process": "\nprocess announce_split {\n       \n                          \n                 \n      \n\n    input:\n    path json\n\n    script:\n    \"\"\"\n    echo 'webhook ${params.webhook}'\n    curl -X POST -H \"Content-type: application/json\" -d @${json} ${params.webhook}\n    \"\"\"\n}",
        "nb_lignes_process": 14,
        "string_script": "    \"\"\"\n    echo 'webhook ${params.webhook}'\n    curl -X POST -H \"Content-type: application/json\" -d @${json} ${params.webhook}\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "json"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "check_tree_building_size": {
        "name_process": "check_tree_building_size",
        "string_process": "\nprocess check_tree_building_size {\n       \n                                              \n                  \n      \n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.checked.fa\"\n\n    script:\n    \"\"\"\n    if [[ \\$(cat ${fasta} | grep \">\" | wc -l) -ge ${params.max_tree_size} ]]\n    then\n        echo \"FASTA TOO BIG TO BUILD\"\n    else\n        cp ${fasta} \"${fasta.baseName}.checked.fa\"\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    if [[ \\$(cat ${fasta} | grep \">\" | wc -l) -ge ${params.max_tree_size} ]]\n    then\n        echo \"FASTA TOO BIG TO BUILD\"\n    else\n        cp ${fasta} \"${fasta.baseName}.checked.fa\"\n    fi\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "fasttree": {
        "name_process": "fasttree",
        "string_process": "\nprocess fasttree {\n       \n                                \n                          \n      \n    memory { 4.0 * task.attempt + lineage_fasta.size() * 0.000000065 < 96 ? 4.GB * task.attempt + lineage_fasta.size() * 65.B : 96.GB }\n    errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n    maxRetries = 1\n    cpus 3\n\n    input:\n    tuple val(lineage), path(lineage_fasta)\n\n    output:\n    tuple val(lineage), path(\"${lineage_fasta.baseName}.unrooted.tree\")\n\n    script:\n    \"\"\"\n    export OMP_NUM_THREADS=${task.cpus}\n    FastTreeMP -nosupport -nt ${lineage_fasta} > ${lineage_fasta.baseName}.unrooted.tree\n    #touch ${lineage_fasta.baseName}.unrooted.tree\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    export OMP_NUM_THREADS=${task.cpus}\n    FastTreeMP -nosupport -nt ${lineage_fasta} > ${lineage_fasta.baseName}.unrooted.tree\n    #touch ${lineage_fasta.baseName}.unrooted.tree\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "lineage",
            "lineage_fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "lineage"
        ],
        "nb_outputs": 1,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "memory { 4.0 * task.attempt + lineage_fasta.size() * 0.000000065 < 96 ? 4.GB * task.attempt + lineage_fasta.size() * 65.B : 96.GB }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries = 1",
            "cpus 3"
        ],
        "when": "",
        "stub": ""
    },
    "veryfasttree": {
        "name_process": "veryfasttree",
        "string_process": "\nprocess veryfasttree {\n       \n                                \n                          \n      \n    memory { 8.0 * task.attempt + lineage_fasta.size() * 0.000000065 < 96 ? 8.GB * task.attempt + lineage_fasta.size() * 65.B : 96.GB }\n    errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n    maxRetries = 1\n    cpus 8\n    time '2d'\n\n    input:\n    tuple val(lineage), path(lineage_fasta)\n\n    output:\n    tuple val(lineage), path(\"${lineage_fasta.baseName}.unrooted.tree\")\n\n    script:\n    \"\"\"\n    VeryFastTree -double-precision -nosupport -nt ${lineage_fasta} -threads ${task.cpus} > ${lineage_fasta.baseName}.unrooted.tree\n    #touch ${lineage_fasta.baseName}.unrooted.tree\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    VeryFastTree -double-precision -nosupport -nt ${lineage_fasta} -threads ${task.cpus} > ${lineage_fasta.baseName}.unrooted.tree\n    #touch ${lineage_fasta.baseName}.unrooted.tree\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "lineage",
            "lineage_fasta"
        ],
        "nb_inputs": 2,
        "outputs": [
            "lineage"
        ],
        "nb_outputs": 1,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "memory { 8.0 * task.attempt + lineage_fasta.size() * 0.000000065 < 96 ? 8.GB * task.attempt + lineage_fasta.size() * 65.B : 96.GB }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries = 1",
            "cpus 8",
            "time '2d'"
        ],
        "when": "",
        "stub": ""
    },
    "root_tree": {
        "name_process": "root_tree",
        "string_process": "\nprocess root_tree {\n       \n                          \n                 \n      \n\n    label 'retry_increasing_mem'\n\n    input:\n    path tree\n\n    output:\n    path \"${tree.baseName}.rooted.tree\"\n\n    script:\n    \"\"\"\n    jclusterfunk reroot \\\n        --format newick \\\n        -i ${tree} \\\n        -o ${tree.baseName}.rooted.tree \\\n        --outgroup Wuhan/WH04/2020\n    #touch ${tree.baseName}.rooted.tree\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    jclusterfunk reroot \\\n        --format newick \\\n        -i ${tree} \\\n        -o ${tree.baseName}.rooted.tree \\\n        --outgroup Wuhan/WH04/2020\n    #touch ${tree.baseName}.rooted.tree\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "graft_tree": {
        "name_process": "graft_tree",
        "string_process": "\nprocess graft_tree {\n       \n                                    \n                                         \n      \n    memory { 10.GB * task.attempt + scions.size() * 20.B }\n\n\n    input:\n    path scions\n    val lineages\n    val label\n\n    output:\n    path \"cog_gisaid_grafted.${label}.tree\"\n\n    script:\n    \"\"\"\n    echo \"${lineages}\"\n    echo \"${scions}\"\n    clusterfunk graft \\\n        --scions ${scions} \\\n        --input ${guide_tree} \\\n        --output \"cog_gisaid_grafted.${label}.tree\" \\\n        --in-format newick \\\n        --out-format newick \\\n        --scion-annotation-name scion_lineage \\\n        --annotate-scions ${lineages}\n    #touch cog_gisaid_grafted.tree\n    \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "    \"\"\"\n    echo \"${lineages}\"\n    echo \"${scions}\"\n    clusterfunk graft \\\n        --scions ${scions} \\\n        --input ${guide_tree} \\\n        --output \"cog_gisaid_grafted.${label}.tree\" \\\n        --in-format newick \\\n        --out-format newick \\\n        --scion-annotation-name scion_lineage \\\n        --annotate-scions ${lineages}\n    #touch cog_gisaid_grafted.tree\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "scions",
            "lineages",
            "label"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "memory { 10.GB * task.attempt + scions.size() * 20.B }"
        ],
        "when": "",
        "stub": ""
    },
    "sort_and_collapse": {
        "name_process": "sort_and_collapse",
        "string_process": "\nprocess sort_and_collapse {\n       \n                                           \n                 \n      \n\n    input:\n    path tree\n\n    output:\n    path \"cog_gisaid_full.tree\"\n\n    script:\n    \"\"\"\n    gotree rotate sort -i ${tree} -o rotated.tree\n    gotree collapse length --length ${params.collapse} -i rotated.tree -o cog_gisaid_full.tree\n    \"\"\"\n}",
        "nb_lignes_process": 17,
        "string_script": "    \"\"\"\n    gotree rotate sort -i ${tree} -o rotated.tree\n    gotree collapse length --length ${params.collapse} -i rotated.tree -o cog_gisaid_full.tree\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "announce_tree_complete": {
        "name_process": "announce_tree_complete",
        "string_process": "\nprocess announce_tree_complete {\n       \n                                  \n                 \n      \n\n    input:\n    path tree\n    val label\n\n    output:\n    path \"usher_tree.json\"\n\n    script:\n        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > usher_tree.json\n            echo \"*${params.whoami}: Usher ${label} expanded tree for ${params.date} complete*\\\\n\" >> usher_tree.json\n            echo \"Total number of sequences in tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\n\" >> usher_tree.json\n            echo '\"}' >> usher_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @usher_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           echo '{\"text\":\"' > usher_tree.json\n           echo \"*${params.whoami}: Usher ${label} expanded tree for ${params.date} complete*\\\\n\" >> usher_tree.json\n           echo \"Total number of sequences in tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\n\" >> usher_tree.json\n           echo '\"}' >> usher_tree.json\n           \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > usher_tree.json\n            echo \"*${params.whoami}: Usher ${label} expanded tree for ${params.date} complete*\\\\n\" >> usher_tree.json\n            echo \"Total number of sequences in tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\n\" >> usher_tree.json\n            echo '\"}' >> usher_tree.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @usher_tree.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           echo '{\"text\":\"' > usher_tree.json\n           echo \"*${params.whoami}: Usher ${label} expanded tree for ${params.date} complete*\\\\n\" >> usher_tree.json\n           echo \"Total number of sequences in tree: \\$(gotree stats tips -i ${tree} | tail -n+2 | wc -l)\\n\" >> usher_tree.json\n           echo '\"}' >> usher_tree.json\n           \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "tree",
            "label"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "hash_non_unique_seqs": {
        "name_process": "hash_non_unique_seqs",
        "string_process": "\nprocess hash_non_unique_seqs {\n       \n                                       \n                            \n      \n    memory { fasta.size() * 2.B  + 2.GB * task.attempt }\n    errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n    maxRetries = 2\n\n    input:\n    path fasta\n    path metadata\n\n    output:\n    path \"${fasta.baseName}.unique.fasta\", emit: fasta\n    path \"${fasta.baseName}.hashmap.csv\", emit: hashmap\n\n    script:\n    \"\"\"\n    $project_dir/../bin/hash_non_unique_seqs.py \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --out-fasta \"${fasta.baseName}.unique.fasta\" \\\n        --out-metadata \"${fasta.baseName}.hashmap.csv\" \\\n        --outgroups ${lineage_splits}\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    $project_dir/../bin/hash_non_unique_seqs.py \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --out-fasta \"${fasta.baseName}.unique.fasta\" \\\n        --out-metadata \"${fasta.baseName}.hashmap.csv\" \\\n        --outgroups ${lineage_splits}\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "memory { fasta.size() * 2.B + 2.GB * task.attempt }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries = 2"
        ],
        "when": "",
        "stub": ""
    },
    "expand_hashmap": {
        "name_process": "expand_hashmap",
        "string_process": "\nprocess expand_hashmap {\n       \n                                                    \n                          \n      \n    publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy'\n\n\n    input:\n    path tree\n    path hashmap\n\n    output:\n    path \"${tree.baseName}.expanded.tree\"\n\n    script:\n    \"\"\"\n    jclusterfunk insert \\\n        -i \"${tree}\" \\\n        --metadata ${hashmap} \\\n        --unique-only \\\n        --ignore-missing \\\n        --format newick \\\n        -o \"${tree.baseName}.expanded.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    jclusterfunk insert \\\n        -i \"${tree}\" \\\n        --metadata ${hashmap} \\\n        --unique-only \\\n        --ignore-missing \\\n        --format newick \\\n        -o \"${tree.baseName}.expanded.tree\"\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree",
            "hashmap"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy'"
        ],
        "when": "",
        "stub": ""
    },
    "get_git_hash": {
        "name_process": "get_git_hash",
        "string_process": "\nprocess get_git_hash {\n       \n                     \n      \n    publishDir \"${publish_dev}\", mode: 'copy', overwrite: true\n\n    input:\n    path commit_file\n\n    output:\n    path \"${commit_file}\"\n\n    script:\n    \"\"\"\n    echo \"\\n Git hash \\t = \\t \\$( git rev-parse HEAD) \\n\\n\" >> ${commit_file}\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    echo \"\\n Git hash \\t = \\t \\$( git rev-parse HEAD) \\n\\n\" >> ${commit_file}\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "commit_file"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}\", mode: 'copy', overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "filter_on_sample_date_for_recent": {
        "name_process": "filter_on_sample_date_for_recent",
        "string_process": "\nprocess filter_on_sample_date_for_recent {\n       \n                                                                   \n                                                            \n                     \n                              \n                               \n      \n\n    input:\n    path metadata\n\n    output:\n    path \"${metadata.baseName}.recent.csv\"\n\n    script:\n    if ( params.time_window && params.date )\n        \"\"\"\n        $project_dir/../bin/date_filter.py \\\n                    --in-metadata ${metadata} \\\n                    --out-metadata \"${metadata.baseName}.recent.csv\" \\\n                    --date ${params.date} \\\n                    --time-window ${params.time_window} \\\n                    --filter-column \"why_excluded\" \\\n                    --restrict\n        \"\"\"\n    else\n        \"\"\"\n        echo \"date ${params.date}\"\n        echo \"time window ${params.time_window}\"\n        mv \"${metadata}\" \"${metadata.baseName}.recent.csv\"\n        \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "    if ( params.time_window && params.date )\n        \"\"\"\n        $project_dir/../bin/date_filter.py \\\n                    --in-metadata ${metadata} \\\n                    --out-metadata \"${metadata.baseName}.recent.csv\" \\\n                    --date ${params.date} \\\n                    --time-window ${params.time_window} \\\n                    --filter-column \"why_excluded\" \\\n                    --restrict\n        \"\"\"\n    else\n        \"\"\"\n        echo \"date ${params.date}\"\n        echo \"time window ${params.time_window}\"\n        mv \"${metadata}\" \"${metadata.baseName}.recent.csv\"\n        \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "fetch_recent": {
        "name_process": "fetch_recent",
        "string_process": "\nprocess fetch_recent {\n       \n                                       \n                            \n                   \n      \n\n    input:\n    path fasta\n    path metadata\n\n    output:\n    path \"${fasta.baseName}.recent.fa\"\n\n    script:\n    \"\"\"\n    fastafunk fetch \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --out-fasta \"${fasta.baseName}.recent.fa\" \\\n        --index-column \"sequence_name\" \\\n        --low-memory\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    fastafunk fetch \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --out-fasta \"${fasta.baseName}.recent.fa\" \\\n        --index-column \"sequence_name\" \\\n        --low-memory\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "fetch_designations": {
        "name_process": "fetch_designations",
        "string_process": "\nprocess fetch_designations {\n       \n                                                                \n                  \n      \n    label 'retry_increasing_mem'\n\n    input:\n    path fasta\n    path metadata\n\n    output:\n    path \"${fasta.baseName}.designations.fasta\"\n\n    script:\n    \"\"\"\n    fastafunk extract \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --out-fasta \"${fasta.baseName}.designations.fasta\" \\\n        --reject-fasta \"tmp.fasta\" \\\n        --low-memory\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    fastafunk extract \\\n        --in-fasta ${fasta} \\\n        --in-metadata ${metadata} \\\n        --out-fasta \"${fasta.baseName}.designations.fasta\" \\\n        --reject-fasta \"tmp.fasta\" \\\n        --low-memory\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "fetch_outgroups": {
        "name_process": "fetch_outgroups",
        "string_process": "\nprocess fetch_outgroups {\n       \n                                                             \n                  \n      \n    label 'retry_increasing_mem'\n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.outgroups.fasta\"\n\n    script:\n    \"\"\"\n    tail -n+2 ${lineage_splits} | cut -f2 -d\",\" >> outgroups.csv\n    fastafunk extract \\\n        --in-fasta ${fasta} \\\n        --in-metadata \"outgroups.csv\" \\\n        --out-fasta \"${fasta.baseName}.outgroups.fasta\" \\\n        --reject-fasta \"tmp.fasta\" \\\n        --low-memory\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    tail -n+2 ${lineage_splits} | cut -f2 -d\",\" >> outgroups.csv\n    fastafunk extract \\\n        --in-fasta ${fasta} \\\n        --in-metadata \"outgroups.csv\" \\\n        --out-fasta \"${fasta.baseName}.outgroups.fasta\" \\\n        --reject-fasta \"tmp.fasta\" \\\n        --low-memory\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "label 'retry_increasing_mem'"
        ],
        "when": "",
        "stub": ""
    },
    "filter_blacklist": {
        "name_process": "filter_blacklist",
        "string_process": "\nprocess filter_blacklist {\n       \n                                           \n                  \n      \n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.blacklist_excluded.fa\"\n\n    script:\n    \"\"\"\n    fastafunk remove \\\n      --in-fasta ${fasta} \\\n      --in-metadata ${blacklist} \\\n      --out-fasta \"${fasta.baseName}.blacklist_excluded.fa\"\n    \"\"\"\n}",
        "nb_lignes_process": 19,
        "string_script": "    \"\"\"\n    fastafunk remove \\\n      --in-fasta ${fasta} \\\n      --in-metadata ${blacklist} \\\n      --out-fasta \"${fasta.baseName}.blacklist_excluded.fa\"\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "remove_reference": {
        "name_process": "remove_reference",
        "string_process": "\nprocess remove_reference {\n       \n                                            \n                      \n                               \n                       \n      \n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.noref.fa\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/remove_ref.py \\\n      --in-alignment ${fasta} \\\n      --out-alignment \"${fasta.baseName}.noref.fa\" \\\n      --reference ${reference}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    $project_dir/../bin/remove_ref.py \\\n      --in-alignment ${fasta} \\\n      --out-alignment \"${fasta.baseName}.noref.fa\" \\\n      --reference ${reference}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "mask_fasta": {
        "name_process": "mask_fasta",
        "string_process": "\nprocess mask_fasta {\n       \n                             \n                      \n                               \n                       \n      \n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.masked.fa\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/add_mask.py \\\n      --in-alignment ${fasta} \\\n      --out-alignment \"${fasta.baseName}.masked.fa\" \\\n      --vcf ${mask_file} \\\n      --filters nanopore_adapter single_src highly_homoplasic\n    \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "    \"\"\"\n    $project_dir/../bin/add_mask.py \\\n      --in-alignment ${fasta} \\\n      --out-alignment \"${fasta.baseName}.masked.fa\" \\\n      --vcf ${mask_file} \\\n      --filters nanopore_adapter single_src highly_homoplasic\n    \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "copy_protobuf": {
        "name_process": "copy_protobuf",
        "string_process": "\nprocess copy_protobuf {\n       \n                     \n                     \n      \n\n    input:\n    path protobuf\n\n    output:\n    path \"${protobuf.baseName}.in.pb\"\n\n    script:\n    \"\"\"\n    cp ${protobuf} \"${protobuf.baseName}.in.pb\"\n    \"\"\"\n}",
        "nb_lignes_process": 16,
        "string_script": "    \"\"\"\n    cp ${protobuf} \"${protobuf.baseName}.in.pb\"\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "protobuf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "add_reference_to_fasta": {
        "name_process": "add_reference_to_fasta",
        "string_process": "\nprocess add_reference_to_fasta {\n       \n                                              \n                  \n      \n    maxForks 100\n    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }\n\n    input:\n    path fasta\n    path ref\n\n    output:\n    path \"${fasta.baseName}.with_reference.fasta\"\n\n    script:\n    \"\"\"\n    cat ${ref} > \"${fasta.baseName}.with_reference.fasta\"\n    cat ${fasta} >> \"${fasta.baseName}.with_reference.fasta\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    cat ${ref} > \"${fasta.baseName}.with_reference.fasta\"\n    cat ${fasta} >> \"${fasta.baseName}.with_reference.fasta\"\n    \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "ref"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "maxForks 100",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }"
        ],
        "when": "",
        "stub": ""
    },
    "fasta_to_vcf": {
        "name_process": "fasta_to_vcf",
        "string_process": "\nprocess fasta_to_vcf {\n       \n                         \n                  \n      \n    maxForks 100\n    memory { 10.GB * task.attempt + fasta.size() * 3.B }\n    errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }\n\n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.vcf\"\n\n    script:\n    \"\"\"\n    faToVcf ${fasta} ${fasta.baseName}.vcf\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    faToVcf ${fasta} ${fasta.baseName}.vcf\n    \"\"\"",
        "nb_lignes_script": 2,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "maxForks 100",
            "memory { 10.GB * task.attempt + fasta.size() * 3.B }",
            "errorStrategy { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }"
        ],
        "when": "",
        "stub": ""
    },
    "usher_start_tree": {
        "name_process": "usher_start_tree",
        "string_process": "\nprocess usher_start_tree {\n       \n                                         \n                      \n      \n    publishDir \"${publish_dev}/trees\", pattern: \"trees/*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true\n    publishDir \"${publish_dev}/trees\", pattern: \"trees/*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true\n\n    memory { 10.GB * task.attempt + vcf.size() * 3.B }\n    errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }\n    maxRetries 1\n    cpus {params.max_cpus}\n\n    input:\n    path vcf\n    path tree\n\n    output:\n    path \"trees/${tree.baseName}.USH.tree\", emit: tree\n    path \"trees/${tree.baseName}.pb\", emit: protobuf\n\n    script:\n    \"\"\"\n    mkdir -p trees\n    usher --tree ${tree} \\\n          --vcf ${vcf} \\\n          --threads ${task.cpus} \\\n          --save-mutation-annotated-tree trees/${tree.baseName}.pb \\\n          --max-uncertainty-per-sample ${params.max_parsimony_placements} \\\n          --collapse-tree \\\n          --write-uncondensed-final-tree \\\n          --outdir trees\n\n    cp trees/uncondensed-final-tree.nh trees/${tree.baseName}.USH.tree\n    \"\"\"\n}",
        "nb_lignes_process": 35,
        "string_script": "    \"\"\"\n    mkdir -p trees\n    usher --tree ${tree} \\\n          --vcf ${vcf} \\\n          --threads ${task.cpus} \\\n          --save-mutation-annotated-tree trees/${tree.baseName}.pb \\\n          --max-uncertainty-per-sample ${params.max_parsimony_placements} \\\n          --collapse-tree \\\n          --write-uncondensed-final-tree \\\n          --outdir trees\n\n    cp trees/uncondensed-final-tree.nh trees/${tree.baseName}.USH.tree\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vcf",
            "tree"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"trees/*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true",
            "publishDir \"${publish_dev}/trees\", pattern: \"trees/*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true",
            "memory { 10.GB * task.attempt + vcf.size() * 3.B }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'terminate' }",
            "maxRetries 1",
            "cpus {params.max_cpus}"
        ],
        "when": "",
        "stub": ""
    },
    "optimize_start_tree": {
        "name_process": "optimize_start_tree",
        "string_process": "\nprocess optimize_start_tree {\n       \n                                      \n                 \n      \n\n    publishDir \"${publish_dev}/trees\", pattern: \"*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true\n\n    input:\n    path protobuf\n\n    output:\n    path \"${protobuf.baseName}.optimized.pb\"\n\n    script:\n    if (params.optimize)\n    \"\"\"\n    matOptimize -i ${protobuf} \\\n            -o \"${protobuf.baseName}.optimized.pb\" \\\n            -r 100 \\\n            -T ${params.max_cpus} \\\n            -s 259200\n    \"\"\"\n    else\n    \"\"\"\n    mv ${protobuf} \"${protobuf.baseName}.optimized.pb\"\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    if (params.optimize)\n    \"\"\"\n    matOptimize -i ${protobuf} \\\n            -o \"${protobuf.baseName}.optimized.pb\" \\\n            -r 100 \\\n            -T ${params.max_cpus} \\\n            -s 259200\n    \"\"\"\n    else\n    \"\"\"\n    mv ${protobuf} \"${protobuf.baseName}.optimized.pb\"\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "protobuf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "protobuf_to_tree": {
        "name_process": "protobuf_to_tree",
        "string_process": "\nprocess protobuf_to_tree {\n       \n                                      \n                 \n      \n\n    publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true\n\n    input:\n    path protobuf\n\n    output:\n    path \"${protobuf.baseName}.tree\"\n\n    script:\n    \"\"\"\n    matUtils extract \\\n        -i ${protobuf} \\\n        -t \"${protobuf.baseName}.tree\"\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    \"\"\"\n    matUtils extract \\\n        -i ${protobuf} \\\n        -t \"${protobuf.baseName}.tree\"\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "protobuf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true"
        ],
        "when": "",
        "stub": ""
    },
    "usher_update_tree": {
        "name_process": "usher_update_tree",
        "string_process": "\nprocess usher_update_tree {\n       \n                                         \n                      \n      \n    publishDir \"${publish_dev}/trees\", pattern: \"trees/*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true\n    publishDir \"${publish_dev}/trees\", pattern: \"trees/*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true\n\n    memory { 10.GB * task.attempt + vcf_list.size() * 3.B }\n    errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'ignore' }\n    maxRetries 2\n    cpus {params.max_cpus}\n\n    input:\n    path vcf_list\n    path protobuf\n\n    output:\n    path \"trees/${protobuf.baseName}.USH.tree\", emit: tree\n    path \"trees/*.pb\", emit: protobuf\n    path \"usher.log\", emit: usher_log\n\n    script:\n    \"\"\"\n    mkdir -p trees\n    cp ${protobuf} in.pb\n\n    for vcf in ${vcf_list}\n    do\n      echo \"Adding VCF \\$vcf to tree\\n\" >> update_tree.log\n      usher -i in.pb \\\n          --vcf \\$vcf \\\n          --threads ${task.cpus} \\\n          --save-mutation-annotated-tree out.pb \\\n          --max-uncertainty-per-sample ${params.max_parsimony_placements} \\\n          --write-uncondensed-final-tree \\\n          --outdir trees 2>> usher.log\n      echo \"Total number of sequences in tree: \\$(gotree stats tips -i trees/uncondensed-final-tree.nh | tail -n+2 | wc -l)\\n\" >> update_tree.log\n      if [ \\$? -eq 0 ]; then\n        mv out.pb in.pb\n      fi\n    done\n    if [ \\$? -eq 0 ]; then\n        cp in.pb trees/${protobuf.baseName}.${params.date}.pb\n        cp trees/uncondensed-final-tree.nh trees/${protobuf.baseName}.USH.tree\n        cat usher.log | grep \"Number of parsimony-optimal placements\"\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 48,
        "string_script": "    \"\"\"\n    mkdir -p trees\n    cp ${protobuf} in.pb\n\n    for vcf in ${vcf_list}\n    do\n      echo \"Adding VCF \\$vcf to tree\\n\" >> update_tree.log\n      usher -i in.pb \\\n          --vcf \\$vcf \\\n          --threads ${task.cpus} \\\n          --save-mutation-annotated-tree out.pb \\\n          --max-uncertainty-per-sample ${params.max_parsimony_placements} \\\n          --write-uncondensed-final-tree \\\n          --outdir trees 2>> usher.log\n      echo \"Total number of sequences in tree: \\$(gotree stats tips -i trees/uncondensed-final-tree.nh | tail -n+2 | wc -l)\\n\" >> update_tree.log\n      if [ \\$? -eq 0 ]; then\n        mv out.pb in.pb\n      fi\n    done\n    if [ \\$? -eq 0 ]; then\n        cp in.pb trees/${protobuf.baseName}.${params.date}.pb\n        cp trees/uncondensed-final-tree.nh trees/${protobuf.baseName}.USH.tree\n        cat usher.log | grep \"Number of parsimony-optimal placements\"\n    fi\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vcf_list",
            "protobuf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"trees/*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true",
            "publishDir \"${publish_dev}/trees\", pattern: \"trees/*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true",
            "memory { 10.GB * task.attempt + vcf_list.size() * 3.B }",
            "errorStrategy { task.exitStatus in 137..140 ? 'retry' : 'ignore' }",
            "maxRetries 2",
            "cpus {params.max_cpus}"
        ],
        "when": "",
        "stub": ""
    },
    "usher_force_update_tree": {
        "name_process": "usher_force_update_tree",
        "string_process": "\nprocess usher_force_update_tree {\n       \n                                         \n                          \n      \n    publishDir \"${publish_dev}/trees\", pattern: \"trees/*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true\n    publishDir \"${publish_dev}/trees\", pattern: \"trees/*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true\n\n    memory { 140.GB + 160.GB * task.attempt }\n    errorStrategy { task.exitStatus in 137..139 ? 'retry' : 'ignore' }\n    maxRetries 1\n    cpus {params.max_cpus}\n\n    input:\n    path vcf_list\n    path protobuf\n\n    output:\n    path \"trees/${protobuf.baseName}.USH.tree\", emit: tree\n    path \"trees/*.pb\", emit: protobuf\n    path \"usher.log\", emit: usher_log\n\n    script:\n    \"\"\"\n    mkdir -p trees\n        cp ${protobuf} in.pb\n\n        for vcf in ${vcf_list}\n        do\n          echo \"Adding VCF \\$vcf to tree\\n\" >> update_tree.log\n          usher -i in.pb \\\n              --vcf \\$vcf \\\n              --threads ${task.cpus} \\\n              --save-mutation-annotated-tree out.pb \\\n              --write-uncondensed-final-tree \\\n              --outdir trees 2>> usher.log\n          echo \"Total number of sequences in tree: \\$(gotree stats tips -i trees/uncondensed-final-tree.nh | tail -n+2 | wc -l)\\n\" >> update_tree.log\n          if [ \\$? -eq 0 ]; then\n            mv out.pb in.pb\n          fi\n        done\n        if [ \\$? -eq 0 ]; then\n            cp in.pb trees/${protobuf.baseName}.${params.date}.pb\n            cp trees/uncondensed-final-tree.nh trees/${protobuf.baseName}.USH.tree\n        fi\n    \"\"\"\n}",
        "nb_lignes_process": 46,
        "string_script": "    \"\"\"\n    mkdir -p trees\n        cp ${protobuf} in.pb\n\n        for vcf in ${vcf_list}\n        do\n          echo \"Adding VCF \\$vcf to tree\\n\" >> update_tree.log\n          usher -i in.pb \\\n              --vcf \\$vcf \\\n              --threads ${task.cpus} \\\n              --save-mutation-annotated-tree out.pb \\\n              --write-uncondensed-final-tree \\\n              --outdir trees 2>> usher.log\n          echo \"Total number of sequences in tree: \\$(gotree stats tips -i trees/uncondensed-final-tree.nh | tail -n+2 | wc -l)\\n\" >> update_tree.log\n          if [ \\$? -eq 0 ]; then\n            mv out.pb in.pb\n          fi\n        done\n        if [ \\$? -eq 0 ]; then\n            cp in.pb trees/${protobuf.baseName}.${params.date}.pb\n            cp trees/uncondensed-final-tree.nh trees/${protobuf.baseName}.USH.tree\n        fi\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "vcf_list",
            "protobuf"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"trees/*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true",
            "publishDir \"${publish_dev}/trees\", pattern: \"trees/*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true",
            "memory { 140.GB + 160.GB * task.attempt }",
            "errorStrategy { task.exitStatus in 137..139 ? 'retry' : 'ignore' }",
            "maxRetries 1",
            "cpus {params.max_cpus}"
        ],
        "when": "",
        "stub": ""
    },
    "prune_tree_of_long_branches": {
        "name_process": "prune_tree_of_long_branches",
        "string_process": "\nprocess prune_tree_of_long_branches {\n       \n                                                         \n                 \n      \n\n    publishDir \"${publish_dev}/trees\", pattern: \"*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true\n    publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true\n\n    memory { 4.GB + 4.GB * task.attempt }\n\n    input:\n    path protobuf\n\n    output:\n    path \"${protobuf.baseName}.pruned.tree\", emit: tree\n    path \"${protobuf.baseName}.pruned.pb\", emit: protobuf\n\n    script:\n    \"\"\"\n    matUtils extract -i ${protobuf} \\\n            --max-parsimony ${params.max_parsimony} \\\n            --max-branch-length ${params.max_branch_length} \\\n            --write-tree \"${protobuf.baseName}.pruned.tree\" \\\n            --collapse-tree \\\n            --write-mat \"${protobuf.baseName}.pruned.pb\"\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    matUtils extract -i ${protobuf} \\\n            --max-parsimony ${params.max_parsimony} \\\n            --max-branch-length ${params.max_branch_length} \\\n            --write-tree \"${protobuf.baseName}.pruned.tree\" \\\n            --collapse-tree \\\n            --write-mat \"${protobuf.baseName}.pruned.pb\"\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "protobuf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [
            "publishDir \"${publish_dev}/trees\", pattern: \"*.pb\", mode: 'copy', saveAs: { \"cog_global.${params.date}.pb\" }, overwrite: true",
            "publishDir \"${publish_dev}/trees\", pattern: \"*.tree\", mode: 'copy', saveAs: { \"cog_global.${params.date}.tree\" }, overwrite: true",
            "memory { 4.GB + 4.GB * task.attempt }"
        ],
        "when": "",
        "stub": ""
    },
    "add_usher_metadata": {
        "name_process": "add_usher_metadata",
        "string_process": "\nprocess add_usher_metadata {\n       \n                                  \n                          \n      \n\n    input:\n    path usher_log\n    path metadata\n\n    output:\n    path \"${metadata.baseName}.usher.csv\"\n\n    script:\n    \"\"\"\n    $project_dir/../bin/parse_usher_log.py \\\n                --in ${usher_log} \\\n                --out \"usher_log.csv\"\n\n    fastafunk add_columns \\\n                  --in-metadata ${metadata} \\\n                  --in-data \"usher_log.csv\" \\\n                  --index-column sequence_name \\\n                  --join-on sequence_name \\\n                  --new-columns parsimony_score num_parsimony_optimal_placements is_unreliable_in_tree \\\n                  --out-metadata \"${metadata.baseName}.usher.csv\"\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    \"\"\"\n    $project_dir/../bin/parse_usher_log.py \\\n                --in ${usher_log} \\\n                --out \"usher_log.csv\"\n\n    fastafunk add_columns \\\n                  --in-metadata ${metadata} \\\n                  --in-data \"usher_log.csv\" \\\n                  --index-column sequence_name \\\n                  --join-on sequence_name \\\n                  --new-columns parsimony_score num_parsimony_optimal_placements is_unreliable_in_tree \\\n                  --out-metadata \"${metadata.baseName}.usher.csv\"\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "usher_log",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "rescale_branch_lengths": {
        "name_process": "rescale_branch_lengths",
        "string_process": "\nprocess rescale_branch_lengths {\n       \n                                                   \n                 \n      \n\n    input:\n    path tree\n\n    output:\n    path \"${tree.baseName}.scaled.tree\"\n\n    script:\n    \"\"\"\n    jclusterfunk scale \\\n        --format newick \\\n        -i ${tree} \\\n        -o ${tree.baseName}.scaled.tree \\\n        --factor 0.00003344146 \\\n        --threshold ${params.collapse}\n    \"\"\"\n}",
        "nb_lignes_process": 21,
        "string_script": "    \"\"\"\n    jclusterfunk scale \\\n        --format newick \\\n        -i ${tree} \\\n        -o ${tree.baseName}.scaled.tree \\\n        --factor 0.00003344146 \\\n        --threshold ${params.collapse}\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "tree"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "announce_protobuf_complete": {
        "name_process": "announce_protobuf_complete",
        "string_process": "\nprocess announce_protobuf_complete {\n       \n                                  \n                     \n      \n\n    input:\n    path protobuf\n\n    output:\n    path \"usher_pb.json\"\n\n    script:\n        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > usher_pb.json\n            echo \"*${params.whoami}: Usher protobuf for ${params.date} complete*\\\\n\" >> usher_pb.json\n            echo '\"}' >> usher_pb.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @usher_pb.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           echo '{\"text\":\"' > usher_pb.json\n           echo \"*${params.whoami}: Usher protobuf for ${params.date} complete*\\\\n\" >> usher_pb.json\n           echo '\"}' >> usher_pb.json\n           \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "        if (params.webhook)\n            \"\"\"\n            echo '{\"text\":\"' > usher_pb.json\n            echo \"*${params.whoami}: Usher protobuf for ${params.date} complete*\\\\n\" >> usher_pb.json\n            echo '\"}' >> usher_pb.json\n\n            echo 'webhook ${params.webhook}'\n\n            curl -X POST -H \"Content-type: application/json\" -d @usher_pb.json ${params.webhook}\n            \"\"\"\n        else\n           \"\"\"\n           echo '{\"text\":\"' > usher_pb.json\n           echo \"*${params.whoami}: Usher protobuf for ${params.date} complete*\\\\n\" >> usher_pb.json\n           echo '\"}' >> usher_pb.json\n           \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [
            "CURLS"
        ],
        "tools_url": [
            "https://bio.tools/CURLS"
        ],
        "tools_dico": [
            {
                "name": "CURLS",
                "uri": "https://bio.tools/CURLS",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "Public health and epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Pathology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3335",
                            "term": "Cardiovascular medicine"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Public_health"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3305",
                            "term": "https://en.wikipedia.org/wiki/Epidemiology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3421",
                            "term": "https://en.wikipedia.org/wiki/Surgery"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "Disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0634",
                            "term": "https://en.wikipedia.org/wiki/Pathology"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "towards a wider use of basic echo applications in Africa.\n\nBACKGROUND:Point-of-care ultrasound is increasingly being used as a diagnostic tool in resource-limited settings. The majority of existing ultrasound protocols have been developed and implemented in high-resource settings. In sub-Saharan Africa (SSA), patients with heart failure of various etiologies commonly present late in the disease process, with a similar syndrome of dyspnea, edema and cardiomegaly on chest X-ray. The causes of heart failure in SSA differ from those in high-resource settings. Point-of-care ultrasound has the potential to identify the underlying etiology of heart failure, and lead to targeted therapy.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'ultrasound', 'Cardiac ultrasound resource-limited settings', 'high-resource', 'cardiomegaly SSA'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31883027"
            }
        ],
        "inputs": [
            "protobuf"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "filter_on_sample_date": {
        "name_process": "filter_on_sample_date",
        "string_process": "\nprocess filter_on_sample_date {\n       \n                                                                   \n                                                            \n                     \n                              \n                               \n      \n\n    input:\n    path metadata\n\n    output:\n    path \"${metadata.baseName}.date_filtered.csv\"\n\n    script:\n    if ( params.time_window && params.date)\n        \"\"\"\n        $project_dir/../bin/date_filter.py \\\n                    --in-metadata ${metadata} \\\n                    --out-metadata \"${metadata.baseName}.date_filtered.csv\" \\\n                    --date ${params.date} \\\n                    --time-window ${params.time_window} \\\n                    --filter-column \"date_filter\"\n        \"\"\"\n    else\n        \"\"\"\n        echo \"date ${params.date}\"\n        echo \"time window ${params.time_window}\"\n        mv \"${metadata}\" \"${metadata.baseName}.date_filtered.csv\"\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    if ( params.time_window && params.date)\n        \"\"\"\n        $project_dir/../bin/date_filter.py \\\n                    --in-metadata ${metadata} \\\n                    --out-metadata \"${metadata.baseName}.date_filtered.csv\" \\\n                    --date ${params.date} \\\n                    --time-window ${params.time_window} \\\n                    --filter-column \"date_filter\"\n        \"\"\"\n    else\n        \"\"\"\n        echo \"date ${params.date}\"\n        echo \"time window ${params.time_window}\"\n        mv \"${metadata}\" \"${metadata.baseName}.date_filtered.csv\"\n        \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "metadata"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "filter_on_ambiguous_sites": {
        "name_process": "filter_on_ambiguous_sites",
        "string_process": "\nprocess filter_on_ambiguous_sites {\n       \n                                                                          \n                  \n                   \n                   \n      \n\n    input:\n    path fasta\n\n    output:\n    path \"${fasta.baseName}.site_filtered.fa\", emit: fasta\n    path \"ids_with_ambiguous_sites.log\", emit: ambiguous_site_ids\n\n\n    script:\n    if ( params.downsample )\n        \"\"\"\n        $project_dir/../bin/filter_by_ambiguous_sites.py \\\n                --in-alignment ${fasta} \\\n                --out-alignment \"${fasta.baseName}.site_filtered.fa\" \\\n                --outgroups ${lineage_splits} \\\n                --sites ${ambiguous_sites} > \"ids_with_ambiguous_sites.log\"\n        \"\"\"\n    else\n        \"\"\"\n        mv \"${fasta}\" \"${fasta.baseName}.site_filtered.fa\"\n        \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    if ( params.downsample )\n        \"\"\"\n        $project_dir/../bin/filter_by_ambiguous_sites.py \\\n                --in-alignment ${fasta} \\\n                --out-alignment \"${fasta.baseName}.site_filtered.fa\" \\\n                --outgroups ${lineage_splits} \\\n                --sites ${ambiguous_sites} > \"ids_with_ambiguous_sites.log\"\n        \"\"\"\n    else\n        \"\"\"\n        mv \"${fasta}\" \"${fasta.baseName}.site_filtered.fa\"\n        \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "downsample": {
        "name_process": "downsample",
        "string_process": "\nprocess downsample {\n       \n                                                                                           \n                     \n      \n\n    input:\n    path fasta\n    path metadata\n\n    output:\n    path \"${fasta.baseName}.downsampled.fa\", emit: fasta\n    path \"${metadata.baseName}.downsampled.csv\", emit: metadata\n\n    script:\n    if ( params.downsample )\n        \"\"\"\n        $project_dir/../bin/downsample.py \\\n            --in-metadata ${metadata} \\\n            --in-fasta ${fasta} \\\n            --out-metadata \"${metadata.baseName}.downsampled.csv\" \\\n            --out-fasta \"${fasta.baseName}.downsampled.fa\" \\\n            --outgroups ${lineage_splits} \\\n            --diff ${params.downsample_diff} \\\n            --downsample_date_excluded\n        \"\"\"\n    else\n        \"\"\"\n        mv \"${fasta}\" \"${fasta.baseName}.downsampled.fa\"\n        mv \"${metadata}\" \"${metadata.baseName}.downsampled.csv\"\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "    if ( params.downsample )\n        \"\"\"\n        $project_dir/../bin/downsample.py \\\n            --in-metadata ${metadata} \\\n            --in-fasta ${fasta} \\\n            --out-metadata \"${metadata.baseName}.downsampled.csv\" \\\n            --out-fasta \"${fasta.baseName}.downsampled.fa\" \\\n            --outgroups ${lineage_splits} \\\n            --diff ${params.downsample_diff} \\\n            --downsample_date_excluded\n        \"\"\"\n    else\n        \"\"\"\n        mv \"${fasta}\" \"${fasta.baseName}.downsampled.fa\"\n        mv \"${metadata}\" \"${metadata.baseName}.downsampled.csv\"\n        \"\"\"",
        "nb_lignes_script": 15,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "fasta",
            "metadata"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "virus-evolution__phylopipe",
        "directive": [],
        "when": "",
        "stub": ""
    }
}