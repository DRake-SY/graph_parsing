{
    "DRAW_GIS": {
        "name_process": "DRAW_GIS",
        "string_process": "process DRAW_GIS {\n  publishDir \"${params.output}/${prefix}/genomic_islands\", mode: 'copy', saveAs: { filename ->\n    if (filename == \"plots\") \"$filename\"\n    else null\n  }\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_ultralow' ]\n  \n\n  input:\n  tuple val(prefix), file(gff), file(gis_bed)\n\n  output:\n                                                \n  tuple val(prefix), file(\"plots\")     optional true\n  tuple val(prefix), file(\"teste.png\") optional true\n\n  script:\n  \"\"\"\n  # create output directories\n  mkdir \\\\\n    -p plots \\\\\n    plots/id_label \\\\\n    plots/product_label ;\n\n  # draw genomic islands\n  draw_gis.sh \\\\\n    -i $gis_bed \\\\\n    -g $gff \\\\\n    -f \\$(which input.fofn) ;\n\n  # get one image\n  name=\\$(ls plots/product_label | head -n 1)\n  [[ \\$(ls plots/product_label/) ]] && \\\\\n    cp \"plots/product_label/\\${name}\" ./teste.png || \\\\\n    echo \"empty\" ;\n  \"\"\"\n}",
        "nb_lignes_process": 36,
        "string_script": "  \"\"\"\n  # create output directories\n  mkdir \\\\\n    -p plots \\\\\n    plots/id_label \\\\\n    plots/product_label ;\n\n  # draw genomic islands\n  draw_gis.sh \\\\\n    -i $gis_bed \\\\\n    -g $gff \\\\\n    -f \\$(which input.fofn) ;\n\n  # get one image\n  name=\\$(ls plots/product_label | head -n 1)\n  [[ \\$(ls plots/product_label/) ]] && \\\\\n    cp \"plots/product_label/\\${name}\" ./teste.png || \\\\\n    echo \"empty\" ;\n  \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "gff",
            "gis_bed"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/genomic_islands\", mode: 'copy', saveAs: { filename -> if (filename == \"plots\") \"$filename\" else null }",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_ultralow' ]"
        ],
        "when": "",
        "stub": ""
    },
    "REFSEQ_MASHER": {
        "name_process": "REFSEQ_MASHER",
        "string_process": "process REFSEQ_MASHER {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else \"refseq_masher/$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'python', 'process_low' ]\n\n  input:\n  tuple val(prefix), path(genome)\n\n  output:\n                 \n  tuple val(prefix), path(\"refseq_masher_results.txt\")\n  path(\"*_version.txt\")\n\n  script:\n  \"\"\"\n  # Get tool version\n  refseq_masher --version > refseq_masher_version.txt ;\n\n  # Run tool\n  refseq_masher \\\\\n    -vv matches \\\\\n    --top-n-results 10 \\\\\n    --output-type tab \\\\\n    $genome > refseq_masher_results.txt\n  \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "  \"\"\"\n  # Get tool version\n  refseq_masher --version > refseq_masher_version.txt ;\n\n  # Run tool\n  refseq_masher \\\\\n    -vv matches \\\\\n    --top-n-results 10 \\\\\n    --output-type tab \\\\\n    $genome > refseq_masher_results.txt\n  \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "genome"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prefix"
        ],
        "nb_outputs": 1,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"refseq_masher/$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'python', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "CALL_METHYLATION": {
        "name_process": "CALL_METHYLATION",
        "string_process": "process CALL_METHYLATION {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else \"methylations/$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_high' ]\n\n  input:\n  tuple val(prefix), file(draft), file(reads), file(fast5)\n\n  output:\n                     \n  file \"*_calls.tsv\" optional true\n  file \"*_frequency.tsv\" optional true\n  tuple val(prefix), file(\"methylation_frequency.bedGraph\") optional true\n  tuple val(prefix), file(\"chr.sizes\") optional true\n  file('nanopolish_version.txt')\n\n  when:\n                                                           \n  if (fast5.getName() != 'input.5' && reads.getName() != 'input.4')                                                 \n\n  script:\n  fast5_dir = fast5.getName()\n  \"\"\"\n  # Get tool version\n  nanopolish --version > nanopolish_version.txt ;\n\n  # Index Our Fast5 Data\n  nanopolish \\\\\n    index \\\\\n    -d ${fast5_dir} \\\\\n    ${reads} ;\n\n  # Map Our Indexed Reads to Our Genome\n  minimap2 \\\\\n    -a \\\\\n    -x map-ont \\\\\n    ${draft} \\\\\n    ${reads} | \\\\\n    samtools \\\\\n      sort \\\\\n      -T tmp \\\\\n      -o reads_output.sorted.bam ;\n  \n  # Index BAM\n  samtools index reads_output.sorted.bam ;\n\n  # Call Methylation\n  nanopolish \\\\\n    call-methylation \\\\\n    -r ${reads} \\\\\n    -b reads_output.sorted.bam \\\\\n    -g ${draft} \\\\\n    -t $task.cpus > methylation_call.tsv ;\n\n  # Calculate Methylation Frequencies\n  /work/nanopolish/scripts/calculate_methylation_frequency.py methylation_call.tsv > methylation_frequency.tsv ;\n\n  # Transform These TSV files into bedGraph\n  [ ! -s methylation_frequency.tsv ] || \\\\\n    grep \\\\\n      -v \"start\" \\\\\n      methylation_frequency.tsv | \\\\\n    awk \\\\\n      '{ print \\$1 \"\\t\" \\$2 \"\\t\" \\$3 \"\\t\" \\$7 }' > methylation_frequency.bedGraph ;\n\n  # Create Contig Sizes File\n  seqtk \\\\\n    comp \\\\\n    ${draft} | \\\\\n    awk '{ print \\$1 \"\\t\" \\$2 }' > chr.sizes\n  \"\"\"\n}",
        "nb_lignes_process": 73,
        "string_script": "  fast5_dir = fast5.getName()\n  \"\"\"\n  # Get tool version\n  nanopolish --version > nanopolish_version.txt ;\n\n  # Index Our Fast5 Data\n  nanopolish \\\\\n    index \\\\\n    -d ${fast5_dir} \\\\\n    ${reads} ;\n\n  # Map Our Indexed Reads to Our Genome\n  minimap2 \\\\\n    -a \\\\\n    -x map-ont \\\\\n    ${draft} \\\\\n    ${reads} | \\\\\n    samtools \\\\\n      sort \\\\\n      -T tmp \\\\\n      -o reads_output.sorted.bam ;\n  \n  # Index BAM\n  samtools index reads_output.sorted.bam ;\n\n  # Call Methylation\n  nanopolish \\\\\n    call-methylation \\\\\n    -r ${reads} \\\\\n    -b reads_output.sorted.bam \\\\\n    -g ${draft} \\\\\n    -t $task.cpus > methylation_call.tsv ;\n\n  # Calculate Methylation Frequencies\n  /work/nanopolish/scripts/calculate_methylation_frequency.py methylation_call.tsv > methylation_frequency.tsv ;\n\n  # Transform These TSV files into bedGraph\n  [ ! -s methylation_frequency.tsv ] || \\\\\n    grep \\\\\n      -v \"start\" \\\\\n      methylation_frequency.tsv | \\\\\n    awk \\\\\n      '{ print \\$1 \"\\t\" \\$2 \"\\t\" \\$3 \"\\t\" \\$7 }' > methylation_frequency.bedGraph ;\n\n  # Create Contig Sizes File\n  seqtk \\\\\n    comp \\\\\n    ${draft} | \\\\\n    awk '{ print \\$1 \"\\t\" \\$2 }' > chr.sizes\n  \"\"\"",
        "nb_lignes_script": 49,
        "language_script": "bash",
        "tools": [
            "nanopolish",
            "CINdex",
            "Minimap2",
            "SAMtools",
            "seqtk",
            "CCOMP"
        ],
        "tools_url": [
            "https://bio.tools/nanopolish",
            "https://bio.tools/cindex",
            "https://bio.tools/minimap2",
            "https://bio.tools/samtools",
            "https://bio.tools/seqtk",
            "https://bio.tools/ccomp"
        ],
        "tools_dico": [
            {
                "name": "nanopolish",
                "uri": "https://bio.tools/nanopolish",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3204",
                                    "term": "Methylation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Sequence variation analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Variant analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3197",
                                    "term": "Genetic variation annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3204",
                                    "term": "Methylation profile analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2093",
                                "term": "Data reference"
                            },
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0867",
                                "term": "Sequence alignment report"
                            }
                        ]
                    }
                ],
                "description": "A package for detecting cytosine methylations and genetic variations from nanopore MinION sequencing data.",
                "homepage": "https://github.com/jts/nanopolish"
            },
            {
                "name": "CINdex",
                "uri": "https://bio.tools/cindex",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3233",
                                    "term": "Copy number estimation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3196",
                                    "term": "Genotyping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3233",
                                    "term": "Transcript copy number estimation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "The package addresses important area of high-throughput genomic analysis. It allows the automated processing and analysis of the experimental DNA copy number data generated by Affymetrix SNP 6.0 arrays or similar. It calculates the chromosome instability index to quantitatively characterize genome-wide DNA copy number alterations. This package calculates not only overall genomic instability, but also instability in terms of copy number gains and losses at the chromosome and cytoband level.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/CINdex.html"
            },
            {
                "name": "Minimap2",
                "uri": "https://bio.tools/minimap2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Pairwise aligner for genomic and spliced nucleotide sequences",
                "homepage": "https://github.com/lh3/minimap2"
            },
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "seqtk",
                "uri": "https://bio.tools/seqtk",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2121",
                                    "term": "Sequence file editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A tool for processing sequences in the FASTA or FASTQ format. It parses both FASTA and FASTQ files which can also be optionally compressed by gzip.",
                "homepage": "https://github.com/lh3/seqtk"
            },
            {
                "name": "CCOMP",
                "uri": "https://bio.tools/ccomp",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0128",
                            "term": "Protein interactions"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2275",
                            "term": "Molecular modelling"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise sequence alignment"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0491",
                                    "term": "Pairwise alignment"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Complex COMParison,\u00a0is a simple command-line tool for comparing ligand/receptor complexes. It can also be used for calculating pairwise all-atom RMSD of slightly different protein structures, taking care of missing atoms, sequence inconsistencies, etc.",
                "homepage": "http://www.pirx.com/ccomp/index.shtml"
            }
        ],
        "inputs": [
            "prefix",
            "draft",
            "reads",
            "fast5"
        ],
        "nb_inputs": 4,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"methylations/$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_high' ]"
        ],
        "when": "if (fast5.getName() != 'input.5' && reads.getName() != 'input.4')",
        "stub": ""
    },
    "PLATON": {
        "name_process": "PLATON",
        "string_process": "process PLATON {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else if (filename == \"platon\") \"plasmids/$filename\"\n    else null\n  }\n  tag \"${prefix}\"\n  label = [ 'python', 'process_medium' ]\n\n  input:\n  tuple val(prefix), file(genome)\n  file(bacannot_db)\n\n  output:\n  path(\"platon\")\n  tuple val(prefix), path(\"platon/${prefix}.tsv\")\n  path(\"platon_version.txt\")\n\n  script:\n  \"\"\"\n  # Get version\n  platon --version > platon_version.txt ;\n\n  # Run platon\n  platon \\\\\n      --db ${bacannot_db}/platon_db/ \\\\\n      --output platon \\\\\n      --threads $task.cpus \\\\\n      $genome > tmp.txt || true ;\n  [ -s platon/${prefix}.tsv ] || cat tmp.txt > platon/${prefix}.tsv ;\n  \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "  \"\"\"\n  # Get version\n  platon --version > platon_version.txt ;\n\n  # Run platon\n  platon \\\\\n      --db ${bacannot_db}/platon_db/ \\\\\n      --output platon \\\\\n      --threads $task.cpus \\\\\n      $genome > tmp.txt || true ;\n  [ -s platon/${prefix}.tsv ] || cat tmp.txt > platon/${prefix}.tsv ;\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "Platon"
        ],
        "tools_url": [
            "https://bio.tools/Platon"
        ],
        "tools_dico": [
            {
                "name": "Platon",
                "uri": "https://bio.tools/Platon",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0798",
                            "term": "Mobile genetic elements"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2995",
                                    "term": "Sequence classification"
                                }
                            ],
                            []
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": []
                    }
                ],
                "description": "Identification and characterization of bacterial plasmid contigs from short-read draft assemblies.",
                "homepage": "https://github.com/oschwengers/platon"
            }
        ],
        "inputs": [
            "prefix",
            "genome",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix"
        ],
        "nb_outputs": 1,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else if (filename == \"platon\") \"plasmids/$filename\" else null }",
            "tag \"${prefix}\"",
            "label = [ 'python', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "BARRNAP": {
        "name_process": "BARRNAP",
        "string_process": "process BARRNAP {\n   publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n     if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n     else \"rRNA/$filename\"\n   }\n   tag \"${prefix}\"\n   label = [ 'perl', 'process_low' ]\n\n   input:\n   tuple val(prefix), file(genome)\n\n   output:\n   tuple val(prefix), path(\"${prefix}_rRNA.gff\")\n   tuple val(prefix), path(\"${prefix}_rRNA.fa\")\n   path('barrnap_version.txt')\n\n   script:\n   \"\"\"\n   # save barrnap tool version\n   barrnap --version &> barrnap_version.txt ;\n\n   # run barrnap\n   barrnap -o ${prefix}_rRNA.fa < $genome > ${prefix}_rRNA.gff\n   \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "   \"\"\"\n   # save barrnap tool version\n   barrnap --version &> barrnap_version.txt ;\n\n   # run barrnap\n   barrnap -o ${prefix}_rRNA.fa < $genome > ${prefix}_rRNA.gff\n   \"\"\"",
        "nb_lignes_script": 6,
        "language_script": "bash",
        "tools": [
            "Barrnap"
        ],
        "tools_url": [
            "https://bio.tools/barrnap"
        ],
        "tools_dico": [
            {
                "name": "Barrnap",
                "uri": "https://bio.tools/barrnap",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1255",
                                "term": "Sequence features"
                            }
                        ]
                    }
                ],
                "description": "Predict the location of ribosomal RNA genes in genomes. It supports bacteria (5S,23S,16S), archaea (5S,5.8S,23S,16S), mitochondria (12S,16S) and eukaryotes (5S,5.8S,28S,18S).",
                "homepage": "https://github.com/tseemann/barrnap"
            }
        ],
        "inputs": [
            "prefix",
            "genome"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"rRNA/$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'perl', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "COMPUTE_GC": {
        "name_process": "COMPUTE_GC",
        "string_process": "process COMPUTE_GC {\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_ultralow' ]\n\n  input:\n  tuple val(prefix), file(genome)\n\n  output:\n                                                \n  tuple val(prefix), path(\"input_GC_500_bps.sorted.bedGraph\"), path(\"input.sizes\")\n\n  script:\n  \"\"\"\n  # Index de genome\n  samtools faidx $genome ;\n\n  # Get contig sizes\n  cut -f 1,2 ${genome}.fai > input.sizes ;\n\n  # Create genome sliding window\n  bedtools makewindows -g input.sizes -w 500 > input_500_bps.bed ;\n\n  # Compute GC content\n  bedtools nuc -fi ${genome} -bed input_500_bps.bed > input_500_bps_nuc.txt ;\n\n  # Create bedGraph for JBrowse\n  awk 'BEGIN{FS=\"\\\\t\"; OFS=\"\\\\t\"} FNR > 1 { print \\$1,\\$2,\\$3,\\$5 }' input_500_bps_nuc.txt > input_GC_500_bps.bedGraph\n\n  # Sort results\n  bedtools sort -i input_GC_500_bps.bedGraph > input_GC_500_bps.sorted.bedGraph\n  \"\"\"\n}",
        "nb_lignes_process": 30,
        "string_script": "  \"\"\"\n  # Index de genome\n  samtools faidx $genome ;\n\n  # Get contig sizes\n  cut -f 1,2 ${genome}.fai > input.sizes ;\n\n  # Create genome sliding window\n  bedtools makewindows -g input.sizes -w 500 > input_500_bps.bed ;\n\n  # Compute GC content\n  bedtools nuc -fi ${genome} -bed input_500_bps.bed > input_500_bps_nuc.txt ;\n\n  # Create bedGraph for JBrowse\n  awk 'BEGIN{FS=\"\\\\t\"; OFS=\"\\\\t\"} FNR > 1 { print \\$1,\\$2,\\$3,\\$5 }' input_500_bps_nuc.txt > input_GC_500_bps.bedGraph\n\n  # Sort results\n  bedtools sort -i input_GC_500_bps.bedGraph > input_GC_500_bps.sorted.bedGraph\n  \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "SAMtools",
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/samtools",
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "SAMtools",
                "uri": "https://bio.tools/samtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "Rare diseases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0102",
                            "term": "Mapping"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3325",
                            "term": "https://en.wikipedia.org/wiki/Rare_disease"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Parsing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Indexing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Data visualisation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0337",
                                    "term": "Rendering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Data loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_1812",
                                    "term": "Loading"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Data indexing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0227",
                                    "term": "Database indexing"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0924",
                                "term": "Sequence trace"
                            }
                        ]
                    }
                ],
                "description": "A software package with various utilities for processing alignments in the SAM format, including variant calling and alignment viewing.",
                "homepage": "http://www.htslib.org/"
            },
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "prefix",
            "genome"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prefix"
        ],
        "nb_outputs": 1,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_ultralow' ]"
        ],
        "when": "",
        "stub": ""
    },
    "KOFAMSCAN": {
        "name_process": "KOFAMSCAN",
        "string_process": "process KOFAMSCAN {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else \"$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_high' ]\n\n  input:\n  tuple val(prefix), file('proteins.faa')\n  file(bacannot_db)\n\n  output:\n                     \n  file(\"KOfamscan\")\n  tuple val(prefix), file(\"KOfamscan/${prefix}_ko_forKEGGMapper.txt\")\n\n  script:\n  \"\"\"\n  # Get kofamscan version\n  exec_annotation -v | sed \"s/exec_annotation/kofamscan/\" > kofamscan_version.txt\n\n  # Create dir for results\n  mkdir KOfamscan ;\n\n  # Run kofamscan with detailed output\n  exec_annotation \\\\\n      -p ${bacannot_db}/kofamscan_db/profiles/prokaryote.hal \\\\\n      -k ${bacannot_db}/kofamscan_db/ko_list \\\\\n      -o KOfamscan/${prefix}_ko_detailed.txt \\\\\n      --keep-tabular \\\\\n      --cpu=$task.cpus \\\\\n      proteins.faa ;\n\n  # Re-run kofamscan with mapper-output\n  exec_annotation \\\\\n      -p ${bacannot_db}/kofamscan_db/profiles/prokaryote.hal \\\\\n      -k ${bacannot_db}/kofamscan_db/ko_list \\\\\n      -o KOfamscan/${prefix}_ko_forKEGGMapper.txt \\\\\n      --reannotate \\\\\n      --cpu=$task.cpus \\\\\n      -f mapper \\\\\n      proteins.faa ;\n  \"\"\"\n}",
        "nb_lignes_process": 43,
        "string_script": "  \"\"\"\n  # Get kofamscan version\n  exec_annotation -v | sed \"s/exec_annotation/kofamscan/\" > kofamscan_version.txt\n\n  # Create dir for results\n  mkdir KOfamscan ;\n\n  # Run kofamscan with detailed output\n  exec_annotation \\\\\n      -p ${bacannot_db}/kofamscan_db/profiles/prokaryote.hal \\\\\n      -k ${bacannot_db}/kofamscan_db/ko_list \\\\\n      -o KOfamscan/${prefix}_ko_detailed.txt \\\\\n      --keep-tabular \\\\\n      --cpu=$task.cpus \\\\\n      proteins.faa ;\n\n  # Re-run kofamscan with mapper-output\n  exec_annotation \\\\\n      -p ${bacannot_db}/kofamscan_db/profiles/prokaryote.hal \\\\\n      -k ${bacannot_db}/kofamscan_db/ko_list \\\\\n      -o KOfamscan/${prefix}_ko_forKEGGMapper.txt \\\\\n      --reannotate \\\\\n      --cpu=$task.cpus \\\\\n      -f mapper \\\\\n      proteins.faa ;\n  \"\"\"",
        "nb_lignes_script": 25,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "bacannot_db"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prefix"
        ],
        "nb_outputs": 1,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_high' ]"
        ],
        "when": "",
        "stub": ""
    },
    "GFF2GBK": {
        "name_process": "GFF2GBK",
        "string_process": "process GFF2GBK {\n  publishDir \"${params.output}/${prefix}/gbk\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_ultralow' ]\n\n  input:\n  tuple val(prefix), file(gff), file(input)\n\n  output:\n  file \"*.genbank\"\n\n  \"\"\"\n  # Activate env\n  export PATH=/opt/conda/envs/antismash/bin:\\$PATH\n\n  # Run emboss seqret\n  seqret \\\\\n    -sequence $input \\\\\n    -feature \\\\\n    -fformat gff \\\\\n    -fopenfile $gff \\\\\n    -osformat genbank \\\\\n    -osname_outseq ${prefix} \\\\\n    -ofdirectory_outseq gbk_file \\\\\n    -auto\n  \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "\"\"\"\n  # Activate env\n  export PATH=/opt/conda/envs/antismash/bin:\\$PATH\n\n  # Run emboss seqret\n  seqret \\\\\n    -sequence $input \\\\\n    -feature \\\\\n    -fformat gff \\\\\n    -fopenfile $gff \\\\\n    -osformat genbank \\\\\n    -osname_outseq ${prefix} \\\\\n    -ofdirectory_outseq gbk_file \\\\\n    -auto\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "seqret"
        ],
        "tools_url": [
            "https://bio.tools/seqret"
        ],
        "tools_dico": [
            {
                "name": "seqret",
                "uri": "https://bio.tools/seqret",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ]
                    }
                ],
                "description": "Read and write (return) sequences.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/seqret.html"
            }
        ],
        "inputs": [
            "prefix",
            "gff",
            "input"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/gbk\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_ultralow' ]"
        ],
        "when": "",
        "stub": ""
    },
    "VICTORS": {
        "name_process": "VICTORS",
        "string_process": "process VICTORS {\n  publishDir \"${params.output}/${prefix}/virulence/victors\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_low' ]\n\n  input:\n  tuple val(prefix), file(genes)\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), path(\"${prefix}_victors_blastp_onGenes.summary.txt\")\n  tuple val(prefix), path(\"${prefix}_victors_blastp_onGenes.txt\")\n  path('*.txt')\n\n  script:\n  \"\"\"\n  # Victors has protein database\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/victors_db/diamond.dmnd \\\\\n      --minid ${params.blast_virulence_minid} \\\\\n      --mincov ${params.blast_virulence_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_victors_blastp_onGenes.txt \\\\\n      --2way | \\\\\n  sed -e 's/PRODUCT/VICTORS_ID/g' > ${prefix}_victors_blastp_onGenes.summary.txt ;\n  \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "  \"\"\"\n  # Victors has protein database\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/victors_db/diamond.dmnd \\\\\n      --minid ${params.blast_virulence_minid} \\\\\n      --mincov ${params.blast_virulence_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_victors_blastp_onGenes.txt \\\\\n      --2way | \\\\\n  sed -e 's/PRODUCT/VICTORS_ID/g' > ${prefix}_victors_blastp_onGenes.summary.txt ;\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "BLASTP-ACC"
        ],
        "tools_url": [
            "https://bio.tools/BLASTP-ACC"
        ],
        "tools_dico": [
            {
                "name": "BLASTP-ACC",
                "uri": "https://bio.tools/BLASTP-ACC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3297",
                            "term": "Biotechnology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3802",
                                    "term": "Sorting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Sequence alignment (local)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parallel Architecture and Hardware Accelerator Design for BLAST-based Protein Sequence Alignment.\n\nIn this study, we design a hardware accelerator for a widely used sequence alignment algorithm, the basic local alignment search tool for proteins (BLASTP). The architecture of the proposed accelerator consists of five stages: a new systolic-array-based one-hit finding stage, a novel RAM-REG-based two-hit finding stage, a refined ungapped extension stage, a faster gapped extension stage, and a highly efficient parallel sorter. The system is implemented on an Altera Stratix V FPGA with a processing speed of more than 500 giga cell updates per second (GCUPS). It can receive a query sequence, compare it with the sequences in the database, and generate a list sorted in descending order of the similarity scores between the query sequence and the subject sequences.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'accelerator', 'Altera', 'Stratix', 'RAM-REG-based'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31581096"
            }
        ],
        "inputs": [
            "prefix",
            "genes",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/virulence/victors\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "AMRFINDER": {
        "name_process": "AMRFINDER",
        "string_process": "process AMRFINDER {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else \"resistance/AMRFinderPlus/$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_medium' ]\n\n  input:\n  tuple val(prefix), file(proteins)\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), file(\"AMRFinder_resistance-only.tsv\")\n  tuple val(prefix), file(\"AMRFinder_complete.tsv\")\n  file(\"${prefix}_args.faa\")\n  file(\"amrfinder_version.txt\")\n\n  script:\n  resistance_minid  = params.blast_resistance_minid / 100.00\n  resistance_mincov = params.blast_resistance_mincov / 100.00\n  \"\"\"\n  # Get tool version\n  amrfinder --version > amrfinder_version.txt ;\n\n  # run amrfinder\n  amrfinder \\\\\n      -p $proteins \\\\\n      --plus \\\\\n      -o AMRFinder_complete.tsv \\\\\n      --threads $task.cpus \\\\\n      --ident_min ${resistance_minid} \\\\\n      --coverage_min ${resistance_mincov} \\\\\n      --name ${prefix} \\\\\n      --protein_output ${prefix}_args.faa \\\\\n      --database ${bacannot_db}/amrfinder_db/latest\n  \n  # filter results\n  awk \\\\\n      -F '\\t' \\\\\n      '{ if (\\$3 != \"\") { print } }' \\\\\n      AMRFinder_complete.tsv | \\\\\n      grep -v \"VIRULENCE\" > AMRFinder_resistance-only.tsv ;\n  \"\"\"\n}",
        "nb_lignes_process": 44,
        "string_script": "  resistance_minid  = params.blast_resistance_minid / 100.00\n  resistance_mincov = params.blast_resistance_mincov / 100.00\n  \"\"\"\n  # Get tool version\n  amrfinder --version > amrfinder_version.txt ;\n\n  # run amrfinder\n  amrfinder \\\\\n      -p $proteins \\\\\n      --plus \\\\\n      -o AMRFinder_complete.tsv \\\\\n      --threads $task.cpus \\\\\n      --ident_min ${resistance_minid} \\\\\n      --coverage_min ${resistance_mincov} \\\\\n      --name ${prefix} \\\\\n      --protein_output ${prefix}_args.faa \\\\\n      --database ${bacannot_db}/amrfinder_db/latest\n  \n  # filter results\n  awk \\\\\n      -F '\\t' \\\\\n      '{ if (\\$3 != \"\") { print } }' \\\\\n      AMRFinder_complete.tsv | \\\\\n      grep -v \"VIRULENCE\" > AMRFinder_resistance-only.tsv ;\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "proteins",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"resistance/AMRFinderPlus/$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "SEQUENCESERVER": {
        "name_process": "SEQUENCESERVER",
        "string_process": "process SEQUENCESERVER {\n    publishDir \"${params.output}/${prefix}/SequenceServerDBs\", mode: 'copy'\n    tag \"${prefix}\"\n    label = [ 'server', 'process_ultralow' ]\n    \n\n    input:\n    tuple val(prefix), file(genome), file(genes), file(proteins)\n\n    output:\n    file(\"*\")\n    file(\"${genome}\")\n    file(\"${genes}\")\n    file(\"${proteins}\")\n\n    script:\n    \"\"\"\n    # genome\n    makeblastdb -in $genome -dbtype nucl -title \"${prefix} genome\" -parse_seqids\n\n    # genes\n    makeblastdb -in $genes -dbtype nucl -title \"${prefix} genes\" -parse_seqids\n\n    # proteins\n    makeblastdb -in $proteins -dbtype prot -title \"${prefix} proteins\" -parse_seqids\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    # genome\n    makeblastdb -in $genome -dbtype nucl -title \"${prefix} genome\" -parse_seqids\n\n    # genes\n    makeblastdb -in $genes -dbtype nucl -title \"${prefix} genes\" -parse_seqids\n\n    # proteins\n    makeblastdb -in $proteins -dbtype prot -title \"${prefix} proteins\" -parse_seqids\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "genome",
            "genes",
            "proteins"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/SequenceServerDBs\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'server', 'process_ultralow' ]"
        ],
        "when": "",
        "stub": ""
    },
    "MLST": {
        "name_process": "MLST",
        "string_process": "process MLST {\n   publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n     if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n     else \"MLST/$filename\"\n   }\n   tag \"${prefix}\"\n   label = [ 'perl', 'process_ultralow' ]\n\n   input:\n   tuple val(prefix), file(genome)\n   file(bacannot_db)\n\n   output:\n   tuple val(prefix), path(\"${prefix}_mlst_analysis.txt\")   optional true\n   tuple val(prefix), path(\"${prefix}_novel_alleles.fasta\") optional true\n   path('mlst_version.txt')\n\n   script:\n   \"\"\"\n   # update tool database\n   mlst_dir=\\$(which mlst | sed 's/bin\\\\/mlst//g')\n   cp ${bacannot_db}/mlst_db/* -r \\${mlst_dir}/db/pubmlst/\n   ( cd \\$mlst_dir/scripts && ./mlst-make_blast_db )\n\n   # Save mlst tool version\n   mlst --version > mlst_version.txt ;\n\n   # run mlst\n   mlst \\\\\n       --quiet \\\\\n       --novel ${prefix}_novel_alleles.fasta \\\\\n       $genome > ${prefix}_mlst_analysis.txt\n   \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "   \"\"\"\n   # update tool database\n   mlst_dir=\\$(which mlst | sed 's/bin\\\\/mlst//g')\n   cp ${bacannot_db}/mlst_db/* -r \\${mlst_dir}/db/pubmlst/\n   ( cd \\$mlst_dir/scripts && ./mlst-make_blast_db )\n\n   # Save mlst tool version\n   mlst --version > mlst_version.txt ;\n\n   # run mlst\n   mlst \\\\\n       --quiet \\\\\n       --novel ${prefix}_novel_alleles.fasta \\\\\n       $genome > ${prefix}_mlst_analysis.txt\n   \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "MLST"
        ],
        "tools_url": [
            "https://bio.tools/mlst"
        ],
        "tools_dico": [
            {
                "name": "MLST",
                "uri": "https://bio.tools/mlst",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2830",
                            "term": "Immunoproteins and antigens"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "Multi Locus Sequence Typing from an assembled genome or from a set of reads.",
                "homepage": "http://cge.cbs.dtu.dk/services/MLST/"
            }
        ],
        "inputs": [
            "prefix",
            "genome",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"MLST/$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'perl', 'process_ultralow' ]"
        ],
        "when": "",
        "stub": ""
    },
    "PLASMIDFINDER": {
        "name_process": "PLASMIDFINDER",
        "string_process": "process PLASMIDFINDER {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename == \"plasmidfinder\") \"plasmids/$filename\"\n    else null\n  }\n  tag \"${prefix}\"\n  label = [ 'python', 'process_low' ]\n\n  input:\n  tuple val(prefix), file(genome)\n  file(bacannot_db)\n\n  output:\n  tuple val(prefix), path(\"plasmidfinder\")\n  tuple val(prefix), path(\"plasmidfinder/results_tab.tsv\")\n\n  script:\n  \"\"\"\n  # Check thresholds\n  [ \"${params.plasmids_mincov}\" > 1 ] && mincov=\\$(( ${params.plasmids_mincov} / 100 )) || mincov=${params.plasmids_mincov}\n  [ \"${params.plasmids_minid}\" > 1 ] && minid=\\$(( ${params.plasmids_minid} / 100 )) || minid=${params.plasmids_minid}\n\n  # Run plasmidfinder\n  mkdir plasmidfinder ;\n  plasmidfinder.py \\\\\n      -i $genome \\\\\n      -o plasmidfinder \\\\\n      -l \\$mincov \\\\\n      -t \\$minid \\\\\n      -x \\\\\n      --databasePath ${bacannot_db}/plasmidfinder_db\n\n  # Remove tmp\n  rm -rf plasmidfinder/tmp\n  \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "  \"\"\"\n  # Check thresholds\n  [ \"${params.plasmids_mincov}\" > 1 ] && mincov=\\$(( ${params.plasmids_mincov} / 100 )) || mincov=${params.plasmids_mincov}\n  [ \"${params.plasmids_minid}\" > 1 ] && minid=\\$(( ${params.plasmids_minid} / 100 )) || minid=${params.plasmids_minid}\n\n  # Run plasmidfinder\n  mkdir plasmidfinder ;\n  plasmidfinder.py \\\\\n      -i $genome \\\\\n      -o plasmidfinder \\\\\n      -l \\$mincov \\\\\n      -t \\$minid \\\\\n      -x \\\\\n      --databasePath ${bacannot_db}/plasmidfinder_db\n\n  # Remove tmp\n  rm -rf plasmidfinder/tmp\n  \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "genome",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename == \"plasmidfinder\") \"plasmids/$filename\" else null }",
            "tag \"${prefix}\"",
            "label = [ 'python', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "RESFINDER": {
        "name_process": "RESFINDER",
        "string_process": "process RESFINDER {\n  publishDir \"${params.output}/${prefix}/resistance\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_medium' ]\n\n  input:\n  tuple val(prefix), file(genome), val(resfinder_species)\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), file(\"resfinder/ResFinder_results_tab.txt\")\n  tuple val(prefix), file(\"resfinder/PointFinder_results.txt\")\n  tuple val(prefix), file(\"resfinder/args_pheno_table.txt\")\n  tuple val(prefix), file(\"resfinder/results_tab.gff\")\n  file(\"resfinder/*\")                   \n\n  when:\n  (resfinder_species && resfinder_species != \"missing_resfinder\")\n\n  script:\n  resistance_minid  = params.blast_resistance_minid / 100.00\n  resistance_mincov = params.blast_resistance_mincov / 100.00\n  if (resfinder_species.toLowerCase() != \"other\")\n  \"\"\"\n  # Make databases available\n  ln -rs ${bacannot_db}/resfinder_db/db_* \\$(dirname \\$(which run_resfinder.py))\n\n  # Run resfinder acquired resistance\n  run_resfinder.py \\\\\n      --inputfasta $genome \\\\\n      -o resfinder \\\\\n      --species \\\"${resfinder_species}\\\" \\\\\n      --min_cov  ${resistance_mincov} \\\\\n      --threshold ${resistance_minid} \\\\\n      --acquired ;\n\n  # Fix name of pheno table\n  mv resfinder/pheno_table.txt resfinder/args_pheno_table.txt &> /dev/null ;\n\n  # Run resfinder pointfinder resistance\n  run_resfinder.py \\\\\n      --inputfasta $genome \\\\\n      -o resfinder \\\\\n      --species \\\"${resfinder_species}\\\" \\\\\n      --min_cov  ${resistance_mincov} \\\\\n      --threshold ${resistance_minid} \\\\\n      --point ;\n\n  # Fix name of pheno table\n  mv resfinder/pheno_table.txt resfinder/mutation_pheno_table.txt &> /dev/null ;\n\n  # Convert to GFF\n  resfinder2gff.py \\\\\n      -i resfinder/ResFinder_results_tab.txt > resfinder/results_tab.gff ;\n  \"\"\"\n\n  else if (resfinder_species.toLowerCase() == \"other\")\n  \"\"\"\n  # Make databases available\n  ln -rs ${bacannot_db}/resfinder_db/db_* \\$(dirname \\$(which run_resfinder.py))\n\n  # Run resfinder acquired resistance\n  run_resfinder.py \\\\\n      --inputfasta $genome \\\\\n      -o resfinder \\\\\n      --species \\\"${resfinder_species}\\\" \\\\\n      --min_cov  ${resistance_mincov} \\\\\n      --threshold ${resistance_minid} \\\\\n      --acquired ;\n\n  # Fix name of pheno table\n  mv resfinder/pheno_table.txt resfinder/args_pheno_table.txt &> /dev/null ;\n\n  # touch pointfinder\n  touch resfinder/PointFinder_results.txt ;\n\n  # Convert to GFF\n  resfinder2gff.py \\\\\n      -i resfinder/ResFinder_results_tab.txt > resfinder/results_tab.gff ;\n  \"\"\"\n}",
        "nb_lignes_process": 80,
        "string_script": "  resistance_minid  = params.blast_resistance_minid / 100.00\n  resistance_mincov = params.blast_resistance_mincov / 100.00\n  if (resfinder_species.toLowerCase() != \"other\")\n  \"\"\"\n  # Make databases available\n  ln -rs ${bacannot_db}/resfinder_db/db_* \\$(dirname \\$(which run_resfinder.py))\n\n  # Run resfinder acquired resistance\n  run_resfinder.py \\\\\n      --inputfasta $genome \\\\\n      -o resfinder \\\\\n      --species \\\"${resfinder_species}\\\" \\\\\n      --min_cov  ${resistance_mincov} \\\\\n      --threshold ${resistance_minid} \\\\\n      --acquired ;\n\n  # Fix name of pheno table\n  mv resfinder/pheno_table.txt resfinder/args_pheno_table.txt &> /dev/null ;\n\n  # Run resfinder pointfinder resistance\n  run_resfinder.py \\\\\n      --inputfasta $genome \\\\\n      -o resfinder \\\\\n      --species \\\"${resfinder_species}\\\" \\\\\n      --min_cov  ${resistance_mincov} \\\\\n      --threshold ${resistance_minid} \\\\\n      --point ;\n\n  # Fix name of pheno table\n  mv resfinder/pheno_table.txt resfinder/mutation_pheno_table.txt &> /dev/null ;\n\n  # Convert to GFF\n  resfinder2gff.py \\\\\n      -i resfinder/ResFinder_results_tab.txt > resfinder/results_tab.gff ;\n  \"\"\"\n\n  else if (resfinder_species.toLowerCase() == \"other\")\n  \"\"\"\n  # Make databases available\n  ln -rs ${bacannot_db}/resfinder_db/db_* \\$(dirname \\$(which run_resfinder.py))\n\n  # Run resfinder acquired resistance\n  run_resfinder.py \\\\\n      --inputfasta $genome \\\\\n      -o resfinder \\\\\n      --species \\\"${resfinder_species}\\\" \\\\\n      --min_cov  ${resistance_mincov} \\\\\n      --threshold ${resistance_minid} \\\\\n      --acquired ;\n\n  # Fix name of pheno table\n  mv resfinder/pheno_table.txt resfinder/args_pheno_table.txt &> /dev/null ;\n\n  # touch pointfinder\n  touch resfinder/PointFinder_results.txt ;\n\n  # Convert to GFF\n  resfinder2gff.py \\\\\n      -i resfinder/ResFinder_results_tab.txt > resfinder/results_tab.gff ;\n  \"\"\"",
        "nb_lignes_script": 59,
        "language_script": "bash",
        "tools": [
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "prefix",
            "resfinder_species",
            "genome",
            "bacannot_db"
        ],
        "nb_inputs": 4,
        "outputs": [
            "prefix",
            "prefix",
            "prefix",
            "prefix"
        ],
        "nb_outputs": 4,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/resistance\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_medium' ]"
        ],
        "when": "(resfinder_species && resfinder_species != \"missing_resfinder\")",
        "stub": ""
    },
    "PHAST": {
        "name_process": "PHAST",
        "string_process": "process PHAST {\n  publishDir \"${params.output}/${prefix}/prophages/phast_db\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_low' ]\n\n  input:\n  tuple val(prefix), file(genes)\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), path(\"${prefix}_phast_blastp_onGenes.summary.txt\")\n  tuple val(prefix), path(\"${prefix}_phast_blastp_onGenes.txt\")\n  path('*.txt')\n\n  script:\n  \"\"\"\n  # PHAST has protein database\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/phast_db/diamond.dmnd \\\\\n      --minid ${params.blast_MGEs_minid} \\\\\n      --mincov ${params.blast_MGEs_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_phast_blastp_onGenes.txt --2way | \\\\\n  sed -e 's/PRODUCT/PHAST_ID/g' > ${prefix}_phast_blastp_onGenes.summary.txt ;\n  \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "  \"\"\"\n  # PHAST has protein database\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/phast_db/diamond.dmnd \\\\\n      --minid ${params.blast_MGEs_minid} \\\\\n      --mincov ${params.blast_MGEs_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_phast_blastp_onGenes.txt --2way | \\\\\n  sed -e 's/PRODUCT/PHAST_ID/g' > ${prefix}_phast_blastp_onGenes.summary.txt ;\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "BLASTP-ACC"
        ],
        "tools_url": [
            "https://bio.tools/BLASTP-ACC"
        ],
        "tools_dico": [
            {
                "name": "BLASTP-ACC",
                "uri": "https://bio.tools/BLASTP-ACC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3297",
                            "term": "Biotechnology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3802",
                                    "term": "Sorting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Sequence alignment (local)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parallel Architecture and Hardware Accelerator Design for BLAST-based Protein Sequence Alignment.\n\nIn this study, we design a hardware accelerator for a widely used sequence alignment algorithm, the basic local alignment search tool for proteins (BLASTP). The architecture of the proposed accelerator consists of five stages: a new systolic-array-based one-hit finding stage, a novel RAM-REG-based two-hit finding stage, a refined ungapped extension stage, a faster gapped extension stage, and a highly efficient parallel sorter. The system is implemented on an Altera Stratix V FPGA with a processing speed of more than 500 giga cell updates per second (GCUPS). It can receive a query sequence, compare it with the sequences in the database, and generate a list sorted in descending order of the similarity scores between the query sequence and the subject sequences.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'accelerator', 'Altera', 'Stratix', 'RAM-REG-based'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31581096"
            }
        ],
        "inputs": [
            "prefix",
            "genes",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/prophages/phast_db\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "CREATE_SQL": {
        "name_process": "CREATE_SQL",
        "string_process": "process CREATE_SQL {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\".sqlite\") > 0) \"sqldb/$filename\"\n    else \"$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'renv', 'process_medium' ]\n\n  input:\n    tuple val(prefix), file(gff), file(genes_nt), file(genes_aa), file(genome), file(\"digIS.gff\"), file(\"digIS.fa\"), file(\"digIS.faa\")\n\n  output:\n    file \"${prefix}.sqlite\"\n    file \"run_server.sh\"\n\n  script:\n  \"\"\"\n  if [ -s digIS.fa ] ;\n  then\n\n    # concatenate files\n    cat $gff digIS.gff | bedtools sort > input.gff\n    cat $genes_nt digIS.fa  > input.fa\n    cat $genes_aa digIS.faa > input.faa\n\n    # Create SQL db\n    gff2sql.R -i input.gff -o ${prefix}.sqlite -n input.fa -a input.faa -f $genome &> gff2sql.log;\n\n  else\n\n    # Create SQL db\n    gff2sql.R -i $gff -o ${prefix}.sqlite -n $genes_nt -a $genes_aa -f $genome &> gff2sql.log;\n\n  fi\n\n  # Save results with better name\n  mv /work/${prefix}.sqlite . ;\n\n  # Save parser\n  cp /work/bscripts/run_server.sh . ;\n  \"\"\"\n}",
        "nb_lignes_process": 40,
        "string_script": "  \"\"\"\n  if [ -s digIS.fa ] ;\n  then\n\n    # concatenate files\n    cat $gff digIS.gff | bedtools sort > input.gff\n    cat $genes_nt digIS.fa  > input.fa\n    cat $genes_aa digIS.faa > input.faa\n\n    # Create SQL db\n    gff2sql.R -i input.gff -o ${prefix}.sqlite -n input.fa -a input.faa -f $genome &> gff2sql.log;\n\n  else\n\n    # Create SQL db\n    gff2sql.R -i $gff -o ${prefix}.sqlite -n $genes_nt -a $genes_aa -f $genome &> gff2sql.log;\n\n  fi\n\n  # Save results with better name\n  mv /work/${prefix}.sqlite . ;\n\n  # Save parser\n  cp /work/bscripts/run_server.sh . ;\n  \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "prefix",
            "gff",
            "genes_nt",
            "genes_aa",
            "genome"
        ],
        "nb_inputs": 5,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\".sqlite\") > 0) \"sqldb/$filename\" else \"$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'renv', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "ICEBERG": {
        "name_process": "ICEBERG",
        "string_process": "process ICEBERG {\n  publishDir \"${params.output}/${prefix}/ICEs\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_low' ]\n\n  input:\n  tuple val(prefix), file(genes_aa)\n  tuple val(prefix), file(genome)\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), file(\"${prefix}_iceberg_blastp_onGenes.summary.txt\")\n  tuple val(prefix), file(\"${prefix}_iceberg_blastp_onGenes.txt\")\n  tuple val(prefix), file(\"${prefix}_iceberg_blastn_onGenome.summary.txt\")\n  file('*.txt')            \n\n  script:\n  \"\"\"\n  # ICEberg is a protein and nucleotide dabatase\n  # In protein are the genes found inside ICEs\n  # In nucleotide are the full-length ICEs\n\n  ## Checking ICE genes\n  ## With predicted gene sequences\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes_aa \\\\\n      --db ${bacannot_db}/iceberg_db/diamond.dmnd \\\\\n      --minid ${params.blast_MGEs_minid} \\\\\n      --mincov ${params.blast_MGEs_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_iceberg_blastp_onGenes.txt --2way | \\\\\n  sed -e 's/GENE/ICEBERG_ID/g' > ${prefix}_iceberg_blastp_onGenes.summary.txt ;\n\n  ## Checking for full-length ICEs\n  ### The blast db was throwing errors\n  makeblastdb \\\\\n      -dbtype nucl \\\\\n      -in ${bacannot_db}/iceberg_db/sequences \\\\\n      -out sequences ;\n  run_blasts.py \\\\\n      blastn \\\\\n      --query $genome \\\\\n      --db sequences \\\\\n      --minid 0 \\\\\n      --mincov 0 \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_iceberg_blastn_onGenome.txt | \\\\\n  sed -e 's/GENE/ICEBERG_ID/g' > ${prefix}_iceberg_blastn_onGenome.summary.txt ;\n  \"\"\"\n}",
        "nb_lignes_process": 50,
        "string_script": "  \"\"\"\n  # ICEberg is a protein and nucleotide dabatase\n  # In protein are the genes found inside ICEs\n  # In nucleotide are the full-length ICEs\n\n  ## Checking ICE genes\n  ## With predicted gene sequences\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes_aa \\\\\n      --db ${bacannot_db}/iceberg_db/diamond.dmnd \\\\\n      --minid ${params.blast_MGEs_minid} \\\\\n      --mincov ${params.blast_MGEs_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_iceberg_blastp_onGenes.txt --2way | \\\\\n  sed -e 's/GENE/ICEBERG_ID/g' > ${prefix}_iceberg_blastp_onGenes.summary.txt ;\n\n  ## Checking for full-length ICEs\n  ### The blast db was throwing errors\n  makeblastdb \\\\\n      -dbtype nucl \\\\\n      -in ${bacannot_db}/iceberg_db/sequences \\\\\n      -out sequences ;\n  run_blasts.py \\\\\n      blastn \\\\\n      --query $genome \\\\\n      --db sequences \\\\\n      --minid 0 \\\\\n      --mincov 0 \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_iceberg_blastn_onGenome.txt | \\\\\n  sed -e 's/GENE/ICEBERG_ID/g' > ${prefix}_iceberg_blastn_onGenome.summary.txt ;\n  \"\"\"",
        "nb_lignes_script": 32,
        "language_script": "bash",
        "tools": [
            "BLASTP-ACC",
            "G-BLASTN"
        ],
        "tools_url": [
            "https://bio.tools/BLASTP-ACC",
            "https://bio.tools/g-blastn"
        ],
        "tools_dico": [
            {
                "name": "BLASTP-ACC",
                "uri": "https://bio.tools/BLASTP-ACC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3297",
                            "term": "Biotechnology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3802",
                                    "term": "Sorting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Sequence alignment (local)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parallel Architecture and Hardware Accelerator Design for BLAST-based Protein Sequence Alignment.\n\nIn this study, we design a hardware accelerator for a widely used sequence alignment algorithm, the basic local alignment search tool for proteins (BLASTP). The architecture of the proposed accelerator consists of five stages: a new systolic-array-based one-hit finding stage, a novel RAM-REG-based two-hit finding stage, a refined ungapped extension stage, a faster gapped extension stage, and a highly efficient parallel sorter. The system is implemented on an Altera Stratix V FPGA with a processing speed of more than 500 giga cell updates per second (GCUPS). It can receive a query sequence, compare it with the sequences in the database, and generate a list sorted in descending order of the similarity scores between the query sequence and the subject sequences.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'accelerator', 'Altera', 'Stratix', 'RAM-REG-based'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31581096"
            },
            {
                "name": "G-BLASTN",
                "uri": "https://bio.tools/g-blastn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0346",
                                    "term": "Sequence similarity search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2976",
                                "term": "Protein sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0857",
                                "term": "Sequence search results"
                            }
                        ]
                    }
                ],
                "description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "homepage": "http://www.comp.hkbu.edu.hk/~chxw/software/G-BLASTN.html"
            }
        ],
        "inputs": [
            "prefix",
            "genes_aa",
            "prefix",
            "genome",
            "bacannot_db"
        ],
        "nb_inputs": 5,
        "outputs": [
            "prefix",
            "prefix",
            "prefix"
        ],
        "nb_outputs": 3,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/ICEs\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "UNICYCLER": {
        "name_process": "UNICYCLER",
        "string_process": "process UNICYCLER {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else if (filename == \"unicycler_${prefix}\") \"assembly\"\n    else null\n  }\n  label 'process_high'\n  tag \"${prefix}\"\n\n  input:\n  tuple val(prefix), val(entrypoint), file(sread1), file(sread2), file(sreads), file(lreads), val(lr_type), file(fast5), val(assembly), val(resfinder_species)\n\n  output:\n  file \"unicycler_${prefix}\"                   \n                                            \n  tuple val(\"${prefix}\"), val(\"${entrypoint}\"), val(\"${sread1}\"), val(\"${sread2}\"), val(\"${sreads}\"), file(\"${lreads}\"), val(\"${lr_type}\"), file(\"${fast5}\"), file(\"unicycler_${prefix}.fasta\"), val(\"${resfinder_species}\")\n  file('unicycler_version.txt')\n  \n  script:\n  unpaired_param = (sreads.getName() != \"input.3\") ? \"-s $sreads\" : \"\"\n  paired_param = (sread1.getName() != \"input.1\" && sread2.getName() != \"input.2\") ? \"-1 $sread1 -2 $sread2\" : \"\"\n  lr_param = (lreads.getName() != \"input.4\") ? \"-l $lreads\" : \"\"\n\n  \"\"\"\n  # Save unicycler version\n  unicycler --version > unicycler_version.txt\n\n  # Run unicycler\n  unicycler \\\\\n    $paired_param \\\\\n    $unpaired_param \\\\\n    $lr_param \\\\\n    -o unicycler_${prefix} \\\\\n    -t $task.cpus &> unicycler.log\n\n  # Save copy for annotation\n  cp unicycler_${prefix}/assembly.fasta unicycler_${prefix}.fasta\n  \"\"\"\n}",
        "nb_lignes_process": 37,
        "string_script": "  unpaired_param = (sreads.getName() != \"input.3\") ? \"-s $sreads\" : \"\"\n  paired_param = (sread1.getName() != \"input.1\" && sread2.getName() != \"input.2\") ? \"-1 $sread1 -2 $sread2\" : \"\"\n  lr_param = (lreads.getName() != \"input.4\") ? \"-l $lreads\" : \"\"\n\n  \"\"\"\n  # Save unicycler version\n  unicycler --version > unicycler_version.txt\n\n  # Run unicycler\n  unicycler \\\\\n    $paired_param \\\\\n    $unpaired_param \\\\\n    $lr_param \\\\\n    -o unicycler_${prefix} \\\\\n    -t $task.cpus &> unicycler.log\n\n  # Save copy for annotation\n  cp unicycler_${prefix}/assembly.fasta unicycler_${prefix}.fasta\n  \"\"\"",
        "nb_lignes_script": 18,
        "language_script": "bash",
        "tools": [
            "Unicycler"
        ],
        "tools_url": [
            "https://bio.tools/unicycler"
        ],
        "tools_dico": [
            {
                "name": "Unicycler",
                "uri": "https://bio.tools/unicycler",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3301",
                            "term": "Microbiology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3436",
                                    "term": "Aggregation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0925",
                                "term": "Sequence assembly"
                            }
                        ]
                    }
                ],
                "description": "A tool for assembling bacterial genomes from a combination of short (2nd generation) and long (3rd generation) sequencing reads.",
                "homepage": "https://github.com/rrwick/Unicycler"
            }
        ],
        "inputs": [
            "prefix",
            "entrypoint",
            "lr_type",
            "assembly",
            "resfinder_species",
            "sread1",
            "sread2",
            "sreads",
            "lreads",
            "fast5"
        ],
        "nb_inputs": 10,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else if (filename == \"unicycler_${prefix}\") \"assembly\" else null }",
            "label 'process_high'",
            "tag \"${prefix}\""
        ],
        "when": "",
        "stub": ""
    },
    "REPORT": {
        "name_process": "REPORT",
        "string_process": "process REPORT {\n  publishDir \"${params.output}/${prefix}/report_files\", mode: 'copy'\n  label = [ 'renv', 'process_medium' ]\n  tag \"${prefix}\"\n\n  input:\n  tuple val(prefix), file(prokka_stats), file(gff), file(barrnap), file(mlst), file(keggsvg), file(refseq_masher_txt), file(amrfinder), file(rgi), file(rgi_parsed), file(rgi_heatmap), file(argminer_out), file(resfinder_tab), file(resfinder_point), file(resfinder_phenotable), file(vfdb_blastn), file(victors_blastp), file(phigaro_txt), file(phispy_tsv), file(iceberg_blastp), file(iceberg_blastn), file(plasmids_tsv), file(platon_tsv), file(gi_image), file(phast_blastp), file(digIS)\n  \n  output:\n  file '*.html'\n\n  script:\n  \"\"\"\n  #!/usr/bin/env Rscript\n\n  ## Copy reports\n  system(\"cp /work/reports/* .\") ;\n\n  ## Remove empty files\n  system(\"rm -f input.??\") ;\n  system(\"rm -f input.?\") ;\n\n  ## Generate generic Report\n  rmarkdown::render(\"report_general.Rmd\" , \\\n  params = list( prokka  = \"$prokka_stats\", \\\n                 kegg    = \"$keggsvg\", \\\n                 barrnap = \"$barrnap\", \\\n                 mlst    = \"$mlst\", \\\n                 refseq_masher = \"$refseq_masher_txt\", \\\n                 query = \"${prefix}\")) ;\n\n  ## Generate Resistance Report\n  rmarkdown::render(\"report_resistance.Rmd\", params = list(\\\n    blast_id = ${params.blast_resistance_minid} , \\\n    blast_cov = ${params.blast_resistance_mincov}, \\\n    amrfinder = \"$amrfinder\", \\\n    query = \"${prefix}\", \\\n    rgitool = \"$rgi\", \\\n    rgiparsed = \"$rgi_parsed\", \\\n    rgi_heatmap = \"$rgi_heatmap\", \\\n    argminer_blastp = \"$argminer_out\", \\\n    resfinder_tab = \"$resfinder_tab\", \\\n    resfinder_pointfinder = \"$resfinder_point\", \\\n    resfinder_phenotype = \"$resfinder_phenotable\", \\\n    gff = \"$gff\")) ;\n\n  ## Generate Virulence Report\n  rmarkdown::render(\"report_virulence.Rmd\" , \\\n  params = list( blast_id = ${params.blast_virulence_minid} , \\\n                 blast_cov = ${params.blast_virulence_mincov}, \\\n                 vfdb_blast = \"$vfdb_blastn\", \\\n                 gff = \"$gff\", \\\n                 victors_blast = \"$victors_blastp\", \\\n                 query = \"${prefix}\")) ;\n\n  ## Generate MGEs report\n  rmarkdown::render(\"report_MGEs.Rmd\", \\\n  params = list( blast_id = ${params.blast_MGEs_minid}, \\\n                 blast_cov = ${params.blast_MGEs_mincov}, \\\n                 phigaro_dir = \"${params.output}/prophages/phigaro\", \\\n                 phigaro_txt = \"$phigaro_txt\", \\\n                 phispy_tsv = \"$phispy_tsv\", \\\n                 ice_prot_blast = \"$iceberg_blastp\", \\\n                 ice_genome_blast = \"$iceberg_blastn\", \\\n                 plasmid_finder_tab = \"$plasmids_tsv\", \\\n                 platon_tsv = \"$platon_tsv\", \\\n                 query = \"${prefix}\", \\\n                 gi_image = \"$gi_image\", \\\n                 digis = \"$digIS\", \\\n                 gff = \"$gff\", \\\n                 phast_prot_blast = \"$phast_blastp\" )) ;\n  \"\"\"\n}",
        "nb_lignes_process": 71,
        "string_script": "  \"\"\"\n  #!/usr/bin/env Rscript\n\n  ## Copy reports\n  system(\"cp /work/reports/* .\") ;\n\n  ## Remove empty files\n  system(\"rm -f input.??\") ;\n  system(\"rm -f input.?\") ;\n\n  ## Generate generic Report\n  rmarkdown::render(\"report_general.Rmd\" , \\\n  params = list( prokka  = \"$prokka_stats\", \\\n                 kegg    = \"$keggsvg\", \\\n                 barrnap = \"$barrnap\", \\\n                 mlst    = \"$mlst\", \\\n                 refseq_masher = \"$refseq_masher_txt\", \\\n                 query = \"${prefix}\")) ;\n\n  ## Generate Resistance Report\n  rmarkdown::render(\"report_resistance.Rmd\", params = list(\\\n    blast_id = ${params.blast_resistance_minid} , \\\n    blast_cov = ${params.blast_resistance_mincov}, \\\n    amrfinder = \"$amrfinder\", \\\n    query = \"${prefix}\", \\\n    rgitool = \"$rgi\", \\\n    rgiparsed = \"$rgi_parsed\", \\\n    rgi_heatmap = \"$rgi_heatmap\", \\\n    argminer_blastp = \"$argminer_out\", \\\n    resfinder_tab = \"$resfinder_tab\", \\\n    resfinder_pointfinder = \"$resfinder_point\", \\\n    resfinder_phenotype = \"$resfinder_phenotable\", \\\n    gff = \"$gff\")) ;\n\n  ## Generate Virulence Report\n  rmarkdown::render(\"report_virulence.Rmd\" , \\\n  params = list( blast_id = ${params.blast_virulence_minid} , \\\n                 blast_cov = ${params.blast_virulence_mincov}, \\\n                 vfdb_blast = \"$vfdb_blastn\", \\\n                 gff = \"$gff\", \\\n                 victors_blast = \"$victors_blastp\", \\\n                 query = \"${prefix}\")) ;\n\n  ## Generate MGEs report\n  rmarkdown::render(\"report_MGEs.Rmd\", \\\n  params = list( blast_id = ${params.blast_MGEs_minid}, \\\n                 blast_cov = ${params.blast_MGEs_mincov}, \\\n                 phigaro_dir = \"${params.output}/prophages/phigaro\", \\\n                 phigaro_txt = \"$phigaro_txt\", \\\n                 phispy_tsv = \"$phispy_tsv\", \\\n                 ice_prot_blast = \"$iceberg_blastp\", \\\n                 ice_genome_blast = \"$iceberg_blastn\", \\\n                 plasmid_finder_tab = \"$plasmids_tsv\", \\\n                 platon_tsv = \"$platon_tsv\", \\\n                 query = \"${prefix}\", \\\n                 gi_image = \"$gi_image\", \\\n                 digis = \"$digIS\", \\\n                 gff = \"$gff\", \\\n                 phast_prot_blast = \"$phast_blastp\" )) ;\n  \"\"\"",
        "nb_lignes_script": 59,
        "language_script": "Rscript",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "prokka_stats",
            "gff",
            "barrnap",
            "mlst",
            "keggsvg",
            "refseq_masher_txt",
            "amrfinder",
            "rgi",
            "rgi_parsed",
            "rgi_heatmap",
            "argminer_out",
            "resfinder_tab",
            "resfinder_point",
            "resfinder_phenotable",
            "vfdb_blastn",
            "victors_blastp",
            "phigaro_txt",
            "phispy_tsv",
            "iceberg_blastp",
            "iceberg_blastn",
            "plasmids_tsv",
            "platon_tsv",
            "gi_image",
            "phast_blastp",
            "digIS"
        ],
        "nb_inputs": 26,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/report_files\", mode: 'copy'",
            "label = [ 'renv', 'process_medium' ]",
            "tag \"${prefix}\""
        ],
        "when": "",
        "stub": ""
    },
    "DIGIS": {
        "name_process": "DIGIS",
        "string_process": "process DIGIS {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else if (filename == \"${prefix}.gff\") null\n    else if (filename == \"${prefix}_IS.gff\") null\n    else \"$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_low' ]\n\n  input:\n  tuple val(prefix), path(genome), path(genbank)\n\n  output:\n                 \n  file(\"digIS\")\n  tuple val(prefix), path(\"digIS/results/${prefix}.gff\")\n  tuple val(prefix), path(\"${prefix}_IS.gff\"), path(\"digIS/results/fastas/${prefix}_IS.fa\"), path(\"digIS/results/fastas/${prefix}_IS.faa\")\n\n  script:\n  \"\"\"\n  # activate env\n  source activate digIS\n\n  # run digIS\n  python3 \\$(which digIS_search.py) -i $genome -g $genbank -o digIS\n\n  # deactivate env\n  conda deactivate\n\n  # parse digIS to get nucleotide and aminoacide\n  # also put ids in uppercase\n  # required for annotation merging and sqldb\n\n  ## dir for fastas\n  mkdir -p digIS/results/fastas ;\n\n  ## save info in gff\n  sed \\\\\n    -e 's/id=/ID=/g' \\\\\n    digIS/results/${prefix}.gff > ${prefix}_IS.gff ;\n\n  ## get nucl sequences\n  gff-toolbox \\\\\n    convert \\\\\n    -i ${prefix}_IS.gff  \\\\\n    -f fasta-nt \\\\\n    --fasta $genome \\\\\n    --fasta_features transposable_element > digIS/results/fastas/${prefix}_IS.fa  ;\n  \n  ## get prot sequences\n  gff-toolbox \\\\\n    convert \\\\\n    -i ${prefix}_IS.gff  \\\\\n    -f fasta-aa \\\\\n    --fasta $genome \\\\\n    --fasta_features transposable_element > digIS/results/fastas/${prefix}_IS.faa ;\n  \"\"\"\n}",
        "nb_lignes_process": 57,
        "string_script": "  \"\"\"\n  # activate env\n  source activate digIS\n\n  # run digIS\n  python3 \\$(which digIS_search.py) -i $genome -g $genbank -o digIS\n\n  # deactivate env\n  conda deactivate\n\n  # parse digIS to get nucleotide and aminoacide\n  # also put ids in uppercase\n  # required for annotation merging and sqldb\n\n  ## dir for fastas\n  mkdir -p digIS/results/fastas ;\n\n  ## save info in gff\n  sed \\\\\n    -e 's/id=/ID=/g' \\\\\n    digIS/results/${prefix}.gff > ${prefix}_IS.gff ;\n\n  ## get nucl sequences\n  gff-toolbox \\\\\n    convert \\\\\n    -i ${prefix}_IS.gff  \\\\\n    -f fasta-nt \\\\\n    --fasta $genome \\\\\n    --fasta_features transposable_element > digIS/results/fastas/${prefix}_IS.fa  ;\n  \n  ## get prot sequences\n  gff-toolbox \\\\\n    convert \\\\\n    -i ${prefix}_IS.gff  \\\\\n    -f fasta-aa \\\\\n    --fasta $genome \\\\\n    --fasta_features transposable_element > digIS/results/fastas/${prefix}_IS.faa ;\n  \"\"\"",
        "nb_lignes_script": 37,
        "language_script": "bash",
        "tools": [
            "ANACONDA",
            "convert"
        ],
        "tools_url": [
            "https://bio.tools/anaconda",
            "https://bio.tools/convert"
        ],
        "tools_dico": [
            {
                "name": "ANACONDA",
                "uri": "https://bio.tools/anaconda",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3658",
                                    "term": "Statistical inference"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Nucleic acid sequence analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2478",
                                    "term": "Sequence analysis (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software package specially developed for the study of genes\u2019 primary structure. It uses gene sequences downloaded from public databases, as FASTA and GenBank, and it applies a set of statistical and visualization methods in different ways, to reveal information about codon context, codon usage, nucleotide repeats within open reading frames (ORFeome) and others.",
                "homepage": "http://bioinformatics.ua.pt/software/anaconda/"
            },
            {
                "name": "convert",
                "uri": "https://bio.tools/convert",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3511",
                            "term": "Nucleic acid sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3434",
                                    "term": "Conversion"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File reformatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File format conversion"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "File formatting"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0335",
                                    "term": "Reformatting"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0863",
                                "term": "Sequence alignment"
                            },
                            {
                                "uri": "http://edamontology.org/data_2854",
                                "term": "Position-specific scoring matrix"
                            },
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2854",
                                "term": "Position-specific scoring matrix"
                            },
                            {
                                "uri": "http://edamontology.org/data_1669",
                                "term": "P-value"
                            },
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "Define coerce methods for microarray data objects.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/convert.html"
            }
        ],
        "inputs": [
            "prefix",
            "genome",
            "genbank"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else if (filename == \"${prefix}.gff\") null else if (filename == \"${prefix}_IS.gff\") null else \"$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "CARD_RGI": {
        "name_process": "CARD_RGI",
        "string_process": "process CARD_RGI {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else if (filename == \"Parsed_RGI_${prefix}_hits.txt\") null\n    else \"resistance/RGI/$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'python', 'process_medium' ]\n\n  input:\n  tuple val(prefix), path(input)\n  path(bacannot_db)\n\n  output:\n                     \n  path \"*RGI_${prefix}*\" optional true\n                                                \n  tuple val(prefix), path(\"Parsed_RGI_${prefix}_hits.txt\") optional true\n  tuple val(prefix), path(\"RGI_${prefix}.txt\") optional true\n  tuple val(prefix), path(\"heatmap/RGI*heatmap*.png\") optional true\n  path(\"heatmap\") optional true\n  path(\"*_version.txt\")\n\n  script:\n  \"\"\"\n  # activate env\n  source activate rgi\n  \n  # load database\n  rgi load --card_json ${bacannot_db}/card_db/card.json --local\n\n  # get tool version\n  rgi main --version > rgi_version.txt ;\n  rgi database --version --local > card_db_version.txt ;\n\n  # execute RGI\n  rgi main \\\\\n      --local \\\\\n      --input_sequence $input \\\\\n      --output_file RGI_${prefix}_unfiltered \\\\\n      --input_type protein \\\\\n      --num_threads $task.cpus \\\\\n      --exclude_nudge \\\\\n      --clean ;\n\n  ## filtering by identity\n  awk '\n      BEGIN { FS = \"\\\\t\"; OFS=\"\\\\t\" } \n      { if (\\$10 >= ${params.blast_resistance_minid}) print }\n      ' RGI_${prefix}_unfiltered.txt > ./RGI_${prefix}.txt\n\n  ## parse RGI results for reports\n  cat RGI_${prefix}.txt | \\\\\n      tail -n +2 | \\\\\n      awk '\n          BEGIN { FS = \"\\\\t\"; OFS=\"\\\\t\" }\n          { split(\\$1,a,\" \"); print a[1],\\$6,\\$9,\\$11,\\$15,\\$16,\\$17 }\n          ' > Parsed_RGI_${prefix}_hits.txt\n\n  # draw heatmap for single sample\n  if [ \\$(wc -l RGI_${prefix}.txt | cut -d \" \" -f 1) -gt 1 ]\n  then\n    mkdir -p heatmap ;\n    cp RGI_${prefix}_unfiltered.json heatmap/${prefix}.json ;\n    rgi heatmap --input ./heatmap -cat drug_class -d text ;\n    rm heatmap/${prefix}.json ;\n    mv RGI*heatmap* heatmap ;\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 68,
        "string_script": "  \"\"\"\n  # activate env\n  source activate rgi\n  \n  # load database\n  rgi load --card_json ${bacannot_db}/card_db/card.json --local\n\n  # get tool version\n  rgi main --version > rgi_version.txt ;\n  rgi database --version --local > card_db_version.txt ;\n\n  # execute RGI\n  rgi main \\\\\n      --local \\\\\n      --input_sequence $input \\\\\n      --output_file RGI_${prefix}_unfiltered \\\\\n      --input_type protein \\\\\n      --num_threads $task.cpus \\\\\n      --exclude_nudge \\\\\n      --clean ;\n\n  ## filtering by identity\n  awk '\n      BEGIN { FS = \"\\\\t\"; OFS=\"\\\\t\" } \n      { if (\\$10 >= ${params.blast_resistance_minid}) print }\n      ' RGI_${prefix}_unfiltered.txt > ./RGI_${prefix}.txt\n\n  ## parse RGI results for reports\n  cat RGI_${prefix}.txt | \\\\\n      tail -n +2 | \\\\\n      awk '\n          BEGIN { FS = \"\\\\t\"; OFS=\"\\\\t\" }\n          { split(\\$1,a,\" \"); print a[1],\\$6,\\$9,\\$11,\\$15,\\$16,\\$17 }\n          ' > Parsed_RGI_${prefix}_hits.txt\n\n  # draw heatmap for single sample\n  if [ \\$(wc -l RGI_${prefix}.txt | cut -d \" \" -f 1) -gt 1 ]\n  then\n    mkdir -p heatmap ;\n    cp RGI_${prefix}_unfiltered.json heatmap/${prefix}.json ;\n    rgi heatmap --input ./heatmap -cat drug_class -d text ;\n    rm heatmap/${prefix}.json ;\n    mv RGI*heatmap* heatmap ;\n  fi\n  \"\"\"",
        "nb_lignes_script": 44,
        "language_script": "bash",
        "tools": [
            "Rgin"
        ],
        "tools_url": [
            "https://bio.tools/rgin"
        ],
        "tools_dico": [
            {
                "name": "Rgin",
                "uri": "https://bio.tools/rgin",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "Genetic variation"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2885",
                            "term": "DNA polymorphism"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0199",
                            "term": "DNA variation"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2497",
                                    "term": "Pathway or network analysis"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "C++ implementation of SConES.",
                "homepage": "http://bioconductor.org/packages/release/bioc/html/Rgin.html"
            }
        ],
        "inputs": [
            "prefix",
            "input",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix",
            "prefix"
        ],
        "nb_outputs": 3,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else if (filename == \"Parsed_RGI_${prefix}_hits.txt\") null else \"resistance/RGI/$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'python', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "VFDB": {
        "name_process": "VFDB",
        "string_process": "process VFDB {\n  publishDir \"${params.output}/${prefix}/virulence/vfdb\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_low' ]\n\n  input:\n  tuple val(prefix), file(genes)\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), path(\"${prefix}_vfdb_blastn_onGenes.summary.txt\")\n  tuple val(prefix), path(\"${prefix}_vfdb_blastn_onGenes.txt\")\n  path('*.txt')\n\n  script:\n  \"\"\"\n  # VFDB has nucleotide database\n  run_blasts.py \\\\\n      blastn \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/vfdb_db/sequences \\\\\n      --minid ${params.blast_virulence_minid} \\\\\n      --mincov ${params.blast_virulence_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_vfdb_blastn_onGenes.txt \\\\\n      --2way | \\\\\n  sed -e 's/ACCESSION/VFDB_ID/g' > ${prefix}_vfdb_blastn_onGenes.summary.txt ;\n  \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "  \"\"\"\n  # VFDB has nucleotide database\n  run_blasts.py \\\\\n      blastn \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/vfdb_db/sequences \\\\\n      --minid ${params.blast_virulence_minid} \\\\\n      --mincov ${params.blast_virulence_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_vfdb_blastn_onGenes.txt \\\\\n      --2way | \\\\\n  sed -e 's/ACCESSION/VFDB_ID/g' > ${prefix}_vfdb_blastn_onGenes.summary.txt ;\n  \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [
            "G-BLASTN"
        ],
        "tools_url": [
            "https://bio.tools/g-blastn"
        ],
        "tools_dico": [
            {
                "name": "G-BLASTN",
                "uri": "https://bio.tools/g-blastn",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acids"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0077",
                            "term": "Nucleic acid informatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0654",
                            "term": "DNA analysis"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0346",
                                    "term": "Sequence similarity search"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0292",
                                    "term": "Sequence alignment construction"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2976",
                                "term": "Protein sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0857",
                                "term": "Sequence search results"
                            }
                        ]
                    }
                ],
                "description": "GPU-accelerated nucleotide alignment tool based on the widely used NCBI-BLAST.",
                "homepage": "http://www.comp.hkbu.edu.hk/~chxw/software/G-BLASTN.html"
            }
        ],
        "inputs": [
            "prefix",
            "genes",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix",
            "prefix"
        ],
        "nb_outputs": 2,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/virulence/vfdb\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "ARGMINER": {
        "name_process": "ARGMINER",
        "string_process": "process ARGMINER {\n  publishDir \"${params.output}/${prefix}/resistance/ARGMiner\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_low' ]\n\n  input:\n  tuple val(prefix), file(genes)\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), file(\"${prefix}_argminer_blastp_onGenes.summary.txt\")\n  file('*.txt')                  \n\n  script:\n  \"\"\"\n  # run blast with argminer db\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/argminer_db/diamond.dmnd \\\\\n      --minid ${params.blast_resistance_minid} \\\\\n      --mincov ${params.blast_resistance_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_argminer_blastp_onGenes.txt \\\\\n      --2way > ${prefix}_argminer_blastp_onGenes.summary.txt ;\n  \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "  \"\"\"\n  # run blast with argminer db\n  run_blasts.py \\\\\n      blastp \\\\\n      --query $genes \\\\\n      --db ${bacannot_db}/argminer_db/diamond.dmnd \\\\\n      --minid ${params.blast_resistance_minid} \\\\\n      --mincov ${params.blast_resistance_mincov} \\\\\n      --threads $task.cpus \\\\\n      --out ${prefix}_argminer_blastp_onGenes.txt \\\\\n      --2way > ${prefix}_argminer_blastp_onGenes.summary.txt ;\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [
            "BLASTP-ACC"
        ],
        "tools_url": [
            "https://bio.tools/BLASTP-ACC"
        ],
        "tools_dico": [
            {
                "name": "BLASTP-ACC",
                "uri": "https://bio.tools/BLASTP-ACC",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3297",
                            "term": "Biotechnology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structure analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Proteins"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Structural bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0081",
                            "term": "Biomolecular structure"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein bioinformatics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0078",
                            "term": "Protein informatics"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Database search"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3802",
                                    "term": "Sorting"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Local sequence alignment"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0495",
                                    "term": "Sequence alignment (local)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2421",
                                    "term": "Search"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Parallel Architecture and Hardware Accelerator Design for BLAST-based Protein Sequence Alignment.\n\nIn this study, we design a hardware accelerator for a widely used sequence alignment algorithm, the basic local alignment search tool for proteins (BLASTP). The architecture of the proposed accelerator consists of five stages: a new systolic-array-based one-hit finding stage, a novel RAM-REG-based two-hit finding stage, a refined ungapped extension stage, a faster gapped extension stage, and a highly efficient parallel sorter. The system is implemented on an Altera Stratix V FPGA with a processing speed of more than 500 giga cell updates per second (GCUPS). It can receive a query sequence, compare it with the sequences in the database, and generate a list sorted in descending order of the similarity scores between the query sequence and the subject sequences.\n\n||| HOMEPAGE MISSING!.\n\n||| CORRECT NAME OF TOOL COULD ALSO BE 'accelerator', 'Altera', 'Stratix', 'RAM-REG-based'",
                "homepage": "https://www.ncbi.nlm.nih.gov/pubmed/?term=31581096"
            }
        ],
        "inputs": [
            "prefix",
            "genes",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix"
        ],
        "nb_outputs": 1,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/resistance/ARGMiner\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "PROKKA": {
        "name_process": "PROKKA",
        "string_process": "process PROKKA {\n    publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n      if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n      else if (filename == \"annotation\") \"$filename\"\n      else null\n    }\n    tag \"${prefix}\"\n    label = [ 'perl', 'process_medium' ]\n\n    input:\n    tuple val(prefix), val(entrypoint), file(sread1), file(sread2), file(sreads), file(lreads), val(lr_type), file(fast5), file(assembly), val(resfinder_species)\n    file(bacannot_db)\n\n    output:\n                       \n    path(\"annotation\")\n                                                  \n    tuple val(prefix), path(\"annotation/${prefix}.gff\")\n    tuple val(prefix), path(\"annotation/${prefix}.gbk\")\n    tuple val(prefix), path(\"annotation/${prefix}.fna\")\n    tuple val(prefix), path(\"annotation/${prefix}.faa\")\n    tuple val(prefix), path(\"annotation/${prefix}.ffn\")\n    tuple val(prefix), path(\"annotation/${prefix}.fna\"), path(\"${lreads}\"), path(\"${fast5}\")\n    tuple val(prefix), path(\"annotation/${prefix}.fna\"), val(\"${resfinder_species}\")\n    tuple val(prefix), path(\"annotation/${prefix}.txt\")\n    path('prokka_version.txt')\n\n    script:\n    kingdom = (params.prokka_kingdom)      ? \"--kingdom ${params.prokka_kingdom}\"        : ''\n    gcode   = (params.prokka_genetic_code) ? \"--gcode ${params.prokka_genetic_code}\"     : ''\n    rnammer = (params.prokka_use_rnammer)  ? \"--rnammer\"                                 : ''\n    models  = (params.prokka_use_pgap)     ? \"PGAP_NCBI.hmm\" : \"TIGRFAMs_15.0.hmm\"\n    \"\"\"\n    # save prokka version\n    prokka -v &> prokka_version.txt ;\n\n    # where are default prokka dbs?\n    dbs_dir=\\$(prokka --listdb 2>&1 >/dev/null |  grep \"databases in\" | cut -f 4 -d \":\" | tr -d \" \") ;\n\n    # get hmms that shall be used\n    # PGAP contains TIGRFAM hmm models. When not skipping PGAP, TIGRFAM is not loaded.\n    cp -r \\$dbs_dir prokka_db\n    cp ${bacannot_db}/prokka_db/${models} prokka_db/hmm\n\n    # hmmpress\n    ( cd  prokka_db/hmm/ ; for i in *.hmm ; do hmmpress -f \\$i ; done )\n\n    # run prokka\n    prokka \\\\\n        --dbdir prokka_db \\\\\n        $kingdom $gcode $rnammer \\\\\n        --outdir annotation \\\\\n        --cpus $task.cpus \\\\\n        --mincontiglen 200 \\\\\n        --prefix ${prefix} \\\\\n        --genus '' \\\\\n        --species '' \\\\\n        --strain \\\"${prefix}\\\" \\\\\n        $assembly\n    \n    # remove tmp dir to gain space\n    rm -r prokka_db\n    \"\"\"\n}",
        "nb_lignes_process": 62,
        "string_script": "    kingdom = (params.prokka_kingdom)      ? \"--kingdom ${params.prokka_kingdom}\"        : ''\n    gcode   = (params.prokka_genetic_code) ? \"--gcode ${params.prokka_genetic_code}\"     : ''\n    rnammer = (params.prokka_use_rnammer)  ? \"--rnammer\"                                 : ''\n    models  = (params.prokka_use_pgap)     ? \"PGAP_NCBI.hmm\" : \"TIGRFAMs_15.0.hmm\"\n    \"\"\"\n    # save prokka version\n    prokka -v &> prokka_version.txt ;\n\n    # where are default prokka dbs?\n    dbs_dir=\\$(prokka --listdb 2>&1 >/dev/null |  grep \"databases in\" | cut -f 4 -d \":\" | tr -d \" \") ;\n\n    # get hmms that shall be used\n    # PGAP contains TIGRFAM hmm models. When not skipping PGAP, TIGRFAM is not loaded.\n    cp -r \\$dbs_dir prokka_db\n    cp ${bacannot_db}/prokka_db/${models} prokka_db/hmm\n\n    # hmmpress\n    ( cd  prokka_db/hmm/ ; for i in *.hmm ; do hmmpress -f \\$i ; done )\n\n    # run prokka\n    prokka \\\\\n        --dbdir prokka_db \\\\\n        $kingdom $gcode $rnammer \\\\\n        --outdir annotation \\\\\n        --cpus $task.cpus \\\\\n        --mincontiglen 200 \\\\\n        --prefix ${prefix} \\\\\n        --genus '' \\\\\n        --species '' \\\\\n        --strain \\\"${prefix}\\\" \\\\\n        $assembly\n    \n    # remove tmp dir to gain space\n    rm -r prokka_db\n    \"\"\"",
        "nb_lignes_script": 34,
        "language_script": "bash",
        "tools": [
            "RNAmmer",
            "AMModels",
            "Prokka",
            "NullSeq"
        ],
        "tools_url": [
            "https://bio.tools/rnammer",
            "https://bio.tools/ammodels",
            "https://bio.tools/prokka",
            "https://bio.tools/nullseq"
        ],
        "tools_dico": [
            {
                "name": "RNAmmer",
                "uri": "https://bio.tools/rnammer",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Nucleic acid feature detection"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0415",
                                    "term": "Sequence feature detection (nucleic acid)"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_2044",
                                "term": "Sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_1277",
                                "term": "Protein features"
                            }
                        ]
                    }
                ],
                "description": "Prediction of 5S/8S, 16S/18S, and 23S/28S ribosomal RNA in full genome sequences.",
                "homepage": "http://cbs.dtu.dk/services/RNAmmer/"
            },
            {
                "name": "AMModels",
                "uri": "https://bio.tools/ammodels",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2269",
                            "term": "Statistics and probability"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Tool which helps enable adaptive management by codifying knowledge in the form of models generated from numerous analyses and data sets. Facilitates this process by storing all models and data sets in a single object that can be updated and saved, thus tracking changes in knowledge through time. A shiny application called AM Model Manager (modelMgr()) enables the use of these functions via a GUI.",
                "homepage": "https://cran.r-project.org/web/packages/AMModels/index.html"
            },
            {
                "name": "Prokka",
                "uri": "https://bio.tools/prokka",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Model organisms"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0781",
                            "term": "Virology"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0621",
                            "term": "Organisms"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "Coding region prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0436",
                                    "term": "ORF finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Software tool to annotate bacterial, archaeal and viral genomes quickly and produce standards-compliant output files.",
                "homepage": "https://github.com/tseemann/prokka"
            },
            {
                "name": "NullSeq",
                "uri": "https://bio.tools/nullseq",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0364",
                                    "term": "Random sequence generation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Creates Random Coding Sequences with specified GC content and Amino Acid usage.",
                "homepage": "https://github.com/amarallab/NullSeq"
            }
        ],
        "inputs": [
            "prefix",
            "entrypoint",
            "lr_type",
            "resfinder_species",
            "sread1",
            "sread2",
            "sreads",
            "lreads",
            "fast5",
            "assembly",
            "bacannot_db"
        ],
        "nb_inputs": 11,
        "outputs": [
            "prefix",
            "prefix",
            "prefix",
            "prefix",
            "prefix",
            "prefix",
            "prefix",
            "prefix"
        ],
        "nb_outputs": 8,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else if (filename == \"annotation\") \"$filename\" else null }",
            "tag \"${prefix}\"",
            "label = [ 'perl', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_ANNOTATIONS": {
        "name_process": "MERGE_ANNOTATIONS",
        "string_process": "process MERGE_ANNOTATIONS {\n  publishDir \"${params.output}/${prefix}/gffs\", mode: 'copy'\n  label = [ 'renv', 'process_medium', 'error_retry' ]\n  tag \"${prefix}\"\n\n  input:\n  tuple val(prefix), file('prokka_gff'), file(kofamscan), file(vfdb), file(victors), file(amrfinder), file(resfinder), file(rgi), file(iceberg), file(phast), file('digis_gff'), file(custom_databases)\n\n  output:\n  tuple val(prefix), path(\"${prefix}.gff\")\n  tuple val(prefix), path(\"transposable_elements_digis.gff\")\n  tuple val(prefix), path(\"custom_database_*.gff\") optional true\n  path(\"*.gff\")\n\n  script:\n  \"\"\"\n  # Rename gff and remove sequence entries\n  grep \"ID=\" prokka_gff > ${prefix}.gff ;\n\n  ## Increment GFF with custom annotations\n  ### VFDB\n  if [ ! \\$(cat $vfdb | wc -l) -le 1 ]\n  then\n    addBlast2Gff.R -i $vfdb -g ${prefix}.gff -o ${prefix}.gff -d VFDB -t Virulence ;\n    grep \"VFDB\" ${prefix}.gff > virulence_vfdb.gff ;\n  fi\n\n  ### Victors\n  if [ ! \\$(cat $victors | wc -l) -le 1 ]\n  then \n    addBlast2Gff.R -i $victors -g ${prefix}.gff -o ${prefix}.gff -d Victors -t Virulence ;\n    grep \"Victors\" ${prefix}.gff > virulence_victors.gff ;\n  fi\n\n  ### KEGG Orthology\n  ## Reformat KOfamscan Output\n  if [ ! \\$(cat $kofamscan | wc -l) -eq 0 ]\n  then\n    awk \\\\\n      -F'\\\\t' \\\\\n      -v OFS='\\\\t' \\\\\n      '{x=\\$1;\\$1=\"\";a[x]=a[x]\\$0}END{for(x in a)print x,a[x]}' \\\\\n      $kofamscan  | \\\\\n    sed \\\\\n      -e 's/\\\\t/,/g' \\\\\n      -e 's/,,/\\\\t/g' | \\\\\n    awk  '\\$2!=\"\"' > formated.txt ;\n    addKO2Gff.R -i formated.txt -g ${prefix}.gff -o ${prefix}.gff -d KEGG ;\n  fi\n\n  ### ICEs\n  if [ ! \\$(cat $iceberg | wc -l) -le 1 ]\n  then\n    addBlast2Gff.R -i $iceberg -g ${prefix}.gff -o ${prefix}.gff -d ICEberg -t ICE ;\n    grep \"ICEberg\" ${prefix}.gff > ices_iceberg.gff ;\n  fi\n\n  ### Prophages\n  if [ ! \\$(cat $phast | wc -l) -le 1 ]\n  then\n    addBlast2Gff.R -i $phast -g ${prefix}.gff -o ${prefix}.gff -d PHAST -t Prophage ;\n    grep \"PHAST\" ${prefix}.gff > prophages_phast.gff ;\n  fi\n\n  ### Resistance\n  #### RGI\n  if [ ! \\$(cat $rgi | wc -l) -le 1 ]\n  then\n    addRGI2gff.R -g ${prefix}.gff -i $rgi -o ${prefix}.gff ;\n    grep \"CARD\" ${prefix}.gff > resistance_card.gff ;\n  fi\n\n  #### AMRFinderPlus\n  if [ ! \\$(cat $amrfinder | wc -l) -le 1 ]\n  then \n    addNCBIamr2Gff.R -g ${prefix}.gff -i $amrfinder -o ${prefix}.gff -t Resistance -d AMRFinderPlus ;\n    grep \"AMRFinderPlus\" ${prefix}.gff > resistance_amrfinderplus.gff ;\n  fi\n\n  #### Resfinder\n  if [ ! \\$(cat $resfinder | wc -l) -eq 0 ]\n  then\n    bedtools intersect -a $resfinder -b ${prefix}.gff -wo > resfinder_intersected.txt ;\n    addBedtoolsIntersect.R -g ${prefix}.gff -t resfinder_intersected.txt --type Resistance --source Resfinder -o ${prefix}.gff ;\n    grep \"Resfinder\" ${prefix}.gff > resistance_resfinder.gff ;\n    rm -f resfinder_intersected.txt ;\n  fi\n\n  #### Custom Blast databases\n  for file in ${custom_databases.join(\" \")} ;\n  do\n    if [ -s \\$file ]\n    then\n      db=\\${file%%_custom_db.gff} ;\n      bedtools intersect -a \\${file} -b ${prefix}.gff -wo > bedtools_intersected.txt ;\n      addBedtoolsIntersect.R -g ${prefix}.gff -t bedtools_intersected.txt --type \"CDS\" --source \"\\${db}\" -o ${prefix}.gff ;\n      grep \"\\${db}\" ${prefix}.gff > custom_database_\\${db}.gff ;\n      rm -f bedtools_intersected.txt ;\n    fi\n  done\n\n  ### digIS transposable elements\n  touch transposable_elements_digis.gff\n  if [ -s digis_gff ]\n  then\n    ( cat digis_gff | sed 's/id=/ID=/g' > transposable_elements_digis.gff && rm digis_gff ) ;\n    cat ${prefix}.gff transposable_elements_digis.gff | bedtools sort > tmp.out.gff ;\n    ( cat tmp.out.gff > ${prefix}.gff && rm tmp.out.gff );\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 109,
        "string_script": "  \"\"\"\n  # Rename gff and remove sequence entries\n  grep \"ID=\" prokka_gff > ${prefix}.gff ;\n\n  ## Increment GFF with custom annotations\n  ### VFDB\n  if [ ! \\$(cat $vfdb | wc -l) -le 1 ]\n  then\n    addBlast2Gff.R -i $vfdb -g ${prefix}.gff -o ${prefix}.gff -d VFDB -t Virulence ;\n    grep \"VFDB\" ${prefix}.gff > virulence_vfdb.gff ;\n  fi\n\n  ### Victors\n  if [ ! \\$(cat $victors | wc -l) -le 1 ]\n  then \n    addBlast2Gff.R -i $victors -g ${prefix}.gff -o ${prefix}.gff -d Victors -t Virulence ;\n    grep \"Victors\" ${prefix}.gff > virulence_victors.gff ;\n  fi\n\n  ### KEGG Orthology\n  ## Reformat KOfamscan Output\n  if [ ! \\$(cat $kofamscan | wc -l) -eq 0 ]\n  then\n    awk \\\\\n      -F'\\\\t' \\\\\n      -v OFS='\\\\t' \\\\\n      '{x=\\$1;\\$1=\"\";a[x]=a[x]\\$0}END{for(x in a)print x,a[x]}' \\\\\n      $kofamscan  | \\\\\n    sed \\\\\n      -e 's/\\\\t/,/g' \\\\\n      -e 's/,,/\\\\t/g' | \\\\\n    awk  '\\$2!=\"\"' > formated.txt ;\n    addKO2Gff.R -i formated.txt -g ${prefix}.gff -o ${prefix}.gff -d KEGG ;\n  fi\n\n  ### ICEs\n  if [ ! \\$(cat $iceberg | wc -l) -le 1 ]\n  then\n    addBlast2Gff.R -i $iceberg -g ${prefix}.gff -o ${prefix}.gff -d ICEberg -t ICE ;\n    grep \"ICEberg\" ${prefix}.gff > ices_iceberg.gff ;\n  fi\n\n  ### Prophages\n  if [ ! \\$(cat $phast | wc -l) -le 1 ]\n  then\n    addBlast2Gff.R -i $phast -g ${prefix}.gff -o ${prefix}.gff -d PHAST -t Prophage ;\n    grep \"PHAST\" ${prefix}.gff > prophages_phast.gff ;\n  fi\n\n  ### Resistance\n  #### RGI\n  if [ ! \\$(cat $rgi | wc -l) -le 1 ]\n  then\n    addRGI2gff.R -g ${prefix}.gff -i $rgi -o ${prefix}.gff ;\n    grep \"CARD\" ${prefix}.gff > resistance_card.gff ;\n  fi\n\n  #### AMRFinderPlus\n  if [ ! \\$(cat $amrfinder | wc -l) -le 1 ]\n  then \n    addNCBIamr2Gff.R -g ${prefix}.gff -i $amrfinder -o ${prefix}.gff -t Resistance -d AMRFinderPlus ;\n    grep \"AMRFinderPlus\" ${prefix}.gff > resistance_amrfinderplus.gff ;\n  fi\n\n  #### Resfinder\n  if [ ! \\$(cat $resfinder | wc -l) -eq 0 ]\n  then\n    bedtools intersect -a $resfinder -b ${prefix}.gff -wo > resfinder_intersected.txt ;\n    addBedtoolsIntersect.R -g ${prefix}.gff -t resfinder_intersected.txt --type Resistance --source Resfinder -o ${prefix}.gff ;\n    grep \"Resfinder\" ${prefix}.gff > resistance_resfinder.gff ;\n    rm -f resfinder_intersected.txt ;\n  fi\n\n  #### Custom Blast databases\n  for file in ${custom_databases.join(\" \")} ;\n  do\n    if [ -s \\$file ]\n    then\n      db=\\${file%%_custom_db.gff} ;\n      bedtools intersect -a \\${file} -b ${prefix}.gff -wo > bedtools_intersected.txt ;\n      addBedtoolsIntersect.R -g ${prefix}.gff -t bedtools_intersected.txt --type \"CDS\" --source \"\\${db}\" -o ${prefix}.gff ;\n      grep \"\\${db}\" ${prefix}.gff > custom_database_\\${db}.gff ;\n      rm -f bedtools_intersected.txt ;\n    fi\n  done\n\n  ### digIS transposable elements\n  touch transposable_elements_digis.gff\n  if [ -s digis_gff ]\n  then\n    ( cat digis_gff | sed 's/id=/ID=/g' > transposable_elements_digis.gff && rm digis_gff ) ;\n    cat ${prefix}.gff transposable_elements_digis.gff | bedtools sort > tmp.out.gff ;\n    ( cat tmp.out.gff > ${prefix}.gff && rm tmp.out.gff );\n  fi\n  \"\"\"",
        "nb_lignes_script": 94,
        "language_script": "bash",
        "tools": [
            "BEDTools"
        ],
        "tools_url": [
            "https://bio.tools/bedtools"
        ],
        "tools_dico": [
            {
                "name": "BEDTools",
                "uri": "https://bio.tools/bedtools",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0622",
                            "term": "Genomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "BEDTools is an extensive suite of utilities for comparing genomic features in BED format.",
                "homepage": "https://github.com/arq5x/bedtools2"
            }
        ],
        "inputs": [
            "prefix",
            "kofamscan",
            "vfdb",
            "victors",
            "amrfinder",
            "resfinder",
            "rgi",
            "iceberg",
            "phast",
            "custom_databases"
        ],
        "nb_inputs": 10,
        "outputs": [
            "prefix",
            "prefix",
            "prefix"
        ],
        "nb_outputs": 3,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/gffs\", mode: 'copy'",
            "label = [ 'renv', 'process_medium', 'error_retry' ]",
            "tag \"${prefix}\""
        ],
        "when": "",
        "stub": ""
    },
    "JBROWSE": {
        "name_process": "JBROWSE",
        "string_process": "process JBROWSE {\n  publishDir \"${params.output}/${prefix}/jbrowse\", mode: 'copy'\n  label = [ 'jbrowse', 'process_low' ]\n  tag \"${prefix}\"\n\n  input:\n  tuple val(prefix), file(merged_gff), file(draft), file(\"prokka_gff\"), file(barrnap), file(gc_bedGraph), file(gc_chrSizes), file(resfinder_gff), file(phigaro), file(genomic_islands), file(\"methylation\"), file(\"chr.sizes\"), file(phispy_tsv), file(digIS_gff), file(antiSMASH), file(custom_annotations)\n\n  output:\n  file \"*\"\n\n  script:\n  \"\"\"\n  # Get JBrowse Files in working directory\n  cp -R /work/jbrowse/* . ;\n\n  # Render genome browser\n  run_jbrowse.sh \\\\\n    -p $prefix \\\\\n    -g $draft \\\\\n    -b $gc_bedGraph \\\\\n    -s $gc_chrSizes \\\\\n    -f $merged_gff \\\\\n    -r $barrnap \\\\\n    -B $phigaro \\\\\n    -P $phispy_tsv \\\\\n    -G $genomic_islands \\\\\n    -m methylation \\\\\n    -S chr.sizes \\\\\n    -R $resfinder_gff \\\\\n    -d $digIS_gff \\\\\n    -A $antiSMASH\n  \"\"\"\n}",
        "nb_lignes_process": 32,
        "string_script": "  \"\"\"\n  # Get JBrowse Files in working directory\n  cp -R /work/jbrowse/* . ;\n\n  # Render genome browser\n  run_jbrowse.sh \\\\\n    -p $prefix \\\\\n    -g $draft \\\\\n    -b $gc_bedGraph \\\\\n    -s $gc_chrSizes \\\\\n    -f $merged_gff \\\\\n    -r $barrnap \\\\\n    -B $phigaro \\\\\n    -P $phispy_tsv \\\\\n    -G $genomic_islands \\\\\n    -m methylation \\\\\n    -S chr.sizes \\\\\n    -R $resfinder_gff \\\\\n    -d $digIS_gff \\\\\n    -A $antiSMASH\n  \"\"\"",
        "nb_lignes_script": 20,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "merged_gff",
            "draft",
            "barrnap",
            "gc_bedGraph",
            "gc_chrSizes",
            "resfinder_gff",
            "phigaro",
            "genomic_islands",
            "phispy_tsv",
            "digIS_gff",
            "antiSMASH",
            "custom_annotations"
        ],
        "nb_inputs": 13,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/jbrowse\", mode: 'copy'",
            "label = [ 'jbrowse', 'process_low' ]",
            "tag \"${prefix}\""
        ],
        "when": "",
        "stub": ""
    },
    "ANTISMASH": {
        "name_process": "ANTISMASH",
        "string_process": "process ANTISMASH {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else \"$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_medium' ]\n\n  input:\n  tuple val(prefix), file(genbank)\n  file(bacannot_db)\n\n  output:\n                 \n  tuple val(prefix), path(\"antiSMASH/regions.gff\")\n  path(\"antiSMASH\")\n  path(\"*_version.txt\")\n\n  script:\n  \"\"\"\n  # Activate env\n  export PATH=/opt/conda/envs/antismash/bin:\\$PATH\n  \n  # Get tool version\n  antismash --version > antismash_version.txt ;\n\n  # Run tool\n  antismash \\\\\n    --output-dir antiSMASH \\\\\n    --genefinding-tool none \\\\\n    -c $task.cpus \\\\\n    --databases ${bacannot_db}/antismash_db \\\\\n    $genbank ;\n\n  # enter results dir\n  cd antiSMASH ;\n\n  # produce gff from main results\n  genbank=\"${genbank}\"\n  seqret \\\\\n    -sequence \\${genbank} \\\\\n    -feature \\\\\n    -fformat genbank \\\\\n    -fopenfile \\${genbank} \\\\\n    -osformat gff \\\\\n    -osname_outseq \\${genbank%%.gbk} \\\\\n    -auto ;\n\n  # get the locus tags annotated as list\n  grep \\\\\n    \"locus_tag\" \\\\\n    *region*gbk | \\\\\n    cut \\\\\n    -f 2 \\\\\n    -d \"=\" | \\\\\n    tr -d '\"' | \\\\\n    sort -u > gene_ids.lst ;\n\n  # subset regions GFF from main GFF for JBrowse\n  grep \\\\\n    -w \\\\\n    -f gene_ids.lst \\\\\n    \\${genbank%%.gbk}.gff > regions.gff ;\n  \"\"\"\n}",
        "nb_lignes_process": 63,
        "string_script": "  \"\"\"\n  # Activate env\n  export PATH=/opt/conda/envs/antismash/bin:\\$PATH\n  \n  # Get tool version\n  antismash --version > antismash_version.txt ;\n\n  # Run tool\n  antismash \\\\\n    --output-dir antiSMASH \\\\\n    --genefinding-tool none \\\\\n    -c $task.cpus \\\\\n    --databases ${bacannot_db}/antismash_db \\\\\n    $genbank ;\n\n  # enter results dir\n  cd antiSMASH ;\n\n  # produce gff from main results\n  genbank=\"${genbank}\"\n  seqret \\\\\n    -sequence \\${genbank} \\\\\n    -feature \\\\\n    -fformat genbank \\\\\n    -fopenfile \\${genbank} \\\\\n    -osformat gff \\\\\n    -osname_outseq \\${genbank%%.gbk} \\\\\n    -auto ;\n\n  # get the locus tags annotated as list\n  grep \\\\\n    \"locus_tag\" \\\\\n    *region*gbk | \\\\\n    cut \\\\\n    -f 2 \\\\\n    -d \"=\" | \\\\\n    tr -d '\"' | \\\\\n    sort -u > gene_ids.lst ;\n\n  # subset regions GFF from main GFF for JBrowse\n  grep \\\\\n    -w \\\\\n    -f gene_ids.lst \\\\\n    \\${genbank%%.gbk}.gff > regions.gff ;\n  \"\"\"",
        "nb_lignes_script": 44,
        "language_script": "bash",
        "tools": [
            "antiSMASH",
            "seqret"
        ],
        "tools_url": [
            "https://bio.tools/antismash",
            "https://bio.tools/seqret"
        ],
        "tools_dico": [
            {
                "name": "antiSMASH",
                "uri": "https://bio.tools/antismash",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Gene and protein families"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0623",
                            "term": "Genes, gene family or system"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence clustering"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3223",
                                    "term": "Differential gene expression profiling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster construction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0291",
                                    "term": "Sequence cluster generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3223",
                                    "term": "Differential gene analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3223",
                                    "term": "Differentially expressed gene identification"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3223",
                                    "term": "Differential expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3223",
                                    "term": "Differential gene expression analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene finding"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2454",
                                    "term": "Gene calling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Rapid genome-wide identification, annotation and analysis of secondary metabolite biosynthesis gene clusters in bacterial and fungal genomes. It integrates and cross-links with a large number of in silico secondary metabolite analysis tools that have been published earlier.",
                "homepage": "http://antismash.secondarymetabolites.org"
            },
            {
                "name": "seqret",
                "uri": "https://bio.tools/seqret",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data retrieval"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3096",
                                    "term": "Editing"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Data extraction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2422",
                                    "term": "Retrieval"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_0849",
                                "term": "Sequence record"
                            }
                        ]
                    }
                ],
                "description": "Read and write (return) sequences.",
                "homepage": "http://emboss.open-bio.org/rel/rel6/apps/seqret.html"
            }
        ],
        "inputs": [
            "prefix",
            "genbank",
            "bacannot_db"
        ],
        "nb_inputs": 3,
        "outputs": [
            "prefix"
        ],
        "nb_outputs": 1,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "KEGG_DECODER": {
        "name_process": "KEGG_DECODER",
        "string_process": "process KEGG_DECODER {\n  publishDir \"${params.output}/${prefix}/KOfamscan\", mode: 'copy'\n  tag \"${prefix}\"\n  label = [ 'misc', 'process_low' ]\n\n  input:\n  tuple val(prefix), path('input_mapper.txt')\n\n  output:\n                     \n  path(\"*\")                                    \n  tuple val(prefix), path(\"*.svg\")           \n\n  script:\n  \"\"\"\n  # Activate env\n  export PATH=/opt/conda/envs/KEGGDecoder/bin:\\$PATH\n\n  # draw static heatmap\n  KEGG-decoder \\\\\n      --input input_mapper.txt \\\\\n      --output ${prefix}_kegg-decoder_heatmap_static.tsv \\\\\n      --vizoption static ;\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "  \"\"\"\n  # Activate env\n  export PATH=/opt/conda/envs/KEGGDecoder/bin:\\$PATH\n\n  # draw static heatmap\n  KEGG-decoder \\\\\n      --input input_mapper.txt \\\\\n      --output ${prefix}_kegg-decoder_heatmap_static.tsv \\\\\n      --vizoption static ;\n  \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix"
        ],
        "nb_inputs": 1,
        "outputs": [
            "prefix"
        ],
        "nb_outputs": 1,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}/KOfamscan\", mode: 'copy'",
            "tag \"${prefix}\"",
            "label = [ 'misc', 'process_low' ]"
        ],
        "when": "",
        "stub": ""
    },
    "PHIGARO": {
        "name_process": "PHIGARO",
        "string_process": "process PHIGARO {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename == \"out.phg\") null\n    else if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else \"prophages/phigaro/$filename\"\n  }\n  tag \"${prefix}\"\n  label = [ 'python', 'process_medium' ]\n\n  input:\n  tuple val(prefix), file(\"assembly.fasta\")\n  file(bacannot_db)\n\n  output:\n                                                \n  tuple val(prefix), path(\"${prefix}_phigaro.tsv\")\n  tuple val(prefix), path(\"${prefix}_phigaro.bed\")\n  tuple val(prefix), path(\"${prefix}_phigaro.html\") optional true\n  path('phigaro_version.txt')\n\n  script:\n  \"\"\"\n  # activate env\n  source activate phigaro\n  \n  # get tool version\n  phigaro -V > phigaro_version.txt ;\n\n  # create new config to properly load database\n  cp \\$(which config.yml) ./custom_config.yml ;\n  sed -i \"s|CHANGE_PVOG|${bacannot_db}/phigaro_db/allpvoghmms|\" ./custom_config.yml ;\n  HMM_BIN=\\$(which hmmsearch) ;\n  sed -i \"s|CHANGE_HMMSEARCH|\\$HMM_BIN|\" ./custom_config.yml ;\n  PRODIGAL_BIN=\\$(which prodigal) ;\n  sed -i \"s|CHANGE_PRODIGAL|\\$PRODIGAL_BIN|\" ./custom_config.yml ;\n\n  # run phigaro\n  phigaro \\\\\n      -f assembly.fasta \\\\\n      --config ./custom_config.yml \\\\\n      -t $task.cpus \\\\\n      -e html tsv \\\\\n      -o out.phg \\\\\n      --delete-shorts \\\\\n      -p \\\\\n      --not-open ;\n\n  # change names\n  [ ! -s out.phg/assembly.phigaro.tsv  ] || mv out.phg/assembly.phigaro.tsv ${prefix}_phigaro.tsv ;\n  [ ! -s out.phg/assembly.phigaro.html ] || mv out.phg/assembly.phigaro.html ${prefix}_phigaro.html ;\n\n  # create BED\n  grep -v \"taxonomy\" ${prefix}_phigaro.tsv | \\\n  awk 'BEGIN { FS = \"\\t\"; OFS=\"\\\\t\" } { print \\$1,\\$2,\\$3 }' > ${prefix}_phigaro.bed\n  \"\"\"\n}",
        "nb_lignes_process": 54,
        "string_script": "  \"\"\"\n  # activate env\n  source activate phigaro\n  \n  # get tool version\n  phigaro -V > phigaro_version.txt ;\n\n  # create new config to properly load database\n  cp \\$(which config.yml) ./custom_config.yml ;\n  sed -i \"s|CHANGE_PVOG|${bacannot_db}/phigaro_db/allpvoghmms|\" ./custom_config.yml ;\n  HMM_BIN=\\$(which hmmsearch) ;\n  sed -i \"s|CHANGE_HMMSEARCH|\\$HMM_BIN|\" ./custom_config.yml ;\n  PRODIGAL_BIN=\\$(which prodigal) ;\n  sed -i \"s|CHANGE_PRODIGAL|\\$PRODIGAL_BIN|\" ./custom_config.yml ;\n\n  # run phigaro\n  phigaro \\\\\n      -f assembly.fasta \\\\\n      --config ./custom_config.yml \\\\\n      -t $task.cpus \\\\\n      -e html tsv \\\\\n      -o out.phg \\\\\n      --delete-shorts \\\\\n      -p \\\\\n      --not-open ;\n\n  # change names\n  [ ! -s out.phg/assembly.phigaro.tsv  ] || mv out.phg/assembly.phigaro.tsv ${prefix}_phigaro.tsv ;\n  [ ! -s out.phg/assembly.phigaro.html ] || mv out.phg/assembly.phigaro.html ${prefix}_phigaro.html ;\n\n  # create BED\n  grep -v \"taxonomy\" ${prefix}_phigaro.tsv | \\\n  awk 'BEGIN { FS = \"\\t\"; OFS=\"\\\\t\" } { print \\$1,\\$2,\\$3 }' > ${prefix}_phigaro.bed\n  \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [
            "Phigaro"
        ],
        "tools_url": [
            "https://bio.tools/phigaro"
        ],
        "tools_dico": [
            {
                "name": "Phigaro",
                "uri": "https://bio.tools/phigaro",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0160",
                            "term": "Sequence sites, features and motifs"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0798",
                            "term": "Mobile genetic elements"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0362",
                                    "term": "Genome annotation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2429",
                                    "term": "Cartography"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Phigaro is a high-throughput prophage sequence annotation.\n\nPhigaro is a standalone command-line application that is able to detect prophage regions taking raw genome and metagenome assemblies as an input. It also produces dynamic annotated \u201cprophage genome maps\u201d and marks possible transposon insertion spots inside prophages. It is applicable for mining prophage regions from large metagenomic datasets.",
                "homepage": "https://github.com/bobeobibo/phigaro"
            }
        ],
        "inputs": [
            "prefix",
            "bacannot_db"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prefix",
            "prefix",
            "prefix"
        ],
        "nb_outputs": 3,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename == \"out.phg\") null else if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else \"prophages/phigaro/$filename\" }",
            "tag \"${prefix}\"",
            "label = [ 'python', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "PHISPY": {
        "name_process": "PHISPY",
        "string_process": "process PHISPY {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else if (filename == \"PhiSpy\") \"prophages/$filename\"\n    else null\n  }\n  tag \"${prefix}\"\n  label = [ 'python', 'process_medium' ]\n\n  input:\n  tuple val(prefix), file(input)\n\n  output:\n  tuple val(prefix), path(\"PhiSpy\")\n  tuple val(prefix), path(\"PhiSpy/prophage.tsv\")\n  tuple val(prefix), path(\"phispy_version.txt\")\n\n  script:\n  \"\"\"\n  # get tool version\n  PhiSpy.py -v > phispy_version.txt ;\n\n  # run phispy\n  PhiSpy.py \\\\\n      -o PhiSpy \\\\\n      $input \\\\\n      --color \\\\\n      --output_choice 127 \\\\\n      --threads $task.cpus\n  \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "  \"\"\"\n  # get tool version\n  PhiSpy.py -v > phispy_version.txt ;\n\n  # run phispy\n  PhiSpy.py \\\\\n      -o PhiSpy \\\\\n      $input \\\\\n      --color \\\\\n      --output_choice 127 \\\\\n      --threads $task.cpus\n  \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "prefix",
            "input"
        ],
        "nb_inputs": 2,
        "outputs": [
            "prefix",
            "prefix",
            "prefix"
        ],
        "nb_outputs": 3,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else if (filename == \"PhiSpy\") \"prophages/$filename\" else null }",
            "tag \"${prefix}\"",
            "label = [ 'python', 'process_medium' ]"
        ],
        "when": "",
        "stub": ""
    },
    "FLYE": {
        "name_process": "FLYE",
        "string_process": "process FLYE {\n  publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename ->\n    if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\"\n    else if (filename == \"flye_${prefix}\") \"assembly\"\n    else null\n  }\n  label 'process_high'\n  tag \"${prefix}\"\n\n  input:\n  tuple val(prefix), val(entrypoint), file(sread1), file(sread2), file(sreads), file(lreads), val(lr_type), file(fast5), val(assembly), val(resfinder_species)\n\n  output:\n  file \"flye_${prefix}\"                   \n                                            \n  tuple val(\"${prefix}\"), val(\"${entrypoint}\"), val(\"${sread1}\"), val(\"${sread2}\"), val(\"${sreads}\"), file(\"${lreads}\"), val(\"${lr_type}\"), file(\"${fast5}\"), file(\"flye_${prefix}.fasta\"), val(\"${resfinder_species}\")\n  file('flye_version.txt')\n\n  script:\n  lr = (lr_type == 'nanopore') ? '--nano-raw' : '--pacbio-raw'\n  \"\"\"\n  # Save flye version\n  flye -v > flye_version.txt ;\n\n  # Run flye\n  flye \\\\\n    ${lr} \\\\\n    $lreads \\\\\n    --out-dir flye_${prefix} \\\\\n    --threads $task.cpus &> flye.log ;\n\n  # Save a copy for annotation\n  cp flye_${prefix}/assembly.fasta flye_${prefix}.fasta\n  \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "  lr = (lr_type == 'nanopore') ? '--nano-raw' : '--pacbio-raw'\n  \"\"\"\n  # Save flye version\n  flye -v > flye_version.txt ;\n\n  # Run flye\n  flye \\\\\n    ${lr} \\\\\n    $lreads \\\\\n    --out-dir flye_${prefix} \\\\\n    --threads $task.cpus &> flye.log ;\n\n  # Save a copy for annotation\n  cp flye_${prefix}/assembly.fasta flye_${prefix}.fasta\n  \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [
            "LRC",
            "Flye"
        ],
        "tools_url": [
            "https://bio.tools/lrc",
            "https://bio.tools/Flye"
        ],
        "tools_dico": [
            {
                "name": "LRC",
                "uri": "https://bio.tools/lrc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2830",
                            "term": "Immunoproteins and antigens"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2229",
                            "term": "Cell biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0804",
                            "term": "Immunology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2814",
                            "term": "Protein structure analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_2814",
                            "term": "Protein structure"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0477",
                                    "term": "Protein modelling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2480",
                                    "term": "Structure analysis"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0477",
                                    "term": "Homology modelling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0477",
                                    "term": "Comparative modelling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0477",
                                    "term": "Protein structure comparative modelling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0477",
                                    "term": "Homology structure modelling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "A computational method based on a combination of physicochemical and structural properties to predict the B-cell epitopes.",
                "homepage": "http://bs.ipm.ir/softwares/LRC/"
            },
            {
                "name": "Flye",
                "uri": "https://bio.tools/Flye",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0196",
                            "term": "Sequence assembly"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Whole genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "Genome sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3673",
                            "term": "WGS"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Mapping assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De-novo assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genome assembly"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0523",
                                    "term": "Sequence assembly (mapping assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "De Bruijn graph"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0524",
                                    "term": "Sequence assembly (de-novo assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Sequence assembly (genome assembly)"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0525",
                                    "term": "Genomic assembly"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Flye is a de novo assembler for single molecule sequencing reads, such as those produced by PacBio and Oxford Nanopore Technologies. It is designed for a wide range of datasets, from small bacterial projects to large mammalian-scale assemblies. The package represents a complete pipeline: it takes raw PB / ONT reads as input and outputs polished contigs.",
                "homepage": "https://github.com/fenderglass/Flye"
            }
        ],
        "inputs": [
            "prefix",
            "entrypoint",
            "lr_type",
            "assembly",
            "resfinder_species",
            "sread1",
            "sread2",
            "sreads",
            "lreads",
            "fast5"
        ],
        "nb_inputs": 10,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "fmalmeida__bacannot",
        "directive": [
            "publishDir \"${params.output}/${prefix}\", mode: 'copy', saveAs: { filename -> if (filename.indexOf(\"_version.txt\") > 0) \"tools_versioning/$filename\" else if (filename == \"flye_${prefix}\") \"assembly\" else null }",
            "label 'process_high'",
            "tag \"${prefix}\""
        ],
        "when": "",
        "stub": ""
    }
}