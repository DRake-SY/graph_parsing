{
    "bamMergeSortMarkdup": {
        "name_process": "bamMergeSortMarkdup",
        "string_process": "\nprocess bamMergeSortMarkdup {\n  container \"${container[params.container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\",\n    mode: \"copy\",\n    enabled: \"${params.publish_dir ? true : ''}\"\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n\n  input:\n    path aligned_lane_bams\n    path ref_genome_gz\n    path ref_genome_gz_secondary_file\n    path tempdir\n\n  output:\n    path \"${params.aligned_basename}.{bam,cram}\", emit: merged_seq\n    path \"${params.aligned_basename}.{bam.bai,cram.crai}\", emit: merged_seq_idx\n    path \"${params.aligned_basename}.duplicates_metrics.tgz\", optional: true, emit: duplicates_metrics\n\n  script:\n    arg_markdup = params.markdup ? \"-d\" : \"\"\n    arg_lossy = params.lossy ? \"-l\" : \"\"\n    arg_tempdir = tempdir.name != 'NO_DIR' ? \"-t ${tempdir}\" : \"\"\n    \"\"\"\n    bam-merge-sort-markdup.py \\\n      -i ${aligned_lane_bams} \\\n      -r ${ref_genome_gz} \\\n      -n ${params.cpus} \\\n      -b ${params.aligned_basename} ${arg_markdup} \\\n      -o ${params.output_format} ${arg_lossy} ${arg_tempdir}\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    arg_markdup = params.markdup ? \"-d\" : \"\"\n    arg_lossy = params.lossy ? \"-l\" : \"\"\n    arg_tempdir = tempdir.name != 'NO_DIR' ? \"-t ${tempdir}\" : \"\"\n    \"\"\"\n    bam-merge-sort-markdup.py \\\n      -i ${aligned_lane_bams} \\\n      -r ${ref_genome_gz} \\\n      -n ${params.cpus} \\\n      -b ${params.aligned_basename} ${arg_markdup} \\\n      -o ${params.output_format} ${arg_lossy} ${arg_tempdir}\n    \"\"\"",
        "nb_lignes_script": 10,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "aligned_lane_bams",
            "ref_genome_gz",
            "ref_genome_gz_secondary_file",
            "tempdir"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo__demo-wfpkgs",
        "directive": [
            "container \"${container[params.container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\" , mode: \"copy\" , enabled: \"${params.publish_dir ? true : ''}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "alignedSeqQC": {
        "name_process": "alignedSeqQC",
        "string_process": "\nprocess alignedSeqQC {\n  container \"${container[params.container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\",\n    mode: \"copy\",\n    enabled: \"${params.publish_dir ? true : ''}\"\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path seq\n    path ref_genome_gz\n    path ref_genome_gz_secondary_file\n    val dependencies\n\n  output:\n    path \"*.qc_metrics.tgz\", emit: metrics\n\n  script:\n    \"\"\"\n    aligned-seq-qc.py -s ${seq} \\\n                      -r ${ref_genome_gz} \\\n                      -n ${params.cpus}\n    \"\"\"\n}",
        "nb_lignes_process": 24,
        "string_script": "    \"\"\"\n    aligned-seq-qc.py -s ${seq} \\\n                      -r ${ref_genome_gz} \\\n                      -n ${params.cpus}\n    \"\"\"",
        "nb_lignes_script": 4,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "seq",
            "ref_genome_gz",
            "ref_genome_gz_secondary_file",
            "dependencies"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo__demo-wfpkgs",
        "directive": [
            "container \"${container[params.container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\" , mode: \"copy\" , enabled: \"${params.publish_dir ? true : ''}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "bwaMemAligner": {
        "name_process": "bwaMemAligner",
        "string_process": "\nprocess bwaMemAligner {\n  container \"${container[params.container_registry]}:${params.container_version ?: version}\"\n  publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: \"${params.publish_dir ? true : ''}\"\n\n  cpus params.cpus\n  memory \"${params.mem} GB\"\n\n  input:\n    path input_bam\n    path ref_genome_gz\n    path ref_genome_gz_secondary_files\n    path sequencing_experiment_analysis\n    path tempdir\n    val dependencies\n\n  output:\n    path \"${params.aligned_lane_prefix}.${input_bam.baseName}.bam\", emit: aligned_bam\n\n  script:\n    metadata = sequencing_experiment_analysis ? \"-m \" + sequencing_experiment_analysis : \"\"\n    arg_tempdir = tempdir.name != 'NO_DIR' ? \"-t ${tempdir}\": \"\"\n    \"\"\"\n    bwa-mem-aligner.py \\\n      -i ${input_bam} \\\n      -r ${ref_genome_gz} \\\n      -o ${params.aligned_lane_prefix} \\\n      -n ${task.cpus} ${metadata} ${arg_tempdir}\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    metadata = sequencing_experiment_analysis ? \"-m \" + sequencing_experiment_analysis : \"\"\n    arg_tempdir = tempdir.name != 'NO_DIR' ? \"-t ${tempdir}\": \"\"\n    \"\"\"\n    bwa-mem-aligner.py \\\n      -i ${input_bam} \\\n      -r ${ref_genome_gz} \\\n      -o ${params.aligned_lane_prefix} \\\n      -n ${task.cpus} ${metadata} ${arg_tempdir}\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "input_bam",
            "ref_genome_gz",
            "ref_genome_gz_secondary_files",
            "sequencing_experiment_analysis",
            "tempdir",
            "dependencies"
        ],
        "nb_inputs": 6,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo__demo-wfpkgs",
        "directive": [
            "container \"${container[params.container_registry]}:${params.container_version ?: version}\"",
            "publishDir \"${params.publish_dir}/${task.process.replaceAll(':', '_')}\", mode: \"copy\", enabled: \"${params.publish_dir ? true : ''}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "generateDummyFile": {
        "name_process": "generateDummyFile",
        "string_process": "\nprocess generateDummyFile {\n    input:\n        val file_name\n        val file_size\n\n    output:\n        path \"*\", emit: file\n\n    script:\n        file_name_arg = file_name instanceof List ? file_name.join(\".\") : file_name\n        \"\"\"\n        dd if=/dev/urandom of=\"${file_name_arg}\" bs=1 count=${file_size}\n        \"\"\"\n}",
        "nb_lignes_process": 13,
        "string_script": "        file_name_arg = file_name instanceof List ? file_name.join(\".\") : file_name\n        \"\"\"\n        dd if=/dev/urandom of=\"${file_name_arg}\" bs=1 count=${file_size}\n        \"\"\"",
        "nb_lignes_script": 3,
        "language_script": "bash",
        "tools": [
            "NDD"
        ],
        "tools_url": [
            "https://bio.tools/NDD"
        ],
        "tools_dico": [
            {
                "name": "NDD",
                "uri": "https://bio.tools/NDD",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3439",
                                    "term": "Pathway or network prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Drug-Drug Interaction Predicting by Neural Network Using Integrated Similarity | Link of paper: https://www.nature.com/articles/s41598-019-50121-3 A Novel Method For Predicting Drug-Drug Interaction By Neural Network Due to the great importance of this issue in the economy, industry, and health, proposing appropriate computational methods for predicting unknown DDI with high precision is challenging. We propose a novel machine learning method for predicting unknown DDIs called \"NDD\", using a two-layer fully connected neural network. NDD uses various characteristics of drugs to have comprehensive information. Multiple drug similarities are calculated. NDD integrat various drug similarities with a non-linear similarity fusion method called \"SNF\" to achieve high-level features. Dependency: python version 3.5.3 deep learning lib keras: https://github.com/fchollet/keras/ machine learning lib scikit-learn: https://github.com/scikit-learn/scikit-learn Contact: nasim.rohani74@gmail.com",
                "homepage": "https://github.com/nrohani/NDD"
            }
        ],
        "inputs": [
            "file_name",
            "file_size"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo__demo-wfpkgs",
        "directive": [],
        "when": "",
        "stub": ""
    },
    "cleanupWorkdir": {
        "name_process": "cleanupWorkdir",
        "string_process": "\nprocess cleanupWorkdir {\n    container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"\n    cpus params.cpus\n    memory \"${params.mem} GB\"\n\n    input:\n        path files_to_delete                                                                                       \n        val virtual_dep_flag                                                                                               \n\n    output:\n        stdout\n\n    script:\n        \"\"\"\n        set -euxo pipefail\n\n        IFS=\" \"\n        read -a files <<< \"${files_to_delete}\"\n        for f in \"\\${files[@]}\"\n        do\n            dir_to_rm=\\$(dirname \\$(readlink -f \\$f))\n\n            if [[ \\$dir_to_rm != ${workflow.workDir}/* ]]; then  # skip dir not under workdir, like from input file dir\n                echo \"Not delete: \\$dir_to_rm/*\\\"\n                continue\n            fi\n\n            rm -fr \\$dir_to_rm/*  # delete all files and subdirs but not hidden ones\n            echo \"Deleted: \\$dir_to_rm/*\"\n        done\n        \"\"\"\n}",
        "nb_lignes_process": 31,
        "string_script": "        \"\"\"\n        set -euxo pipefail\n\n        IFS=\" \"\n        read -a files <<< \"${files_to_delete}\"\n        for f in \"\\${files[@]}\"\n        do\n            dir_to_rm=\\$(dirname \\$(readlink -f \\$f))\n\n            if [[ \\$dir_to_rm != ${workflow.workDir}/* ]]; then  # skip dir not under workdir, like from input file dir\n                echo \"Not delete: \\$dir_to_rm/*\\\"\n                continue\n            fi\n\n            rm -fr \\$dir_to_rm/*  # delete all files and subdirs but not hidden ones\n            echo \"Deleted: \\$dir_to_rm/*\"\n        done\n        \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "files_to_delete",
            "virtual_dep_flag"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo__demo-wfpkgs",
        "directive": [
            "container \"${params.container ?: container[params.container_registry ?: default_container_registry]}:${params.container_version ?: version}\"",
            "cpus params.cpus",
            "memory \"${params.mem} GB\""
        ],
        "when": "",
        "stub": ""
    },
    "filesExist": {
        "name_process": "filesExist",
        "string_process": "\nprocess filesExist {\n    input:\n        val file_names                                    \n        val expect                                                                                  \n        path files\n        val dependency_flag                                                                          \n\n    script:\n        file_name_arg = file_names instanceof List ? file_names.join(\" \") : file_names\n        \"\"\"\n        if [[ \"${expect}\" = \"exist\"  ]]; then\n            for f in \\$(echo \"${file_name_arg}\"); do\n                if [[ ! -f \\$f ]]; then\n                    exit \"Expected \\$f not exists.\"\n                fi\n            done\n        elif [[ \"${expect}\" = \"not_exist\"  ]]; then\n            for f in \\$(echo \"${file_name_arg}\"); do\n                if [[ -f \\$f ]]; then\n                    exit \"Unexpected \\$f exists.\"\n                fi\n            done\n        else\n            exit \"Second argument must be either 'exist' or 'not_exist'. '${expect}' is supplied.\"\n        fi\n        \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "        file_name_arg = file_names instanceof List ? file_names.join(\" \") : file_names\n        \"\"\"\n        if [[ \"${expect}\" = \"exist\"  ]]; then\n            for f in \\$(echo \"${file_name_arg}\"); do\n                if [[ ! -f \\$f ]]; then\n                    exit \"Expected \\$f not exists.\"\n                fi\n            done\n        elif [[ \"${expect}\" = \"not_exist\"  ]]; then\n            for f in \\$(echo \"${file_name_arg}\"); do\n                if [[ -f \\$f ]]; then\n                    exit \"Unexpected \\$f exists.\"\n                fi\n            done\n        else\n            exit \"Second argument must be either 'exist' or 'not_exist'. '${expect}' is supplied.\"\n        fi\n        \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "file_names",
            "expect",
            "files",
            "dependency_flag"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "icgc-argo__demo-wfpkgs",
        "directive": [],
        "when": "",
        "stub": ""
    }
}