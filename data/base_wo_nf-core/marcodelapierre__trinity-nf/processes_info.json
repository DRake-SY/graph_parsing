{
    "overlay_one": {
        "name_process": "overlay_one",
        "string_process": "\nprocess overlay_one {\n  tag \"${dir}/${name}\"\n  storeDir \"${dir}/${params.overoutdirprefix}${name}\"\n\n  container ''\n\n  input:\n  tuple val(dir), val(name), path(read1), path(read2)\n\n  output:\n  tuple val(dir), val(name), path(\"${params.overfileprefix}one\")\n\n  script:\n  \"\"\"\n  singularity exec docker://ubuntu:18.04 bash -c ' \\\n  out_file=\\\"${params.overfileprefix}one\\\" && \\\n  mkdir -p overlay_tmp/upper overlay_tmp/work && \\\n  dd if=/dev/zero of=\\${out_file} count=${params.overlay_size_mb_one} bs=1M && \\\n  mkfs.ext3 -d overlay_tmp \\${out_file} && \\\n  rm -rf overlay_tmp \\\n  '\n  \"\"\"\n}",
        "nb_lignes_process": 22,
        "string_script": "  \"\"\"\n  singularity exec docker://ubuntu:18.04 bash -c ' \\\n  out_file=\\\"${params.overfileprefix}one\\\" && \\\n  mkdir -p overlay_tmp/upper overlay_tmp/work && \\\n  dd if=/dev/zero of=\\${out_file} count=${params.overlay_size_mb_one} bs=1M && \\\n  mkfs.ext3 -d overlay_tmp \\${out_file} && \\\n  rm -rf overlay_tmp \\\n  '\n  \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "Singularity Hub",
            "NDD"
        ],
        "tools_url": [
            "https://bio.tools/singularity_hub",
            "https://bio.tools/NDD"
        ],
        "tools_dico": [
            {
                "name": "Singularity Hub",
                "uri": "https://bio.tools/singularity_hub",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3524",
                            "term": "Simulation experiment"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Framework to build and deploy Singularity containers for mobility of compute, and the singularity-python software with novel metrics for assessing reproducibility of such containers.",
                "homepage": "https://singularity-hub.org/"
            },
            {
                "name": "NDD",
                "uri": "https://bio.tools/NDD",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3439",
                                    "term": "Pathway or network prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Drug-Drug Interaction Predicting by Neural Network Using Integrated Similarity | Link of paper: https://www.nature.com/articles/s41598-019-50121-3 A Novel Method For Predicting Drug-Drug Interaction By Neural Network Due to the great importance of this issue in the economy, industry, and health, proposing appropriate computational methods for predicting unknown DDI with high precision is challenging. We propose a novel machine learning method for predicting unknown DDIs called \"NDD\", using a two-layer fully connected neural network. NDD uses various characteristics of drugs to have comprehensive information. Multiple drug similarities are calculated. NDD integrat various drug similarities with a non-linear similarity fusion method called \"SNF\" to achieve high-level features. Dependency: python version 3.5.3 deep learning lib keras: https://github.com/fchollet/keras/ machine learning lib scikit-learn: https://github.com/scikit-learn/scikit-learn Contact: nasim.rohani74@gmail.com",
                "homepage": "https://github.com/nrohani/NDD"
            }
        ],
        "inputs": [
            "dir",
            "name",
            "read1",
            "read2"
        ],
        "nb_inputs": 4,
        "outputs": [
            "name"
        ],
        "nb_outputs": 1,
        "name_workflow": "marcodelapierre__trinity-nf",
        "directive": [
            "tag \"${dir}/${name}\"",
            "storeDir \"${dir}/${params.overoutdirprefix}${name}\"",
            "container ''"
        ],
        "when": "",
        "stub": ""
    },
    "overlay_many": {
        "name_process": "overlay_many",
        "string_process": "\nprocess overlay_many {\n  tag \"${dir}/${name}\"\n  storeDir \"${dir}/${params.overoutdirprefix}${name}\"\n\n  container ''\n\n  input:\n  tuple val(dir), val(name), path(reads_fa)\n\n  output:\n  tuple val(dir), val(name), val(label_fa), path(\"${params.overfileprefix}${label_fa}\")\n\n  script:\n  label_fa = file(reads_fa).getSimpleName()\n  \"\"\"\n  singularity exec docker://ubuntu:18.04 bash -c ' \\\n  out_file=\\\"${params.overfileprefix}${reads_fa.toString().minus('.tgz')}\\\" && \\\n  mkdir -p overlay_tmp/upper overlay_tmp/work && \\\n  dd if=/dev/zero of=\\${out_file} count=${params.overlay_size_mb_many} bs=1M && \\\n  mkfs.ext3 -d overlay_tmp \\${out_file} && \\\n  rm -rf overlay_tmp \\\n  '\n  \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "  label_fa = file(reads_fa).getSimpleName()\n  \"\"\"\n  singularity exec docker://ubuntu:18.04 bash -c ' \\\n  out_file=\\\"${params.overfileprefix}${reads_fa.toString().minus('.tgz')}\\\" && \\\n  mkdir -p overlay_tmp/upper overlay_tmp/work && \\\n  dd if=/dev/zero of=\\${out_file} count=${params.overlay_size_mb_many} bs=1M && \\\n  mkfs.ext3 -d overlay_tmp \\${out_file} && \\\n  rm -rf overlay_tmp \\\n  '\n  \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [
            "Singularity Hub",
            "NDD"
        ],
        "tools_url": [
            "https://bio.tools/singularity_hub",
            "https://bio.tools/NDD"
        ],
        "tools_dico": [
            {
                "name": "Singularity Hub",
                "uri": "https://bio.tools/singularity_hub",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3524",
                            "term": "Simulation experiment"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Data handling"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Utility operation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File handling"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "File processing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2409",
                                    "term": "Report handling"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Framework to build and deploy Singularity containers for mobility of compute, and the singularity-python software with novel metrics for assessing reproducibility of such containers.",
                "homepage": "https://singularity-hub.org/"
            },
            {
                "name": "NDD",
                "uri": "https://bio.tools/NDD",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3474",
                            "term": "Machine learning"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0602",
                            "term": "Molecular interactions, pathways and networks"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Essential dynamics"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3439",
                                    "term": "Pathway or network prediction"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "PCA"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "Principal modes"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3891",
                                    "term": "ED"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Drug-Drug Interaction Predicting by Neural Network Using Integrated Similarity | Link of paper: https://www.nature.com/articles/s41598-019-50121-3 A Novel Method For Predicting Drug-Drug Interaction By Neural Network Due to the great importance of this issue in the economy, industry, and health, proposing appropriate computational methods for predicting unknown DDI with high precision is challenging. We propose a novel machine learning method for predicting unknown DDIs called \"NDD\", using a two-layer fully connected neural network. NDD uses various characteristics of drugs to have comprehensive information. Multiple drug similarities are calculated. NDD integrat various drug similarities with a non-linear similarity fusion method called \"SNF\" to achieve high-level features. Dependency: python version 3.5.3 deep learning lib keras: https://github.com/fchollet/keras/ machine learning lib scikit-learn: https://github.com/scikit-learn/scikit-learn Contact: nasim.rohani74@gmail.com",
                "homepage": "https://github.com/nrohani/NDD"
            }
        ],
        "inputs": [
            "dir",
            "name",
            "reads_fa"
        ],
        "nb_inputs": 3,
        "outputs": [
            "label_fa"
        ],
        "nb_outputs": 1,
        "name_workflow": "marcodelapierre__trinity-nf",
        "directive": [
            "tag \"${dir}/${name}\"",
            "storeDir \"${dir}/${params.overoutdirprefix}${name}\"",
            "container ''"
        ],
        "when": "",
        "stub": ""
    },
    "jellyfish": {
        "name_process": "jellyfish",
        "string_process": "\nprocess jellyfish {\n  tag \"${dir}/${name}\"\n  stageInMode { params.copyinput ? 'copy' : 'symlink' }\n\n  input:\n  tuple val(dir), val(name), path(read1), path(read2), path(\"${params.overtaskfile}\")\n\n  output:\n  tuple val(dir), val(name), path(read1), path(read2), path(\"${params.taskoutdir}\"), path(\"${params.overtaskfile}\")\n\n  script:\n  \"\"\"\n  mem='${task.memory}'\n  mem=\\${mem%B}\n  mem=\\${mem// /}\n\n  Trinity \\\n    --left $read1 \\\n    --right $read2 \\\n    --seqType fq \\\n    --no_normalize_reads \\\n    --verbose \\\n    --no_version_check \\\n    --output ${params.taskoutdir} \\\n    --max_memory \\${mem} \\\n    --CPU ${task.cpus} \\\n    --no_run_inchworm\n  \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "  \"\"\"\n  mem='${task.memory}'\n  mem=\\${mem%B}\n  mem=\\${mem// /}\n\n  Trinity \\\n    --left $read1 \\\n    --right $read2 \\\n    --seqType fq \\\n    --no_normalize_reads \\\n    --verbose \\\n    --no_version_check \\\n    --output ${params.taskoutdir} \\\n    --max_memory \\${mem} \\\n    --CPU ${task.cpus} \\\n    --no_run_inchworm\n  \"\"\"",
        "nb_lignes_script": 16,
        "language_script": "bash",
        "tools": [
            "Trinity"
        ],
        "tools_url": [
            "https://bio.tools/trinity"
        ],
        "tools_dico": [
            {
                "name": "Trinity",
                "uri": "https://bio.tools/trinity",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Trinity is a transcriptome assembler which relies on three different tools, inchworm an assembler, chrysalis which pools contigs and butterfly which amongst others compacts a graph resulting from butterfly with reads.",
                "homepage": "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
            }
        ],
        "inputs": [
            "dir",
            "name",
            "read1",
            "read2"
        ],
        "nb_inputs": 4,
        "outputs": [
            "name"
        ],
        "nb_outputs": 1,
        "name_workflow": "marcodelapierre__trinity-nf",
        "directive": [
            "tag \"${dir}/${name}\"",
            "stageInMode { params.copyinput ? 'copy' : 'symlink' }"
        ],
        "when": "",
        "stub": ""
    },
    "inchworm": {
        "name_process": "inchworm",
        "string_process": "\nprocess inchworm {\n  tag \"${dir}/${name}\"\n\n  input:\n  tuple val(dir), val(name), path(read1), path(read2), path(\"${params.taskoutdir}\"), path(\"${params.overtaskfile}\")\n\n  output:\n  tuple val(dir), val(name), path(read1), path(read2), path(\"${params.taskoutdir}\"), path(\"${params.overtaskfile}\")\n\n  script:\n  \"\"\"\n  mem='${task.memory}'\n  mem=\\${mem%B}\n  mem=\\${mem// /}\n\n  Trinity \\\n    --left $read1 \\\n    --right $read2 \\\n    --seqType fq \\\n    --no_normalize_reads \\\n    --verbose \\\n    --no_version_check \\\n    --output ${params.taskoutdir} \\\n    --max_memory \\${mem} \\\n    --CPU ${task.cpus} \\\n    --inchworm_cpu ${task.cpus} \\\n    --no_run_chrysalis\n  \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "  \"\"\"\n  mem='${task.memory}'\n  mem=\\${mem%B}\n  mem=\\${mem// /}\n\n  Trinity \\\n    --left $read1 \\\n    --right $read2 \\\n    --seqType fq \\\n    --no_normalize_reads \\\n    --verbose \\\n    --no_version_check \\\n    --output ${params.taskoutdir} \\\n    --max_memory \\${mem} \\\n    --CPU ${task.cpus} \\\n    --inchworm_cpu ${task.cpus} \\\n    --no_run_chrysalis\n  \"\"\"",
        "nb_lignes_script": 17,
        "language_script": "bash",
        "tools": [
            "Trinity"
        ],
        "tools_url": [
            "https://bio.tools/trinity"
        ],
        "tools_dico": [
            {
                "name": "Trinity",
                "uri": "https://bio.tools/trinity",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Trinity is a transcriptome assembler which relies on three different tools, inchworm an assembler, chrysalis which pools contigs and butterfly which amongst others compacts a graph resulting from butterfly with reads.",
                "homepage": "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
            }
        ],
        "inputs": [
            "dir",
            "name",
            "read1",
            "read2"
        ],
        "nb_inputs": 4,
        "outputs": [
            "name"
        ],
        "nb_outputs": 1,
        "name_workflow": "marcodelapierre__trinity-nf",
        "directive": [
            "tag \"${dir}/${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "chrysalis": {
        "name_process": "chrysalis",
        "string_process": "\nprocess chrysalis {\n  tag \"${dir}/${name}\"\n\n  input:\n  tuple val(dir), val(name), path(read1), path(read2), path(\"${params.taskoutdir}\"), path(\"${params.overtaskfile}\")\n\n  output:\n  tuple val(dir), val(name), path{ params.localdisk ? \"chunk*.tgz\" : \"${params.taskoutdir}/read_partitions/**inity.reads.fa\" }\n\n  script:\n  \"\"\"\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    here=\\$PWD\n    rm -rf ${params.localdir}\n    mkdir ${params.localdir}\n    cp -r \\$( readlink $read1 ) ${params.localdir}/\n    cp -r \\$( readlink $read2 ) ${params.localdir}/\n    cp -r \\$( readlink ${params.taskoutdir} ) ${params.localdir}/\n    cd ${params.localdir}\n  fi\n\n  mem='${task.memory}'\n  mem=\\${mem%B}\n  mem=\\${mem// /}\n\n  Trinity \\\n    --left $read1 \\\n    --right $read2 \\\n    --seqType fq \\\n    --no_normalize_reads \\\n    --verbose \\\n    --no_version_check \\\n    --output ${params.taskoutdir} \\\n    --max_memory \\${mem} \\\n    --CPU ${task.cpus} \\\n    --no_distributed_trinity_exec\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    find ${params.taskoutdir}/read_partitions -name \"*inity.reads.fa\" >output_list\n    split -l ${params.bf_collate} -a 4 output_list chunk\n    for f in chunk* ; do\n      tar -cz -h -f \\${f}.tgz -T \\${f}\n    done\n    cd \\$here\n    cp ${params.localdir}/chunk*.tgz .\n    rm -r ${params.localdir}\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 48,
        "string_script": "  \"\"\"\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    here=\\$PWD\n    rm -rf ${params.localdir}\n    mkdir ${params.localdir}\n    cp -r \\$( readlink $read1 ) ${params.localdir}/\n    cp -r \\$( readlink $read2 ) ${params.localdir}/\n    cp -r \\$( readlink ${params.taskoutdir} ) ${params.localdir}/\n    cd ${params.localdir}\n  fi\n\n  mem='${task.memory}'\n  mem=\\${mem%B}\n  mem=\\${mem// /}\n\n  Trinity \\\n    --left $read1 \\\n    --right $read2 \\\n    --seqType fq \\\n    --no_normalize_reads \\\n    --verbose \\\n    --no_version_check \\\n    --output ${params.taskoutdir} \\\n    --max_memory \\${mem} \\\n    --CPU ${task.cpus} \\\n    --no_distributed_trinity_exec\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    find ${params.taskoutdir}/read_partitions -name \"*inity.reads.fa\" >output_list\n    split -l ${params.bf_collate} -a 4 output_list chunk\n    for f in chunk* ; do\n      tar -cz -h -f \\${f}.tgz -T \\${f}\n    done\n    cd \\$here\n    cp ${params.localdir}/chunk*.tgz .\n    rm -r ${params.localdir}\n  fi\n  \"\"\"",
        "nb_lignes_script": 37,
        "language_script": "bash",
        "tools": [
            "Trinity"
        ],
        "tools_url": [
            "https://bio.tools/trinity"
        ],
        "tools_dico": [
            {
                "name": "Trinity",
                "uri": "https://bio.tools/trinity",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Trinity is a transcriptome assembler which relies on three different tools, inchworm an assembler, chrysalis which pools contigs and butterfly which amongst others compacts a graph resulting from butterfly with reads.",
                "homepage": "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
            }
        ],
        "inputs": [
            "dir",
            "name",
            "read1",
            "read2"
        ],
        "nb_inputs": 4,
        "outputs": [
            "name"
        ],
        "nb_outputs": 1,
        "name_workflow": "marcodelapierre__trinity-nf",
        "directive": [
            "tag \"${dir}/${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "butterfly": {
        "name_process": "butterfly",
        "string_process": "\nprocess butterfly {\n  tag \"${dir}/${name}\"\n\n  input:\n  tuple val(dir), val(name), path(reads_fa), path(\"${params.overtaskfile}\")\n\n  output:\n  tuple val(dir), val(name), path{ params.localdisk ? \"out_${reads_fa}\" : \"*inity.fasta\" }, optional: true\n\n                                                                                        \n  script:\n  \"\"\"\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    here=\\$PWD\n    rm -rf ${params.localdir}\n    mkdir ${params.localdir}\n    cp -r \\$( readlink $reads_fa ) ${params.localdir}/\n    cd ${params.localdir}\n  fi\n\n  mem='${params.bf_mem}'\n  mem=\\${mem%B}\n  export mem=\\${mem// /}\n\n  cat << \"EOF\" >trinity.sh\nTrinity \\\n  --single \\${1} \\\n  --run_as_paired \\\n  --seqType fa \\\n  --verbose \\\n  --no_version_check \\\n  --workdir trinity_workdir \\\n  --output \\${1}.out \\\n  --max_memory \\${mem} \\\n  --CPU ${params.bf_cpus} \\\n  --trinity_complete \\\n  --full_cleanup \\\n  --no_distributed_trinity_exec\nEOF\n  chmod +x trinity.sh\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    tar xzf ${reads_fa}\n    find ${params.taskoutdir}/read_partitions -name \"*inity.reads.fa\" | parallel -j ${task.cpus} ./trinity.sh {}\n    find ${params.taskoutdir}/read_partitions -name \"*inity.fasta\" | tar -cz -h -f out_${reads_fa} -T -\n    cd \\$here\n    cp ${params.localdir}/out_chunk*.tgz .\n    rm -r ${params.localdir}\n  else\n    ls *inity.reads.fa | parallel -j ${task.cpus} ./trinity.sh {}\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 52,
        "string_script": "  \"\"\"\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    here=\\$PWD\n    rm -rf ${params.localdir}\n    mkdir ${params.localdir}\n    cp -r \\$( readlink $reads_fa ) ${params.localdir}/\n    cd ${params.localdir}\n  fi\n\n  mem='${params.bf_mem}'\n  mem=\\${mem%B}\n  export mem=\\${mem// /}\n\n  cat << \"EOF\" >trinity.sh\nTrinity \\\n  --single \\${1} \\\n  --run_as_paired \\\n  --seqType fa \\\n  --verbose \\\n  --no_version_check \\\n  --workdir trinity_workdir \\\n  --output \\${1}.out \\\n  --max_memory \\${mem} \\\n  --CPU ${params.bf_cpus} \\\n  --trinity_complete \\\n  --full_cleanup \\\n  --no_distributed_trinity_exec\nEOF\n  chmod +x trinity.sh\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    tar xzf ${reads_fa}\n    find ${params.taskoutdir}/read_partitions -name \"*inity.reads.fa\" | parallel -j ${task.cpus} ./trinity.sh {}\n    find ${params.taskoutdir}/read_partitions -name \"*inity.fasta\" | tar -cz -h -f out_${reads_fa} -T -\n    cd \\$here\n    cp ${params.localdir}/out_chunk*.tgz .\n    rm -r ${params.localdir}\n  else\n    ls *inity.reads.fa | parallel -j ${task.cpus} ./trinity.sh {}\n  fi\n  \"\"\"",
        "nb_lignes_script": 40,
        "language_script": "bash",
        "tools": [
            "Trinity",
            "NeoFuse",
            "parallelGWAS"
        ],
        "tools_url": [
            "https://bio.tools/trinity",
            "https://bio.tools/NeoFuse",
            "https://bio.tools/parallelgwas"
        ],
        "tools_dico": [
            {
                "name": "Trinity",
                "uri": "https://bio.tools/trinity",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3308",
                            "term": "Transcriptomics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Gene expression"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0203",
                            "term": "Expression"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3258",
                                    "term": "Transcriptome assembly"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Trinity is a transcriptome assembler which relies on three different tools, inchworm an assembler, chrysalis which pools contigs and butterfly which amongst others compacts a graph resulting from butterfly with reads.",
                "homepage": "https://github.com/trinityrnaseq/trinityrnaseq/wiki"
            },
            {
                "name": "NeoFuse",
                "uri": "https://bio.tools/NeoFuse",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_2830",
                            "term": "Immunoproteins and antigens"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0154",
                            "term": "Small molecules"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "Gene transcripts"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Transcriptome profiling"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA-Seq analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small RNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Small-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "Whole transcriptome shotgun sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "RNA sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3170",
                            "term": "WTSS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "Cancer biology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_2640",
                            "term": "https://en.wikipedia.org/wiki/Oncology"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3512",
                            "term": "mRNA features"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0310",
                                    "term": "Sequence assembly"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Peptide immunogenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Immunogenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0252",
                                    "term": "Antigenicity prediction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3799",
                                    "term": "Quantitation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Predicting fusion neoantigens from RNA sequencing data.\n\nThe Section for Bioinformatrics at the Biocenter of Innsbruck Medical University is commited to the generation, management, integration, and leveraging data from genomics studies.\n\nQuantification of the tumor immune contexture.\n\nZlatko Trajanoski awarded with ERC Advanced Grant.",
                "homepage": "https://icbi.i-med.ac.at/NeoFuse/"
            },
            {
                "name": "parallelGWAS",
                "uri": "https://bio.tools/parallelgwas",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS study"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3053",
                            "term": "Genetics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype and phenotype resources"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0625",
                            "term": "Genotype-phenotype"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS analysis"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "GWAS"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3517",
                            "term": "Genome-wide association study"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype mapping"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype reconstruction"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype map generation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0487",
                                    "term": "Haplotype inference"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Developing parallel computing tools for genome-wide association studies.",
                "homepage": "https://en.osdn.jp/projects/parallelgwas/"
            }
        ],
        "inputs": [
            "dir",
            "name",
            "reads_fa"
        ],
        "nb_inputs": 3,
        "outputs": [
            "name"
        ],
        "nb_outputs": 1,
        "name_workflow": "marcodelapierre__trinity-nf",
        "directive": [
            "tag \"${dir}/${name}\""
        ],
        "when": "",
        "stub": ""
    },
    "aggregate": {
        "name_process": "aggregate",
        "string_process": "\nprocess aggregate {\n  tag \"${dir}/${name}\"\n  publishDir \"${dir}/${params.outprefix}\", mode: 'copy', saveAs: { filename -> \"${name}_\"+filename }\n\n  input:\n  tuple val(dir), val(name), path(reads_fasta), path(\"${params.overtaskfile}\")\n\n  output:\n  tuple val(dir), val(name), path(\"Trinity.fasta\"), path(\"Trinity.fasta.gene_trans_map\")\n\n  script:\n  \"\"\"\n  my_trinity=\\$(which Trinity)\n  my_trinity=\\$(dirname \\$my_trinity)\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    here=\\$PWD\n    rm -rf ${params.localdir}\n    mkdir ${params.localdir}\n    cd ${params.localdir}\n    for f in ${reads_fasta} ; do\n      cp \\$( readlink \\$here/\\$f ) .\n      tar xzf \\${f}\n    done\n    find ${params.taskoutdir}/read_partitions -name \"*inity.fasta\" >input_list\n  else\n    ls *inity.fasta >input_list\n  fi\n\n  cat input_list | \\${my_trinity}/util/support_scripts/partitioned_trinity_aggregator.pl \\\n    --token_prefix TRINITY_DN --output_prefix Trinity.tmp\n  mv Trinity.tmp.fasta Trinity.fasta\n\n  \\${my_trinity}/util/support_scripts/get_Trinity_gene_to_trans_map.pl Trinity.fasta > Trinity.fasta.gene_trans_map\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    cd \\$here\n    cp ${params.localdir}/Trinity.fasta* .\n    rm -r ${params.localdir}\n  fi\n  \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "  \"\"\"\n  my_trinity=\\$(which Trinity)\n  my_trinity=\\$(dirname \\$my_trinity)\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    here=\\$PWD\n    rm -rf ${params.localdir}\n    mkdir ${params.localdir}\n    cd ${params.localdir}\n    for f in ${reads_fasta} ; do\n      cp \\$( readlink \\$here/\\$f ) .\n      tar xzf \\${f}\n    done\n    find ${params.taskoutdir}/read_partitions -name \"*inity.fasta\" >input_list\n  else\n    ls *inity.fasta >input_list\n  fi\n\n  cat input_list | \\${my_trinity}/util/support_scripts/partitioned_trinity_aggregator.pl \\\n    --token_prefix TRINITY_DN --output_prefix Trinity.tmp\n  mv Trinity.tmp.fasta Trinity.fasta\n\n  \\${my_trinity}/util/support_scripts/get_Trinity_gene_to_trans_map.pl Trinity.fasta > Trinity.fasta.gene_trans_map\n\n  if [ \"${params.localdisk}\" == \"true\" ] ; then\n    cd \\$here\n    cp ${params.localdir}/Trinity.fasta* .\n    rm -r ${params.localdir}\n  fi\n  \"\"\"",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "dir",
            "name",
            "reads_fasta"
        ],
        "nb_inputs": 3,
        "outputs": [
            "name"
        ],
        "nb_outputs": 1,
        "name_workflow": "marcodelapierre__trinity-nf",
        "directive": [
            "tag \"${dir}/${name}\"",
            "publishDir \"${dir}/${params.outprefix}\", mode: 'copy', saveAs: { filename -> \"${name}_\"+filename }"
        ],
        "when": "",
        "stub": ""
    }
}