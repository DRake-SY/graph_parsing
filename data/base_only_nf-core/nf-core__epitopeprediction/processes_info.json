{
    "PEPTIDE_PREDICTION": {
        "name_process": "PEPTIDE_PREDICTION",
        "string_process": "process PEPTIDE_PREDICTION {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"bioconda::snpsift=4.3.1t bioconda::python=2.7.15 bioconda::pyvcf=0.6.8 conda-forge::pandas=0.24.2 bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' :\n        'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\"\n\n    input:\n    tuple val(meta), path(splitted), path(software_versions)\n\n    output:\n    tuple val(meta), path(\"*.json\"), emit: json\n    tuple val(meta), path(\"*.tsv\"), emit: predicted\n    tuple val(meta), path(\"*.fasta\"), emit: fasta optional true\n    path \"versions.yml\", emit: versions\n\n    script:\n                                                                     \n                                                                       \n    def argument = task.ext.args\n\n    if (params.proteome) {\n        argument = \"--proteome ${params.proteome} \" + argument\n    }\n\n    if (params.wild_type) {\n        argument = \"--wild_type \" + argument\n    }\n\n    if (params.fasta_output) {\n        argument = \"--fasta_output \" + argument\n    }\n\n    if (params.tool_thresholds) {\n        argument = \"--tool_thresholds ${params.tool_thresholds} \" + argument\n    }\n\n    \"\"\"\n    epaa.py --identifier ${splitted.baseName} \\\n        --alleles '${meta.alleles}' \\\n        --versions ${software_versions} \\\n        ${argument} ${splitted}\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version 2>&1 | sed 's/Python //g')\n        fred2: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\")\n        pandas: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('pandas').version)\")\n        pyvcf: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('pyvcf').version)\")\n        mhcflurry: \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//')\n        mhcnuggets: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('mhcnuggets').version)\")\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 53,
        "string_script": "    def argument = task.ext.args\n\n    if (params.proteome) {\n        argument = \"--proteome ${params.proteome} \" + argument\n    }\n\n    if (params.wild_type) {\n        argument = \"--wild_type \" + argument\n    }\n\n    if (params.fasta_output) {\n        argument = \"--fasta_output \" + argument\n    }\n\n    if (params.tool_thresholds) {\n        argument = \"--tool_thresholds ${params.tool_thresholds} \" + argument\n    }\n\n    \"\"\"\n    epaa.py --identifier ${splitted.baseName} \\\n        --alleles '${meta.alleles}' \\\n        --versions ${software_versions} \\\n        ${argument} ${splitted}\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version 2>&1 | sed 's/Python //g')\n        fred2: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\")\n        pandas: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('pandas').version)\")\n        pyvcf: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('pyvcf').version)\")\n        mhcflurry: \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//')\n        mhcnuggets: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('mhcnuggets').version)\")\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 33,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "splitted",
            "software_versions"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::snpsift=4.3.1t bioconda::python=2.7.15 bioconda::pyvcf=0.6.8 conda-forge::pandas=0.24.2 bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' : 'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "SPLIT_PEPTIDES": {
        "name_process": "SPLIT_PEPTIDES",
        "string_process": "process SPLIT_PEPTIDES {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/python:3.8.3' :\n        'quay.io/biocontainers/python:3.8.3' }\"\n\n    input:\n    tuple val(meta), path(peptide)\n\n    output:\n    tuple val(meta), path(\"*.tsv\"), emit: splitted\n    path \"versions.yml\", emit: versions\n\n    script:\n    def prefix = task.ext.suffix ? \"${peptide.baseName}_${task.ext.suffix}\" : \"${peptide.baseName}\"\n\n    \"\"\"\n    split_peptides.py --input ${peptide} \\\\\n    --output_base \"${prefix}\" \\\\\n    $task.ext.args\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    def prefix = task.ext.suffix ? \"${peptide.baseName}_${task.ext.suffix}\" : \"${peptide.baseName}\"\n\n    \"\"\"\n    split_peptides.py --input ${peptide} \\\\\n    --output_base \"${prefix}\" \\\\\n    $task.ext.args\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "peptide"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/python:3.8.3' : 'quay.io/biocontainers/python:3.8.3' }\""
        ],
        "when": "",
        "stub": ""
    },
    "CSVTK_CONCAT": {
        "name_process": "CSVTK_CONCAT",
        "string_process": "process CSVTK_CONCAT {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"bioconda::csvtk=0.23.0\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/csvtk:0.23.0--h9ee0642_0' :\n        'quay.io/biocontainers/csvtk:0.23.0--h9ee0642_0' }\"\n\n    input:\n    tuple val(meta), path(predicted)\n\n    output:\n    tuple val(meta), path(\"*.tsv\"), emit: predicted\n    path \"versions.yml\", emit: versions\n\n    script:\n    \"\"\"\n    csvtk concat -t $predicted > ${meta.sample}_prediction_result.tsv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        csvtk: \\$(echo \\$( csvtk version | sed -e \"s/csvtk v//g\" ))\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    csvtk concat -t $predicted > ${meta.sample}_prediction_result.tsv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        csvtk: \\$(echo \\$( csvtk version | sed -e \"s/csvtk v//g\" ))\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "predicted"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::csvtk=0.23.0\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/csvtk:0.23.0--h9ee0642_0' : 'quay.io/biocontainers/csvtk:0.23.0--h9ee0642_0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "GET_PREDICTION_VERSIONS": {
        "name_process": "GET_PREDICTION_VERSIONS",
        "string_process": "process GET_PREDICTION_VERSIONS {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' :\n        'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\"\n\n    input:\n    val external_tool_versions\n\n    output:\n    path \"versions.csv\", emit: versions\n\n    script:\n    def external_tools = external_tool_versions.join('\\n')\n\n    \"\"\"\n    cat <<-END_VERSIONS > versions.csv\n    mhcflurry: \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//')\n    mhcnuggets: \\$(python -c \"import pkg_resources; print('mhcnuggets' + pkg_resources.get_distribution('mhcnuggets').version)\" | sed 's/^mhcnuggets//; s/ .*\\$//' )\n    fred2: \\$(python -c \"import pkg_resources; print('fred2' + pkg_resources.get_distribution('Fred2').version)\" | sed 's/^fred2//; s/ .*\\$//')\n    END_VERSIONS\n\n    if ! [ -z \"${external_tools}\" ]\n    then\n        echo ${external_tools} >> versions.csv\n    fi\n    \"\"\"\n}",
        "nb_lignes_process": 28,
        "string_script": "    def external_tools = external_tool_versions.join('\\n')\n\n    \"\"\"\n    cat <<-END_VERSIONS > versions.csv\n    mhcflurry: \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//')\n    mhcnuggets: \\$(python -c \"import pkg_resources; print('mhcnuggets' + pkg_resources.get_distribution('mhcnuggets').version)\" | sed 's/^mhcnuggets//; s/ .*\\$//' )\n    fred2: \\$(python -c \"import pkg_resources; print('fred2' + pkg_resources.get_distribution('Fred2').version)\" | sed 's/^fred2//; s/ .*\\$//')\n    END_VERSIONS\n\n    if ! [ -z \"${external_tools}\" ]\n    then\n        echo ${external_tools} >> versions.csv\n    fi\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "external_tool_versions"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' : 'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "CHECK_REQUESTED_MODELS": {
        "name_process": "CHECK_REQUESTED_MODELS",
        "string_process": "process CHECK_REQUESTED_MODELS {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' :\n        'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\"\n\n    input:\n    tuple val(alleles), path(input_file)\n    path(software_versions)\n\n    output:\n    path '*.txt', emit: txt                    \n    path '*.log', emit: log                      \n    path \"versions.yml\", emit: versions\n\n\n    script:\n    def argument = task.ext.args\n\n    if (argument.contains(\"peptides\") == true) {\n        argument += \" ${input_file}\"\n    }\n\n    if (params.multiqc_title) {\n        argument += \"--title \\\"$params.multiqc_title\\\"\"\n    }\n\n    \"\"\"\n    check_requested_models.py ${argument} \\\n        --alleles '${alleles.join(';')}' \\\n        --mhcclass ${params.mhc_class} \\\n        --versions ${software_versions} > model_warnings.log\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        mhcflurry: \\$(echo \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//') )\n        mhcnuggets: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('mhcnuggets').version)\"))\n        fred2: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\"))\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 41,
        "string_script": "    def argument = task.ext.args\n\n    if (argument.contains(\"peptides\") == true) {\n        argument += \" ${input_file}\"\n    }\n\n    if (params.multiqc_title) {\n        argument += \"--title \\\"$params.multiqc_title\\\"\"\n    }\n\n    \"\"\"\n    check_requested_models.py ${argument} \\\n        --alleles '${alleles.join(';')}' \\\n        --mhcclass ${params.mhc_class} \\\n        --versions ${software_versions} > model_warnings.log\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        mhcflurry: \\$(echo \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//') )\n        mhcnuggets: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('mhcnuggets').version)\"))\n        fred2: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\"))\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 22,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "alleles",
            "input_file",
            "software_versions"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' : 'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "CSVTK_SPLIT": {
        "name_process": "CSVTK_SPLIT",
        "string_process": "process CSVTK_SPLIT {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"bioconda::csvtk=0.23.0\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/csvtk:0.23.0--h9ee0642_0' :\n        'quay.io/biocontainers/csvtk:0.23.0--h9ee0642_0' }\"\n\n    input:\n    tuple val(meta), path(raw)\n\n    output:\n    tuple val(meta), path(\"*.tsv\"), emit: splitted\n    path \"versions.yml\", emit: versions\n\n    script:\n    \"\"\"\n    sed -i.bak '/^##/d' ${raw}\n    csvtk split ${raw} -t -C '&' -f '#chr'\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        csvtk: \\$(echo \\$( csvtk version | sed -e \"s/csvtk v//g\" ))\n    END_VERSIONS\n    \"\"\"\n\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    sed -i.bak '/^##/d' ${raw}\n    csvtk split ${raw} -t -C '&' -f '#chr'\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        csvtk: \\$(echo \\$( csvtk version | sed -e \"s/csvtk v//g\" ))\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "raw"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::csvtk=0.23.0\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/csvtk:0.23.0--h9ee0642_0' : 'quay.io/biocontainers/csvtk:0.23.0--h9ee0642_0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "SHOW_SUPPORTED_MODELS": {
        "name_process": "SHOW_SUPPORTED_MODELS",
        "string_process": "process SHOW_SUPPORTED_MODELS {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' :\n        'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\"\n\n    input:\n    tuple val(meta), path(raw), path(software_versions)\n\n    output:\n    path '*.txt', emit: txt                    \n    path \"versions.yml\", emit: versions\n\n    script:\n    \"\"\"\n    check_supported_models.py --versions ${software_versions}\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        mhcflurry: \\$(echo \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//') )\n        mhcnuggets: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('mhcnuggets').version)\"))\n        fred2: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\"))\n    END_VERSIONS\n    \"\"\"\n\n}",
        "nb_lignes_process": 26,
        "string_script": "    \"\"\"\n    check_supported_models.py --versions ${software_versions}\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        mhcflurry: \\$(echo \\$(mhcflurry-predict --version 2>&1 | sed 's/^mhcflurry //; s/ .*\\$//') )\n        mhcnuggets: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('mhcnuggets').version)\"))\n        fred2: \\$(echo \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\"))\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "raw",
            "software_versions"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::fred2=2.0.7 bioconda::mhcflurry=1.4.3 bioconda::mhcnuggets=2.3.2\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' : 'quay.io/biocontainers/mulled-v2-c3f301504f7fa2e7bf81c3783de19a9990ea3001:12b1b9f040fd92a80629d58f8a558dde4820eb15-0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "CAT_FILES": {
        "name_process": "CAT_FILES",
        "string_process": "process CAT_FILES {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"conda-forge::cat=5.2.3\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/cat:5.2.3--hdfd78af_1' :\n        'quay.io/biocontainers/cat:5.2.3--hdfd78af_1' }\"\n\n    input:\n    tuple val(meta), path(input)\n\n    output:\n    tuple val(meta), path(\"*_prediction.*\"), emit: output\n\n    script:\n    def fileExt = input[0].name.tokenize(\"\\\\.\")[-1]\n    prefix = task.ext.suffix ? \"${meta.sample}_${task.ext.suffix}\" : \"${meta.sample}\"\n\n    \"\"\"\n    cat $input > ${prefix}_prediction.${fileExt}\n    \"\"\"\n}",
        "nb_lignes_process": 20,
        "string_script": "    def fileExt = input[0].name.tokenize(\"\\\\.\")[-1]\n    prefix = task.ext.suffix ? \"${meta.sample}_${task.ext.suffix}\" : \"${meta.sample}\"\n\n    \"\"\"\n    cat $input > ${prefix}_prediction.${fileExt}\n    \"\"\"",
        "nb_lignes_script": 5,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "input"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"conda-forge::cat=5.2.3\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/cat:5.2.3--hdfd78af_1' : 'quay.io/biocontainers/cat:5.2.3--hdfd78af_1' }\""
        ],
        "when": "",
        "stub": ""
    },
    "EXTERNAL_TOOLS_IMPORT": {
        "name_process": "EXTERNAL_TOOLS_IMPORT",
        "string_process": "\nprocess EXTERNAL_TOOLS_IMPORT {\n    label 'process_low'\n\n    input:\n    tuple val(toolname), val(toolversion), val(toolchecksum), path(tooltarball), file(datatarball), val(datachecksum), val(toolbinaryname)\n\n    output:\n    path \"${toolname}\", emit: nonfree_tools\n    val  \"v_*.txt\", emit: versions\n\n    script:\n    \"\"\"\n    #\n    # CHECK IF THE PROVIDED SOFTWARE TARBALL IS A REGULAR FILES\n    #\n    if [ ! -f \"$tooltarball\" ]; then\n        echo \"Path specified for ${toolname} does not point to a regular file. Please specify a path to the original tool tarball.\" >&2\n        exit 1\n    fi\n\n    #\n    # VALIDATE THE CHECKSUM OF THE PROVIDED SOFTWARE TARBALL\n    #\n    checksum=\"\\$(md5sum \"$tooltarball\" | cut -f1 -d' ')\"\n    echo \"\\$checksum\"\n    if [ \"\\$checksum\" != \"${toolchecksum}\" ]; then\n        echo \"Checksum error for $toolname. Please make sure to provide the original tarball for $toolname version $toolversion\" >&2\n        exit 2\n    fi\n\n    #\n    # UNPACK THE PROVIDED SOFTWARE TARBALL\n    #\n    mkdir -v \"${toolname}\"\n    tar -C \"${toolname}\" --strip-components 1 -x -f \"$tooltarball\"\n\n    #\n    # MODIFY THE NETMHC WRAPPER SCRIPT ACCORDING TO INSTALL INSTRUCTIONS\n    # Substitution 1: We install tcsh via conda, thus /bin/tcsh won't work\n    # Substitution 2: We want temp files to be written to /tmp if TMPDIR is not set\n    # Substitution 3: NMHOME should be the folder in which the tcsh script itself resides\n    #\n    sed -i.bak \\\n        -e 's_bin/tcsh.*\\$_usr/bin/env tcsh_' \\\n        -e \"s_/scratch_/tmp_\" \\\n        -e \"s_setenv[[:space:]]NMHOME.*_setenv NMHOME \\\\`realpath -s \\\\\\$0 | sed -r 's/[^/]+\\$//'\\\\`_\" \"${toolname}/${toolbinaryname}\"\n\n    #\n    # VALIDATE THE CHECKSUM OF THE DOWNLOADED MODEL DATA\n    #\n    checksum=\"\\$(md5sum \"$datatarball\" | cut -f1 -d' ')\"\n    if [ \"\\$checksum\" != \"${datachecksum}\" ]; then\n        echo \"A checksum mismatch occurred when checking the data file for ${toolname}.\" >&2\n        exit 3\n    fi\n\n    #\n    # UNPACK THE DOWNLOADED MODEL DATA\n    #\n    tar -C \"${toolname}\" -v -x -f \"$datatarball\"\n\n    #\n    # CREATE VERSION FILE\n    #\n    echo \"${toolname} ${toolversion}\" > \"v_${toolname}.txt\"\n    \"\"\"\n}",
        "nb_lignes_process": 66,
        "string_script": "    \"\"\"\n    #\n    # CHECK IF THE PROVIDED SOFTWARE TARBALL IS A REGULAR FILES\n    #\n    if [ ! -f \"$tooltarball\" ]; then\n        echo \"Path specified for ${toolname} does not point to a regular file. Please specify a path to the original tool tarball.\" >&2\n        exit 1\n    fi\n\n    #\n    # VALIDATE THE CHECKSUM OF THE PROVIDED SOFTWARE TARBALL\n    #\n    checksum=\"\\$(md5sum \"$tooltarball\" | cut -f1 -d' ')\"\n    echo \"\\$checksum\"\n    if [ \"\\$checksum\" != \"${toolchecksum}\" ]; then\n        echo \"Checksum error for $toolname. Please make sure to provide the original tarball for $toolname version $toolversion\" >&2\n        exit 2\n    fi\n\n    #\n    # UNPACK THE PROVIDED SOFTWARE TARBALL\n    #\n    mkdir -v \"${toolname}\"\n    tar -C \"${toolname}\" --strip-components 1 -x -f \"$tooltarball\"\n\n    #\n    # MODIFY THE NETMHC WRAPPER SCRIPT ACCORDING TO INSTALL INSTRUCTIONS\n    # Substitution 1: We install tcsh via conda, thus /bin/tcsh won't work\n    # Substitution 2: We want temp files to be written to /tmp if TMPDIR is not set\n    # Substitution 3: NMHOME should be the folder in which the tcsh script itself resides\n    #\n    sed -i.bak \\\n        -e 's_bin/tcsh.*\\$_usr/bin/env tcsh_' \\\n        -e \"s_/scratch_/tmp_\" \\\n        -e \"s_setenv[[:space:]]NMHOME.*_setenv NMHOME \\\\`realpath -s \\\\\\$0 | sed -r 's/[^/]+\\$//'\\\\`_\" \"${toolname}/${toolbinaryname}\"\n\n    #\n    # VALIDATE THE CHECKSUM OF THE DOWNLOADED MODEL DATA\n    #\n    checksum=\"\\$(md5sum \"$datatarball\" | cut -f1 -d' ')\"\n    if [ \"\\$checksum\" != \"${datachecksum}\" ]; then\n        echo \"A checksum mismatch occurred when checking the data file for ${toolname}.\" >&2\n        exit 3\n    fi\n\n    #\n    # UNPACK THE DOWNLOADED MODEL DATA\n    #\n    tar -C \"${toolname}\" -v -x -f \"$datatarball\"\n\n    #\n    # CREATE VERSION FILE\n    #\n    echo \"${toolname} ${toolversion}\" > \"v_${toolname}.txt\"\n    \"\"\"",
        "nb_lignes_script": 54,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "toolname",
            "toolversion",
            "toolchecksum",
            "datachecksum",
            "toolbinaryname",
            "datatarball",
            "tooltarball"
        ],
        "nb_inputs": 7,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'"
        ],
        "when": "",
        "stub": ""
    },
    "SNPSIFT_SPLIT": {
        "name_process": "SNPSIFT_SPLIT",
        "string_process": "process SNPSIFT_SPLIT {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"conda-forge::snpsift:4.2\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/snpsift:4.2--hdfd78af_5' :\n        'quay.io/biocontainers/snpsift:4.2--hdfd78af_5' }\"\n\n    input:\n    tuple val(meta), path(input_file)\n\n    output:\n    tuple val(meta), path(\"*.vcf\"), emit: splitted\n    path \"versions.yml\", emit: versions\n\n    script:\n    \"\"\"\n    SnpSift split ${input_file}\n\n    cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            snpsift: \\$(echo \\$(snpsift -version 2>&1 | sed -n 3p | cut -d\\$' ' -f3))\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    SnpSift split ${input_file}\n\n    cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            snpsift: \\$(echo \\$(snpsift -version 2>&1 | sed -n 3p | cut -d\\$' ' -f3))\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [
            "SnpSift"
        ],
        "tools_url": [
            "https://bio.tools/snpsift"
        ],
        "tools_dico": [
            {
                "name": "SnpSift",
                "uri": "https://bio.tools/snpsift",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Biological databases"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3365",
                            "term": "Data architecture, analysis and design"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Data management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Information systems"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3071",
                            "term": "Databases and information systems"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3675",
                                    "term": "Variant filtering"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "Toolbox that allows you to filter and manipulate annotated vcf files.",
                "homepage": "http://snpeff.sourceforge.net/SnpSift.html"
            }
        ],
        "inputs": [
            "meta",
            "input_file"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"conda-forge::snpsift:4.2\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/snpsift:4.2--hdfd78af_5' : 'quay.io/biocontainers/snpsift:4.2--hdfd78af_5' }\""
        ],
        "when": "",
        "stub": ""
    },
    "SAMPLESHEET_CHECK": {
        "name_process": "SAMPLESHEET_CHECK",
        "string_process": "process SAMPLESHEET_CHECK {\n    tag \"$samplesheet\"\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/python:3.8.3' :\n        'quay.io/biocontainers/python:3.8.3' }\"\n\n    input:\n    path samplesheet\n\n    output:\n    path '*.csv'       , emit: csv\n    path \"versions.yml\", emit: versions\n\n    script:                                                                               \n    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplesheet"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "tag \"$samplesheet\"",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/python:3.8.3' : 'quay.io/biocontainers/python:3.8.3' }\""
        ],
        "when": "",
        "stub": ""
    },
    "MULTIQC": {
        "name_process": "MULTIQC",
        "string_process": "process MULTIQC {\n    label 'process_medium'\n\n    conda (params.enable_conda ? 'bioconda::multiqc=1.11' : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0' :\n        'quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0' }\"\n\n    input:\n    path multiqc_files\n\n    output:\n    path \"*multiqc_report.html\", emit: report\n    path \"*_data\"              , emit: data\n    path \"*_plots\"             , optional:true, emit: plots\n    path \"versions.yml\"        , emit: versions\n\n    script:\n    def args = task.ext.args ?: ''\n    \"\"\"\n    multiqc -f $args .\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        multiqc: \\$( multiqc --version | sed -e \"s/multiqc, version //g\" )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 26,
        "string_script": "    def args = task.ext.args ?: ''\n    \"\"\"\n    multiqc -f $args .\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        multiqc: \\$( multiqc --version | sed -e \"s/multiqc, version //g\" )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "multiqc_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_medium'",
            "conda (params.enable_conda ? 'bioconda::multiqc=1.11' : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0' : 'quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "MERGE_JSON": {
        "name_process": "MERGE_JSON",
        "string_process": "process MERGE_JSON {\n    label 'process_low'\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/python:3.8.3' :\n        'quay.io/biocontainers/python:3.8.3' }\"\n\n    input:\n    tuple val(meta), path(json)\n\n    output:\n    tuple val(meta), path(\"*.json\"), emit: json\n    path \"versions.yml\", emit: versions\n\n    script:\n    def argument = task.ext.args\n    if (argument.contains(\"single_input\") == true) {\n        argument += \" ${json}\"\n    }\n    \"\"\"\n    merge_jsons.py --prefix ${meta.sample} ${argument}\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 27,
        "string_script": "    def argument = task.ext.args\n    if (argument.contains(\"single_input\") == true) {\n        argument += \" ${json}\"\n    }\n    \"\"\"\n    merge_jsons.py --prefix ${meta.sample} ${argument}\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 11,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "json"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/python:3.8.3' : 'quay.io/biocontainers/python:3.8.3' }\""
        ],
        "when": "",
        "stub": ""
    },
    "CUSTOM_DUMPSOFTWAREVERSIONS": {
        "name_process": "CUSTOM_DUMPSOFTWAREVERSIONS",
        "string_process": "process CUSTOM_DUMPSOFTWAREVERSIONS {\n    label 'process_low'\n\n                                                                                                  \n    conda (params.enable_conda ? \"bioconda::multiqc=1.11\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0' :\n        'quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0' }\"\n\n    input:\n    path versions\n\n    output:\n    path \"software_versions.yml\"    , emit: yml\n    path \"software_versions_mqc.yml\", emit: mqc_yml\n    path \"versions.yml\"             , emit: versions\n\n    script:\n    def args = task.ext.args ?: ''\n    template 'dumpsoftwareversions.py'\n}",
        "nb_lignes_process": 19,
        "string_script": "    def args = task.ext.args ?: ''\n    template 'dumpsoftwareversions.py'",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [
            "docxtemplate"
        ],
        "tools_url": [
            "https://bio.tools/docxtemplate"
        ],
        "tools_dico": [
            {
                "name": "docxtemplate",
                "uri": "https://bio.tools/docxtemplate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3314",
                            "term": "Chemistry"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0322",
                                    "term": "Molecular model refinement"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Phenix', 'restraints', 'Amber', 'refinement' | Improved chemistry restraints for crystallographic refinement by integrating the Amber force field into Phenix | Word templates and tools for Windows | The IUCr Word templates utilize the content management features and document styles of Word to format your manuscript and to store essential details for submission of your manuscript",
                "homepage": "http://journals.iucr.org/services/docxtemplate/"
            }
        ],
        "inputs": [
            "versions"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::multiqc=1.11\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0' : 'quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0' }\""
        ],
        "when": "",
        "stub": ""
    },
    "FRED2_GENERATEPEPTIDES": {
        "name_process": "FRED2_GENERATEPEPTIDES",
        "string_process": "process FRED2_GENERATEPEPTIDES {\n    label 'process_low'\n    tag \"${meta.sample}\"\n\n    conda (params.enable_conda ? \"conda-forge::fred2:2.0.7\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/fred2:2.0.7--py_0' :\n        'quay.io/biocontainers/fred2:2.0.7--py_0' }\"\n\n    input:\n    tuple val(meta), path(raw)\n\n    output:\n    tuple val(meta), path(\"*.tsv\"), emit: splitted\n    path \"versions.yml\", emit: versions\n\n    script:\n    def prefix = task.ext.suffix ? \"${meta.sample}_${task.ext.suffix}\" : \"${meta.sample}_peptides\"\n\n    \"\"\"\n    gen_peptides.py --input ${raw} \\\\\n    --output '${prefix}.tsv' \\\\\n    $task.ext.args\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        fred2: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\")\n        python: \\$(python --version 2>&1 | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    def prefix = task.ext.suffix ? \"${meta.sample}_${task.ext.suffix}\" : \"${meta.sample}_peptides\"\n\n    \"\"\"\n    gen_peptides.py --input ${raw} \\\\\n    --output '${prefix}.tsv' \\\\\n    $task.ext.args\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        fred2: \\$(python -c \"import pkg_resources; print(pkg_resources.get_distribution('Fred2').version)\")\n        python: \\$(python --version 2>&1 | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 12,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "raw"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__epitopeprediction",
        "directive": [
            "label 'process_low'",
            "tag \"${meta.sample}\"",
            "conda (params.enable_conda ? \"conda-forge::fred2:2.0.7\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/fred2:2.0.7--py_0' : 'quay.io/biocontainers/fred2:2.0.7--py_0' }\""
        ],
        "when": "",
        "stub": ""
    }
}