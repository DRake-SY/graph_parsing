{
    "FASTQC": {
        "name_process": "FASTQC",
        "string_process": "process FASTQC {\n    tag \"$meta.id\"\n    label 'process_medium'\n\n    conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0' :\n        'quay.io/biocontainers/fastqc:0.11.9--0' }\"\n\n    input:\n    tuple val(meta), path(reads)\n\n    output:\n    tuple val(meta), path(\"*.html\"), emit: html\n    tuple val(meta), path(\"*.zip\") , emit: zip\n    path  \"versions.yml\"           , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n                                                                          \n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $args --threads $task.cpus ${prefix}.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 45,
        "string_script": "    def args = task.ext.args ?: ''\n                                                                          \n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    if (meta.single_end) {\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastqc $args --threads $task.cpus ${prefix}.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    } else {\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastqc $args --threads $task.cpus ${prefix}_1.fastq.gz ${prefix}_2.fastq.gz\n\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastqc: \\$( fastqc --version | sed -e \"s/FastQC v//g\" )\n        END_VERSIONS\n        \"\"\"\n    }",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "FastQC"
        ],
        "tools_url": [
            "https://bio.tools/fastqc"
        ],
        "tools_dico": [
            {
                "name": "FastQC",
                "uri": "https://bio.tools/fastqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3572",
                            "term": "Data quality management"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequence analysis"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0080",
                            "term": "Sequences"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality control"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0236",
                                    "term": "Sequence composition calculation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Significance testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical testing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical test"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_2238",
                                    "term": "Statistical analysis"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing QC"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3218",
                                    "term": "Sequencing quality assessment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_0848",
                                "term": "Raw sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2955",
                                "term": "Sequence report"
                            }
                        ]
                    }
                ],
                "description": "This tool aims to provide a QC report which can spot problems or biases which originate either in the sequencer or in the starting library material. It can be run in one of two modes. It can either run as a stand alone interactive application for the immediate analysis of small numbers of FastQ files, or it can be run in a non-interactive mode where it would be suitable for integrating into a larger analysis pipeline for the systematic processing of large numbers of files.",
                "homepage": "http://www.bioinformatics.babraham.ac.uk/projects/fastqc/"
            }
        ],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "conda (params.enable_conda ? \"bioconda::fastqc=0.11.9\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/fastqc:0.11.9--0' : 'quay.io/biocontainers/fastqc:0.11.9--0' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "CAT_FASTQ": {
        "name_process": "CAT_FASTQ",
        "string_process": "process CAT_FASTQ {\n    tag \"$meta.id\"\n    label 'process_low'\n\n    conda (params.enable_conda ? \"conda-forge::sed=4.7\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img' :\n        'biocontainers/biocontainers:v1.2.0_cv1' }\"\n\n    input:\n    tuple val(meta), path(reads, stageAs: \"input*/*\")\n\n    output:\n    tuple val(meta), path(\"*.merged.fastq.gz\"), emit: reads\n    path \"versions.yml\"                       , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    def readList = reads.collect{ it.toString() }\n    if (meta.single_end) {\n        if (readList.size > 1) {\n            \"\"\"\n            cat ${readList.join(' ')} > ${prefix}.merged.fastq.gz\n\n            cat <<-END_VERSIONS > versions.yml\n            \"${task.process}\":\n                cat: \\$(echo \\$(cat --version 2>&1) | sed 's/^.*coreutils) //; s/ .*\\$//')\n            END_VERSIONS\n            \"\"\"\n        }\n    } else {\n        if (readList.size > 2) {\n            def read1 = []\n            def read2 = []\n            readList.eachWithIndex{ v, ix -> ( ix & 1 ? read2 : read1 ) << v }\n            \"\"\"\n            cat ${read1.join(' ')} > ${prefix}_1.merged.fastq.gz\n            cat ${read2.join(' ')} > ${prefix}_2.merged.fastq.gz\n\n            cat <<-END_VERSIONS > versions.yml\n            \"${task.process}\":\n                cat: \\$(echo \\$(cat --version 2>&1) | sed 's/^.*coreutils) //; s/ .*\\$//')\n            END_VERSIONS\n            \"\"\"\n        }\n    }\n}",
        "nb_lignes_process": 49,
        "string_script": "    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    def readList = reads.collect{ it.toString() }\n    if (meta.single_end) {\n        if (readList.size > 1) {\n            \"\"\"\n            cat ${readList.join(' ')} > ${prefix}.merged.fastq.gz\n\n            cat <<-END_VERSIONS > versions.yml\n            \"${task.process}\":\n                cat: \\$(echo \\$(cat --version 2>&1) | sed 's/^.*coreutils) //; s/ .*\\$//')\n            END_VERSIONS\n            \"\"\"\n        }\n    } else {\n        if (readList.size > 2) {\n            def read1 = []\n            def read2 = []\n            readList.eachWithIndex{ v, ix -> ( ix & 1 ? read2 : read1 ) << v }\n            \"\"\"\n            cat ${read1.join(' ')} > ${prefix}_1.merged.fastq.gz\n            cat ${read2.join(' ')} > ${prefix}_2.merged.fastq.gz\n\n            cat <<-END_VERSIONS > versions.yml\n            \"${task.process}\":\n                cat: \\$(echo \\$(cat --version 2>&1) | sed 's/^.*coreutils) //; s/ .*\\$//')\n            END_VERSIONS\n            \"\"\"\n        }\n    }",
        "nb_lignes_script": 29,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_low'",
            "conda (params.enable_conda ? \"conda-forge::sed=4.7\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img' : 'biocontainers/biocontainers:v1.2.0_cv1' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "SAMPLESHEET_CHECK": {
        "name_process": "SAMPLESHEET_CHECK",
        "string_process": "process SAMPLESHEET_CHECK {\n    tag \"$samplesheet\"\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/python:3.8.3' :\n        'quay.io/biocontainers/python:3.8.3' }\"\n\n    input:\n    path samplesheet\n\n    output:\n    path '*.csv'       , emit: csv\n    path \"versions.yml\", emit: versions\n\n    script:                                                                         \n    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 25,
        "string_script": "    \"\"\"\n    check_samplesheet.py \\\\\n        $samplesheet \\\\\n        samplesheet.valid.csv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 9,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "samplesheet"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$samplesheet\"",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/python:3.8.3' : 'quay.io/biocontainers/python:3.8.3' }\""
        ],
        "when": "",
        "stub": ""
    },
    "DATABASE_CHECK": {
        "name_process": "DATABASE_CHECK",
        "string_process": "process DATABASE_CHECK {\n    tag \"$databasesheet\"\n\n    conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/python:3.8.3' :\n        'quay.io/biocontainers/python:3.8.3' }\"\n\n    input:\n    path databasesheet\n\n    output:\n    path '*.csv'       , emit: csv\n    path \"versions.yml\", emit: versions\n\n    script:                                                                         \n    \"\"\"\n    cat $databasesheet >> database_sheet.valid.csv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 23,
        "string_script": "    \"\"\"\n    cat $databasesheet >> database_sheet.valid.csv\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        python: \\$(python --version | sed 's/Python //g')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 7,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "databasesheet"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$databasesheet\"",
            "conda (params.enable_conda ? \"conda-forge::python=3.8.3\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/python:3.8.3' : 'quay.io/biocontainers/python:3.8.3' }\""
        ],
        "when": "",
        "stub": ""
    },
    "PORECHOP": {
        "name_process": "PORECHOP",
        "string_process": "process PORECHOP {\n    tag \"$meta.id\"\n    label 'process_medium'\n\n    conda (params.enable_conda ? \"bioconda::porechop=0.2.4\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/porechop:0.2.4--py39h7cff6ad_2' :\n        'quay.io/biocontainers/porechop:0.2.4--py39h7cff6ad_2' }\"\n\n    input:\n    tuple val(meta), path(reads)\n\n    output:\n    tuple val(meta), path(\"*.fastq.gz\"), emit: reads\n    path \"versions.yml\"                , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    \"\"\"\n    porechop \\\\\n        -i $reads \\\\\n        -t $task.cpus \\\\\n        $args \\\\\n        -o ${prefix}.fastq.gz\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        porechop: \\$( porechop --version )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 33,
        "string_script": "    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    \"\"\"\n    porechop \\\\\n        -i $reads \\\\\n        -t $task.cpus \\\\\n        $args \\\\\n        -o ${prefix}.fastq.gz\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        porechop: \\$( porechop --version )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 13,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "reads"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "conda (params.enable_conda ? \"bioconda::porechop=0.2.4\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/porechop:0.2.4--py39h7cff6ad_2' : 'quay.io/biocontainers/porechop:0.2.4--py39h7cff6ad_2' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "UNTAR": {
        "name_process": "UNTAR",
        "string_process": "process UNTAR {\n    tag \"$archive\"\n    label 'process_low'\n\n    conda (params.enable_conda ? \"conda-forge::tar=1.32\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img' :\n        'biocontainers/biocontainers:v1.2.0_cv1' }\"\n\n    input:\n    tuple val(meta), path(archive)\n\n    output:\n    tuple val(meta), path(\"$untar\"), emit: untar\n    path \"versions.yml\"            , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args  = task.ext.args ?: ''\n    def args2 = task.ext.args2 ?: ''\n    untar     = archive.toString() - '.tar.gz'\n    \"\"\"\n    tar \\\\\n        -xzvf \\\\\n        $args \\\\\n        $archive \\\\\n        $args2 \\\\\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        untar: \\$(echo \\$(tar --version 2>&1) | sed 's/^.*(GNU tar) //; s/ Copyright.*\\$//')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 34,
        "string_script": "    def args  = task.ext.args ?: ''\n    def args2 = task.ext.args2 ?: ''\n    untar     = archive.toString() - '.tar.gz'\n    \"\"\"\n    tar \\\\\n        -xzvf \\\\\n        $args \\\\\n        $archive \\\\\n        $args2 \\\\\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        untar: \\$(echo \\$(tar --version 2>&1) | sed 's/^.*(GNU tar) //; s/ Copyright.*\\$//')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 14,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "archive"
        ],
        "nb_inputs": 2,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$archive\"",
            "label 'process_low'",
            "conda (params.enable_conda ? \"conda-forge::tar=1.32\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://containers.biocontainers.pro/s3/SingImgsRepo/biocontainers/v1.2.0_cv1/biocontainers_v1.2.0_cv1.img' : 'biocontainers/biocontainers:v1.2.0_cv1' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "MULTIQC": {
        "name_process": "MULTIQC",
        "string_process": "process MULTIQC {\n    label 'process_medium'\n\n    conda (params.enable_conda ? 'bioconda::multiqc=1.12' : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/multiqc:1.12--pyhdfd78af_0' :\n        'quay.io/biocontainers/multiqc:1.12--pyhdfd78af_0' }\"\n\n    input:\n    path multiqc_files\n\n    output:\n    path \"*multiqc_report.html\", emit: report\n    path \"*_data\"              , emit: data\n    path \"*_plots\"             , optional:true, emit: plots\n    path \"versions.yml\"        , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n    \"\"\"\n    multiqc -f $args .\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        multiqc: \\$( multiqc --version | sed -e \"s/multiqc, version //g\" )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 29,
        "string_script": "    def args = task.ext.args ?: ''\n    \"\"\"\n    multiqc -f $args .\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        multiqc: \\$( multiqc --version | sed -e \"s/multiqc, version //g\" )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 8,
        "language_script": "bash",
        "tools": [
            "MultiQC"
        ],
        "tools_url": [
            "https://bio.tools/multiqc"
        ],
        "tools_dico": [
            {
                "name": "MultiQC",
                "uri": "https://bio.tools/multiqc",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "Sequencing"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0091",
                            "term": "Bioinformatics"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3168",
                            "term": "DNA-Seq"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_2428",
                                    "term": "Validation"
                                }
                            ],
                            []
                        ],
                        "input": [],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_2048",
                                "term": "Report"
                            }
                        ]
                    }
                ],
                "description": "MultiQC aggregates results from multiple bioinformatics analyses across many samples into a single report. It searches a given directory for analysis logs and compiles a HTML report. It's a general use tool, perfect for summarising the output from numerous bioinformatics tools.",
                "homepage": "http://multiqc.info/"
            }
        ],
        "inputs": [
            "multiqc_files"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "label 'process_medium'",
            "conda (params.enable_conda ? 'bioconda::multiqc=1.12' : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/multiqc:1.12--pyhdfd78af_0' : 'quay.io/biocontainers/multiqc:1.12--pyhdfd78af_0' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "KRAKEN2_KRAKEN2": {
        "name_process": "KRAKEN2_KRAKEN2",
        "string_process": "process KRAKEN2_KRAKEN2 {\n    tag \"$meta.id\"\n    label 'process_high'\n\n    conda (params.enable_conda ? 'bioconda::kraken2=2.1.2 conda-forge::pigz=2.6' : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:87fc08d11968d081f3e8a37131c1f1f6715b6542-0' :\n        'quay.io/biocontainers/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:87fc08d11968d081f3e8a37131c1f1f6715b6542-0' }\"\n\n    input:\n    tuple val(meta), path(reads)\n    path  db\n\n    output:\n    tuple val(meta), path('*classified*')  , emit: classified\n    tuple val(meta), path('*unclassified*'), emit: unclassified\n    tuple val(meta), path('*report.txt')   , emit: txt\n    path \"versions.yml\"                    , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    def paired       = meta.single_end ? \"\" : \"--paired\"\n    def classified   = meta.single_end ? \"${prefix}.classified.fastq\"   : \"${prefix}.classified#.fastq\"\n    def unclassified = meta.single_end ? \"${prefix}.unclassified.fastq\" : \"${prefix}.unclassified#.fastq\"\n    \"\"\"\n    kraken2 \\\\\n        --db $db \\\\\n        --threads $task.cpus \\\\\n        --unclassified-out $unclassified \\\\\n        --classified-out $classified \\\\\n        --report ${prefix}.kraken2.report.txt \\\\\n        --gzip-compressed \\\\\n        $paired \\\\\n        $args \\\\\n        $reads\n\n    pigz -p $task.cpus *.fastq\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        kraken2: \\$(echo \\$(kraken2 --version 2>&1) | sed 's/^.*Kraken version //; s/ .*\\$//')\n        pigz: \\$( pigz --version 2>&1 | sed 's/pigz //g' )\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 47,
        "string_script": "    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    def paired       = meta.single_end ? \"\" : \"--paired\"\n    def classified   = meta.single_end ? \"${prefix}.classified.fastq\"   : \"${prefix}.classified#.fastq\"\n    def unclassified = meta.single_end ? \"${prefix}.unclassified.fastq\" : \"${prefix}.unclassified#.fastq\"\n    \"\"\"\n    kraken2 \\\\\n        --db $db \\\\\n        --threads $task.cpus \\\\\n        --unclassified-out $unclassified \\\\\n        --classified-out $classified \\\\\n        --report ${prefix}.kraken2.report.txt \\\\\n        --gzip-compressed \\\\\n        $paired \\\\\n        $args \\\\\n        $reads\n\n    pigz -p $task.cpus *.fastq\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        kraken2: \\$(echo \\$(kraken2 --version 2>&1) | sed 's/^.*Kraken version //; s/ .*\\$//')\n        pigz: \\$( pigz --version 2>&1 | sed 's/pigz //g' )\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [
            "kraken2"
        ],
        "tools_url": [
            "https://bio.tools/kraken2"
        ],
        "tools_dico": [
            {
                "name": "kraken2",
                "uri": "https://bio.tools/kraken2",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_0637",
                            "term": "Taxonomy"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3174",
                            "term": "Metagenomics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomic classification"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3460",
                                    "term": "Taxonomy assignment"
                                }
                            ]
                        ],
                        "input": [
                            {
                                "uri": "http://edamontology.org/data_3494",
                                "term": "DNA sequence"
                            }
                        ],
                        "output": [
                            {
                                "uri": "http://edamontology.org/data_3028",
                                "term": "Taxonomy"
                            }
                        ]
                    }
                ],
                "description": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds. This classifier matches each k-mer within a query sequence to the lowest common ancestor (LCA) of all genomes containing the given k-mer. The k-mer assignments inform the classification algorithm.",
                "homepage": "https://ccb.jhu.edu/software/kraken2/"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "db"
        ],
        "nb_inputs": 3,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_high'",
            "conda (params.enable_conda ? 'bioconda::kraken2=2.1.2 conda-forge::pigz=2.6' : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:87fc08d11968d081f3e8a37131c1f1f6715b6542-0' : 'quay.io/biocontainers/mulled-v2-5799ab18b5fc681e75923b2450abaa969907ec98:87fc08d11968d081f3e8a37131c1f1f6715b6542-0' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "FASTP": {
        "name_process": "FASTP",
        "string_process": "process FASTP {\n    tag \"$meta.id\"\n    label 'process_medium'\n\n    conda (params.enable_conda ? 'bioconda::fastp=0.23.2' : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/fastp:0.23.2--h79da9fb_0' :\n        'quay.io/biocontainers/fastp:0.23.2--h79da9fb_0' }\"\n\n    input:\n    tuple val(meta), path(reads)\n    val   save_trimmed_fail\n    val   save_merged\n\n    output:\n    tuple val(meta), path('*.trim.fastq.gz')  , optional:true, emit: reads\n    tuple val(meta), path('*.json')           , emit: json\n    tuple val(meta), path('*.html')           , emit: html\n    tuple val(meta), path('*.log')            , emit: log\n    path \"versions.yml\"                       , emit: versions\n    tuple val(meta), path('*.fail.fastq.gz')  , optional:true, emit: reads_fail\n    tuple val(meta), path('*.merged.fastq.gz'), optional:true, emit: reads_merged\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n                                                                           \n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    if (meta.single_end) {\n        def fail_fastq = save_trimmed_fail ? \"--failed_out ${prefix}.fail.fastq.gz\" : ''\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastp \\\\\n            --in1 ${prefix}.fastq.gz \\\\\n            --out1 ${prefix}.trim.fastq.gz \\\\\n            --thread $task.cpus \\\\\n            --json ${prefix}.fastp.json \\\\\n            --html ${prefix}.fastp.html \\\\\n            $fail_fastq \\\\\n            $args \\\\\n            2> ${prefix}.fastp.log\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastp: \\$(fastp --version 2>&1 | sed -e \"s/fastp //g\")\n        END_VERSIONS\n        \"\"\"\n    } else {\n        def fail_fastq  = save_trimmed_fail ? \"--unpaired1 ${prefix}_1.fail.fastq.gz --unpaired2 ${prefix}_2.fail.fastq.gz\" : ''\n        def merge_fastq = save_merged ? \"-m --merged_out ${prefix}.merged.fastq.gz\" : ''\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastp \\\\\n            --in1 ${prefix}_1.fastq.gz \\\\\n            --in2 ${prefix}_2.fastq.gz \\\\\n            --out1 ${prefix}_1.trim.fastq.gz \\\\\n            --out2 ${prefix}_2.trim.fastq.gz \\\\\n            --json ${prefix}.fastp.json \\\\\n            --html ${prefix}.fastp.html \\\\\n            $fail_fastq \\\\\n            $merge_fastq \\\\\n            --thread $task.cpus \\\\\n            --detect_adapter_for_pe \\\\\n            $args \\\\\n            2> ${prefix}.fastp.log\n\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastp: \\$(fastp --version 2>&1 | sed -e \"s/fastp //g\")\n        END_VERSIONS\n        \"\"\"\n    }\n}",
        "nb_lignes_process": 73,
        "string_script": "    def args = task.ext.args ?: ''\n                                                                           \n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    if (meta.single_end) {\n        def fail_fastq = save_trimmed_fail ? \"--failed_out ${prefix}.fail.fastq.gz\" : ''\n        \"\"\"\n        [ ! -f  ${prefix}.fastq.gz ] && ln -s $reads ${prefix}.fastq.gz\n        fastp \\\\\n            --in1 ${prefix}.fastq.gz \\\\\n            --out1 ${prefix}.trim.fastq.gz \\\\\n            --thread $task.cpus \\\\\n            --json ${prefix}.fastp.json \\\\\n            --html ${prefix}.fastp.html \\\\\n            $fail_fastq \\\\\n            $args \\\\\n            2> ${prefix}.fastp.log\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastp: \\$(fastp --version 2>&1 | sed -e \"s/fastp //g\")\n        END_VERSIONS\n        \"\"\"\n    } else {\n        def fail_fastq  = save_trimmed_fail ? \"--unpaired1 ${prefix}_1.fail.fastq.gz --unpaired2 ${prefix}_2.fail.fastq.gz\" : ''\n        def merge_fastq = save_merged ? \"-m --merged_out ${prefix}.merged.fastq.gz\" : ''\n        \"\"\"\n        [ ! -f  ${prefix}_1.fastq.gz ] && ln -s ${reads[0]} ${prefix}_1.fastq.gz\n        [ ! -f  ${prefix}_2.fastq.gz ] && ln -s ${reads[1]} ${prefix}_2.fastq.gz\n        fastp \\\\\n            --in1 ${prefix}_1.fastq.gz \\\\\n            --in2 ${prefix}_2.fastq.gz \\\\\n            --out1 ${prefix}_1.trim.fastq.gz \\\\\n            --out2 ${prefix}_2.trim.fastq.gz \\\\\n            --json ${prefix}.fastp.json \\\\\n            --html ${prefix}.fastp.html \\\\\n            $fail_fastq \\\\\n            $merge_fastq \\\\\n            --thread $task.cpus \\\\\n            --detect_adapter_for_pe \\\\\n            $args \\\\\n            2> ${prefix}.fastp.log\n\n        cat <<-END_VERSIONS > versions.yml\n        \"${task.process}\":\n            fastp: \\$(fastp --version 2>&1 | sed -e \"s/fastp //g\")\n        END_VERSIONS\n        \"\"\"\n    }",
        "nb_lignes_script": 46,
        "language_script": "bash",
        "tools": [
            "fastPHASE"
        ],
        "tools_url": [
            "https://bio.tools/fastphase"
        ],
        "tools_dico": [
            {
                "name": "fastPHASE",
                "uri": "https://bio.tools/fastphase",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3056",
                            "term": "Population genetics"
                        }
                    ],
                    []
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3454",
                                    "term": "Phasing"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Imputation"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3557",
                                    "term": "Data imputation"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "fastPHASE is a program to estimate missing genotypes and unobserved haplotypes. It is an implementation of the model described in Scheet & Stephens (2006). This is a cluster-based model for haplotype variation, and gains its utility from implicitly modeling the genealogy of chromosomes in a random sample from a population as a tree but summarizing all haplotype variation in the \"tips\" of the trees.",
                "homepage": "http://scheet.org/software.html"
            }
        ],
        "inputs": [
            "meta",
            "reads",
            "save_trimmed_fail",
            "save_merged"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_medium'",
            "conda (params.enable_conda ? 'bioconda::fastp=0.23.2' : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/fastp:0.23.2--h79da9fb_0' : 'quay.io/biocontainers/fastp:0.23.2--h79da9fb_0' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "MALT_RUN": {
        "name_process": "MALT_RUN",
        "string_process": "process MALT_RUN {\n    tag \"$meta.id\"\n    label 'process_high'\n\n    conda (params.enable_conda ? \"bioconda::malt=0.53\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/malt:0.53--hdfd78af_0' :\n        'quay.io/biocontainers/malt:0.53--hdfd78af_0' }\"\n\n    input:\n    tuple val(meta), path(fastqs)\n    val mode\n    path index\n\n    output:\n    tuple val(meta), path(\"*.rma6\")                          , emit: rma6\n    tuple val(meta), path(\"*.{tab,text,sam}\"),  optional:true, emit: alignments\n    tuple val(meta), path(\"*.log\")                           , emit: log\n    path \"versions.yml\"                                      , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    def avail_mem = 6\n    if (!task.memory) {\n        log.info '[MALT_RUN] Available memory not known - defaulting to 6GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.giga\n    }\n\n    \"\"\"\n    malt-run \\\\\n        -J-Xmx${avail_mem}g \\\\\n        -t $task.cpus \\\\\n        -v \\\\\n        -o . \\\\\n        $args \\\\\n        --inFile ${fastqs.join(' ')} \\\\\n        -m $mode \\\\\n        --index $index/ |&tee ${prefix}-malt-run.log\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        malt: \\$(malt-run --help  2>&1 | grep -o 'version.* ' | cut -f 1 -d ',' | cut -f2 -d ' ')\n    END_VERSIONS\n    \"\"\"\n}",
        "nb_lignes_process": 48,
        "string_script": "    def args = task.ext.args ?: ''\n    def prefix = task.ext.prefix ?: \"${meta.id}\"\n    def avail_mem = 6\n    if (!task.memory) {\n        log.info '[MALT_RUN] Available memory not known - defaulting to 6GB. Specify process memory requirements to change this.'\n    } else {\n        avail_mem = task.memory.giga\n    }\n\n    \"\"\"\n    malt-run \\\\\n        -J-Xmx${avail_mem}g \\\\\n        -t $task.cpus \\\\\n        -v \\\\\n        -o . \\\\\n        $args \\\\\n        --inFile ${fastqs.join(' ')} \\\\\n        -m $mode \\\\\n        --index $index/ |&tee ${prefix}-malt-run.log\n\n    cat <<-END_VERSIONS > versions.yml\n    \"${task.process}\":\n        malt: \\$(malt-run --help  2>&1 | grep -o 'version.* ' | cut -f 1 -d ',' | cut -f2 -d ' ')\n    END_VERSIONS\n    \"\"\"",
        "nb_lignes_script": 24,
        "language_script": "bash",
        "tools": [],
        "tools_url": [],
        "tools_dico": [],
        "inputs": [
            "meta",
            "fastqs",
            "mode",
            "index"
        ],
        "nb_inputs": 4,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "tag \"$meta.id\"",
            "label 'process_high'",
            "conda (params.enable_conda ? \"bioconda::malt=0.53\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/malt:0.53--hdfd78af_0' : 'quay.io/biocontainers/malt:0.53--hdfd78af_0' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    },
    "CUSTOM_DUMPSOFTWAREVERSIONS": {
        "name_process": "CUSTOM_DUMPSOFTWAREVERSIONS",
        "string_process": "process CUSTOM_DUMPSOFTWAREVERSIONS {\n    label 'process_low'\n\n                                                                                                  \n    conda (params.enable_conda ? \"bioconda::multiqc=1.11\" : null)\n    container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ?\n        'https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0' :\n        'quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0' }\"\n\n    input:\n    path versions\n\n    output:\n    path \"software_versions.yml\"    , emit: yml\n    path \"software_versions_mqc.yml\", emit: mqc_yml\n    path \"versions.yml\"             , emit: versions\n\n    when:\n    task.ext.when == null || task.ext.when\n\n    script:\n    def args = task.ext.args ?: ''\n    template 'dumpsoftwareversions.py'\n}",
        "nb_lignes_process": 22,
        "string_script": "    def args = task.ext.args ?: ''\n    template 'dumpsoftwareversions.py'",
        "nb_lignes_script": 1,
        "language_script": "bash",
        "tools": [
            "docxtemplate"
        ],
        "tools_url": [
            "https://bio.tools/docxtemplate"
        ],
        "tools_dico": [
            {
                "name": "docxtemplate",
                "uri": "https://bio.tools/docxtemplate",
                "topic": [
                    [
                        {
                            "uri": "http://edamontology.org/topic_3314",
                            "term": "Chemistry"
                        },
                        {
                            "uri": "http://edamontology.org/topic_0176",
                            "term": "Molecular dynamics"
                        },
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database management"
                        }
                    ],
                    [
                        {
                            "uri": "http://edamontology.org/topic_3489",
                            "term": "Database administration"
                        }
                    ]
                ],
                "function": [
                    {
                        "operation": [
                            [
                                {
                                    "uri": "http://edamontology.org/operation_0249",
                                    "term": "Protein geometry calculation"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_0322",
                                    "term": "Molecular model refinement"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Deposition"
                                }
                            ],
                            [
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database deposition"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Database submission"
                                },
                                {
                                    "uri": "http://edamontology.org/operation_3431",
                                    "term": "Data deposition"
                                }
                            ]
                        ],
                        "input": [],
                        "output": []
                    }
                ],
                "description": "> VERY_LOW CONFIDENCE! | > CORRECT NAME OF TOOL COULD ALSO BE 'Phenix', 'restraints', 'Amber', 'refinement' | Improved chemistry restraints for crystallographic refinement by integrating the Amber force field into Phenix | Word templates and tools for Windows | The IUCr Word templates utilize the content management features and document styles of Word to format your manuscript and to store essential details for submission of your manuscript",
                "homepage": "http://journals.iucr.org/services/docxtemplate/"
            }
        ],
        "inputs": [
            "versions"
        ],
        "nb_inputs": 1,
        "outputs": [],
        "nb_outputs": 0,
        "name_workflow": "nf-core__taxprofiler",
        "directive": [
            "label 'process_low'",
            "conda (params.enable_conda ? \"bioconda::multiqc=1.11\" : null)",
            "container \"${ workflow.containerEngine == 'singularity' && !task.ext.singularity_pull_docker_container ? 'https://depot.galaxyproject.org/singularity/multiqc:1.11--pyhdfd78af_0' : 'quay.io/biocontainers/multiqc:1.11--pyhdfd78af_0' }\""
        ],
        "when": "task.ext.when == null || task.ext.when",
        "stub": ""
    }
}